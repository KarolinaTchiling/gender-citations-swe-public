FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Lin, YS
   Liu, YC
   Lee, CC
AF Lin, Yun-Shao
   Liu, Yi-Ching
   Lee, Chi-Chun
TI An Interaction-process-guided Framework for Small-group Performance
   Prediction
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Small group interaction; Supervised Auto-encoder; communicative
   functions; multimodal behaviors
ID DECISION-MAKING; TEAM PROCESS; COMMUNICATION; INTELLIGENCE; REFLECTION;
   INNOVATION; BEHAVIOR; TRIADS; STYLE; DYADS
AB A small group is a fundamental interaction unit for achieving a shared goal. Group performance can be automatically predicted using computational methods to analyze members' verbal behavior in task-oriented interactions, as has been proven in several recent works. Most of the prior works focus on lower-level verbal behaviors, such as acoustics and turn-taking patterns, using either hand-crafted features or even advanced end-to-end methods. However, higher-level group-based communicative functions used between groupmembers during conversations have not yet been considered. In this work, we propose a two-stage training framework that effectively integrates the communication function, as defined using Bales's interaction process analysis (IPA) coding system, with the embedding learned from the low-level features in order to improve the group performance prediction. Our result shows a significant improvement compared to the state-of-the-art methods (4.241 MSE and 0.341 Pearson's correlation on NTUBA-task1 and 3.794 MSE and 0.291 Pearson's correlation on NTUBA-task2) on the National Taiwan University Business Administration (NTUBA) small-group interaction database. Furthermore, based on the design of IPA, our computational framework can provide a time-grained analysis of the group communication process and interpret the beneficial communicative behaviors for achieving better group performance.
C1 [Lin, Yun-Shao; Lee, Chi-Chun] Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu, Taiwan.
   [Lin, Yun-Shao; Lee, Chi-Chun] MOST Joint Res Ctr AI Technol & All Vista Healthc, Taipei, Taiwan.
   [Liu, Yi-Ching] Natl Taiwan Univ, Dept Business Adm, Taipei, Taiwan.
C3 National Tsing Hua University; National Taiwan University
RP Lin, YS (corresponding author), Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu, Taiwan.; Lin, YS (corresponding author), MOST Joint Res Ctr AI Technol & All Vista Healthc, Taipei, Taiwan.
EM yunshaolin@gmail.com; cclee@ee.nthu.edu.tw
OI Lee, Chi-Chun/0000-0003-0186-4321; Liu, Yi-Ching/0000-0002-1941-0814
CR [Anonymous], 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems
   Avci U, 2016, IEEE T MULTIMEDIA, V18, P643, DOI 10.1109/TMM.2016.2521348
   Bales RobertF., 1950, INTERACTION PROCESS
   Bazarevsky V, 2020, Arxiv, DOI arXiv:2006.10204
   Bazarevsky V, 2019, Arxiv, DOI [arXiv:1907.05047, 10.48550/arXiv.1907.05047, DOI 10.48550/ARXIV.1907.05047]
   Bhattacharya I, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P249, DOI 10.1145/3304109.3325816
   BOTTGER PC, 1988, ORGAN BEHAV HUM DEC, V42, P234, DOI 10.1016/0749-5978(88)90014-3
   Braley M, 2018, PROCEEDINGS OF THE GROUP INTERACTION FRONTIERS IN TECHNOLOGY (GIFT'18), DOI 10.1145/3279981.3279985
   Bunt H, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P430
   Clarke N, 2010, J WORKPLACE LEARN, V22, P125, DOI 10.1108/13665621011028594
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   DiMicco JM, 2007, HUM-COMPUT INTERACT, V22, P47
   Fischer U, 2007, AVIAT SPACE ENVIR MD, V78, pB86
   Foushee H.C., 1981, 5. INFORMATION TRANSFER WITHIN THE COCKPIT: PROBLEMS IN mTRACOCKPlT COMMUNICATIONS, P63
   FOUSHEE HC, 1984, AM PSYCHOL, V39, P885, DOI 10.1037/0003-066X.39.8.885
   GIST ME, 1987, J MANAGE, V13, P237, DOI 10.1177/014920638701300204
   Gonzales AL, 2010, COMMUN RES, V37, P3, DOI 10.1177/0093650209351468
   Gorse CA, 2009, CONSTR MANAG ECON, V27, P983, DOI 10.1080/01446190903179710
   Gorse CA, 2007, CONSTR MANAG ECON, V25, P1197, DOI 10.1080/01446190701567413
   Gorse Christopher A., 2001, P ASS RES CONSTRUCTI, P5
   Hackman J.R., 1975, Advances in experimental social psychology, V8, P47, DOI [DOI 10.1016/S0065-2601(08)60248-8, 10.1016/S0065-2601(08)60248-8]
   Hackman J.R., 2010, HDB SOCIAL PSYCHOL, V2, P1208, DOI [10.1002/9780470561119.socpsy002032, DOI 10.1002/9780470561119.SOCPSY002032]
   HILTZ SR, 1986, HUM COMMUN RES, V13, P225, DOI 10.1111/j.1468-2958.1986.tb00104.x
   Ishii R, 2019, LECT NOTES COMPUT SC, V11579, P45, DOI 10.1007/978-3-030-21905-5_4
   Ishii R, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P31, DOI 10.1145/3242969.3242978
   Kartynnik Y, 2019, Arxiv, DOI [arXiv:1907.06724, DOI 10.48550/ARXIV.1907.06724]
   Kubasova U, 2019, Arxiv, DOI arXiv:1907.01369
   Kubasova U, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P191, DOI 10.1145/3395035.3425964
   Le L, 2018, ADV NEUR IN, V31
   Leshed G., 2009, AUTOMATED LANGUAGE B
   Li SX, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P426, DOI 10.1145/3340555.3353743
   Lin YS, 2020, INT CONF ACOUST SPEE, P8044, DOI [10.1109/icassp40776.2020.9053308, 10.1109/ICASSP40776.2020.9053308]
   Lin YS, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P163, DOI 10.1145/3242969.3243001
   Malik U, 2020, PROC INT C TOOLS ART, P349, DOI 10.1109/ICTAI50040.2020.00062
   Martin Melanie J., 2004, AUTOMATED TEAM DISCO
   McGrath J.E., 1984, GROUPS INTERACTION P
   Murray G, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P14, DOI 10.1145/3242969.3243027
   Nowak Michael, 2012, P ACM 2012 C COMPUTE, P1081
   Ohlsson J, 2013, J WORKPLACE LEARN, V25, P296, DOI 10.1108/JWL-Feb-2012-0011
   Okada S, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P169, DOI 10.1145/2993148.2993154
   Olaniran B.A., 1994, MANAGE COMMUN Q, V7, P256
   Pianesi F, 2007, LANG RESOUR EVAL, V41, P409, DOI 10.1007/s10579-007-9060-6
   Reitter D, 2014, J MEM LANG, V76, P29, DOI 10.1016/j.jml.2014.05.008
   ROBY TB, 1956, SOCIOMETRY, V19, P105, DOI 10.2307/2786120
   Sanchez-Cortes D, 2012, IEEE T MULTIMEDIA, V14, P816, DOI 10.1109/TMM.2011.2181941
   Somech A, 2006, J MANAGE, V32, P132, DOI 10.1177/0149206305277799
   Subburaj Shree Krishna, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P423, DOI 10.1145/3382507.3418877
   Tschan F, 2002, SMALL GR RES, V33, P615, DOI 10.1177/1046496402238618
   TSCHAN F, 1995, BASIC APPL SOC PSYCH, V17, P371, DOI 10.1207/s15324834basp1703_6
   Vaswani A, 2017, ADV NEUR IN, V30
   West MA, 2000, ADV INT ST, V5, P1
   Wheelan S.A., 2005, The handbook of group research and practice
   Wiedow A, 2011, SMALL GR RES, V42, P32, DOI 10.1177/1046496410377358
   Woolley AW, 2010, SCIENCE, V330, P686, DOI 10.1126/science.1193147
   Zhong SC, 2019, INTERSPEECH, P1676, DOI 10.21437/Interspeech.2019-2087
NR 55
TC 0
Z9 0
U1 1
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2023
VL 19
IS 2
AR 58
DI 10.1145/3558768
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J7DP3
UT WOS:001011190000008
DA 2024-07-18
ER

PT J
AU Jaiswal, RK
   Dubey, RK
AF Jaiswal, Rahul Kumar
   Dubey, Rajesh Kumar
TI CAQoE: A Novel No-Reference Context-aware Speech Quality Prediction
   Metric
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Classifier; deep neural network; speech enhancement; no-reference;
   speech quality; quality of experience (QoE); voice activity detector;
   VoIP
ID NARROW-BAND; ENHANCEMENT; NETWORKS; STANDARD
AB The quality of speech degradeswhile communicating over Voice over Internet Protocol applications, for example, Google Meet, Microsoft Skype, and Apple FaceTime, due to different types of background noise present in the surroundings. It reduces human perceived Quality of Experience (QoE). Along this line, this article proposes a novel speech quality prediction metric that can meet human's desired QoE level. Our motivation is driven by the lack of evidence showing speech quality metrics that can distinguish different noise degradations before predicting the quality of speech. The quality of speech in noisy environments is improved by speech enhancement algorithms, and for measuring and monitoring the quality of speech, objective speech quality metrics are used. With the integration of these components, a novel no-reference context-aware QoE prediction metric (CAQoE) is proposed in this article, which initially identifies the context or noise type or degradation type of the input noisy speech signal and then predicts context-specific speech quality for that input speech signal. It will have of great importance in deciding the speech enhancement algorithms if the types of degradations causing poor speech quality are known along with the quality metric. Results demonstrate that the proposed CAQoE metric outperforms in different contexts as compared to the metric where contexts are not identified before predicting the quality of speech, even in the presence of limited size speech corpus having different contexts available from the NOIZEUS speech database.
C1 [Jaiswal, Rahul Kumar] Univ Agder, Fac Sci & Engn, Dept Informat & Commun Technol, Grimstad, Norway.
   [Dubey, Rajesh Kumar] Cent Univ Haryana, Sch Engn & Technol, Dept Elect Engn, Mahendragarh 123031, India.
C3 University of Agder; Central University of Haryana
RP Jaiswal, RK (corresponding author), Univ Agder, Dept Informat & Commun Technol, Fac Engn & Sci, N-4879 Grimstad, Norway.
EM rahul.jaiswal@uia.no; rajesh.dubey@cuh.ac.in
OI DUBEY, RAJESH/0000-0003-0028-507X; Jaiswal, Rahul/0000-0003-3800-7235
CR Affonso ET, 2018, IEEE ACCESS, V6, P77022, DOI 10.1109/ACCESS.2018.2871072
   Alpaydin E., 2020, INTRO MACHINE LEARNI, DOI DOI 10.7551/MITPRESS/13811.001.0001
   [Anonymous], 2004, ITU-T Rec. P.563
   [Anonymous], 1996, Rec. ITU-T P.800
   [Anonymous], 2011, P863 ITUT
   [Anonymous], 2003, Itu-t recommendation g. 107: The e-model, a computational model for use in transmission planning
   [Anonymous], 2013, White Paper
   Avila AR, 2019, INT CONF ACOUST SPEE, P631, DOI 10.1109/ICASSP.2019.8683175
   Belarouci S., 2017, ADV SCI TECHNOLOGY E, V2, P116, DOI DOI 10.25046/AJ020316
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Bruhn S., 2012, US Patent, Patent No. [8,195,449, 8195449]
   Catellier AA, 2020, INT CONF ACOUST SPEE, P331, DOI [10.1109/icassp40776.2020.9054204, 10.1109/ICASSP40776.2020.9054204]
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chinen M, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123150
   Deligiannidis L., 2014, Emerging Trends in Image Processing, Computer Vision and Pattern Recognition
   Dimitrakopoulos GN, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), DOI 10.1145/3200947.3201029
   Dozat T., 2016, ICLR WORKSHOP
   Drummond C., 2003, P INT C MACH LEARN W
   Dubey RK, 2013, INT J SPEECH TECHNOL, V16, P89, DOI 10.1007/s10772-012-9162-4
   Dubey RK, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSC), P261, DOI 10.1109/ICSPCom.2015.7150659
   Eisen M, 2018, CONF REC ASILOMAR C, P1289, DOI 10.1109/ACSSC.2018.8645312
   EPHRAIM Y, 1992, P IEEE, V80, P1526, DOI 10.1109/5.168664
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Fernandez A., 2018, LEARNING IMBALANCED
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Fu Szu-Wei, 2018, P C INT SPEECH COMMU
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Grancharov V, 2006, IEEE T AUDIO SPEECH, V14, P1948, DOI 10.1109/TASL.2006.883250
   Gustafsson H, 2001, IEEE T SPEECH AUDI P, V9, P799, DOI 10.1109/89.966083
   HaojunWu YongWang, 2017, ACM T MULTIM COMPUT, V13, P1
   Hines A, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0054-9
   Hinton G., 2012, COURSERA VIDEO LECT
   Hirsch Hans-Gunter, 2000, ASR2000 AUT SPEECH R
   Hu Y, 2004, IEEE T SPEECH AUDI P, V12, P59, DOI 10.1109/TSA.2003.819949
   Hu Y, 2003, IEEE T SPEECH AUDI P, V11, P334, DOI 10.1109/TSA.2003.814458
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Hu Y, 2006, INT CONF ACOUST SPEE, P153
   Israel C, 2002, IEEE SIGNAL PROC LET, V9, P113, DOI 10.1109/97.1001645
   ITU-T Rec, 1998, COD SPEECH DAT P S23
   Jahromi HZ, 2018, INT CONF UBIQ FUTUR, P126, DOI 10.1109/ICUFN.2018.8436625
   Jain R. K., 2014, 2014 International Conference on Computing in Civil and Building Engineering. Proceedings, P1675
   Jaiswal Rahul, 2022, Proceedings of the 11th International Conference on Robotics, Vision, Signal Processing and Power Applications: Enhancing Research and Innovation through the Fourth Industrial Revolution. Lecture Notes in Electrical Engineering (829), P59, DOI 10.1007/978-981-16-8129-5_10
   Jaiswal R, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2020), P1, DOI 10.1109/BigDataService49289.2020.00009
   Jedari E, 2015, INT C INDOOR POSIT
   Kamath S, 2002, INT CONF ACOUST SPEE, P4164
   Kim DS, 2007, BELL LABS TECH J, V12, P221, DOI 10.1002/bltj.20228
   Kingma D. P., 2015, P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR P 3 INT C LEARN REPR, P1
   Li Y, 2017, KNOWL INF SYST, V53, P551, DOI 10.1007/s10115-017-1059-8
   Liang XM, 2012, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT (IEEE IC-NIDC 2012), P57, DOI 10.1109/ICNIDC.2012.6418711
   Malfait L, 2006, IEEE T AUDIO SPEECH, V14, P1924, DOI 10.1109/TASL.2006.883177
   Mittal U, 2000, IEEE T SPEECH AUDI P, V8, P159, DOI 10.1109/89.824700
   Möller S, 2011, IEEE SIGNAL PROC MAG, V28, P18, DOI 10.1109/MSP.2011.942469
   Nunes RD, 2019, IET COMMUN, V13, P3401, DOI 10.1049/iet-com.2018.5165
   Ooster J, 2018, INTERSPEECH, P976
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Rodríguez DZ, 2021, IEEE-ACM T AUDIO SPE, V29, P956, DOI 10.1109/TASLP.2021.3057955
   Rodríguez DZ, 2019, IEEE ACCESS, V7, P35719, DOI 10.1109/ACCESS.2019.2902798
   Rodriguez Demostenes Zegarra, 2019, INT WORK QUAL MULTIM, P1
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199
   Soni MH, 2021, SPEECH COMMUN, V130, P27, DOI 10.1016/j.specom.2021.03.004
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun HR, 2017, IEEE INT WORK SIGN P
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Vapnik VN, 2000, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-3264-1
   Wang QY, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3345314
   Yang H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P99, DOI 10.1109/ICDSP.2016.7868524
   Ye H, 2018, IEEE GLOBE WORK
   Ye H, 2018, IEEE WIREL COMMUN LE, V7, P114, DOI 10.1109/LWC.2017.2757490
   Zareapoor Masoumeh, 2021, ACMTRANS MULTIMEDIA, V17, P1
   Zhang HY, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3357253
NR 72
TC 1
Z9 1
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2023
VL 19
IS 1
SU S
AR 35
DI 10.1145/3529394
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I2QV2
UT WOS:001001289700001
OA Bronze
DA 2024-07-18
ER

PT J
AU Yuan, MQ
   Bao, BK
   Tan, ZY
   Xu, CS
AF Yuan, Mengqi
   Bao, Bing-Kun
   Tan, Zhiyi
   Xu, Changsheng
TI Adaptive Text Denoising Network for Image Caption Editing
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image caption editing; sequence editing; cross-modal semantic matching
AB Image caption editing, which aims at editing the inaccurate descriptions of the images, is an interdisciplinary task of computer vision and natural language processing. As the task requires encoding the image and its corresponding inaccurate caption simultaneously and decoding to generate an accurate image caption, the encoder-decoder framework is widely adopted for image caption editing. However, existing methods mostly focus on the decoder, yet ignore a big challenge on the encoder: the semantic inconsistency between image and caption. To this end, we propose a novel Adaptive Text Denoising Network (ATD-Net) to filter out noises at the word level and improve the model's robustness at sentence level. Specifically, at the word level, we design a cross-attention mechanism called Textual Attention Mechanism (TAM), to differentiate the misdescriptive words. The TAM is designed to encode the inaccurate caption word by word based on the content of both image and caption. At the sentence level, in order to minimize the influence of misdescriptive words on the semantic of an entire caption, we introduce a Bidirectional Encoder to extract the correct semantic representation from the raw caption. The Bidirectional Encoder is able to model the global semantics of the raw caption, which enhances the robustness of the framework. We extensively evaluate our proposals on the MS-COCO image captioning dataset and prove the effectiveness of our method when compared with the state-of-the-arts.
C1 [Yuan, Mengqi; Bao, Bing-Kun; Tan, Zhiyi] Nanjing Univ Postsand Telecommun, Nanjing, Peoples R China.
   [Xu, Changsheng] Peng Cheng Lab, Beijing, Peoples R China.
   [Xu, Changsheng] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Xu, Changsheng] Chinese Acad Sci, Inst Automat, NLPR, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Automation, CAS
RP Bao, BK (corresponding author), Nanjing Univ Postsand Telecommun, Nanjing, Peoples R China.
EM 2020010306@njupt.edu.cn; bingkunbao@njupt.edu.cn
RI YUAN, Mengqi/ABE-5029-2021; xu, cj/HJZ-3488-2023
OI YUAN, Mengqi/0000-0002-2471-5145; Bao, Bingkun/0000-0001-5956-831X; xu,
   chang sheng/0000-0001-8343-9665
FU National Key Research and Development Project [2020AAA0106200]; National
   Nature Science Foundation of China [61936005, 61872424]; Natural Science
   Foundation of Jiangsu Province [BK20200037, BK20210595]
FX This work was supported by National Key Research and Development Project
   (No. 2020AAA0106200), the National Nature Science Foundation of China
   under Grants (No. 61936005, 61872424), and the Natural Science
   Foundation of Jiangsu Province (Grants No. BK20200037 and BK20210595).
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chen C., 2021, P IEEE INT C COMPUTE, P10
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Guo LT, 2020, IEEE T MULTIMEDIA, V22, P2149, DOI 10.1109/TMM.2019.2951226
   Guo LT, 2019, PROC CVPR IEEE, P4199, DOI 10.1109/CVPR.2019.00433
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Huang L, 2019, ADV NEUR IN, V32
   Huang YQ, 2020, IEEE T IMAGE PROCESS, V29, P4013, DOI 10.1109/TIP.2020.2969330
   Jean S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1
   Ji JZ, 2020, IEEE T IMAGE PROCESS, V29, P7615, DOI 10.1109/TIP.2020.3004729
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Kingma D, 2014, ICLR P, V2014, P1
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Liao Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3855
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ling Lo, 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), DOI 10.1109/ICME51207.2021.9428120
   Liu AJ, 2021, IEEE T CYBERNETICS, V51, P3198, DOI 10.1109/TCYB.2020.2983962
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Malmi E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5054
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sammani F., 2019, BMVC, P75
   Sammani F, 2020, PROC CVPR IEEE, P4807, DOI 10.1109/CVPR42600.2020.00486
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shi N, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1758
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9959, DOI 10.1109/CVPR42600.2020.00998
   Sutskever I, 2014, ADV NEUR IN, V27
   Tao M., 2022, P IEEE C COMPUTER VI
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang J., 2021, IEEE Transactions on Multimedia, V14, P8
   Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176
   Wang L, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4003
   Wu LX, 2020, IEEE T MULTIMEDIA, V22, P808, DOI 10.1109/TMM.2019.2931815
   Xie HX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2871, DOI 10.1145/3394171.3414012
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu N, 2020, IEEE T MULTIMEDIA, V22, P1372, DOI 10.1109/TMM.2019.2941820
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Zha ZJ, 2022, IEEE T PATTERN ANAL, V44, P710, DOI 10.1109/TPAMI.2019.2909864
   Zhou L, 2020, IEEE T IMAGE PROCESS, V29, P694, DOI 10.1109/TIP.2019.2928144
NR 55
TC 2
Z9 2
U1 8
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2023
VL 19
IS 1
SU S
AR 41
DI 10.1145/3532627
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Q4HK
UT WOS:000927169800015
DA 2024-07-18
ER

PT J
AU Zhu, XK
   Li, CL
   Chen, XP
   Zhang, XY
   Jing, XY
AF Zhu, Xiaoke
   Li, Changlong
   Chen, Xiaopan
   Zhang, Xinyu
   Jing, Xiao-Yuan
TI Distance and Direction Based Deep Discriminant Metric Learning for
   Kinship Verification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image-based kinship verification; distance-based and direction-based
   deep discriminant metric learning ((DML)-M-4)
ID FACE; NETWORKS; FEATURES
AB Image-based kinship verification is an important task in computer vision and has many applications in practice, such as missing children search and family album construction, among others. Due to the differences in age, gender, expression and appearance, there usually exists a large discrepancy between the facial images of parent and child. This makes kinship verification a challenging task. In this article, we propose a Distance and Direction Based Deep Discriminant Metric Learning ((DML)-M-4) approach for kinship verification. The basic idea of D4ML is to make full use of the discriminant information contained in the facial images of parent and child such that the network can learn more a discriminating distance metric. Specifically, D4ML learns the metric by utilizing the discriminant information from two perspectives: distance-based perspective and direction-based perspective. From the distance-based perspective, the designed loss function is used to minimize the distance between images having kinship and maximize the distance between images without kinship. In practice, the gender difference and large age gap may significantly increase the distance between facial images of parent and child. Therefore, learning the metric only from a distance-based perspective is insufficient. Considering that two vectors with a large distance may appear with high similarity in direction, D4ML also employs the direction-based loss function in the training process. Both kinds of loss function work together to improve the discriminability of the learned metric. Experimental results on four small size publicly available datasets demonstrate the effectiveness of our approach. Source code of our approach can be found at https://github.com/lclhenu/D4ML.
C1 [Zhu, Xiaoke] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475001, Peoples R China.
   [Li, Changlong] Henan Univ, Henan Engn Res Ctr Intelligent Technol & Applicat, Kaifeng 475001, Peoples R China.
   [Chen, Xiaopan] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475001, Peoples R China.
   [Zhang, Xinyu; Jing, Xiao-Yuan] Wuhan Univ, Sch Comp, Wuhan 475001, Peoples R China.
C3 Henan University; Henan University; Henan University; Wuhan University
RP Chen, XP (corresponding author), Henan Univ, Sch Comp & Informat Engn, Kaifeng 475001, Peoples R China.; Jing, XY (corresponding author), Wuhan Univ, Sch Comp, Wuhan 475001, Peoples R China.
EM whuzxk@whu.edu.cn; Changlongli@henu.edu.cn; xpchen@henu.edu.cn;
   zhangxinyu@whu.edu.cn; jingxy_2000@126.com
RI He, Chen/JLM-5059-2023; Sun, Jia/JXM-0311-2024; YE, Chen/KFR-3858-2024
OI zhang, xinyu/0000-0002-9109-1889; Li, Changlong/0000-0001-6301-9866;
   Zhu, Xiaoke/0000-0002-0664-1832; Chen, Xiaopan/0000-0002-2766-9367
FU NSFC Project [62176069]; Young Scientists Fund of the National Natural
   Science Foundation of China [62006070]; Natural Science Foundation of
   Henan Province [202300410092, 202300410093]; Key Scientific and
   Technological Project of Henan Province of China [222102210204,
   222102210197]; Excellent Youth Scientific Research Project of Hunan
   Education Department [21B0582]; Natural Science Foundation of Guangdong
   Province [2019A1515011076]; Innovation Group of Guangdong Education
   Department [2020KCXTD014, 2018KCXTD019]; State Key Laboratory for Novel
   Software Technology [KFKT2021B29]; NSFC-Key Project of General
   Technology Fundamental Research United Fund [U1736211]; NSFC-Key Project
   [61933013]
FX This work was supported by the NSFC Project (No. 62176069), Young
   Scientists Fund of the National Natural Science Foundation of China (No.
   62006070), Natural Science Foundation of Henan Province (Nos.
   202300410092 and 202300410093), Key Scientific and Technological Project
   of Henan Province of China (Nos. 222102210204 and 222102210197), the
   Excellent Youth Scientific Research Project of Hunan Education
   Department (No. 21B0582), the Natural Science Foundation of Guangdong
   Province (No. 2019A1515011076), the Innovation Group of Guangdong
   Education Department (Nos. 2020KCXTD014 and 2018KCXTD019), the project
   of State Key Laboratory for Novel Software Technology (No. KFKT2021B29),
   the NSFC-Key Project of General Technology Fundamental Research United
   Fund (No. U1736211), and the NSFC-Key Project (No. 61933013).
CR [Anonymous], 2009, P ART INT STAT CLEAR
   Chen XP, 2022, SIGNAL PROCESS-IMAGE, V101, DOI 10.1016/j.image.2021.116543
   Chen XP, 2021, IEEE T CIRC SYST VID, V31, P1939, DOI 10.1109/TCSVT.2020.3017683
   Dahan E., 2017, P 2017 WORKSH REC FA, P31, DOI DOI 10.1145/3134421.3134423
   Dawson M, 2019, LECT NOTES COMPUT SC, V11363, P654, DOI 10.1007/978-3-030-20893-6_41
   DeBruine LM, 2008, ARCH SEX BEHAV, V37, P64, DOI 10.1007/s10508-007-9266-0
   Dehghan A, 2014, PROC CVPR IEEE, P1757, DOI 10.1109/CVPR.2014.227
   Dehshibi MM, 2019, VISUAL COMPUT, V35, P23, DOI 10.1007/s00371-017-1442-1
   Dibeklioglu H, 2017, IEEE I CONF COMP VIS, P2478, DOI 10.1109/ICCV.2017.269
   Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189
   Ding ZM, 2017, IEEE T IMAGE PROCESS, V26, P660, DOI 10.1109/TIP.2016.2631887
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Guo GD, 2012, IEEE T INSTRUM MEAS, V61, P2322, DOI 10.1109/TIM.2012.2187468
   Haibin Yan, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457930
   Nguyen HV, 2011, LECT NOTES COMPUT SC, V6493, P709
   Jain Apoorv, 2020, ADV DATA SCI SECURIT, P353
   Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811
   Kou L, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/472473
   Laiadi O, 2019, IEEE INT CONF AUTOMA, P735, DOI 10.1109/fg.2019.8756627
   Li L, 2016, LECT NOTES COMPUT SC, V9730, P539, DOI 10.1007/978-3-319-41501-7_60
   Li WH, 2021, PROC CVPR IEEE, P16130, DOI 10.1109/CVPR46437.2021.01587
   Li WH, 2021, IEEE T IMAGE PROCESS, V30, P4947, DOI 10.1109/TIP.2021.3077111
   Liang JQ, 2019, IEEE T IMAGE PROCESS, V28, P1149, DOI 10.1109/TIP.2018.2875346
   Liang JY, 2017, COMM COM INF SC, V771, P563, DOI 10.1007/978-981-10-7299-4_47
   Liu XC, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1, DOI 10.1109/CompComm.2015.7387529
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Mahalanobis PC, 2018, SANKHYA SER A, V80, P1, DOI 10.1007/s13171-019-00164-5
   Nandy A, 2019, IEEE INT CONF AUTOMA, P739
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Rachmadi RF, 2019, 2019 IEEE 11TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA 2019), P59, DOI [10.1109/iwcia47330.2019.8955092, 10.1109/IWCIA47330.2019.8955092]
   Robinson J. P., 2016, P 24 ACM INT C MULT, P242, DOI DOI 10.1145/2964284.2967219
   Robinson JP, 2018, IEEE T PATTERN ANAL, V40, P2624, DOI 10.1109/TPAMI.2018.2826549
   Robinson Joseph P., 2016, ABS160402182 CORR
   Sellam A, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON APPLIED SMART SYSTEMS (ICASS)
   Shao M., 2011, CVPR 2011 WORKSH, P60, DOI DOI 10.1109/CVPRW.2011.5981801
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tidjani A, 2018, IET IMAGE PROCESS, V12, P2336, DOI 10.1049/iet-ipr.2018.5552
   Vieira TF, 2014, VISUAL COMPUT, V30, P1333, DOI 10.1007/s00371-013-0884-3
   Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334, DOI 10.1109/TPAMI.2005.165
   Wang M., 2015, International Low Impact Development China Conference, P1, DOI [DOI 10.1109/COMPSAC.2015.343, 10.1109/MMSP.2015.7340820, DOI 10.1049/CP.2015.0489, 10.1049/cp.2015.0489]
   Wang SW, 2020, PATTERN RECOGN LETT, V138, P38, DOI 10.1016/j.patrec.2020.06.019
   Wang SY, 2019, IEEE T PATTERN ANAL, V41, P2783, DOI [10.1109/INTMAG.2018.8508542, 10.1109/TNNLS.2017.2771290, 10.1109/TPAMI.2018.2861871]
   Wang SY, 2017, IEEE INT CONF AUTOMA, P216, DOI [10.1109/FG.2017.35, 10.1109/ICEMI.2017.8265769]
   Xia S., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, P2539, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Yan HB, 2019, PATTERN RECOGN LETT, V128, P169, DOI 10.1016/j.patrec.2019.08.023
   Yan HB, 2019, PATTERN RECOGN LETT, V117, P146, DOI 10.1016/j.patrec.2018.05.027
   Yan HB, 2015, IEEE T CYBERNETICS, V45, P2535, DOI 10.1109/TCYB.2014.2376934
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Zhang K., 2015, Proc. BMVC, DOI [DOI 10.5244/C.29.148, 10.5244/C.29.148]
   Zhang L, 2021, IEEE T CYBERNETICS, V51, P5883, DOI 10.1109/TCYB.2019.2959403
   Zhou X., 2011, ACM Multimedia, P953
   Zhou XZ, 2019, INFORM FUSION, V48, P84, DOI 10.1016/j.inffus.2018.07.011
   Zhou XZ, 2016, INFORM FUSION, V32, P40, DOI 10.1016/j.inffus.2015.08.006
NR 57
TC 3
Z9 3
U1 1
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2023
VL 19
IS 1
SU S
AR 37
DI 10.1145/3531014
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Q4HK
UT WOS:000927169800011
DA 2024-07-18
ER

PT J
AU Song, Y
   Tang, H
   Sebe, N
   Wang, W
AF Song, Yue
   Tang, Hao
   Sebe, Nicu
   Wang, Wei
TI Disentangle Saliency Detection into Cascaded Detail Modeling and Body
   Filling
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; visual saliency; foreground segmentation
ID OBJECT DETECTION
AB Salient object detection has been long studied to identify the most visually attractive objects in images/videos. Recently, a growing amount of approaches have been proposed, all of which rely on the contour/edge information to improve detection performance. The edge labels are either put into the loss directly or used as extra supervision. The edge and body can also be learned separately and then fused afterward. Both methods either lead to high prediction errors near the edge or cannot be trained in an end-to-end manner. Another problem is that existing methods may fail to detect objects of various sizes due to the lack of efficient and effective feature fusion mechanisms. In this work, we propose to decompose the saliency detection task into two cascaded sub-tasks, i.e., detail modeling and body filling. Specifically, detail modeling focuses on capturing the object edges by supervision of explicitly decomposed detail label that consists of the pixels that are nested on the edge and near the edge. Then the body filling learns the body part that will be filled into the detail map to generate more accurate saliency map. To effectively fuse the features and handle objects at different scales, we have also proposed two novel multi-scale detail attention and body attention blocks for precise detail and body modeling. Experimental results show that our method achieves state-of-the-art performances on six public datasets.
C1 [Song, Yue; Sebe, Nicu; Wang, Wei] Univ Trento, Via Sommar 9, I-38123 Trento, Italy.
   [Tang, Hao] Swiss Fed Inst Technol, Ramistr 101, CH-8092 Zurich, Switzerland.
C3 University of Trento; Swiss Federal Institutes of Technology Domain; ETH
   Zurich
RP Song, Y (corresponding author), Univ Trento, Via Sommar 9, I-38123 Trento, Italy.
EM yue.song@unitn.it; hao.tang@vision.ee.ethz.ch; nicu.sebe@unitn.it;
   wei.wang@unitn.it
RI Sebe, Niculae/KEC-2000-2024; Wang, Wei/AAK-5521-2021
OI Sebe, Niculae/0000-0002-6597-7248; Wang, Wei/0000-0002-5477-1017
FU EU [951911]
FX This work has been supported by the EU H2020 AI4Media (Grant No.
   951911).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Bruno A, 2020, IEEE ACCESS, V8, P121330, DOI 10.1109/ACCESS.2020.3006700
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan Deng-Ping, 2018, P 27 INT JOINT C ART
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Guo CL, 2008, PROC CVPR IEEE, P2908
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hou XD, 2007, PROC CVPR IEEE, P2280
   JunWei ShuhuiWang, 2020, P IEEE C COMPUTER VI
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Máttyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang Q, 2017, NEUROCOMPUTING, V243, P35, DOI 10.1016/j.neucom.2017.02.064
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao K, 2019, IEEE I CONF COMP VIS, P8848, DOI 10.1109/ICCV.2019.00894
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhao Xiaoqi, 2020, P EUROPEAN C COMPUTE
   Zhong Yijie, 2021, P BRIT MACHINE VISIO
NR 51
TC 2
Z9 2
U1 1
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2023
VL 19
IS 1
AR 7
DI 10.1145/3513134
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Q4GM
UT WOS:000927167400007
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Tang, ZM
   Huang, J
AF Tang, Zengming
   Huang, Jun
TI Harmonious Multi-branch Network for Person Re-identification with Harder
   Triplet Loss
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; pooling strategy; attention mechanism; triplet
   loss
ID NEURAL-NETWORK; ATTENTION
AB Recently, advances in person re-identification (Re-ID) has benefitted from use of the popular multi-branch network. However, performing feature learning in a single branch with uniform partitioning is likely to separate meaningful local regions, and correlation among different branches is not well established. In this article, we propose a novel harmonious multi-branch network (HMBN) to relieve these intra-branch and inter-branch problems harmoniously. HMBN is a multi-branch network with various stripes on different branches to learn coarse-to-fine pedestrian information. We first replace the uniform partition with a horizontal overlapped partition to cover meaningful local regions between adjacent stripes in a single branch. We then incorporate a novel attention module to make all branches interact by modeling spatial contextual dependencies across branches. Finally, in order to train the HMBN more effectively, a harder triplet loss is introduced to optimize triplets in a harder manner. Extensive experiments are conducted on three benchmark datasets - DukeMTMC-reID, CUHK03, and Market-1501 - demonstrating the superiority of our proposed HMBN over state-of-the-art methods.
C1 [Tang, Zengming; Huang, Jun] Chinese Acad Sci, Shanghai Adv Res Inst, 99 Haike Rd, Shanghai 201210, Peoples R China.
   [Tang, Zengming; Huang, Jun] Univ Chinese Acad Sci, 19A Yuquan Rd, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Advanced Research Institute, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Huang, J (corresponding author), Chinese Acad Sci, Shanghai Adv Res Inst, 99 Haike Rd, Shanghai 201210, Peoples R China.; Huang, J (corresponding author), Univ Chinese Acad Sci, 19A Yuquan Rd, Beijing 100049, Peoples R China.
EM tangzengming2019@sari.ac.cn; huangj@sari.ac.cn
OI Tang, Zengming/0000-0001-5485-1829; huang, jun/0000-0003-4939-3880
FU National Key R&D Program of China [2020YFC1523202]
FX This work was supported by the National Key R&D Program of China
   (2020YFC1523202).
CR Cao JJ, 2018, PROC CVPR IEEE, P4290, DOI 10.1109/CVPR.2018.00451
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen GY, 2019, IEEE T IMAGE PROCESS, V28, P4192, DOI 10.1109/TIP.2019.2908062
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cornia M, 2019, PROC CVPR IEEE, P8299, DOI 10.1109/CVPR.2019.00850
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Fu ZH, 2019, IEEE T IMAGE PROCESS, V28, P6077, DOI 10.1109/TIP.2019.2922095
   Guo YQ, 2017, IEEE INT C INTELL TR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu JW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P737, DOI 10.1145/3240508.3240585
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ma S, 2018, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2018.00593
   Paszke A, 2019, ADV NEUR IN, V32
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Shizhen Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P647, DOI 10.1007/978-3-030-58539-6_39
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang Zengming, 2020, P AS C COMP VIS ACCV, P322
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Yao HT, 2017, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2017.8019485
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang S, 2020, INT J COMPUT VISION, V128, P96, DOI 10.1007/s11263-019-01212-1
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhou SP, 2019, IEEE I CONF COMP VIS, P8039, DOI 10.1109/ICCV.2019.00813
   Zhou SP, 2017, PROC CVPR IEEE, P5028, DOI 10.1109/CVPR.2017.534
NR 70
TC 11
Z9 12
U1 3
U2 27
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2022
VL 18
IS 4
AR 98
DI 10.1145/3501405
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0E1KA
UT WOS:000776441600009
OA Bronze
DA 2024-07-18
ER

PT J
AU Shi, WZ
   Liu, SH
AF Shi, Wuzhen
   Liu, Shaohui
TI Hiding Message Using a Cycle Generative Adversarial Network
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Steganography; generative adversarial network; cycle generative
   adversarial network; residual learning; inverse steganographic network
AB Training an image steganography is an unsupervised problem, because it is impossible to obtain an ideal supervised steganographic image corresponding to the cover image and secret message. Inspired by the success of cycle generative adversarial networks in unsupervised tasks such as style transfer, this article proposes to use a cycle generative adversarial network to solve the problem of unsupervised image steganography. Specifically, this article jointly trains five networks, i.e., a steganographic network, an inverse steganographic network, a hidden message reconstruction network, and two discriminative networks, which together constitute a hidden message cycle generative adversarial network (HCGAN). Compared with the recent image steganography based on generative adversative network, HCGAN provides more accurate supervised information, which makes the training process of HCGAN converge faster and the performance of the trained image steganography network is better. In addition, this article introduces an image steganographic network based on residual learning and shows that residual learning can effectively improve the performance of steganography. Furthermore, to the best of our knowledge, we are the first to propose an inverse steganographic network for eliminating steganographic message from steganographic images, which can be used to avoid steganographic message being discovered or acquired by a third party. The experimental results show that compared with the steganography based on generative adversarial network, the proposed HCGAN has a higher correct decoding rate, better visual quality of steganographic image, and higher secrecy.
C1 [Shi, Wuzhen] Shenzhen Univ, Coll Elect & Informat Engn,Shenzhen Key Lab Digit, Guangdong Prov Engn Lab Digital Creat Technol, Guangdong Hong Kong Joint Lab Big Data Imaging &, 3688 Nanhai Ave, Shenzhen 518060, Guangdong, Peoples R China.
   [Liu, Shaohui] Harbin Inst Technol, Sch Comp Sci & Technol, State Key Lab Commun Content Cognit, 92 Xidazhi St, Harbin, Peoples R China.
   [Liu, Shaohui] Peng Cheng Lab, 92 Xidazhi St, Harbin, Peoples R China.
C3 Shenzhen University; Harbin Institute of Technology
RP Shi, WZ (corresponding author), Shenzhen Univ, Coll Elect & Informat Engn,Shenzhen Key Lab Digit, Guangdong Prov Engn Lab Digital Creat Technol, Guangdong Hong Kong Joint Lab Big Data Imaging &, 3688 Nanhai Ave, Shenzhen 518060, Guangdong, Peoples R China.
EM wzhshi@szu.edu.cn; shliu@hit.edu.cn
RI Liu, Shaohui/AAC-3092-2019
OI Liu, Shaohui/0000-0002-1810-5412
FU National Key Research and Development Program of China [2020YFB1406902,
   A12003]; National Science Foundation of China [62101346]; Guangdong
   Basic and Applied Basic Research Foundation [2021A1515011702]; Stable
   Support Plan for Shenzhen Higher Education Institutions
   [20200812104316001]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFB1406902 and A12003, in
   part by the National Science Foundation of China under Grant 62101346,
   in part by the Guangdong Basic and Applied Basic Research Foundation
   under Grant 2021A1515011702, and in part by the Stable Support Plan for
   Shenzhen Higher Education Institutions under Grant 20200812104316001.
CR Abadi M., 2016, arXiv, DOI DOI 10.48550/ARXIV.1603.04467
   Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Altaay AAJ, 2012, INT CONF ADV COMPUT, P122, DOI 10.1109/ACSAT.2012.25
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hayes J, 2017, ADV NEUR IN, V30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lerch-Hostalot D, 2016, ENG APPL ARTIF INTEL, V50, P45, DOI 10.1016/j.engappai.2015.12.013
   Li B, 2014, IEEE T INF FOREN SEC, V9, P1264, DOI 10.1109/TIFS.2014.2326954
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Maas AL, 2013, PROC INT C MACH LEAR
   MaxWelling Simon Osindero, 2002, C ADV NEURAL INFORM, P1383
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Shi HC, 2019, Arxiv, DOI arXiv:1801.10365
   Shi HC, 2018, LECT NOTES COMPUT SC, V10735, P534, DOI 10.1007/978-3-319-77380-3_51
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Sun Y, 2019, J REAL-TIME IMAGE PR, V16, P635, DOI 10.1007/s11554-019-00849-y
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Volkhonskiy D, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559429
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 34
TC 3
Z9 3
U1 8
U2 28
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2022
VL 18
IS 3
SU S
SI SI
AR 143
DI 10.1145/3495566
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A0AE2
UT WOS:000951829800013
DA 2024-07-18
ER

PT J
AU Yin, GH
   Sun, SQ
   Yu, DA
   Li, DJ
   Zhang, KJ
AF Yin, Guanghao
   Sun, Shouqian
   Yu, Dian
   Li, Dejian
   Zhang, Kejun
TI A Multimodal Framework for Large-Scale Emotion Recognition by Fusing
   Music and Electrodermal Activity Signals
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multimodal fusion; large-scale emotion recognition; attention mechanism
ID NEURAL-NETWORKS; FEATURES; EEG
AB Considerable attention has been paid to physiological signal-based emotion recognition in the field of affective computing. For reliability and user-friendly acquisition, electrodermal activity (EDA) has a great advantage in practical applications. However, EDA-based emotion recognition with large-scale subjects is still a tough problem. The traditional well-designed classifiers with hand-crafted features produce poorer results because of their limited representation abilities. And the deep learning models with auto feature extraction suffer the overfitting drop-off because of large-scale individual differences. Since music has a strong correlation with human emotion, static music can be involved as the external benchmark to constrain various dynamic EDA signals. In this article, we make an attempt by fusing the subject's individual EDA features and the external evoked music features. And we propose an end-to-end multimodal framework, the one-dimensional residual temporal and channel attention network (RTCAN-1D). For EDA features, the channel-temporal attention mechanism for EDA-based emotion recognition is first involved in mine the temporal and channel-wise dynamic and steady features. The comparisons with single EDA-based SOTA models on DEAP and AMIGOS datasets prove the effectiveness of RTCAN-1D to mine EDA features. For music features, we simply process the music signal with the open-source toolkit openSMILE to obtain external feature vectors. We conducted systematic and extensive evaluations. The experiments on the current largest music emotion dataset PMEmo validate that the fusion of EDA and music is a reliable and efficient solution for large-scale emotion recognition.
C1 [Yin, Guanghao; Sun, Shouqian; Yu, Dian; Li, Dejian; Zhang, Kejun] Zhejiang Univ, Zheda Rd 38, Hangzhou 430176221, Peoples R China.
   [Zhang, Kejun] Zhejiang Univ, Joint Res Inst Frontier Technol, Zheda Rd 38, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Zhang, KJ (corresponding author), Zhejiang Univ, Zheda Rd 38, Hangzhou 430176221, Peoples R China.; Zhang, KJ (corresponding author), Zhejiang Univ, Joint Res Inst Frontier Technol, Zheda Rd 38, Hangzhou, Peoples R China.
EM ygh_zju@zju.edu.cn; ssq@zju.edu.cn; yudian329@zju.edu.cn;
   dejianli@zju.edu.cn; zhangkejun@zju.edu.cn
RI Li, Dejian/ABG-3740-2021
CR Al Machot F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071659
   Alexander DM, 2005, J NEUROSCI METH, V146, P116, DOI 10.1016/j.jneumeth.2005.02.001
   Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   Anusha A.S., 2018, 2018 IEEE INT S MED, P1, DOI DOI 10.1109/MEMEA.2018.8438595
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Becker Judith, 2004, DEEP LISTENERS MUSIC, V1
   Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028
   Benedek M, 2010, PSYCHOPHYSIOLOGY, V47, P647, DOI 10.1111/j.1469-8986.2009.00972.x
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chiliguano P, 2016, INT CONF ACOUST SPEE, P2618, DOI 10.1109/ICASSP.2016.7472151
   Damasio A., 1994, DESCARTESS ERROR EMO
   Dawson ME, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P159, DOI 10.1017/cbo9780511546396.007
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Frantzidis CA, 2010, IEEE T INF TECHNOL B, V14, P309, DOI 10.1109/TITB.2009.2038481
   Ganapathy N, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113571
   Greco A, 2017, IEEE SENS J, V17, P716, DOI 10.1109/JSEN.2016.2623677
   Greco A, 2016, IEEE T BIO-MED ENG, V63, P797, DOI 10.1109/TBME.2015.2474131
   Guo R, 2013, INT CONF PER COMP, P436, DOI 10.4108/icst.pervasivehealth.2013.252133
   Hamann S, 2012, TRENDS COGN SCI, V16, P458, DOI 10.1016/j.tics.2012.07.006
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Izard CE, 2007, PERSPECT PSYCHOL SCI, V2, P260, DOI [10.1111/j.1745-6916.2007.00044.x, 10.1111/j.1745-6916.2007.00053.x]
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Jerritta S., 2011, 2011 Proceedings of IEEE 7th International Colloquium on Signal Processing & its Applications (CSPA 2011), P410, DOI 10.1109/CSPA.2011.5759912
   Katsis CD, 2008, IEEE T SYST MAN CY A, V38, P502, DOI 10.1109/TSMCA.2008.918624
   Kelsey M, 2018, BIOMED SIGNAL PROCES, V40, P58, DOI 10.1016/j.bspc.2017.08.024
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Kim Jonghwa., 2007, BIMODAL EMOTION RECO
   Kim Y, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808204
   Koelstra S, 2013, IMAGE VISION COMPUT, V31, P164, DOI 10.1016/j.imavis.2012.10.002
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Langhorne P, 2011, LANCET, V377, P1693, DOI 10.1016/S0140-6736(11)60325-5
   Lawrence S, 2000, IEEE IJCNN, P114, DOI 10.1109/IJCNN.2000.857823
   Lawrence S., 1997, P AAAI IAAI, P540
   Lin WQ, 2017, LECT NOTES COMPUT SC, V10667, P385, DOI 10.1007/978-3-319-71589-6_33
   Lin YC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037683
   Liu JM, 2018, LECT NOTES COMPUT SC, V10735, P194, DOI 10.1007/978-3-319-77380-3_19
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   Nittala AS, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376366
   Pei WJ, 2017, PROC CVPR IEEE, P820, DOI 10.1109/CVPR.2017.94
   Picard R.W., 2000, Affective Computing
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   PLUTCHIK R, 1982, SOC SCI INFORM, V21, P529, DOI 10.1177/053901882021004003
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sano A, 2013, INT CONF AFFECT, P671, DOI 10.1109/ACII.2013.117
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sharma V, 2019, BIOMED SIGNAL PROCES, V47, P324, DOI 10.1016/j.bspc.2018.08.024
   Shukla J, 2021, IEEE T AFFECT COMPUT, V12, P857, DOI 10.1109/TAFFC.2019.2901673
   Simonyan K., 2014, CORR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Thammasan N, 2017, AAAI CONF ARTIF INTE, P4991
   Torres CA, 2013, IEEE ENG MED BIO, P4330, DOI 10.1109/EMBC.2013.6610504
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wundt Wilhelm Max, 1921, AM J PSYCHOL, V32, P151
   Xiong N., 2002, Information Fusion, V3, P163, DOI 10.1016/S1566-2535(02)00055-6
   Yin GH, 2019, IEEE IMAGE PROC, P3277, DOI [10.1109/ICIP.2019.8803627, 10.1109/icip.2019.8803627]
   Zhang KJ, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P135, DOI 10.1145/3206025.3206037
NR 63
TC 12
Z9 12
U1 15
U2 98
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2022
VL 18
IS 3
AR 78
DI 10.1145/3490686
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA ZY5UA
UT WOS:000772650600012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Salim, S
   Moustafa, N
   Turnbull, B
   Razzak, I
AF Salim, Sara
   Moustafa, Nour
   Turnbull, Benjamin
   Razzak, Imran
TI Perturbation-enabled Deep Federated Learning for Preserving Internet of
   Things-based Social Networks
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Differential privacy; data perturbation; deep federated learning; model
   inversion attacks; privacy preservation
ID PRIVACY; FRAMEWORK
AB Federated Learning (FL), as an emerging form of distributed machine learning (ML), can protect participants' private data from being substantially disclosed to cyber adversaries. It has potential uses in many large-scale, data-rich environments, such as the Internet of Things (IoT), Industrial IoT, Social Media (SM), and the emerging SM 3.0. However, federated learning is susceptible to some forms of data leakage through model inversion attacks. Such attacks occur through the analysis of participants' uploaded model updates. Model inversion attacks can reveal private data and potentially undermine some critical reasons for employing federated learning paradigms. This article proposes novel differential privacy (DP)-based deep federated learning framework. We theoretically prove that our framework can fulfill DP's requirements under distinct privacy levels by appropriately adjusting scaled variances of Gaussian noise. We then develop a Differentially Private Data-Level Perturbation (DP-DLP) mechanism to conceal any single data point's impact on the training phase. Experiments on real-world datasets, specifically the social media 3.0, Iris, and Human Activity Recognition (HAR) datasets, demonstrate that the proposed mechanism can offer high privacy, enhanced utility, and elevated efficiency. Consequently, it simplifies the development of various DP-based FL models with different tradeoff preferences on data utility and privacy levels.
C1 [Salim, Sara; Moustafa, Nour; Turnbull, Benjamin] Univ New South Wales ADFA, Sch Engn & Informat Technol, 33 Northcott Dr, Campbell, ACT 2612, Australia.
   [Razzak, Imran] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW 1466, Australia.
C3 University of New South Wales Sydney; University of New South Wales
   Sydney
RP Salim, S (corresponding author), Univ New South Wales ADFA, Sch Engn & Informat Technol, 33 Northcott Dr, Campbell, ACT 2612, Australia.
EM s.salim@student.adfa.edu.au; nour.moustafa@adfa.edu.au;
   benjamin.turnbull@unsw.edu.au; imran.razzak@ieee.org
RI Moustafa, Nour/Z-1160-2018; Razzak, Imran/AEW-5139-2022; Turnbull,
   Benjamin/IZE-8140-2023
OI Moustafa, Nour/0000-0001-6127-9349; Razzak, Imran/0000-0002-3930-6600;
   Turnbull, Benjamin/0000-0003-0440-5032; Salim, Sara/0000-0002-0577-4625
CR Alzamzami F, 2021, IEEE ACCESS, V9, P91184, DOI 10.1109/ACCESS.2021.3088410
   Anandhan A, 2018, IEEE ACCESS, V6, P15608, DOI 10.1109/ACCESS.2018.2810062
   [Anonymous], 2021, 13 CRITICAL DATA BRE
   Arachchige PCM, 2020, IEEE T IND INFORM, V16, P6092, DOI 10.1109/TII.2020.2974555
   Cheung M, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3524135
   Cheung M, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978771
   Cheung M, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2978568
   Das S, 2018, MEXIHC 2018: PROCEEDINGS OF THE 7TH MEXICAN CONFERENCE ON HUMAN-COMPUTER INTERACTION, DOI 10.1145/3293578.3293589
   Dua D., 2017, UCI MACHINE LEARNING
   Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Garfinkel S., 2015, De-identification of Personal Information, P1, DOI [10.6028/NIST.IR.8053, DOI 10.6028/NIST.IR.8053]
   Geiping Jonas, 2020, ADV NEURAL INFORM PR, V33, P16937
   Geyer Robin C., 2017, arXiv
   Hassija V, 2019, IEEE ACCESS, V7, P82721, DOI 10.1109/ACCESS.2019.2924045
   Jia B, 2022, IEEE T IND INFORM, V18, P4049, DOI 10.1109/TII.2021.3085960
   Ju CH, 2019, MULTIMED TOOLS APPL, V78, P29867, DOI 10.1007/s11042-018-6604-2
   Kang YL, 2020, Arxiv, DOI arXiv:2002.08570
   Kasyap H, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3426474
   Liu Y, 2020, IEEE INTERNET THINGS, V7, P7751, DOI 10.1109/JIOT.2020.2991401
   Lu YL, 2020, IEEE T IND INFORM, V16, P4177, DOI 10.1109/TII.2019.2942190
   Majeed A, 2021, IEEE ACCESS, V9, P8512, DOI 10.1109/ACCESS.2020.3045700
   Mendes R, 2017, IEEE ACCESS, V5, P10562, DOI 10.1109/ACCESS.2017.2706947
   Naren, 2021, IEEE Internet of Things Magazine, V4, P72, DOI 10.1109/IOTM.0211.2100002
   Truong N, 2021, COMPUT SECUR, V110, DOI 10.1016/j.cose.2021.102402
   Quan-Haase A, 2018, SMSOCIETY'18: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON SOCIAL MEDIA AND SOCIETY, P150, DOI 10.1145/3217804.3217907
   Reyes-Ortiz Jorge L, 2012, UCI Machine Learning Repository
   Rodríguez-Barroso N, 2020, INFORM FUSION, V64, P270, DOI 10.1016/j.inffus.2020.07.009
   Salim Sara, 2020, 2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P856, DOI 10.1109/TrustCom50675.2020.00115
   Salim S, 2021, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2021.3134463
   Salim S, 2022, AD HOC NETW, V128, DOI 10.1016/j.adhoc.2022.102786
   Sharma P, 2021, AD HOC NETW, V123, DOI 10.1016/j.adhoc.2021.102685
   Sun WW, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3165265
   Titcombe T, 2021, Arxiv, DOI arXiv:2104.05743
   Truex Stacey, 2019, P 12 ACM WORKSH ART, P1, DOI [DOI 10.1145/3338501.3357370, 10.1145/3338501.3357370]
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Wei K., 2021, P FEDERATED LEARNING, P51
   Xudong Zhu, 2019, Information Security and Cryptology. 14th International Conference, Inscrypt 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11449), P370, DOI 10.1007/978-3-030-14234-6_20
   Yang DQ, 2019, IEEE T KNOWL DATA EN, V31, P507, DOI 10.1109/TKDE.2018.2840974
   Yazdanjue N, 2020, COMPUT J, V63, P1039, DOI 10.1093/comjnl/bxz069
   Zhang JX, 2018, IEEE INFOCOM SER, P1106, DOI 10.1109/INFOCOM.2018.8486242
   Zhang W, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3279952
NR 42
TC 6
Z9 6
U1 2
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2022
VL 18
IS 2
SU S
AR 120
DI 10.1145/3537899
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7R6FY
UT WOS:000910168000007
DA 2024-07-18
ER

PT J
AU Kizilkaya, B
   Ever, E
   Yatbaz, HY
   Yazici, A
AF Kizilkaya, Burak
   Ever, Enver
   Yatbaz, Hakan Yekta
   Yazici, Adnan
TI An Effective Forest Fire Detection Framework Using Heterogeneous
   Wireless Multimedia Sensor Networks
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE IoT; WMSNs; deep learning; edge computing; energy efficiency;
   heterogeneous WMSN architecture
ID ENERGY-EFFICIENT; RASPBERRY PI
AB With improvements in the area of Internet of Things (IoT), surveillance systems have recently become more accessible. At the same time, optimizing the energy requirements of smart sensors, especially for data transmission, has always been very important and the energy efficiency of IoT systems has been the subject of numerous studies. For environmental monitoring scenarios, it is possible to extract more accurate information using smart multimedia sensors. However, multimedia data transmission is an expensive operation. In this study, a novel hierarchical approach is presented for the detection of forest fires. The proposed framework introduces a new approach in which multimedia and scalar sensors are used hierarchically to minimize the transmission of visual data. A lightweight deep learning model is also developed for devices at the edge of the network to improve detection accuracy and reduce the traffic between the edge devices and the sink. The framework is evaluated using a real testbed, network simulations, and 10-fold cross-validation in terms of energy efficiency and detection accuracy. Based on the results of our experiments, the validation accuracy of the proposed system is 98.28%, and the energy saving is 29.94%. The proposed deep learning model's validation accuracy is very close to the accuracy of the best performing architectures when the existing studies and lightweight architectures are considered. In terms of suitability for edge computing, the proposed approach is superior to the existing ones with reduced computational requirements and model size.
C1 [Kizilkaya, Burak; Ever, Enver; Yatbaz, Hakan Yekta] Middle East Tech Univ, Comp Engn, Northern Cyprus Campus, TR-99738 Mersin 10, Guzelyurt, Turkey.
   [Kizilkaya, Burak] Univ Glasgow, Sch Engn, Glasgow, Lanark, Scotland.
   [Yazici, Adnan] Nazarbayev Univ, Sch Engn & Digital Sci, Dept Comp Sci, Nur Sultan, Kazakhstan.
   [Yazici, Adnan] Middle East Tech Univ, Dept Comp Engn, Ankara, Turkey.
C3 Middle East Technical University; University of Glasgow; Nazarbayev
   University; Middle East Technical University
RP Kizilkaya, B (corresponding author), Middle East Tech Univ, Comp Engn, Northern Cyprus Campus, TR-99738 Mersin 10, Guzelyurt, Turkey.; Kizilkaya, B (corresponding author), Univ Glasgow, Sch Engn, Glasgow, Lanark, Scotland.
EM b.kizilkaya.1@research.gla.ac.uk; eever@metu.edu.tr;
   hakan.yatbaz@metu.edu.tr; adnan.yazici@nu.edu.kz
RI Ever, Enver/K-9500-2013; Kizilkaya, Burak/AAN-3960-2020; Yatbaz, Hakan
   Yekta/ISB-5191-2023
OI Kizilkaya, Burak/0000-0002-7429-7527; YAZICI, Adnan/0000-0001-9404-9494
FU NU Faculty-development competitive research grants program, Nazarbayev
   University [110119FD4543]
FX This work was supported by NU Faculty-development competitive research
   grants program, Nazarbayev University, Grant No. 110119FD4543.
CR Ahmad K, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3306240
   Al-Kaff A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020260
   Alablani I., 2019, I C COMP SYST APPLIC, P1, DOI [10.1109/AICCSA47632.2019.9035239, DOI 10.1109/aiccsa47632.2019.9035239]
   [Anonymous], 2011, CONTIKI OS OPERATING
   Aslan YE, 2012, COMPUT ENVIRON URBAN, V36, P614, DOI 10.1016/j.compenvurbsys.2012.03.002
   Bhosle AS, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P287, DOI 10.1109/ICEEOT.2016.7755194
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Capotondi A, 2020, IEEE T CIRCUITS-II, V67, P871, DOI 10.1109/TCSII.2020.2983648
   Chen YH, 2019, C IND ELECT APPL, P2118, DOI [10.1109/ICIEA.2019.8833958, 10.1109/iciea.2019.8833958]
   Chollet F, 2015, KERAS
   Civelek M, 2017, IEEE SENS J, V17, P1116, DOI 10.1109/JSEN.2016.2638853
   Cortez P., 2007, A data mining approach to predict forest fires using meteorological data
   Ergul O, 2016, IEEE COMMUN MAG, V54, P92, DOI 10.1109/MCOM.2016.7452272
   Farsi M, 2019, IEEE ACCESS, V7, P28940, DOI 10.1109/ACCESS.2019.2902072
   Ferdoush S, 2014, PROCEDIA COMPUT SCI, V34, P103, DOI 10.1016/j.procs.2014.07.059
   Fire Lookout Towers, 2018, BC FIR LOOK TOW
   Forests Department, 2018, FOR FIR STAT 2000 20
   Fu JS, 2016, IEEE COMMUN MAG, V54, P16, DOI 10.1109/MCOM.2016.7588224
   Fu XW, 2019, FUTURE GENER COMP SY, V91, P223, DOI 10.1016/j.future.2018.08.031
   Gaur A, 2019, IEEE SENS J, V19, P3191, DOI 10.1109/JSEN.2019.2894665
   Han J, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), P579, DOI [10.1109/icaiic.2019.8669042, 10.1109/ICAIIC.2019.8669042]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, P 12 INT C SIGN PROC, P1, DOI 10.1109/ICSPCS.2018.8631711
   Iandola Forrest, 2017, 2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), DOI 10.1145/3125502.3125606
   Illiano VP, 2018, ACM T SENSOR NETWORK, V14, DOI 10.1145/3176621
   Jackson R, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3446976
   Jan MA, 2018, FUTURE GENER COMP SY, V80, P613, DOI 10.1016/j.future.2016.05.034
   Kadri B., 2018, 2018 INT C APPL SMAR, P1, DOI DOI 10.1109/ICASS.2018.8651977
   Kajmakovic A, 2019, IEEE INT SYMP SOFTW, P440, DOI 10.1109/ISSREW.2019.00108
   Kaur H, 2019, J NETW COMPUT APPL, V144, P171, DOI 10.1016/j.jnca.2019.07.005
   Ngo KA, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION TECHNOLOGY (ICIIT 2018), P39, DOI 10.1145/3193063.3193066
   Kochlán M, 2014, ACSIS-ANN COMPUT SCI, V2, P1023
   Koyuncu M, 2019, IEEE SENS J, V19, P1839, DOI 10.1109/JSEN.2018.2885281
   Krizhevsky Alex, 2014, ARXIV14045997
   Kumar R, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGIES AND INTELLIGENT DATA ENGINEERING (ICCTIDE'16)
   Li J, 2019, IEEE SENS J, V19, P3711, DOI 10.1109/JSEN.2019.2895735
   Li YG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3378026
   Nguyen L, 2020, COMPUT NETW, V174, DOI 10.1016/j.comnet.2020.107236
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Molina-Pico A, 2016, J SENSORS, V2016, DOI 10.1155/2016/8325845
   Muduli L, 2018, J NETW COMPUT APPL, V106, P48, DOI 10.1016/j.jnca.2017.12.022
   Muhammad K, 2019, IEEE COMMUN MAG, V57, P60, DOI 10.1109/MCOM.2018.1800371
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   OMNET, OMNET DISCR EV SIM
   Pan Hu, 2020, SenSys '20: Proceedings of the 18th Conference on Embedded Networked Sensor Systems, P395, DOI 10.1145/3384419.3430769
   Panousopoulou A, 2016, AD HOC NETW, V49, P70, DOI 10.1016/j.adhoc.2016.06.011
   Parsons Andy, 2020, WHY FIRES AUSTR ARE
   Ray PP, 2019, COMPUT NETW, V149, P226, DOI 10.1016/j.comnet.2018.12.006
   Sanchez-Iborra R, 2020, IEEE CIRC SYST MAG, V20, P4, DOI 10.1109/MCAS.2020.3005467
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma V, 2016, EGYPT INFORM J, V17, P45, DOI 10.1016/j.eij.2015.08.003
   Snidaro L, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071403
   Srinivas Kethavath, 2020, Inventive Computation Technologies. Lecture Notes in Networks and Systems (LNNS 98), P646, DOI 10.1007/978-3-030-33846-6_69
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Taylor-Coleman, 2018, WILDFIRES WORLD PHOT
   Toulouse T, 2017, FIRE SAFETY J, V92, P188, DOI 10.1016/j.firesaf.2017.06.012
   Varga A., 2008, P 1 INT C SIMULATION, P60, DOI DOI 10.4108/ICST.SIMUTOOLS2008.3027
   Wang DH, 2020, COMPUT NETW, V178, DOI 10.1016/j.comnet.2020.107313
   Wang LN, 2017, NEURAL NETWORKS, V93, P219, DOI 10.1016/j.neunet.2017.06.003
   Wonjae Lee, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P252, DOI 10.1109/ICCE.2017.7889305
   Xie LX, 2016, PROC CVPR IEEE, P4753, DOI 10.1109/CVPR.2016.514
   Xu YH, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10100102
   Yuan C, 2017, INT CONF UNMAN AIRCR, P567
NR 66
TC 23
Z9 23
U1 2
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2022
VL 18
IS 2
AR 47
DI 10.1145/3473037
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0A0YT
UT WOS:000773689400004
OA Green Accepted, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, FF
   Xu, ML
   Xu, CS
AF Zhang, Feifei
   Xu, Mingliang
   Xu, Changsheng
TI Tell, Imagine, and Search: End-to-end Learning for Composing Text and
   Image to Image Retrieval
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Composing text and image to image retrieval; end-to-end; image
   generation; generative adversarial network; global-local
AB Composing Text and Image to Image Retrieval (CTI-IR) is an emerging task in computer vision, which allows retrieving images relevant to a query image with text describing desired modifications to the query image. Most conventional cross-modal retrieval approaches usually take one modality data as the query to retrieve relevant data of another modality. Different from the existing methods, in this article, we propose an endto-end trainable network for simultaneous image generation and CTI-IR. The proposed model is based on Generative Adversarial Network (GAN) and enjoys several merits. First, it can learn a generative and discriminative feature for the query (a query image with text description) by jointly training a generative model and a retrieval model. Second, our model can automatically manipulate the visual features of the reference image in terms of the text description by the adversarial learning between the synthesized image and target image. Third, global-local collaborative discriminators and attention-based generators are exploited, allowing our approach to focus on both the global and local differences between the query image and the target image. As a result, the semantic consistency and fine-grained details of the generated images can be better enhanced in our model. The generated image can also be used to interpret and empower our retrieval model. Quantitative and qualitative evaluations on three benchmark datasets demonstrate that the proposed algorithm performs favorably against state-of-the-art methods.
C1 [Zhang, Feifei; Xu, Changsheng] Chinese Acad Sci, Inst Automat, NLPR, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   [Zhang, Feifei] Tianjin Univ Technol, Sch Comp Sci & Engn, 391 Bin Shui Xi Dao Rd, Tianjin 300384, Peoples R China.
   [Zhang, Feifei] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, 100 Sci Ave, Zhengzhou 450001, Henan, Peoples R China.
   [Xu, Changsheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, 19 Yuquan Rd, Beijing 100049, Peoples R China.
   [Xu, Changsheng] Peng Cheng Lab, 2 Xingke 1st St, Shenzhen 518000, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Tianjin
   University of Technology; Chinese Academy of Sciences; Institute of
   Automation, CAS; Zhengzhou University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS; Peng Cheng Laboratory
RP Zhang, FF (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.; Zhang, FF (corresponding author), Tianjin Univ Technol, Sch Comp Sci & Engn, 391 Bin Shui Xi Dao Rd, Tianjin 300384, Peoples R China.; Zhang, FF (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
EM feifeizhang1231@gmail.com; iexumingliang@zzu.edu.cn; csxu@nlpr.ia.ac.cn
RI Zhang, Feifei/A-3199-2015; xu, cj/HJZ-3488-2023; Xu, Chang/GQP-7280-2022
FU National Key Research and Development Program of China [2018AAA0100604];
   National Natural Science Foundation of China [62036012, 61720106006,
   62002355, 61721004, 61832002, 62072455, U1705262, U1836220]; Key
   Research Program of Frontier Sciences of CAS [QYZDJ-SSW-JSC039];
   National Postdoctoral Program for Innovative Talents [BX20190367];
   Beijing Natural Science Foundation [L201001]
FX This work is supported by National Key Research and Development Program
   of China (No. 2018AAA0100604), National Natural Science Foundation of
   China (Nos. 62036012, 61720106006, 62002355, 61721004, 61832002,
   62072455, U1705262, and U1836220), Key Research Program of Frontier
   Sciences of CAS (QYZDJ-SSW-JSC039), National Postdoctoral Program for
   Innovative Talents (BX20190367), Beijing Natural Science Foundation
   (L201001).
CR Ak KE, 2019, IEEE I CONF COMP VIS, P10540, DOI 10.1109/ICCV.2019.01064
   Ak KE, 2018, PROC CVPR IEEE, P7708, DOI 10.1109/CVPR.2018.00804
   Nguyen A, 2017, PROC CVPR IEEE, P3510, DOI 10.1109/CVPR.2017.374
   [Anonymous], 2007, International Conference on Computer Vision (ICCV)
   Chen JX, 2019, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2019.00088
   Chung Junyoung, 2014, ARXIV14123555
   Dey S, 2019, PROC CVPR IEEE, P2174, DOI 10.1109/CVPR.2019.00228
   Dong JF, 2019, PROC CVPR IEEE, P9338, DOI 10.1109/CVPR.2019.00957
   Dorfer M, 2018, INT J MULTIMED INF R, V7, P117, DOI 10.1007/s13735-018-0151-5
   Dutta A, 2019, PROC CVPR IEEE, P5084, DOI 10.1109/CVPR.2019.00523
   Fan HH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3390891
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   Guo XX, 2018, ADV NEUR IN, V31
   Han XT, 2017, IEEE I CONF COMP VIS, P1472, DOI 10.1109/ICCV.2017.163
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Heim E, 2019, PROC CVPR IEEE, P10745, DOI 10.1109/CVPR.2019.01101
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Isola P, 2015, PROC CVPR IEEE, P1383, DOI 10.1109/CVPR.2015.7298744
   Jiang XY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P69, DOI 10.1145/2733373.2806240
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Karpathy A, 2014, ADV NEUR IN, V27
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim JH, 2016, ADV NEUR IN, V29
   Kim J, 2021, AAAI CONF ARTIF INTE, V35, P1771
   Kingma D.P., 2014, ARXIV14126980
   Klein B, 2019, PROC CVPR IEEE, P5036, DOI 10.1109/CVPR.2019.00518
   Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026
   Lao QC, 2019, IEEE I CONF COMP VIS, P7566, DOI 10.1109/ICCV.2019.00766
   Li CX, 2019, IEEE T MULTIMEDIA, V21, P2863, DOI 10.1109/TMM.2019.2912714
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Liu JW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P665, DOI 10.1145/3343031.3350991
   Liu X, 2021, IEEE T PATTERN ANAL, V43, P964, DOI 10.1109/TPAMI.2019.2940446
   Mao Q, 2019, PROC CVPR IEEE, P1429, DOI 10.1109/CVPR.2019.00152
   Min WQ, 2020, IEEE T MULTIMEDIA, V22, P3128, DOI 10.1109/TMM.2020.2974326
   Min WQ, 2017, IEEE T MULTIMEDIA, V19, P1100, DOI 10.1109/TMM.2016.2639382
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Murrugarra-Llerena N, 2019, PROC CVPR IEEE, P6422, DOI 10.1109/CVPR.2019.00659
   Nagarajan T, 2018, LECT NOTES COMPUT SC, V11205, P172, DOI 10.1007/978-3-030-01246-5_11
   Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11
   Pang K., 2017, BMVC, P1
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Perez E, 2018, AAAI CONF ARTIF INTE, P3942
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Reed S, 2016, PR MACH LEARN RES, V48
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santra A, 2017, ADV GEOSPAT TECH, P1, DOI 10.4018/978-1-5225-1814-3
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10635, DOI 10.1109/CVPR42600.2020.01065
   Song G, 2019, IEEE T MULTIMEDIA, V21, P1261, DOI 10.1109/TMM.2018.2877122
   Song Y, 2019, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2019.00208
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan HC, 2019, IEEE I CONF COMP VIS, P10500, DOI 10.1109/ICCV.2019.01060
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Vo N, 2019, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2019.00660
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang H, 2019, PROC CVPR IEEE, P11564, DOI 10.1109/CVPR.2019.01184
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wu YL, 2020, IEEE T MULTIMEDIA, V22, P1310, DOI 10.1109/TMM.2019.2942494
   Wu Y, 2017, PROC CVPR IEEE, P3984, DOI 10.1109/CVPR.2017.424
   Wu Y, 2020, IEEE T IMAGE PROCESS, V29, P3984, DOI 10.1109/TIP.2020.2967584
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yin GJ, 2019, PROC CVPR IEEE, P2322, DOI 10.1109/CVPR.2019.00243
   Zhang D, 2019, PROC CVPR IEEE, P1247, DOI 10.1109/CVPR.2019.00134
   Zhang F., 2020, ACM MULTIMEDIA, V2020, P3367
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang J, 2020, IEEE T MULTIMEDIA, V22, P174, DOI 10.1109/TMM.2019.2922128
   Zhang JY, 2018, LECT NOTES COMPUT SC, V11206, P304, DOI 10.1007/978-3-030-01216-8_19
   Zhang LL, 2020, IEEE T MULTIMEDIA, V22, P775, DOI 10.1109/TMM.2019.2931352
   Zhao B, 2017, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2017.652
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
   Zhu B, 2019, PROC CVPR IEEE, P11469, DOI 10.1109/CVPR.2019.01174
   Zhu L., 2020, P IEEE CVF C COMP VI, DOI 10.1109/CVPR42600.2020.00877
NR 78
TC 11
Z9 11
U1 1
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2022
VL 18
IS 2
AR 59
DI 10.1145/3478642
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0A0YT
UT WOS:000773689400012
DA 2024-07-18
ER

PT J
AU Han, XH
   Zheng, YQ
   Chen, YW
AF Han, Xian-Hua
   Zheng, Yinqiang
   Chen, Yen-Wei
TI Hyperspectral Image Reconstruction Using Multi-scale Fusion Learning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Hyper-spectral image super-resolution; DCNN; spectral and spatial
   fusion; alternative back projection; multi-scale fusion; U-shape
   architecture
ID MULTISPECTRAL DATA; LANDSAT-TM; CLASSIFICATION
AB Hyperspectral imaging is a promising imaging modality that simultaneously captures several images for the same scene on narrow spectral bands, and it has made considerable progress in different fields, such as agriculture, astronomy, and surveillance. However, the existing hyperspectral (HS) cameras sacrifice the spatial resolution for providing the detail spectral distribution of the imaged scene, which leads to low-resolution (LR) HS images compared with the common red-green-blue (RGB) images. Generating a high-resolution HS (HR-HS) image via fusing an observed LR-HS image with the corresponding HR-RGB image has been actively studied. Existing methods for this fusing task generally investigate hand-crafted priors to model the inherent structure of the latent HR-HS image, and they employ optimization approaches for solving it. However, proper priors for different scenes can possibly be diverse, and to figure it out for a specific scene is difficult. This study investigates a deep convolutional neural network (DCNN)-based method for automatic prior learning, and it proposes a novel fusion DCNN model with multi-scale spatial and spectral learning for effectively merging an HR-RGB and LR-HS images. Specifically, we construct an U-shape network architecture for gradually reducing the feature sizes of the HR-RGB image (Encoder-side) and increasing the feature sizes of the LR-HS image (Decoder-side), and we fuse the HR spatial structure and the detail spectral attribute in multiple scales for tackling the large resolution difference in spatial domain of the observed HR-RGB and LR-HS images. Then, we employ multi-level cost functions for the proposed multi-scale learning network to alleviate the gradient vanish problem in long-propagation procedure. In addition, for further improving the reconstruction performance of the HR-HS image, we refine the predicted HR-HS image using an alternating back-projection method for minimizing the reconstruction errors of the observed LR-HS and HR-RGB images. Experiments on three benchmark HS image datasets demonstrate the superiority of the proposed method in both quantitative values and visual qualities.
C1 [Han, Xian-Hua] Yamaguchi Univ, Grad Sch Sci & Technol Innovat, 1677-1 Yoshida, Yamaguchi 7538511, Japan.
   [Zheng, Yinqiang] Natl Inst Informat, Tokyo, Japan.
   [Zheng, Yinqiang] Univ Tokyo, Bunkyo Ku, Next Generat Artificial Intelligence Res Ctr, Hongo 7-3-1, Tokyo 1137656, Japan.
   [Chen, Yen-Wei] Ritsumeikan Univ, Coll Informat Sci & Engn, 1-1-1 NojiHigashi, Kusatsu, Shiga, Japan.
C3 Yamaguchi University; Research Organization of Information & Systems
   (ROIS); National Institute of Informatics (NII) - Japan; University of
   Tokyo; Ritsumeikan University
RP Han, XH (corresponding author), Yamaguchi Univ, Grad Sch Sci & Technol Innovat, 1677-1 Yoshida, Yamaguchi 7538511, Japan.
EM hanxhua@yamaguchi-u.ac.jp; yqzheng@ai.u-tokyo.ac.jp;
   chen@is.ritsumei.ac.jp
RI Han, Xian-Hua/A-5563-2017
OI Han, Xian-Hua/0000-0002-5003-3180; Zheng, Yinqiang/0000-0001-7434-5069
FU Japanese Ministry for Education, Science, Culture and Sports (MEXT)
   [20K11867]; Grants-in-Aid for Scientific Research [20K11867] Funding
   Source: KAKEN
FX This research was supported in part by the Grant-in Aid for Scientific
   Research from the Japanese Ministry for Education, Science, Culture and
   Sports (MEXT) under the Grant No. 20K11867.
CR Aiazzi B, 2009, IEEE GEOSCI REMOTE S, V6, P302, DOI 10.1109/LGRS.2008.2012003
   Akhtar N, 2015, PROC CVPR IEEE, P3631, DOI 10.1109/CVPR.2015.7298986
   Akhtar N, 2014, INT C PATT RECOG, P3726, DOI 10.1109/ICPR.2014.640
   Akhtar N, 2014, LECT NOTES COMPUT SC, V8695, P63, DOI 10.1007/978-3-319-10584-0_5
   Alvarez-Gila A, 2017, IEEE INT CONF COMP V, P480, DOI 10.1109/ICCVW.2017.64
   [Anonymous], 2014, INT J SIGNAL PROCESS
   Arad B, 2016, LECT NOTES COMPUT SC, V9911, P19, DOI 10.1007/978-3-319-46478-7_2
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Cetin M, 2009, INT J REMOTE SENS, V30, P1779, DOI 10.1080/01431160802639525
   Chakrabarti A, 2011, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2011.5995660
   CHAVEZ PS, 1991, PHOTOGRAMM ENG REM S, V57, P295
   Dian RW, 2019, IEEE T IMAGE PROCESS, V28, P5135, DOI 10.1109/TIP.2019.2916734
   Dian RW, 2018, IEEE T NEUR NET LEAR, V29, P5345, DOI 10.1109/TNNLS.2018.2798162
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2016, IEEE T IMAGE PROCESS, V25, P2337, DOI 10.1109/TIP.2016.2542360
   Fauvel M, 2013, P IEEE, V101, P652, DOI 10.1109/JPROC.2012.2197589
   Galliani S., 2017, ARXIV170309470
   Grohnfeldt C, 2013, INT GEOSCI REMOTE SE, P4090, DOI 10.1109/IGARSS.2013.6723732
   Han XH, 2019, IEEE INT CONF COMP V, P4330, DOI 10.1109/ICCVW.2019.00533
   Han XH, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P266, DOI [10.1109/BigMM.2019.00049, 10.1109/BigMM.2019.00-13]
   Han XH, 2018, IEEE IMAGE PROC, P2506, DOI 10.1109/ICIP.2018.8451142
   Han XH, 2018, INT C PATT RECOG, P2664, DOI 10.1109/ICPR.2018.8545634
   Han XH, 2018, IEEE T IMAGE PROCESS, V27, P5625, DOI 10.1109/TIP.2018.2855418
   Haris M, 2017, SIGNAL IMAGE VIDEO P, V11, P1, DOI 10.1007/s11760-016-0880-y
   Haydn R., 1982, P ISRSE
   Huang B, 2014, IEEE T GEOSCI REMOTE, V52, P1693, DOI 10.1109/TGRS.2013.2253612
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kawakami R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2329, DOI 10.1109/CVPR.2011.5995457
   Kim Jiwon, 2016, P CVPR
   KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N
   Kwan C, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091416
   Kwan C, 2017, INT CONF ACOUST SPEE, P6180, DOI 10.1109/ICASSP.2017.7953344
   Lanaras C, 2015, IEEE I CONF COMP VIS, P3586, DOI 10.1109/ICCV.2015.409
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li YS, 2017, NEUROCOMPUTING, V266, P29, DOI 10.1016/j.neucom.2017.05.024
   Mei SH, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111139
   Minghelli-Roman A, 2006, IEEE GEOSCI REMOTE S, V3, P227, DOI 10.1109/LGRS.2005.861699
   Nguyen RMH, 2014, LECT NOTES COMPUT SC, V8695, P186, DOI 10.1007/978-3-319-10584-0_13
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Qu Y, 2018, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2018.00266
   Simonyan K., 2014, CORR
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tarabalka Y, 2010, IEEE T SYST MAN CY B, V40, P1267, DOI 10.1109/TSMCB.2009.2037132
   Uzair M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.57
   Van Nguyen H., 2010, P 2010 IEEE COMP SOC, P44
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Q, 2015, IEEE T GEOSCI REMOTE, V53, P3658, DOI 10.1109/TGRS.2014.2381272
   Wycoff E, 2013, INT CONF ACOUST SPEE, P1409, DOI 10.1109/ICASSP.2013.6637883
   Xu Y, 2019, IEEE T IMAGE PROCESS, V28, P3034, DOI 10.1109/TIP.2019.2893530
   Yokoya N, 2012, IEEE T GEOSCI REMOTE, V50, P528, DOI 10.1109/TGRS.2011.2161320
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang L, 2018, IEEE T IMAGE PROCESS, V27, P5969, DOI 10.1109/TIP.2018.2862629
   Zhou J, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.035024
   Zhou Y, 2014, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2014.394
   Zurita-Milla R, 2008, IEEE GEOSCI REMOTE S, V5, P453, DOI 10.1109/LGRS.2008.919685
NR 58
TC 2
Z9 2
U1 2
U2 20
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2022
VL 18
IS 1
AR 16
DI 10.1145/3477396
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5OX
UT WOS:000772636900016
DA 2024-07-18
ER

PT J
AU Liu, XB
   He, JS
   Song, LP
   Liu, S
   Srivastava, G
AF Liu, Xiangbin
   He, Jiesheng
   Song, Liping
   Liu, Shuai
   Srivastava, Gautam
TI Medical Image Classification based on an Adaptive Size Deep Learning
   Model
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Deep learning; medical images; adaptive size; classification; multi-size
ID COVID-19 CLASSIFICATION; FUSION; NETWORK
AB With the rapid development of Artificial Intelligence (AI), deep learning has increasingly become a research hotspot in various fields, such as medical image classification. Traditional deep learning models use Bilinear Interpolation when processing classification tasks of multi-size medical image dataset, which will cause the loss of information of the image, and then affect the classification effect. In response to this problem, this work proposes a solution for an adaptive size deep learning model. First, according to the characteristics of the multi-size medical image dataset, the optimal size set module is proposed in combination with the unpooling process. Next, an adaptive deep learning model module is proposed based on the existing deep learning model. Then, the model is fused with the size fine-tuning module used to process multi-size medical images to obtain a solution of the adaptive size deep learning model. Finally, the proposed solution model is applied to the pneumonia CT medical image dataset. Through experiments, it can be seen that the model has strong robustness, and the classification effect is improved by about 4% compared with traditional algorithms.
C1 [Liu, Xiangbin; He, Jiesheng; Song, Liping; Liu, Shuai] Hunan Normal Univ, Coll Informat Sci & Engn, Changsha, Peoples R China.
   [Liu, Xiangbin; Liu, Shuai] Hunan Normal Univ, Hunan Prov Key Lab Intelligent Comp & Language In, 36 Lushan Rd, Changsha 410081, Hunan, Peoples R China.
   [Liu, Shuai] Hunan Xiangjiang Artificial Intelligence Acad, Changsha, Peoples R China.
   [Srivastava, Gautam] Brandon Univ, Dept Math & Comp Sci, 270 18th St, Brandon, MB R7A 6A9, Canada.
   [Srivastava, Gautam] China Med Univ, Res Ctr Interneural Comp, 91 Xueshi Rd, Taichung 40402, Taiwan.
C3 Hunan Normal University; Hunan Normal University; Brandon University;
   China Medical University Taiwan
RP Liu, S (corresponding author), Hunan Normal Univ, Coll Informat Sci & Engn, Changsha, Peoples R China.; Liu, S (corresponding author), Hunan Normal Univ, Hunan Prov Key Lab Intelligent Comp & Language In, 36 Lushan Rd, Changsha 410081, Hunan, Peoples R China.; Liu, S (corresponding author), Hunan Xiangjiang Artificial Intelligence Acad, Changsha, Peoples R China.; Srivastava, G (corresponding author), Brandon Univ, Dept Math & Comp Sci, 270 18th St, Brandon, MB R7A 6A9, Canada.; Srivastava, G (corresponding author), China Med Univ, Res Ctr Interneural Comp, 91 Xueshi Rd, Taichung 40402, Taiwan.
EM xbliufrank@hunnu.edu.cn; JasonHE@hunnu.edu.cn; song@hunnu.edu.cn;
   liushuai@hunnu.edu.cn; srivastavag@brandonu.ca
RI Liu, Shuai/P-3939-2017; Srivastava, Gautam/N-5668-2019
OI Liu, Shuai/0000-0001-9909-0664; Srivastava, Gautam/0000-0001-9851-4103
FU Natural Science Foundation of Hunan Province [2020JJ4434]; Key
   Scientific Research Projects of Department of Education of Hunan
   Province [19A312]; Hunan Provincial Science & Technology Project
   Foundation [2018TP1018, 2018RS3065]; National Natural Science Foundation
   of China [61502254]; Scientific Research Fund of Hunan Provincial
   Education Department [14C0710]
FX This study is partly funded by the Natural Science Foundation of Hunan
   Province under Grant 2020JJ4434, the Key Scientific Research Projects of
   Department of Education of Hunan Province with No.19A312; Hunan
   Provincial Science & Technology Project Foundation (2018TP1018,
   2018RS3065), National Natural Science Foundation of China with No.
   61502254, Scientific Research Fund of Hunan Provincial Education
   Department (14C0710).
CR Amini Z, 2016, CURR MED IMAGING, V12, P130, DOI 10.2174/1573394711666150827203543
   Bai J, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/1065652
   Chi JN, 2017, J DIGIT IMAGING, V30, P477, DOI 10.1007/s10278-017-9997-y
   Choi JY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187336
   Cui XY, 2019, J AM ACAD DERMATOL, V81, P1176, DOI 10.1016/j.jaad.2019.06.042
   Geng L, 2019, COMPUT ASSIST SURG, V24, P27, DOI 10.1080/24699322.2019.1649071
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirano G, 2020, SKIN RES TECHNOL, V26, P891, DOI 10.1111/srt.12891
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Jayapriya K, 2020, INT J IMAG SYST TECH, V30, P348, DOI 10.1002/ima.22377
   Kaehler A., 2016, Learning OpenCV 3
   Kaur Taranjit, 2019, 2019 International Conference on Information Technology (ICIT), P94, DOI 10.1109/ICIT48102.2019.00023
   Kermany Daniel, 2018, Mendeley Data, V3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Li MY, 2020, MED PHYS, V47, P1139, DOI 10.1002/mp.14003
   Li W, 2021, MOBILE NETW APPL, V26, P381, DOI 10.1007/s11036-020-01674-5
   Li Y, 2019, METHODS, V166, P4, DOI 10.1016/j.ymeth.2019.04.008
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008
   Lu ZY, 2020, PATTERN RECOGN LETT, V133, P173, DOI 10.1016/j.patrec.2020.03.007
   Ma L, 2020, MED BIOL ENG COMPUT, V58, P1251, DOI 10.1007/s11517-020-02163-3
   Mandavifar S, 2019, NEUROCOMPUTING, V347, P149, DOI 10.1016/j.neucom.2019.02.056
   Ongsulee P., 2017, INT C ICT KNOWL ENG, P1, DOI [DOI 10.1109/ICTKE.2017.8259629, 10.1109/ICTKE.2017.8259629]
   Polap D, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102748
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang SH, 2021, INFORM FUSION, V68, P131, DOI 10.1016/j.inffus.2020.11.005
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Wang SH, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00205
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Zhang QC, 2020, INFORM SCIENCES, V536, P91, DOI 10.1016/j.ins.2020.05.013
   Zhang YD, 2020, INFORM FUSION, V64, P149, DOI 10.1016/j.inffus.2020.07.006
   Zhang ZC, 2019, TRANSPORT RES C-EMER, V105, P297, DOI 10.1016/j.trc.2019.05.039
NR 36
TC 14
Z9 14
U1 15
U2 111
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2021
VL 17
IS 3
SU S
SI SI
AR 102
DI 10.1145/3465220
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YA4BM
UT WOS:000738280600004
DA 2024-07-18
ER

PT J
AU Du, Y
   Xu, YY
   Ye, TZ
   Wen, Q
   Xiao, CF
   Dong, JY
   Han, GQ
   He, SF
AF Du, Yong
   Xu, Yangyang
   Ye, Taizhong
   Wen, Qiang
   Xiao, Chufeng
   Dong, Junyu
   Han, Guoqiang
   He, Shengfeng
TI Invertible Grayscale with Sparsity Enforcing Priors
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Decolorization; colorization; sparsity enforcing priors; convolutional
   neural networks
ID COLORIZATION; CONVERSION; IMAGES
AB Color dimensionality reduction is believed as a non-invertible process, as re-colorization results in perceptually noticeable and unrecoverable distortion. In this article, we propose to convert a color image into a grayscale image that can fully recover its original colors, and more importantly, the encoded information is discriminative and sparse, which saves storage capacity. Particularly, we design an invertible deep neural network for color encoding and decoding purposes. This network learns to generate a residual image that encodes color information, and it is then combined with a base grayscale image for color recovering. In this way, the non-differentiable compression process (e.g., JPEG) of the base grayscale image can be integrated into the network in an end-to-end manner. To further reduce the size of the residual image, we present a specific layer to enhance Sparsity Enforcing Priors (SEP), thus leading to negligible storage space. The proposed method allows color embedding on a sparse residual image while keeping a high, 35dB PSNR on average. Extensive experiments demonstrate that the proposed method outperforms state-of-the-arts in terms of image quality and tolerability to compression.
C1 [Du, Yong; Dong, Junyu] Ocean Univ China, Qingdao, Peoples R China.
   [Xu, Yangyang; Ye, Taizhong; Wen, Qiang; Han, Guoqiang; He, Shengfeng] South China Univ Technol, Guangzhou, Peoples R China.
   [Xiao, Chufeng] City Univ Hong Kong, Hong Kong, Peoples R China.
C3 Ocean University of China; South China University of Technology; City
   University of Hong Kong
RP He, SF (corresponding author), South China Univ Technol, Guangzhou, Peoples R China.
EM csyongdu@ouc.edu.cn; cnnlstm@gmail.com; walden2021@foxmail.com;
   csqiangwen@gmail.com; chufengxiao@outlook.com; dongjunyu@ouc.edu.cn;
   csgqhan@scut.edu.cn; hesfe@scut.edu.cn
RI He, Shengfeng/E-5682-2016
OI He, Shengfeng/0000-0002-3802-4644; Xiao, Chufeng/0000-0001-6749-0161
FU National Natural Science Foundation of China [61972162, 61702194,
   U1706218, 41927805]; China Postdoctoral Science Foundation
   [2020M682240]; National Key R&D Program of China [2018AAA0100600];
   CCF-Tencent Open Research fund [CCF-Tencent RAGR20190112]
FX This project is supported by the National Natural Science Foundation of
   China under Grant No.: 61972162, 61702194, U1706218, 41927805; the China
   Postdoctoral Science Foundation under Grant No.: 2020M682240; the
   National Key R&D Program of China under Grant No.: 2018AAA0100600; and
   the CCF-Tencent Open Research fund under Grant No.: CCFTencent
   RAGR20190112.
CR [Anonymous], 2018, INT C LEARN REPR
   [Anonymous], 2007, PROC 3 EUR C COMPUTA
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Baig MH, 2017, COMPUT VIS IMAGE UND, V164, P111, DOI 10.1016/j.cviu.2017.01.010
   Balle J., 2017, INT C LEARN REPR
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Du H, 2015, IEEE T IMAGE PROCESS, V24, P434, DOI 10.1109/TIP.2014.2380172
   Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2014, AUTOENCODING VARIATI, P3581
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li M, 2018, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2018.00339
   Lu CW, 2014, INT J COMPUT VISION, V110, P222, DOI 10.1007/s11263-014-0732-6
   Luan Q., 2007, P 18 EUR C CREND TEC, P309
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Maddison Chris J, 2016, ARXIV161100712
   Matsuda I, 2000, IEEE IMAGE PROC, P132, DOI 10.1109/ICIP.2000.900912
   Nand NR, 2012, P IEEE INT FREQ CONT
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Simonyan K., 2014, CORR
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Smith K, 2008, COMPUT GRAPH FORUM, V27, P193, DOI 10.1111/j.1467-8659.2008.01116.x
   Tucker G, 2017, ADV NEUR IN, V30
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu Y., 2018, INT C LEARNING REPRE
   Xia MH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275080
   Xu L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508404
   Ye TZ, 2020, IEEE ACCESS, V8, P89670, DOI 10.1109/ACCESS.2020.2994148
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 35
TC 1
Z9 1
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2021
VL 17
IS 3
AR 97
DI 10.1145/3451993
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UC5SO
UT WOS:000686585400021
OA Green Published
DA 2024-07-18
ER

PT J
AU Lin, MX
   Tang, F
   Dong, WM
   Li, X
   Xu, CS
   Ma, CY
AF Lin, Minxuan
   Tang, Fan
   Dong, Weiming
   Li, Xiao
   Xu, Changsheng
   Ma, Chongyang
TI Distribution Aligned Multimodal and Multi-domain Image Stylization
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image stylization; multi-domain; multimodal
ID GENERATIVE ADVERSARIAL NETWORKS
AB Multimodal and multi-domain stylization are two important problems in the field of image style transfer. Currently, there are few methods that can perform multimodal and multi-domain stylization simultaneously. In this study, we propose a unified framework for multimodal and multi-domain style transfer with the support of both exemplar-based reference and randomly sampled guidance. The key component of our method is a novel style distribution alignment module that eliminates the explicit distribution gaps between various style domains and reduces the risk of mode collapse. The multimodal diversity is ensured by either guidance from multiple images or random style codes, while the multi-domain controllability is directly achieved by using a domain label. We validate our proposed framework on painting style transfer with various artistic styles and genres. Qualitative and quantitative comparisons with state-of-the-art methods demonstrate that our method can generate high-quality results of multi-domain styles and multimodal instances from reference style guidance or a random sampled style.
C1 [Lin, Minxuan; Dong, Weiming; Xu, Changsheng] Chinese Acad Sci, Inst Automat, NLPR, 95 East Zhongguancun Rd, Beijing 100190, Peoples R China.
   [Lin, Minxuan] Univ Chinese Acad Sci, Sch Artificial Intelligence, 95 East Zhongguancun Rd, Beijing 100190, Peoples R China.
   [Tang, Fan] Jilin Univ, Sch Artificial Intelligence, 2699 Qianjin St, Changchun 130012, Jilin, Peoples R China.
   [Dong, Weiming; Xu, Changsheng] CASIA LLvis Joint Lab, 95 East Zhongguancun Rd, Beijing 100190, Peoples R China.
   [Li, Xiao] Microsoft Res Asia, 5 Dan Ling St, Beijing 100080, Peoples R China.
   [Ma, Chongyang] Kuaishou Technol, 6 Shangdi West Rd, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Jilin University; Microsoft Research Asia; Microsoft
RP Lin, MX (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, 95 East Zhongguancun Rd, Beijing 100190, Peoples R China.; Lin, MX (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, 95 East Zhongguancun Rd, Beijing 100190, Peoples R China.
EM linminxuan2018@ia.ac.cn; tangfan@jlu.edu.cn; weiming.dong@ia.ac.cn;
   pableetoli@gmail.com; csxu@nlpr.ia.ac.cn; chongyangm@gmail.com
RI DONG, Weiming/AAG-7678-2020; Xu, Chang/GQP-7280-2022; xu,
   cj/HJZ-3488-2023; Tang, Fan/O-3923-2018
OI DONG, Weiming/0000-0001-6502-145X; Tang, Fan/0000-0002-3975-2483
FU National Key R&D Program of China [2020AAA0106200]; National Natural
   Science Foundation of China [61832016, U20B2070]
FX This work was supported by National Key R&D Program of China under Grant
   No. 2020AAA0106200, and by National Natural Science Foundation of China
   under Grants No. 61832016 and No. U20B2070.
CR Anoosheh A, 2018, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2018.00122
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Chang S, 2019, IEEE I CONF COMP VIS, P4802, DOI 10.1109/ICCV.2019.00490
   Choi Y., 2020, P IEEE C COMP VIS PA, P8185, DOI [10.1109/CVPR42600.2020.00821, DOI 10.1109/CVPR42600.2020.00821]
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chongyang Ma., 2021, P 35 AAAI C ART INT
   Deng YY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2719, DOI 10.1145/3394171.3414015
   Doyle L, 2019, COMPUT VIS MEDIA, V5, P33, DOI 10.1007/s41095-019-0129-0
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2014, AUTOENCODING VARIATI, P3581
   Kotovenko D, 2019, IEEE I CONF COMP VIS, P4421, DOI 10.1109/ICCV.2019.00452
   Kotovenko D, 2019, PROC CVPR IEEE, P10024, DOI 10.1109/CVPR.2019.01027
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li XT, 2019, PROC CVPR IEEE, P3804, DOI 10.1109/CVPR.2019.00393
   Li Y, 2017, Advances in Neural Information Processing Systems, DOI [10.5555/3294771.3294808, DOI 10.5555/3294771.3294808]
   Liu Alexander H, 2018, NIPS, P2590
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Liu Y., 2020, GMM UNIT UNSUPERVISE
   Ma L, 2019, P 7 INT C LEARN REPR
   Makhzani A., 2016, ADVERSARIAL AUTOENCO
   Mao Q, 2019, PROC CVPR IEEE, P1429, DOI 10.1109/CVPR.2019.00152
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Odena A, 2017, PR MACH LEARN RES, V70
   Park DY, 2019, PROC CVPR IEEE, P5873, DOI 10.1109/CVPR.2019.00603
   Romero A, 2019, IEEE INT CONF COMP V, P3285, DOI 10.1109/ICCVW.2019.00410
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Sohn K, 2015, ADV NEUR IN, V28
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Ulyanov D., 2017, Instance Normalization: The Missing Ingredient for Fast Stylization
   Yang FE, 2020, IEEE T IMAGE PROCESS, V29, P2795, DOI 10.1109/TIP.2019.2952707
   Yao Y, 2019, PROC CVPR IEEE, P1467, DOI 10.1109/CVPR.2019.00156
   Yu Xiaoming, 2019, P ADV NEUR INF PROC, P2990
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang SY, 2019, COMPUT VIS MEDIA, V5, P105, DOI 10.1007/s41095-019-0136-1
NR 41
TC 11
Z9 11
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2021
VL 17
IS 3
AR 96
DI 10.1145/3450525
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UC5SO
UT WOS:000686585400020
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, ZZ
   Xu, PF
   Yang, YP
   Bao, BK
AF Yang, Zhenzhen
   Xu, Pengfei
   Yang, Yongpeng
   Bao, Bing-Kun
TI A Densely Connected Network Based on U-Net for Medical Image
   Segmentation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; deep learning; U-Net network; densely
   connection; dense block
AB The U-Net has become the most popular structure in medical image segmentation in recent years. Although its performance for medical image segmentation is outstanding, a large number of experiments demonstrate that the classical U-Net network architecture seems to be insufficient when the size of segmentation targets changes and the imbalance happens between target and background in different forms of segmentation. To improve the U-Net network architecture, we develop a new architecture named densely connected U-Net (DenseUNet) network in this article. The proposed DenseUNet network adopts a dense block to improve the feature extraction capability and employs a multi-feature fuse block fusing feature maps of different levels to increase the accuracy of feature extraction. In addition, in view of the advantages of the cross entropy and the dice loss functions, a new loss function for the DenseUNet network is proposed to deal with the imbalance between target and background. Finally, we test the proposed DenseUNet network and compared it with the multi-resolutional U-Net (MultiResUNet) and the classic U-Net networks on three different datasets. The experimental results show that the DenseUNet network has significantly performances compared with the MultiResUNet and the classic U-Net networks.
C1 [Yang, Zhenzhen] Nanjing Univ Posts & Telecommun, Natl Engn Res Ctr Commun & Networking, Sch Sci, 9 Wenyuan Rd, Nanjing 210023, Peoples R China.
   [Xu, Pengfei; Bao, Bing-Kun] Nanjing Univ Posts & Telecommun, Natl Engn Res Ctr Commun & Networking, 9 Wenyuan Rd, Nanjing 210023, Peoples R China.
   [Yang, Yongpeng] Nanjing Vocat Coll Informat Technol, Sch Network & Commun, 99 Wenlan Rd, Nanjing 210023, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications; Nanjing Vocational College of Information
   Technology
RP Yang, ZZ (corresponding author), Nanjing Univ Posts & Telecommun, Natl Engn Res Ctr Commun & Networking, Sch Sci, 9 Wenyuan Rd, Nanjing 210023, Peoples R China.; Yang, YP (corresponding author), Nanjing Vocat Coll Informat Technol, Sch Network & Commun, 99 Wenlan Rd, Nanjing 210023, Peoples R China.
EM yangzz@njupt.edu.cn; yangyp@njcit.cn
FU National Natural Science Foundation of China [61501251, 11671004,
   6193000388, 61872424]; China Postdoctoral Science Foundation
   [2018M632326]; Open Topic of National Engineering Research Center of
   Communications and Networking [TXKY17010]; Natural Science Foundation of
   Jiangsu Higher Education Institutions of China [19KJB510044]; NUPTSF
   [NY220207]; National Key Research & Development Plan of China
   [2020AAA0106200]; Natural Science Foundation of Jiangsu Province
   [BK20200037]; Natural Science Foundation of Nanjing Vocational College
   of Information Technology [YK20190402]
FX This work is sponsored by the National Natural Science Foundation of
   China (Grant Nos. 61501251,11671004, 6193000388 and 61872424), the China
   Postdoctoral Science Foundation (Grant No. 2018M632326), the Open Topic
   of National Engineering Research Center of Communications and Networking
   (Grant No. TXKY17010), the Natural Science Foundation of Jiangsu Higher
   Education Institutions of China (Grant No. 19KJB510044), the NUPTSF
   (Grant No. NY220207), the National Key Research & Development Plan of
   China 2020AAA0106200, the Natural Science Foundation of Jiangsu Province
   (Grants No BK20200037) and the Natural Science Foundation of Nanjing
   Vocational College of Information Technology (Grant No. YK20190402).
CR [Anonymous], ARXIV180310417
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cardona A, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000502
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YJ, 2021, IEEE GEOSCI REMOTE S, V18, P162, DOI 10.1109/LGRS.2020.2967104
   Ciresan D., 2012, NIPS, P2843
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Eigen David, 2014, R FERGUS Y LECUN OVE
   Huang GL, 2017, IEEE ICC
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Ji YL, 2020, IEEE T IMAGE PROCESS, V29, P2742, DOI 10.1109/TIP.2019.2952088
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li CG, 2017, IEEE T IMAGE PROCESS, V26, P2988, DOI 10.1109/TIP.2017.2691557
   Lian CF, 2019, IEEE T IMAGE PROCESS, V28, P755, DOI 10.1109/TIP.2018.2872908
   Liang K, 2018, PROCEEDINGS OF 2018 IEEE 4TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2018), P1111, DOI 10.1109/ITOEC.2018.8740402
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Oktay O, 2018, IEEE T MED IMAGING, V37, P384, DOI 10.1109/TMI.2017.2743464
   Punn NS, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3376922
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Van Rossum G., 2007, Usenix annual technical conference, V41, P1
   Wang XP, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3355397
   Yang JZ, 2018, MED PHYS, V45, P4568, DOI 10.1002/mp.13141
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang JH, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3372800
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 32
TC 11
Z9 12
U1 4
U2 43
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2021
VL 17
IS 3
AR 89
DI 10.1145/3446618
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UC5SO
UT WOS:000686585400013
DA 2024-07-18
ER

PT J
AU Kasyap, H
   Tripathy, S
AF Kasyap, Harsh
   Tripathy, Somanath
TI Privacy-preserving Decentralized Learning Framework for Healthcare
   System
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Healthcare system; federated learning; blockchain; security; privacy
ID SECURITY
AB Clinical trials and drug discovery would not be effective without the collaboration of institutions. Earlier, it has been at the cost of individual's privacy. Several pacts and compliances have been enforced to avoid data breaches. The existing schemes collect the participant's data to a central repository for learning predictions as the collaboration is indispensable for research advances. The current COVID pandemic has put a question mark on our existing setup where the existing data repository has proved to be obsolete. There is a need for contemporary data collection, processing, and learning. The smartphones and devices held by the last person of the society have also made them a potential contributor. It demands to design a distributed and decentralized Collaborative Learning system that would make the knowledge inference from every data point. Federated Learning [21], proposed by Google, brings the concept of in-place model training by keeping the data intact to the device. Though it is privacy-preserving in nature, however, it is susceptible to inference, poisoning, and Sybil attacks. Blockchain is a decentralized programming paradigm that provides a broader control of the system, making it attack resistant. It poses challenges of high computing power, storage, and latency. These emerging technologies can contribute to the desired learning system and motivate them to address their security and efficiency issues. This article systematizes the security issues in Federated Learning, its corresponding mitigation strategies, and Blockchain's challenges. Further, a Blockchain-based Federated Learning architecture with two layers of participation is presented, which improves the global model accuracy and guarantees participant's privacy. It leverages the channel mechanism of Blockchain for parallel model training and distribution. It facilitates establishing decentralized trust between the participants and the gateways using the Blockchain, which helps to have only honest participants.
C1 [Kasyap, Harsh; Tripathy, Somanath] Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801103, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Patna
RP Kasyap, H (corresponding author), Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801103, Bihar, India.
EM harsh_1921cs01@iitp.ac.in; som@iitp.ac.in
RI Tripathy, Somanath/JMC-2884-2023
OI Tripathy, Somanath/0000-0002-6964-2648; Kasyap,
   Harsh/0000-0002-8313-6354
FU Ministry of Human Resource Development, Government of India
FX We acknowledge the Ministry of Human Resource Development, Government of
   India, for providing a fellowship to complete this work.
CR Abramson, 2020, DISTRIBUTED TRUST FR
   Barreno M, 2010, MACH LEARN, V81, P121, DOI 10.1007/s10994-010-5188-5
   Blanchard P., 2017, Advances in Neural Information Processing Systems, P118
   Bonawitz Keith, 2016, PRACTICAL SECURE AGG, V68, P23
   Brisimi TS, 2018, INT J MED INFORM, V112, P59, DOI 10.1016/j.ijmedinf.2018.01.007
   Camenisch J, 2003, LECT NOTES COMPUT SC, V2576, P268
   Chen YQ, 2020, IEEE INTELL SYST, V35, P83, DOI 10.1109/MIS.2020.2988604
   Dwork C, 2010, PROC APPL MATH, V135, P174
   Fung C., 2018, Mitigating Sybils in Federated Learning Poisoning
   Hitaj B, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P603, DOI 10.1145/3133956.3134012
   Kang JW, 2019, IEEE INTERNET THINGS, V6, P10700, DOI 10.1109/JIOT.2019.2940820
   Kim H, 2020, IEEE COMMUN LETT, V24, P1279, DOI 10.1109/LCOMM.2019.2921755
   Kumar S, 2018, MULTIMED TOOLS APPL, V77, P11017, DOI 10.1007/s11042-017-4966-5
   Liu, 2018, FADL FEDERATED AUTON
   Lu, 2019, LEARN ELECT HLTH REC
   Lu YL, 2020, IEEE T IND INFORM, V16, P4177, DOI 10.1109/TII.2019.2942190
   Ma C, 2020, IEEE NETWORK, V34, P242, DOI 10.1109/MNET.001.1900506
   Majeed U., 2019, ASIA-PAC NETW OPER M, P1, DOI DOI 10.23919/APNOMS.2019.8892848
   McMahan H. B., 2016, arXiv preprint arXiv:1602.05629
   Melis L., 2018, Exploiting unintended feature leakage in collaborative learning
   Nasr Milad, 2018, IEEE S P
   Numhauser Jonathan Magen, 2012, ESCRITURAS SILENCIAD, P111
   Shae Z, 2018, INT CON DISTR COMP S, P1290, DOI 10.1109/ICDCS.2018.00129
   Shamir O, 2014, PR MACH LEARN RES, V32, P1000
   Shokri R, 2015, ANN ALLERTON CONF, P909, DOI 10.1109/ALLERTON.2015.7447103
   Stephen O, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4180949
   Vepakomma P., 2018, Split learning for health: Distributed deep learning without sharing raw patient data
   Wang FW, 2019, IEEE ACCESS, V7, P166054, DOI 10.1109/ACCESS.2019.2953495
   Weng JS, 2021, IEEE T DEPEND SECURE, V18, P2438, DOI 10.1109/TDSC.2019.2952332
   Xing HQ, 2016, INT WORKS EARTH OB
   Xu GW, 2020, IEEE T INF FOREN SEC, V15, P911, DOI 10.1109/TIFS.2019.2929409
   Xu Jie, 2019, Federated learning for healthcare informatics
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Yao A. C., 1986, 27th Annual Symposium on Foundations of Computer Science (Cat. No.86CH2354-9), P162, DOI 10.1109/SFCS.1986.25
   Yin D., 2018, Byzantine-robust distributed learning: Towards optimal statistical rates
   Zhao Y., 2019, ARXIV190610893
NR 36
TC 24
Z9 24
U1 3
U2 50
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2021
VL 17
IS 2
SU S
SI SI
AR 68
DI 10.1145/3426474
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TA7ZH
UT WOS:000667464100010
DA 2024-07-18
ER

PT J
AU Li, ZX
   Lin, L
   Zhang, CL
   Ma, HF
   Zhao, WZ
   Shi, ZP
AF Li, Zhixin
   Lin, Lan
   Zhang, Canlong
   Ma, Huifang
   Zhao, Weizhong
   Shi, Zhiping
TI A Semi-supervised Learning Approach Based on Adaptive Weighted Fusion
   for Automatic Image Annotation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; semi-supervised learning; adaptive weighted
   fusion; co-training; covolutional neural network; support vector machine
ID SVMS
AB To learn a well-performed image annotation model, a large number of labeled samples are usually required. Although the unlabeled samples are readily available and abundant, it is a difficult task for humans to annotate large numbers of images manually. In this article, we propose a novel semi-supervised approach based on adaptive weighted fusion for automatic image annotation that can simultaneously utilize the labeled data and unlabeled data to improve the annotation performance. At first, two different classifiers, constructed based on support vector machine and covolutional neural network, respectively, are trained by different features extracted from the labeled data. Therefore, these two classifiers are independently represented as different feature views. Then, the corresponding features of unlabeled images are extracted and input into these two classifiers, and the semantic annotation of images can be obtained respectively. At the same time, the confidence of corresponding image annotation can be measured by an adaptive weighted fusion strategy. After that, the images and its semantic annotations with high confidence are submitted to the classifiers for retraining until a certain stop condition is reached. As a result, we can obtain a strong classifier that can make full use of unlabeled data. Finally, we conduct experiments on four datasets, namely, Corel 5K, IAPR TC12, ESP Game, and NUS-WIDE. In addition, we measure the performance of our approach with standard criteria, including precision, recall, F-measure, N+, and mAP. The experimental results show that our approach has superior performance and outperforms many state-of-the-art approaches.
C1 [Li, Zhixin; Lin, Lan; Zhang, Canlong] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, 15 Yucai Rd Qixing Dist, Guilin 541004, Guangxi, Peoples R China.
   [Ma, Huifang] Northwest Normal Univ, Coll Comp Sci & Engn, 967 Anning East Rd Anning Dist, Lanzhou 730070, Gansu, Peoples R China.
   [Zhao, Weizhong] Cent China Normal Univ, Sch Comp, 152 Luoyu Rd Hongshan Dist, Wuhan 430079, Hubei, Peoples R China.
   [Shi, Zhiping] Capital Normal Univ, Coll Informat Engn, 105 West Third Ring North Rd & Laidian Dist, Beijing 100048, Peoples R China.
C3 Guangxi Normal University; Northwest Normal University - China; Central
   China Normal University; Capital Normal University
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, 15 Yucai Rd Qixing Dist, Guilin 541004, Guangxi, Peoples R China.
EM lizx@gxnu.edu.cn; linlan_2015@sina.com; clzhang@gxnu.edu.cn;
   mahuifang@yeah.net; zhaowz81@163.com; shizp@cnu.edu.cn
RI Ma, Huifang/JTV-4982-2023; Li, Zhixin/ABI-9264-2022
OI Ma, Huifang/0000-0002-5104-8982; Li, Zhixin/0000-0002-5313-6134
FU National Natural Science Foundation of China [61966004, 61663004,
   61762078, 61866004, 61876111]; Guangxi Natural Science Foundation
   [2019GXNSFDA245018, 2018GXNSFDA281009]; Guangxi "Bagui Scholar" Teams
   for Innovation and Research Project; Guangxi Talent Highland Project of
   Big Data Intelligence and Application; Guangxi Collaborative Innovation
   Center of Multi-Source Information Integration and Intelligent
   Processing
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61966004, 61663004, 61762078, 61866004, 61876111), the
   Guangxi Natural Science Foundation (Nos. 2019GXNSFDA245018,
   2018GXNSFDA281009), the Guangxi "Bagui Scholar" Teams for Innovation and
   Research Project, the Guangxi Talent Highland Project of Big Data
   Intelligence and Application, and Guangxi Collaborative Innovation
   Center of Multi-Source Information Integration and Intelligent
   Processing.
CR [Anonymous], 2010, Proceedings of the Eighteenth ACM International Conference on Multimedia, DOI DOI 10.1145/1873951.1873959
   [Anonymous], 2009, NUSWIDE: A real-world web image database from National University of Singapore, DOI DOI 10.1145/1646396.1646452
   [Anonymous], 2013, ARXIV13124894
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Cevikalp H, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107164
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Fei Wu, 2015, IEEE Transactions on Big Data, V1, P109, DOI 10.1109/TBDATA.2015.2497270
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Goh KS, 2005, IEEE T KNOWL DATA EN, V17, P1333, DOI 10.1109/TKDE.2005.170
   Goldman S., 2000, ICML, P327
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jing LP, 2017, IEEE T IMAGE PROCESS, V26, P4612, DOI 10.1109/TIP.2017.2719939
   Jing XY, 2016, IEEE T IMAGE PROCESS, V25, P2712, DOI 10.1109/TIP.2016.2549459
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Ke X, 2017, PATTERN RECOGN, V71, P60, DOI 10.1016/j.patcog.2017.05.020
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lavrenko V, 2004, ADV NEUR IN, V16, P553
   Li ZC, 2013, PATTERN RECOGN, V46, P2700, DOI 10.1016/j.patcog.2013.03.016
   Li ZX, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P63, DOI 10.1145/3323873.3325023
   Li ZX, 2017, MULTIMEDIA SYST, V23, P679, DOI 10.1007/s00530-016-0530-9
   Li ZX, 2013, ENG APPL ARTIF INTEL, V26, P2143, DOI 10.1016/j.engappai.2013.07.004
   Li ZX, 2011, PATTERN RECOGN LETT, V32, P516, DOI 10.1016/j.patrec.2010.11.015
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Qi XJ, 2007, PATTERN RECOGN, V40, P728, DOI 10.1016/j.patcog.2006.04.042
   Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5
   Simonyan K., 2014, 14091556 ARXIV
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P2837, DOI 10.1109/TMM.2019.2909860
   Tariq A, 2018, IMAGE VISION COMPUT, V69, P33, DOI 10.1016/j.imavis.2017.11.002
   Uricchio T, 2017, PATTERN RECOGN, V71, P144, DOI 10.1016/j.patcog.2017.05.019
   Verma Y, 2019, PATTERN RECOGN, V93, P470, DOI 10.1016/j.patcog.2019.05.018
   Verma Y, 2017, INT J COMPUT VISION, V121, P126, DOI 10.1007/s11263-016-0927-0
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Xing YY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2882
   Zhan W, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1305, DOI 10.1145/3097983.3098141
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhao MB, 2015, KNOWL-BASED SYST, V76, P148, DOI 10.1016/j.knosys.2014.12.014
   Zhou T, 2020, MULTIMED TOOLS APPL, V79, P6871, DOI 10.1007/s11042-019-08568-z
   Zhu X., 2007, P INT C MACH LEARN
NR 54
TC 22
Z9 22
U1 1
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2021
VL 17
IS 1
AR 37
DI 10.1145/3426974
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RO6SX
UT WOS:000641174200017
DA 2024-07-18
ER

PT J
AU Becattini, F
   Uricchio, T
   Seidenari, L
   Ballan, L
   del Bimbo, A
AF Becattini, Federico
   Uricchio, Tiberio
   Seidenari, Lorenzo
   Ballan, Lamberto
   del Bimbo, Alberto
TI Am I Done? Predicting Action Progress in Videos
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Action progress; action recognition
AB In this article, we deal with the problem of predicting action progress in videos. We argue that this is an extremely important task, since it can be valuable for a wide range of interaction applications. To this end, we introduce a novel approach, named ProgressNet, capable of predicting when an action takes place in a video, where it is located within the frames, and how far it has progressed during its execution. To provide a general definition of action progress, we ground our work in the linguistics literature, borrowing terms and concepts to understand which actions can be the subject of progress estimation. As a result, we define a categorization of actions and their phases. Motivated by the recent success obtained from the interaction of Convolutional and Recurrent Neural Networks, our model is based on a combination of the Faster R-CNN framework, to make framewise predictions, and LSTM networks, to estimate action progress through time. After introducing two evaluation protocols for the task at hand, we demonstrate the capability of our model to effectively predict action progress on the UCF-101 and J-HMDB datasets.
C1 [Becattini, Federico; Uricchio, Tiberio; Seidenari, Lorenzo; del Bimbo, Alberto] Univ Florence, Florence, Italy.
   [Ballan, Lamberto] Univ Padua, Padua, Italy.
C3 University of Florence; University of Padua
RP Becattini, F (corresponding author), Univ Florence, Florence, Italy.
EM federico.becattini@unifi.it; tiberio.uricchio@unifi.it;
   lorenzo.seidenari@unifi.it; lamberto.ballan@unipd.it;
   alberlo.delbimbo@unifi.it
RI Seidenari, Lorenzo/AAA-1848-2020; Becattini, Federico/AAE-8554-2021;
   Ballan, Lamberto/B-3450-2008
OI Seidenari, Lorenzo/0000-0003-4816-0268; Becattini,
   Federico/0000-0003-2537-2700; Ballan, Lamberto/0000-0003-0819-851X;
   URICCHIO, TIBERIO/0000-0003-1025-4541
FU NVIDIA Corporation; PRIN 2017 project "PREVUE -PRediction of activities
   and Events by Vision in an Urban Environment"
FX This work was partially done while L. Ballan was at the University of
   Florence, Italy. The authors gratefully acknowledge the support of
   NVIDIA Corporation with the donation of the Titan XP GPU used for this
   research. Lamberto Ballan is partially supported by the PRIN 2017
   project "PREVUE -PRediction of activities and Events by Vision in an
   Urban Environment."
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aliakbarian MS, 2017, IEEE I CONF COMP VIS, P280, DOI 10.1109/ICCV.2017.39
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.214
   Arbib MA, 2006, CORTEX, V42, P507, DOI 10.1016/S0010-9452(08)70388-5
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Comrie Bernard, 1976, Aspect: An introduction to the study of verbal aspect and related problems (Vol. 2)
   De Geest R, 2016, LECT NOTES COMPUT SC, V9909, P269, DOI 10.1007/978-3-319-46454-1_17
   Dwibedi D, 2019, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2019.00190
   Escorcia V, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102886
   Fermuller C., 2016, INT J COMPUT VISION, P1
   Flanagan JR, 2003, NATURE, V424, P769, DOI 10.1038/nature01861
   Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Han Tengda, 2017, ARXIV14126980
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heidarivincheh Farnoosh, 2016, BRIT MACH VIS C
   Heidarivincheh Farnoosh, 2019, P IEEE INT C COMP VI
   Heidarivincheh Farnoosh, 2018, P BRIT MACH VIS C BM
   Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Kalogeiton V, 2017, IEEE I CONF COMP VIS, P4415, DOI 10.1109/ICCV.2017.472
   Kingma D. P., 2014, arXiv
   Kong Y, 2017, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2017.390
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Li X, 2017, J ELECTR COMPUT ENG, V2017, P1, DOI 10.1155/2017/5232507
   Liang JW, 2019, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR.2019.00587
   Liu DC, 2019, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2019.00139
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Mathieu M., 2015, PROC INT C LEARN REP
   Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3
   Moltisanti D, 2017, IEEE I CONF COMP VIS, P2905, DOI 10.1109/ICCV.2017.314
   Neumann A., 2019, P IEEE C COMP VIS PA
   Pastra K, 2012, PHILOS T R SOC B, V367, P103, DOI 10.1098/rstb.2011.0123
   Patra A., 2018, ARXIV181011868
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Nguyen PX, 2019, IEEE I CONF COMP VIS, P5501, DOI 10.1109/ICCV.2019.00560
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saha S., 2016, BMVC
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Sigurdsson GA, 2017, IEEE I CONF COMP VIS, P2156, DOI 10.1109/ICCV.2017.235
   Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Soran B, 2015, IEEE I CONF COMP VIS, P4669, DOI 10.1109/ICCV.2015.530
   Steele J, 2012, PHILOS T R SOC B, V367, P4, DOI 10.1098/rstb.2011.0295
   Twinanda AP, 2019, IEEE T MED IMAGING, V38, P1069, DOI 10.1109/TMI.2018.2878055
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   VENDLER Z, 1957, PHILOS REV, V66, P143, DOI 10.2307/2182371
   Vondrick C., 2016, ADV NEURAL INFORM PR, P613, DOI DOI 10.13016/M26GIH-TNYZ
   Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18
   Wang XL, 2016, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2016.291
   Weinzaepfel P, 2015, IEEE I CONF COMP VIS, P3164, DOI 10.1109/ICCV.2015.362
   Xiong Y., 2017, CoRR
   Yang R, 2019, IEEE INT CON MULTI, P532, DOI 10.1109/ICME.2019.00098
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Yu G, 2015, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2015.7298735
   Yuan ZH, 2017, PROC CVPR IEEE, P3215, DOI 10.1109/CVPR.2017.342
   Yue Zhao, 2017, IEEE INT C COMP VIS
   Zhu HY, 2017, IEEE I CONF COMP VIS, P5814, DOI 10.1109/ICCV.2017.619
NR 66
TC 4
Z9 5
U1 0
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2021
VL 16
IS 4
AR 119
DI 10.1145/3402447
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QB4CR
UT WOS:000614088800003
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU He, X
   Liu, Q
   Yang, Y
AF He, Xin
   Liu, Qiong
   Yang, You
TI Make Full Use of Priors: Cross-View Optimized Filter for Multi-View
   Depth Enhancement
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multi-view video plus depth; view consistency; global optimization
ID ENERGY MINIMIZATION; VIDEO; IMAGES; COLOR
AB Multi-view video plus depth (MVD) is the promising and widely adopted data representation for future 3D visual applications and interactive media. However, compression distortions on depth videos impede the development of such applications, and filters are crucially needed for the quality enhancement at the terminal side. Cross-view priors can intuitively be involved in filter design, but these priors are also distorted in compression and thus the contribution of them can hardly be considered in previous research. In this article, we propose a cross-view optimized filter for depth map quality enhancement by making full use of inner- and cross-view priors. We dedicate to evaluate the contributions of distorted cross-view priors in filtering the current view of depth, and then both inner- and cross-view priors can be involved in the filter design. Thus, distortions of cross-view priors are not harriers again as before. For the purpose of that, mutual information guided cross-view consistency is designed to evaluate the contributions of cross-view priors from compression distortions of MVD. After that, under the framework of global optimization, both inner- and cross-view priors are modeled and taken to minimize the designed energy function where both data accuracy and spatial smoothness are modeled. The experimental results show that the proposed model outperforms state-of-the-art methods, where 3.289 dB and 0.0407 average gains on peak signal-to-noise ratio and structural similarity metrics can be obtained, respectively. For the subjective evaluations, object details and structure information are recovered in the compressed depth video. We also verify our method via several practical applications, including virtual view synthesis for smooth interaction and point cloud for 31) modeling for accuracy evaluation. In these verifications, the ringing and malposition artifacts on object contours are properly handled for interactive video, and discontinuous object surfaces are restored for 3D modeling. All of these results suggest that compression distortions in MVD can be properly filtered by the proposed model, which provides a promising solution for future bandwidth constrained 3D and interactive visual applications.
C1 [He, Xin; Liu, Qiong; Yang, You] Huazhong Univ Sci & Technol, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Yang, Y (corresponding author), Huazhong Univ Sci & Technol, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.
EM 1071564592@qq.com; q.liu@hust.edu.cn; yangyou@hust.edu.cn
FU National Natural Science Foundation of China [91848107, 61971203];
   National Key Research and Development Program of China [2017YFC0806202]
FX This work was partially supported by the National Natural Science
   Foundation of China (grants 91848107 and 61971203) and the National Key
   Research and Development Program of China (grant 2017YFC0806202).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Aflaki P, 2010, IEEE IMAGE PROC, P4021, DOI 10.1109/ICIP.2010.5650661
   Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   [Anonymous], 2016, MOBILE INF SYST
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chan Derek, 2008, P WORKSH MULT CAM MU
   Chen SQ, 2019, IEEE DATA COMPR CONF, P560, DOI 10.1109/DCC.2019.00072
   Choi J, 2014, IEEE T CIRC SYST VID, V24, P603, DOI 10.1109/TCSVT.2013.2278160
   Dai R, 2009, IEEE ICC, P143
   Diebel J., 2005, P C ADV NEUR INF PRO, P291
   Dong WS, 2017, IEEE T MULTIMEDIA, V19, P293, DOI 10.1109/TMM.2016.2613824
   Eigen D., 2014, NIPS, DOI DOI 10.5555/2969033.2969091
   Ekmekcioglu E, 2011, IEEE J-STSP, V5, P352, DOI 10.1109/JSTSP.2010.2052783
   Fehn Christoph, 2007, 3DTV Conference, 2007, P1
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Jin Z, 2015, ADV PSYCHOL MENT, P1, DOI 10.4018/978-1-4666-6599-6
   Kim D, 2013, PROC SPIE, V8650, DOI 10.1117/12.2001733
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P494, DOI 10.1109/TPAMI.2019.2894422
   Liu Q, 2013, NEUROCOMPUTING, V104, P1, DOI 10.1016/j.neucom.2012.09.009
   Liu Q, 2012, IEEE SIGNAL PROC LET, V19, P295, DOI 10.1109/LSP.2012.2190060
   Liu W, 2017, NEURAL PLAST, V2017, DOI 10.1155/2017/6871089
   Lu JB, 2011, INT CONF ACOUST SPEE, P985
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Muller K, 2014, ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, JCT3v, VG1100, P1
   Muller Karsten, 2014, P 7 M JCT
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Qiao YG, 2019, IEEE T MULTIMEDIA, V21, P1, DOI 10.1109/TMM.2018.2845699
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Rochette Guillaume, 2019, ARXIV190906119
   Shao F, 2012, IEEE T MULTIMEDIA, V14, P157, DOI 10.1109/TMM.2011.2169045
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Tanimoto M., 2008, M15836 ISO IEC
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang YK, 2014, VISUAL COMPUT, V30, P1157, DOI 10.1007/s00371-013-0896-z
   Wang Y, 2020, IEEE ACCESS, V8, P52232, DOI 10.1109/ACCESS.2020.2981161
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Xu XY, 2014, SIGNAL PROCESS-IMAGE, V29, P316, DOI 10.1016/j.image.2013.12.005
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yang YW, 2018, APPL BIONICS BIOMECH, V2018, DOI 10.1155/2018/7854052
   Zhao LJ, 2017, SIGNAL PROCESS-IMAGE, V54, P11, DOI 10.1016/j.image.2017.02.009
   Zhao LJ, 2015, ELECTRON LETT, V51, P224, DOI 10.1049/el.2014.3912
NR 48
TC 0
Z9 0
U1 1
U2 22
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2021
VL 16
IS 4
AR 127
DI 10.1145/3408293
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QB4CR
UT WOS:000614088800011
DA 2024-07-18
ER

PT J
AU Zhu, L
   Jiang, XR
   Li, JN
   Hao, YH
   Tian, YH
AF Zhu, Lin
   Jiang, Xiurong
   Li, Jianing
   Hao, Yuanhong
   Tian, Yonghong
TI Motion-Aware Structured Matrix Factorization for Foreground Detection in
   Complex Scenes
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Matrix factorization; foreground detection; I-2,I-q regularization;
   structured sparse-inducing norm
ID BACKGROUND SUBTRACTION; LOW-RANK; SEGMENTATION; GRADIENT
AB Foreground detection is one of the key steps in computer vision applications. Many foreground and background models have been proposed and achieved promising performance in static scenes. However, due to challenges such as dynamic background, irregular movement, and noise, most algorithms degrade sharply in complex scenes. To address the problem, we propose a motion-aware structured matrix factorization approach (MSMF), which integrates the structural and spa tiotemporal motion information into a unified sparselow-rank matrix factorization framework. Technologically, it has three main contributions: First, a variant of structured sparsity-inducing norm is proposed to constrain both structure and sparsity of foreground. The model is robust to the statistical variability of the underlying foreground pixels in complex scenes. Second, to capture the ambiguous pixels, a spatiotemporal cube-based motion trajectory is extracted for assisting matrix factorization. Finally, to solve the optimization problem of structured matrix factorization, we develop an augmented Lagrange multiplier method with the alternating direction strategy and Douglas-Rachford monotone operator splitting algorithm. Experiments demonstrate that the proposed approach achieves impressive performance in separating irregular moving foreground while suppressing the dynamic background and the noise, and outperforms some state-of-the-art algorithms.
C1 [Zhu, Lin; Li, Jianing; Tian, Yonghong] Peking Univ, 5 Yiheyuan Rd, Beijing, Peoples R China.
   [Jiang, Xiurong] Beijing Univ Posts & Telecommun, 10 Xitucheng Rd, Beijing, Peoples R China.
   [Hao, Yuanhong] North Automat Control Technol Inst, 351 Tiyu Rd, Taiyuan, Peoples R China.
C3 Peking University; Beijing University of Posts & Telecommunications
RP Tian, YH (corresponding author), Peking Univ, 5 Yiheyuan Rd, Beijing, Peoples R China.
EM linzhu@pku.edu.cn; jiangxiurong@bupt.edu.cn; lijianing@pku.edu.cn;
   facerecognition@163.com; yhtian@pku.edu.cn
RI zhu, lin/AEC-6241-2022
OI zhu, lin/0000-0001-6487-0441
FU National Natural Science Foundation of China [61825101, U1611461]
FX This work is partially supported by grants from the National Natural
   Science Foundation of China under contract No. 61825101 and No.
   U1611461.
CR [Anonymous], 2014, ECCV
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao WF, 2013, J VIS COMMUN IMAGE R, V24, P31, DOI 10.1016/j.jvcir.2012.10.006
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Combettes PL, 2007, IEEE J-STSP, V1, P564, DOI 10.1109/JSTSP.2007.910264
   Ding XH, 2011, IEEE T IMAGE PROCESS, V20, P3419, DOI 10.1109/TIP.2011.2156801
   Ebadi SE, 2018, IEEE T PATTERN ANAL, V40, P2273, DOI 10.1109/TPAMI.2017.2745573
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131
   Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Javed S, 2019, IEEE T IMAGE PROCESS, V28, P1007, DOI 10.1109/TIP.2018.2874289
   Javed S, 2018, IEEE T CIRC SYST VID, V28, P1315, DOI 10.1109/TCSVT.2016.2632302
   Javed S, 2017, IEEE T IMAGE PROCESS, V26, P5840, DOI 10.1109/TIP.2017.2746268
   Javed S, 2016, INT C PATT RECOG, P120, DOI 10.1109/ICPR.2016.7899619
   Jenatton R, 2011, J MACH LEARN RES, V12, P2777
   Jiang SQ, 2018, IEEE T CIRC SYST VID, V28, P2105, DOI 10.1109/TCSVT.2017.2711659
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Li CJ, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1236471.1236475
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Liu J, 2010, INT CONF COMP SCI, P145, DOI 10.1109/ICCSIT.2010.5563638
   Liu J, 2009, SIMUL: 2009 FIRST INTERNATIONAL CONFERENCE ON ADVANCES IN SYSTEM SIMULATION, P1, DOI 10.1109/SIMUL.2009.24
   Liu X., 2019, IS T INT S ELECT IMA, P2691
   Liu X, 2018, IEEE T CIRC SYST VID, V28, P1737, DOI 10.1109/TCSVT.2017.2697972
   Luo H, 2014, PROC INT CONF ANTI, P55
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Matsuyama T., 1999, P AS C COMP VIS, P662
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mondejar-Guerra V., 2019, BRIT MACH VIS C 2019, P2691
   Oreifej O, 2013, IEEE T PATTERN ANAL, V35, P450, DOI 10.1109/TPAMI.2012.97
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Shakeri M, 2016, COMPUT VIS IMAGE UND, V146, P27, DOI 10.1016/j.cviu.2016.02.009
   Shi W, 2017, ENVIRON SCI TECH LET, V4, P1, DOI 10.1021/acs.estlett.6b00458
   St-Charles PL, 2016, IEEE T IMAGE PROCESS, V25, P4768, DOI 10.1109/TIP.2016.2598691
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tang G., 2011, P ANN C INF SCI SYST, P1, DOI DOI 10.1109/CISS.2011.5766144
   Vacavant Antoine, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P291, DOI 10.1007/978-3-642-37410-4_25
   Varghese A., 2017, IPSJ Transactions on Computer Vision and Applications, V9, P1, DOI DOI 10.1186/S41074-017-0036-1
   Wang NY, 2012, LECT NOTES COMPUT SC, V7578, P126, DOI 10.1007/978-3-642-33786-4_10
   Wang SL, 2015, METALL MATER TRANS E, V2, P250, DOI 10.1007/s40553-015-0062-9
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Xin B, 2015, PROC CVPR IEEE, P4676, DOI 10.1109/CVPR.2015.7299099
   Xu J, 2013, IEEE I CONF COMP VIS, P3376, DOI 10.1109/ICCV.2013.419
   Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412
   Ye XC, 2015, IEEE T CIRC SYST VID, V25, P1721, DOI 10.1109/TCSVT.2015.2392491
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zheng AH, 2019, NEUROCOMPUTING, V328, P113, DOI 10.1016/j.neucom.2018.02.101
   Zhou T., P 28 INT C MACH LEAR
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zhu L, 2018, ADV COND MATTER PHYS, V2018, DOI [10.1109/EMBC.2018.8512736, 10.1155/2018/3787843]
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 62
TC 0
Z9 0
U1 0
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2021
VL 16
IS 4
AR 123
DI 10.1145/3407188
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QB4CR
UT WOS:000614088800007
DA 2024-07-18
ER

PT J
AU Meng, QL
   Zhu, HY
   Zhang, WG
   Piao, XF
   Zhang, AJ
AF Meng, Quanling
   Zhu, Heyan
   Zhang, Weigang
   Piao, Xuefeng
   Zhang, Aijie
TI Action Recognition Using Form and Motion Modalities
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Action recognition; hierarchical sparse coding; form and motion; Fisher
   vector
ID IMAGE CLASSIFICATION; TRACKING; RGB; REPRESENTATIONS; POINTS
AB Action recognition has attracted increasing interest in computer vision due to its potential applications in many vision systems. One of the main challenges in action recognition is to extract powerful features from videos. Most existing approaches exploit either hand-crafted techniques or learning-based methods to extract features from videos. However, these methods mainly focus on extracting the dynamic motion features, which ignore the static form features. Therefore, these methods cannot fully capture the underlying information in videos accurately. In this article, we propose a novel feature representation method for action recognition, which exploits hierarchical sparse coding to learn the underlying features from videos. The learned features characterize the form and motion simultaneously and therefore provide more accurate and complete feature representation. The learned form and motion features are considered as two modalities, which are used to represent both the static and motion features. These modalities are further encoded into a global representation via a pairwise dictionary learning and then fed to an SVM classifier for action classification. Experimental results on several challenging datasets validate that the proposed method is superior to several state-of-the-art methods.
C1 [Meng, Quanling; Zhang, Weigang; Piao, Xuefeng] Harbin Inst Technol, 2 Wenhuaxi Rd, Weihai 264209, Shandong, Peoples R China.
   [Zhu, Heyan] Yantai Univ, 30 Qinquan Rd, Yantai 264005, Shandong, Peoples R China.
   [Zhang, Aijie] Qingdao Univ Sci & Technol, 99 Songling Rd, Qingdao, Shandong, Peoples R China.
C3 Harbin Institute of Technology; Yantai University; Qingdao University of
   Science & Technology
RP Piao, XF (corresponding author), Harbin Inst Technol, 2 Wenhuaxi Rd, Weihai 264209, Shandong, Peoples R China.
EM mengquanling@gmail.com; 1980zhuheyan@163.com; wgzhang@hit.edu.cn;
   hbpark@hit.edu.cn; Ana_jieaizhang@163.com
RI Zhang, Weigang/GZA-9095-2022
OI Zhang, Weigang/0000-0003-0042-7074; Piao, Xuefeng/0000-0001-5528-1848
FU Shandong Provincial Natural Science Foundation [ZR2017MF001]; Key R&D
   Program of Yantai City [2016YT06000609]; Scientific Research Innovation
   Foundation of HIT (Weihai)
FX This work was supported in part by Shandong Provincial Natural Science
   Foundation (ZR2017MF001), the Key R&D Program of Yantai City
   (2016YT06000609), and the Scientific Research Innovation Foundation of
   HIT (Weihai).
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2004, Int. J. Comput. Vis., DOI [DOI 10.1023/B:VISI.0000029664.99615.94, 10.1023/B:VISI.0000029664.99615.94]
   [Anonymous], 2010, P INT C MACH LEARN
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Burgos-Artizzu XP, 2012, PROC CVPR IEEE, P1322, DOI 10.1109/CVPR.2012.6247817
   Cadieu CF, 2012, NEURAL COMPUT, V24, P827, DOI 10.1162/NECO_a_00247
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Duta IC, 2017, PROC CVPR IEEE, P3205, DOI 10.1109/CVPR.2017.341
   Gao RQ, 2018, PROC CVPR IEEE, P9155, DOI 10.1109/CVPR.2018.00954
   Garcia Nuno C., 2018, P 15 EUR C COMP VIS
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang F., 2015, J MACHINE LEARNING R, V16, P2
   Jiang ZH, 2019, IEEE T IMAGE PROCESS, V28, P1133, DOI 10.1109/TIP.2018.2875335
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Lan XY, 2019, IEEE T IND ELECTRON, V66, P9887, DOI 10.1109/TIE.2019.2898618
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Liang HL, 2017, ASIA CONTROL CONF AS, P2340, DOI 10.1109/ASCC.2017.8287540
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu F, 2016, IEEE T IMAGE PROCESS, V25, P949, DOI 10.1109/TIP.2015.2512107
   Liu HP, 2015, NEUROCOMPUTING, V149, P79, DOI 10.1016/j.neucom.2013.12.061
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Liu L, 2014, PATTERN RECOGN, V47, P3819, DOI 10.1016/j.patcog.2014.07.006
   Marzalek M., 2009, P INT C PATT REC, P2929
   Miao J, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2490551
   Multimodal learning with deep Boltzmann machines, 2011, J MACHINE LEARNING R
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Ni B., 2011, P INT C COMP VIS WOR
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Qi YW, 2020, IEEE T SYST MAN CY-S, V50, P1442, DOI 10.1109/TSMC.2018.2801284
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Seo HJ, 2009, IEEE I CONF COMP VIS, P1965, DOI 10.1109/ICCV.2009.5459433
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Song Y, 2015, IEEE SIGNAL PROC LET, V22, P426, DOI 10.1109/LSP.2014.2361901
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang LZ, 2015, PROC CVPR IEEE, P4942, DOI 10.1109/CVPR.2015.7299128
   Wilf P, 2016, P NATL ACAD SCI USA, V113, P3305, DOI 10.1073/pnas.1524473113
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Xie DF, 2017, APPL COMPUT INTELL S, V2017, DOI 10.1155/2017/1320780
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Yu J, 2012, PATTERN RECOGN LETT, V33, P1196, DOI 10.1016/j.patrec.2012.02.002
   Yuan CF, 2013, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2013.99
   Zhang L, 2019, PROC SPIE, V10954, DOI 10.1117/12.2513090
   Zhang Lei, 2016, P INT C IM PROC
   Zhang Lei, 2019, MED IMAGING 2019 COM, V10950
   Zhang L, 2018, NANO-MICRO LETT, V10, DOI 10.1007/s40820-017-0178-9
   Zhang Shao-Yan, 2013, ISRN Radiol, V2013, P874570, DOI 10.5402/2013/874570
   Zhang SP, 2018, IEEE T INTELL TRANSP, V19, P187, DOI 10.1109/TITS.2017.2766093
   Zhang SP, 2017, IEEE T CIRC SYST VID, V27, P421, DOI 10.1109/TCSVT.2016.2539860
   Zhang SP, 2015, AAAI CONF ARTIF INTE, P3165
   Zhang SP, 2015, IEEE T CIRC SYST VID, V25, P1749, DOI 10.1109/TCSVT.2015.2406194
   Zhang SP, 2015, SIGNAL PROCESS, V110, P132, DOI 10.1016/j.sigpro.2014.08.027
   Zhang SP, 2014, INFORM SCIENCES, V281, P635, DOI 10.1016/j.ins.2013.12.052
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   ZHANG SP, 2017, IEEE T NEURAL NETWOR, V29, P100, DOI DOI 10.21147/J.ISSN.1000-9604.2017.02.02
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
   Zhen XT, 2014, INFORM SCIENCES, V281, P295, DOI 10.1016/j.ins.2014.05.021
   Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou TY, 2013, IEEE T IMAGE PROCESS, V22, P244, DOI 10.1109/TIP.2012.2202678
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 78
TC 11
Z9 11
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2020
VL 16
IS 1
SU S
SI SI
AR 22
DI 10.1145/3350840
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1EL
UT WOS:000583710300004
DA 2024-07-18
ER

PT J
AU Bentaleb, A
   Yadav, PK
   Ooi, WT
   Zimmermann, R
AF Bentaleb, Abdelhak
   Yadav, Praveen Kumar
   Ooi, Wei Tsang
   Zimmermann, Roger
TI DQ-DASH: A Queuing Theory Approach to Distributed Adaptive Video
   Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multiple server; multi-source; queuing theory; DASH; QoE; fairness; ABR
ID RATE ADAPTATION
AB The significant popularity of HTTP adaptive video streaming (HAS), such as Dynamic Adaptive Streaming over HTTP (DASH), over the Internet has led to a stark increase in user expectations in terms of video quality and delivery robustness. This situation creates new challenges for content providers who must satisfy the Quality-of-Experience (QoE) requirements and demands of their customers over a best-effort network infrastructure. Unlike traditional single server DASH, we developed a Distributed Queuing theory bitrate adaptation algorithm for DASH (DQ-DASH) that leverages the availability of multiple servers by downloading segments in parallel. DQ-DASH uses a (M/D)-D-x/1/K queuing theory based bitrate selection in conjunction with the request scheduler to download subsequent segments of the same quality through parallel requests to reduce quality fluctuations. DQ-DASH facilitates the aggregation of bandwidth from different servers and increases fault-tolerance and robustness through path diversity. The resulting resilience prevents clients from suffering QoE degradations when some of the servers become congested. DQ-DASH also helps to fully utilize the aggregate bandwidth from the servers and download the imminently required segment from the server with the highest throughput. We have also analyzed the effect of buffer capacity and segment duration for multi-source video streaming.
C1 [Bentaleb, Abdelhak; Yadav, Praveen Kumar; Ooi, Wei Tsang; Zimmermann, Roger] Natl Univ Singapore, Sch Comp, 21 Lower Kent Ridge Rd, Singapore 119077, Singapore.
C3 National University of Singapore
RP Bentaleb, A (corresponding author), Natl Univ Singapore, Sch Comp, 21 Lower Kent Ridge Rd, Singapore 119077, Singapore.
EM bentaleb@comp.nus.edu.sg; praveen@comp.nus.edu.sg;
   ooiwt@comp.nus.edu.sg; rogerz@comp.nus.edu.sg
RI Zimmermann, Roger/D-7944-2015; Bentaleb, Abdelhak/ABI-3704-2020; Ooi,
   Wei Tsang/HLW-5142-2023
OI Zimmermann, Roger/0000-0002-7410-2590; Ooi, Wei
   Tsang/0000-0001-8994-1736; Bentaleb, Abdelhak/0000-0002-5382-6530
FU Singapore Ministry of Education Academic Research Fund Tier 2 under
   MOE's official grant [MOE2018-T2-1-103]; National Research Foundation,
   Prime Minister's Office, Singapore under its IRC@SG Funding Initiative;
   NVIDIA Corporation
FX This research is supported by Singapore Ministry of Education Academic
   Research Fund Tier 2 under MOE's official grant number MOE2018-T2-1-103
   and in part of NExT++ research, supported by the National Research
   Foundation, Prime Minister's Office, Singapore under its IRC@SG Funding
   Initiative. We gratefully acknowledge the support of NVIDIA Corporation
   with the donation of a Titan Xp GPU used for this research.
CR Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   [Anonymous], 2017, DASH REFERENCE PLAYE
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], 2006, WWW WORKSH IPTV SERV
   [Anonymous], 2014, GUID IMPL DASH AVC 2
   Bentaleb A, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P13, DOI 10.1145/3204949.3204961
   Bentaleb A, 2019, IEEE COMMUN SURV TUT, V21, P562, DOI 10.1109/COMST.2018.2862938
   Bentaleb A, 2017, IEEE T MULTIMEDIA, V19, P2136, DOI 10.1109/TMM.2017.2733344
   Bentaleb A, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1296, DOI 10.1145/2964284.2964332
   Brun O, 2000, J APPL PROBAB, V37, P1092, DOI 10.1239/jap/1014843086
   Bruneau-Queyreix J, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3183515
   Bruneau-Queyreix J, 2017, CONSUM COMM NETWORK, P580, DOI 10.1109/CCNC.2017.7983175
   Cao J, 2003, LECT NOTES STAT, V171, P83
   Cao JY, 2018, STAT PROBABIL LETT, V133, P42, DOI 10.1016/j.spl.2017.09.012
   Corbillon Xavier, 2016, ACM MMSYS
   Dai H, 2011, ACTA HORTIC, P169, DOI 10.17660/ActaHortic.2011.913.20
   Dudin AN, 2016, TELECOMMUN SYST, V61, P403, DOI 10.1007/s11235-014-9946-8
   Evensen K, 2012, SIGNAL PROCESS-IMAGE, V27, P312, DOI 10.1016/j.image.2011.10.007
   Evensen K, 2010, NOSSDAV 2010: PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P21
   Famaey J, 2013, LECT NOTES COMPUT SC, V7943, P13, DOI 10.1007/978-3-642-38998-6_2
   Ganjam Aditya., 2015, USENIX NSDI
   Han B, 2016, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT'16), P129, DOI 10.1145/2999572.2999606
   Huang TY, 2014, ACM SIGCOMM COMP COM, V44, P187, DOI 10.1145/2740070.2626296
   ISO/IEC, 2014, Rep. 23009-1. ISO/IEC JTCI/SC29/WG11
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Johansen D., 2009, P 17 ACM INT C MULTI, P989
   Juhoon Kim, 2014, ACM SIGMETRICS Performance Evaluation Review, V42, P583
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Kaspar D, 2010, CONSUM COMM NETWORK, P47
   Kua J, 2017, IEEE COMMUN SURV TUT, V19, P1842, DOI 10.1109/COMST.2017.2685630
   Kuschnig R, 2010, CONSUM COMM NETWORK, P200
   Lederer S., 2012, P 3 MULT SYST C, P89
   Lederer S., 2013, Proceedings of the 4th ACM Multimedia Systems Conference (MMSys '13), P131
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Liu CH, 2012, SIGNAL PROCESS-IMAGE, V27, P288, DOI 10.1016/j.image.2011.10.001
   Liu HH, 2012, ACM SIGCOMM COMP COM, V42, P371, DOI 10.1145/2377677.2377753
   Liu Y., 2007, MULTIMEDIA '07: Proceedings of the 15th international conference on Multimedia, P127
   Liu ZH, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL II, P7, DOI 10.1109/ISECS.2009.150
   Mao HZ, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P197, DOI 10.1145/3098822.3098843
   Mukerjee MK, 2017, CONEXT'17: PROCEEDINGS OF THE 2017 THE 13TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES, P68, DOI 10.1145/3143361.3143366
   Mukerjee MK, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P311, DOI 10.1145/2785956.2787475
   Nafaa M, 2009, 2009 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2009) VOLS 1 AND 2, P291, DOI 10.1109/INM.2009.5188824
   Nguyen T. P. Q., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4673, P186, DOI 10.1117/12.449979
   NUS, 2018, NAT CYB LAB NCL TEST
   Petrangeli S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818361
   Professor Vector, 2017, MATH STACK EXCHANGE
   Pu W, 2011, GLOB TELECOMM CONF
   Reese W., 2008, Linux J, V2008, P2, DOI 10.5555/1412202.1412204
   Sandvine, 2016, VID QUAL EXP REQ CON
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Sun Y, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P272, DOI 10.1145/2934872.2934898
   Thomas Emmanuel, 2017, Motion Imaging Journal, V126, P22, DOI 10.5594/JMI.2016.2632338
   VNI Cisco, 2017, CISC VIS NETW IND FO
   Wamser F, 2017, PROCEEDINGS OF THE 2017 WORKSHOP ON QOE-BASED ANALYSIS AND MANAGEMENT OF DATA COMMUNICATION NETWORKS (INTERNET QOE 17), P19, DOI 10.1145/3098603.3098607
   Wang B, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1556134.1556142
   YADAV PK, 2017, ACM MM, P1130, DOI DOI 10.1145/3123266.3123390
   Yin XQ, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P325, DOI 10.1145/2785956.2787486
   Yu L, 2018, IEEE T MULTIMEDIA, V20, P15, DOI 10.1109/TMM.2017.2726900
   Yuan H, 2018, IEEE T MOBILE COMPUT, V17, P2334, DOI 10.1109/TMC.2018.2800749
   Yuan H, 2018, IEEE T MULTIMEDIA, V20, P183, DOI 10.1109/TMM.2017.2724850
   Yuan H, 2017, IEEE T BROADCAST, V63, P338, DOI 10.1109/TBC.2016.2630267
   Zhang DL, 2017, MINERAL MET MAT SER, P3, DOI 10.1007/978-3-319-52392-7_1
   Zhang X, 2019, IEEE T CIRC SYST VID, V29, P1130, DOI 10.1109/TCSVT.2018.2819804
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   Zhou C, 2014, IEEE T CIRC SYST VID, V24, P681, DOI 10.1109/TCSVT.2013.2290580
   Zhou YP, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P226, DOI 10.1109/ICNP.2007.4375853
NR 67
TC 9
Z9 9
U1 2
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2020
VL 16
IS 1
AR 4
DI 10.1145/3371040
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1FD
UT WOS:000583712100003
DA 2024-07-18
ER

PT J
AU Zheng, YP
   Li, XL
   Lu, XQ
AF Zheng, Yunpeng
   Li, Xuelong
   Lu, Xiaoqiang
TI Unsupervised Learning of Human Action Categories in Still Images with
   Deep Representations
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Action categorization; unsupervised learning; deep representations
ID ACTION RECOGNITION; RANDOM FORESTS; FEATURES
AB In this article, we propose a novel method for unsupervised learning of human action categories in still images. In contrast to previous methods, the proposed method explores distinctive information of actions directly from unlabeled image databases, attempting to learn discriminative deep representations in an unsupervised manner to distinguish different actions. In the proposed method, action image collections can be used without manual annotations. Specifically, (i) to deal with the problem that unsupervised discriminative deep representations are difficult to learn, the proposed method builds a training dataset with surrogate labels from the unlabeled dataset, then learns discriminative representations by alternately updating convolutional neural network (CNN) parameters and the surrogate training dataset in an iterative manner; (ii) to explore the discriminatory information among different action categories, training batches for updating the CNN parameters are built with triplet groups and the triplet loss function is introduced to update the CNN parameters; and (iii) to learn more discriminative deep representations, a Random Forest classifier is adopted to update the surrogate training dataset, and more beneficial triplet groups then can be built with the updated surrogate training dataset. Extensive experiments on four benchmark datasets demonstrate the effectiveness of the proposed method.
C1 [Zheng, Yunpeng; Lu, Xiaoqiang] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol CAS, Xian 710119, Shaanxi, Peoples R China.
   [Zheng, Yunpeng] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Li, Xuelong] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS; Northwestern Polytechnical University;
   Northwestern Polytechnical University
RP Lu, XQ (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol CAS, Xian 710119, Shaanxi, Peoples R China.
EM zhengyunpeng2014@opt.cn; xuelong_li@nwpu.edu.cn; luxq666666@gmail.com
RI Li, Xuelong/ABF-3381-2020
OI Lu, Xiaoqiang/0000-0002-7037-5188
FU National Natural Science Foundation of China [61772510, 61702498]; Key
   Research Program of Frontier Sciences, CAS [QYZDY-SSW-JSC044]; Young
   Top-notch Talent Program of Chinese Academy of Sciences
   [QYZDB-SSW-JSC015]; National Key R&D Program of China [2017YFB0502900];
   CAS "Light of West China" Program [XAB2017B15]
FX This work was supported in part by the National Natural Science
   Foundation of China under grant nos. 61772510 and 61702498, in part by
   the Key Research Program of Frontier Sciences, CAS under grant no.
   QYZDY-SSW-JSC044, in part by the Young Top-notch Talent Program of
   Chinese Academy of Sciences under grant no. QYZDB-SSW-JSC015, in part by
   the National Key R&D Program of China under grant no. 2017YFB0502900, in
   part by the CAS "Light of West China" Program under grant no.
   XAB2017B15.
CR Ahmad K, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3199668
   [Anonymous], 2019, IEEE T PATTERN ANAL
   [Anonymous], 2011, P EUR S ART NEUR NET
   [Anonymous], ACM T MULTIMEDIA COM
   [Anonymous], 2010, P BRIT MACH VIS C 20
   [Anonymous], 2004, Workshop on Generative Model Based Vision
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, 3 INT C LEARN REPR I
   [Anonymous], 2006, Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition
   [Anonymous], ACM T MULTIM COMPUT
   [Anonymous], 2016, P ADV NEUR INF PROC
   [Anonymous], 2013, P ACM INT C MULT RET
   Bautista MA, 2017, PROC CVPR IEEE, P1923, DOI 10.1109/CVPR.2017.208
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Breiman L., 2001, Mach. Learn., V45, P5
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chenxia Wu, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P4362, DOI 10.1109/CVPR.2015.7299065
   Delaitre V., 2011, P INT C NEUR INF PRO, P1503
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Dosovitskiy A, 2014, ADV NEUR IN, V27
   Fang Y, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON COMPUTING AND ARTIFICIAL INTELLIGENCE (ICCAI 2018), P52, DOI 10.1145/3194452.3194470
   Fernando B, 2017, IEEE COMPUT SOC CONF, P1604, DOI 10.1109/CVPRW.2017.205
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2015.284
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Huang M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177757
   Ikizler N., 2008, ICPR, P1, DOI DOI 10.1109/ICPR.2008.4761663
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang SH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152114
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Li PJ, 2011, LECT NOTES COMPUT SC, V6897, P302, DOI 10.1007/978-3-642-23535-1_27
   Li SY, 2018, ACM T EMBED COMPUT S, V17, DOI 10.1145/3070721
   Li X, 2018, IEEE WINT CONF APPL, P362, DOI 10.1109/WACV.2018.00046
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma F, 2017, PR MACH LEARN RES, V70
   Ma SG, 2017, PATTERN RECOGN, V68, P334, DOI 10.1016/j.patcog.2017.01.027
   Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3177, DOI 10.1109/CVPR.2011.5995631
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI
   Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158
   Qi L, 2018, ROUTL ADV TRANSL INT, P1, DOI 10.4324/9781351060837
   Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621
   Razavi N, 2011, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2011.5995441
   Ristin M, 2016, IEEE T PATTERN ANAL, V38, P490, DOI 10.1109/TPAMI.2015.2459678
   Sener F, 2012, LECT NOTES COMPUT SC, V7585, P263, DOI 10.1007/978-3-642-33885-4_27
   Sharma G, 2017, IEEE T PATTERN ANAL, V39, P87, DOI 10.1109/TPAMI.2016.2537325
   Soomro K., 2012, ARXIV12120402CS
   Soomro K, 2017, IEEE I CONF COMP VIS, P696, DOI 10.1109/ICCV.2017.82
   Strehl A., 2002, J. Machine Learning Res, V3, P583
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang PS, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152127
   Wang XL, 2017, IEEE I CONF COMP VIS, P1338, DOI 10.1109/ICCV.2017.149
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Yang JW, 2016, PROC CVPR IEEE, P5147, DOI 10.1109/CVPR.2016.556
   Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Yatskar M, 2016, PROC CVPR IEEE, P5534, DOI 10.1109/CVPR.2016.597
   Yin Zheng, 2012, 2012 19th IEEE International Conference on Image Processing (ICIP 2012), P785, DOI 10.1109/ICIP.2012.6466977
   Yuan Y, 2018, NEUROCOMPUTING, V315, P221, DOI 10.1016/j.neucom.2018.06.071
   Yuan Y, 2016, IMAGE VISION COMPUT, V55, P77, DOI 10.1016/j.imavis.2016.04.001
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P5479, DOI 10.1109/TIP.2016.2605305
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
   Zhao ZC, 2016, PATTERN RECOGN LETT, V84, P134, DOI 10.1016/j.patrec.2016.08.020
   Zhu Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629483
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
NR 74
TC 2
Z9 2
U1 1
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2019
VL 15
IS 4
AR 112
DI 10.1145/3362161
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KJ8DH
UT WOS:000512285800012
DA 2024-07-18
ER

PT J
AU Ben Yahia, M
   Le Louedec, Y
   Simon, G
   Nuaymi, L
   Corbillon, X
AF Ben Yahia, Mariem
   Le Louedec, Yannick
   Simon, Gwendal
   Nuaymi, Loutfi
   Corbillon, Xavier
TI HTTP/2-based Frame Discarding for Low-Latency Adaptive Video Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Video delivery; low latency; DASH; HTTP/2; wireless networks; video
   frame discarding
ID QUALITY
AB In this article, we propose video delivery schemes insuring around 1s delivery latency with Dynamic Adaptive Streaming over HTTP (DASH), which is a standard version of HTTP Live Streaming (FILS), so as to benefit from the video representation switching between successive video segments. We also propose HTTP/2-based algorithms to apply video frame discarding policies inside a video segment when a selected DASH representation does not match with the available network resources. The current solutions with small buffer suffer from rebuffering events. Rebuffering not only impacts the Quality of Experience (QoE) but also increases the delivery delay between the displayed and the original video streams. In this work, we completely eliminate rebuffering events by developing optimal and practical video frame discarding algorithms to meet the is latency constraint. In all our algorithms, we request the video frames individually through HTTP/2 multiple streams, and we selectively drop the least meaningful video frames thanks to HTTP/2 stream resetting feature. Our simulations show that the proposed algorithms eliminate rebuffering while insuring an acceptable video quality with at least a Peak Signal to Noise Ratio (PSNR) of 35dB compared to 25dB of the basic First In First Out (FIFO) algorithm. We also quantify and qualify the resulting temporal distortion of the video segments per algorithm. An important number of missing video frames results in a temporal fluidity break known as video jitter. The displayed video looks like a series of snapshots. We show that both the optimal Integer Linear Program (ILP) and practical algorithms decrease the frequency and duration of the jitters. For example, practical algorithms reduce the number of crashed displayed videos (presenting one jitter longer than 1,350ms) with 22% compared to the basic FIFO algorithm. We also show that requesting video frames separately with HTTP/2 slightly increases the overhead from 4.34% to 5.76%.
C1 [Ben Yahia, Mariem; Le Louedec, Yannick] Orange Labs, Lannion, France.
   [Simon, Gwendal; Nuaymi, Loutfi; Corbillon, Xavier] IMT Atlantique, Rennes, France.
C3 Orange SA; IMT - Institut Mines-Telecom; IMT Atlantique
RP Ben Yahia, M (corresponding author), Orange Labs, Lannion, France.
EM mariem.benyahia@orange.com; yannick.lelouedec@orange.com;
   gwendal.simon@imt-atlantique.fr; loutfi.nuaymi@imt-atlantique.fr;
   xavier.corbillon@imt-atlantique.fr
RI Simon, Gwendal/Y-6950-2019
OI Simon, Gwendal/0000-0002-7282-918X
CR [Anonymous], 2016, CORR
   [Anonymous], VIEW EXP REP 2015
   [Anonymous], 2015, RFC 7540
   Ben Yahia M, 2017, IEEE CONF COMPUT, P677, DOI 10.1109/INFCOMW.2017.8116458
   Bouzakaria N, 2015, IEEE INT WORKSH MULT
   Bouzakaria N, 2014, 5TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS, IISA 2014, P92, DOI 10.1109/IISA.2014.6878732
   Campbell Pete, 2016, TECHNICAL REPORT
   Chakareski J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P1001
   Chang YL, 2012, IEEE T IMAGE PROCESS, V21, P3353, DOI 10.1109/TIP.2012.2191567
   Cherif W., 2015, P 25 ACM WORKSHOP NE, P25
   Cisco, 2017, White Paper
   Corbillon X, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P65, DOI 10.1145/2910017.2910594
   Corbillon Xavier, 2016, P 7 INT C MULT SYST, P1
   Darabkh KA, 2015, INT J NETW MANAG, V25, P181, DOI 10.1002/nem.1888
   Darabkh KA, 2014, WIRELESS PERS COMMUN, V79, P293, DOI 10.1007/s11277-014-1857-1
   Dobrian F, 2013, COMMUN ACM, V56, P91, DOI 10.1145/2428556.2428577
   Duan XJ, 2016, J ORTHOP SURG RES, V11, DOI 10.1186/s13018-016-0490-y
   Gangadharan D, 2011, IEEE INT CONF EMBED, P319, DOI 10.1109/RTCSA.2011.49
   Houzé P, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511550
   Huysegems Rafael, 2015, P ANN ACM C MULT C M
   ISO, 2015, 230082 ISOIEC
   ISO, 2012, 1449610 ISOIEC
   ISO, 2012, 23009 ISOIEC
   Kalampogia A, 2018, IEEE T MULTIMEDIA, V20, P171, DOI 10.1109/TMM.2017.2713642
   Karagkioules Theodoros, 2017, P 27 WORKSH NETW OP, P1, DOI [10.1145/3083165.3083170, DOI 10.1145/3083165.3083170]
   Krishnan SS, 2013, IEEE ACM T NETWORK, V21, P2001, DOI 10.1109/TNET.2013.2281542
   Kua J, 2017, IEEE COMMUN SURV TUT, V19, P1842, DOI 10.1109/COMST.2017.2685630
   Feuvre J, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P751
   Liu Ke, 2015, P ACM INT C COMP FRO
   Ma LV, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19090477
   Mehdian S, 2014, 2014 IEEE 22ND INTERNATIONAL SYMPOSIUM OF QUALITY OF SERVICE (IWQOS), P168, DOI 10.1109/IWQoS.2014.6914317
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Mueller C, 2013, IEEE INT CON MULTI
   Pastrana-Vidal Ricardo, 2006, P WORKSH VID PROC QU
   Quan Huynh-thu, 2006, P 2 INT WORKSH VID P
   Samba Alassane, 2017, 2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM), P624, DOI 10.23919/INM.2017.7987345
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Spiteri Kevin, 2018, P ACM MULT SYST C MM
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   van Kester S., 2011, P SOC PHOTO-OPT INS
   Wei S, 2015, IEEE INT WORKSH MULT
   Weil Nicolas, 2016, 23009 STREAM MED
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiao Mengbai, 2016, P 26 INT WORKSH NOSS
   Xie BC, 2011, IEEE INT SYMP ELEC, P16, DOI 10.1109/ISEMC.2011.6038277
NR 45
TC 19
Z9 19
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2019
VL 15
IS 1
AR 18
DI 10.1145/3280854
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HM9JB
UT WOS:000459798800002
DA 2024-07-18
ER

PT J
AU Irondi, I
   Wang, Q
   Grecos, C
   Calero, JMA
   Casaseca-De-La-Higuera, P
AF Irondi, Iheanyi
   Wang, Qi
   Grecos, Christos
   Calero, Jose M. Alcaraz
   Casaseca-De-La-Higuera, Pablo
TI Efficient QoE-Aware Scheme for Video Quality Switching Operations in
   Dynamic Adaptive Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE QoE-aware; DASH; quality scaling dimension; adaptation algorithm
AB Dynamic Adaptive Streaming over HTTP (DASH) is a popular over-the-top video content distribution technique that adapts the streaming session according to the user's network condition typically in terms of down-link bandwidth. This video quality adaptation can be achieved by scaling the frame quality, spatial resolution or frame rate. Despite the flexibility on the video quality scaling methods, each of these quality scaling dimensions has varying effects on the Quality of Experience (QoE) for end users. Furthermore, in video streaming, the changes in motion over time along with the scaling method employed have an influence on QoE, hence the need to carefully tailor scaling methods to suit streaming applications and content type. In this work, we investigate an intelligent DASH approach for the latest video coding standard H.265 and propose a heuristic QoE-aware cost-efficient adaptation scheme that does not switch unnecessarily to the highest quality level but rather stays temporarily at an intermediate quality level in certain streaming scenarios. Such an approach achieves a comparable and consistent level of quality under impaired network conditions as commonly found in Internet and mobile networks while reducing bandwidth requirements and quality switching overhead. The rationale is based on our empirical experiments, which show that an increase in bitrate does not necessarily mean noticeable improvement in QoE. Furthermore, our work demonstrates that the Signal-to-Noise Ratio (SNR) and the spatial resolution scalability types are the best fit for our proposed algorithm. Finally, we demonstrate an innovative interaction between quality scaling methods and the polarity of switching operations. The proposed QoE-aware scheme is implemented and empirical results show that it is able to reduce bandwidth requirements by up to 41% whilst achieving equivalent QoE compared with a representative DASH reference implementation.
C1 [Irondi, Iheanyi; Wang, Qi; Calero, Jose M. Alcaraz; Casaseca-De-La-Higuera, Pablo] Univ West Scotland, Sch Comp Engn & Phys Sci, Paisley PA1 2BE, Renfrew, Scotland.
   [Grecos, Christos] Cent Washington Univ, Comp Sci Dept, Ellensburg, WA 98926 USA.
   [Casaseca-De-La-Higuera, Pablo] Univ Valladolid, Lab Proc Imagen, ETSI Telecomunicac, E-47011 Valladolid, Spain.
C3 University of West Scotland; Central Washington University; Universidad
   de Valladolid
RP Irondi, I; Wang, Q (corresponding author), Univ West Scotland, Sch Comp Engn & Phys Sci, Paisley PA1 2BE, Renfrew, Scotland.
EM Iheanyi.Irondi@uws.ac.uk; Qi.Wang@uws.ac.uk; grecoschristos@gmail.com;
   Jose.Alcaraz-Calero@uws.ac.uk; casaseca@lpi.tel.uva.es
RI Casaseca-de-la-Higuera, Pablo/L-4140-2017; Alcaraz Calero, Jose
   M./JWP-8793-2024
OI Casaseca-de-la-Higuera, Pablo/0000-0003-1565-0842; Alcaraz Calero, Jose
   M./0000-0002-2654-7595
FU European Commission Horizon 2020 5G-PPP Programs
   [H2020-ICT-2014-2/671672, H2020-ICT-2016-2/761913]; UK Royal Society of
   Edinburgh; National Science Foundation of China
FX This work is in part supported by the European Commission Horizon 2020
   5G-PPP Programs under Grant Agreement number H2020-ICT-2014-2/671672
   (SELFNET: Framework for Self-Organized Network Management in Virtualized
   and Software Defined Networks), and H2020-ICT-2016-2/761913 (SliceNet:
   End-to-End Cognitive Network Slicing and Slice Management Framework in
   Virtualised Multi-Domain, Multi-Tenant 5G Networks). Thanks are also
   given to the to the UK Royal Society of Edinburgh and National Science
   Foundation of China for the funding associated to the project "Flood
   Detection and Monitoring using Hyperspectral Remote Sensing from
   Unmanned Aerial Vehicles".
CR Akhshabi S, 2012, SIGNAL PROCESS-IMAGE, V27, P271, DOI 10.1016/j.image.2011.10.003
   [Anonymous], 2012, Recommendation BT.500-13
   [Anonymous], 2017, TOMSK 2
   [Anonymous], 2016, HIGH EFF VID COD
   [Anonymous], 2008, Subjective video quality assessment methods for multimedia applications. Recommendation P.910
   Blender Foundation, 2016, EL DREAM
   Blender Institute Production, 2016, BIGB BUNN
   Carlucci G., 2015, 30 ANN ACM S APPL CO
   Cranley N, 2006, INT J HUM-COMPUT ST, V64, P637, DOI 10.1016/j.ijhcs.2005.12.002
   GPAC Multimedia Project, 2013, GPAC MP4CLIENT
   Grafl Michael, 2013, 4 INT WORKSH PERC QU
   Gürses E, 2005, COMPUT NETW, V48, P489, DOI 10.1016/j.comnet.2004.10.015
   Hobfeld Tobias, IEEE 6 INT WORKSH QU
   Hossfeld T, 2012, INT WORK QUAL MULTIM, P1, DOI 10.1109/QoMEX.2012.6263849
   Huang TY, 2014, ACM SIGCOMM COMP COM, V44, P187, DOI 10.1145/2740070.2626296
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Huysegems Rafael, 2015, 23 ACM INT C MULT MM
   Krishnan SS, 2013, IEEE ACM T NETWORK, V21, P2001, DOI 10.1109/TNET.2013.2281542
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Liu Chenghao, 2011, 2 ANN ACM C MULT SYS
   Liu Yitong, 2013, IEEE INT C COMM WORK
   Martin Jim, 2013, IEEE 10 CONS COMM NE, DOI [10.1109/ccnc.2013.6488451, DOI 10.1109/CCNC.2013.6488451]
   McCarrthy John D., 2004, SIGCHI C HUM FACT CO
   Mkwawa IH, 2012, IEEE GLOBE WORK, P1276, DOI 10.1109/GLOCOMW.2012.6477765
   N. Alliance, 2016, NGMN 5G P, V1, P1
   Ni Pengpeng, 2011, ACM INT C MULT MM 11
   Pantos R., 2017, Http live streaming, DOI DOI 10.17487/RFC8216
   Quan Huynh-Thu, 2006, WORKSH VID PROC QUAL
   Robinson DC, 2012, BELL LABS TECH J, V16, P5, DOI 10.1002/bltj.20531
   Rodríguez DZ, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-216
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Staelens N, 2015, INT WORK QUAL MULTIM
   Staelens N, 2014, IEEE T BROADCAST, V60, P707, DOI 10.1109/TBC.2014.2359255
   Tavakoli S, 2016, IEEE J SEL AREA COMM, V34, P2141, DOI 10.1109/JSAC.2016.2577361
   Tavakoli S, 2014, PROC SPIE, V9016, DOI 10.1117/12.2040131
   van der Hooft J, 2016, IEEE COMMUN LETT, V20, P2177, DOI 10.1109/LCOMM.2016.2601087
   Winkler Stefan, 2005, INT WORKSH VID PROC
   Zambelli A., 2009, IIS Smooth Streaming Technical Overview
   Zink M, 2005, IEEE T MULTIMEDIA, V7, P75, DOI 10.1109/TMM.2004.840595
NR 40
TC 4
Z9 6
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2019
VL 15
IS 1
AR 17
DI 10.1145/3269494
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HM9JB
UT WOS:000459798800001
DA 2024-07-18
ER

PT J
AU Shamai, G
   Slossberg, R
   Kimmel, R
AF Shamai, Gil
   Slossberg, Ron
   Kimmel, Ron
TI Synthesizing Facial Photometries and Corresponding Geometries Using
   Generative Adversarial Networks
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks; 3D morphable model; face recognition;
   3D face synthesis; data augmentation; facial texture and geometry
AB Artificial data synthesis is currently a well-studied topic with useful applications in data science, computer vision, graphics, and many other fields. Generating realistic data is especially challenging, since human perception is highly sensitive to non-realistic appearance. In recent times, new levels of realism have been achieved by advances in GAN training procedures and architectures. These successful models, however, are tuned mostly for use with regularly sampled data such as images, audio, and video. Despite the successful application of the architecture on these types of media, applying the same tools to geometric data poses a far greater challenge. The study of geometric deep learning is still a debated issue within the academic community, as the lack of intrinsic parametrization inherent to geometric objects prohibits the direct use of convolutional filters, a main building block of today's machine learning systems.
   In this article, we propose a new method for generating realistic human facial geometries coupled with overlayed textures. We circumvent the parametrization issue by utilizing a specialized non-rigid alignment procedure, and imposing a global mapping from our data to the unit rectangle. This mapping enables the representation of our geometric data as regularly sampled 2D images. We further discuss how to design such a mapping to control the distortion and conserve area within the target image. By representing geometric textures and geometries as images, we are able to use advanced GAN methodologies to generate new plausible textures and geometries. We address the often-neglected topic of relationship between texture and geometry and propose different methods for fitting generated geometries to generated textures. In addition, we widen the scope of our discussion and offer a new method for training GAN models on partially corrupted data. Finally, we provide empirical evidence demonstrating our generative model's ability to produce examples of new facial identities, independent from the training data, while maintaining a high level of realism-two traits that are often at odds.
C1 [Shamai, Gil; Slossberg, Ron; Kimmel, Ron] Technion Israel Inst Technol, Dept Comp Sci, 435 Taub Bldg, IL-3200003 Haifa, Israel.
C3 Technion Israel Institute of Technology
RP Shamai, G (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, 435 Taub Bldg, IL-3200003 Haifa, Israel.
EM sgils@campus.technion.ac.il; ronslos@campus.technion.ac.il;
   ron@cs.technion.ac.il
FU Israel Ministry of Science [3-14719]; Technion Hiroshi Fujiwara Cyber
   Security Research Center; Israel Cyber Bureau
FX This research was partially supported by the Israel Ministry of Science,
   grant number 3-14719, and the Technion Hiroshi Fujiwara Cyber Security
   Research Center and the Israel Cyber Bureau.
CR [Anonymous], 2017, BLEND A 3D MOD REND
   [Anonymous], 2018, NONLINEAR 3D FACE MO
   Antonakos Epameinondas, 2016, DENSEREG FULLY CONVO
   Bas A, 2017, IEEE INT CONF COMP V, P895, DOI 10.1109/ICCVW.2017.110
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Booth James, 2017, P IEEE C COMPUTERVIS
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Chu YF, 2014, IEEE DECIS CONTR P, P1899, DOI 10.1109/CDC.2014.7039675
   Deng J, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND BIOINFORMATICS (ICBEB 2018), P1, DOI 10.1145/3278198.3278199
   Floater MS, 1997, COMPUT AIDED GEOM D, V14, P231, DOI 10.1016/S0167-8396(96)00031-3
   Gecer B., 2018, P ECCV
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Karras T, 2018, P INT C LEARN REPR I
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kosloff S, 2009, IMPACT OF 9/11 ON PSYCHOLOGY AND EDUCATION: THE DAY THAT CHANGED EVERYTHING, P7
   Litany O., 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00202
   Ludwiczuk B., 2016, Tech. Rep. CMU-CS-16-118
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Rabin J, 2012, LECT NOTES COMPUT SC, V6667, P435, DOI 10.1007/978-3-642-24785-9_37
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589
   Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56
   Saito Shunsuke, 2017, P IEEE C COMP VIS PA, V3
   Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175
   Shamai Gil, 2018, IEEE T PATTERN ANAL
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Slossberg R., 2018, Proceedings of the European Conference on Computer Vision
   Tewari Ayush, 2018, P IEEE C COMP VIS PA
   Trân AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wu J, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON SOCIAL, EDUCATION AND MANAGEMENT ENGINEERING (SEME 2016), P82
NR 37
TC 23
Z9 23
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2019
VL 15
IS 3
SU S
SI SI
AR 87
DI 10.1145/3337067
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LR5EU
UT WOS:000535718800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, XP
   Wang, YH
   Li, WX
AF Wang, Xueping
   Wang, Yunhong
   Li, Weixin
TI U-Net Conditional GANs for Photo-Realistic and Identity-Preserving
   Facial Expression Synthesis
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Facial expression synthesis; generative adversarial networks (GANs);
   identity preserving
AB Facial expression synthesis (FES) is a challenging task since the expression changes are highly non-linear and depend on the facial appearance. Person identity should also be well preserved in the synthesized face. In this article, we present a novel U-Net Conditional Generative Adversarial Network for FES. U-Net helps retain the property of the input face, including the identity information and facial details. Category condition is added to the U-Net model so that one-to-many expression synthesis can be achieved simultaneously. We also design constraints for identity preservation during FFS to further guarantee that the identity of the input face can be well preserved in the generated face image. Specifically, we pair the generated output with condition image of other identities for the discriminator, so as to encourage it to learn the distinctions between the synthesized and natural images, as well as between input and other identities, which can help improve its discriminating ability. Additionally, we utilize the triplet loss to maintain the generated face images closer to the same identity person by imposing a margin between the positive pairs and negative pairs in feature space. Both qualitative and quantitative evaluations are conducted on the Oulu-CASIA NIR&VIS facial expression database, the Radboud Faces Database, and the Karolinska Directed Emotional Faces database, and the experimental results show that our method can generate faces with natural and realistic expressions while preserving identity information.
C1 [Wang, Xueping; Wang, Yunhong; Li, Weixin] Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
C3 Beihang University
RP Li, WX (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM xpwang@buaa.edu.cn; yhwang@buaa.edu.cn; weixinli@buaa.edu.cn
FU National Natural Science Foundation of China [61806016, 61421003]
FX This work was funded by the National Natural Science Foundation of China
   (nos. 61806016 and 61421003).
CR Abadi M, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467
   [Anonymous], 1998, KAROLINSKA DIRECTED
   [Anonymous], 2018, SENSORS-BASEL
   [Anonymous], 2018, 32 AAAI C ART INT
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.632
   [Anonymous], MICR EM API
   [Anonymous], 2016, P INT C LEARN REPR I
   [Anonymous], 2014, CLASS PROJECT STANFO
   [Anonymous], 2016, ARXIV161109961
   [Anonymous], P 32 INT C COMP GRAP
   [Anonymous], 2015, P 3 INT C LEARN REPR
   [Anonymous], P INT C LEARN REPR W
   [Anonymous], Face++ research toolkit
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.262
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Leibe B., 2017, ARXIV170307737CS
   Li M., 2016, ARXIV161005586
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li X., 2006, P THE 3 CANADIAN C C, P77
   Lien JJJ, 2000, ROBOT AUTON SYST, V31, P131, DOI 10.1016/S0921-8890(99)00103-7
   Lisetti C.L., 2000, Pragmatics cognition, V8, P185, DOI DOI 10.1075/PC.8.1.09LIS
   Liu XF, 2019, PATTERN RECOGN, V88, P1, DOI 10.1016/j.patcog.2018.11.001
   Liu ZC, 2001, COMP GRAPH, P271
   Maas A.L., 2013, P INT C MACH LEARN, P3
   Odena A, 2017, PR MACH LEARN RES, V70
   Olszewski K, 2017, IEEE I CONF COMP VIS, P5439, DOI 10.1109/ICCV.2017.580
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Reed S, 2014, PR MACH LEARN RES, V32, P1431
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Seitz SM, 1996, P SIGGRAPH, P21, DOI DOI 10.1145/237170.237196
   Simonyan K., 2014, 14091556 ARXIV
   Song LX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P627, DOI 10.1145/3240508.3240612
   Susskind Joshua M., 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition, P421
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang XP, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P283, DOI 10.1145/3206025.3206068
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Yang HY, 2018, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2018.00011
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhou YQ, 2017, INT CONF AFFECT, P370, DOI 10.1109/ACII.2017.8273626
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 53
TC 14
Z9 16
U1 0
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2019
VL 15
IS 3
SU S
SI SI
AR 88
DI 10.1145/3355397
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LR5EU
UT WOS:000535718800004
DA 2024-07-18
ER

PT J
AU Sikora, M
   Russo, M
   Derek, J
   Jurcevic, A
AF Sikora, Marjan
   Russo, Mladen
   Derek, Jurica
   Jurcevic, Ante
TI Soundscape of an Archaeological Site Recreated with Audio Augmented
   Reality
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; auralization; affective computing
AB This article investigates the use of an audio augmented reality (AAR) system to recreate the soundscape of a medieval archaeological site. The aim of our work was to explore whether it is possible to enhance a tourist's archaeological experience, which is often derived from only scarce remains. We developed a smartphone-based AAR system, which uses location and orientation sensors to synthesize the soundscape of a site and plays it to the user via headphones. We recreated the ancient soundscape of a medieval archaeological site in Croatia and tested it in situ on two groups of participants using the soundwalk method. One test group performed the soundwalk while listening to the recreated soundscape using the AAR system, while the second control group did not use the AAR equipment. We measured the experiences of the participants using two methods: the standard soundwalk questionnaire and affective computing equipment for detecting the emotional state of participants. The results of both test methods show that participants who were listening to the ancient soundscape using our AAR system experienced higher arousal than those visiting the site without AAR.
C1 [Sikora, Marjan; Russo, Mladen] Univ Split, Fac Elect Engn Mech Engn & Naval Architecture, Rudjera Boskovica 32, Split 21000, Croatia.
   [Derek, Jurica] Ericsson Nikola Tesla Dd, Krapinska 45, Zagreb 10000, Croatia.
   [Jurcevic, Ante] Museum Croatian Archaeol Monuments, S Gunjace Bb, Split 21000, Croatia.
C3 University of Split; Ericsson
RP Sikora, M (corresponding author), Univ Split, Fac Elect Engn Mech Engn & Naval Architecture, Rudjera Boskovica 32, Split 21000, Croatia.
EM sikora@fesb.hr; mrusso@fesb.hr; jurica.derek@ericsson.com;
   ante.jurcevic@mhas-split.hr
RI Russo, Mladen/E-2257-2017; Sikora, Marjan/D-9203-2017
OI Russo, Mladen/0000-0002-9363-6723; 
FU Croatian Science Foundation [UIP-2014-09-3875]
FX This work has been fully supported by the Croatian Science Foundation
   under the project number UIP-2014-09-3875.
CR Aletta F, 2017, URBAN SCI, V1, DOI 10.3390/urbansci1010004
   [Anonymous], P 7 C ALPS ADR AC AS
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 1992, P MULT INT DES INCOL
   [Anonymous], P INVISIBLE PLACES
   [Anonymous], P 5 C ALPS ADR AC AS
   [Anonymous], 1994, P 1 ANN C ASS TECHN, DOI DOI 10.1145/191028.191051
   [Anonymous], ARCHAEOACUSTICS
   [Anonymous], P 11 INT C VIRT REAL
   [Anonymous], P EURONOISE
   [Anonymous], P ANN INT C IEEE ENG
   [Anonymous], P LANDSC ARCH C LAC
   [Anonymous], J EXTENSION
   [Anonymous], P C ED RES COMP AID
   [Anonymous], SWORDS CROWNS CENSER
   [Anonymous], J PERSONALITY SOCIAL
   [Anonymous], P 4 INT C AFF COMP C
   [Anonymous], P INTERNOISE
   [Anonymous], 2014, 1291312014 ISOFDIS
   [Anonymous], FUNDAMENTALS WEARABL
   [Anonymous], P MUSEUMS WEB 2004
   [Anonymous], P ANN C AUSTR AC SOC
   [Anonymous], P EURONOISE
   Botteldooren D., 2011, FORUM ACUSTICUM 2011, P2047
   Chatzidimitris T, 2016, IEEE MEDITERR ELECT
   Davies WJ, 2014, ACTA ACUST UNITED AC, V100, P285, DOI 10.3813/AAA.918708
   Debertolis Paolo., 2015, Journal of Anthropology and Archaeology, V3, P59, DOI DOI 10.15640/JAA.V3N1A4
   Feiner S, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P74, DOI 10.1109/ISWC.1997.629922
   Fränti P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3115935
   Guastavino C, 2005, ACTA ACUST UNITED AC, V91, P333
   Harriet S, 2015, ACTA ACUST UNITED AC, V101, P798, DOI 10.3813/AAA.918874
   Heller F, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P615, DOI 10.1145/2556288.2557021
   Karafotias G, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092840
   Pijanowski BC, 2011, LANDSCAPE ECOL, V26, P1213, DOI 10.1007/s10980-011-9600-8
   RAIMBAULT M, 2005, ACTA ACUST UNITED AC, V22, P339, DOI DOI 10.1016/J.CITIES.2005.05.003
   Schafer Murray., 1977, The Tuning of the World
   Seidenari L, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092832
   Semidor C, 2006, ACTA ACUST UNITED AC, V92, P959
   Udovicic G., 2017, Proceedings of the. 2nd Int. Workshop on Multimedia for. Personal Health and Health Care, P53, DOI [10.1145/3132635.3132641, DOI 10.1145/3132635.3132641]
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Vazquez-Alvarez Y, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2829944
   Zheng YT, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422959
NR 42
TC 17
Z9 17
U1 2
U2 22
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2018
VL 14
IS 3
AR 74
DI 10.1145/3230652
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GT7CI
UT WOS:000444677600007
DA 2024-07-18
ER

PT J
AU Berretti, S
   Daoudi, M
   Turaga, P
   Basu, A
AF Berretti, Stefano
   Daoudi, Mohamed
   Turaga, Pavan
   Basu, Anup
TI Representation, Analysis, and Recognition of 3D Humans: A Survey
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE 3D humans; 3D shape representation; 3D face and body representation; 3D
   face and body analysis and retrieval
ID FACIAL EXPRESSION RECOGNITION; NONLINEAR DYNAMICAL-SYSTEMS; FRONTAL GAIT
   RECOGNITION; FACE RECOGNITION; SHAPE RETRIEVAL; 3-D FACE; DEPTH; RGB;
   FEATURES; MODEL
AB Computer Vision and Multimedia solutions are now offering an increasing number of applications ready for use by end users in everyday life. Many of these applications are centered for detection, representation, and analysis of face and body. Methods based on 2D images and videos are the most widespread, but there is a recent trend that successfully extends the study to 3D human data as acquired by a new generation of 3D acquisition devices. Based on these premises, in this survey, we provide an overview on the newly designed techniques that exploit 3D human data and also prospect the most promising current and future research directions. In particular, we first propose a taxonomy of the representation methods, distinguishing between spatial and temporal modeling of the data. Then, we focus on the analysis and recognition of 3D humans from 3D static and dynamic data, considering many applications for body and face.
C1 [Berretti, Stefano] Univ Florence, Dept Informat Engn, Via Santa Marta 3, I-50139 Florence, Italy.
   [Daoudi, Mohamed] Univ Lille, IMT Lille Douai, Ctr Rech Informat Signal & Automat Lille, CNRS,CRIStAL,UMR 9189, 20 Rue Guglielmo Marconi, F-59650 Villeneuve Dascq, France.
   [Turaga, Pavan] Arizona State Univ, ASU Tempe Campus,Stauffer B-259, Tempe, AZ 85287 USA.
   [Basu, Anup] Univ Alberta, Fac Sci, 402 Athabasca Hall, Edmonton, AB T6G 2E1, Canada.
C3 University of Florence; Universite de Lille; Centrale Lille; Centre
   National de la Recherche Scientifique (CNRS); IMT - Institut
   Mines-Telecom; IMT Nord Europe; Arizona State University; Arizona State
   University-Tempe; University of Alberta
RP Berretti, S (corresponding author), Univ Florence, Dept Informat Engn, Via Santa Marta 3, I-50139 Florence, Italy.
EM stefano.berretti@unifi.it; mohamed.daoudi@imt-lille-douai.fr;
   pturaga@asu.edu; basu@ualberta.ca
RI Turaga, Pavan/W-6186-2019; Berretti, Stefano/U-9004-2019; Daoudi,
   Mohammed/H-5935-2013
OI Berretti, Stefano/0000-0003-1219-4386; Daoudi,
   Mohammed/0000-0003-4219-7860
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Al Ismaeil Kassem, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P8, DOI 10.1109/CVPRW.2015.7301389
   Al Ismaeil K, 2017, IEEE T PATTERN ANAL, V39, P2045, DOI 10.1109/TPAMI.2016.2622698
   Al Ismaeil K, 2016, COMPUT VIS IMAGE UND, V147, P38, DOI 10.1016/j.cviu.2016.04.006
   Albiol A, 2012, IET COMPUT VIS, V6, P378, DOI 10.1049/iet-cvi.2011.0140
   Ali S., 2007, IEEE INT C COMPUTER
   Althloothi S, 2014, PATTERN RECOGN, V47, P1800, DOI 10.1016/j.patcog.2013.11.032
   Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   Anirudh R, 2017, IEEE T PATTERN ANAL, V39, P922, DOI 10.1109/TPAMI.2016.2564409
   Anirudh R, 2015, PROC CVPR IEEE, P3147, DOI 10.1109/CVPR.2015.7298934
   [Anonymous], IEEE T AFF COMP
   [Anonymous], ABS170310714 CORR
   [Anonymous], CORR
   [Anonymous], 2012, WORKSH KIN PERV COMP
   [Anonymous], EUR CONF COMP VISION
   [Anonymous], 2016, IEEE T NEUR NET LEAR, DOI DOI 10.1109/TNNLS.2014.2387383
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2016, BRIT MACH VIS C BMVC
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE INT S MIX AUGM
   [Anonymous], J COMPUTER VISION
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2017, ARXIV171105942
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2017, ACM T GRAPHICS
   [Anonymous], 2010, P 3 EUR C 3D OBJ RET
   [Anonymous], INT S VIS COMP
   [Anonymous], EUR CONF COMP VISION
   [Anonymous], POSITIVE DEFINITE MA
   [Anonymous], CENTR EUR SEM COMP G
   [Anonymous], 2014, Asian Conference on Computer Vision
   [Anonymous], 1 IEEE INT C BIOM TH
   [Anonymous], 2013, Cognitive Systems Monographs Modeling, Simulation and Optimization of Bipedal Walking, DOI [DOI 10.1007/978-3-642-36368-9_6, 10.1007/978-3-642-36368-9_6]
   [Anonymous], 2017, IEEE TPAMI
   Aouada D, 2007, INT CONF ACOUST SPEE, P645
   Arsigny V, 2005, LECT NOTES COMPUT SC, V3749, P115
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Ben Amor B, 2014, IEEE T CYBERNETICS, V44, P2443, DOI 10.1109/TCYB.2014.2308091
   Benedikt L, 2010, IEEE T SYST MAN CY A, V40, P449, DOI 10.1109/TSMCA.2010.2041656
   Berretti S, 2014, IEEE T INF FOREN SEC, V9, P1436, DOI 10.1109/TIFS.2014.2337258
   Berretti S, 2013, IEEE T INF FOREN SEC, V8, P374, DOI 10.1109/TIFS.2012.2235833
   Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x
   Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   Berretti S, 2009, IMAGE VISION COMPUT, V27, P1540, DOI 10.1016/j.imavis.2009.02.004
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591
   Bondi E, 2016, IEEE T INF FOREN SEC, V11, P2843, DOI 10.1109/TIFS.2016.2601059
   Bonnabel S, 2009, SIAM J MATRIX ANAL A, V31, P1055, DOI 10.1137/080731347
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Chattopadhyay P, 2015, PATTERN RECOGN LETT, V63, P9, DOI 10.1016/j.patrec.2015.06.004
   Chattopadhyay P, 2014, IEEE T INF FOREN SEC, V9, P1843, DOI 10.1109/TIFS.2014.2352114
   Chattopadhyay P, 2014, J VIS COMMUN IMAGE R, V25, P53, DOI 10.1016/j.jvcir.2013.02.010
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chen HZ, 2016, PATTERN RECOGN, V55, P148, DOI 10.1016/j.patcog.2016.01.020
   Colombo A, 2006, PATTERN RECOGN, V39, P444, DOI 10.1016/j.patcog.2005.09.009
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Daoudi M, 2017, LECT NOTES COMPUT SC, V10484, P550, DOI 10.1007/978-3-319-68560-1_49
   Devanne M, 2016, INT C PATT RECOG, P895, DOI 10.1109/ICPR.2016.7899749
   Devanne M, 2017, PATTERN RECOGN, V61, P222, DOI 10.1016/j.patcog.2016.07.041
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Ekman P., 1971, Nebraska symposium on motivation, V19, P207
   Ekman P, 1978, FACIAL ACTION CODING
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Fang Y, 2015, PROC CVPR IEEE, P2319, DOI 10.1109/CVPR.2015.7298845
   Ferrari C, 2017, IEEE T MULTIMEDIA, V19, P2666, DOI 10.1109/TMM.2017.2707341
   Gong B., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P569
   Gong L., 2010, ACM Symp. on Applied Computing, P1203
   Grossmann R, 2002, IEEE T PATTERN ANAL, V24, P433, DOI 10.1109/34.993552
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   Hajari N., 2016, IEEE INT S MULTIMEDI, P1
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Haque A, 2016, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2016.138
   Hariri W, 2017, ENG APPL ARTIF INTEL, V64, P25, DOI 10.1016/j.engappai.2017.05.009
   Hernandez M, 2012, EUR SIGNAL PR CONF, P1995
   Huang D, 2014, LECT NOTES COMPUT SC, V8691, P410, DOI 10.1007/978-3-319-10578-9_27
   Huang WB, 2016, PROC CVPR IEEE, P3938, DOI 10.1109/CVPR.2016.427
   Huber P, 2017, IEEE SIGNAL PROC LET, V24, P437, DOI 10.1109/LSP.2016.2643284
   Ioannidis D, 2007, IEEE T INF FOREN SEC, V2, P623, DOI 10.1109/TIFS.2007.902040
   Izadi S., 2011, ACM SIGGRAPH 2011 Talks, P23, DOI 10.1145/2037826.2037857
   Jalal A, 2017, PATTERN RECOGN, V61, P295, DOI 10.1016/j.patcog.2016.08.003
   Jia XF, 2012, INT C PATT RECOG, P3001
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Jongmoo Choi, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P19, DOI 10.1109/ROMAN.2013.6628525
   Kapur A, 2005, LECT NOTES COMPUT SC, V3784, P1
   Karg M, 2013, IEEE T AFFECT COMPUT, V4, P341, DOI 10.1109/T-AFFC.2013.29
   Karg M, 2010, IEEE T SYST MAN CY B, V40, P1050, DOI 10.1109/TSMCB.2010.2044040
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Kokkinos I, 2012, PROC CVPR IEEE, P159, DOI 10.1109/CVPR.2012.6247671
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kurusa A, 2007, ACTA SCI MATH, V73, P424
   Laga H, 2017, IEEE T PATTERN ANAL, V39, P2451, DOI 10.1109/TPAMI.2016.2647596
   Li BYL, 2013, IEEE WORK APP COMP, P186, DOI 10.1109/WACV.2013.6475017
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liang B, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P76
   Liang Shu, 2014, Proc Int Conf 3D Vis, V2014, P31, DOI 10.1109/3DV.2014.67
   Ling HB, 2005, PROC CVPR IEEE, P719
   Liu J., 2017, IEEE T PATTERN ANAL
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lo Presti L, 2015, IMAGE VISION COMPUT, V44, P29, DOI 10.1016/j.imavis.2015.09.007
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Lui YM, 2012, IMAGE VISION COMPUT, V30, P380, DOI 10.1016/j.imavis.2011.08.002
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Maalej Ahmed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4129, DOI 10.1109/ICPR.2010.1003
   Pozo JM, 2011, IEEE T PATTERN ANAL, V33, P471, DOI 10.1109/TPAMI.2010.139
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Mpiperis I, 2008, IEEE T INF FOREN SEC, V3, P498, DOI 10.1109/TIFS.2008.924598
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Ni BB, 2013, IEEE T CYBERNETICS, V43, P1383, DOI 10.1109/TCYB.2013.2276433
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Pan G, 2006, LECT NOTES COMPUT SC, V3952, P389
   Papyan V, 2017, J MACH LEARN RES, V18, P1
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Patel A, 2009, PROC CVPR IEEE, P1327, DOI 10.1109/CVPRW.2009.5206522
   Patil H, 2015, ARTIF INTELL REV, V44, P393, DOI 10.1007/s10462-015-9431-0
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Pickup D, 2016, INT J COMPUT VISION, V120, P169, DOI 10.1007/s11263-016-0903-8
   Pons-Moll G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766993
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Kassim SRA, 2006, IEEE IMAGE PROC, P661
   Rastegari M, 2011, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2011.6126556
   Ravichandran A, 2013, IEEE T PATTERN ANAL, V35, P342, DOI 10.1109/TPAMI.2012.83
   Reale M, 2013, IEEE INT CONF AUTOMA
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Romdhani S, 2005, PROC CVPR IEEE, P986
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Sandbach G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P406, DOI 10.1109/FG.2011.5771434
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Savran A, 2017, COMPUT VIS IMAGE UND, V162, P146, DOI 10.1016/j.cviu.2017.07.005
   Schuon S, 2009, PROC CVPR IEEE, P343, DOI 10.1109/CVPRW.2009.5206804
   SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shotton J., 2011, IEEE INT C COMPUTER, P1
   Singh M., 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P1091
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Smeets D, 2013, COMPUT VIS IMAGE UND, V117, P158, DOI 10.1016/j.cviu.2012.10.002
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840
   Tierny J, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P105
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52
   Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143
   Vemulapalli R, 2016, COMPUT VIS IMAGE UND, V152, P155, DOI 10.1016/j.cviu.2016.04.005
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Venkataraman V, 2016, IEEE T PATTERN ANAL, V38, P2531, DOI 10.1109/TPAMI.2016.2533388
   Venkatesh YV, 2009, PATTERN RECOGN LETT, V30, P1128, DOI 10.1016/j.patrec.2009.04.007
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Vuong Le, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P414, DOI 10.1109/FG.2011.5771435
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wang J, 2012, ELECTRON J QUAL THEO, P1
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang T, 2007, PATTERN RECOGN LETT, V28, P501, DOI 10.1016/j.patrec.2006.09.004
   Wei P, 2013, IEEE I CONF COMP VIS, P3272, DOI 10.1109/ICCV.2013.406
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Werghi N, 2016, IEEE T INF FOREN SEC, V11, P964, DOI 10.1109/TIFS.2016.2515505
   Werghi N, 2015, IEEE T IMAGE PROCESS, V24, P220, DOI 10.1109/TIP.2014.2370253
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xie J, 2015, PROC CVPR IEEE, P1275, DOI 10.1109/CVPR.2015.7298732
   Yang K, 2016, J VIS COMMUN IMAGE R, V39, P209, DOI 10.1016/j.jvcir.2016.05.020
   Yang Q., 2007, IEEE C COMPUTER VISI
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yin LJ, 1999, PATTERN RECOGN LETT, V20, P651, DOI 10.1016/S0167-8655(99)00029-X
   Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang XK, 2016, PROC CVPR IEEE, P4498, DOI 10.1109/CVPR.2016.487
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
NR 193
TC 19
Z9 19
U1 0
U2 28
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2018
VL 14
IS 1
SU S
AR 16
DI 10.1145/3182179
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GH5ZK
UT WOS:000433517100002
DA 2024-07-18
ER

PT J
AU Li, S
   Li, K
   Fu, Y
AF Li, Sheng
   Li, Kang
   Fu, Yun
TI Early Recognition of 3D Human Actions
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Marked point process; 3D action recognition; motion analysis
ID TIME-SERIES; EARLY CLASSIFICATION; MODEL; DESCRIPTOR; ENSEMBLE; LATENCY
AB Action recognition is an important research problem of human motion analysis (HMA). In recent years, 3D observation-based action recognition has been receiving increasing interest in the multimedia and computer vision communities, due to the recent advent of cost-effective sensors, such as depth camera Kinect. This work takes this one step further, focusing on early recognition of ongoing 3D human actions, which is beneficial for a large variety of time-critical applications, e.g., gesture-based human machine interaction, somatosensory games, and so forth. Our goal is to infer the class label information of 3D human actions with partial observation of temporally incomplete action executions. By considering 3D action data as multivariate time series (m.t.s.) synchronized to a shared common clock (frames), we propose a stochastic process called dynamic marked point process (DMP) to model the 3D action as temporal dynamic patterns, where both timing and strength information are captured. To achieve even more early and better accuracy of recognition, we also explore the temporal dependency patterns between feature dimensions. A probabilistic suffix tree is constructed to represent sequential patterns among features in terms of the variable-order Markov model (VMM). Our approach and several baselines are evaluated on five 3D human action datasets. Extensive results show that our approach achieves superior performance for early recognition of 3D human actions.
C1 [Li, Sheng; Li, Kang; Fu, Yun] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
   [Fu, Yun] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.
C3 Northeastern University; Northeastern University
RP Li, S (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
EM shengli@ece.neu.edu; kongkong115@gmail.com; yunfu@ece.neu.edu
OI Li, Sheng/0000-0003-1205-8632
FU NSF IIS [1651902]; ONR [N00014-14-1-0484]; U.S. Army Research Office
   [W911NF-17-1-0367]
FX This research is supported in part by the NSF IIS award 1651902, ONR
   Young Investigator Award N00014-14-1-0484, and U.S. Army Research Office
   Award W911NF-17-1-0367.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Begleiter R, 2004, J ARTIF INTELL RES, V22, P385, DOI 10.1613/jair.1491
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bregón A, 2006, LECT NOTES ARTIF INT, V4177, P211
   Cai XY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1075, DOI 10.1145/2733373.2806285
   Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343
   CLEARY JG, 1984, IEEE T COMMUN, V32, P396, DOI 10.1109/TCOM.1984.1096090
   Dachraoui A, 2015, LECT NOTES ARTIF INT, V9284, P433, DOI 10.1007/978-3-319-23528-8_27
   Daley Daryl J, 2003, INTRO THEORY POINT P, Vi, DOI 10.1007/b97277
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Eruhimov V, 2007, LECT NOTES ARTIF INT, V4702, P414
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Ghalwash M.F., 2012, Bioinformatics and Biomedicine (BIBM), 2012 IEEE International Conference on, P1
   Ghalwash MF, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-195
   Gunawardana A., 2011, Advances in neural information processing systems, P1962
   Hadfield S, 2013, PROC CVPR IEEE, P3398, DOI 10.1109/CVPR.2013.436
   He GL, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1889, DOI 10.1145/2505515.2507888
   He GL, 2015, NEUROCOMPUTING, V149, P777, DOI 10.1016/j.neucom.2014.07.056
   Jansen A, 2009, SPEECH COMMUN, V51, P1155, DOI 10.1016/j.specom.2009.05.008
   Katagiri H, 2012, COMPUT J, V55, P325, DOI 10.1093/comjnl/bxr042
   Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476
   Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406
   Kim Gunhee., 2012, ACM SIGKDD, P1068
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Koppula Hema, 2013, P ICML, P792
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Li K, 2014, IEEE T PATTERN ANAL, V36, P1644, DOI 10.1109/TPAMI.2013.2297321
   Li K, 2017, IEEE T IMAGE PROCESS, V26, P2261, DOI 10.1109/TIP.2017.2678800
   Li K, 2014, IEEE DATA MINING, P310, DOI 10.1109/ICDM.2014.100
   Li K, 2012, LECT NOTES COMPUT SC, V7572, P286, DOI 10.1007/978-3-642-33718-5_21
   Li S, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P989, DOI 10.1145/2983323.2983780
   Li S, 2015, IEEE I CONF COMP VIS, P4453, DOI 10.1109/ICCV.2015.506
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13
   Lin L, 2016, INT J COMPUT VISION, V118, P256, DOI 10.1007/s11263-015-0876-z
   Lin YF, 2015, LECT NOTES ARTIF INT, V9077, P199, DOI 10.1007/978-3-319-18038-0_16
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu L., 2013, 23 INT JOINT C ART I
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Mahasseni B, 2016, PROC CVPR IEEE, P3054, DOI 10.1109/CVPR.2016.333
   Hoai M, 2012, PROC CVPR IEEE, P2863, DOI 10.1109/CVPR.2012.6248012
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Karthir,, 2010, PROC CVPR IEEE, P1967, DOI 10.1109/CVPR.2010.5539871
   Rodriguez J. J., 2001, Intelligent Data Analysis, V5, P245
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Utasi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3385, DOI 10.1109/CVPR.2011.5995699
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wei L, 2006, P 12 ACM SIGKDD INT, P748, DOI [10.1145/1150402.1150498, DOI 10.1145/1150402.1150498]
   Xi X., 2006, Proceedings of the 23rd international conference on Machine learning, VVolume 2006, P1033, DOI [10.1145/1143844.1143974, DOI 10.1145/1143844.1143974]
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xing Z., 2011, Proceedings of SDM, P247
   Xing ZZ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1297
   Ye LX, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P947
   Yu Kong, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163084
   Yun Fu, 2015, HUMAN ACTIVITY RECOG
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang CY, 2015, COMPUT VIS IMAGE UND, V139, P29, DOI 10.1016/j.cviu.2015.05.010
   Zhang Z, 2012, COMPUT J, V55, P1088, DOI 10.1093/comjnl/bxs029
NR 67
TC 16
Z9 17
U1 1
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2018
VL 14
IS 1
SU S
AR 20
DI 10.1145/3131344
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GH5ZK
UT WOS:000433517100006
OA Bronze
DA 2024-07-18
ER

PT J
AU Su, Y
   Feng, ZY
   Zhang, JH
   Peng, WL
   Xing, M
AF Su, Yong
   Feng, Zhiyong
   Zhang, Jianhai
   Peng, Weilong
   Xing, Meng
TI Sequential Articulated Motion Reconstruction from a Monocular Image
   Sequence
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Articulated motion; Riemannian manifold; Extend Rauch Tung Striebel
   smoother; convex hull; simplex
ID STRUCTURE-FROM-MOTION; 3D SHAPE; TRACKING; REPRESENTATION; POSE
AB In this article, we present a sequential approach for articulated motion estimation from a 2D skeleton sequence. This is a challenging task due to the complexity of human movements and the inherent depth ambiguities. The proposed approach models the human movement on a kinematic manifold with the tangent bundle, which is a natural geometrical representation of articulated motion. Combined with a second-order stochastic dynamic model based on the Markov hypothesis, we generalize the Extended Rauch Tung Striebel smoother to a Riemannian manifold to simulate the process of human movement. The human motor system might violate the Markov hypothesis when the human body is subject to external forces, and therefore a refinement stage is introduced to correct the estimation error. Specifically, the current estimation is refined in a feasible solution region consisting of a set of local estimations. This region is called a simplex, in which each element can be represented by a convex hull of all ingredients. We have proved that the refinement problem can be converted into a convex optimization problem with the simplicial constraint. Since the proposed formulation conforms to the principles of kinematic and spatio-temporal continuity of articulated motion, the reconstruction ambiguity can be alleviated essentially. The performance of the proposed algorithm is conducted on multiple synthetic sequences from the CMU and the HDM05 MoCap databases. The results show that, without requiring any training data, the proposed approach achieves greater accuracy over state-ofthe-art baselines. Furthermore, the proposed approach outperforms two baselines on real sequences from the Human3.6m MoCap database.
C1 [Su, Yong; Zhang, Jianhai; Peng, Weilong; Xing, Meng] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Feng, Zhiyong] Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Feng, ZY (corresponding author), Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
EM suyong@tju.edu.cn; zyfeng@tju.edu.cn; zhangjianhai@tju.edu.cn;
   wlpeng@tju.edu.cn; xingmeng@tju.edu.cn
RI su, yong/JEO-5411-2023; Gulliver, Aaron/K-7925-2012; Peng,
   Weilong/GVS-5360-2022
OI su, yong/0000-0002-6851-4142; Peng, Weilong/0000-0001-5820-889X; Zhang,
   Jianhai/0000-0002-0330-6908; Meng, Xing/0000-0001-6082-4675
CR Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   Agudo A, 2016, IEEE T PATTERN ANAL, V38, P979, DOI 10.1109/TPAMI.2015.2469293
   Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751
   Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201
   [Anonymous], 2017, ARXIV170501583
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2007, Computer Graphics Technical Report CG-2007-2
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581
   Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941
   Brubaker MarcusA., 2007, COMPUTER VISION PATT, P1
   Chen YS, 2014, PROC CVPR IEEE, P1478, DOI 10.1109/CVPR.2014.192
   Cherian A, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.302
   Dai Y., 2012, COMPUT VISION PATTER, V107, P101
   Daubney B, 2011, PROC CVPR IEEE, P1321, DOI 10.1109/CVPR.2011.5995502
   Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758
   Ding LY, 2009, IMAGE VISION COMPUT, V27, P1826, DOI 10.1016/j.imavis.2009.02.005
   Drummond T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P315, DOI 10.1109/ICCV.2001.937642
   Gonczarek Adam, 2016, ARTICULATED TRACKING, P275
   Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7
   Grauman K, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P641
   Gudmundsson S., 2002, Expo. Math., V20, P1, DOI [DOI 10.1016/S0723-0869(02)80027-5, 10.1515/crll.1962.210.73]
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jia-Bin Huang, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P48
   Kong C, 2016, PROC CVPR IEEE, P4123, DOI 10.1109/CVPR.2016.447
   Lehrmann AM, 2014, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2014.171
   Leonardos Spyridon, 2016, P IEEE INT C ROB AUT
   LEONDES CT, 1970, IEEE T SYST SCI CYB, VSSC6, P63, DOI 10.1109/TSSC.1970.300330
   Liu JG, 2015, SIGNAL PROCESS, V110, P164, DOI 10.1016/j.sigpro.2014.08.028
   Moutzouris A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2301, DOI 10.1109/ICIP.2011.6116100
   Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734
   Olsen SI, 2008, J MATH IMAGING VIS, V31, P233, DOI 10.1007/s10851-007-0060-3
   Park D, 2011, IEEE I CONF COMP VIS, P2627, DOI 10.1109/ICCV.2011.6126552
   Park HS, 2011, IEEE I CONF COMP VIS, P201, DOI 10.1109/ICCV.2011.6126243
   Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41
   Raskin L, 2007, VISAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOLUME IU/MTSV, P459
   Rius I, 2009, PATTERN RECOGN, V42, P2907, DOI 10.1016/j.patcog.2009.02.012
   Sanzari M, 2016, LECT NOTES COMPUT SC, V9912, P566, DOI 10.1007/978-3-319-46484-8_34
   Sedai S, 2013, IEEE T IMAGE PROCESS, V22, P4286, DOI 10.1109/TIP.2013.2271850
   Sigal L, 2012, INT J COMPUT VISION, V98, P15, DOI 10.1007/s11263-011-0493-4
   Sigal Leonid, 2008, CONTINUOUS STATE GRA
   Sigal Leonid, 2010, HUMAN ATTRIBUTES 3D, P243
   Sigal Leonid, 2014, HUMAN POSE ESTIMATIO
   Simo-Serra E., 2016, INT J COMPUT VISION, P1
   Simo-Serra E, 2015, 2015 14th IAPR International Conference on Machine Vision Applications (MVA), P394, DOI 10.1109/MVA.2015.7153212
   Simo-Serra Edgar, 2012, P C COMP VIS PATT RE
   Sminchisescu C, 2003, PROC CVPR IEEE, P69
   Song Y, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2133366.2133371
   Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157
   Tekin B, 2016, PROC CVPR IEEE, pCP8, DOI 10.1109/CVPR.2016.113
   Tian Y, 2013, IMAGE VISION COMPUT, V31, P223, DOI 10.1016/j.imavis.2012.06.009
   Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Urtasun R., 2006, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2006.15
   Valmadre J, 2012, LECT NOTES COMPUT SC, V7572, P72, DOI 10.1007/978-3-642-33718-5_6
   Vondrak M, 2013, IEEE T PATTERN ANAL, V35, P52, DOI 10.1109/TPAMI.2012.61
   Wandt B, 2016, IEEE T PATTERN ANAL, V38, P1505, DOI 10.1109/TPAMI.2016.2553028
   Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wei XL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778779
   Wei XLK, 2009, IEEE I CONF COMP VIS, P1873, DOI 10.1109/ICCV.2009.5459415
   Xiao J, 2004, PROC CVPR IEEE, P668
   Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yao A., 2011, P ADV NEUR INF PROC, P1359
   Yasin H., 2015, ARXIV150906720
   Zhang XQ, 2015, INT J COMPUT VISION, V115, P279, DOI 10.1007/s11263-015-0819-8
   Zhou XW, 2017, IEEE T PATTERN ANAL, V39, P1648, DOI 10.1109/TPAMI.2016.2605097
   Zhou XW, 2015, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2015.7299074
   Zhu YG, 2011, PROCEEDINGS OF THE ASME INTERNATIONAL MANUFACTURING SCIENCE AND ENGINEERING CONFERENCE 2010, VOL 2, P1, DOI 10.1109/CVPR.2011.5995650
NR 70
TC 5
Z9 5
U1 0
U2 12
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2018
VL 14
IS 1
SU S
AR 23
DI 10.1145/3180420
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GH5ZK
UT WOS:000433517100009
DA 2024-07-18
ER

PT J
AU Li, K
   Qi, GJ
   Hua, KA
AF Li, Kai
   Qi, Guo-Jun
   Hua, Kien A.
TI Learning Label Preserving Binary Codes for Multimedia Retrieval: A
   General Approach
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Learning to hash; supervised learning; multimedia retrieval; large-scale
   similarity search; discrete optimization; binary integer programming
ID PRODUCT QUANTIZATION
AB Learning-based hashing has been researched extensively in the past few years due to its great potential in fast and accurate similarity search among huge volumes of multimedia data. In this article, we present a novel multimedia hashing framework, called Label Preserving Multimedia Hashing (LPMH) for multimedia similarity search. In LPMH, a general optimization method is used to learn the joint binary codes of multiple media types by explicitly preserving semantic label information. Compared with existing hashing methods which are typically developed under and thus restricted to some specific objective functions, the proposed optimization strategy is not tied to any specific loss function and can easily incorporate bit balance constraints to produce well-balanced binary codes. Specifically, our formulation leads to a set of Binary Integer Programming (BIP) problems that have exact solutions both with and without bit balance constraints. These problems can be solved extremely fast and the solution can easily scale up to large-scale datasets. In the hash function learning stage, the boosted decision trees algorithm is utilized to learn multiple media-specific hash functions that can map heterogeneous data sources into a homogeneous Hamming space for cross-media retrieval. We have comprehensively evaluated the proposed method using a range of large-scale datasets in both single-media and cross-media retrieval tasks. The experimental results demonstrate that LPMH is competitive with state-of-the-art methods in both speed and accuracy.
C1 [Li, Kai; Qi, Guo-Jun; Hua, Kien A.] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Li, K (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
EM kaili@cs.ucf.edu; guojun.qi@ucf.edu; kienhua@cs.ucf.edu
RI Qi, Guo-Jun/AAH-8294-2019
OI Li, Kai/0000-0003-1560-0853; Qi, Guo-Jun/0000-0003-3508-1851
FU NASA [NNX15AV40A]
FX This material is based upon work partially supported by NASA under Grant
   Number NNX15AV40A. Any opinions, findings, and conclusions or
   recommendations expressed in these materials are those of the authors
   and do not necessarily reflect the views of NASA.
CR [Anonymous], 2014, PR MACH LEARN RES
   [Anonymous], 2013, PMLR
   [Anonymous], 2009, NIPS
   [Anonymous], ARXIV160202255
   [Anonymous], 2016, ARXIV160206697
   Babenko A, 2015, PROC CVPR IEEE, P4240, DOI 10.1109/CVPR.2015.7299052
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cao Y, 2017, AAAI CONF ARTIF INTE, P3974
   Cao Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P197, DOI 10.1145/2911996.2912000
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Ding K, 2017, IEEE T MULTIMEDIA, V19, P571, DOI 10.1109/TMM.2016.2625747
   Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Irie G, 2015, IEEE I CONF COMP VIS, P1886, DOI 10.1109/ICCV.2015.219
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Lai Hanjiang, 2015, IEEE C COMNP VIS PAT
   Li K, 2016, INT PARALL DISTRIB P, P1, DOI 10.1109/IPDPS.2016.126
   Li K, 2017, INT J SEMANT COMPUT, V11, P171, DOI 10.1142/S1793351X17400074
   Li K, 2016, IEEE INT SYM MULTIM, P551, DOI [10.1109/ISM.2016.133, 10.1109/ISM.2016.0121]
   Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253
   Lin GS, 2013, IEEE I CONF COMP VIS, P2552, DOI 10.1109/ICCV.2013.317
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liu Hong Liu, IJCAI 16
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Long MS, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P579, DOI 10.1145/2911451.2911493
   Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225
   Norouzi M.E., 2011, ICML
   Norouzi M, 2012, PROC CVPR IEEE, P3108, DOI 10.1109/CVPR.2012.6248043
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shi XS, 2016, LECT NOTES COMPUT SC, V9911, P419, DOI 10.1007/978-3-319-46478-7_26
   Song Jingkuan, ACM SIGMOD 13, P785
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Wu B., 2015, P 24 INT JOINT C ART
   Zhang Dongqing, AAAI 14
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3025, DOI 10.1109/TIP.2014.2326010
   Zhang SF, 2016, IEEE DATA MINING, P1347, DOI [10.1109/ICDM.2016.0184, 10.1109/ICDM.2016.100]
   Zhang T, 2016, PROC CVPR IEEE, P2036, DOI 10.1109/CVPR.2016.224
   Zhang T, 2015, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2015.7299085
   Zhang YD, 2014, IEEE T MULTIMEDIA, V16, P1127, DOI 10.1109/TMM.2014.2306392
   Zhang ZM, 2016, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2016.649
   Zhen Yi, SIGKDD 12
   Zhen Yi, NIPS 12, P1376
   Zhou Jile, ACM SIGIR 14, P415
NR 51
TC 10
Z9 10
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2018
VL 14
IS 1
AR 2
DI 10.1145/3152126
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FW9HO
UT WOS:000425646500002
DA 2024-07-18
ER

PT J
AU Liu, SC
   Poccia, SR
   Candan, KS
   Sapino, ML
   Wang, XL
AF Liu, Sicong
   Poccia, Silvestro Roberto
   Candan, K. Selcuk
   Sapino, Maria Luisa
   Wang, Xiaolan
TI Robust Multi-Variate Temporal Features of Multi-Variate Time Series
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Robust multi-variate temporal features; multi-variate time series
AB Many applications generate and/or consume multi-variate temporal data, and experts often lack the means to adequately and systematically search for and interpret multi-variate observations. In this article, we first observe that multi-variate time series often carry localized multi-variate temporal features that are robust against noise. We then argue that these multi-variate temporal features can be extracted by simultaneously considering, at multiple scales, temporal characteristics of the time series along with external knowledge, including variate relationships that are known a priori. Relying on these observations, we develop data models and algorithms to detect robust multi-variate temporal (RMT) features that can be indexed for efficient and accurate retrieval and can be used for supporting data exploration and analysis tasks. Experiments confirm that the proposed RMT algorithm is highly effective and efficient in identifying robust multi-scale temporal features of multi-variate time series.
C1 [Liu, Sicong; Candan, K. Selcuk] Arizona State Univ, CIDSE, 699 S Mill Ave, Tempe, AZ 85281 USA.
   [Poccia, Silvestro Roberto; Sapino, Maria Luisa] Univ Torino, Via Pessinetto 12, I-10149 Turin, TO, Italy.
   [Wang, Xiaolan] Univ Massachusetts, Amherst, MA 01003 USA.
   [Wang, Xiaolan] Comp Sci Bldg,140 Governors Dr, Amherst, MA 01003 USA.
C3 Arizona State University; Arizona State University-Tempe; University of
   Turin; University of Massachusetts System; University of Massachusetts
   Amherst
RP Liu, SC (corresponding author), Arizona State Univ, CIDSE, 699 S Mill Ave, Tempe, AZ 85281 USA.
EM s.liu@asu.edu; poccia@di.unito.it; candan@asu.edu; mlsapino@di.unito.it;
   xlwang@cs.umass.edu
RI Sapino, Maria Luisa/C-6257-2011
FU NSF [1339835, 1318788, 1610282, 1633381]; EU-H Marie Sklodowska-Curie
   grant [690817]; Directorate For Engineering; Div Of Civil, Mechanical, &
   Manufact Inn [1610282] Funding Source: National Science Foundation; Div
   Of Information & Intelligent Systems; Direct For Computer & Info Scie &
   Enginr [1318788] Funding Source: National Science Foundation; Office of
   Advanced Cyberinfrastructure (OAC); Direct For Computer & Info Scie &
   Enginr [1339835] Funding Source: National Science Foundation
FX This work is supported by NSF#1339835, "SI2-SSE: E-SDMS: Energy
   Simulation Data Management System Software"; NSF#1318788, "Data
   Management for Real-Time Data Driven Epidemic Spread Simulations";
   NSF#1610282, "DataStorm: A Data Enabled System for End-to-End Disaster
   Planning and Response"; NSF#1633381, "BIGDATA: Discovering
   Context-Sensitive Impact in Complex Systems"; and EU-H2020 Marie
   Sklodowska-Curie grant agreement No 690817, "FourCModeling."
CR [Anonymous], 1983, INTRO MODERN INFORM
   [Anonymous], 2005, thesis
   Batal Iyad, 2012, KDD, V2012, P280
   Bemdt D., 1994, Using Dynamic Time Warping to FindPatterns in Time Series
   Blei DM, 2006, P 23 INT C MACH LEAR, P113
   Candan K.S., 2010, Data Management for Multimedia Retrieval
   Candan KS, 2012, PROC VLDB ENDOW, V5, P1519, DOI 10.14778/2350229.2350266
   Castro N.Azevedo., 2010, P SIAM INT C DATA MI, P665
   Chen L, 2004, P 30 INT C VER LARG, V30, P792, DOI [DOI 10.1016/B978-012088469-8.50070-X, DOI 10.1016/B978-012088469-8/50070-X]
   Chen Y., 2015, UCR TIME SERIES CLAS
   Chung F. -L., 2001, INT JOINT C ART INT, P1
   de Silva A, 2010, STAT MODEL, V10, P353, DOI 10.1177/1471082X0901000401
   Ding H, 2008, PROC VLDB ENDOW, V1, P1542
   Eichler Michael, 2006, J ECONOMETR
   Esling P, 2012, ACM COMPUT SURV, V45, DOI 10.1145/2379776.2379788
   GARG Y, 2017, ICMR, P489, DOI DOI 10.1145/3078971.3079009
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Harvey A.C., 1997, SYSTEM DYNAMICS EC F
   Hopkins A. S., 2011, SIMULATING NATL REPR, P55
   Ji X, 2007, KNOWL INF SYST, V11, P259, DOI 10.1007/s10115-006-0038-2
   Jin YH, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1925101.1925104
   Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9
   Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406
   Keogh Eamonn J., 2013, 2013 SIAM international conference on data mining, P668, DOI DOI 10.1137/1.9781611972832.74
   Kim DJ, 2011, PERVASIVE MOB COMPUT, V7, P727, DOI 10.1016/j.pmcj.2011.09.006
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   KRUSKAL JB, 1983, SIAM REV, V25, P201, DOI 10.1137/1025045
   KRZANOWSKI WJ, 1979, J AM STAT ASSOC, V74, P703, DOI 10.2307/2286995
   Li CJ, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1236471.1236475
   Li L, 2010, PROC VLDB ENDOW, V3, P385, DOI 10.14778/1920841.1920893
   Lin J., 2003, 8THACM SIGMOD WORKSH, DOI [10.1145/882082. 882086, DOI 10.1145/882082.882086]
   Liu Sicong, 2015, P AAAI INT WORKSH CO
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mehta S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P287, DOI 10.1109/ICHI.2013.41
   Mills T. C., 1990, Time Series Techniques for Economists
   Mocap, 2001, CMU MOC DAT SET
   Mohammad Y, 2009, NEW GENERAT COMPUT, V27, P319, DOI 10.1007/s00354-009-0068-x
   Morchen F., 2003, TIME SERIES FEATURE
   Peng JL, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2039, DOI 10.1145/2882903.2882963
   Perng C.-S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P33, DOI 10.1109/ICDE.2000.839385
   Poccia S.R., 2017, 20 INT C EXTENDING D, P582
   Rakthanmanon Thanawin, 2012, KDD, V2012, P262, DOI 10.1145/2339530.2339576
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Sanguansat Parinya, 2012, WSEAS Transactions on Mathematics, V11, P684
   Shuai L, 2017, IEEE T VIS COMPUT GR, V23, P1085, DOI 10.1109/TVCG.2016.2520926
   Vespier Ugo, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P371, DOI 10.1007/978-3-642-33486-3_24
   Vlachos M, 2006, VLDB J, V15, P1, DOI 10.1007/s00778-004-0144-2
   Wang X., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, P430
   Wang XL, 2014, PROC INT CONF DATA, P388, DOI 10.1109/ICDE.2014.6816667
   Yang K., 2004, ACM INT WORKSHOP MUL, P65, DOI DOI 10.1145/1032604.1032616
   Yankov D, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P844
   Ye LX, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P947
NR 53
TC 3
Z9 4
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2018
VL 14
IS 1
AR 7
DI 10.1145/3152123
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FW9HO
UT WOS:000425646500007
OA Green Published
DA 2024-07-18
ER

PT J
AU Kleinrouweler, JW
   Cabrero, S
   Cesar, P
AF Kleinrouweler, Jan Willem
   Cabrero, Sergio
   Cesar, Pablo
TI An SDN Architecture for Privacy-Friendly Network-Assisted DASH
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE DASH; HTTP adaptive streaming; video streaming; network assistance;
   Wi-Fi; performance
ID VIDEO QUALITY
AB Dynamic Adaptive Streaming over HTTP (DASH) is the premier technology for Internet video streaming. DASH efficiently uses existing HTTP-based delivery infrastructures implementing adaptive streaming. However, DASH traffic is bursty in nature. This causes performance problems when DASH players share a network connection or in networks with heavy background traffic. The result is unstable and lower quality video. In this article, we present the design and implementation of a so-called DASH Assisting Network Element (DANE). Our system provides target bitrate signaling and dynamic traffic control. These two mechanisms realize proper bandwidth sharing among clients. Our system is privacy friendly and fully supports encrypted video streams. Trying to improve the streaming experience for users who share a network connection, our system increases the video bitrate and reduces the number of quality switches. We show this through evaluations in our Wi-Fi testbed.
C1 [Kleinrouweler, Jan Willem; Cabrero, Sergio; Cesar, Pablo] Ctr Wiskunde & Informat, Sci Pk 123, NL-1098 XG Amsterdam, Netherlands.
   [Cesar, Pablo] Delft Univ Technol, Mekelweg 4, NL-2628 CD Delft, Netherlands.
C3 Delft University of Technology
RP Kleinrouweler, JW (corresponding author), Ctr Wiskunde & Informat, Sci Pk 123, NL-1098 XG Amsterdam, Netherlands.
EM j.w.m.kleinrouweler@cwi.nl; cabrero@cwi.nl; p.s.cesar@cwi.nl
OI Cesar, Pablo/0000-0003-1752-6837
CR [Anonymous], P 27 INT TEL C ITC 2
   [Anonymous], ABS160106748 CORR
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], BEST IET IBC
   [Anonymous], 2014, 230091 ISOIEC
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], GLOB INT PHEN REP LA
   [Anonymous], 2015, WHY YOUTUBE NETFLIX
   Bouten N., 2012, 2012 8th International Conference on Network and Service Management (CNSM 2012), P336
   Cranley N, 2006, INT J HUM-COMPUT ST, V64, P637, DOI 10.1016/j.ijhcs.2005.12.002
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   Dobrian F, 2013, COMMUN ACM, V56, P91, DOI 10.1145/2428556.2428577
   Georgopoulos P., 2013, Proceedings of the 2013 ACM SIGCOMM Workshop on Future Human-centric Multimedia Networking, FhMN '13, (New York, NY, USA), P15, DOI DOI 10.1145/2491172.2491181
   Hamberg R, 1999, SMPTE J, V108, P802, DOI 10.5594/J04337
   Hossfeld T, 2015, COMPUT NETW, V81, P320, DOI 10.1016/j.comnet.2015.02.015
   Houdaille R., 2012, P 3 MULTIMEDIA SYSTE, P1
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Jarnikov D, 2011, SIGNAL PROCESS-IMAGE, V26, P378, DOI 10.1016/j.image.2011.03.003
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Kleinrouweler JW, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P36, DOI 10.1145/2910017.2910599
   Lohmar T., 2012, 22nd ACM Workshop on Network and Operating System Support for Digital Audio and Video (NOSSDAV), P21
   McKeown N, 2008, ACM SIGCOMM COMP COM, V38, P69, DOI 10.1145/1355734.1355746
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Petrangeli S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818361
   Robinson DC, 2012, BELL LABS TECH J, V16, P5, DOI 10.1002/bltj.20531
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
NR 26
TC 8
Z9 9
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2017
VL 13
IS 3
SU S
AR 44
DI 10.1145/3092838
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FP1UO
UT WOS:000417400400012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Vandecasteele, F
   Vandenbroucke, K
   Schuurman, D
   Verstockt, S
AF Vandecasteele, Florian
   Vandenbroucke, Karel
   Schuurman, Dimitri
   Verstockt, Steven
TI Spott: On-the-Spot e-Commerce for Television Using Deep Learning-Based
   Video Analysis Techniques
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Interactive television; video summarization; deep learning; object
   recognition; metadata enrichment; experience studies; user-validation
AB Spott is an innovative second screen mobile multimedia application which offers viewers relevant information on objects (e.g., clothing, furniture, food) they see and like on their television screens. The application enables interaction between TV audiences and brands, so producers and advertisers can offer potential consumers tailored promotions, e-shop items, and/or free samples. In line with the current views on innovation management, the technological excellence of the Spott application is coupled with iterative user involvement throughout the entire development process. This article discusses both of these aspects and how they impact each other. First, we focus on the technological building blocks that facilitate the (semi-) automatic interactive tagging process of objects in the video streams. The majority of these building blocks extensively make use of novel and state-of-the-art deep learning concepts and methodologies. We show how these deep learning based video analysis techniques facilitate video summarization, semantic keyframe clustering, and (similar) object retrieval. Secondly, we provide insights in user tests that have been performed to evaluate and optimize the application's user experience. The lessons learned from these open field tests have already been an essential input in the technology development and will further shape the future modifications to the Spott application.
C1 [Vandecasteele, Florian; Verstockt, Steven] Univ Ghent, IMEC, Ghent, Belgium.
   [Vandecasteele, Florian; Verstockt, Steven] ELIS, IDLab, Paris, France.
   [Vandenbroucke, Karel; Schuurman, Dimitri] Univ Ghent, IMEC, MICT, Ghent, Belgium.
C3 IMEC; Ghent University; IMEC; Ghent University
RP Vandecasteele, F (corresponding author), Univ Ghent, IMEC, Ghent, Belgium.; Vandecasteele, F (corresponding author), ELIS, IDLab, Paris, France.
EM florian.vandecasteele@ugent.be
RI Schuurman, Dimitri/JWP-7525-2024
OI Schuurman, Dimitri/0000-0003-4006-0596
FU Ghent University; iMinds; Institute for the Promotion of Innovation by
   Science and Technology in Flanders (IWT); Appiness bvba; IWT/VLAIO O&O
   Spotshop project
FX The research activities as described in this article were funded by
   Ghent University, iMinds, the Institute for the Promotion of Innovation
   by Science and Technology in Flanders (IWT) and Appiness bvba. This work
   is supported by the IWT/VLAIO O&O Spotshop project. The project's
   related e-commerce service - under the name "Spott" - was launched on
   the market by project partner Appiness (20/04/16). Other project
   partners are Medialaan and BBDO. (More info:
   http://www.iminds.be/en/projects/spotshop).
CR Ajmal M, 2012, LECT NOTES COMPUT SC, V7594, P1, DOI 10.1007/978-3-642-33564-8_1
   [Anonymous], 2014, P ASIAN C COMP VIS A
   Baraldi L, 2015, LECT NOTES COMPUT SC, V9256, P801, DOI 10.1007/978-3-319-23192-1_67
   Belo LD, 2016, NEUROCOMPUTING, V173, P1001, DOI 10.1016/j.neucom.2015.08.057
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   De Marez Lieven, 2007, OBSERVATORIO, V1, P3
   iMinds Digimeter, 2014, RES REPORT
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8
   Lieven D.M., 2004, Journal of Targeting, Measurement Analysis for Marketing, V13, P32, DOI DOI 10.1057/PALGRAVE.JT.5740130
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu KH, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P313, DOI 10.1145/2911996.2912058
   Qiu XK, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1517, DOI 10.1109/ICME.2008.4607735
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rogers E. M., 1983, Diffusions of innovations, DOI DOI 10.1007/978-3-642-79868-9_2
   Schuurman D., 2015, Bridging the gap between Open and User Innovation? Exploring the value of Living Labs as a means to structure user contribution and manage distributed innovation
   Tang Yuxing, 2016, P IEEE C COMP VIS PA
   Vandecasteele Florian, 2016, P INT C HUM COMP INT, P448
   Vandenbroucke Karel, 2016, IMINDS APPINESS MEDI
   Wang F, 2012, IEEE T MULTIMEDIA, V14, P76, DOI 10.1109/TMM.2011.2165531
   Wang H., 2015, MULTIMEDIA DATA MINI, P253
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zagoruyko S., 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 27
TC 6
Z9 6
U1 0
U2 17
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2017
VL 13
IS 3
SU S
AR 38
DI 10.1145/3092834
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FP1UO
UT WOS:000417400400006
OA Green Published
DA 2024-07-18
ER

PT J
AU Wu, TT
   Dou, WC
   Wu, F
   Tang, SJ
   Hu, CH
   Chen, JJ
AF Wu, Taotao
   Dou, Wanchun
   Wu, Fan
   Tang, Shaojie
   Hu, Chunhua
   Chen, Jinjun
TI A Deployment Optimization Scheme Over Multimedia Big Data for
   Large-Scale Media Streaming Application
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Large-scale media streaming application; multimedia big data; cloud;
   local memory; deployment optimization
ID ON-DEMAND
AB With the prosperity of media streaming applications over the Internet in the past decades, multimedia data has sharply increased (categorized as multimedia big data), which exerts more pressure on the infrastructure, such as networking of the application provider. In order to move this hurdle, an increasing number of traditional media streaming applications have migrated from a private server cluster onto the cloud. With the elastic resource provisioning and centralized management of the cloud, the operational costs of media streaming application providers can decrease dramatically. However, to the best of our knowledge, existing migration solutions do not fully take viewer information such as hardware condition into consideration. In this article, we consider the deployment optimization problem named ODP by leveraging local memories at each viewer. Considering the NP-hardness of calculating the optimal solution, we turn to propose computationally tractable algorithms. Specifically, we unfold the original problem into two interactive subproblems: coarse-grained migration subproblem and fine-grained scheduling subproblem. Then, the corresponding offline approximation algorithms with performance guarantee and computational efficiency are given. The results of extensive evaluation show that compared with the baseline algorithm without leveraging local memories at viewers, our proposed algorithms and their online versions can decrease total bandwidth reservation and enhance the utilization of bandwidth reservation dramatically.
C1 [Wu, Taotao; Dou, Wanchun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
   [Wu, Taotao; Chen, Jinjun] Univ Technol Sydney, Fac Engn & IT, Sydney, NSW 2007, Australia.
   [Wu, Fan] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Tang, Shaojie] Univ Texas Dallas, Dept Informat Syst, Richardson, TX 75083 USA.
   [Hu, Chunhua] Hunan Univ, Sch Comp & Informat Engn, Changsha, Hunan, Peoples R China.
C3 Nanjing University; University of Technology Sydney; Shanghai Jiao Tong
   University; University of Texas System; University of Texas Dallas;
   Hunan University
RP Dou, WC (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
EM wutaotaoxpy@gmail.com; douwc@nju.edu.cn; fwu@cs.sjtu.edu.cn;
   tangshaojie@gmail.com; huchunhua777@163.com; jinjun.chen@gmail.com
RI Chen, Jinjun/AAP-2361-2020; WU, FAN/GRX-1654-2022; Wu, Fan/J-9583-2019
OI Wu, Fan/0000-0003-3615-1217; Chen, Jinjun/0000-0003-1677-9525
FU National Science Foundation of China [91318301, 61273232, 61321491]; Key
   Research and Development Project of Jiangsu Province [BE2015154];
   Collaborative Innovation Center of Novel Software Technology and
   Industrialization, Nanjing University; Program for New Century Excellent
   Talents in University [NCET-13-0785]
FX This research is partially supported by the National Science Foundation
   of China under Grant No. 91318301, No. 61273232, and No. 61321491; the
   Key Research and Development Project of Jiangsu Province under Grant No.
   BE2015154; and the Collaborative Innovation Center of Novel Software
   Technology and Industrialization, Nanjing University. The research is
   also partly supported by the Program for New Century Excellent Talents
   in University under NCET-13-0785.
CR Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   Aggarwal V, 2013, IEEE T MULTIMEDIA, V15, P789, DOI 10.1109/TMM.2013.2240287
   Amble MM, 2011, IEEE INFOCOM SER, P2858, DOI 10.1109/INFCOM.2011.5935123
   Bar-Noy A, 2008, THEOR COMPUT SCI, V399, P3, DOI 10.1016/j.tcs.2008.02.003
   Boyang Yu, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P603, DOI 10.1109/INFOCOM.2015.7218428
   Chen FF, 2012, IEEE INFOCOM SER, P433, DOI 10.1109/INFCOM.2012.6195782
   Chvatal V., 1979, Mathematics of Operations Research, V4, P233, DOI 10.1287/moor.4.3.233
   Fleischer R, 2001, THEOR COMPUT SCI, V268, P161, DOI 10.1016/S0304-3975(00)00266-8
   Gabale V., 2012, 2012 IEEE 20 INT WOR, P1
   Guo J, 2013, IEEE INFOCOM SER, P2139
   Haitao Li, 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P203, DOI 10.1109/CLOUD.2011.41
   Hajjat M, 2010, ACM SIGCOMM COMP COM, V40, P243, DOI 10.1145/1851275.1851212
   Korte B, 2012, ALGORITHMS COMB, V21, P1, DOI 10.1007/978-3-642-24488-9
   Laoutaris N, 2007, IEEE INFOCOM SER, P2144, DOI 10.1109/INFCOM.2007.248
   Leblet J, 2011, COMPUT COMMUN, V34, P1968, DOI 10.1016/j.comcom.2011.06.002
   Li H, 2016, IEEE T EMERG TOP COM, V4, P266, DOI 10.1109/TETC.2016.2517930
   Li H, 2015, IEEE CLOUD COMPUT, V2, P42, DOI 10.1109/MCC.2015.114
   Li H, 2015, COMPUT J, V58, P1373, DOI 10.1093/comjnl/bxu122
   Niu D, 2012, IEEE INFOCOM SER, P460, DOI 10.1109/INFCOM.2012.6195785
   Pathan M, 2009, LECT NOTES COMPUT SC, V5802, P13, DOI 10.1007/978-3-642-04409-0_7
   Pujol J. M., 2010, COMPUT COMMUN REV, P1162
   Qiu XJ, 2012, IEEE INFOCOM SER, P2571, DOI 10.1109/INFCOM.2012.6195655
   Scellato S., 2011, Proceedings of the 20th International Conference on World Wide Web, P457
   Shen HY, 2014, IEEE INFOCOM SER, P835, DOI 10.1109/INFOCOM.2014.6848011
   Wang F.-K., 2014, Journal of Applied Mathematics, V2014, P1, DOI DOI 10.1155/2014/643785
   Wang W, 2015, IEEE T PARALL DISTR, V26, P3407, DOI 10.1109/TPDS.2014.2385697
   Wenjie Hu, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P1185, DOI 10.1109/INFOCOM.2015.7218493
   Wu T., 2015, TECHNICAL REPORT
   Wu Y, 2012, IEEE INFOCOM SER, P684, DOI 10.1109/INFCOM.2012.6195813
   Xi ZY, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTERS, COMMUNICATIONS, AND SYSTEMS (ICCCS), P252, DOI 10.1109/CCOMS.2015.7562910
   Yu L, 2014, INT CON DISTR COMP S, P258, DOI 10.1109/ICDCS.2014.34
   Zhang H, 2009, 2009 IEEE CONGRESS ON SERVICES (SERVICES-1 2009), VOLS 1 AND 2, P701, DOI 10.1109/SERVICES-I.2009.26
   Zhao YH, 2014, IEEE INFOCOM SER, P298, DOI 10.1109/INFOCOM.2014.6847951
   Zink M., 2008, SPIE IS T MULTIMEDIA
NR 34
TC 7
Z9 8
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2016
VL 12
IS 5
SU S
AR 73
DI 10.1145/2983642
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ0VT
UT WOS:000392929700004
DA 2024-07-18
ER

PT J
AU Tang, JH
   Shu, XB
   Li, ZC
   Qi, GJ
   Wang, JD
AF Tang, Jinhui
   Shu, Xiangbo
   Li, Zechao
   Qi, Guo-Jun
   Wang, Jingdong
TI Generalized Deep Transfer Networks for Knowledge Propagation in
   Heterogeneous Domains
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous-domain knowledge propagation; cross-domain label transfer;
   deep transfer network; image classification
AB In recent years, deep neural networks have been successfully applied to model visual concepts and have achieved competitive performance on many tasks. Despite their impressive performance, traditional deep networks are subjected to the decayed performance under the condition of lacking sufficient training data. This problem becomes extremely severe for deep networks trained on a very small dataset, making them overfitting by capturing nonessential or noisy information in the training set. Toward this end, we propose a novel generalized deep transfer networks (DTNs), capable of transferring label information across heterogeneous domains, textual domain to visual domain. The proposed framework has the ability to adequately mitigate the problem of insufficient training images by bringing in rich labels from the textual domain. Specifically, to share the labels between two domains, we build parameter-and representation-shared layers. They are able to generate domain-specific and shared interdomain features, making this architecture flexible and powerful in capturing complex information from different domains jointly. To evaluate the proposed method, we release a new dataset extended from NUS-WIDE at http://imag.njust.edu.cn/NUS-WIDE-128.html. Experimental results on this dataset show the superior performance of the proposed DTNs compared to existing state-of-the-art methods.
C1 [Tang, Jinhui; Shu, Xiangbo; Li, Zechao] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Qi, Guo-Jun] Univ Cent Florida, Coll Engn & Comp Sci, Orlando, FL 32816 USA.
   [Wang, Jingdong] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Nanjing University of Science & Technology; State University System of
   Florida; University of Central Florida; Microsoft Research Asia;
   Microsoft
RP Shu, XB (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM jinhuitang@njust.edu.cn; shuxb104@gmail.com; zechao.li@njust.edu.cn;
   guojun.qi@ucf.edu; jingdw@microsoft.com
RI Wang, Jingdong/E-9920-2017; Shu, Xiangbo/AAC-6245-2022; Tang,
   Jinhui/KBR-0891-2024; Qi, Guo-Jun/AAH-8294-2019
OI Wang, Jingdong/0000-0002-4888-4445; Shu, Xiangbo/0000-0003-4902-4663;
   Qi, Guo-Jun/0000-0003-3508-1851; Tang, Jinhui/0000-0001-9008-222X
FU 973 Program of China [2014CB347600]; National Natural Science Foundation
   of China [61522203, 61402228]; National Ten Thousand Talent Program of
   China (Young Top-Notch Talent)
FX This work was partially supported by the 973 Program of China (project
   2014CB347600), the National Natural Science Foundation of China (grants
   61522203 and 61402228), and the National Ten Thousand Talent Program of
   China (Young Top-Notch Talent).
CR [Anonymous], 2011, P INT C MACH LEARN I
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], P INT C WORLD WID WE
   [Anonymous], 2013, ADV NEURAL INFORM PR
   [Anonymous], ARXIV14022031
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P INT C MACH LEARN I
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P INT C MACH LEARN I
   [Anonymous], P INT C MACH LEARN I
   [Anonymous], ARXIV150300591
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], ARXIV150904942
   [Anonymous], ARXIV14126257
   [Anonymous], 2012, ACM MM'12'
   [Anonymous], ARXIV150408215
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2012, ARXIV12065538V1
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], 2009, JMLR P
   [Anonymous], P AAAI C ART INT AAA
   [Anonymous], P INT C MACH LEARN I
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P VLDB ENDOWMENT
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], P C IM VID RETR CIVR
   [Anonymous], 2011, P INT C MACH LEARN I
   [Anonymous], P INT C COMP VIS ICC
   Ba J., 2013, Advances in neural information processing systems, P3084
   Bengio Y., 2012, UNSUPERVISED TRANSFE, V7, P19
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Feng FX, 2015, NEUROCOMPUTING, V154, P50, DOI 10.1016/j.neucom.2014.12.020
   Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang Y.-G., 2009, Proc. ACM MM, P155, DOI DOI 10.1145/1631272.1631296
   Kandaswamy C, 2014, IEEE SYS MAN CYBERN, P1380, DOI 10.1109/SMC.2014.6974107
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Ou XY, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P969, DOI 10.1145/2647868.2654987
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216
   Song XN, 2016, MULTIMEDIA SYST, V22, P41, DOI 10.1007/s00530-014-0390-0
   Tang JH, 2015, IEEE T MULTIMEDIA, V17, P1899, DOI 10.1109/TMM.2015.2476660
   Tang JM, 2016, INT J POLYM SCI, V2016, DOI 10.1155/2016/8458752
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Weston Jason, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P639, DOI 10.1007/978-3-642-35289-8_34
   Xu P, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P107, DOI 10.1145/2647868.2654914
   Yang XS, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700286
   Zhang Y, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/423581
NR 57
TC 123
Z9 125
U1 4
U2 22
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2016
VL 12
IS 4
SU S
AR 68
DI 10.1145/2998574
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI8DS
UT WOS:000392736100012
DA 2024-07-18
ER

PT J
AU Sun, SY
   Zhou, WG
   Tian, Q
   Li, HQ
AF Sun, Shaoyan
   Zhou, Wengang
   Tian, Qi
   Li, Houqiang
TI Scalable Object Retrieval with Compact Image Representation from Generic
   Object Regions
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Experimentation; Performance; Image retrieval; compact image
   representation
ID CODEBOOK; CONTEXT
AB In content-based visual object retrieval, image representation is one of the fundamental issues in improving retrieval performance. Existing works adopt either local SIFT-like features or holistic features, and may suffer sensitivity to noise or poor discrimination power. In this article, we propose a compact representation for scalable object retrieval from few generic object regions. The regions are identified with a general object detector and are described with a fusion of learning-based features and aggregated SIFT features. Further, we compress feature representation in large-scale image retrieval scenarios. We evaluate the performance of the proposed method on two public ground-truth datasets, with promising results. Experimental results on a million-scale image database demonstrate superior retrieval accuracy with efficiency gain in both computation and memory usage.
C1 [Sun, Shaoyan; Zhou, Wengang; Li, Houqiang] Univ Sci & Technol China, Elect Engn & Informat Sci Dept, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China.
   [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; University of Texas System; University of Texas at San
   Antonio (UTSA)
RP Sun, SY; Zhou, WG; Li, HQ (corresponding author), Univ Sci & Technol China, Elect Engn & Informat Sci Dept, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China.; Tian, Q (corresponding author), Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
EM sunshy@mail.ustc.edu.cn; zhwg@ustc.edu.cn; qitian@cs.utsa.edu;
   lihq@ustc.edu.cn
RI Li, Houqiang Li/B-6259-2013
FU 973 Program [2015CB351803]; NSFC [61325009, 61390514, 61472378,
   61429201]; Fundamental Research Funds for the Central Universities
   [WK2100060014, WK2100060011]; ARO [W911NF-12-1-0057]; Faculty Research
   Awards by NEC Laboratories of America
FX This work was supported in part for Professor Houqiang Li by 973 Program
   under contract No. 2015CB351803, NSFC under contract No. 61325009 and
   No. 61390514; in part for Dr. Wengang Zhou by NSFC under contract No.
   61472378 and the Fundamental Research Funds for the Central Universities
   under contract No. WK2100060014 and WK2100060011; and in part for Prof.
   Qi Tian by ARO grant W911NF-12-1-0057 and Faculty Research Awards by NEC
   Laboratories of America, respectively. This work was supported in part
   by NSFC under contract No. 61429201.
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2014, P INT C INT MULT COM
   [Anonymous], P INT C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Chu LY, 2014, IEEE INT CON MULTI
   Chu LY, 2013, IEEE T MULTIMEDIA, V15, P1982, DOI 10.1109/TMM.2013.2270455
   Chum O, 2010, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2010.5539997
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Felzenszwalb P., 2008, P IEEE C COMPUTER VI
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Hoi SCH, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823752
   Horster E., 2008, Proceedings of the 16th ACM international conference on Multimedia, P643
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Kadir T, 2004, LECT NOTES COMPUT SC, V3021, P228
   Krizhevsky A., 2012, NEURAL INFORM PROCES, V78, P523
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu Z, 2015, IEEE T MULTIMEDIA, V17, P538, DOI 10.1109/TMM.2015.2399851
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Nister David, 2006, CVPR
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V23, P287, DOI 10.1109/TIP.2013.2264677
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang S, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700292
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Wengert C., 2011, P 19 ACM INT C MULT, P1437, DOI [DOI 10.1145/2072298.2072034, 10.1145/2072298.2072034]
   Xie LX, 2015, IEEE T MULTIMEDIA, V17, P636, DOI 10.1109/TMM.2015.2408566
   Xie LX, 2014, COMPUT VIS IMAGE UND, V124, P31, DOI 10.1016/j.cviu.2013.12.011
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
   Zhang SL, 2011, IEEE T IMAGE PROCESS, V20, P2664, DOI 10.1109/TIP.2011.2128333
   Zhou WG, 2014, J COMPUT SCI TECH-CH, V29, P837, DOI 10.1007/s11390-014-1472-3
   Zhou WG, 2015, IEEE T IMAGE PROCESS, V24, P967, DOI 10.1109/TIP.2015.2389624
   Zhou WG, 2014, IEEE T MULTIMEDIA, V16, P601, DOI 10.1109/TMM.2014.2301979
   Zhou WG, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422960
   Zhou WG, 2011, PATTERN RECOGN, V44, P2263, DOI 10.1016/j.patcog.2010.08.016
NR 56
TC 22
Z9 23
U1 0
U2 21
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2016
VL 12
IS 2
AR 29
DI 10.1145/2818708
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ0PK
UT WOS:000373906200003
OA Bronze
DA 2024-07-18
ER

PT J
AU Liu, LQ
   Xing, JL
   Liu, S
   Xu, H
   Zhou, X
   Yan, SC
AF Liu, Luoqi
   Xing, Junliang
   Liu, Si
   Xu, Hui
   Zhou, Xi
   Yan, Shuicheng
TI "Wow! You Are So Beautiful Today!"
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Experimentation; Performance; Beauty recommendation; beauty
   synthesis; multiple tree-structured super-graphs model
AB Beauty e-Experts, a fully automatic system for makeover recommendation and synthesis, is developed in this work. The makeover recommendation and synthesis system simultaneously considers many kinds of makeover items on hairstyle and makeup. Given a user-provided frontal face image with short/bound hair and no/light makeup, the Beauty e-Experts system not only recommends the most suitable hairdo and makeup, but also synthesizes the virtual hairdo and makeup effects. To acquire enough knowledge for beauty modeling, we built the Beauty e-Experts Database, which contains 1,505 female photos with a variety of attributes annotated with different discrete values. We organize these attributes into two different categories, beauty attributes and beauty-related attributes. Beauty attributes refer to those values that are changeable during the makeover process and thus need to be recommended by the system. Beauty-related attributes are those values that cannot be changed during the makeup process but can help the system to perform recommendation. Based on this Beauty e-Experts Dataset, two problems are addressed for the Beauty e-Experts system: what to recommend and how to wear it, which describes a similar process of selecting hairstyle and cosmetics in daily life. For the what-to-recommend problem, we propose a multiple tree-structured supergraph model to explore the complex relationships among high-level beauty attributes, mid-level beauty-related attributes, and low-level image features. Based on this model, the most compatible beauty attributes for a given facial image can be efficiently inferred. For the how-to-wear-it problem, an effective and efficient facial image synthesis module is designed to seamlessly synthesize the recommended makeovers into the user facial image. We have conducted extensive experiments on testing images of various conditions to evaluate and analyze the proposed system. The experimental results well demonstrate the effectiveness and efficiency of the proposed system.
C1 [Liu, Luoqi; Liu, Si; Yan, Shuicheng] Natl Univ Singapore, Singapore 117548, Singapore.
   [Xing, Junliang] Chinese Acad Sci, Inst Automat, Beijing 100864, Peoples R China.
   [Xu, Hui; Zhou, Xi] Chinese Acad Sci, Chongqing Inst Green & Intelligent Technol, Beijing 100864, Peoples R China.
C3 National University of Singapore; Chinese Academy of Sciences; Institute
   of Automation, CAS; Chinese Academy of Sciences; Chongqing Institute of
   Green & Intelligent Technology, CAS
RP Liu, LQ (corresponding author), Natl Univ Singapore, Singapore 117548, Singapore.
EM a0092770@nus.edu.sg; jlxing@nlpr.ia.ac.cn; dcslius@nus.edu.sg;
   xuhui@cigit.ac.cn; zhouxi@cigit.ac.cn; eleyans@nus.edu.sg
RI Yan, Shuicheng/HCI-1431-2022; Xing, Junliang/HGE-9630-2022
OI Xing, Junliang/0000-0001-6801-0510
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   AUCOIN Kevyn., 2000, Face Forward
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berg M., 2008, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-3-540-77974-2
   Bookstein Fred L., 1989, IEEE T PATTERN ANAL, V3
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Fangmei, 2010, P INT C MED BIOM
   Chow C., 1968, IEEE T INF THEORY
   Cootes Timothy, 1995, COMPUT VISION IMAGE
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dalal N., CVPR, P886, DOI [DOI 10.1109/CVPR.2005.177, 10.1109/CVPR.2005.177]
   Felzenszwalb P. F., 2009, PAMI, V32, P1627, DOI [DOI 10.1109/TPAMI.2009.167, 10.1109/TPAMI.2009.167]
   Goshtasby Ardeshir, 1986, PATTERN RECOGN
   Guo Dong, 2009, P IEEE C COMP VIS PA
   Haykin S, 1999, NEURAL NETWORKS
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Huang Gary, 2007, TECHNICAL REPORT
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Jolliffe I., 2002, Encyclopedia of Statistics in Behavioral Science
   Jones M., 1999, P IEEE C COMP VIS PA
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Levin Anat, 2007, P IEEE C COMP VIS PA
   Liu Luoqi, 2013, P 21 ACM INT C ACM M
   Liu Si, 2012, P 20 ACM INT C ACM M
   Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83
   Nagai Yuki, 2005, U.S. Patent, Patent No. [US20050251463 A1, 20050251463]
   Rother Carsten, 2004, ACM T GRAPH
   Scherbaum K, 2011, COMPUT GRAPH FORUM, V30, P485, DOI 10.1111/j.1467-8659.2011.01874.x
   Siddiquie B., 2011, P IEEE C COMP VIS PA
   Tong Wai, 2007, P IEEE INT C AUT FAC
   Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001
   Wang Nan, 2012, P IEEE C COMP VIS PA
   Wang Yang, 2010, P EUR C COMP VIS
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Yi Y., 2011, P IEEE C COMP VIS PA
NR 36
TC 36
Z9 42
U1 1
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2014
VL 11
IS 1
SU S
SI SI
AR 20
DI 10.1145/2659234
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS0RG
UT WOS:000343984800012
DA 2024-07-18
ER

PT J
AU Wang, F
   Zhao, WL
   Ngo, CW
   Merialdo, B
AF Wang, Feng
   Zhao, Wan-Lei
   Ngo, Chong-Wah
   Merialdo, Bernard
TI A Hamming Embedding Kernel with Informative Bag-of-Visual Words for
   Video Semantic Indexing
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Experimentation; Performance; Bag-of-visual word; Hamming
   embedding; kernel optimization; video semantic indexing
ID UNIVERSAL; SCALE
AB In this article, we propose a novel Hamming embedding kernel with informative bag-of-visual words to address two main problems existing in traditional BoW approaches for video semantic indexing. First, Hamming embedding is employed to alleviate the information loss caused by SIFT quantization. The Hamming distances between keypoints in the same cell are calculated and integrated into the SVM kernel to better discriminate different image samples. Second, to highlight the concept-specific visual information, we propose to weight the visual words according to their informativeness for detecting specific concepts. We show that our proposed kernels can significantly improve the performance of concept detection.
C1 [Wang, Feng] E China Normal Univ, Dept Comp Sci & Technol, Shanghai 200241, Peoples R China.
   [Zhao, Wan-Lei; Ngo, Chong-Wah] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 East China Normal University; City University of Hong Kong
RP Wang, F (corresponding author), E China Normal Univ, Dept Comp Sci & Technol, 500 Dongchuan Rd, Shanghai 200241, Peoples R China.
EM fwang@cs.ecnu.edu.cn
OI Ngo, Chong Wah/0000-0003-4182-8261
FU City University of Hong Kong [7008178]; National Natural Science
   Foundation of China [61103127, 61375016]; Shanghai Pujiang Program [12PJ
   1402700]; Fundamental Research Funds for the Central Universities
FX The work described in this article was partially supported by a grant
   from City University of Hong Kong (project no. 7008178), the National
   Natural Science Foundation of China (nos. 61103127 and 61375016),
   Shanghai Pujiang Program (no. 12PJ 1402700), and the Fundamental
   Research Funds for the Central Universities.
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], INT J COMPUT VIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], NIST TRECVID WORKSH
   [Anonymous], 2006, P IEEE C COMP VIS PA
   [Anonymous], 2008, P 31 ANN INT ACM SIG
   [Anonymous], 2003, Dep. Pap. (CIS)
   [Anonymous], P IEEE C COMP VIS
   [Anonymous], COMPUTER VISION
   [Anonymous], NIST TRECVID WORKSH
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P 2 ACM INT C MULT R
   [Anonymous], P INT C IM VID RETR
   [Anonymous], 2002, P ACM S THEOR COMP
   [Anonymous], P S THEOR COMP
   [Anonymous], NIST TRECVID WORKSH
   [Anonymous], LIBSVM
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2008, P 7 ACM INT C IMAGE
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2005, Learning Task-Specific Similarity
   [Anonymous], GUIDELINES TRECVID
   [Anonymous], P INT WORKSH VER LAR
   [Anonymous], P IEEE INT WORKSH MU
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], NIST TRECVID WORKSH
   [Anonymous], 2008, P VIS COMP SCI BCS I
   Cai HP, 2011, IEEE T PATTERN ANAL, V33, P338, DOI 10.1109/TPAMI.2010.89
   Cristianini N, 2002, ADV NEUR IN, V14, P367
   Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15
   He XF, 2004, ADV NEUR IN, V16, P153
   Igel C, 2007, IEEE ACM T COMPUT BI, V4, P216, DOI 10.1109/tcbb.2007.070208
   Jain M., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1441
   Jiang YG, 2013, IEEE T MULTIMEDIA, V15, P442, DOI 10.1109/TMM.2012.2231061
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Kesorn K, 2012, IEEE T MULTIMEDIA, V14, P211, DOI 10.1109/TMM.2011.2170665
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
NR 49
TC 4
Z9 4
U1 0
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2014
VL 10
IS 3
AR 26
DI 10.1145/2535938
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AF3AM
UT WOS:000334583800004
OA Green Published
DA 2024-07-18
ER

PT J
AU Chen, XY
   Mu, YD
   Liu, HR
   Yan, SC
   Rui, Y
   Chua, TS
AF Chen, Xiangyu
   Mu, Yadong
   Liu, Hairong
   Yan, Shuicheng
   Rui, Yong
   Chua, Tat-Seng
TI Large-Scale Multilabel Propagation Based on Efficient Sparse Graph
   Construction
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Performance; Experimentation; Image annotation;
   collaborative multilabel propagation; sparsity induced graph
   construction
AB With the popularity of photo-sharing websites, the number of web images has exploded into unseen magnitude. Annotating such large-scale data will cost huge amount of human resources and is thus unaffordable. Motivated by this challenging problem, we propose a novel sparse graph based multilabel propagation (SGMP) scheme for super large scale datasets. Both the efficacy and accuracy of the image annotation are further investigated under different graph construction strategies, where Gaussian noise and non-Gaussian sparse noise are simultaneously considered in the formulations of these strategies. Our proposed approach outperforms the state-of-the-art algorithms by focusing on: (1) For large-scale graph construction, a simple yet efficient LSH (Locality Sensitive Hashing)-based sparse graph construction scheme is proposed to speed up the construction. We perform the multilabel propagation on this hashing-based graph construction, which is derived with LSH approach followed by sparse graph construction within the individual hashing buckets; (2) To further improve the accuracy, we propose a novel sparsity induced scalable graph construction scheme, which is based on a general sparse optimization framework. Sparsity essentially implies a very strong prior: for large scale optimization, the values of most variables shall be zeros when the solution reaches the optimum. By utilizing this prior, the solutions of large-scale sparse optimization problems can be derived by solving a series of much smaller scale subproblems; (3) For multilabel propagation, different from the traditional algorithms that propagate over individual label independently, our proposed propagation first encodes the label information of an image as a unit label confidence vector and naturally imposes inter-label constraints and manipulates labels interactively. Then, the entire propagation problem is formulated on the concept of Kullback-Leibler divergence defined on probabilistic distributions, which guides the propagation of the supervision information. Extensive experiments on the benchmark dataset NUS-WIDE with 270k images and its lite version NUS-WIDE-LITE with 56k images well demonstrate the effectiveness and scalability of the proposed multi-label propagation scheme.
   Categories and Subject Descriptors: H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing-Indexing methods
C1 [Chen, Xiangyu] Inst Infocomm Res, Singapore 138632, Singapore.
   [Chen, Xiangyu; Mu, Yadong; Liu, Hairong; Yan, Shuicheng; Chua, Tat-Seng] Natl Univ Singapore, Singapore 117417, Singapore.
   [Rui, Yong] Beijing Sigma Ctr, Beijing 100090, Peoples R China.
   [Mu, Yadong] Columbia Univ, New York, NY 10027 USA.
   [Liu, Hairong] Purdue Univ, W Lafayette, IN 47907 USA.
   [Rui, Yong] Microsoft Res Asia, Bangalore, Karnataka, India.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); National University of Singapore;
   Microsoft; Columbia University; Purdue University System; Purdue
   University
RP Chen, XY (corresponding author), Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis South Tower, Singapore 138632, Singapore.
EM chenxy@i2r.a-star.edu.sg
RI Yan, Shuicheng/HCI-1431-2022; Liu, Hairong/I-6695-2012
FU NUS-Tsinghua Extreme Search project [R-252-300-001-490]
FX This work was supported by NUS-Tsinghua Extreme Search project under the
   grant number: R-252-300-001-490.
CR Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   Andrew G., 2007, P ICML
   [Anonymous], P CVPR
   [Anonymous], SIAM J OPTIM
   [Anonymous], P INT C MACH LEARN I
   [Anonymous], SIAM J SCI COMPUT
   Beck A., 2009, SIAM J IMAG SCI
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Charikar M. S., 2002, P 34 ANN ACM S THEOR, P380
   Chen G., 2008, P SIAM INT C DAT MIN, P410, DOI DOI 10.1137/1.9781611972788.37
   Chen SS., 2001, SIAM review
   Chen X., 2010, P ACM MM
   CHENG B, 2010, IEEE T IMAGE P
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Collobert R, 2006, J MACH LEARN RES, V7, P1687
   Datar M., 2004, P SCG
   Delalleau Olivier, 2005, AISTAT
   Duda R., 1973, Pattern Classification and Scene Analysis
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Hale E. T., 2008, SIAM J OPTIM
   Hiriart-Urruty J.-B., 2001, FUNDAMENTALS CONVEX
   INDYK P, 1998, P INT C MACH LEARN I
   KARLEN M., 2008, P CVPR
   LIU J, 2009, P UAI
   LIU Y, 2006, P AAAI
   Mu Y., 2012, P EUR C COMP VIS ECC
   NG A, 2007, P CVPR
   Perkins S., 2003, J MECH LEARN RES
   Qi G.-J., 2007, P MM
   Rosenfeld, 2005, SEMISUPERVISED LEARN
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Russell S., 2009, Artificial intelligence
   Schmidt M., 2009, P UAI
   Sindhwani V., 2006, Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval
   Subramanya A., 2008, P EMNLP
   Subramanya A., 2009, P NIPS
   Tang J., 2009, P MM
   Tibshirani R., 1996, J. Roy. Stat. Soc. B.
   Tsang I. W., 2006, P NIPS
   WANG F, 2006, P ICML
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009
   Zhang H., 2012, P CVPR
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
   Zhu X., 2006, Computer Science, University of Wisconsin-Madison
NR 45
TC 2
Z9 3
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2013
VL 10
IS 1
AR 6
DI 10.1145/2542205.2542209
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 280JP
UT WOS:000329025400006
OA Bronze
DA 2024-07-18
ER

PT J
AU Mallik, A
   Ghosh, H
   Chaudhury, S
   Harit, G
AF Mallik, Anupama
   Ghosh, Hiranmay
   Chaudhury, Santanu
   Harit, Gaurav
TI MOWL: An Ontology Representation Language for Web-Based Multimedia
   Applications
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Theory; Standardization; Experimentation; Languages; Multimedia web
   ontology language; multimedia ontology; Bayesian networks; concept
   recognition; digital heritage; recommendation engine
ID INTEROPERABILITY
AB Several multimedia applications need to reason with concepts and their media properties in specific domain contexts. Media properties of concepts exhibit some unique characteristics that cannot be dealt with conceptual modeling schemes followed in the existing ontology representation and reasoning schemes. We have proposed a new perceptual modeling technique for reasoning with media properties observed in multimedia instances and the latent concepts. Our knowledge representation scheme uses a causal model of the world where concepts manifest in media properties with uncertainties. We introduce a probabilistic reasoning scheme for belief propagation across domain concepts through observation of media properties. In order to support the perceptual modeling and reasoning paradigm, we propose a new ontology language, Multimedia Web Ontology Language (MOWL). Our primary contribution in this article is to establish the need for the new ontology language and to introduce the semantics of its novel language constructs. We establish the generality of our approach with two disperate knowledge-intensive applications involving reasoning with media properties of concepts.
   Categories and Subject Descriptors: F.4.1 [Mathematical Logic and Formal Languages]: Mathematical Logic; H.2.4 [Database Management]: Systems-Multimedia databases; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-Representation languages
C1 [Mallik, Anupama; Chaudhury, Santanu] Multimedia Lab, Shenyang 110016, Peoples R China.
   [Ghosh, Hiranmay] TCS Innovat Labs Delhi, Gurgaon 122016, India.
   [Harit, Gaurav] IIT Jodhpur, Jodhpur, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Jodhpur
RP Mallik, A (corresponding author), Multimedia Lab, Block II, Shenyang 110016, Peoples R China.
EM ansimal@gmail.com; hiranmay.ghosh@tcs.com; schaudhury@ee.iitd.ac.in;
   gharit@iitj.ac.in
RI Ghosh, Hiranmay/AAE-8634-2020
CR [Anonymous], 2012, P ACM INT C MULT
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Bai L, 2007, IMVIP 2007: INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P117, DOI 10.1109/IMVIP.2007.13
   Bertini M, 2009, IEEE MULTIMEDIA, V16, P42, DOI 10.1109/MMUL.2009.25
   Busa-Fekete R., 2012, P ECAI 12 WORKSH PRE
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V49, P167, DOI 10.1007/s11042-009-0393-6
   DING Z, 2004, P 37 HAW INT C SYST
   Doerr M., 2012, AI MAG, V24, P3
   FOLEY JD, 1982, COMPUTER GRAPHICS PR
   Gangemi A, 2002, LECT NOTES ARTIF INT, V2473, P166
   Garcia R., 2005, P 5 KNOWL MARK SEM A
   Ghosh H, 2004, IEEE T KNOWL DATA EN, V16, P1082, DOI 10.1109/TKDE.2004.40
   Ghosh H., 2007, ONTOLOGIES HDB PRINC
   Hunter J, 2003, IEEE T CIRC SYST VID, V13, P49, DOI 10.1109/TCSVT.2002.808088
   Jiang SQ, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P131
   Kangassalo H., 1991, Advances in information modelling and knowledge bases, P66
   Kentner B., 1979, COLOR ME SEASON COMP
   Mallik A., 2011, Journal on Computing and Cultural Heritage JOCCH, V4, P11
   Nikolopoulos S, 2011, IEEE T SYST MAN CY B, V41, P1366, DOI 10.1109/TSMCB.2011.2147781
   Papadias D, 2001, ACM T INFORM SYST, V19, P53, DOI 10.1145/366836.366874
   Patel-Schneider P.F., 2004, OWL Web Ontology Lan-guage semantics and abstract syntax
   Pradhan M, 1996, ARTIF INTELL, V85, P363, DOI 10.1016/0004-3702(96)00002-1
   Rafatirad S., 2009, P 1 ACM INT WORKSHOP, P65
   Randell David., 2001, Proceedings of the 17th International Joint Conference on Artificial Intelligence, volume 1 of IJCAI'01, V1, P57
   Saathoff C, 2010, P 19 INT C WORLD WID, P831, DOI [10.1145/1772690.1772775, DOI 10.1145/1772690.1772775]
   Salembier P, 2001, IEEE T CIRC SYST VID, V11, P748, DOI 10.1109/76.927435
   Scherp A, 2009, K-CAP'09: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE, P137
   Schneider L, 2003, LECT NOTES COMPUT SC, V2813, P91
   Shaw R, 2009, LECT NOTES COMPUT SC, V5926, P153, DOI 10.1007/978-3-642-10871-6_11
   Tsinaraki C, 2007, IEEE T KNOWL DATA EN, V19, P219, DOI 10.1109/TKDE.2007.33
   Vogiatzis D, 2012, EXPERT SYST APPL, V39, P10647, DOI 10.1016/j.eswa.2012.02.178
   W3C, 2012, OWL 2 WEB ONTOLOGY L
   Wattamwar S. S., 2008, P 2 ACM WORKSH MULT, P48, DOI [10.1145/1460676.1460686, DOI 10.1145/1460676.1460686]
NR 33
TC 17
Z9 17
U1 0
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2013
VL 10
IS 1
AR 8
DI 10.1145/2542205.2542210
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 280JP
UT WOS:000329025400008
DA 2024-07-18
ER

PT J
AU Tian, XM
   Tao, DC
   Rui, Y
AF Tian, Xinmei
   Tao, Dacheng
   Rui, Yong
TI Sparse Transfer Learning for Interactive Video Search Reranking
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithm; Experimentation; Performance; Interactive video search
   reranking; dimension reduction; transfer learning; sparsity
ID NONLINEAR DIMENSIONALITY REDUCTION; IMAGE RETRIEVAL;
   DISCRIMINANT-ANALYSIS; RELEVANCE-FEEDBACK
AB Visual reranking is effective to improve the performance of the text-based video search. However, existing reranking algorithms can only achieve limited improvement because of the well-known semantic gap between low-level visual features and high-level semantic concepts. In this article, we adopt interactive video search reranking to bridge the semantic gap by introducing user's labeling effort. We propose a novel dimension reduction tool, termed sparse transfer learning (STL), to effectively and efficiently encode user's labeling information. STL is particularly designed for interactive video search reranking. Technically, it (a) considers the pair-wise discriminative information to maximally separate labeled query relevant samples from labeled query irrelevant ones, (b) achieves a sparse representation for the subspace to encodes user's intention by applying the elastic net penalty, and (c) propagates user's labeling information from labeled samples to unlabeled samples by using the data distribution knowledge. We conducted extensive experiments on the TRECVID 2005, 2006 and 2007 benchmark datasets and compared STL with popular dimension reduction algorithms. We report superior performance by using the proposed STL-based interactive video search reranking.
C1 [Tian, Xinmei] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Anhui, Peoples R China.
   [Rui, Yong] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Tao, Dacheng] Univ Technol Sydney, Sydney, NSW 2007, Australia.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Microsoft; Microsoft Research Asia; University of Technology
   Sydney
RP Tian, XM (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, 96 Jinzhai Rd, Hefei 230027, Anhui, Peoples R China.
EM xinmeitian@gmail.com; dacheng.tao@uts.edu.au; yongrui@microsoft.com
RI Tao, Dacheng/A-5449-2012
OI Tao, Dacheng/0000-0001-7225-5449
FU Australian ARC discovery project [ARC DP-120103730]; Open Project
   Program of the State Key Lab of CADCG [A1006]; Zhejiang University
FX This work was supported in part by the Australian ARC discovery project
   (ARC DP-120103730 and the Open Project Program of the State Key Lab of
   CAD&CG (Grant No. A1006), Zhejiang University.
CR [Anonymous], 2007, PROC IEEE INT C COMP
   Bian W, 2011, IEEE T PATTERN ANAL, V33, P1037, DOI 10.1109/TPAMI.2010.189
   Cai D., 2005, Tech Rep
   Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   Efron B., 2004, ANN STAT, V32, P68
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496
   HE X., 2003, ADV NEURAL INF PROC
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hsu W. H., 2006, MULTIMEDIA '06, P35
   Hsu WinstonH., 2007, ACM MM
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Kotoulas L, 2003, IEE P-CIRC DEV SYST, V150, P387, DOI 10.1049/ip-cds:20030481
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   LIN Y.-Y., 2005, P ACM INT C MULT, P06
   Liu Jingjing., 2007, MULTIMEDIA 07, P208
   Liu L, 2008, INT CONF ACOUST SPEE, P2145
   Ma WY, 1998, CONF REC ASILOMAR C, P253, DOI 10.1109/ACSSC.1998.750865
   Natsev Apostol., 2007, MULTIMEDIA 07, P991
   Neumaier A, 1998, SIAM REV, V40, P636, DOI 10.1137/S0036144597321909
   Nguyen GP, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1324287.1324294
   Qi GJ, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404883
   Robertson S.-E., 1997, TR356 CAMBR U COMP L
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Slonim N., 1999, ADV NEURAL INFORM PR
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tao DC, 2006, IEEE T MULTIMEDIA, V8, P716, DOI 10.1109/TMM.2005.861375
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tian X., 2008, ACM INT C MULTIMEDIA, P131, DOI DOI 10.1145/1459359.1459378.ISBN
   Tian XM, 2010, IEEE T IMAGE PROCESS, V19, P805, DOI 10.1109/TIP.2009.2035866
   TRECVID.TREC Video Retrieval Evaluation, P TREC 10
   YAN S., 2004, P ACM INT C CONT BAS, P60
   Yan SC, 2007, IEEE T CIRC SYST VID, V17, P468, DOI 10.1109/TCSVT.2007.893837
   Yang B, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671954.1671957
   Zhang TH, 2008, IEEE IJCNN, P1670, DOI 10.1109/IJCNN.2008.4634022
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhou TY, 2011, DATA MIN KNOWL DISC, V22, P340, DOI 10.1007/s10618-010-0182-x
   Zhou XS, 2001, PROC CVPR IEEE, P11
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 48
TC 60
Z9 62
U1 0
U2 37
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUL
PY 2012
VL 8
IS 3
AR 26
DI 10.1145/2240136.2240139
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 986AM
UT WOS:000307311700003
DA 2024-07-18
ER

PT J
AU Li, R
   Bhanu, B
   Dong, AL
AF Li, Rui
   Bhanu, Bir
   Dong, Anlei
TI Feature synthesized EM algorithm for image retrieval
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE algorithms; experimentation; coevolutionary feature synthesis;
   expectation maximization; semi-supervised learning; content-based image
   retrieval
ID RELEVANCE FEEDBACK; PARTS
AB As a commonly used unsupervised learning algorithm in Content-Based Image Retrieval (CBIR), Expectation-Maximization ( EM) algorithm has several limitations, including the curse of dimensionality and the convergence at a local maximum. In this article, we propose a novel learning approach, namely Coevolutionary Feature Synthesized Expectation- Maximization ( CFSEM), to address the above problems. The CFS-EM is a hybrid of coevolutionary genetic programming ( CGP) and EM algorithm applied on partially labeled data. CFS-EM is especially suitable for image retrieval because the images can be searched in the synthesized low-dimensional feature space, while a kernel-based method has to make classification computation in the original high-dimensional space. Experiments on real image databases show that CFS-EM outperforms Radial Basis Function Support Vector Machine ( RBF-SVM), CGP, Discriminant-EM ( D-EM) and Transductive-SVM ( TSVM) in the sense of classification performance and it is computationally more efficient than RBF-SVM in the query phase.
C1 [Li, Rui; Bhanu, Bir; Dong, Anlei] Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA.
C3 University of California System; University of California Riverside
RP Li, R (corresponding author), Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA.
EM rli@vislab.ucr.edu; bhanu@vislab.ucr.edu; adong@vislab.ucr.edu
OI Bhanu, Bir/0000-0001-8971-6416
CR [Anonymous], 1999, Advances in Kernel Methods-Support Vector Learning
   [Anonymous], GENETIC LEARNING ADA
   [Anonymous], 2005, MG COMP SCI
   Bargeron D, 2005, PROC INT CONF DOC, P1166, DOI 10.1109/ICDAR.2005.59
   Bhanu B, 2003, IMAGE VISION COMPUT, V21, P591, DOI 10.1016/S0262-8856(03)00057-X
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen ZW, 2003, CHINA ECON REV, V14, P451, DOI 10.1016/j.chieco.2003.09.016
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DONG A, 2005, P IEEE WORKSH APPL C, P330
   Dong AL, 2005, IEEE T SYST MAN CY B, V35, P450, DOI 10.1109/TSMCB.2005.846653
   Dong AL, 2003, PROC CVPR IEEE, P662
   Fang YC, 2005, LECT NOTES COMPUT SC, V3546, P637
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   He XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P385, DOI 10.1109/ICCV.2003.1238370
   He Xiaofei., 2004, ACM MULTIMEDIA, P17
   Hua Y, 2003, PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PDCAT'2003, PROCEEDINGS, P268, DOI 10.1109/PDCAT.2003.1236303
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Joachims T., 2003, P 20 INT C MACH LEAR, V20, P290, DOI DOI 10.1145/2612669.2612699
   Koza J. R., 1994, Genetic programming II: Automatic discovery of reusable programs, VII, DOI DOI 10.5555/183460
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   LI R, 2005, P APPL COMP MULT, P696
   Li SZ, 2001, PROC CVPR IEEE, P207
   Lin RP, 2005, GEOPH MONOG SERIES, V156, P171
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118
   Nakao Miki, 2001, Recent Research Developments in Immunology, V3, P15
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   Peng J, 1999, COMPUT VIS IMAGE UND, V75, P150, DOI 10.1006/cviu.1999.0770
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Saunders C, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P722
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Su Z., 2001, ACM MULTIMEDIA, P98
   Swets DL, 1999, IEEE T PATTERN ANAL, V21, P386, DOI 10.1109/34.765652
   Tang HL, 2003, IEEE T INF TECHNOL B, V7, P26, DOI 10.1109/TITB.2003.808500
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   VIRGINIA RDS, 1993, ADV NEURAL INFORM PR, P112
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wu P, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P726, DOI 10.1109/ICIP.2000.899557
   Wu Y, 2000, PROC CVPR IEEE, P133, DOI 10.1109/CVPR.2000.855810
   XIANG S, 2005, P AS C COMP VIS, P216
   Yin PY, 2005, IEEE T PATTERN ANAL, V27, P1536, DOI 10.1109/TPAMI.2005.201
   Yin PY, 2002, INT C PATT RECOG, P533, DOI 10.1109/ICPR.2002.1047994
   Yu J., 2006, ACM MULTIMEDIA 06, P297
   ZHOU XS, 1999, P INT C IM PROC KOB
   ZHU L, 2000, P INT C MULT EXP, P397
NR 48
TC 7
Z9 7
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2008
VL 4
IS 2
AR 10
DI 10.1145/1352012.1352014
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 306RG
UT WOS:000256264900002
DA 2024-07-18
ER

PT J
AU Murray, N
   Roberts, D
   Steed, A
   Sharkey, P
   Dickerson, P
   Rae, J
AF Murray, Norman
   Roberts, Dave
   Steed, Anthony
   Sharkey, Paul
   Dickerson, Paul
   Rae, John
TI An assessment of eye-gaze potential within immersive virtual
   environments
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
AB In collaborative situations, eye gaze is a critical element of behavior which supports and fulfills many activities and roles. In current computer-supported collaboration systems, eye gaze is poorly supported. Even in a state-of-the-art video conferencing system such as the access grid, although one can see the face of the user, much of the communicative power of eye gaze is lost. This article gives an overview of some preliminary work that looks towards integrating eye gaze into an immersive collaborative virtual environment and assessing the impact that this would have on interaction between the users of such a system. Three experiments were conducted to assess the efficacy of eye gaze within immersive virtual environments. In each experiment, subjects observed on a large screen the eye-gaze behavior of an avatar. The eye-gaze behavior of that avatar had previously been recorded from a user with the use of a head-mounted eye tracker. The first experiment was conducted to assess the difference between users' abilities to judge what objects an avatar is looking at with only head gaze being viewed and also with eye- and head-gaze data being displayed. The results from the experiment show that eye gaze is of vital importance to the subjects, correctly identifying what a person is looking at in an immersive virtual environment. The second experiment examined whether a monocular or binocular eye-tracker would be required. This was examined by testing subjects' ability to identify where an avatar was looking from their eye direction alone, or by eye direction combined with convergence. This experiment showed that convergence had a significant impact on the subjects' ability to identify where the avatar was looking. The final experiment looked at the effects of stereo and mono-viewing of the scene, with the subjects being asked to identify where the avatar was looking. This experiment showed that there was no difference in the subjects' ability to detect where the avatar was gazing. This is followed by a description of how the eye-tracking system has been integrated into an immersive collaborative virtual environment and some preliminary results from the use of such a system.
C1 [Murray, Norman; Roberts, Dave] Univ Salford, Ctr Virtual Environm, Salford M5 4WT, Lancs, England.
   [Steed, Anthony] UCL, Dept Comp Sci, London WC1E 6BT, England.
   [Dickerson, Paul] Univ Reading, Sch Syst Engn, Reading RG6 6AH, Berks, England.
   [Dickerson, Paul; Rae, John] Roehampton Univ, Sch Human & Life Sci, London SW15 5PU, England.
C3 University of Salford; University of London; University College London;
   University of Reading; Roehampton University
RP Murray, N (corresponding author), Univ Salford, Ctr Virtual Environm, Business House, Salford M5 4WT, Lancs, England.
EM n.murray@salford.ac.uk
OI Steed, Anthony/0000-0001-9034-3020; Dickerson, Paul/0000-0002-7566-0826
FU EPSRC [EP/E007406/1, EP/E007570/1] Funding Source: UKRI
CR [Anonymous], 1975, BODILY COMMUNICATION
   [Anonymous], P ACM S VIRT REAL SO
   Argyle M., 1977, J ENV PSYCHOL NONVER, V1, P6, DOI [10.1007/BF01115461, DOI 10.1007/BF01115461]
   Argyle Michael, 1975, BODILY COMMUNICATION
   BENFORD S, 1995, P C COMP HUM INT
   Bente G., 2002, Proceedings of Fifth Annual International Workshop PRESENCE 2002, Porto, Portugal, P233
   Bruce V., 1998, In the eye of the beholder: the science of face perception
   DeFanti TA, 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P135, DOI 10.1145/166117.166134.
   Dickerson P., 2005, APPL CONVERSATION AN, P19
   GARAU M, 2001, P SIG CHI C HUM FACT
   GARAU M, 2003, P SIG CHI C HUM FACT
   GOODWIN C, 1986, SEMIOTICA, V62, P29, DOI 10.1515/semi.1986.62.1-2.29
   Goodwin C., 2000, Handbook of Visual Analysis, P157
   Heath C., 1984, STRUCTURES SOCIAL AC, P247
   Heldal I, 2005, PRESENCE-VIRTUAL AUG, V14, P563, DOI 10.1162/105474605774918679
   Hindmarsh J., 2000, ACM Transactions on Computer-Human Interaction, V7, P477, DOI 10.1145/365058.365088
   KENDON A, 1967, ACTA PSYCHOL, V26, P22, DOI 10.1016/0001-6918(67)90005-4
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Lerner G., 1996, PRAGMATICS, V6, P281, DOI 10.1075/prag.6.3.02ler
   Lerner GH, 2003, LANG SOC, V32, P177, DOI 10.1017/S004740450332202X
   MARKUS G, 2003, P ACM SIGGRAPH INT C
   MURRAY N, 2006, 10 IEEE INT S DISTR
   Murray N., 2003, 9 INT C HUMAN COMPUT, V1, P1198
   Rae J, 2001, RES LANG SOC INTERAC, V34, P253, DOI 10.1207/S15327973RLSI34-2_4
   RASKAR R, 1998, P ACM SIGGRAPH INT C
   ROBERTS DJ, 2004, P ACM INT S VIRT REA
   Schroeder R, 2001, COMPUT GRAPH-UK, V25, P781, DOI 10.1016/S0097-8493(01)00120-0
   Steed Anthony., 2003, P ACM SIGGRAPH S INT, P51
   TANGER R, 2004, P PAC RIM C MULT SPR
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
NR 30
TC 16
Z9 19
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2007
VL 3
IS 4
AR 26
DI 10.1145/1314303.1314311
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 250QU
UT WOS:000252315900008
DA 2024-07-18
ER

PT J
AU Truong, BT
   Venkatesh, S
AF Truong, Ba Tu
   Venkatesh, Svetha
TI Video abstraction: A systematic review and classification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Review
DE algorithms; management; video summarization; video abstraction;
   keyframe; video skimming; survey
ID KEY FRAME SELECTION; RETRIEVAL; SEGMENTATION; HIGHLIGHTS; EXTRACTION;
   ALGORITHM; SCHEME
AB The demand for various multimedia applications is rapidly increasing due to the recent advance in the computing and network infrastructure, together with the widespread use of digital video technology. Among the key elements for the success of these applications is how to effectively and efficiently manage and store a huge amount of audio visual information, while at the same time providing user-friendly access to the stored data. This has fueled a quickly evolving research area known as video abstraction. As the name implies, video abstraction is a mechanism for generating a short summary of a video, which can either be a sequence of stationary images (keyframes) or moving images (video skims). In terms of browsing and navigation, a good video abstract will enable the user to gain maximum information about the target video sequence in a specified time constraint or sufficient information in the minimum time. Over past years, various ideas and techniques have been proposed towards the effective abstraction of video contents. The purpose of this article is to provide a systematic classification of these works. We identify and detail, for each approach, the underlying components and how they are addressed in specific works.
C1 Curtin Univ Technol, Dept Comp Sci, Perth, WA, Australia.
C3 Curtin University
RP Truong, BT (corresponding author), Curtin Univ Technol, Dept Comp Sci, Perth, WA, Australia.
EM truongbt@cs.curtin.edu.au; svetha@cs.curtin.edu.au
OI Venkatesh, Svetha/0000-0001-8675-6631
CR AGNIHOTRI L, 2004, P INT C MULT EXP ICM
   Agnihotri Lalitha, 2005, P 7 ACM SIGMM INT WO
   Aizawa K, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P398, DOI 10.1109/ICIP.2001.958135
   ANER A, 2002, P EUR C COMP VIS DEN
   [Anonymous], 2000, P 2000 ACM WORKSH MU, DOI DOI 10.1145/357744.357942
   Aoyagi S, 2004, PROC SPIE, V5305, P178
   ARIKI Y, 2003, P ACM INT WORKSH MUL, P209
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   BABAGUCHI N, 2000, P ICME C NEW YORK
   BABAGUCHI N, 2001, P IEEE INT C MULT EX
   Bagga A, 2002, INT C PATT RECOG, P818, DOI 10.1109/ICPR.2002.1048428
   CAI R, 2003, P IEEE INT C MULT EX
   Calic J, 2002, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P28, DOI 10.1109/ITCC.2002.1000355
   Calic J, 2004, P WORKSH IM AN MULT
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   CHANG P, 2002, P IEEE INT C IM PROC
   CHAU WS, 2004, P ICME C TAIP
   CHEN SC, 2004, P ICME C TAIP
   CHIU P, 2004, P INT C MULT EXP ICM
   Christel MG, 1999, P IEEE INT FORUM RES, P98, DOI 10.1109/ADL.1999.777702
   CHRISTEL MG, 1998, P C COMP HUM INT CHI, P117
   COLDEFY F, 2004, P IEEE INT WORKSH MU
   Coldefy F., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P268
   Cooper M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P502, DOI 10.1109/ICME.2005.1521470
   Cooper M, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P25
   Dagtas S, 2004, MULTIMEDIA SYST, V9, P586, DOI 10.1007/s00530-003-0130-3
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   DESILVA GC, 2005, P ACM MULT C ACMMM
   DIMITROVA V, 1997, P 6 INT C INF KNOWL, P113
   Divakaran A, 2002, IEEE IMAGE PROC, P932
   Divakaran A., 2003, VIDEO MINING
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Doulamis ND, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P875, DOI 10.1109/ICIP.1998.723660
   DOULAMIS ND, 1999, P 3 WORKSH MULT SIGN
   DREW MS, 2000, P ACM MULT C LOS ANG
   Dufaux F, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P275, DOI 10.1109/ICIP.2000.899354
   Ekin A, 2002, PROC SPIE, V4671, P763, DOI 10.1117/12.453120
   Erol B, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P25
   FAUVET B, 2004, P CVIP C DUBL
   Ferman AM, 1998, J VIS COMMUN IMAGE R, V9, P336, DOI 10.1006/jvci.1998.0402
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   GIBSON NCD, 2002, P 15 INT C VIS INT
   Girgensohn A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P77
   Girgensohn A, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P756, DOI 10.1109/MMCS.1999.779294
   Girgensohn A, 2001, COMPUTER, V34, P61, DOI 10.1109/2.947093
   GONG Y, 2001, P INT C MULT EXP ICM
   Gong YH, 2003, MULTIMEDIA SYST, V9, P157, DOI 10.1007/s00530-003-0086-3
   GONG YH, 2003, EURASIP J APPL SIG P, P2
   GU L, 1999, P EUR WORKSH MULT MI
   GUNSEL B, 1998, P ICIP C CHIC
   HAMMOUD R, 2000, P INT WORKSH REAL TI
   Han M., 2002, Proc. ACM Multimedia, P347, DOI [DOI 10.1145/641007.641081, 10.1145/641007.641081]
   HAN SH, 2005, INT C MULT EXP
   Hanjalic A, 2003, IEEE IMAGE PROC, P1
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   HANJALIC A, 1998, IMAGE DATABASES MULT
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279
   JAIMES A, 2002, P ICIP C ROCH
   Joshi A, 1998, EIGHTH INTERNATIONAL WORKSHOP ON RESEARCH ISSUES IN DATA ENGINEERING - CONTINUOUS-MEDIA DATABASES AND APPLICATIONS, PROCEEDINGS, P42, DOI 10.1109/RIDE.1998.658277
   JUNG B, 2004, P ACM MULT ACMMM C
   Kang EK, 1999, IEEE T CONSUM ELECTR, V45, P932, DOI 10.1109/30.793648
   Kang H., 2002, Distributed Multimedia Databases: Techniques and Applications, P120
   Kang H W, 2005, P ACM MULT C
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P1128, DOI 10.1109/TCSVT.2002.806813
   Kim JG, 2003, INT J IMAG SYST TECH, V13, P267, DOI 10.1002/ima.10067
   KOBLA V, 1999, P IEEE 1999 INT WORK
   Komlodi A., 1998, Digital 98 Libraries. Third ACM Conference on Digital Libraries, P118, DOI 10.1145/276675.276688
   KOPF S, 2004, P INT C MULT EXP ICM
   KRAAIJ W, 2004, P NIST TRECV C
   LATECKI LJ, 2001, P MULT SIGN PROC C C
   Lee HC, 2003, SIGNAL PROCESS-IMAGE, V18, P1, DOI 10.1016/S0923-5965(02)00089-9
   Lee HC, 2002, ELECTRON LETT, V38, P217, DOI 10.1049/el:20020112
   LEE J, 2005, ACM MULT C ACMMM, P810
   Lee MC, 1997, IEEE T CIRC SYST VID, V7, P130, DOI 10.1109/76.554424
   LEE S, 2004, P ICASSP C
   LEE SH, 2004, P INT C MULT EXP ICM
   LEINHART RW, 2003, Patent No. 6597859
   LI Y, 2001, HP2001191 HP
   Li Y., 2003, VIDEO MINING
   LI Z, 2004, P IEEE INT C IM PROC
   Lie WN, 2004, LECT NOTES COMPUT SC, V3332, P246
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   LIENHART R, 1997, P SPIE C STOR RETR M, V3972, P378
   LIU T, 2002, P INT C MULT EXP ICM
   LIU T, 2002, P EUR C COMP VIS ECC
   LIU T, 2002, P INT C IM PROC ICIP
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Liu TY, 2004, PATTERN RECOGN LETT, V25, P1451, DOI 10.1016/j.patrec.2004.05.020
   LU S, 2005, P 11 INT MULT MOD C
   LU S, 2004, P IEEE S CIRC SYST I
   Lu S., 2003, P 9 INT C DISTRIBUTE, P456
   LU S, 2004, P INT C MULT EXP ICM
   Ma Y.-F., 2002, P ACM MULT C ACMMM J
   MARLOW S, 2002, P IR SIGN SYST C
   Masumitsu K, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P267, DOI 10.1109/ICIP.2000.899351
   MAULDIN ML, 1997, Patent No. 5664227
   MEI T, 2005, P ACM MULT C ACMMM
   MIURA K, 2003, IPSJ T COMPUT VIS IM, P44
   Miyauchi S., 2003, Systems and Computers in Japan, V34, P22, DOI 10.1002/scj.10493
   NARASIMHA R, 2003, P AS C SIGN SYST COM
   NG HW, 2002, P INT C MUTL EXP ICM, V1, P325
   NGO CW, 2003, P INT C COMP VIS ICC, V1
   Omoigui N., 1999, P SIGCHI C HUMAN FAC, P136
   Otsuka I, 2005, IEEE T CONSUM ELECTR, V51, P112, DOI 10.1109/TCE.2005.1405707
   Ouyang J.-Q., 2003, P MACH LEARN CYB INT, V5
   PAN H, 2001, P ICASSP C SALT LAK
   PARSHIN, 2004, P RIAO C
   PARSHIN, 2000, LECT NOTES COMPUTER, V1923, P206
   Peker KA, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P414, DOI 10.1109/ICIP.2001.958139
   PEKER KA, 2004, P ICME C TAIP
   PETKOVIC M, 2002, P IEEE INT C MULT EX
   PEYRARD N, 2003, P IEEE INT C MULT EX
   Pfeiffer S, 1996, J VIS COMMUN IMAGE R, V7, P345, DOI 10.1006/jvci.1996.0030
   Pope A, 1998, CONF REC ASILOMAR C, P915, DOI 10.1109/ACSSC.1998.751015
   Porter SV, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P460, DOI 10.1109/ICIAP.2003.1234093
   RADHAKRISHNAN R, 2004, P INT C MULT EXP ICM
   RADHAKRISHNAN R, 2004, MIR P 6 ACM SIGMM IN, P157
   Rasheed Z., 2003, P IEEE COMP VIS PATT
   RONG J, 2004, P INT C MULT EXP ICM
   Rui Y., 2000, P ACM MULT C ACMMM L
   Russell D. M., 2000, P 33 HAW INT C SYST, P3048
   SHIH HC, 2004, P INT C MULT EXP ICM
   Smith MA, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P61, DOI 10.1109/CAIVD.1998.646034
   SUGANO M, 2004, LECT NOTES COMPUTER, V3332
   Sull S, 2001, P SOC PHOTO-OPT INS, V4315, P553, DOI 10.1117/12.410967
   Sun XD, 2000, REAL-TIME IMAGING, V6, P449, DOI 10.1006/rtim.1999.0197
   SUNDARAM H, 2002, P IEEE C IM PROC IC
   SUNDARAM H, 2001, P IEEE INT C MULT EX
   Takahashi Y, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1171
   Taniguchi Y, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P427
   Taskiran CM, 2002, PROC SPIE, V4676, P371
   Teodosio L., 1993, Proceedings ACM Multimedia 93, P39, DOI 10.1145/166266.166270
   TIEYAN L, 2000, P INT C SIGN PROC IC, V2, P1018
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   TJONDRONEGORO DW, 2004, P INT C MULT EXP ICM
   TONOMURA Y, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P131
   Truong BT, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P109
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   VERMAAK J, 2002, P BRIT MACH VIS C BM, V1
   Wan K, 2004, INT C PATT RECOG, P973, DOI 10.1109/ICPR.2004.1334691
   WAN K, 2004, P INT C MULT EXP ICM
   Wan KW, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P638
   WANG J, 2004, P INT C MULT EXP ICM
   WANG P, 2004, P INT C MULT EXP ICM
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Wu J., 2000, Perspective on Content-Based Multimedia Systems
   Xie YX, 2004, LECT NOTES COMPUT SC, V3115, P106
   Xiong W, 1997, MACH VISION APPL, V10, P51, DOI 10.1007/s001380050059
   XIONG Z, 2004, P INT C MULT EXP ICM
   XIONG Z, 2003, P  ICASSP C HONG KON
   Xiong ZY, 2003, IEEE IMAGE PROC, P5
   YAHIAOUI I, 2001, P CBMIR C
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   YEUNG MM, 1995, P C ICIP, V2, P338
   YU B, 2003, P ACM MULT C ACMMM B
   Yu XD, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P117
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhang LH, 2003, PATTERN RECOGN LETT, V24, P9, DOI 10.1016/S0167-8655(02)00160-5
   Zhang XD, 2003, PATTERN RECOGN LETT, V24, P1523, DOI 10.1016/S0167-8655(02)00391-4
   Zhao M, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P620
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 163
TC 511
Z9 573
U1 0
U2 53
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2007
VL 3
IS 1
AR 3
DI 10.1145/1198302.1198305
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 230IZ
UT WOS:000250871500003
DA 2024-07-18
ER

PT J
AU Madhwacharyula, CL
   Davis, M
   Clips-Imag, PM
   Kankanhalli, MS
AF Madhwacharyula, Chitra L.
   Davis, Marc
   Clips-Imag, Philippe Mulhem
   Kankanhalli, Mohan S.
TI Metadata handling: A video perspective
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE algorithms; design; performance; standardization; preexisting video;
   metadata; editing; reuse; semantic; content; representation
AB This article addresses the problem of processing the annotations of preexisting video productions to enable reuse and repurposing of metadata. We introduce the concept of automatic content-based editing of preexisting semantic home video metadata. We propose a formal representation and implementation techniques for reusing and repurposing semantic video metadata in concordance with the actual video editing operations. A novel representation for metadata editing is proposed and an implementation framework for editing the metadata in accordance with the video editing operations is demonstrated. Conflict resolution and regularization operations are defined and implemented in the context of the video metadata editing operations.
C1 Univ Calif Berkeley, Sch Informat Management & Syst, Berkeley, CA 94720 USA.
   Natl Univ Singapore, Singapore 117548, Singapore.
C3 University of California System; University of California Berkeley;
   National University of Singapore
RP Madhwacharyula, CL (corresponding author), Univ Calif Berkeley, Sch Informat Management & Syst, Berkeley, CA 94720 USA.
EM chitra@sims.berkeley.edu; mohan@comp.nus.edu.sg
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
CR *AD SYST INC, AD PREM
   AUFFRET G, 1999, P ACM HYP 99 C DARMS, P169
   Bordwell David., 1997, FILM ART, V5th
   Davis M, 1997, COMMUN ACM, V40, P43, DOI 10.1145/253671.253697
   DAVIS M, 1995, READINGS HUMAN COMPU, P854
   *FXPAL, FLYABOUT
   GIRGENSOHN A, 2000, S US INT SOFTW TECHN, V2, P81
   MA WY, 2000, 10 EUR SIGN PROC C T, P5
   MADHWACHARYULA C, 2003, 4 IEEE PAC RIM C MUL, P15
   Nack F, 2004, MULTIMED TOOLS APPL, V22, P263, DOI 10.1023/B:MTAP.0000017031.26875.f7
   SHAW GM, 1989, QUERY ALGEBRA OBJECT
   Sundaram Hari., 2002, COMUNICA O APRESENTA, DOI [DOI 10.1145/641007.641042, 10.1145/641007.641042]
   *ULEAD, ULEAD VIS STUD
   WEISS R, 1995, IEEE MULTIMEDIA, V2, P12, DOI 10.1109/93.368596
   XIANSHENG H, 2003, P 11 ACM MULT C NOV, P2
   YU JCS, 2003, P IEEE INT C MULT EX
   ZETTL H, 2003, VIDEO BASICS
NR 17
TC 10
Z9 11
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2006
VL 2
IS 4
BP 358
EP 388
DI 10.1145/1201730.1201736
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 230IY
UT WOS:000250871400006
DA 2024-07-18
ER

PT J
AU Ayoughi, M
   Mettes, P
   Groth, P
AF Ayoughi, Melika
   Mettes, Pascal
   Groth, Paul
TI Self-contained Entity Discovery from Captioned Videos
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Entity discovery; self-contained video recognition; multimodal video
   understanding
AB This article introduces the task of visual named entity discovery in videos without the need for task-specific supervision or task-specific external knowledge sources. Assigning specific names to entities (e.g., faces, scenes, or objects) in video frames is a long-standing challenge. Commonly, this problem is addressed as a supervised learning objective by manually annotating entities with labels. To bypass the annotation burden of this setup, several works have investigated the problem by utilizing external knowledge sources such as movie databases. While effective, such approaches do not work when task-specific knowledge sources are not provided and can only be applied to movies and TV series. In this work, we take the problem a step further and propose to discover entities in videos from videos and corresponding captions or subtitles. We introduce a three-stage method where we (i) create bipartite entity-name graphs from frame-caption pairs, (ii) find visual entity agreements, and (iii) refine the entity assignment through entity-level prototype construction. To tackle this new problem, we outline two new benchmarks, SC-Friends and SC-BBT, based on the Friends and Big Bang Theory TV series. Experiments on the benchmarks demonstrate the ability of our approach to discover which named entity belongs to which face or scene, with an accuracy close to a supervised oracle, just from the multimodal information present in videos. Additionally, our qualitative examples show the potential challenges of self-contained discovery of any visual entity for future work. The code and the data are available on GitHub.(1)
C1 [Ayoughi, Melika; Mettes, Pascal; Groth, Paul] Univ Amsterdam, Amsterdam, Netherlands.
C3 University of Amsterdam
RP Ayoughi, M (corresponding author), Univ Amsterdam, Amsterdam, Netherlands.
EM m.ayoughi@uva.nl; p.s.m.mettes@uva.nl; p.t.groth@uva.nl
RI Groth, Paul/AAI-2019-2021
OI Groth, Paul/0000-0003-0183-6910; Mettes, Pascal/0000-0001-9275-5942
CR Alayrac JB, 2016, PROC CVPR IEEE, P4575, DOI 10.1109/CVPR.2016.495
   Bain M., 2020, ACCV
   Bin Y, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5110, DOI 10.1145/3474085.3475173
   Bredin Herve, 2016, MEDIAEVAL 2016
   Brown Andrew, 2021, IEEE MIPR
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen SZ, 2019, IEEE T MULTIMEDIA, V21, P2407, DOI 10.1109/TMM.2019.2896515
   Curtis Keith, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P355, DOI 10.1145/3372278.3390742
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   Esler Tim, 2021, FACENET PYTORCH PRET
   Everingham M., 2006, P BRIT MACH VIS C, P899, DOI [DOI 10.5244/C.20.92, 10.5244/C.20.92]
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer Christoph, 2016, NeurIPS
   Gan C, 2016, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2016.106
   Gan C, 2016, LECT NOTES COMPUT SC, V9907, P849, DOI 10.1007/978-3-319-46487-9_52
   Goyal P., 2022, Vision models are more robust and fair when pretrained on uncurated images without supervision
   Grauman Kristen, 2022, IEEE CVF COMP VIS PA
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   Guo S, 2018, LECT NOTES COMPUT SC, V11214, P139, DOI 10.1007/978-3-030-01249-6_9
   Huang FR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1874, DOI 10.1145/3240508.3240614
   Huang Qingqiu, 2020, P EUR C COMP VIS
   Jang Y, 2017, PROC CVPR IEEE, P1359, DOI 10.1109/CVPR.2017.149
   Ji JW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8086, DOI 10.1109/ICCV48922.2021.00800
   Jiang L., 2018, ICML
   Kalogeiton Vicky, 2020, BMCV
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Kim KM, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2016
   Kukleva Anna, 2020, P IEEE CVF C COMP VI, P9849
   Le N, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095732
   Lei J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2603
   Lei J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1369
   Li D, 2019, IEEE T MULTIMEDIA, V21, P416, DOI 10.1109/TMM.2018.2862341
   Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142
   Mahon Louis, 2020, 2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA), P25, DOI 10.1109/ICMLA51294.2020.00014
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Mithun NC, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/3206025.3206064
   Mun J, 2017, IEEE I CONF COMP VIS, P2886, DOI 10.1109/ICCV.2017.312
   Poignant J., 2015, MEDIAEVAL 2015
   Poignant J, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P2649
   Poignant Johann, 2015, MEDIAEVAL 2015
   Qingqiu Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P139, DOI 10.1007/978-3-030-58520-4_9
   Rohrbach A, 2017, INT J COMPUT VISION, V123, P94, DOI 10.1007/s11263-016-0987-1
   Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P586, DOI 10.1109/TMM.2012.2188784
   Sanh V, 2019, AAAI CONF ARTIF INTE, P6949
   Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319
   Sharma V, 2020, IEEE INT CONF AUTOMA, P109, DOI 10.1109/FG47880.2020.00011
   Snell J, 2017, ADV NEUR IN, V30
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Tan R., 2021, NEURIPS
   Tapaswi M, 2019, IEEE I CONF COMP VIS, P5026, DOI 10.1109/ICCV.2019.00513
   Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501
   Tapaswi M, 2015, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2015.7298792
   the MDZ Digital Library team, 2021, LARG CAS BERT FIN EN
   Tian HS, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3155, DOI 10.1145/3394171.3413501
   Torabi Atousa, 2015, UNPUB
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Ul Haq I, 2019, IEEE ACCESS, V7, P9265, DOI 10.1109/ACCESS.2018.2890560
   Veit A, 2017, PROC CVPR IEEE, P6575, DOI 10.1109/CVPR.2017.696
   Vicol P, 2018, PROC CVPR IEEE, P8581, DOI 10.1109/CVPR.2018.00895
   Woo S, 2018, ADV NEUR IN, V31
   Wu CY, 2021, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR46437.2021.00192
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhan XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11762, DOI 10.1109/ICCV48922.2021.01157
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
   Zhuang BH, 2017, PROC CVPR IEEE, P2915, DOI 10.1109/CVPR.2017.311
NR 71
TC 0
Z9 0
U1 5
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2023
VL 19
IS 5
SU S
AR 177
DI 10.1145/3583138
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L0SK0
UT WOS:001020437100013
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Yang, TC
   Huang, YP
   Xie, YL
   Liu, JB
   Wang, SC
AF Yang, Taocun
   Huang, Yaping
   Xie, Yanlin
   Liu, Junbo
   Wang, Shengchun
TI MixOOD: Improving Out-of-distribution Detection with Enhanced Data Mixup
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Out-of-distribution detection; mixup; data augmentation; anomaly
   detection; machine learning
AB Detecting out-of-distribution (OOD) inputs for deep learning models is a critical task when models are deployed in real-world environments. Recently, a large number of works have been dedicated to tackling the OOD detection problem. One of the most straightforward and effective ways is OOD training, which adds heterogeneous auxiliary data in the training stage. However, the extra auxiliary data cannot be involved arbitrarily. A high-quality and powerful auxiliary dataset must contain samples that belong to OOD but are close to in-distribution (ID), which can teach the model to learn more information about OOD samples, furthermore, distinguish OOD from ID. The key issue for this problem is how to simply acquire such distinctive OOD samples. In this article, we propose an enhanced Mixup-based OOD (MixOOD) detection strategy that can be attached to any threshold-based OOD detecting method. Different from the traditional Mixup designed for ID data augmentation, our proposed MixOOD generates augmented images with deliberately modified Mixup and then uses them as auxiliary OOD data to leverage the OOD detection. We test our method with classical OOD detecting approaches like Maximum Softmax Probability, Energy Score, and Out-of-distribution detector for Neural networks. Experiments show that models with MixOOD can better distinguish in- and out-of-distribution samples than the original version of each approach.
C1 [Yang, Taocun; Huang, Yaping] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.
   [Xie, Yanlin] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
   [Liu, Junbo; Wang, Shengchun] China Acad Railway Sci Corp Ltd, Infrastruct Inspect Res Inst, Beijing 100081, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Huang, YP (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.
EM yangtaocun@bjtu.edu.cn; yphuang@bjtu.edu.cn; windyskys@bjtu.edu.cn;
   liujunbo@rails.cn; wangshengchun@rails.cn
OI Yang, Taocun/0000-0003-3599-9961
FU Beijing Natural Science Foundation [L211015, M22022]; National Natural
   Science Foundation of China [62271042, 62106017, 61906013]; Hebei
   Natural Science Foundation [F2022105018]; Fundamental Research Funds for
   the Central Universities [2019JBZ104]; Key Research and Development
   Project of China Academy of Railway Sciences Corporation Limited
   [2021YJ310]
FX This work is supported by Beijing Natural Science Foundation (Grants No.
   L211015 and No. M22022), National Natural Science Foundation of China
   (Grants No. 62271042, No. 62106017, and No. 61906013), Hebei Natural
   Science Foundation (Grant No. F2022105018), Fundamental Research Funds
   for the Central Universities (Grant No. 2019JBZ104), and the Key
   Research and Development Project of China Academy of Railway Sciences
   Corporation Limited (Grant No. 2021YJ310).
CR Ahmed F, 2020, AAAI CONF ARTIF INTE, V34, P3154
   Chen GY, 2022, IEEE T PATTERN ANAL, V44, P8065, DOI 10.1109/TPAMI.2021.3106743
   Chen TS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2023, DOI 10.1145/3240508.3240523
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Hendrycks D., 2017, 5 INT C LEARNING REP
   Hendrycks Dan, 2019, ARXIV190312261
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kingma D. P., 2014, arXiv
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2006, PREDICTING STRUCTURE, V1
   Lee KM, 2018, Arxiv, DOI arXiv:1711.09325
   Liang SY, 2020, Arxiv, DOI [arXiv:1706.02690, DOI 10.48550/ARXIV.1706.02690]
   Liu Weitang, 2020, ADV NEURAL INFORM PR, V33, P21464
   Maji S, 2013, Arxiv, DOI arXiv:1306.5151
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Mehta D, 2022, LECT NOTES COMPUT SC, V13431, P732, DOI 10.1007/978-3-031-16431-6_69
   Ravikumar Deepak, 2021, INTRACLASS MIXUP OUT
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sun Yi-Xuan, 2022, P AAAI C ARTIFICIAL
   Tan MX, 2019, PR MACH LEARN RES, V97
   Van Horn G, 2015, PROC CVPR IEEE, P595, DOI 10.1109/CVPR.2015.7298658
   Vaze S., 2022, arXiv, DOI 10.48550/arXiv.2110.06207
   Vyas A, 2018, LECT NOTES COMPUT SC, V11212, P560, DOI 10.1007/978-3-030-01237-3_34
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Xu PM, 2015, Arxiv, DOI [arXiv:1504.06755, DOI 10.48550/ARXIV.1504.06755]
   Yu FS, 2016, Arxiv, DOI arXiv:1506.03365
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zhang HY, 2018, Arxiv, DOI [arXiv:1710.09412, DOI 10.48550/ARXIV.1710.09412]
   Zhang JY, 2022, Arxiv, DOI arXiv:2106.03917
NR 36
TC 3
Z9 3
U1 2
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2023
VL 19
IS 5
AR 155
DI 10.1145/3578935
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K7WP6
UT WOS:001018509300004
OA Bronze
DA 2024-07-18
ER

PT J
AU Zeng, ZR
   Zhao, BK
   Chao, HC
   You, I
   Yeh, KH
   Meng, WZ
AF Zeng, Zengri
   Zhao, Baokang
   Chao, Han-Chieh
   You, Ilsun
   Yeh, Kuo-Hui
   Meng, Weizhi
TI Towards Intelligent Attack Detection Using DNA Computing
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Imbalance; attack detection; DNA computing; nondominated ranking;
   multiclassification
ID INTRUSION DETECTION; GENETIC ALGORITHM
AB In recent years, frequent network attacks have seriously threatened the interests and security of humankind. To address this threat, many detection methods have been studied, some of which have achieved good results. However, with the development of network interconnection technology, massive amounts of network data have been produced, and considerable redundant information has been generated. At the same time, the frequently changing types of cyberattacks result in great difficulty collecting samples, resulting in a serious imbalance in the sample size of each attack type in the dataset. These two problems seriously reduce the robustness of existing detection methods, and existing research methods do not provide a good solution. To address these two problems, we define an unbalanced index and an optimal feature index to directly reflect the performance of a detection method in terms of overall accuracy, feature subset optimization, and detection balance. Inspired by DNA computing, we propose intelligent attack detection based on DNA computing (ADDC). First, we design a set of regular encoding and decoding features based on DNA sequences and obtain a better subset of features through biochemical reactions. Second, nondominated ranking based on reference points is used to select individuals to form a new population to optimize the detection balance. Finally, a large number of experiments are carried out on four datasets to reflect real-world cyberattack situations. Experimental results show that compared with the most recent detection methods, our method can improve the overall accuracy of multiclass classification by up to 10%; the imbalance index decreased by 0.5, and 1.5 more attack types were detected on average; and the optimal index of the feature subset increased by 83.8%.
C1 [Zeng, Zengri; Zhao, Baokang] Natl Univ Def Technol, Coll Comp, Changsha 410000, Hunan, Peoples R China.
   [Zeng, Zengri] Hunan Univ Humanities Sci & Technol, Informat Sch, Loudi 417000, Hunan, Peoples R China.
   [Chao, Han-Chieh] Natl Dong Hwa Univ, Dept Elect Engn, Hualien 97441, Taiwan.
   [You, Ilsun] Kookmin Univ, Dept Financial Informat Secur, Jeongneung Ro,Seongvuk Gu 77, Seoul 02707, South Korea.
   [Yeh, Kuo-Hui] Natl Dong Hwa Univ, Hualien 97441, Taiwan.
   [Meng, Weizhi] Tech Univ Denmark DTU, DK-999017 Copenhagen, Denmark.
C3 National University of Defense Technology - China; Hunan University Of
   Humanities, Science & Technology; National Dong Hwa University; Kookmin
   University; National Dong Hwa University; Technical University of
   Denmark
RP Chao, HC (corresponding author), Natl Dong Hwa Univ, Dept Elect Engn, Hualien 97441, Taiwan.; You, I (corresponding author), Kookmin Univ, Dept Financial Informat Secur, Jeongneung Ro,Seongvuk Gu 77, Seoul 02707, South Korea.
EM zengzr@nudt.edu.cn; bkzhao@nudt.edu.cn; hcchao@gmail.com;
   ilsunu@gail.com; khyeh@gms.ndhu.edu.tw; weme@dtu.dk
RI Meng, Weizhi/N-9638-2019
OI Meng, Weizhi/0000-0003-4384-5786; You, Ilsun/0000-0002-0604-3445; zeng,
   zengri/0000-0002-5329-0713; Yeh, Kuo-Hui/0000-0003-0598-761X; Chao,
   Han-Chieh/0000-0003-3222-1708
FU Natural Science Foundation of China [61972412]
FX This work is supported by the Natural Science Foundation of China (grant
   no. 61972412).
CR Abdulhammed R, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2879990
   ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Aguilar-Rivera A, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106047
   Almaiah MA., 2021, Artificial Intelligence and Blockchain for Future Cybersecurity Applications, P107, DOI [10.1007/978-3-030-74575-2_6, DOI 10.1007/978-3-030-74575-2_6]
   Almseidin M, 2022, J INTELL FUZZY SYST, V43, P3679, DOI 10.3233/JIFS-213247
   Bedi Punam, 2020, Procedia Computer Science, V171, P780, DOI 10.1016/j.procs.2020.04.085
   Bedi P, 2021, APPL INTELL, V51, P1133, DOI 10.1007/s10489-020-01886-y
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bollella P, 2020, INT J UNCONV COMPUT, V15, P127
   Cai Zhong-Min, 2003, Chinese Journal of Computers, V26, P361
   Cerrudo Cesar., 2017, SECURING SMART CITIE, V17, P137
   Chen SJ, 2021, COMPUT SECUR, V104, DOI 10.1016/j.cose.2020.102095
   Chuang LY, 2011, COMPUT BIOL MED, V41, P228, DOI 10.1016/j.compbiomed.2011.02.004
   Das I, 1998, SIAM J OPTIMIZ, V8, P631, DOI 10.1137/S1052623496307510
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deb K., 2014, SEARCH METHODOLOGIES, P403, DOI DOI 10.1007/978-1-4614-6940-7_15
   Deb K, 2014, IEEE T EVOLUT COMPUT, V18, P577, DOI 10.1109/TEVC.2013.2281535
   Ding Y. S., 2001, ACTA SIMULATA SYSTEM
   Fern Soon Hui, 2022, Proceedings of the 6th International Conference on Electrical, Control and Computer Engineering: InECCE2021. Lecture Notes in Electrical Engineering (842), P1057, DOI 10.1007/978-981-16-8690-0_92
   Ferrag MA, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102419
   Ibrahim LM, 2013, J ENG SCI TECHNOL, V8, P107
   Injadat MN, 2021, IEEE T NETW SERV MAN, V18, P1803, DOI 10.1109/TNSM.2020.3014929
   Injadat M, 2020, KNOWL-BASED SYST, V200, DOI 10.1016/j.knosys.2020.105992
   Jadwal Pankaj Kumar, MICROSYST TECHNOL, P1
   Jatoth C, 2019, FUTURE GENER COMP SY, V94, P185, DOI 10.1016/j.future.2018.11.022
   Jazayeri N, 2021, EVOL INTELL, V14, P1763, DOI 10.1007/s12065-020-00453-1
   Jianping X., 2021, FRONTIERS DATA COMPU, V3, P59
   Kilincer IF, 2021, COMPUT NETW, V188, DOI 10.1016/j.comnet.2021.107840
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Liu L, 2021, IEEE ACCESS, V9, P7550, DOI 10.1109/ACCESS.2020.3048198
   Mittal M, 2023, SOFT COMPUT, V27, P13039, DOI 10.1007/s00500-021-06608-1
   Moizuddin M, 2022, KNOWL-BASED SYST, V238, DOI 10.1016/j.knosys.2021.107894
   MontazeriShatoori M, 2020, 2020 IEEE INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, INTL CONF ON CLOUD AND BIG DATA COMPUTING, INTL CONF ON CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P63, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00026
   Paun G., 2005, DNA COMPUTING NEW CO
   Prada Alessandro, 2019, Applied Mechanics and Materials, V887, P140, DOI 10.4028/www.scientific.net/AMM.887.140
   Prasad M, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105980
   Sharafaldin I, 2019, INT CARN CONF SECU
   Sharafaldin I, 2018, ICISSP: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY, P108, DOI 10.5220/0006639801080116
   Shukla A, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON FUTURISTIC TRENDS ON COMPUTATIONAL ANALYSIS AND KNOWLEDGE MANAGEMENT (ABLAZE), P515, DOI 10.1109/ABLAZE.2015.7154916
   Smith DC, 2021, J ENERGY NAT RESO LA, V39, P265, DOI 10.1080/02646811.2021.1943935
   Usman A. M., 2020, INT C EMERGING APPL, P124
   Xiao JH, 2009, COMPUT MATH APPL, V57, P1949, DOI 10.1016/j.camwa.2008.10.021
   Xiao J, 2018, COMPLEXITY, DOI 10.1155/2018/3051854
   Yan BH, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6026878
   Zang WK, 2018, FUTURE GENER COMP SY, V81, P465, DOI 10.1016/j.future.2017.07.036
   Zeng ZR, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/8986243
   Zhang JW, 2020, COMPUT SECUR, V89, DOI 10.1016/j.cose.2019.101681
   Zhou J, 2020, IEEE ACCESS, V8, P19306, DOI 10.1109/ACCESS.2020.2967061
   Zhou JY, 2022, MAGN RESON MED, V88, P546, DOI 10.1002/mrm.29241
   Zhu YY, 2017, KNOWL-BASED SYST, V116, P74, DOI 10.1016/j.knosys.2016.10.030
NR 50
TC 1
Z9 1
U1 6
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2023
VL 19
IS 3
SU S
AR 126
DI 10.1145/3561057
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FU9
UT WOS:001011934700001
OA Green Published
DA 2024-07-18
ER

PT J
AU Huang, WX
   Jia, XM
   Zhong, X
   Wang, X
   Jiang, K
   Wang, Z
AF Huang, Wenxin
   Jia, Xuemei
   Zhong, Xian
   Wang, Xiao
   Jiang, Kui
   Wang, Zheng
TI Beyond the Parts: Learning Coarse-to-Fine Adaptive Alignment
   Representation for Person Search
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Person search; alignment representation learning; coarse-to-fine;
   Part-Attentional Progressive Module; Re-weighting Alignment Module
AB Person search is a time-consuming computer vision task that entails locating and recognizing query people in scenic pictures. Body components are commonly mismatched during matching due to position variation, occlusions, and partially absent body parts, resulting in unsatisfactory person search results. Existing approaches for extracting local characteristics of the human body using keypoint information are unable to handle the search job when distinct body parts are misaligned, ignoring to exploit multiple granularities, which is crucial in the person search process. Moreover, the alignment learning methods learn body part features with fixed and equal weights, ignoring the beneficial contextual information, e.g., the umbrella carried by the pedestrian, which supplements compelling clues for identifying the person. In this paper, we propose a Coarse-to-Fine Adaptive Alignment Representation (CFA(2)R) network for learning multiple granular features in misaligned person search in the coarse-to-fine perspective. To exploit more beneficial body parts and related context of the cropped pedestrians, we design a Part-Attentional Progressive Module (PAPM) to guide the network to focus on informative body parts and positive accessorial regions. Besides, we propose a Re-weighting Alignment Module (RAM) shedding light on more contributive parts instead of treating them equally. Specifically, adaptive re-weighted but not fixed part features are reconstructed by Re-weighting Reconstruction module, considering that different parts serve unequally during image matching. Extensive experiments conducted on CUHK-SYSU and PRW datasets demonstrate competitive performance of our proposed method.
C1 [Huang, Wenxin] Hubei Univ, Sch Comp Sci & Informat Engn, 368 Youyi Ave, Wuhan 430062, Peoples R China.
   [Jia, Xuemei; Jiang, Kui; Wang, Zheng] Wuhan Univ, Sch Comp Sci, 299 Bayi Rd, Wuhan 430072, Peoples R China.
   [Zhong, Xian] Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, 21 Gongda Rd, Wuhan 430070, Peoples R China.
   [Zhong, Xian] Peking Univ, Sch Elect Engn & Comp Sci, 5 Yiheyuan Rd, Beijing 100091, Peoples R China.
   [Wang, Xiao] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, 2 West Huangjiahu Rd, Wuhan 430081, Peoples R China.
C3 Hubei University; Wuhan University; Wuhan University of Technology;
   Peking University; Wuhan University of Science & Technology
RP Jia, XM (corresponding author), Wuhan Univ, Sch Comp Sci, 299 Bayi Rd, Wuhan 430072, Peoples R China.; Zhong, X (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, 21 Gongda Rd, Wuhan 430070, Peoples R China.; Zhong, X (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, 5 Yiheyuan Rd, Beijing 100091, Peoples R China.
EM wenxinhuang_wh@163.com; jiaxuemeiL@163.com; zhongx@whut.edu.cn;
   wangxiao2021@wust.edu.cn; kuijiang@whu.edu.cn; wangzwhu@whu.edu.cn
RI Jiang, Kui/Z-2573-2019; Huang, Wenxin/AFN-5558-2022
OI Jiang, Kui/0000-0002-4055-7503; 
FU Department of Science and Technology, Hubei Provincial People's
   Government [2021CFB281, 2021CFB513]; National Natural Science Foundation
   of China [62271361, 62171325]
FX This work was supported in part by the Department of Science and
   Technology, Hubei Provincial People's Government under Grants 2021CFB281
   and 2021CFB513, and the National Natural Science Foundation of China
   under Grants 62271361 and 62171325.
CR Ainam JP, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377352
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chang XJ, 2018, LECT NOTES COMPUT SC, V11213, P86, DOI 10.1007/978-3-030-01240-3_6
   Chen D, 2021, INT J COMPUT VISION, V129, P3154, DOI 10.1007/s11263-021-01512-5
   Chen D, 2020, AAAI CONF ARTIF INTE, V34, P10518
   Chen D, 2018, LECT NOTES COMPUT SC, V11211, P764, DOI 10.1007/978-3-030-01234-2_45
   Chen D, 2020, IEEE T IMAGE PROCESS, V29, P4669, DOI 10.1109/TIP.2020.2973513
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai J, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107120
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Dong WK, 2020, PROC CVPR IEEE, P2836, DOI 10.1109/CVPR42600.2020.00291
   Dong WK, 2020, PROC CVPR IEEE, P2582, DOI 10.1109/CVPR42600.2020.00266
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Han CC, 2021, AAAI CONF ARTIF INTE, V35, P1505
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He ZW, 2019, LECT NOTES COMPUT SC, V11362, P349, DOI 10.1007/978-3-030-20890-5_23
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang WX, 2021, NEURAL COMPUT APPL, V33, P961, DOI 10.1007/s00521-020-05314-7
   Jia XM, 2022, IEEE T IMAGE PROCESS, V31, P4227, DOI 10.1109/TIP.2022.3183469
   Jiang K, 2021, IEEE T CIRC SYST VID, V31, P3981, DOI 10.1109/TCSVT.2020.3044887
   Jing XY, 2017, IEEE T IMAGE PROCESS, V26, P1363, DOI 10.1109/TIP.2017.2651364
   Kim H, 2021, PROC CVPR IEEE, P4863, DOI 10.1109/CVPR46437.2021.00483
   Lan X, 2018, LECT NOTES COMPUT SC, V11205, P553, DOI 10.1007/978-3-030-01246-5_33
   Li JH, 2019, IEEE INT CON MULTI, P1114, DOI 10.1109/ICME.2019.00195
   Li W, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107862
   Li Wenbo, 2018, PROC SPRINGER ASIAN, V11361, P467
   Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu C, 2021, NEUROCOMPUTING, V465, P184, DOI 10.1016/j.neucom.2021.08.136
   Liu H, 2017, IEEE I CONF COMP VIS, P493, DOI 10.1109/ICCV.2017.61
   Liu JW, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3450, DOI 10.1145/3394171.3413878
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Pang YW, 2019, IEEE I CONF COMP VIS, P4966, DOI 10.1109/ICCV.2019.00507
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607
   Wang X, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4463, DOI 10.1145/3474085.3475599
   Wang X, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3380549
   Xiao J, 2016, IEEE T MULTIMEDIA, V18, P1691, DOI 10.1109/TMM.2016.2581590
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xu X, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3414839
   Xu X, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2021.107827
   Yan YC, 2021, PROC CVPR IEEE, P7686, DOI 10.1109/CVPR46437.2021.00760
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18
   Yu T, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243217
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang XY, 2021, AAAI CONF ARTIF INTE, V35, P3412
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zhong X, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5316, DOI 10.1145/3474085.3475654
   Zhong X, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4250, DOI 10.1109/ICASSP39728.2021.9415107
   Zhong YJ, 2020, PROC CVPR IEEE, P6826, DOI 10.1109/CVPR42600.2020.00686
   Zhou SR, 2021, NEURAL COMPUT APPL, V33, P4001, DOI 10.1007/s00521-020-05566-3
NR 68
TC 7
Z9 7
U1 6
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2023
VL 19
IS 3
AR 105
DI 10.1145/3565886
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FQ5
UT WOS:001011930300005
DA 2024-07-18
ER

PT J
AU Li, L
   Zhou, ZY
   Wu, SP
   Cao, YR
AF Li, Lei
   Zhou, Zhiyuan
   Wu, Suping
   Cao, Yongrong
TI Multi-scale Edge-guided Learning for 3D Reconstruction
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; multi-scale Gaussians difference; multi-scale feature
   interaction; dynamic probability fusion
ID SHAPE
AB Single-view three-dimensional (3D) object reconstruction has always been a long-term challenging task. Objects with complex topologies are hard to accurately reconstruct, which makes existing methods suffer from blurring of shape boundaries between multiple components in the object. Moreover, most of them cannot balance learning between global geometric structure information and local detail information. In this article, we propose a multi-scale edge-guided learning network (MEGLN) to utilize the global edge information guiding the network to better capture and recover local details. The goal is to exploit the multi-scale learning strategy to learn global edge information and local details, thus achieving robust 3D object reconstruction. We first design a multi-scale Gaussian difference block (MGDB) to extract global edge geometry features for input images of different scales and adopt the attention mechanism to aggregate the extracted global edge geometry features of different scales. Second, we design a multi-scale feature interaction block (MFIB) to learn local details, which utilizes the multi-scale feature interaction to capture the features of multiple objects or components at multiple scales. The MFIB can learn and capture better as much local detail information as possible under the guidance of global edge information. Finally, we dynamically fuse the predicted probabilities of the MGDB and MFIB to obtain the final predicted result, which makes our MEGLN able to recover 3D shapes with global complex topological structures and rich local details via the multi-scale learning strategy. Extensive qualitative and quantitative experimental results on the ShapeNet dataset demonstrate that our approach achieves competitive performance compared with state-of-the-art methods. Code is available at https://github.com/Ray-tju/MEGLN.
C1 [Li, Lei; Zhou, Zhiyuan; Wu, Suping; Cao, Yongrong] Ningxia Univ, 489 Helanshan West Rd, Yinchuan 750021, Ningxia, Peoples R China.
C3 Ningxia University
RP Wu, SP (corresponding author), Ningxia Univ, 489 Helanshan West Rd, Yinchuan 750021, Ningxia, Peoples R China.
EM lei_li@tongji.edu.cn; zy980203123@163.com; pswuu@nxu.edu.cn;
   yongrongc3@gmail.com
RI Li, Lei/IYT-2371-2023
OI Li, Lei/0000-0002-0253-516X; Zhou, Zhiyuan/0000-0002-6871-6043
FU National Natural Science Foundation of China [61662059, 62062056];
   Ningxia Graduate Education and Teaching Reform Research and Practice
   Project 2021
FX This work is supported in part by the National Natural Science
   Foundation of China (grant no. 62062056), in part by Ningxia Graduate
   Education and Teaching Reform Research and Practice Project 2021, and in
   part by the National Natural Science Foundation of China (grant no.
   61662059).
CR Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   De Vries Harm, 2017, Advances in Neural Information Processing Systems, V30
   Dong Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P323, DOI 10.1007/978-3-030-58604-1_20
   DRUCKER H, 1992, IEEE T NEURAL NETWOR, V3, P991, DOI 10.1109/72.165600
   Dumoulin V, 2017, Arxiv, DOI arXiv:1606.00704
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Garland M, 1998, VISUALIZATION '98, PROCEEDINGS, P263, DOI 10.1109/VISUAL.1998.745312
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Guiducci A, 1998, COMPUT VIS IMAGE UND, V70, P212, DOI 10.1006/cviu.1997.0633
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Kanazawa A, 2016, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2016.354
   Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   [李雷 Li Lei], 2022, [自动化学报, Acta Automatica Sinica], V48, P1105
   Li L, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4265, DOI 10.1109/ICASSP39728.2021.9413649
   Li L, 2021, INT C PATT RECOG, P7219, DOI 10.1109/ICPR48806.2021.9411960
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Michalkiewicz M, 2020, Arxiv, DOI arXiv:2005.04623
   MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Oswald MR, 2012, PROC CVPR IEEE, P534, DOI 10.1109/CVPR.2012.6247718
   Pontes JK, 2019, LECT NOTES COMPUT SC, V11361, P365, DOI 10.1007/978-3-030-20887-5_23
   Prados E, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P375, DOI 10.1007/0-387-28831-7_23
   Richter SR, 2018, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR.2018.00207
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sun XF, 2019, IEEE-CAA J AUTOMATIC, V6, P118, DOI 10.1109/jas.2017.7510673
   Sun YB, 2018, Arxiv, DOI arXiv:1804.06375
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu J, 2017, ADV NEUR IN, V30
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xu Qiangeng, 2019, Advances in Neural Information Processing Systems, V32
   Yang L, 2020, IEEE-CAA J AUTOMATIC, V7, P991, DOI 10.1109/JAS.2020.1003234
   Yu Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10988, DOI 10.1109/CVPR42600.2020.01100
   Zhang L, 2002, J VISUAL COMP ANIMAT, V13, P225, DOI 10.1002/vis.291
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang X, 2018, ADV NEUR IN, V31
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 57
TC 4
Z9 4
U1 5
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2023
VL 19
IS 3
AR 109
DI 10.1145/3568678
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FQ5
UT WOS:001011930300009
DA 2024-07-18
ER

PT J
AU Liu, YQ
   Zhang, XF
   Wang, SS
   Ma, SW
   Gao, W
AF Liu, Yuqing
   Zhang, Xinfeng
   Wang, Shanshe
   Ma, Siwei
   Gao, Wen
TI Sequential Hierarchical Learning with Distribution Transformation for
   Image Super-Resolution
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image super-resolution; multi-scale; distribution transformation; neural
   network
ID NETWORKS; ATTENTION
AB Multi-scale design has been considered in recent image super-resolution (SR) works to explore the hierarchical feature information. Existing multi-scale networks aim at building elaborate blocks or progressive architecture for restoration. In general, larger scale features concentrate more on structural and high-level information, while smaller scale features contain plentiful details and textured information. In this point of view, information from larger scale features can be derived from smaller ones. Based on the observation, in this article, we build a sequential hierarchical learning super-resolution network (SHSR) for effective image SR. Specially, we consider the inter-scale correlations of features, and devise a sequential multi-scale block (SMB) to progressively explore the hierarchical information. SMB is designed in a recursive way based on the linearity of convolution with restricted parameters. Besides the sequential hierarchical learning, we also investigate the correlations among the feature maps and devise a distribution transformation block (DTB). Different from attention-based methods, DTB regards the transformation in a normalization manner, and jointly considers the spatial and channel-wise correlations with scaling and bias factors. Experiment results show SHSR achieves superior quantitative performance and visual quality to state-of-the-art methods with near 34% parameters and 50% MACs off when scaling factor is x4. To boost the performance without further training, the extension model SHSR+ with self-ensemble achieves competitive performance than larger networks with near 92% parameters and 42% MACs off with scaling factor x4.
C1 [Liu, Yuqing] Dalian Univ Technol, Sch Software, Dalian 116620, Liaoning, Peoples R China.
   [Zhang, Xinfeng] Univ Chinese Acad Sci, 19 A Yuquan Rd, Beijing 100049, Peoples R China.
   [Wang, Shanshe; Ma, Siwei; Gao, Wen] Peking Univ, 5 Yiheyuan Rd, Beijing 100087, Peoples R China.
C3 Dalian University of Technology; Chinese Academy of Sciences; University
   of Chinese Academy of Sciences, CAS; Peking University
RP Liu, YQ (corresponding author), Dalian Univ Technol, Sch Software, Dalian 116620, Liaoning, Peoples R China.
EM liuyuqing@mail.dlut.edu.cn; xfzhang@ucas.ac.cn; sswang@pku.edu.cn;
   swma@pku.edu.cn; wgao@pku.edu.cn
RI Liu, LiuYuqing/GWZ-5665-2022; Zhang, Xinfeng/X-8148-2019
OI Zhang, Xinfeng/0000-0002-7517-3868; Liu, Yuqing/0000-0001-9828-5646
FU National Natural Science Foundation of China [62031013, 62072008];
   National Key Research and Development Project [2019YFF0302703]; High
   Performance Computing Platform of Peking University
FX This work was supported in part by the National Natural Science
   Foundation of China under grant (62031013, 62072008); in part by the
   National Key Research and Development Project (2019YFF0302703); and in
   part by the High Performance Computing Platform of Peking University,
   which are gratefully acknowledged.
CR Afzal H, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177756
   Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ainam JP, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377352
   Anwar S., 2020, IEEE T PATTERN ANAL, V1, P1
   Behjati P, 2020, Arxiv, DOI arXiv:2012.04578
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Choi JS, 2017, IEEE COMPUT SOC CONF, P1150, DOI 10.1109/CVPRW.2017.153
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong XY, 2021, IEEE T GEOSCI REMOTE, V59, P3473, DOI 10.1109/TGRS.2020.3019660
   Fan YC, 2017, IEEE COMPUT SOC CONF, P1157, DOI 10.1109/CVPRW.2017.154
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   Haris M, 2021, IEEE T PATTERN ANAL, V43, P4323, DOI 10.1109/TPAMI.2020.3002836
   He XY, 2019, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2019.00183
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YT, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107831
   Hu YT, 2020, IEEE T CIRC SYST VID, V30, P3911, DOI 10.1109/TCSVT.2019.2915238
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang K, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107475
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lan RS, 2021, IEEE T CYBERNETICS, V51, P1443, DOI 10.1109/TCYB.2020.2970104
   Li B, 2020, IEEE T IMAGE PROCESS, V29, P8368, DOI 10.1109/TIP.2020.3014953
   Li JC, 2021, IEEE T CIRC SYST VID, V31, P2547, DOI 10.1109/TCSVT.2020.3027732
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li MY, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377874
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu H, 2020, INT CONF ACOUST SPEE, P1818, DOI [10.1109/ICASSP40776.2020.9053890, 10.1109/icassp40776.2020.9053890]
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Luo Z, 2020, P 34 INT C NEURAL IN
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Paszke A, 2019, ADV NEUR IN, V32
   Qiu YJ, 2019, IEEE I CONF COMP VIS, P4179, DOI 10.1109/ICCV.2019.00428
   Ren HY, 2017, IEEE COMPUT SOC CONF, P1050, DOI 10.1109/CVPRW.2017.142
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tang YL, 2020, IEEE T NEUR NET LEAR, V31, P1514, DOI 10.1109/TNNLS.2019.2920852
   Wan J, 2021, IEEE T BROADCAST, V67, P372, DOI 10.1109/TBC.2020.3028356
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wu HP, 2021, IEEE T CIRC SYST VID, V31, P512, DOI 10.1109/TCSVT.2020.2988895
   Yu Q, 2017, INT J COMPUT VISION, V122, P411, DOI 10.1007/s11263-016-0932-3
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang DY, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3398685
   Zhang HR, 2021, IEEE J-STSP, V15, P253, DOI 10.1109/JSTSP.2020.3045282
   Zhang K, 2020, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR42600.2020.00328
   Zhang K, 2019, PROC CVPR IEEE, P1671, DOI 10.1109/CVPR.2019.00177
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 65
TC 1
Z9 1
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2023
VL 19
IS 1
SU S
AR 44
DI 10.1145/3532864
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Q4HK
UT WOS:000927169800018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhuang, WM
   Gan, X
   Wen, YG
   Zhang, S
AF Zhuang, Weiming
   Gan, Xin
   Wen, Yonggang
   Zhang, Shuai
TI Optimizing Performance of Federated Person Re-identification:
   Benchmarking and Analysis
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Federated learning; person re-identification
AB Increasingly stringent data privacy regulations limit the development of person re-identification (ReID) because person ReID training requires centralizing an enormous amount of data that contains sensitive personal information. To address this problem, we introduce federated person re-identification (FedReID)-implementing federated learning, an emerging distributed training method, to person ReID. FedReID preserves data privacy by aggregating model updates, instead of raw data, from clients to a central server. Furthermore, we optimize the performance of FedReID under statistical heterogeneity via benchmark analysis. We first construct a benchmark with an enhanced algorithm, two architectures, and nine person ReID datasets with large variances to simulate the real-world statistical heterogeneity. The benchmark results present insights and bottlenecks of FedReID under statistical heterogeneity, including challenges in convergence and poor performance on datasets with large volumes. Based on these insights, we propose three optimization approaches: (1) we adopt knowledge distillation to facilitate the convergence of FedReID by better transferring knowledge from clients to the server, (2) we introduce client clustering to improve the performance of large datasets by aggregating clients with similar data distributions, and (3) we propose cosine distance weight to elevate performance by dynamically updating the weights for aggregation depending on how well models are trained in clients. Extensive experiments demonstrate that these approaches achieve satisfying convergence with much better performance on all datasets. We believe that FedReID will shed light on implementing and optimizing federated learning on more computer vision applications.
C1 [Zhuang, Weiming; Gan, Xin; Wen, Yonggang] Nanyang Technol Univ, S Lab, ABN-02b-11,Acad Block North,61 Nanyang Dr, Singapore 637335, Singapore.
   [Zhang, Shuai] SenseTime Res, 182 Cecil St,36-02 Frasers Tower, Singapore 069547, Singapore.
C3 Nanyang Technological University
RP Zhuang, WM (corresponding author), Nanyang Technol Univ, S Lab, ABN-02b-11,Acad Block North,61 Nanyang Dr, Singapore 637335, Singapore.
EM weiming001@e.ntu.edu.sg; ganx0005@e.ntu.edu.sg; ygwen@ntu.edu.sg;
   zhangshuai@sensetime.com
RI Wen, Yonggang/P-9406-2017
OI Wen, Yonggang/0000-0002-2751-5114
FU RIE2020 Industry Alignment Fund-Industry Collaboration Projects
   (IAF-ICP) Funding Initiative; Singapore MOE under its Tier 1 grant call
   [RG96/20]; Natioanl Research Foundation, Prime Minister's Office,
   Singapore, under its Sustainable Tropical Data Centre Testbed programme
   (STDCT), and its Central Gap Fund ("Central Gap" Award)
   [NRF2020NRF-CG001-027]
FX This work was supported in part by the RIE2020 Industry Alignment
   Fund-Industry Collaboration Projects (IAF-ICP) Funding Initiative, as
   well as cash and in-kind contribution from the industry partner(s);
   Singapore MOE under its Tier 1 grant call (Reference No. RG96/20);
   Natioanl Research Foundation, Prime Minister's Office, Singapore, under
   its Sustainable Tropical Data Centre Testbed programme (STDCT), and its
   Central Gap Fund ("Central Gap" Award No. NRF2020NRF-CG001-027).
CR Acar Durmus Alp Emre, 2020, INT C LEARN REPR
   [Anonymous], 2011, ACM WORKSH HUM GEST
   Avent B., 2021, arXiv
   Caldas S., 2018, arXiv
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen YQ, 2020, IEEE INTELL SYST, V35, P83, DOI 10.1109/MIS.2020.2988604
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Custers B., 2019, EU personal data protection in policy and practice
   Dean J., 2012, ADV NEURAL INFORM PR, P1223
   Dean J., 2015, NIPS DEEP LEARNING R
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu JL, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629
   Hu S., 2020, arXiv
   Karimireddy SP, 2020, PR MACH LEARN RES, V119
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li D, 2018, AAAI CONF ARTIF INTE, P3490
   Li QB, 2021, PROC CVPR IEEE, P10708, DOI 10.1109/CVPR46437.2021.01057
   Li T., 2020, PROC MACH LEARN SYST, V2, P429, DOI DOI 10.48550/ARXIV.1812.06127
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Loy CC, 2013, IEEE IMAGE PROC, P3567, DOI 10.1109/ICIP.2013.6738736
   Luo JH, 2021, Arxiv, DOI arXiv:1910.11089
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Muhammad K, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1234, DOI 10.1145/3394486.3403176
   Niu C., 2020, P 26 ANN INT C MOB C, P1
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Sarfraz MS, 2019, PROC CVPR IEEE, P8926, DOI 10.1109/CVPR.2019.00914
   Shankar S, 2018, Arxiv, DOI arXiv:1804.10745
   Sheller MJ, 2019, LECT NOTES COMPUT SC, V11383, P92, DOI 10.1007/978-3-030-11723-8_9
   Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun P, 2022, IEEE T BIG DATA, V8, P495, DOI 10.1109/TBDATA.2019.2957478
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tianshu Hao, 2019, Benchmarking, Measuring, and Optimizing. First BenchCouncil International Symposium, Bench 2018. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 11459), P23, DOI 10.1007/978-3-030-32813-9_3
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang H., 2020, P INT C LEARNING REP
   Wang JY, 2020, Arxiv, DOI arXiv:2007.07481
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu GL, 2021, AAAI CONF ARTIF INTE, V35, P2898
   Yang JW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1074, DOI 10.1145/3240508.3240645
   Yao Xin, 2019, P NIPS FEDERATED LEA
   Ye M, 2021, Arxiv, DOI arXiv:2001.04193
   Zhang Y., 2021, ICCV, P4420
   Zhao Y, 2022, Arxiv, DOI arXiv:1806.00582
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhuang WM, 2022, IEEE INTERNET THINGS, V9, P13740, DOI 10.1109/JIOT.2022.3143842
   Zhuang WM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P955, DOI 10.1145/3394171.3413814
   Zhuang Weiming, 2022, P INT C LEARNING REP
   Zhuang Weiming, 2021, P IEEECVF INT C COMP, P4912
NR 62
TC 6
Z9 6
U1 1
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2023
VL 19
IS 1
SU S
AR 38
DI 10.1145/3531013
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Q4HK
UT WOS:000927169800012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chowdhury, DR
   Nandi, S
   Goswami, D
AF Chowdhury, Debanjan Roy
   Nandi, Sukumar
   Goswami, Diganta
TI Distributed Gateway Selection for Video Streaming in VANET Using IP
   Multicast
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE VANET; heterogenous vehicular network; video streaming; gateway
   selection; IP multicast
ID ROUTING PROTOCOL; ARCHITECTURE; ALGORITHM; STANDARDS; QUALITY; DSRC
AB The volume of video traffic as infotainment service over vehicular ad hoc network (VANET) has rapidly increased for past few years. Providing video streaming as VANET infotainment service is very challenging because of high mobility and heterogeneity of vehicular networks. While the number of mobile gateways (vehicles connected to the Internet) needs to be minimized to reduce service cost, the streaming quality also needs to be satisfactory for end-users. Existing works either focus on gateway minimization or focus on enhancing user satisfaction. We propose a video streaming solution, namely, DGSVS, which does gateway minimization with the constrained time data delivery to end-users. We formulate our constrained gateway minimization problem as minimum set covering (MSC) problem and solve with a distributed approximation method for MSC. We assume that only a subset of vehicles in VANET run DGSVS application. Therefore, instead of application layer cooperation for gateway-client association, network layer cooperation is proposed. We propose a novel multicast protocol DSS-CAST for this purpose, which is specialized in streaming data distribution for dynamic scenarios. We compare the performance of DGSVS with other existing protocols and found that DGSVS is most effective in service cost minimization while it is able to achieve competitive QoE performance.
C1 [Chowdhury, Debanjan Roy; Nandi, Sukumar; Goswami, Diganta] Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Chowdhury, DR (corresponding author), Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati, Assam, India.
EM chowdhur@iitg.ac.in; sukumar@iitg.ac.in; dgoswami@iitg.ac.in
RI Nandi, Sukumar/AGV-8994-2022
OI Nandi, Sukumar/0000-0002-5869-1057; Roy Chowdhury,
   Debanjan/0000-0002-8422-7768
CR Ahmad I, 2018, COMPUT NETW, V145, P128, DOI 10.1016/j.comnet.2018.08.018
   Aliyu A, 2018, IEEE ACCESS, V6, P47610, DOI 10.1109/ACCESS.2018.2854784
   Balachandran A, 2013, ACM SIGCOMM COMP COM, V43, P339, DOI 10.1145/2534169.2486025
   Benslimane A, 2011, IEEE J SEL AREA COMM, V29, P559, DOI 10.1109/JSAC.2011.110306
   Canourgues L, 2006, MILCOM 2006, VOLS 1-7, P174
   Chekkouri AS, 2018, COMPUT NETW, V140, P15, DOI 10.1016/j.comnet.2018.04.013
   Cormen T.H., 2009, INTRO ALGORITHMS
   De Felice M, 2015, COMPUT COMMUN, V58, P40, DOI 10.1016/j.comcom.2014.08.009
   Duan XY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510994
   Fiore M, 2008, MOBIHOC'08: PROCEEDINGS OF THE NINTH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P261
   JACQUET P, 2002, MULTICAST OPTIMIZED
   Jia LJ, 2002, DISTRIB COMPUT, V15, P193, DOI 10.1007/s00446-002-0078-0
   Kenney JB, 2011, P IEEE, V99, P1162, DOI 10.1109/JPROC.2011.2132790
   Khan H, 2020, IEEE T VEH TECHNOL, V69, P3513, DOI 10.1109/TVT.2020.2975068
   Khelifi H, 2020, IEEE COMMUN SURV TUT, V22, P320, DOI 10.1109/COMST.2019.2894816
   Kim HL, 2010, INT CONF ADV COMMUN, P1377
   Kuipers F, 2010, LECT NOTES COMPUT SC, V6074, P216
   Lee SJ, 2002, MOBILE NETW APPL, V7, P441, DOI 10.1023/A:1020756600187
   Liang B., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P1293, DOI 10.1109/INFCOM.2000.832522
   Loulloudes N, 2015, 2015 IEEE CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC), P192, DOI 10.1109/CIC.2015.25
   Luo JH, 2009, IEEE COMMUN SURV TUT, V11, P78, DOI 10.1109/SURV.2009.090107
   Molina-Masegosa R, 2020, IEEE ACCESS, V8, P121526, DOI 10.1109/ACCESS.2020.3007115
   Morgan YL, 2010, IEEE COMMUN SURV TUT, V12, P504, DOI 10.1109/SURV.2010.033010.00024
   Naboulsi D, 2017, IEEE T MOBILE COMPUT, V16, P1272, DOI 10.1109/TMC.2016.2591527
   Naeimipoor F, 2014, IEEE ICC, P112, DOI 10.1109/ICC.2014.6883304
   Oh SY, 2008, J PARALLEL DISTR COM, V68, P1044, DOI 10.1016/j.jpdc.2008.04.004
   Omar HA, 2015, IEEE T EMERG TOP COM, V3, P335, DOI 10.1109/TETC.2015.2395077
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Pallis G, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS & SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS (MASCOTS), P502
   Perkins CE, 1999, WMCSA '99, SECOND IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P90, DOI 10.1109/MCSA.1999.749281
   Retal S, 2019, COMPUT ELECTR ENG, V73, P289, DOI 10.1016/j.compeleceng.2018.12.004
   Rezende C, 2015, IEEE T COMPUT, V64, P614, DOI 10.1109/TC.2014.2308176
   Rezende C, 2014, AD HOC NETW, V17, P1, DOI 10.1016/j.adhoc.2013.12.011
   Tariq A, 2020, IEEE COMMUN SURV TUT, V22, P68, DOI 10.1109/COMST.2019.2935795
   Ucar S, 2016, IEEE T VEH TECHNOL, V65, P2621, DOI 10.1109/TVT.2015.2421277
   Wu C, 2020, IEEE T COGN COMMUN, V6, P1155, DOI 10.1109/TCCN.2020.3002253
   Wu C, 2018, IEEE COMMUN MAG, V56, P22, DOI 10.1109/MCOM.2018.1800089
   Yaacoub E, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2330343
   Yin Xiaoqi, 2015, ACM SIGCOMM COMP COM, P325
   Zhioua GE, 2015, IEEE T VEH TECHNOL, V64, P804, DOI 10.1109/TVT.2014.2323693
   Zhou H, 2018, IEEE T VEH TECHNOL, V67, P7924, DOI 10.1109/TVT.2018.2847325
   Zhuang WH, 2020, P IEEE, V108, P274, DOI 10.1109/JPROC.2019.2951169
NR 42
TC 3
Z9 3
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2022
VL 18
IS 3
AR 81
DI 10.1145/3491388
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5UA
UT WOS:000772650600015
DA 2024-07-18
ER

PT J
AU Shi, R
   Ma, J
   Ngan, KN
   Xiong, J
   Qiao, T
AF Shi, Ran
   Ma, Jing
   Ngan, King Ngi
   Xiong, Jian
   Qiao, Tong
TI Objective Object Segmentation Visual Quality Evaluation: Quality Measure
   and Pooling Method
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Visual quality evaluation; object segmentation; objective measure;
   pooling method
ID IMAGE; DEEP
AB Objective object segmentation visual quality evaluation is an emergent member of the visual quality assessment family. It aims to develop an objective measure instead of a subjective survey to evaluate the object segmentation quality in agreement with human visual perception. It is an important benchmark for assessing and comparing the performances of object segmentation methods in terms of visual quality. Despite its essential role, sufficient study compared with other visual quality evaluation studies is still lacking. In this article, we propose a novel full-reference objective measure that includes a two-level single object segmentation visual quality measure and a pooling method for multiple object segmentation overall visual quality. The single object segmentation visual quality measure combines a pixel-level sub-measure and a region-level sub-measure for evaluating the similarity of area, shape, and object completeness between the segmentation result and the ground truth in terms of human visual perception. For the proposed multiple object segmentation overall visual quality pooling method, the rank of each object's segmentation quality as a novel factor is integrated into the weighted harmonic mean to evaluate the overall quality. To evaluate the performance of our proposed measure, we tested it on an object segmentation subjective visual quality assessment database. The experimental results demonstrate that our proposed two-level measure and pooling method with good robustness perform better in matching subjective assessments compared with other state-of-the-art objective measures.
C1 [Shi, Ran; Ma, Jing] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
   [Ngan, King Ngi] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Xiong, Jian] Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing, Peoples R China.
   [Qiao, Tong] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Peoples R China.
C3 Nanjing University of Science & Technology; University of Electronic
   Science & Technology of China; Nanjing University of Posts &
   Telecommunications; Hangzhou Dianzi University
RP Qiao, T (corresponding author), Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Peoples R China.
EM rshi@njust.edu.cn; majing1998120@163.com; knngan@uestc.edu.cn;
   jxiong@njupt.edu.cn; tong.qiao@hdu.edu.cn
RI Ngan, N/E-8240-2014
OI Ngan, N/0000-0003-1946-3235
FU National Natural Science Foundation of China [61801219, 61701258,
   61702150]
FX This work was supported by the National Natural Science Foundation of
   China under grants 61801219, 61701258 and 61702150.
CR [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Berezsky O, 2016, 2016 XITH INTERNATIONAL SCIENTIFIC AND TECHNICAL CONFERENCE COMPUTER SCIENCES AND INFORMATION TECHNOLOGIES (CSIT), P33, DOI 10.1109/STC-CSIT.2016.7589862
   Chen LJ, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SAFETY (ICSRS), P1, DOI [10.1109/ICSRS.2018.8688869, 10.1109/ICSRS.2018.00009]
   Chen ZZ, 2019, IEEE T IMAGE PROCESS, V28, P5785, DOI 10.1109/TIP.2019.2922072
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.32
   Dogra DP, 2012, J VIS COMMUN IMAGE R, V23, P150, DOI 10.1016/j.jvcir.2011.09.005
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fu ZQ, 2021, IEEE T MULTIMEDIA, V23, P2100, DOI 10.1109/TMM.2020.3008054
   Ge F, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2762250
   GELASCA ED, 2005, THESIS EPFL LAUSANNE
   Gelasca ED, 2009, IEEE J-STSP, V3, P319, DOI 10.1109/JSTSP.2009.2015067
   Han JG, 2013, NEUROCOMPUTING, V111, P70, DOI 10.1016/j.neucom.2012.12.015
   Hussain Tanveer, 2021, ARXIV PREPRINT ARXIV
   Jian Xiong, 2020, P 2 ACM INT C MULT A
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008
   Peng B, 2018, MACH VISION APPL, V29, P477, DOI 10.1007/s00138-017-0903-x
   Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI [10.1109/TPAMI.2015.2481406, 10.1109/TPAMI.2016.2537320]
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi R, 2015, IEEE T IMAGE PROCESS, V24, P5033, DOI 10.1109/TIP.2015.2473099
   Shi W, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Sim K, 2021, IEEE T MULTIMEDIA, V23, P4037, DOI 10.1109/TMM.2020.3037482
   Sofiiuk Konstantin, 2020, P IEEE CVF C COMP VI
   Villegas P, 2004, IEEE T IMAGE PROCESS, V13, P1092, DOI 10.1109/TIP.2004.828433
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wang WG, 2019, PROC CVPR IEEE, P5961, DOI 10.1109/CVPR.2019.00612
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Wu QB, 2020, IEEE T CIRC SYST VID, V30, P3883, DOI 10.1109/TCSVT.2020.2972566
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Zeng Y, 2019, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2019.00623
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649
   Zhang L, 2019, PROC CVPR IEEE, P6017, DOI 10.1109/CVPR.2019.00618
   Ziólko B, 2018, IEEE T FUZZY SYST, V26, P1789, DOI 10.1109/TFUZZ.2017.2752130
NR 44
TC 2
Z9 2
U1 6
U2 35
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2022
VL 18
IS 3
AR 73
DI 10.1145/3491229
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5UA
UT WOS:000772650600007
DA 2024-07-18
ER

PT J
AU Sun, ZY
   Zhang, YF
   Bao, FX
   Wang, P
   Yao, XX
   Zhang, CM
AF Sun, Ziyi
   Zhang, Yunfeng
   Bao, Fangxun
   Wang, Ping
   Yao, Xunxiang
   Zhang, Caiming
TI SADnet: Semi-supervised Single Image Dehazing Method Based on an
   Attention Mechanism
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Single image dehazing; practical applications; semi-supervised;
   attention; deep learning
ID HAZE
AB Many real-life tasks such as military reconnaissance and traffic monitoring require high-quality images. However, images acquired in foggy or hazy weather pose obstacles to the implementation of these real-life tasks; consequently, image dehazing is an important research problem. To meet the requirements of practical applications, a single image dehazing algorithm has to be able to effectively process real-world hazy images with high computational efficiency. In this article, we present a fast and robust semi-supervised dehazing algorithm named SADnet for practical applications. SADnet utilizes both synthetic datasets and natural hazy images for training, so it has good generalizability for real-world hazy images. Furthermore, considering the uneven distribution of haze in the atmospheric environment, a Channel-Spatial Self-Attention (CSSA) mechanism is presented to enhance the representational power of the proposed SADnet. Extensive experimental results demonstrate that the presented approach achieves good dehazing performances and competitive running times compared with other state-of-the-art image dehazing algorithms.
C1 [Sun, Ziyi; Zhang, Yunfeng] Shandong Univ Finance & Econ, Dept Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Bao, Fangxun] Shandong Univ, Dept Math, Jinan 250100, Peoples R China.
   [Wang, Ping] Quebec Univ, Ecole Technol Suprieure, Dept Software & IT Engn, Montreal, PQ, Canada.
   [Yao, Xunxiang] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW, Australia.
   [Zhang, Caiming] Shandong Univ, Dept Comp Sci & Technol, Jinan 250101, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University;
   University of Quebec; University of Technology Sydney; Shandong
   University
RP Zhang, YF (corresponding author), Shandong Univ Finance & Econ, Dept Comp Sci & Technol, Jinan 250014, Peoples R China.
EM sunziyi@mail.sdufe.edu.cn; yfzhang@sdufe.edu.cn; fxbao@sdu.edu.cn;
   ping.wang.1@ens.etsmtl.ca; yxxlxzw@126.com; czhang@sdu.edu.cn
RI Zhang, Caiming/AHD-6558-2022
OI Zhang, Caiming/0000-0002-6365-6221
FU National Natural Science Foundation of China [61972227, 61902217,
   U1609218]; Natural Science Foundation of Shandong Province
   [ZR201808160102, ZR2019BF043, ZR2019MF051]; Primary Research and
   Development Plan of Shandong Province [2018GGX101013]; Fostering Project
   of Dominant Discipline and Talent Team of Shandong Province Higher
   Education Institutions
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61972227, Grant 61902217, and Grant
   U1609218, in part by the Natural Science Foundation of Shandong Province
   under Grant ZR201808160102, Grant ZR2019BF043, and Grant ZR2019MF051, in
   part by the Primary Research and Development Plan of Shandong Province
   under Grant 2018GGX101013, and in part by the Fostering Project of
   Dominant Discipline and Talent Team of Shandong Province Higher
   Education Institutions.
CR Ancuti CO, 2011, LECT NOTES COMPUT SC, V6493, P501
   Ang JC, 2016, IEEE ACM T COMPUT BI, V13, P971, DOI 10.1109/TCBB.2015.2478454
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen BH, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2726947
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cong XF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1828, DOI 10.1145/3394171.3413876
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gandelsman Y, 2019, PROC CVPR IEEE, P11018, DOI 10.1109/CVPR.2019.01128
   Gao Y, 2017, IEEE T IMAGE PROCESS, V26, P2545, DOI 10.1109/TIP.2017.2675341
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang QX, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508364
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kingma D. P., 2014, arXiv
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li BY, 2020, IEEE T IMAGE PROCESS, V29, P8457, DOI 10.1109/TIP.2020.3016134
   Li LRH, 2020, IEEE T IMAGE PROCESS, V29, P2766, DOI 10.1109/TIP.2019.2952690
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li X, 2018, Arxiv, DOI [arXiv:1805.01086, DOI 10.48550/ARXIV.1805.01086]
   Li YX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3377, DOI 10.1145/3394171.3413948
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Y, 2019, IEEE I CONF COMP VIS, P2492, DOI 10.1109/ICCV.2019.00258
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Paszke Adam, 2017, NIPS W
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Sun ZY, 2021, COMPUT VIS IMAGE UND, V203, DOI 10.1016/j.cviu.2020.103133
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P2837, DOI 10.1109/TMM.2019.2909860
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang P, 2019, IEEE T CONSUM ELECTR, V65, P47, DOI 10.1109/TCE.2018.2884794
   Wang ZY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2486, DOI 10.1145/3219819.3219944
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu H, 2018, IEEE T IMAGE PROCESS, V27, P1259, DOI 10.1109/TIP.2017.2772836
   Wu QB, 2020, IEEE T IMAGE PROCESS, V29, P1788, DOI 10.1109/TIP.2019.2942504
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Zhang H, 2019, Arxiv, DOI [arXiv:1805.08318, DOI 10.48550/ARXIV.1805.08318]
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YF, 2020, IEEE T CIRC SYST VID, V30, P3544, DOI 10.1109/TCSVT.2019.2939853
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu X, 2009, Synthesis Lectures on Artificial Intelligence and Machine Learning, V3, P1, DOI 10.1007/978-3-031-01548-9
NR 62
TC 16
Z9 16
U1 5
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2022
VL 18
IS 2
AR 58
DI 10.1145/3478457
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA VN1FG
UT WOS:001131262100001
DA 2024-07-18
ER

PT J
AU Zhao, ZW
   Song, R
   Zhang, Q
   Duan, P
   Zhang, YM
AF Zhao, Zhongwei
   Song, Ran
   Zhang, Qian
   Duan, Peng
   Zhang, Youmei
TI JoT-GAN: A Framework for Jointly Training GAN and Person
   Re-Identification Model
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; generative adversarial networks; joint
   training
AB To cope with the problem caused by inadequate training data, many person re-identification (re-id) methods exploit generative adversarial networks (GAN) for data augmentation, where the training of GAN is typically independent of that of the re-id model. The coupling relation between them that probably brings in a performance gain of re-id is thus ignored. In this work, we propose a general framework, namely JoT-GAN, to jointly train GAN and the re-id model. It can simultaneously achieve the optima of both the generator and the re-id model, where the training is guided by each other through a discriminator. The re-id model is boosted for two reasons: (1) the adversarial training encourages it to fool the discriminator, and (2) the generated samples augment the training data. Extensive results on benchmark datasets show that for the re-id model trained with the identification loss as well as the triplet loss, the proposed joint training framework outperforms existing methods with separate training and achieves state-of-the-art re-id performance.
C1 [Zhao, Zhongwei; Song, Ran; Zhang, Qian] Shandong Univ, Sch Control Sci & Engn, Jinan, Peoples R China.
   [Duan, Peng] Liaocheng Univ, Sch Comp Sci, Liaocheng, Shandong, Peoples R China.
   [Zhang, Youmei] Qilu Univ Technol, Sch Math & Stat, Jinan, Peoples R China.
C3 Shandong University; Liaocheng University; Qilu University of Technology
RP Song, R (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan, Peoples R China.
EM zhaozw312@gmail.com; ransong@sdu.edu.cn; zhq9669@gmail.com;
   duanpeng@lcu-cs.com; zhangyoumei@qlu.edu.cn
RI Duan, Peng/ITV-2620-2023
OI Duan, Peng/0000-0002-7396-7592; Song, Ran/0000-0002-1344-4415
FU National Natural Science Foundation of China [62076148, 61991411]; Young
   Taishan Scholars Program of Shandong Province [tsqn201909029]; Qilu
   Young Scholars Program of Shandong University [31400082063101]
FX We gratefully acknowledge the support of the National Natural Science
   Foundation of China under Grants 62076148 and 61991411, the Young
   Taishan Scholars Program of Shandong Province No. tsqn201909029, and the
   Qilu Young Scholars Program of Shandong University No. 31400082063101.
CR Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Dai ZH, 2017, 31 ANN C NEURAL INFO, V30
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ge Yixiao, 2018, ARXIV PREPRINT ARXIV
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Huang Y, 2019, IEEE T IMAGE PROCESS, V28, P1391, DOI 10.1109/TIP.2018.2874715
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Li CX, 2017, ADV NEUR IN, V30
   Li JP, 2020, IEEE T CYBERNETICS, V50, P3281, DOI [10.1109/TPAMI.2019.2929036, 10.1109/TCYB.2019.2904052]
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li X, 2018, P EUR C COMP VIS ECC, P280
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Liu M, 2020, IEEE T IMAGE PROCESS, V29, P9360, DOI 10.1109/TIP.2020.3026625
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ma LQ, 2017, ADV NEUR IN, V30
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Radford A., 2015, ARXIV151106434
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Salimans T., 2016, P 30 C NEUR INF PROC, P2234
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Song Ke, 2020, P ADV NEUR INF PROC, V33, P11778
   Song R, 2021, PROC CVPR IEEE, P8849, DOI 10.1109/CVPR46437.2021.00874
   Su C, 2018, IEEE T PATTERN ANAL, V40, P1167, DOI 10.1109/TPAMI.2017.2679002
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang XJ, 2016, IEEE T CIRC SYST VID, V26, P1447, DOI 10.1109/TCSVT.2015.2450331
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Yan YC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P199, DOI 10.1145/3123266.3123277
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Zhang W, 2020, IEEE T IMAGE PROCESS, V29, P3365, DOI 10.1109/TIP.2019.2959653
   Zhang W, 2019, IEEE T NEUR NET LEAR, V30, P3847, DOI 10.1109/TNNLS.2019.2899588
   Zhang W, 2017, IEEE T IMAGE PROCESS, V26, P2042, DOI 10.1109/TIP.2017.2672440
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhongwei Zhao, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12664), P36, DOI 10.1007/978-3-030-68799-1_3
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 54
TC 15
Z9 15
U1 2
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2022
VL 18
IS 1
SU S
SI SI
AR 27
DI 10.1145/3491225
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5PV
UT WOS:000772639300004
DA 2024-07-18
ER

PT J
AU Li, Y
   Yi, Y
   Liu, D
   Li, L
   Li, Z
   Li, HQ
AF Li, Yue
   Yi, Yan
   Liu, Dong
   Li, Li
   Li, Zhu
   Li, Houqiang
TI Neural-Network-Based Cross-Channel Intra Prediction
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; cross-channel prediction; fully connected
   network; high-efficiency video coding (HEVC); transform domain loss;
   versatile video coding (VVC)
ID COLORIZATION; MODEL
AB To reduce the redundancy among different color channels, e.g., YUV, previous methods usually adopt a linear model that tends to be oversimple for complex image content. We propose a neural-network-based method for cross-channel prediction in intra frame coding. The proposed network utilizes twofold cues, i.e., the neighboring reconstructed samples with all channels, and the co-located reconstructed samples with partial channels. Specifically, for YUV video coding, the neighboring samples with YUV are processed by several fully connected layers; the co-located samples with Y are processed by convolutional layers; and the proposed network fuses the twofold cues. We observe that the integration of twofold information is crucial to the performance of intra prediction of the chroma components. We have designed the network architecture to achieve a good balance between compression performance and computational efficiency. Moreover, we propose a transform domain loss for the training of the network. The transform domain loss helps obtain more compact representations of residues in the transform domain, leading to higher compression efficiency. The proposed method is plugged into HEVC and VVC test models to evaluate its effectiveness. Experimental results show that our method provides more accurate cross-channel intra prediction compared with previous methods. On top of HEVC, our method achieves on average 1.3%, 5.4%, and 3.8% BD-rate reductions for Y, Cb, and Cr on common test sequences, and on average 3.8%, 11.3%, and 9.0% BD-rate reductions for Y, Cb, and Cr on ultra-high-definition test sequences. On top of VVC, our method achieves on average 0.5%, 1.7%, and 1.3% BD-rate reductions for Y, Cb, and Cr on common test sequences.
C1 [Li, Yue; Yi, Yan; Liu, Dong; Li, Li; Li, Houqiang] Univ Sci & Technol China, 443 Huangshan Rd, Hefei 230027, Anhui, Peoples R China.
   [Li, Zhu] Univ Missouri, 5100 Rockhill Rd, Kansas City, MO 64110 USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; University of Missouri System; University of Missouri Kansas
   City
RP Liu, D (corresponding author), Univ Sci & Technol China, 443 Huangshan Rd, Hefei 230027, Anhui, Peoples R China.
EM lytt@mail.ustc.edu.cn; yy140177@mail.ustc.edu.cn; dongeliu@ustc.edu.cn;
   lil1@ustc.edu.cn; zhu.li@ieee.org; lihq@ustc.edu.cn
RI Li, Zhu/AAD-8182-2021; Liu, DY/JPL-4171-2023; liu,
   dongsheng/IWM-1597-2023; liu, dong/GRJ-9115-2022; Li, Yue/AEP-3283-2022;
   Li, Houqiang Li/B-6259-2013
OI Li, Zhu/0000-0002-8246-177X; Li, Yue/0000-0002-1679-2941; 
FU Natural Science Foundation of China [61772483, 61931014]
FX This work was supported by the Natural Science Foundation of China under
   Grants 61772483 and 61931014.
CR Balle J., 2016, 5 INT C LEARNING REP
   Ballé J, 2016, PICT COD SYMP, DOI 10.1109/pcs.2016.7906310
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Bossen Frank., 2011, Joint Collaborative Team on Video Coding (JCT-VC), JCTVC-F900
   Burdea G. C., 2003, Virtual reality technology
   Charpiat G, 2008, LECT NOTES COMPUT SC, V5304, P126, DOI 10.1007/978-3-540-88690-7_10
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Dai YY, 2017, LECT NOTES COMPUT SC, V10132, P28, DOI 10.1007/978-3-319-51811-4_3
   Deshpande A, 2015, IEEE I CONF COMP VIS, P567, DOI 10.1109/ICCV.2015.72
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gisquet C, 2013, IEEE DATA COMPR CONF, P23, DOI 10.1109/DCC.2013.10
   Glorot X., 2010, P INT C ART INT STAT, P249
   Gorriz Marc, 2020, ARXIV200615349
   Gupta R. K., 2012, P 20 ACM INT C MULT, P369, DOI DOI 10.1145/2393347.2393402
   Helle P, 2019, IEEE DATA COMPR CONF, P448, DOI 10.1109/DCC.2019.00053
   Hu YY, 2019, IEEE T MULTIMEDIA, V21, P3024, DOI 10.1109/TMM.2019.2920603
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim Jungsun, 2010, ANN M COGN SCI SOC P
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li JH, 2018, IEEE T IMAGE PROCESS, V27, P3236, DOI 10.1109/TIP.2018.2817044
   Li Y, 2018, IEEE IMAGE PROC, P1797, DOI 10.1109/ICIP.2018.8451396
   Li Y, 2018, IEEE T CIRC SYST VID, V28, P2316, DOI 10.1109/TCSVT.2017.2727682
   Liu D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3368405
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   Meyer M, 2019, INT CONF ACOUST SPEE, P1607, DOI [10.1109/icassp.2019.8682846, 10.1109/ICASSP.2019.8682846]
   Pfaff J, 2018, PROC SPIE, V10752, DOI 10.1117/12.2321273
   Pfaff J, 2020, IEEE T CIRC SYST VID, V30, P1281, DOI 10.1109/TCSVT.2019.2945918
   Segall Andrew, 2017, JVETH1002
   Song R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Suehring K., 2018, document JVET-L1010
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tang YB, 2019, IEEE T MULTIMEDIA, V21, P2237, DOI 10.1109/TMM.2019.2900908
   Theis L., 2017, ICLR
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Toderici G., 2015, ARXIV PREPRINT ARXIV
   Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Yan N, 2019, IEEE T CIRC SYST VID, V29, P840, DOI 10.1109/TCSVT.2018.2816932
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yeh CH, 2015, IEEE T MULTIMEDIA, V17, P1508, DOI 10.1109/TMM.2015.2449659
   Yi-Chin Huang, 2005, 13th Annual ACM International Conference on Multimedia, P351, DOI 10.1145/1101149.1101223
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang H, 2016, IEEE INT SYMP SIGNAL, P1, DOI 10.1109/ISSPIT.2016.7885999
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P3983, DOI 10.1109/TIP.2018.2830640
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang T, 2018, IEEE T MULTIMEDIA, V20, P1622, DOI 10.1109/TMM.2017.2775223
   Zhang T, 2017, IEEE T MULTIMEDIA, V19, P2404, DOI 10.1109/TMM.2017.2703114
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang XY, 2014, IEEE T IMAGE PROCESS, V23, P274, DOI 10.1109/TIP.2013.2288007
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhu LW, 2020, IEEE T MULTIMEDIA, V22, P45, DOI 10.1109/TMM.2019.2924591
NR 61
TC 3
Z9 3
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2021
VL 17
IS 3
AR 77
DI 10.1145/3434250
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UC5SO
UT WOS:000686585400001
DA 2024-07-18
ER

PT J
AU Guan, WL
   Chen, ZZ
   Feng, FL
   Liu, WF
   Nie, LQ
AF Guan, Weili
   Chen, Zhaozheng
   Feng, Fuli
   Liu, Weifeng
   Nie, Liqiang
TI Urban Perception: Sensing Cities via a Deep Interactive Multi-task
   Learning Framework
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Urban perception; urban attributes; regional interactions; deep
   multi-task learning
ID IMAGE QUALITY ASSESSMENT; BROKEN WINDOWS
AB Social scientists have shown evidence that visual perceptions of urban attributes, such as safe, wealthy, and beautiful perspectives of the given cities, are highly correlated to the residents' behaviors and quality of life. Despite their significance, measuring visual perceptions of urban attributes is challenging due to the following facts: (1) Visual perceptions are subjectively contradistinctive rather than absolute. (2) Perception comparisons between image pairs are usually conducted region by region, and highly related to the specific urban attributes. And (3) the urban attributes have both the shared and specific information. To address these problems, in this article, we present a Deep inteRActive Multi-task leArning scheme, DRAMA for short. DRAMA comparatively quantifies the perceptions of urban attributes by jointly integrating the pairwise comparisons, regional interactions, and urban attribute correlations within a unified deep scheme. In DRAMA, each urban attribute is treated as a task, whereby the task-sharing and the task-specific information is fully explored. By conducting extensive experiments over a public large-scale benchmark dataset, it is demonstrated that our proposed DRAMA scheme outperforms several state-of-the-art baselines. Meanwhile, we applied the pairwise comparisons of our DRAMA model to further quantify the urban attributes and hence rank cities with respect to the given urban attributes. As a byproduct, we have released the codes and parameter settings to facilitate other researches.
C1 [Guan, Weili] Monash Univ, Fac Informat Technol, Clayton Campus, Melbourne, Vic 3800, Australia.
   [Chen, Zhaozheng] Singapore Management Univ, Singapore, Singapore.
   [Feng, Fuli] Natl Univ Singapore, Singapore, Singapore.
   [Liu, Weifeng] China Univ Petr East China, 66 Changjiang West Rd, Qingdao 266580, Peoples R China.
   [Nie, Liqiang] Shandong Univ, 72 Binhai Rd, Qingdao 266237, Shandong, Peoples R China.
   [Chen, Zhaozheng] SMU Sch Comp & Informat Syst, 80 Stamford Rd, Singapore 178902, Singapore.
   [Feng, Fuli] NExT Res Ctr, 5 Prince Georges Pk, Singapore 118404, Singapore.
C3 Monash University; Singapore Management University; National University
   of Singapore; China University of Petroleum; Shandong University
RP Guan, WL (corresponding author), Monash Univ, Fac Informat Technol, Clayton Campus, Melbourne, Vic 3800, Australia.
EM honeyguan@gmail.com; zhaozhengcc@gmail.com; fulifeng93@gmail.com;
   liuwf@upc.edu.cn; nieliqiang@gmail.com
RI liu, weifeng/B-7909-2008; wang, wjd/GSD-2051-2022; Chen,
   Zhaozheng/GXV-5366-2022
CR Aj Milam, 2010, Urban Rev, V42, P458, DOI 10.1007/s11256-010-0165-7
   [Anonymous], 2015, PLOS ONE, V10
   [Anonymous], 2016, Proceedings of the 24th ACM international conference on Multimedia
   Argyriou V, 2011, IEEE T IMAGE PROCESS, V20, P110, DOI 10.1109/TIP.2010.2057438
   Been V, 2016, J URBAN ECON, V92, P16, DOI 10.1016/j.jue.2015.12.002
   Bratton W., 2006, National Review, V28
   Burges Chris, 2005, P 22 INT C MACH LEAR, P89, DOI DOI 10.1145/1102351.1102363
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Chu WQ, 2018, IEEE T IMAGE PROCESS, V27, P432, DOI 10.1109/TIP.2017.2762591
   Cohen D, 2000, AM J PUBLIC HEALTH, V90, P230, DOI 10.2105/AJPH.90.2.230
   Cohen DA, 2003, AM J PUBLIC HEALTH, V93, P467, DOI 10.2105/AJPH.93.3.467
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Dubey A, 2016, LECT NOTES COMPUT SC, V9905, P196, DOI 10.1007/978-3-319-46448-0_12
   Engilberge M, 2019, PROC CVPR IEEE, P10784, DOI 10.1109/CVPR.2019.01105
   Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916
   Harcourt BE, 1998, MICH LAW REV, V97, P291, DOI 10.2307/1290289
   Harvey C, 2015, LANDSCAPE URBAN PLAN, V142, P18, DOI 10.1016/j.landurbplan.2015.05.007
   He KK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1636, DOI 10.1145/3123266.3123424
   He R, 2015, IEEE T IMAGE PROCESS, V24, P5543, DOI 10.1109/TIP.2015.2466106
   Herbrich R, 2000, ADV NEUR IN, P115
   Herbrich R., 2006, P 19 INT C NEUR INF, P569
   Hidalgo Cesar, 2015, SOC SCI ELECT PUB
   Howard IP, 1996, PERCEPTION, V25, P1203, DOI 10.1068/p251203
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Keizer K, 2008, SCIENCE, V322, P1681, DOI 10.1126/science.1161405
   Khaleefa O., 1999, American Journal of Islamic Social Sciences, V16, P1, DOI DOI 10.35632/AJIS.V16I2.2126
   Li XL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1318, DOI 10.1145/3123266.3123382
   Lissner I, 2012, IEEE T IMAGE PROCESS, V21, P1153, DOI 10.1109/TIP.2011.2163522
   Luo Y, 2016, IEEE T IMAGE PROCESS, V25, P414, DOI 10.1109/TIP.2015.2495116
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Mamassian P, 2002, NEU INF PRO, P13
   Min WQ, 2020, IEEE T IMAGE PROCESS, V29, P657, DOI 10.1109/TIP.2019.2932502
   Ming-Feng Tsai, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P383, DOI 10.1145/1277741.1277808
   Naik N, 2016, AM ECON REV, V106, P128, DOI 10.1257/aer.p20161030
   Naik N, 2014, IEEE COMPUT SOC CONF, P793, DOI 10.1109/CVPRW.2014.121
   Negahban S., 2012, Advances in neural information processing systems, V25, P2474
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Piro FN, 2006, J EPIDEMIOL COMMUN H, V60, P626, DOI 10.1136/jech.2005.042697
   Preiss J, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2302684
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Rigutini L., 2008, P SIGIR WORKSH LEARN, V42, P76
   Ross CE, 2001, J HEALTH SOC BEHAV, V42, P258, DOI 10.2307/3090214
   Ruder S., 2017, OVERVIEW MULTITASK L, P1
   Salesses P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068400
   Sarvadevabhatla RK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P10, DOI 10.1145/3123266.3123270
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wilson J. Q., 1982, ATLANTIC MONTHLY, V249.3, P29, DOI DOI 10.4135/9781412959193.n281
   Wu QB, 2017, IEEE T MULTIMEDIA, V19, P2490, DOI 10.1109/TMM.2017.2700206
   Xu L, 2017, IEEE T CIRC SYST VID, V27, P1833, DOI 10.1109/TCSVT.2016.2543099
   Xu YC, 2019, LECT NOTES COMPUT SC, V11296, P28, DOI 10.1007/978-3-030-05716-9_3
   Yan YC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P199, DOI 10.1145/3123266.3123277
   Zhang Q, 2016, IEEE T IMAGE PROCESS, V25, P2045, DOI 10.1109/TIP.2016.2524212
   Zhang X, 2018, PROC CVPR IEEE, P4786, DOI 10.1109/CVPR.2018.00503
   Zhang Y., 2017, ARXIV PREPRINT ARXIV
   Zhaohui Zheng, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P287, DOI 10.1145/1277741.1277792
NR 56
TC 6
Z9 6
U1 5
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2021
VL 17
IS 1
SU S
SI SI
AR 13
DI 10.1145/3424115
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA RW2ZT
UT WOS:000646396900013
OA Green Published
DA 2024-07-18
ER

PT J
AU Li, YC
   Cao, JL
   Li, ZT
   Oh, SYO
   Komuro, OBYS
AF Li, Yanchun
   Cao, Jianglian
   Li, Zhetao
   Oh, Sangyoon
   Komuro, Nobuyoshi
TI Lightweight Single Image Super-resolution with Dense Connection
   Distillation Network
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Dense connection; single image super-resolution; attention mechanism
AB Single image super-resolution attempts to reconstruct a high-resolution (HR) image from its corresponding low-resolution (LR) image, which has been a research hotspot in computer vision and image processing for decades. To improve the accuracy of super-resolution images, many works adopt very deep networks to model the translation from LR to HR, resulting in memory and computation consumption. In this article, we design a lightweight dense connection distillation network by combining the feature fusion units and dense connection distillation blocks (DCDB) that include selective cascading and dense distillation components. The dense connections are used between and within the distillation block, which can provide rich information for image reconstruction by fusing shallow and deep features. In each DCDB, the dense distillation module concatenates the remaining feature maps of all previous layers to extract useful information, the selected features are then assessed by the proposed layer contrast-aware channel attentionmechanism, and finally the cascade module aggregates the features. The distillation mechanism helps to reduce training parameters and improve training efficiency, and the layer contrast-aware channel attention further improves the performance of model. The quality and quantity experimental results on several benchmark datasets show the proposed method performs better tradeoff in term of accuracy and efficiency.
C1 [Li, Yanchun; Cao, Jianglian; Oh, Sangyoon] Xiangtan Univ, Sch Comp Sci, Xiangtan, Peoples R China.
   [Li, Zhetao] Ajou Univ, Dept Comp & Informat Engn, Suwon, South Korea.
   [Komuro, Nobuyoshi] Chiba Univ, Inst Management & Informat Technol, Inage Ku, Ayoi Cho, Chiba, Japan.
   [Li, Yanchun; Li, Zhetao] Xiangtan Univ, Minist Educ, Key Lab Intelligent Comp & Informat Proc, Xiangtan, Peoples R China.
   [Li, Yanchun; Li, Zhetao] Xiangtan Univ, Key Lab Hunan Prov Internet Things & Informat Sec, Xiangtan, Peoples R China.
   [Li, Zhetao] Hunan Int Sci & Technol Cooperat Base Intelligent, Xiangtan, Peoples R China.
C3 Xiangtan University; Ajou University; Chiba University; Xiangtan
   University; Xiangtan University
RP Cao, JL (corresponding author), Xiangtan Univ, Sch Comp Sci, Xiangtan, Peoples R China.
EM ycli@xtu.edu.cn; Caojl@xtu.edu.cn; liztchina@hotmail.com;
   syoh@ajou.ac.kr; kmr@faculty.chiba-u.jp
RI Li, Zhetao/H-1293-2017; Komuro, Nobuyoshi/AFH-0825-2022
OI Komuro, Nobuyoshi/0000-0002-3312-454X; yanchun, Li/0000-0002-2754-9883
FU Hunan Science and Technology Planning Project [2019RS3019]; Hunan
   Provincial Natural Science Foundation of China for Distinguished Young
   Scholars [2018JJ1025]; Hunan Province Science and Technology Project
   Funds [2018TP1036]; Hunan General project of Education Department
   [19C1758]; Ph.D. Research Startup Foundation of Xiangtan University
   [19QDZ57]
FX This work was supported in part by Hunan Science and Technology Planning
   Project under Grant No. 2019RS3019, the Hunan Provincial Natural Science
   Foundation of China for Distinguished Young Scholars under Grant No.
   2018JJ1025, Hunan Province Science and Technology Project Funds under
   Grant No. 2018TP1036, Hunan General project of Education Department
   under Grant No. 19C1758, and Ph.D. Research Startup Foundation of
   Xiangtan University under Grant No. 19QDZ57.
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Dumoulin Vincent, 2017, CORR ABS161007629
   Haodong Duan, 2017, CORR ABS171205927
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Isaac JS, 2015, 2015 INTERNATIONAL CONFERENCE ON TECHNOLOGY FOR SUSTAINABLE DEVELOPMENT (ICTSD-2015)
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kingma D. P., 2014, arXiv
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Mao XJ, 2016, ADV NEUR IN, V29
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Parmar N, 2018, PR MACH LEARN RES, V80
   Paulus Romain., 2018, CoRR abs/1705.04304
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shum Heung-Yeung, 2008, PROC CVPR IEEE, P1
   Shuo Wang, 2019, P 28 INT JOINT C ART
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P858, DOI 10.1109/TMM.2012.2187181
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Yang, 2020, ARXIV ABS200608159
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wong P. W., 1996, P INT C IM PROC
   Wu E., 2019, IEEE T PATTERN ANAL, V142, P8
   Wu L., 2020, IEEE T NEUR NET LEAR, P1
   Wu L, 2020, IEEE T IMAGE PROCESS, V29, P1233, DOI 10.1109/TIP.2019.2940684
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang Han, 2018, CoRR abs/1805.08318
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 56
TC 25
Z9 25
U1 1
U2 23
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2021
VL 17
IS 1
SU S
SI SI
AR 9
DI 10.1145/3414838
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RW2ZT
UT WOS:000646396900009
DA 2024-07-18
ER

PT J
AU Tran, HTT
   Ngoc, NP
   Hossfeld, T
   Seufert, M
   Thang, TC
AF Tran, Huyen T. T.
   Ngoc, Nam Pham
   Hossfeld, Tobias
   Seufert, Michael
   Thang, Truong Cong
TI Cumulative Quality Modeling for HTTP Adaptive Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Cumulative quality; quality model; quality of experience; adaptive video
   streaming
ID VIDEO QUALITY
AB HTTP Adaptive Streaming has become the de facto choice for multimedia delivery. However, the quality of adaptive video streaming may fluctuate strongly during a session due to throughput fluctuations. So, it is important to evaluate the quality of a streaming session over time. In this article, we propose a model to estimate the cumulative quality for HTTP Adaptive Streaming. In the model, a sliding window of video segments is employed as the basic building block. Through statistical analysis using a subjective dataset, we identify four important components of the cumulative quality model, namely the minimum window quality, the last window quality, the maximum window quality, and the average window quality. Experiment results show that the proposed model achieves high prediction performance and outperforms related quality models. In addition, another advantage of the proposed model is its simplicity and effectiveness for deployment in real-time estimation. Our subjective dataset as well as the source code of the proposed model have been made publicly available at https://sites.google.com/site/huyenthithanhtran1191/cyndatabase.
C1 [Tran, Huyen T. T.; Thang, Truong Cong] Univ Aizu, Aizu Wakamatsu, Fukushima 9658580, Japan.
   [Ngoc, Nam Pham] Vin Univ, Vinhomes Ocean Pk, Hanoi, Vietnam.
   [Hossfeld, Tobias; Seufert, Michael] Univ Wurzburg, Chair Communicat Network, Wurzburg, Germany.
C3 University of Aizu; VinUniversity; University of Wurzburg
RP Tran, HTT (corresponding author), Univ Aizu, Aizu Wakamatsu, Fukushima 9658580, Japan.
EM d8192106@u-aizu.ac.jp; v.nampn3@vingroup.net;
   tobias.hossfeld@uni-wuerzburg.de; michael.seufert@uni-wuerzburg.de;
   thang@u-aizu.ac.jp
RI Seufert, Michael/AAR-7846-2021
OI Seufert, Michael/0000-0002-5036-5206; Hossfeld,
   Tobias/0000-0003-0173-595X
CR Aaron A., 2015, Per-title encode optimization
   [Anonymous], 2012, RECOMMENDATION ITU T
   [Anonymous], 2014, RECOMMENDATION ITU T
   [Anonymous], 2017, RECOMMENDATION ITU T
   [Anonymous], 2012, Recommendation ITU-R P. 684-6: Prediction of Field Strength at Frequencies below about 150 kHz
   [Anonymous], 2004, RECOMMENDATION ITU T
   Bampis CG, 2018, IEEE T IMAGE PROCESS, V27, P3316, DOI 10.1109/TIP.2018.2815842
   Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P5217, DOI 10.1109/TIP.2017.2729891
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Bentaleb A, 2019, IEEE COMMUN SURV TUT, V21, P562, DOI 10.1109/COMST.2018.2862938
   Chakraborty S., 2019, STREAMING VIDEO QOE
   Chen C, 2014, IEEE T IMAGE PROCESS, V23, P2206, DOI 10.1109/TIP.2014.2312613
   Cofano G, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092836
   De Vriendt J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1288
   Dietterich T, 1995, ACM COMPUT SURV, V27, P326, DOI 10.1145/212094.212114
   Duanmu Z., 2019, KNOWLEDGE DRIVEN QUA
   Duanmu ZF, 2018, IEEE T IMAGE PROCESS, V27, P6135, DOI 10.1109/TIP.2018.2855403
   Duanmu ZF, 2018, IEEE T BROADCAST, V64, P474, DOI 10.1109/TBC.2018.2822870
   Duanmu ZF, 2017, IEEE J-STSP, V11, P154, DOI 10.1109/JSTSP.2016.2608329
   Duanmu Zhengfang, 2019, ARXIV191107944
   Eswara N, 2020, IEEE T CIRC SYST VID, V30, P661, DOI 10.1109/TCSVT.2019.2895223
   Eswara N, 2018, IEEE T CIRC SYST VID, V28, P3236, DOI 10.1109/TCSVT.2017.2742601
   Ghadiyaram D, 2019, IEEE T CIRC SYST VID, V29, P183, DOI 10.1109/TCSVT.2017.2768542
   Ghadiyaram D, 2018, IEEE T IMAGE PROCESS, V27, P2257, DOI 10.1109/TIP.2018.2790347
   Guo ZL, 2015, IEEE IMAGE PROC, P3121, DOI 10.1109/ICIP.2015.7351378
   Hossfeld Tobias, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P111, DOI 10.1109/QoMEX.2014.6982305
   Hossfeld Tobias, 2013, Data Traffic Monitoring and Analysis. From Measurement, Classification, and Anomaly Detection to Quality of Experience, P264, DOI 10.1007/978-3-642-36784-7_11
   Huang TC, 2020, IEEE J SEL AREA COMM, V38, P2324, DOI 10.1109/JSAC.2020.3000363
   Juluri P, 2016, IEEE COMMUN SURV TUT, V18, P401, DOI 10.1109/COMST.2015.2401424
   KAHNEMAN D, 1993, PSYCHOL SCI, V4, P401, DOI 10.1111/j.1467-9280.1993.tb00589.x
   Koster Friedemann., 2017, 2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX), P1
   Le Callet P., 2013, Qualinet White Paper on Definitions of Quality of Experience
   Li Z., 2018, VMAF: The journey continues
   Li Zhi, 2019, VMAF VIDEO MULTIMETH
   Lindegren David, 2018, ITU T REC P1203 STAN
   Liu Y, 2015, IEEE T BROADCAST, V61, P651, DOI 10.1109/TBC.2015.2460611
   Mazhar MH, 2018, IEEE INFOCOM SER, P1331, DOI 10.1109/INFOCOM.2018.8486321
   Muller C., 2012, 4th ACM Workshop on Mobile Video (MoVID), P37, DOI DOI 10.1145/2151677.2151686
   Nam H, 2016, IEEE INFOCOM SER
   Ou YF, 2014, IEEE T IMAGE PROCESS, V23, P2473, DOI 10.1109/TIP.2014.2303636
   PETERSON LR, 1959, J EXP PSYCHOL, V58, P193, DOI 10.1037/h0049234
   Petrangeli S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818361
   Raake A., 2017, 2017 9 INT C QUALITY, P1, DOI DOI 10.1109/QOMEX.2017.7965631
   Rehman A, 2013, INT WORK QUAL MULTIM, P218, DOI 10.1109/QoMEX.2013.6603240
   Revlin Russell., 2012, Cognition: Theory and practice
   Robitza W, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P466, DOI 10.1145/3204949.3208124
   Robitza Werner., 2017, PROC 9 INT C QUAL MU, P1
   Rodríguez DZ, 2016, IEEE T BROADCAST, V62, P628, DOI 10.1109/TBC.2016.2570012
   Seshadrinathan K, 2011, INT CONF ACOUST SPEE, P1153
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seufert M, 2019, CONF INNOV CLOUD, P76, DOI 10.1109/ICIN.2019.8685901
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Seufert M, 2013, INT WORK QUAL MULTIM, P52, DOI 10.1109/QoMEX.2013.6603210
   Singh KD, 2012, CONSUM COMM NETWORK, P127, DOI 10.1109/CCNC.2012.6181070
   Takagi M, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P33, DOI 10.1109/VCIP.2014.7051497
   Tavakoli S, 2016, IEEE J SEL AREA COMM, V34, P2141, DOI 10.1109/JSAC.2016.2577361
   Thang Truong Cong, 2020, ARXIV200612697
   Tran HTT, 2016, IEEE GLOBE WORK
   Tran HTT, 2017, IEICE T FUND ELECTR, VE100A, P555, DOI 10.1587/transfun.E100.A.555
   Tran Tran H. T. T. H. T. T., 2018, INT WORK QUAL MULTIM, P1
   Thang TC, 2013, J COMMUN NETW-S KOR, V15, P635, DOI 10.1109/JCN.2013.000112
   Wang C, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2642, DOI 10.1145/3343031.3356069
   Wassermann S, 2019, PROCEEDINGS OF THE 3RD NETWORK TRAFFIC MEASUREMENT AND ANALYSIS CONFERENCE (TMA 2019), P199, DOI 10.23919/TMA.2019.8784589
   Xu M, 2019, IEEE T CIRC SYST VID, V29, P3516, DOI [10.1109/TCSVT.2018.2886277, 10.1080/17445302.2018.1558727]
   Yamagishi K, 2017, IEEE T MULTIMEDIA, V19, P1545, DOI 10.1109/TMM.2017.2669859
   Yarnagula HK, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3311749
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Yu L, 2017, IEEE T BROADCAST, V63, P523, DOI 10.1109/TBC.2017.2687698
   Zhao TS, 2017, IEEE COMMUN SURV TUT, V19, P285, DOI 10.1109/COMST.2016.2619982
NR 69
TC 4
Z9 4
U1 2
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2021
VL 17
IS 1
AR 22
DI 10.1145/3423421
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RO6SX
UT WOS:000641174200002
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Zhang, C
   Wu, XP
   Lu, JC
   Zheng, X
   Jolfaei, A
   Sheng, QZ
   Yu, DJ
AF Zhang, Chao
   Wu, Xiaopei
   Lu, Jianchao
   Zheng, Xi
   Jolfaei, Alireza
   Sheng, Quan Z.
   Yu, Dongjin
TI RICA-MD: A Refined ICA Algorithm for Motion Detection
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Motion detection; Independent Component Analysis (ICA); multi-channel
   input; observation signal reconstruction
ID BACKGROUND SUBTRACTION; SURVEILLANCE
AB With the rapid development of various computing technologies, the constraints of data processing capabilities gradually disappeared, and more data can be simultaneously processed to obtain better performance compared to conventional methods. As a standard statistical analysis method that has been widely used in many fields, Independent Component Analysis (ICA) provides a new way for motion detection by extracting the foreground without precisely modeling the background. However, most existing ICA-based motion detection algorithms use only two-channel data for source separation and simply generate the observation vectors by decomposing and reconstructing the images by row, hence they cannot obtain an integrated and accurate shape of the moving objects in complex scenes. In this article, we propose a refined ICA algorithm for motion detection (RICA-MD), which fuses a larger number of channels than conventional ICA-based motion detection algorithms to provide more effective information for foreground extraction. Meanwhile, we propose four novel methods for generating observation vectors to further cover the diverse motion styles of the moving objects. These improvements enable RICA-MD to effectively deal with slowly moving objects, which are difficult to detect using conventional methods. Our quantitative evaluation in multiple scenes shows that our proposed method is able to achieve a better performance at an acceptable cost of false alarms.
C1 [Zhang, Chao; Wu, Xiaopei] Anhui Univ, Sch Comp Sci & Technol, 111 Jiulong Rd, Hefei 230601, Anhui, Peoples R China.
   [Lu, Jianchao; Zheng, Xi; Jolfaei, Alireza; Sheng, Quan Z.] Macquarie Univ, Balaclava Rd, Macquarie Pk, NSW 2109, Australia.
   [Yu, Dongjin] Hangzhou Dianzi Univ, 115 Wenyi Rd, Hangzhou 310018, Peoples R China.
C3 Anhui University; Macquarie University; Hangzhou Dianzi University
RP Wu, XP (corresponding author), Anhui Univ, Sch Comp Sci & Technol, 111 Jiulong Rd, Hefei 230601, Anhui, Peoples R China.
EM 14042@ahu.edu.cn; iiphci_ahu@163.com; jianchao.lu@students.mq.edu.au;
   james.zheng@mq.edu.au; alireza.jolfaei@mq.edu.au;
   michael.sheng@mq.edu.au; yudj@hdu.edu.cn
RI Sheng, Quan Z./B-8169-2008; Zheng, Xi/AAV-8387-2020; Sheng, Quan
   Z./ITV-5105-2023; Jolfaei, Alireza/GQH-6907-2022
OI Sheng, Quan Z./0000-0002-3326-4147; Zheng, Xi/0000-0002-2572-2355;
   Sheng, Quan Z./0000-0002-3326-4147; Jolfaei,
   Alireza/0000-0001-7818-459X; lu, jianchao/0000-0003-0788-1448
CR Abdullah T, 2014, INT CONF UTIL CLOUD, P39, DOI 10.1109/UCC.2014.12
   Agarwal A, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P409, DOI 10.1109/IC3I.2016.7917999
   Berjón D, 2018, PATTERN RECOGN, V74, P156, DOI 10.1016/j.patcog.2017.09.009
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   Cha YJ, 2017, ENG STRUCT, V132, P300, DOI 10.1016/j.engstruct.2016.11.038
   Chen XR, 2015, OPTIK, V126, P2256, DOI 10.1016/j.ijleo.2015.05.122
   Cho J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143217
   Devabhaktuni V., 2011, ISRN SIGNAL PROCESS, V9
   Fernandes SL, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P122, DOI 10.1109/ICSIPR.2013.6497972
   Guo CS, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.193
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Held C, 2012, COMPUTER, V45, P83, DOI 10.1109/MC.2012.97
   Huang DY, 2012, J VIS COMMUN IMAGE R, V23, P648, DOI 10.1016/j.jvcir.2012.03.002
   Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P151
   Jiménez-Hernández H, 2010, SENSORS-BASEL, V10, P6092, DOI 10.3390/s100606092
   Joshi KinjalA., 2012, International Journal of Soft Computing and Engineering (IJSCE) ISSN, P2231
   Karande K. J., 2012, P INT C COMM INF COM, P1
   Komagal E., 2012, 2012 International Conference on Computing, Communication and Applications, Dindigul, Tamilnadu, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulchandani JS, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Kumar AN, 2015, J ELECTR ENG TECHNOL, V10, P372, DOI 10.5370/JEET.2015.10.1.372
   Lin TH, 2014, IEEE INT CONF ROBOT, P3058, DOI 10.1109/ICRA.2014.6907299
   Liu W, 2015, IET COMPUT VIS, V9, P13, DOI 10.1049/iet-cvi.2013.0242
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Manzanera A, 2007, PATTERN RECOGN LETT, V28, P320, DOI 10.1016/j.patrec.2006.04.007
   Moudgollya R, 2019, MULTIMED TOOLS APPL, V78, P22537, DOI 10.1007/s11042-019-7575-7
   Neves J.C., 2016, Artificial Intelligence Review, V46, P1
   Prativadibhayankaram S, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070090
   Puhan S., 2013, AM J SIGNAL PROCESS, V3, P121
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rejer I, 2015, IEEE ENG MED BIO, P7434, DOI 10.1109/EMBC.2015.7320110
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romero JD, 2018, IEEE T IMAGE PROCESS, V27, P1243, DOI 10.1109/TIP.2017.2776742
   Rong JZ, 2013, OPT LASER TECHNOL, V47, P283, DOI 10.1016/j.optlastec.2012.08.040
   Rymel J, 2004, IEEE IMAGE PROC, P1847
   Sari L, 2014, INT C PATT RECOG, P1639, DOI 10.1109/ICPR.2014.290
   Schwarz LA, 2012, PATTERN RECOGN, V45, P11, DOI 10.1016/j.patcog.2011.06.015
   Schwingshackl G., 2012, P IS T SPIE EL IM C
   Sefidmazgi AN, 2019, MULTIMED TOOLS APPL, V78, P17287, DOI 10.1007/s11042-018-6972-7
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Singh D, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P886, DOI [10.1109/ICMLA.2016.177, 10.1109/ICMLA.2016.0159]
   Sommer L.W., 2016, 2016 IEEE WINTER C A, P1
   Srivastava S, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041103
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tsai DM, 2009, IEEE T IMAGE PROCESS, V18, P158, DOI 10.1109/TIP.2008.2007558
   Utasi A., 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P157, DOI 10.1109/IWSSIP.2007.4381177
   Wang CCR, 2008, IEEE T INTELL TRANSP, V9, P83, DOI 10.1109/TITS.2007.908572
   Xie HM, 2018, IEEE T VEH TECHNOL, V67, P10411, DOI 10.1109/TVT.2018.2868965
   Yamazaki M, 2006, LECT NOTES COMPUT SC, V3852, P467
   Zhang C, 2019, IEEE ACCESS, V7, P11829, DOI 10.1109/ACCESS.2019.2891971
NR 52
TC 1
Z9 1
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2021
VL 17
IS 1
SU S
SI SI
AR 17
DI 10.1145/3416492
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RW2ZT
UT WOS:000646396900017
DA 2024-07-18
ER

PT J
AU Fan, HH
   Zhu, LC
   Yang, Y
   Wu, F
AF Fan, Hehe
   Zhu, Linchao
   Yang, Yi
   Wu, Fei
TI Recurrent Attention Network with Reinforced Generator for Visual Dialog
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Visual Dialog; vision and language; reinforcement learning; deep
   learning
AB In Visual Dialog, an agent has to parse temporal context in the dialog history and spatial context in the image to hold a meaningful dialog with humans. For example, to answer "what is the man on her left wearing?" the agent needs to (1) analyze the temporal context in the dialog history to infer who is being referred to as "her," (2) parse the image to attend "her," and (3) uncover the spatial context to shift the attention to "her left" and check the apparel of the man. In this article, we use a dialog network to memorize the temporal context and an attention processor to parse the spatial context. Since the question and the image are usually very complex, which makes it difficult for the question to be grounded with a single glimpse, the attention processor attends to the imagemultiple times to better collect visual information. In the Visual Dialog task, the generative decoder (G) is trained under the word-by-word paradigm, which suffers from the lack of sentencelevel training. We propose to reinforce G at the sentence level using the discriminative model (D), which aims to select the right answer from a few candidates, to ameliorate the problem. Experimental results on the VisDial dataset demonstrate the effectiveness of our approach.
C1 [Fan, Hehe; Zhu, Linchao; Yang, Yi] Univ Technol Sydney, Ctr Artificial Intelligence, 15 Broadway, Sydney, NSW 2007, Australia.
   [Fan, Hehe] Baidu Res, 1 5 10 Xibeiwang East Rd, Beijing 100193, Peoples R China.
   [Wu, Fei] Zhejiang Univ, Coll Comp Sci, 38 Zhedalu, Hangzhou 310007, Zhejiang, Peoples R China.
C3 University of Technology Sydney; Baidu; Zhejiang University
RP Fan, HH (corresponding author), Univ Technol Sydney, Ctr Artificial Intelligence, 15 Broadway, Sydney, NSW 2007, Australia.; Fan, HH (corresponding author), Baidu Res, 1 5 10 Xibeiwang East Rd, Beijing 100193, Peoples R China.
EM hehe.fan@student.uts.edu.au; linchao.zhu@uts.edu.au; yi.yang@uts.edu.au;
   wufei@cs.zju.edu.cn
RI Yang, Yi/B-9273-2017; Zhu, Linchao/AAE-6700-2020; yang,
   yang/GVT-5210-2022; yang, yang/HGT-7999-2022; yang, yang/GWB-9426-2022;
   Lang, Ming/HIK-0758-2022
OI Yang, Yi/0000-0002-0512-880X; Zhu, Linchao/0000-0002-4093-7557; Fan,
   Hehe/0000-0001-9572-2345
FU ARC [DP200100938, NSFC61625107]
FX Part of this work was done when H. Fan was an intern at Baidu Research.
   The work of Y. Yang was supported in part by ARC DP200100938. The work
   of F. Wu was supported in part by NSFC61625107.
CR Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bai YL, 2018, FASHION CURATING: CRITICAL PRACTICE IN THE MUSEUM AND BEYOND, P213
   Das A, 2017, IEEE I CONF COMP VIS, P2970, DOI 10.1109/ICCV.2017.321
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Ding YH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3369393
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Fan HH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P705
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Feng QY, 2020, IEEE T CIRC SYST VID, V30, P3413, DOI 10.1109/TCSVT.2020.2965966
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kong C, 2014, PROC CVPR IEEE, P3558, DOI 10.1109/CVPR.2014.455
   Li Y, 2018, PROC CVPR IEEE, P7492, DOI 10.1109/CVPR.2018.00782
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2016, ADV NEUR IN, V29
   Malinowski M, 2017, INT J COMPUT VISION, V125, P110, DOI 10.1007/s11263-017-1038-2
   Mnih V, 2014, ADV NEUR IN, V27
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Ramanathan V, 2014, LECT NOTES COMPUT SC, V8689, P95, DOI 10.1007/978-3-319-10590-1_7
   Ranzato MarcAurelio, 2015, CoRR
   Ren Mengye, 2015, NIPS, P2953
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49
   Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940
   Seo PaulHongsuck., 2017, Advances in neural information processing systems, P3722
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang AQ, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3226037
   Wang J, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT 2017), P313, DOI 10.1145/3176653.3176668
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu J, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3271485
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Wu Qi, 2018, P 2018 IEEE C COMP V
   Wu Y, 2020, IEEE T IMAGE PROCESS, V29, P3984, DOI 10.1109/TIP.2020.2967584
   Xu J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P537, DOI 10.1145/3123266.3123448
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Zhu LG, 2019, IRONMAK STEELMAK, V46, P499, DOI 10.1080/03019233.2017.1405153
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 48
TC 39
Z9 40
U1 0
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2020
VL 16
IS 3
AR 78
DI 10.1145/3390891
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NO3HD
UT WOS:000569375200004
DA 2024-07-18
ER

PT J
AU Francis, J
   Baburaj, M
   George, SN
AF Francis, Jobin
   Baburaj, M.
   George, Sudhish N.
TI A Unified Tensor Framework for Clustering and Simultaneous
   Reconstruction of Incomplete Imaging Data
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image clustering; subspace clustering; union of free submodules;
   low-rank approximation; image completion
ID RANK; COMPLETION; ALGORITHM; VIDEO
AB Incomplete observations in the data are always troublesome to data clustering algorithms. In fact, most of the well-received techniques are not designed to encounter such imperative scenarios. Hence, clustering of images under incomplete samples is an inquisitive yet unaddressed area of research. Therefore, the aim of this article is to design a single-stage optimization procedure for clustering as well as simultaneous reconstruction of images without breaking the intrinsic spatial structure. The method employs the self-expressiveness property of submodules, and images are stacked as the lateral slices of a three-dimensional tensor. The proposed optimization method is designed to extract a sparse t-linear combination tensor with low multirank constraint, consisting of a unique set of linear coefficients in the form of mode-3 fibers and the spectral clustering is performed on these fibers. Simultaneously, the recovery of lost samples is accomplished by twisting the entire lateral slices of the data tensor and applying a low-rank approximation on each slice. The prominence of the proposed method lies in the simultaneous execution of data clustering and reconstruction of incomplete observations in a single step. Experimental results reveal the excellence of the proposed method over state-of-the-art clustering algorithms in the context of incomplete imaging data.
C1 [Francis, Jobin; George, Sudhish N.] Natl Inst Technol Calicut, Calicut 673601, Kerala, India.
   [Baburaj, M.] Govt Engn Coll Kozhikode, Calicut, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut; Government Engineering College Kozhikode
RP Francis, J (corresponding author), Natl Inst Technol Calicut, Calicut 673601, Kerala, India.
EM jobinkapyarumalayil@gmail.com; baburajmadathil@gmail.com;
   sudhish@nitc.ac.in
RI Madathil, Baburaj/T-2001-2019
OI Madathil, Baburaj/0000-0003-3151-9270; FRANCIS,
   JOBIN/0000-0003-2666-3737
CR Aeron S, 2015, ANN ALLERTON CONF, P666, DOI 10.1109/ALLERTON.2015.7447068
   Ahmed N, 2015, IET IMAGE PROCESS, V9, P1020, DOI 10.1049/iet-ipr.2014.0885
   Altman A., 2013, A Term of Commutative Algebra
   [Anonymous], 2012, MATH PROBL ENG
   [Anonymous], 2014, ARXIV14127056
   [Anonymous], ANN STAT
   Baburaj M, 2019, MULTIMED TOOLS APPL, V78, P1805, DOI 10.1007/s11042-018-6251-7
   Berkhin P, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P25
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Campos GO, 2016, DATA MIN KNOWL DISC, V30, P891, DOI 10.1007/s10618-015-0444-8
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Das S, 2010, INFORM SCIENCES, V180, P1237, DOI 10.1016/j.ins.2009.11.041
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Duda R., 1973, Pattern Classification and Scene Analysis
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gan G, 2007, ASA SIAM SER STAT AP, V20, P1, DOI 10.1137/1.9780898718348
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Han J., 2005, DATA MINING CONCEPTS
   Hoi SCH, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823752
   Hu WR, 2017, IEEE T NEUR NET LEAR, V28, P2961, DOI 10.1109/TNNLS.2016.2611525
   Kong XY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192281
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu XY, 2016, PROC SPIE, V9848, DOI 10.1117/12.2224039
   Liu Y-H, 2014, MATH PROBL ENG, V2014, P11
   Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567
   Ma Y, 2008, SIAM REV, V50, P413, DOI 10.1137/060655523
   Madathil B, 2018, NEUROCOMPUTING, V318, P120, DOI 10.1016/j.neucom.2018.08.038
   Madathil B, 2018, INFORM SCIENCES, V423, P376, DOI 10.1016/j.ins.2017.09.058
   Nie SD, 2016, RSC ADV, V6, P21511, DOI 10.1039/c5ra25597j
   Parsons L., 2004, SIGKDD Explor Newsl, V6, P90, DOI 10.1145/1007730.1007731
   Piao Xinglin, 2016, ARXIV160100149
   Poddar Sunrita, 2018, Proc IEEE Int Conf Acoust Speech Signal Process, V2018, P2831, DOI [10.1109/ICASSP.2018.8462602, 10.1109/icassp.2018.8462602]
   Romano S, 2016, J MACH LEARN RES, V17
   Sagheer SVM, 2017, BIOMED SIGNAL PROCES, V38, P236, DOI 10.1016/j.bspc.2017.06.011
   Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Saxena A, 2017, NEUROCOMPUTING, V267, P664, DOI 10.1016/j.neucom.2017.06.053
   Schafer JL, 2002, PSYCHOL METHODS, V7, P147, DOI 10.1037//1082-989X.7.2.147
   Shabat Gil, 2013, ARXIV13026768
   Shi Q., 2017, IEEE Trans. Neural. Netw. Learn. Syst., V29, P4744
   Shi QQ, 2019, IEEE T NEUR NET LEAR, V30, P1803, DOI 10.1109/TNNLS.2018.2873655
   Shijila B, 2019, FUTURE GENER COMP SY, V90, P198, DOI 10.1016/j.future.2018.07.065
   Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882
   Tang Jinhui, 2019, IEEE T PATTERN ANAL, V41, P2027
   Tang KW, 2014, IEEE T NEUR NET LEAR, V25, P2167, DOI 10.1109/TNNLS.2014.2306063
   Tom AJ, 2019, IEEE SIGNAL PROC LET, V26, P577, DOI 10.1109/LSP.2019.2900126
   Tom Anju Jose, 2019, IEEE T CYBERNET
   Verleysen M, 2005, LECT NOTES COMPUT SC, V3512, P758
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wu T, 2018, IEEE SIGNAL PROC LET, V25, P1196, DOI 10.1109/LSP.2018.2849590
   Xiaofei He, 2005, 13th Annual ACM International Conference on Multimedia, P132
   Xie Y, 2018, INT J COMPUT VISION, V126, P1157, DOI 10.1007/s11263-018-1086-2
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [DOI 10.1007/S40745-015-0040-1, 10.1007/s40745-015-0040-1]
   Xu Yangyang, 2013, ARXIV13121254
   Xue JZ, 2019, INFORM SCIENCES, V503, P109, DOI 10.1016/j.ins.2019.06.061
   Xue JZ, 2019, IEEE T GEOSCI REMOTE, V57, P5174, DOI 10.1109/TGRS.2019.2897316
   Xue Shengke, 2019, ARXIV190101997
   Xue Z, 2019, INFORM SCIENCES, V493, P176, DOI 10.1016/j.ins.2019.04.034
   Yang CY, 2015, PR MACH LEARN RES, V37, P2463
   Yang X, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3089249
   Zha Zhiyuan, 2017, ARXIV170204463
   Zhang HY, 2016, IEEE T GEOSCI REMOTE, V54, P3672, DOI 10.1109/TGRS.2016.2524557
   Zhang HY, 2015, NEURAL COMPUT, V27, P1915, DOI 10.1162/NECO_a_00762
   Zhang L, 2009, PROCEEDINGS OF 2009 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS TECHNOLOGY AND APPLICATIONS, P212, DOI 10.1109/ICCOMTA.2009.5349209
   Zhang Zemin, 2013, ARXIV13070805
   Zhang Zemin, 2013, IEEE T PATTERN ANAL
   Zhou Pan, 2019, IEEE T PATTERN ANAL
   Zhou XW, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2674559
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zhu L, 2018, IEEE SIGNAL PROC LET, V25, P15, DOI 10.1109/LSP.2017.2768582
NR 71
TC 8
Z9 8
U1 1
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2020
VL 16
IS 3
AR 92
DI 10.1145/3399806
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NO3HD
UT WOS:000569375200018
DA 2024-07-18
ER

PT J
AU Wang, M
   Zhou, WA
   Tian, Q
   Li, HQ
AF Wang, Min
   Zhou, Wengang
   Tian, Qi
   Li, Houqiang
TI Deep Scalable Supervised Quantization by Self-Organizing Map
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Approximate nearest neighbor search; supervised quantization;
   self-organizing map
ID IMAGE; CODES
AB Approximate Nearest Neighbor (ANN) search is an important research topic in multimedia and computer vision fields. In this article, we propose a new deep supervised quantization method by Self-Organizing Map to address this problem. Our method integrates the Convolutional Neural Networks and Self-Organizing Map into a unified deep architecture. The overall training objective optimizes supervised quantization loss as well as classification loss. With the supervised quantization objective, we minimize the differences on the maps between similar image pairs and maximize the differences on the maps between dissimilar image pairs. By optimization, the deep architecture can simultaneously extract deep features and quantize the features into suitable nodes in self-organizing map. To make the proposed deep supervised quantization method scalable for large datasets, instead of constructing a larger self-organizing map, we propose to divide the input space into several subspaces and construct self-organizing map in each subspace. The self-organizing maps in all the subspaces implicitly construct a large self-organizing map, which costs less memory and training time than directly constructing a self-organizing map with equal size. The experiments on several public standard datasets prove the superiority of our approaches over the existing ANN search methods. Besides, as a by-product, our deep architecture can be directly applied to visualization with little modification, and promising performance is demonstrated in the experiments.
C1 [Wang, Min; Zhou, Wengang; Li, Houqiang] Univ Sci & Technol China, Hefei 230027, Anhui, Peoples R China.
   [Tian, Qi] Univ Texas San Antonio, Huawei Noahs Ark Lab, San Antonio, TX USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; University of Texas System; University of Texas at San
   Antonio (UTSA)
RP Zhou, WA; Li, HQ (corresponding author), Univ Sci & Technol China, Hefei 230027, Anhui, Peoples R China.
EM wm123@mail.ustc.edu.cn; zhwg@ustc.edu.cn; qitian@cs.utsa.edu;
   lihq@ustc.edu.cn
RI Li, Houqiang Li/B-6259-2013
FU NSFC [61822208, 61632019, 61836011]; Young Elite Scientists Sponsorship
   Program By CAST [2016QNRC001]
FX This work was supported in part to Dr. Wengang Zhou by NSFC under
   Contracts No. 61822208 and No. 61632019, Young Elite Scientists
   Sponsorship Program By CAST (2016QNRC001), and in part to Dr. Houqiang
   Li by NSFC under Contract No. 61836011.
CR [Anonymous], 2016, BIOMED RES INT
   [Anonymous], 2012, P 20 ACM MULTIMEDIA
   [Anonymous], 2016, P ACM INT C MULT
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2017, CVPR
   Cao Y, 2018, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2018.00134
   Cao Y, 2018, PROC CVPR IEEE, P1287, DOI 10.1109/CVPR.2018.00140
   Cao Y, 2016, AAAI CONF ARTIF INTE, P3457
   Chatfield Ken, 2014, P ASS ADV ART INT
   Chua T.-S., 2009, P ACM INT C IM VID R, P48
   Dizaji KG, 2018, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR.2018.00386
   Duan YQ, 2017, PROC CVPR IEEE, P4857, DOI 10.1109/CVPR.2017.516
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Hsu YC, 2016, ICLR WORKSH TRACK
   Hsu Yen-Chang, 2016, ARXIV161201253
   Hu MQ, 2019, IEEE T IMAGE PROCESS, V28, P2770, DOI 10.1109/TIP.2018.2890144
   Hu MQ, 2018, IEEE T IMAGE PROCESS, V27, P545, DOI 10.1109/TIP.2017.2749147
   Jain H., 2017, P INT C COMP VIS, V1, P3
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jiang Qing-Yuan, 2018, P ASS ADV ART INT
   Jiang YG, 2013, IEEE T MULTIMEDIA, V15, P442, DOI 10.1109/TMM.2012.2231061
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kohonen T., 2007, SCHOLARPEDIA, V2, P1568, DOI DOI 10.4249/SCHOLARPEDIA.1568
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Q, 2017, ADV NEUR IN, V30
   Li WJ, 2016, IJCAI, P1711
   Liao R., 2016, Proceedings of Neural Information Processing Systems, P5076
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1606, DOI 10.1109/TIP.2014.2305072
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P2352, DOI 10.1109/TIP.2017.2678163
   Luo Y, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7560805
   Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388
   Shen FM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1522, DOI 10.1145/3123266.3123345
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang DX, 2015, IEEE T MULTIMEDIA, V17, P1404, DOI 10.1109/TMM.2015.2455415
   Wang Jianfeng., 2013, ACM Multimedia, P133
   Wang M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1707, DOI 10.1145/3123266.3123415
   Wang M, 2018, IEEE T IMAGE PROCESS, V27, P907, DOI 10.1109/TIP.2017.2751150
   Wang XJ, 2016, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2016.222
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Yu LT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P861, DOI 10.1145/3240508.3240590
   Yu T, 2018, LECT NOTES COMPUT SC, V11205, P191, DOI 10.1007/978-3-030-01246-5_12
   Zhang HF, 2018, IEEE T IMAGE PROCESS, V27, P1626, DOI 10.1109/TIP.2017.2781422
   Zhang L, 2013, PROCEEDINGS OF THE EIGHTH INTERNATIONAL SYMPOSIUM ON VITICULTURE AND ENOLOGY (2013), P123
   Zhang QF, 2014, INT CONF MACH LEARN, P807, DOI 10.1109/ICMLC.2014.7009713
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhou W-X, 2014, ADV DIFFER EQU-NY, V2014, P16
   Zhou WG, 2015, IEEE T IMAGE PROCESS, V24, P967, DOI 10.1109/TIP.2015.2389624
   Zhu H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3567
   Zhu WJ, 2015, IEEE T MULTIMEDIA, V17, P935, DOI 10.1109/TMM.2015.2428171
NR 56
TC 1
Z9 1
U1 1
U2 21
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2019
VL 15
IS 3
AR 81
DI 10.1145/3328995
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JJ6YR
UT WOS:000494301200011
DA 2024-07-18
ER

PT J
AU Wu, J
   Hu, HF
   Yang, L
AF Wu, Jie
   Hu, Haifeng
   Yang, Liang
TI Pseudo-3D Attention Transfer Network with Content-aware Strategy for
   Image Captioning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image captioning; pseudo-3D attention network; transfer network;
   pseudo-3D attention transfer network; content-aware strategy
AB In this article, we propose a novel Pseudo-3D Attention Transfer network with Content-aware Strategy (P3DAT-CAS) for the image captioning task. Our model is composed of three parts: the Pseudo-3D Attention (P3DA) network, the P3DA-based Transfer (P3DAT) network, and the Content-aware Strategy (CAS). First, we propose P3DA to take full advantage of three-dimensional (3D) information in convolutional feature maps and capture more details. Most existing attention-based models only extract the 2D spatial representation from convolutional feature maps to decide which area should be paid more attention to. However, convolutional feature maps are 3D and different channel features can detect diverse semantic attributes associated with images. P3DA is proposed to combine 2D spatial maps with 1D semantic-channel attributes and generate more informative captions. Second, we design the transfer network to maintain and transfer the key previous attention information. The traditional attention-based approaches only utilize the current attention information to predict words directly, whereas transfer network is able to learn long-term attention dependencies and explore global modeling pattern. Finally, we present CAS to provide a more relevant and distinct caption for each image. The captioning model trained by maximum likelihood estimation may generate the captions that have a weak correlation with image contents, resulting in the cross-modal gap between vision and linguistics. However, CAS is helpful to convey the meaningful visual contents accurately. P3DAT-CAS is evaluated on Flickr30k and MSCOCO, and it achieves very competitive performance among the state-of-the-art models.
C1 [Wu, Jie; Hu, Haifeng; Yang, Liang] Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Hu, HF (corresponding author), Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM wujie23@mail2.sysu.edu.cn; huhaif@mail.sysu.edu.cn;
   yangliang5@mail2.sysu.edu.cn
OI Hu, Haifeng/0000-0002-4884-323X
FU National Natural Science Foundation of China [61673402, 61273270,
   60802069]; Natural Science Foundation of Guangdong [2017A030311029];
   National Key R&D Program of China [2018YFB1601101]; Science and
   Technology Program of Guangzhou [201704020180, 201604020024];
   Fundamental Research Funds for the Central Universities of China
   [17lgzd08]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61673402, 61273270 and 60802069, in
   part by the Natural Science Foundation of Guangdong under Grants
   2017A030311029, in part by the National Key R&D Program of China under
   Grant 2018YFB1601101, in part by the Science and Technology Program of
   Guangzhou under Grants 201704020180 and 201604020024, and in part by the
   Fundamental Research Funds for the Central Universities of China (under
   Grant 17lgzd08).
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], P ANN C INT SPEECH C
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.345
   [Anonymous], NEURAL PROCESS LETT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2004, TEXT SUMMARIZATION B
   [Anonymous], 2015, ARXIV150504467
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2015, arXiv
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], CVPR
   [Anonymous], 2012, P 20 ACM INT C MULT
   Bahdanau D., 2014, 3 INT C LEARN REPR
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Bengio S, 2015, ADV NEUR IN, V28
   Chen H, 2018, AAAI CONF ARTIF INTE, P6706
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, arXiv
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Li Y., 2018, EUR C COMP VIS ECCV, P684
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Mao Junhua, 2014, CoRR
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang AQ, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3226037
   Wang WX, 2019, NEURAL PROCESS LETT, V50, P1005, DOI 10.1007/s11063-019-10005-z
   Xia Yingce, 2017, ADV NEURAL INFORM PR, P1784, DOI DOI 10.5555/3294771.3294941
   Xu K., 2015, COMPUTER SCI, P2048
   Yang L, 2017, ELECTRON LETT, V53, P1471, DOI 10.1049/el.2017.2351
   Yang Z, 2016, INT CONF ACOUST SPEE, P3236, DOI 10.1109/ICASSP.2016.7472275
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
NR 46
TC 8
Z9 8
U1 0
U2 12
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2019
VL 15
IS 3
AR 80
DI 10.1145/3336495
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JJ6YR
UT WOS:000494301200010
DA 2024-07-18
ER

PT J
AU Wu, K
   Li, GB
   Li, HF
   Zhang, JJ
   Yu, YZ
AF Wu, Kan
   Li, Guanbin
   Li, Haofeng
   Zhang, Jianjun
   Yu, Yizhou
TI Harvesting Visual Objects from Internet Images via Deep-Learning-Based
   Objectness Assessment
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Object detection; object proposals; objectness; internet images;
   convolutional neural networks
AB The collection of internet images has been growing in an astonishing speed. It is undoubted that these images contain rich visual information that can be useful in many applications, such as visual media creation and data-driven image synthesis. In this article, we focus on the methodologies for building a visual object database from a collection of internet images. Such database is built to contain a large number of high-quality visual objects that can help with various data-driven image applications. Our method is based on dense proposal generation and objectness-based re-ranking. A novel deep convolutional neural network is designed for the inference of proposal objectness, the probability of a proposal containing optimally located foreground object. In our work, the objectness is quantitatively measured in regard of completeness and fullness, reflecting two complementary features of an optimal proposal: a complete foreground and relatively small background. Our experiments indicate that object proposals re-ranked according to the output of our network generally achieve higher performance than those produced by other state-of-the-art methods. As a concrete example, a database of over 1.2million visual objects has been built using the proposed method, and has been successfully used in various data-driven image applications.
C1 [Wu, Kan; Li, Haofeng; Yu, Yizhou] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Li, Guanbin] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
   [Yu, Yizhou] Deepwise AI Lab, Beijing, Peoples R China.
C3 University of Hong Kong; Sun Yat Sen University; Bournemouth University
RP Li, GB (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.
EM kwu@cs.hku.hk; liguanbin@mail.sysu.edu.cn; lhaof@foxmail.com;
   jzhang@bournemouth.ac.uk; yizhouy@acm.org
RI Li, Haofeng/AEJ-4106-2022
FU EU [691215]; National Natural Science Foundation of China [61702565];
   Marie Curie Actions (MSCA) [691215] Funding Source: Marie Curie Actions
   (MSCA)
FX This project was partially supported by the EU H2020 project-AniAge
   (No.691215) and the National Natural Science Foundation of China
   (No.61702565).
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2014, ABS14064729 CORR
   [Anonymous], ABS150606204 CORR
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Chavali Neelima, 2016, IEEE C COMP VIS PATT
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   CHO M, 2015, PROC CVPR IEEE, P1201, DOI DOI 10.1109/CVPR.2015.7298724
   Dai Jifeng, 2016, P EUR C COMP VIS
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296
   Guan JW, 2017, IEEE T MULTIMEDIA, V19, P2505, DOI 10.1109/TMM.2017.2703148
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo Weicheng, 2015, ABS150502146 CORR
   Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276381, 10.1145/1239451.1239454]
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li Guanbin, 2018, IEEE T NEURAL NETWOR, V99, P1
   Li N, 2018, IEEE T MULTIMEDIA, V20, P1365, DOI 10.1109/TMM.2017.2771566
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu Cewu, 2015, IEEE INT C COMP VIS
   Lu WT, 2013, IEEE T MULTIMEDIA, V15, P1920, DOI 10.1109/TMM.2013.2280895
   Ma L, 2017, IEEE T MULTIMEDIA, V19, P2545, DOI 10.1109/TMM.2017.2703089
   Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russell BC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508425
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190
   Tsai YH, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925942
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661278
   Wang WY, 2011, IEEE T MULTIMEDIA, V13, P1308, DOI 10.1109/TMM.2011.2165053
   Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10
   Wu K, 2018, IET IMAGE PROCESS, V12, P1131, DOI 10.1049/iet-ipr.2017.1144
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xiao Yao, 2015, IEEE C COMP VIS PATT
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang LJ, 2011, IEEE T MULTIMEDIA, V13, P1295, DOI 10.1109/TMM.2011.2162399
   Yao YZ, 2017, IEEE T MULTIMEDIA, V19, P1771, DOI 10.1109/TMM.2017.2684626
   Zhang FL, 2013, IEEE T MULTIMEDIA, V15, P1480, DOI 10.1109/TMM.2013.2268051
   Zhang H., 2018, CATALYSIS SCI TECHNO, V2018, P1, DOI DOI 10.1109/ICME.2018.8486523
   Zhang JM, 2015, PROC CVPR IEEE, P4045, DOI 10.1109/CVPR.2015.7299031
   Zhang J, 2017, IEEE T MULTIMEDIA, V19, P2439, DOI 10.1109/TMM.2017.2701641
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 60
TC 0
Z9 0
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2019
VL 15
IS 3
AR 72
DI 10.1145/3318463
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JJ6YR
UT WOS:000494301200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hong, JW
   Curran, NM
AF Hong, Joo-Wha
   Curran, Nathaniel Ming
TI Artificial Intelligence, Artists, and Art: Attitudes Toward Artwork
   Produced by Humans vs. Artificial Intelligence
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; creativity; art; CASA; schema theory;
   human-computer interaction; human-machine communication
ID FRAMEWORK; MEDIA
AB This study examines how people perceive artwork created by artificial intelligence (AI) and how presumed knowledge of an artist's identity (Human vs. AI) affects individuals' evaluation of art. Drawing on Schema theory and theory of Computers Are Social Actors (CASA), this study used a survey-experiment that controlled for the identity of the artist (AI vs. Human) and presented participants with two types of artworks (AI-created vs. Human-created). After seeing images of six artworks created by either AI or human artists, participants (n = 288) were asked to evaluate the artistic value using a validated scale commonly employed among art professionals. The study found that human-created artworks and AI-created artworks were not judged to be equivalent in their artistic value. Additionally, knowing that a piece of art was created by AI did not, in general, influence participants' evaluation of art pieces' artistic value. However, having a schema that AI cannot make art significantly influenced evaluation. Implications of the findings for application and theory are discussed.
C1 [Hong, Joo-Wha; Curran, Nathaniel Ming] Univ Southern Calif, Annenberg Sch Commun & Journalism, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Hong, JW (corresponding author), Univ Southern Calif, Annenberg Sch Commun & Journalism, Los Angeles, CA 90089 USA.
EM joowhaho@usc.edu; ncurran@usc.edu
RI Hong, Joo-Wha/AAK-8706-2021
OI Hong, Joo-Wha/0000-0002-6555-3074; Curran, Nathaniel/0000-0002-6477-8730
FU USC Graduate School; USC Annenberg Doctoral Student Summer Research
   Fellowship
FX This research is funded by the USC Graduate School and an Annenberg
   Doctoral Student Summer Research Fellowship.
CR Adams R.L., 2017, FORBES
   [Anonymous], 2012, WIRED
   [Anonymous], 2017, P 8 INT C COMP CREAT
   BARONCOHEN S, 1985, COGNITION, V21, P37, DOI 10.1016/0010-0277(85)90022-8
   Boden M., 1998, ARTIF INTELL, V103
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316
   Casler K, 2013, COMPUT HUM BEHAV, V29, P2156, DOI 10.1016/j.chb.2013.05.009
   Chamberlain R, 2018, PSYCHOL AESTHET CREA, V12, P177, DOI 10.1037/aca0000136
   Chaminade T, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00103
   Chandler J, 2014, BEHAV RES METHODS, V46, P112, DOI 10.3758/s13428-013-0365-7
   Coeckelbergh Mark, 2017, PHILOS TECHNOLOGY, V30, P285
   Cypher M., 2017, Journal of Visual Art Practice, V16, P119, DOI [10.1080/14702029.2017.1292379, DOI 10.1080/14702029.2017.1292379]
   Dannenberg RB, 2006, ARTIF INTELL, V170, P1218, DOI 10.1016/j.artint.2006.10.004
   Dennett Daniel Clement, 1987, The intentional stance
   Dixon TL, 2006, COMMUN MONOGR, V73, P162, DOI 10.1080/03637750600690643
   Eppe M, 2018, ARTIF INTELL, V256, P105, DOI 10.1016/j.artint.2017.11.005
   Gibbs Samuel, 2016, GUARDIAN
   Heider F, 1944, AM J PSYCHOL, V57, P243, DOI 10.2307/1416950
   Hertzmann A, 2018, ARTS, V7, DOI 10.3390/arts7020018
   Jackson TE, 2017, MOSAIC, V50, P47
   Jacobsen T, 2006, LEONARDO, V39, P155, DOI 10.1162/leon.2006.39.2.155
   Lindell AK, 2011, J COGN PSYCHOL, V23, P453, DOI 10.1080/20445911.2011.539556
   Marchesi Serena, 2018, PSYARXIV
   Marzano G, 2017, PROCEDIA COMPUT SCI, V104, P146, DOI 10.1016/j.procs.2017.01.089
   McCarthy J, 2007, ARTIF INTELL, V171, P1174, DOI 10.1016/j.artint.2007.10.009
   McFarland M., 2016, WASHINGTON POST
   MIRANDA ER, 1995, COMPUT MUSIC J, V19, P59, DOI 10.2307/3680600
   Mou Y, 2017, COMPUT HUM BEHAV, V72, P432, DOI 10.1016/j.chb.2017.02.067
   Nass C. I., 2000, J SOC ISSUES, V56, P1
   NORMAN DA, 1981, COGNITION, V10, P235, DOI 10.1016/0010-0277(81)90051-2
   PAGE MM, 1974, J PERS SOC PSYCHOL, V30, P468, DOI 10.1037/h0037036
   Qfiasco Flash, 2018, ARTIF INTELL, V260, P36
   Rilling JK, 2004, NEUROIMAGE, V22, P1694, DOI 10.1016/j.neuroimage.2004.04.015
   Sabol R., 2006, Art Education, V59, P6
   Shermer M., 2017, SKEPTIC ALTADENA CA, V22, P29
   Solly M., 2018, SMITHSONIAN MAGAZINE
   Sundar SS, 2000, COMMUN RES, V27, P683, DOI 10.1177/009365000027006001
   Thellman S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01962
   Turkle S, 2005, SECOND SELF: COMPUTERS AND THE HUMAN SPIRIT, TWENTIETH ANNIVERSARY EDITION, P1
   Wakefield J., 2015, BBC
   WALTHER C, 1994, ARTIF INTELL, V71, P101, DOI 10.1016/0004-3702(94)90063-9
   Wykowska A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094339
   Yu Y., 2016, Revista Ibrica De Sistemas e Tecnologias De Informao, V18B, P116
NR 43
TC 62
Z9 64
U1 53
U2 310
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2019
VL 15
IS 2
SU S
SI SI
AR 58
DI 10.1145/3326337
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA IS2RO
UT WOS:000482001900011
DA 2024-07-18
ER

PT J
AU Hosny, KM
   Darwish, MM
AF Hosny, Khalid M.
   Darwish, Mohamed M.
TI Resilient Color Image Watermarking Using Accurate Quaternion Radial
   Substituted Chebyshev Moments
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Quaternion radial substituted Chebyshev moments; color image
   watermarking; geometric attacks; noise resistance; JPEG compression
ID FOURIER-MELLIN MOMENTS; FAST COMPUTATION; ROBUST; SCHEME; TRANSFORM;
   MULTIMEDIA; INVARIANT
AB In this work, a new quaternion-based method for color image watermarking is proposed. In this method, a novel set of quaternion radial substituted Chebyshev moments (QRSCMs) is presented for robust geometrically invariant image watermarking. An efficient computational method is proposed for highly accurate, fast, and numerically stable QRSCMs in polar coordinates. The proposed watermarking method consists of three stages. In the first stage, the Arnold transform is used to improve the security of the watermarking scheme by scrambling the binary watermark. In the second stage, the proposed accurate and stable QRSCMs of the host color image are computed. In the third stage, the encrypted binary watermark is embedded into the host image by employing the quantization technique on selected-magnitude QRSCMs where the watermarked color image is obtained by adding the original host color image to the compensation image. Then, the binary watermark can be extracted directly without using the original image from the magnitudes of QRSCMs. Numerical experiments are performed where the performance of proposed method is compared with the existing quaternion moment-based watermarking methods. The comparison clearly shows that the proposed method is very efficient in terms of the visual imperceptibility capability and the robustness under different attacks compared to the existing quaternion moment-based watermarking algorithms.
C1 [Hosny, Khalid M.] Zagazig Univ, Fac Comp & Informat, Dept Informat Technol, Zagazig 44519, Egypt.
   [Darwish, Mohamed M.] Assiut Univ, Fac Sci, Dept Math, Assiut 71516, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Assiut University
RP Hosny, KM (corresponding author), Zagazig Univ, Fac Comp & Informat, Dept Informat Technol, Zagazig 44519, Egypt.
EM hosnykm@gmail.com; mohamedcscience@gmail.com
RI Elhoseny, Mohamed/Q-5591-2017; Hosny, Khalid M./B-1404-2008
OI Elhoseny, Mohamed/0000-0001-6347-8368; Hosny, Khalid
   M./0000-0001-8065-8977; Darwish, Mohamed/0000-0003-3256-8728
CR Akhaee MA, 2011, IEEE T INF FOREN SEC, V6, P883, DOI 10.1109/TIFS.2011.2146250
   Al-Otum HA, 2009, COMPUT ELECTR ENG, V35, P673, DOI 10.1016/j.compeleceng.2009.01.007
   Alghoniemy M, 2004, IEEE T IMAGE PROCESS, V13, P145, DOI 10.1109/TIP.2004.823831
   [Anonymous], INT J IMAGE GRAPH SI
   [Anonymous], P INT C COMP AN IM P
   [Anonymous], AEU INT J ELECT COMM
   Battiato S, 2012, IEEE MULTIMEDIA, V19, P17, DOI 10.1109/MMUL.2012.10
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Camacho-Bello C, 2014, J OPT SOC AM A, V31, P124, DOI 10.1364/JOSAA.31.000124
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen BJ, 2018, MULTIMED TOOLS APPL, V77, P20809, DOI 10.1007/s11042-017-5511-2
   [陈北京 Chen Beijing], 2012, [自动化学报, Acta Automatica Sinica], V38, P1815
   Chou CH, 2010, IEEE T IMAGE PROCESS, V19, P2966, DOI 10.1109/TIP.2010.2052261
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Guo FX, 2017, DIGIT SIGNAL PROCESS, V62, P249, DOI 10.1016/j.dsp.2016.12.008
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hosny Khalid Mohamed, 2011, Journal of Computer Sciences, V7, P715, DOI 10.3844/jcssp.2011.715.722
   Hosny KM, 2018, MULTIMED TOOLS APPL, V77, P24727, DOI 10.1007/s11042-018-5670-9
   Hosny KM, 2017, COMPUT ELECTR ENG, V62, P429, DOI 10.1016/j.compeleceng.2017.05.015
   Hosny KM, 2019, J REAL-TIME IMAGE PR, V16, P1235, DOI 10.1007/s11554-016-0622-y
   Hosny KM, 2017, DIGIT SIGNAL PROCESS, V68, P152, DOI 10.1016/j.dsp.2017.06.002
   Hosny KM, 2011, J REAL-TIME IMAGE PR, V6, P73, DOI 10.1007/s11554-009-0135-z
   Iftikhar S, 2015, IEEE T KNOWL DATA EN, V27, P1132, DOI 10.1109/TKDE.2014.2349911
   Ismail Ismail A., 2010, Journal of Computer Sciences, V6, P52, DOI 10.3844/jcssp.2010.52.59
   Kuribayashi M, 2014, IEEE T INF FOREN SEC, V9, P610, DOI 10.1109/TIFS.2014.2305799
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liu KC, 2010, AEU-INT J ELECTRON C, V64, P112, DOI 10.1016/j.aeue.2008.11.006
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Qi M, 2015, SIGNAL PROCESS-IMAGE, V31, P161, DOI 10.1016/j.image.2014.12.009
   Singh C, 2013, OPT LASER TECHNOL, V54, P176, DOI 10.1016/j.optlastec.2013.05.016
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P24221, DOI 10.1007/s11042-016-4164-x
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P707, DOI 10.1007/s11042-015-3071-x
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Tsougenis ED, 2013, OPT LASER TECHNOL, V54, P84, DOI 10.1016/j.optlastec.2013.05.004
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Winkler T, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2545883
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Yang HY, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700299
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
   Zhu HQ, 2010, DIGIT SIGNAL PROCESS, V20, P1612, DOI 10.1016/j.dsp.2010.01.010
NR 52
TC 50
Z9 50
U1 3
U2 25
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2019
VL 15
IS 2
AR 46
DI 10.1145/3325193
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IM3ZV
UT WOS:000477935400017
DA 2024-07-18
ER

PT J
AU Wang, AR
   Cai, JF
   Lu, JW
   Cham, TJ
AF Wang, Anran
   Cai, Jianfei
   Lu, Jiwen
   Cham, Tat-Jen
TI Structure-Aware Multimodal Feature Fusion for RGB-D Scene Classification
   and Beyond
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Feature fusion; multimodal analytics; RGB-D scene classification; action
   recognition; group sparsity
ID ACTION RECOGNITION
AB While convolutional neural networks (CNNs) have been excellent for object recognition, the greater spatial variability in scene images typically means that the standard full-image CNNfeatures are suboptimal for scene classification. In this article, we investigate a framework allowing greater spatial flexibility, in which the Fisher vector (FV)-encoded distribution of local CNN features, obtained from a multitude of region proposals per image, is considered instead. The CNN features are computed from an augmented pixel-wise representation consisting of multiple modalities of RGB, HHA, and surface normals, as extracted from RGB-D data. More significantly, we make two postulates: (1) component sparsity-that only a small variety of region proposals and their corresponding FV GMM components contribute to scene discriminability, and (2) modal nonsparsity-that features from all modalities are encouraged to coexist. In our proposed feature fusion framework, these are implemented through regularization terms that apply group lasso to GMM components and exclusive group lasso across modalities. By learning and combining regressors for both proposal-based FV features and global CNN features, we are able to achieve state-of-the-art scene classification performance on the SUNRGBD Dataset and NYU Depth Dataset V2. Moreover, we further apply our feature fusion framework on an action recognition task to demonstrate that our framework can be generalized for other multimodal well-structured features. In particular, for action recognition, we enforce interpart sparsity to choose more discriminative body parts, and intermodal nonsparsity to make informative features from both appearance and motion modalities coexist. Experimental results on the JHMDB and MPII Cooking Datasets show that our feature fusion is also very effective for action recognition, achieving very competitive performance compared with the state of the art.
C1 [Wang, Anran] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Cai, Jianfei; Cham, Tat-Jen] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Lu, Jiwen] Tsinghua Univ, Dept Automat, Beijing, Peoples R China.
C3 Hong Kong Baptist University; Nanyang Technological University; Tsinghua
   University
RP Wang, AR (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
EM anranwang1991@gmail.com; asjfcai@ntu.edu.sg; lujiwen@tsinghua.edu.cn;
   astjcham@ntu.edu.sg
RI ARSLAN, Okan/AAA-3232-2020
FU Nanyang Technological University (NTU) Singapore; University of North
   Carolina (UNC) at Chapel Hill; National Research Foundation, Prime
   Minister's Office, Singapore under its International Research Centres in
   Singapore
FX This research is supported by the BeingTogether Centre, a collaboration
   between Nanyang Technological University (NTU) Singapore and University
   of North Carolina (UNC) at Chapel Hill. The BeingTogether Centre is
   supported by the National Research Foundation, Prime Minister's Office,
   Singapore under its International Research Centres in Singapore Funding
   Initiative.
CR [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2016, CVPR
   [Anonymous], ARXIV150405843
   [Anonymous], 2014, PROC BRIT MACH VIS C
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Banica D, 2015, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2015.7298974
   Bo L., 2011, Neural Information Processing Systems, P2115
   Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32
   Cherian A, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.302
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Escorcia V, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P508, DOI 10.1109/ICCVW.2013.72
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gupta S, 2015, INT J COMPUT VISION, V112, P133, DOI 10.1007/s11263-014-0777-6
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Huang JZ, 2011, J MACH LEARN RES, V12, P3371
   Janoch A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Kohli Pushmeet, 2012, ECCV
   Kong D., 2014, Advances in Neural Information Processing Systems, P1655
   Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Liao YY, 2016, IEEE INT CONF ROBOT, P2318, DOI 10.1109/ICRA.2016.7487381
   Lillo I, 2016, PROC CVPR IEEE, P1981, DOI 10.1109/CVPR.2016.218
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Naikal N, 2011, IEEE I CONF COMP VIS, P818, DOI 10.1109/ICCV.2011.6126321
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2014, LECT NOTES COMPUT SC, V8689, P616, DOI 10.1007/978-3-319-10590-1_40
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2012, BIOINFORMATICS, V28, pI127, DOI 10.1093/bioinformatics/bts228
   Wang H, 2011, IEEE I CONF COMP VIS, P557, DOI 10.1109/ICCV.2011.6126288
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Yoo D., 2014, ARXIV PREPRINT ARXIV
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou Y., 2010, JMLR WORKSHOP C P, P988
   Zhou Y, 2015, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR.2015.7298953
   Zuo Z, 2014, LECT NOTES COMPUT SC, V8689, P552, DOI 10.1007/978-3-319-10590-1_36
NR 62
TC 9
Z9 10
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2018
VL 14
IS 2
SU S
AR 39
DI 10.1145/3115932
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GI6TD
UT WOS:000434634700012
DA 2024-07-18
ER

PT J
AU Demisse, GG
   Aouada, D
   Ottersten, B
AF Demisse, Girum G.
   Aouada, Djamila
   Ottersten, Bjorn
TI Deformation-Based 3D Facial Expression Representation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE 3D facial expression representation; expression modelling; 3D face
   deformation
ID FACE RECOGNITION; METRICS
AB We propose a deformation-based representation for analyzing expressions fromthree-dimensional (3D) faces. A point cloud of a 3D face is decomposed into an ordered deformable set of curves that start from a fixed point. Subsequently, a mapping function is defined to identify the set of curves with an element of a high-dimensional matrix Lie group, specifically the direct product of SE(3). Representing 3D faces as an element of a high-dimensional Lie group has two main advantages. First, using the group structure, facial expressions can be decoupled from a neutral face. Second, an underlying non-linear facial expression manifold can be captured with the Lie group and mapped to a linear space, Lie algebra of the group. This opens up the possibility of classifying facial expressions with linear models without compromising the underlying manifold. Alternatively, linear combinations of linearised facial expressions can be mapped back from the Lie algebra to the Lie group. The approach is tested on the Binghamton University 3D Facial Expression (BU-3DFE) and the Bosphorus datasets. The results show that the proposed approach performed comparably, on the BU-3DFE dataset, without using features or extensive landmark points.
C1 [Demisse, Girum G.; Aouada, Djamila; Ottersten, Bjorn] Univ Luxembourg, 29 Ave JF Kennedy, L-1855 Luxembourg, Luxembourg.
C3 University of Luxembourg
RP Demisse, GG (corresponding author), Univ Luxembourg, 29 Ave JF Kennedy, L-1855 Luxembourg, Luxembourg.
EM girum.demisse@uni.lu; djamila.aouada@uni.lu; bjorn.ottersten@uni.lu
RI Ottersten, Bjorn/AAF-9147-2019; Ottersten, Bjorn/G-1005-2011
OI Aouada, Djamila/0000-0002-7576-2064; Ottersten,
   Bjorn/0000-0003-2298-6774
FU European Union's Horizon 2020 research and innovation project STARR
   [689947]; H2020 Societal Challenges Programme [689947] Funding Source:
   H2020 Societal Challenges Programme
FX This work was partly funded by the European Union's Horizon 2020
   research and innovation project STARR under grant agreement No. 689947.
CR Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0
   [Anonymous], 2013, LIE GROUPS LIE ALGEB
   [Anonymous], 1 COST 2101 WORKSH B
   [Anonymous], 2007, ARXIV07064299
   [Anonymous], 1998, STAT SHAPE ANAL
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P 2008 8 IEEE INT C, DOI DOI 10.1109/AFGR.2008.4813324
   Aouada D, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P107, DOI 10.1109/AVSS.2014.6918652
   Bartlett MS, 1996, ADV NEUR IN, V8, P823
   BELLMAN R, 1956, P NATL ACAD SCI USA, V42, P767, DOI 10.1073/pnas.42.10.767
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Berretti S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x
   Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293
   Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006
   Demisse GG, 2015, IEEE IMAGE PROC, P4386, DOI 10.1109/ICIP.2015.7351635
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Drira Hassen., 2010, BMVC, P1
   Ekman P, 1978, FACIAL ACTION CODING
   Fang T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P603, DOI 10.1109/FG.2011.5771466
   Gong B., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P569
   Ham Jihun., 2007, NEURAL INFORM PROCES, V11, P91
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   Kurtek S, 2015, COMPUT GRAPH-UK, V51, P52, DOI 10.1016/j.cag.2015.05.027
   Li HB, 2015, COMPUT VIS IMAGE UND, V140, P83, DOI 10.1016/j.cviu.2015.07.005
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Mennucci ACG, 2013, LECT NOTES MATH, V2090, P205, DOI 10.1007/978-3-319-01712-9_4
   Mpiperis I., 2008, FG'08, P1
   Oyedotun OK, 2017, IEEE INT CONF COMP V, P3161, DOI 10.1109/ICCVW.2017.374
   Pantic M., 2007, MACHINE ANAL FACIAL
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   Ranzato M, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995710
   Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235
   Samir C, 2009, INT J COMPUT VISION, V82, P80, DOI 10.1007/s11263-008-0187-8
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Taheri S, 2014, IEEE T IMAGE PROCESS, V23, P3590, DOI 10.1109/TIP.2014.2331141
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Vondrick C, 2013, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2013.8
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x
   Wei J, 2013, IEEE ICCE, P1, DOI 10.1109/ICCE.2013.6486769
   Xudong Yang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163090
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhen QK, 2016, IEEE T MULTIMEDIA, V18, P1438, DOI 10.1109/TMM.2016.2557063
NR 52
TC 3
Z9 3
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2018
VL 14
IS 1
SU S
AR 17
DI 10.1145/3176649
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GH5ZK
UT WOS:000433517100003
OA Green Published
DA 2024-07-18
ER

PT J
AU Guerrini, F
   Adami, N
   Benini, S
   Piacenza, A
   Porteous, J
   Cavazza, M
   Leonardi, R
AF Guerrini, Fabrizio
   Adami, Nicola
   Benini, Sergio
   Piacenza, Alberto
   Porteous, Julie
   Cavazza, Marc
   Leonardi, Riccardo
TI Interactive Film Recombination
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Interactive storytelling; logical story unit; semantic description;
   Markov chains; narrative modeling
AB In this article, we discuss an innovative media entertainment application called Interactive Movietelling. As an offspring of Interactive Storytelling applied to movies, we propose to integrate narrative generation through artificial intelligence (AI) planning with video processing and modeling to construct filmic variants starting from the baseline content. The integration is possible thanks to content description using semantic attributes pertaining to intermediate-level concepts shared between video processing and planning levels. The output is a recombination of segments taken from the input movie performed so as to convey an alternative plot. User tests on the prototype proved how promising Interactive Movietelling might be, even if it was designed at a proof of concept level. Possible improvements that are suggested here lead to many challenging research issues.
C1 [Guerrini, Fabrizio; Adami, Nicola; Benini, Sergio; Piacenza, Alberto; Leonardi, Riccardo] Univ Brescia, Dept Informat Engn, Via Branze 38, I-25123 Brescia, Italy.
   [Porteous, Julie] Teesside Univ, Digital Futures Inst, Sch Comp, Campus Heart,Southfield Rd, Middlesbrough TS1 3BX, Cleveland, England.
   [Cavazza, Marc] Univ Kent, Sch Engn & Digital Arts, Jennison Bldg, Canterbury CT2 7NT, Kent, England.
C3 University of Brescia; University of Teesside; University of Kent
RP Guerrini, F (corresponding author), Univ Brescia, Dept Informat Engn, Via Branze 38, I-25123 Brescia, Italy.
EM fabrizio.guerrini@unibs.it; nicola.adami@unibs.it;
   sergio.benini@unibs.it; alberto.piacenza@unibs.it;
   j.porteous@tees.ac.uk; m.o.cavazza@kent.ac.uk;
   riccardo.leonardi@unibs.it
RI Leonardi, Riccardo/F-5666-2010
OI Porteous, Julie/0000-0003-4618-2359
CR ACM Trans, 2017, MULTIMEDIA COMPUT CO, V13
   [Anonymous], 2010, P 18 ACM INT C MULTI
   Balint K., 2016, J MEDIA PSYCHOL, V1, P1
   Benini S, 2016, MULTIMED TOOLS APPL, V75, P16499, DOI 10.1007/s11042-016-3339-9
   Benini S, 2007, INT WORK CONTENT MUL, P152
   Benini S, 2011, IEEE T MULTIMEDIA, V13, P1356, DOI 10.1109/TMM.2011.2163058
   Benini S, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/709161
   Benini S, 2010, SIGNAL IMAGE VIDEO P, V4, P435, DOI 10.1007/s11760-009-0151-2
   Bocconi S, 2008, J WEB SEMANT, V6, P139, DOI 10.1016/j.websem.2008.01.004
   Brooks K., 1997, 4 ACM INT C MULT, P317
   Canini L, 2013, IEEE T CIRC SYST VID, V23, P636, DOI 10.1109/TCSVT.2012.2211935
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Crawford C., 2003, NEW RIDERS
   Crawford Chris, 2004, C CRAWFORD INTERACTI
   DAVIS M, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P120
   Garcia P., 2008, ACM T MULTIM COMPUT, V4, P1
   GRAESSER AC, 1991, J MEM LANG, V30, P186, DOI 10.1016/0749-596X(91)90003-3
   IRIS, 2011, INT RES INT STOR IRI
   Jung B, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230817
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Kovács AB, 2014, PROJECTIONS, V8, P50, DOI 10.3167/proj.2014.080204
   Mateas M, 2005, P 1 ART INT INT DIG, P93
   Mobbs D, 2006, SOC COGN AFFECT NEUR, V1, P95, DOI 10.1093/scan/nsl014
   Monaco J., 2000, HOW READ FILM WORLD
   Nack F., 1996, AUTEUR APPL VIDEO SE
   Nakamura Y, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P393, DOI 10.1145/266180.266391
   Piacenza A, 2012, EUR SIGNAL PR CONF, P405
   Piacenza A., 2011, Proceedings of the 19th ACM international conference on Multimedia (MM '11), P223, DOI DOI 10.1145/2072298.2072329
   Piacenza A, 2013, IEEE INT WORKSH MULT, P183, DOI 10.1109/MMSP.2013.6659285
   Porteous J, 2010, ACM T INTEL SYST TEC, V1, DOI 10.1145/1869397.1869399
   Radford M., 2004, MERCHANT VENICE FIL
   Sack W., 1994, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.94TH0631-2), P30, DOI 10.1109/MMCS.1994.292430
   Serrano N, 2002, INT C PATT RECOG, P146, DOI 10.1109/ICPR.2002.1047420
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shen EYT, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P809
   Smith T.G. Aguierre., 1992, P 3 INT WORKSHOP NET, P250
   Zsombori V, 2008, LECT NOTES COMPUT SC, V5066, P40, DOI 10.1007/978-3-540-69478-6_5
NR 38
TC 4
Z9 4
U1 2
U2 24
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2017
VL 13
IS 4
AR 52
DI 10.1145/3103241
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FL6JZ
UT WOS:000414352300006
OA Green Submitted, Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Yang, X
   Wang, M
   Hong, RC
   Tian, Q
   Rui, Y
AF Yang, Xun
   Wang, Meng
   Hong, Richang
   Tian, Qi
   Rui, Yong
TI Enhancing Person Re-identification in a Self-Trained Subspace
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; self-training; semi-supervised learning
AB Despite the promising progress made in recent years, person re-identification (re-ID) remains a challenging task due to the complex variations in human appearances from different camera views. For this challenging problem, a large variety of algorithms have been developed in the fully supervised setting, requiring access to a large amount of labeled training data. However, the main bottleneck for fully supervised re-ID is the limited availability of labeled training samples. To address this problem, we propose a self-trained subspace learning paradigm for person re-ID that effectively utilizes both labeled and unlabeled data to learn a discriminative subspace where person images across disjoint camera views can be easily matched. The proposed approach first constructs pseudo-pairwise relationships among unlabeled persons using the k-nearest neighbors algorithm. Then, with the pseudo-pairwise relationships, the unlabeled samples can be easily combined with the labeled samples to learn a discriminative projection by solving an eigenvalue problem. In addition, we refine the pseudo-pairwise relationships iteratively, which further improves learning performance. A multi-kernel embedding strategy is also incorporated into the proposed approach to cope with the non-linearity in a person's appearance and explore the complementation of multiple kernels. In this way, the performance of person re-ID can be greatly enhanced when training data are insufficient. Experimental results on six widely used datasets demonstrate the effectiveness of our approach, and its performance can be comparable to the reported results of most state-of-the-art fully supervised methods while using much fewer labeled data.
C1 [Yang, Xun; Wang, Meng; Hong, Richang] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
   [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
   [Rui, Yong] Lenovo, 6 Shang Di West Rd, Beijing 100085, Peoples R China.
C3 Hefei University of Technology; University of Texas System; University
   of Texas at San Antonio (UTSA); Legend Holdings; Lenovo
RP Wang, M (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
EM hfutyangxun@gmail.com; eric.mengwang@gmail.com; hongrc.hfut@gmail.com;
   qitian@cs.utsa.edu; yongrui@lenovo.com
RI Wang, Meng/ITR-8699-2023
FU National 973 Program of China [2014CB347600]; National Nature Science
   Foundation of China [61432019]
FX This work was supported by the National 973 Program of China under grant
   2014CB347600 and the National Nature Science Foundation of China under
   grant 61432019.
CR An L, 2015, IEEE SIGNAL PROC LET, V22, P1103, DOI 10.1109/LSP.2015.2390222
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], ACM T INTELLIGENT SY
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], ASYMMETRIC DISTANCE
   Basu Sugato, 2002, P INT C MACH LEARN
   Cai D, 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/CVPR.2007.383054
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Figueira D, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P111, DOI 10.1109/AVSS.2013.6636625
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He X., 2003, ADV NEURAL INFORM PR, P153
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hoi S.C., 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587351
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Karaman S, 2014, PATTERN RECOGN, V47, P3767, DOI 10.1016/j.patcog.2014.06.003
   Kodirov E, 2016, LECT NOTES COMPUT SC, V9905, P178, DOI 10.1007/978-3-319-46448-0_11
   Kodirov Elyor, 2015, P 26 BRIT MACH VIS C, V3, P8
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li Sheng, 2015, IJCAI
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Lisanti G., 2014, Proceedings of the International Conference on Distributed Smart Cameras, p10:1
   Lisanti G, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3038916
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   LIU X, 2014, PROC CVPR IEEE, P3550, DOI DOI 10.1109/CVPR.2014.454
   Loog M, 2016, IEEE T PATTERN ANAL, V38, P462, DOI 10.1109/TPAMI.2015.2452921
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Loy CC, 2013, IEEE IMAGE PROC, P3567, DOI 10.1109/ICIP.2013.6738736
   MA B, 2012, P EUR C COMPUT VIS, P413, DOI DOI 10.1007/978-3-642-33863-241
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   MCLACHLAN GJ, 1975, J AM STAT ASSOC, V70, P365
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Qiu SB, 2009, IEEE ACM T COMPUT BI, V6, P190, DOI 10.1109/TCBB.2008.139
   Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Shen Yang, 2015, P IEEE INT C COMP VI
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Shrivastava A, 2014, IEEE T IMAGE PROCESS, V23, P3013, DOI 10.1109/TIP.2014.2324290
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Sugiyama M., 2006, P 23 INT C MACH LEAR, P905, DOI DOI 10.1145/1143844.1143958
   Sugiyama M, 2010, MACH LEARN, V78, P35, DOI 10.1007/s10994-009-5125-7
   Varior RR, 2016, IEEE T IMAGE PROCESS, V25, P3395, DOI 10.1109/TIP.2016.2531280
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yang Xun, 2016, P 25 INT JOINT C ART
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yang Yang, 2016, P INT JOINT C ART IN
   Yarowsky D., 1995, 33 ANN M ASS COMPUTA, P189, DOI DOI 10.3115/981658.981684
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang Y, 2016, PROC CVPR IEEE, P5985, DOI 10.1109/CVPR.2016.644
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, ARXIV
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhu X, 2009, Synthesis Lectures on Artificial Intelligence and Machine Learning, V3, P1, DOI 10.1007/978-3-031-01548-9
NR 72
TC 64
Z9 64
U1 0
U2 20
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2017
VL 13
IS 3
AR 27
DI 10.1145/3089249
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FD5TE
UT WOS:000407591900005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Schramm, R
   Nunes, HD
   Jung, CR
AF Schramm, Rodrigo
   Nunes, Helena De Souza
   Jung, Claudio Rosito
TI Audiovisual Tool for Solfege Assessment
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Sight-singing; melodic transcription; meter-mimicking; automatic
   assessment; music education; Solfege
ID TIME; TRANSCRIPTION; ESTIMATOR
AB Solfege is a general technique used in the music learning process that involves the vocal performance of melodies, regarding the time and duration of musical sounds as specified in the music score, properly associated with the meter-mimicking performed by hand movement. This article presents an audiovisual approach for automatic assessment of this relevant musical study practice. The proposed system combines the gesture of meter-mimicking (video information) with the melodic transcription (audio information), where hand movement works as a metronome, controlling the time flow (tempo) of the musical piece. Thus, meter-mimicking is used to align the music score (ground truth) with the sung: melody; allowing assessment even in time-dynamic scenarios. Audio analysis is applied to achieve the melodic transcription of the sung notes and the solfege performances are evaluated by a set of Bayesian classifiers that were generated from real evaluations done by experts listeners.
C1 [Schramm, Rodrigo; Jung, Claudio Rosito] Univ Fed Rio Grande, Inst Informat, Av Bento Goncalves,9500 Setor IV, BR-91501970 Porto Alegre, RS, Brazil.
   [Nunes, Helena De Souza] Univ Fed Bahia, Escola Mus, Avenida Araujo Pinho, 58 Canela, Campus Univ, BR-40110060 Salvador, BA, Brazil.
C3 Universidade Federal do Rio Grande; Universidade Federal da Bahia
RP Schramm, R; Jung, CR (corresponding author), Univ Fed Rio Grande, Inst Informat, Av Bento Goncalves,9500 Setor IV, BR-91501970 Porto Alegre, RS, Brazil.; Nunes, HD (corresponding author), Univ Fed Bahia, Escola Mus, Avenida Araujo Pinho, 58 Canela, Campus Univ, BR-40110060 Salvador, BA, Brazil.
EM rschramm@inf.ufrgs.br; helena@caef.ufrgs.br; crjung@inf.ufrgs.br
FU CAPES Foundation, Ministry of Education of Brazil [BEX-2106/13-2]
FX This work was supported by the CAPES Foundation, Ministry of Education
   of Brazil, under Grant BEX-2106/13-2.
CR [Anonymous], 1990, The Analysis and Cognition of Basic Melodic Structures: the Implication-realization Model
   [Anonymous], 2007, INFORM RETRIEVAL MUS
   [Anonymous], 2011, Statistical Pattern Recognition
   Bevilacqua F, 2010, LECT NOTES ARTIF INT, V5934, P73, DOI 10.1007/978-3-642-12553-9_7
   Chang-Hung Lin, 2014, 2014 IEEE International Conference on Orange Technologies (ICOT), P165, DOI 10.1109/ICOT.2014.6956625
   de Cheveigné A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Gómez E, 2013, COMPUT MUSIC J, V37, P73, DOI 10.1162/COMJ_a_00180
   Jaques-Dalcroze E., 2014, Rhythm, music and education
   Keogh Eamonn J., 2001, P 1 INT C DAT MIN SD
   KIM SJ, 1992, ANN STAT, V20, P1534, DOI 10.1214/aos/1176348783
   Klapuri A, 2006, SIGNAL PROCESSING ME
   Koning Maartje, 2015, THESIS
   Maes PJ, 2013, INT J HUM-COMPUT INT, V29, P471, DOI 10.1080/10447318.2012.720197
   Mandanici M., 2012, P 9 SOUND MUS COMP C, P271
   Mauch Matthias, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P659, DOI 10.1109/ICASSP.2014.6853678
   Molina E, 2015, IEEE-ACM T AUDIO SPE, V23, P252, DOI 10.1109/TASLP.2014.2331102
   Molina E, 2013, INT CONF ACOUST SPEE, P744, DOI 10.1109/ICASSP.2013.6637747
   Molina Emilio, 2014, P 15 INT SOC MUS INF, P567
   Muller M., 2015, FUNDAMENTALS MUSIC P
   Rudolf Max., 1980, GRAMMAR CONDUCTING, V2nd
   Ryynanen M., 2004, P ISCA TUT RES WORKS
   Schramm R., 2015, ISMIR, P183
   Schramm R, 2015, IEEE T MULTIMEDIA, V17, P243, DOI 10.1109/TMM.2014.2377553
   Swanwick K., 2002, Musical knowledge: Intuition, analysis and music education
   TATE RF, 1954, ANN MATH STAT, V25, P603, DOI 10.1214/aoms/1177728730
   Toh LW., 2013, 2013 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI DOI 10.1109/ICME.2013.6607481
   Viitaniemi T., 2003, Proceedings of the Finnish Signal Processing Symposium, P59
   Zhang Y, 2008, P AMER CONTR CONF, P2864, DOI 10.1109/ACC.2008.4586928
   Zhukov Katie, 2015, ASSESSMENT MUSIC ED, V16
NR 30
TC 1
Z9 1
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2017
VL 13
IS 1
AR 9
DI 10.1145/3007194
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM7WJ
UT WOS:000395522700009
DA 2024-07-18
ER

PT J
AU Bental, DS
   Papadopoulou, E
   Taylor, NK
   Williams, MH
   Blackmun, FR
   Ibrahim, IS
   Lim, MY
   Mimtsoudis, I
   Whyte, SW
   Jennings, E
AF Bental, Diana S.
   Papadopoulou, Eliza
   Taylor, Nicholas K.
   Williams, M. Howard
   Blackmun, Fraser R.
   Ibrahim, Idris S.
   Lim, Mei Yii
   Mimtsoudis, Ioannis
   Whyte, Stuart W.
   Jennings, Edel
TI Smartening Up the Student Learning Experience with Ubiquitous Media
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Experimentation; Human Factors; Ubiquitous computing; social
   networks; mobile computing
AB This article describes how an experimental platform for social, mobile and ubiquitous computing has been used in a wide-ranging longitudinal "in the wild" case study of the platform with a set of third-party services. The article outlines some of the relevant aspects of the platform, including built-in support for community formation, for context sensitivity, automated learning and adaptation to the user, and for management of privacy and trust relationships. The platform architecture is based on the notion of Cooperating Smart Spaces (CSSs), where a CSS is a partition of the platform corresponding to a single user and distributed over the devices belonging to that user. Three of the case study services were intended for use in a physical environment specifically created to support ubiquitous intelligence; they were highly interactive and used shared screens, voice input and gestural interaction. Another three ubiquitous services were available throughout the university environment as mobile and desktop services. The case study exploited this architecture's ability to integrate multiple novel applications and interface devices and to deliver them flexibly in these different environments. The platform proved to be stable and reliable and the study shows that treating a provider of services and resources (the University) as a CSS is instrumental in enabling the platform to provide this range of services across differing environments.
C1 [Bental, Diana S.; Papadopoulou, Eliza; Taylor, Nicholas K.; Williams, M. Howard; Blackmun, Fraser R.; Ibrahim, Idris S.; Lim, Mei Yii; Mimtsoudis, Ioannis; Whyte, Stuart W.] Heriot Watt Univ, Edinburgh EH14 4AS, Midlothian, Scotland.
   [Jennings, Edel] Waterford Inst Technol, Waterford, Ireland.
C3 Heriot Watt University; South East Technological University (SETU)
RP Bental, DS (corresponding author), Heriot Watt Univ, Edinburgh EH14 4AS, Midlothian, Scotland.
RI Lim, MeiYii/KLY-6304-2024
OI Dillon Jennings, Julie Edel/0000-0002-7473-5531; Taylor,
   Nick/0000-0003-1268-9469
FU European Union under the FP7 programme SOCIETIES project
FX This work was supported by the European Union under the FP7 programme
   SOCIETIES project. The authors also wish to thank all colleagues in the
   SOCIETIES consortium who designed, developed, and deployed the system
   platform and third party services. However, it should be noted that this
   article expresses the authors' personal views, which are not necessarily
   those of the SOCIETIES consortium. Apart from funding the SOCIETIES
   project, the European Commission has no responsibility for the content
   of this article.
CR Abowd GD, 1999, IBM SYST J, V38, P508, DOI 10.1147/sj.384.0508
   [Anonymous], PROC CHI 2012 SER CH, DOI DOI 10.1145/2207676.2208580
   [Anonymous], MOBILE SOCIAL NETWOR
   Barkhuus L, 2011, PERS UBIQUIT COMPUT, V15, P629, DOI 10.1007/s00779-010-0342-4
   Bell G, 2007, PERS UBIQUIT COMPUT, V11, P133, DOI 10.1007/s00779-006-0071-x
   Brown B, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1657
   Dingqi Y., 2014, PERSONAL UBIQUITOUS
   Floch J., 2012, ISCRAM
   Gallacher S., 2011, P 1 WORKSH SOC INT M
   Gallacher S, 2013, ACM T AUTON ADAP SYS, V8, DOI 10.1145/2451248.2451253
   Guo B., 2012, P 9 INT C MOB UB SYS
   Kjeldskov J., 2004, P 6 INT S MOB HUM CO
   Matthews Tara., 2014, Proceedings of the 17th ACM conference on Computer supported cooperative work social computing, P900
   Miluzzo E, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P337
   O'Hara K.P., 2014, Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work Social Computing - CSCW '14, P1131, DOI [10.1145/2531602.2531679, DOI 10.1145/2531602.2531679]
   Papadopoulou E, 2012, PERVASIVE MOB COMPUT, V8, P485, DOI 10.1016/j.pmcj.2011.10.008
   Robinson S, 2012, PERS UBIQUIT COMPUT, V16, P973, DOI 10.1007/s00779-011-0457-2
   Rogers Y, 2007, LECT NOTES COMPUT SC, V4717, P336
   Rogers Y, 2006, LECT NOTES COMPUT SC, V4206, P404
   Roussaki I., 2014, LECT NOTES COMPUTER, V8531, P265
   Roussaki I, 2012, IEEE COMMUN MAG, V50, P74, DOI 10.1109/MCOM.2012.6211489
   Sloetjes H., 2008, P ANN C LANG RES EV
   Taylor N, 2008, SASOW 2008: SECOND IEEE INTERNATIONAL CONFERENCE ON SELF-ADAPTIVE AND SELF-ORGANIZING SYSTEMS WORKSHOPS, PROCEEDINGS, P156, DOI 10.1109/SASOW.2008.23
NR 23
TC 4
Z9 4
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2015
VL 12
IS 1
SU S
SI SI
AR 23
DI 10.1145/2808203
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CU6PH
UT WOS:000363654100013
DA 2024-07-18
ER

PT J
AU Liu, KK
   Li, XL
AF Liu, Kaikai
   Li, Xiaolin
TI Enabling Context-Aware Indoor Augmented Reality via Smartphone Sensing
   and Vision Tracking
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Algorithms; Performance; Augmented reality; attitude;
   displacement; smartphone; INS
AB Augmented reality (AR) aims to render the world that users see and overlay information that reflects the real physical dynamics. The digital view could be potentially projected near the Point-of-Interest (POI) in a way that makes the virtual view attached to the POI even when the camera moves. Achieving smooth support for movements is a subject of extensive studies. One of the key problems is where the augmented information should be added to the field of vision in real time. Existing solutions either leverage GPS location for rendering outdoor AR views (hundreds of kilometers away) or rely on image markers for small-scale presentation (only for the marker region). To realize AR applications under various scales and dynamics, we propose a suite of algorithms for fine-grained AR view tracking to improve the accuracy of attitude and displacement estimation, reduce the drift, eliminate the marker, and lower the computation cost. Instead of requiring extremely high, accurate, absolute locations, we propose multimodal solutions according to mobility levels without additional hardware requirement. Experimental results demonstrate significantly less error in projecting and tracking the AR view. These results are expected to make users excited to explore their surroundings with enriched content.
C1 [Liu, Kaikai; Li, Xiaolin] Univ Florida, Scalable Software Syst Lab, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Li, XL (corresponding author), Univ Florida, Scalable Software Syst Lab, Gainesville, FL 32611 USA.
EM andyli@ece.ufl.edu
OI Li, Xiaolin/0000-0002-3368-159X
FU National Science Foundation [IIP-1506361, CNS-0709329, CNS-0923238,
   CCF-0953371, CCF-1128805, CNS-0940805]
FX The work presented in this article is supported in part by National
   Science Foundation under Grant No. IIP-1506361, CNS-0709329,
   CNS-0923238, CCF-0953371, CCF-1128805, and CNS-0940805 (BBN
   subcontract).
CR [Anonymous], 2011, THESIS
   [Anonymous], 2014, BSD LIC
   Apple, 2014, CMATTITUDE CLASS REF
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   CHANDRAKER MK, 2003, REAL TIME CAMERA POS
   des Bouvrie Bas, 2011, THESIS DELFT U TECHN
   Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hwangbo M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1909, DOI 10.1109/IROS.2009.5354093
   Kato H., 2002, IEICE PRMU, P79
   Kitt B, 2010, IEEE INT VEH SYM, P486, DOI 10.1109/IVS.2010.5548123
   Landis Markley F., 2014, SPACECRAFT ATTITUDE
   Langlotz T, 2011, COMPUT GRAPH-UK, V35, P831, DOI 10.1016/j.cag.2011.04.004
   Lazik Patrick., 2012, Proceedings of the 10th ACM Conference on Embedded Network Sensor Systems, SenSys '12, P99
   Liu HB, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P305
   Liu K., 2013, Proceeding of the 11th annual international conference on Mobile systems, applications, and services, P235
   Manweiler J.G., 2012, MobiSys, P211
   Meier L, 2012, AUTON ROBOT, V33, P21, DOI 10.1007/s10514-012-9281-4
   Mixare, 2011, MIX AUGM REAL ENG
   Mulloni A, 2009, IEEE PERVAS COMPUT, V8, P22, DOI 10.1109/MPRV.2009.30
   Nandakumar R, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P281
   Napier Rob, 2014, IOS 7 PROGRAMMING PU
   Newman J, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P77, DOI 10.1109/ISAR.2001.970517
   Pensyl William Russell, 2008, P 7 ACM SIGGRAPH INT, P9
   Qualcomm, 2015, VUF
   Rajmic P, 2005, LECT NOTES ARTIF INT, V3817, P368
   Ribo M, 2004, J ROBOTIC SYST, V21, P53, DOI 10.1002/rob.10124
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shen G., 2013, P 10 USENIX C NETW S, P85
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Wang He, 2012, P 10 INT C MOB SYST, P197, DOI DOI 10.1145/2307636.2307655
   White Zac, 2012, IPHONE AR TOOLKIT
   Yadlin Roni, 2009, ATTITUDE DETERMINATI
   Yang Z, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P269
   Zhou Pengfei, 2014, P ACM MOBICOM 2014
NR 36
TC 17
Z9 21
U1 0
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2015
VL 12
IS 1
SU S
SI SI
AR 15
DI 10.1145/2808208
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CU6PH
UT WOS:000363654100005
DA 2024-07-18
ER

PT J
AU Lee, SK
   Yoo, S
   Jung, J
   Kim, H
   Ryoo, J
AF Lee, Suk Kyu
   Yoo, Seungho
   Jung, Jongtack
   Kim, Hwangnam
   Ryoo, Jihoon
TI Link-Aware Reconfigurable Point-to-Point Video Streaming for Mobile
   Devices
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Experimentation; Measurement; Performance; Link-state feedback; mobile
   multimedia system; reconfigurable video coding
ID QUALITY ASSESSMENT; COMPRESSION; NETWORKS; INTERNET; STANDARD
AB Even though people of all social standings use current mobile devices in the wide spectrum of purpose from entertainment tools to communication means, some issues with real-time video streaming in hostile wireless environment still exist. In this article, we introduce CoSA, a link-aware real-time video streaming system for mobile devices. The proposed system utilizes a 3D camera to distinguish the region of importance (ROI) and non-ROI region within the video frame. Based on the link-state feedback from the receiver, the proposed system allocates a higher bandwidth for the region that is classified as ROI and a lower bandwidth for non-ROI in the video stream by reducing the video's bit rate. We implemented CoSA in a real test-bed where the IEEE 802.11 is employed as a medium for wireless networking. Furthermore, we verified the effectiveness of the proposed system by conducting a thorough empirical study. The results indicate that the proposed system enables real-time video streaming while maintaining a consistent visual quality by dynamically reconfiguring video coding parameters according to the link quality.
C1 [Lee, Suk Kyu; Yoo, Seungho; Jung, Jongtack; Kim, Hwangnam] Korea Univ, Sch Elect Engn, Seoul 136713, South Korea.
   [Ryoo, Jihoon] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 Korea University; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook
RP Kim, H (corresponding author), Korea Univ, Sch Elect Engn, Seoul 136713, South Korea.
EM sklee25@korea.ac.kr; pen0423@korea.ac.kr; skylover89@korea.ac.kr;
   hnkim@korea.ac.kr; jiryoo@cs.stonybrook.edu
RI Ryoo, Jihoon/KDO-9649-2024; Yoo, Seungho/JCN-7474-2023
OI Yoo, Seungho/0000-0002-0510-535X
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2013R1A1A2010388]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2013R1A1A2010388).
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Akkus IE, 2011, J NETW COMPUT APPL, V34, P137, DOI 10.1016/j.jnca.2010.08.006
   [Anonymous], P 8 ACM SIGCOMM HOTN
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], P 12 IEEE INT C MULT
   [Anonymous], 2002, 3261 RFC INT ENG TAS
   [Anonymous], 1994, Mathematica Journal, DOI DOI 10.1016/0165-1684(90
   Bellavista P., 2011, IEEE Transactions on Network and Service Management, V8, P190, DOI 10.1109/TCOMM.2011.072611.100066
   Bellavista P., 2009, IEEE Transactions on Network and Service Management, V6, P80, DOI 10.1109/TNSM.2009.090602
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   EBU, 2010, 3299 EBU EBUTECH
   Hajiesmaili MH, 2012, J NETW COMPUT APPL, V35, P2016, DOI 10.1016/j.jnca.2012.07.024
   Haleem MA, 2005, IEEE J SEL AREA COMM, V23, P1287, DOI 10.1109/JSAC.2005.845636
   Hsu CH, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1870121.1870126
   Hu CL, 2011, J NETW COMPUT APPL, V34, P121, DOI 10.1016/j.jnca.2010.08.010
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Hyun Soon Kim, 2012, 2012 The First IEEE Workshop on Enabling Technologies for Smartphone and Internet of Things (ETSIoT2012), P13, DOI 10.1109/ETSIoT.2012.6311259
   Ji W, 2011, J NETW COMPUT APPL, V34, P1489, DOI 10.1016/j.jnca.2010.06.011
   Kalva H, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P158, DOI 10.1109/ICCE.2012.6161787
   Kim H, 2007, COMPUT NETW, V51, P1922, DOI 10.1016/j.comnet.2006.07.017
   Kouadio M, 2002, J NETW COMPUT APPL, V25, P37, DOI 10.1006/jnca.2002.0125
   Lee SK, 2013, IEEE CONF WIREL MOB, P681, DOI 10.1109/WiMOB.2013.6673430
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   Li Y, 2008, IEEE T MULTIMEDIA, V10, P885, DOI 10.1109/TMM.2008.922860
   LIEBL G, 2005, P IEEE INT C MULT EX
   Manjunath B.S., 2002, Introduction to MPEG-7: multimedia content description interface, V1
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Ni P., 2011, P 19 ACM INT C MULT, P463, DOI DOI 10.1145/2072298.2072359
   Novotny Vit, 2008, Journal of Networks, V3, P1, DOI 10.4304/jnw.3.3.1-10
   Özcelebi T, 2007, IEEE J SEL AREA COMM, V25, P760, DOI 10.1109/JSAC.2007.070512
   Patras P, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2240136.2240142
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Richardson Iain E, 2004, H. 264 and MPEG-4 Video Compression: Video Coding for Next-Generation Multimedia
   Riiser H, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2240136.2240137
   Rosenberg J, 1998, IEEE INFOCOM SER, P233, DOI 10.1109/INFCOM.1998.659659
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Setton E, 2005, IEEE WIREL COMMUN, V12, P59, DOI 10.1109/MWC.2005.1497859
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Sudhakar R., 2005, ICGSTGVIP J, V5, P25
   Tan WT, 1999, IEEE T MULTIMEDIA, V1, P172, DOI 10.1109/6046.766738
   Tavakoli Samira, 2014, P SOC PHOTO-OPT INS, V9016
   Thom GA, 1996, IEEE COMMUN MAG, V34, P52, DOI 10.1109/35.556487
   WANG Yubing., 2006, SURVEY OBJECTIVE VID
   Woo S., 2013, IEEE ACM T NETWORKIN, V21
   Zhang WW, 2013, IEEE T MULTIMEDIA, V15, P1431, DOI 10.1109/TMM.2013.2247583
   Zhao Li, 2001, LECT NOTES COMPUTER, V2216, P210
   Zhou L, 2010, IEEE J SEL AREA COMM, V28, P409, DOI 10.1109/JSAC.2010.100412
NR 49
TC 5
Z9 5
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2015
VL 12
IS 1
AR 9
DI 10.1145/2771438
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CP9LG
UT WOS:000360215200009
DA 2024-07-18
ER

PT J
AU Natarajan, P
   Atrey, PK
   Kankanhalli, M
AF Natarajan, Prabhu
   Atrey, Pradeep K.
   Kankanhalli, Mohan
TI Multi-Camera Coordination and Control in Surveillance Systems: A Survey
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Security; Algorithms; Human Factors; Multi-camera surveillance system;
   active camera coordination and control; PTZ camera network;
   cyber-physical system
ID VIDEO SURVEILLANCE; TRACKING; SELECTION; NETWORK; PAN
AB The use of multiple heterogeneous cameras is becoming more common in today's surveillance systems. In order to perform surveillance tasks, effective coordination and control in multi-camera systems is very important, and is catching significant research attention these days. This survey aims to provide researchers with a state-of-the-art overview of various techniques for multi-camera coordination and control (MC3) that have been adopted in surveillance systems. The existing literature on MC3 is presented through several classifications based on the applicable architectures, frameworks and the associated surveillance tasks. Finally, a discussion on the open problems in surveillance area that can be solved effectively using MC3 and the future directions in MC3 research is presented.
C1 [Natarajan, Prabhu] Natl Univ Singapore, SeSaMe Ctr, Interact Digital Media Inst, Singapore 117548, Singapore.
   [Atrey, Pradeep K.] SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA.
   [Kankanhalli, Mohan] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
C3 National University of Singapore; State University of New York (SUNY)
   System; State University of New York (SUNY) Albany; National University
   of Singapore
RP Natarajan, P (corresponding author), Natl Univ Singapore, SeSaMe Ctr, Interact Digital Media Inst, Singapore 117548, Singapore.
EM prabhu@nus.edu.sg; patrey@albany.edu; mohan@comp.nus.edu.sg
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
FU Singapore National Research Foundation under its Int. Research Centre @
   Singapore Funding Initiative
FX This research was carried out at the NUS-ZJU Sensor-Enhanced Social
   Media (SeSaMe) Centre. It is supported by the Singapore National
   Research Foundation under its Int. Research Centre @ Singapore Funding
   Initiative and administered by the Interactive Digital Media Programme
   Office.
CR Abidi BR, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456657
   Aghajan H, 2009, MULTI-CAMERA NETWORKS: PRINCIPLES AND APPLICATIONS, P1
   AHMEDALI T, 2006, P IEEE CAN C COMP RO, P39
   [Anonymous], 2008, P ECCV WORKSH MULT M
   [Anonymous], PROC 2 ACMIEEE INT C, DOI DOI 10.1109/ICDSC.2008.4635696
   [Anonymous], 1999, P INT C WAV AN PATT
   [Anonymous], 2008, P 2008 2 ACM IEEE IN
   [Anonymous], 2005, INT J COMPUT SCI APP
   [Anonymous], 2012, P 11 INT C AUT AG MU
   [Anonymous], 2010, P 4 ACM IEEE INT C D
   [Anonymous], 2012, Synth. Lectures Comput. Vis.
   [Anonymous], 2011, P 5 ACM IEEE INT C D
   [Anonymous], 2011, VISUAL ANAL HUMANS
   [Anonymous], 2002, P 10 ACM INT C MULTI
   [Anonymous], 2004, P ACM 2 INT WORKSHOP
   Arsic D, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P515
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Barake Bassem, 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P373, DOI 10.1109/ISSPA.2010.5605522
   Bhuyan M. K., 2007, P 9 BIENN C AUSTR PA, P592
   BIXIO L, 2009, P 6 IEEE INT C ADV V, P232
   Bove VM, 2004, BT TECHNOL J, V22, P45, DOI 10.1023/B:BTTJ.0000047582.30576.7e
   Bramberger M, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P474
   Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119
   CASTANEDO F, 2006, VSSN 06, P131, DOI DOI 10.1145/1178782.1178802
   Chang CH, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P1, DOI 10.1109/IMIS.2013.10
   Chang TH, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P19, DOI 10.1109/MOT.2001.937977
   Chen CM, 2012, J ELECTRON MATER, V41, P1, DOI 10.1007/s11664-011-1777-8
   Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341
   Costello CJ, 2005, IEEE DECIS CONTR P, P1485
   Daniyal F., 2011, 2011 Conference for Visual Media Production, P11, DOI 10.1109/CVMP.2011.8
   Daniyal F, 2010, MULTIMED TOOLS APPL, V46, P235, DOI 10.1007/s11042-009-0355-z
   Desurmont X., 2007, ELECT IMAGING
   Devarajan D., 2004, P BASENETS WORKSH CO, P25
   Dieber B., 2012, International Conference on Distributed Smart Cameras, P1
   Dieber B, 2011, IEEE T CIRC SYST VID, V21, P1424, DOI 10.1109/TCSVT.2011.2162770
   Ding C, 2012, IEEE T IMAGE PROCESS, V21, P3282, DOI 10.1109/TIP.2012.2188806
   Ding Chong., 2012, Distributed Smart Cameras (ICDSC), 2012 Sixth International Conference on, P1
   Dockstader SL, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P95, DOI 10.1109/MOT.2001.937987
   Esterle L, 2014, ACM T SENSOR NETWORK, V10, DOI 10.1145/2530001
   Fardi B, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P18
   Fiore L, 2008, J INTELL ROBOT SYST, V52, P5, DOI 10.1007/s10846-007-9201-6
   Fleck S., 2006, PROC C COMPUTER VISI, P118, DOI DOI 10.1109/CVPRW.2006.6
   Fukuda T, 2000, IEEE IND ELEC, P1249, DOI 10.1109/IECON.2000.972301
   Gualdi G., 2008, P 1 ACM WORKSH VIS N, P101
   GULER S, 2003, P 32 APPL IM PATT RE, P275
   Hayet JB, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P493
   Hengqing Tong, 2007, 2007 International Conference on Convergence Information Technology - ICCIT '07, P1726, DOI 10.1109/ICCIT.2007.183
   Hodge L, 2003, IEEE T SYST MAN CY A, V33, P648, DOI 10.1109/TSMCA.2003.817397
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Ilie A., 2011, P 5 ACM IEEE INT C D, P1
   Javed O, 2008, AUTOMATED MULTICAMER
   Jones PB, 2006, IEEE DECIS CONTR P, P2743
   Kerhet A, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P87, DOI 10.1109/AVSS.2007.4425291
   Khanzadi M.R., 2012, P IEEE INT C POW EL, P1, DOI [DOI 10.1109/FCS.2012.6243677, DOI 10.1109/PEDES.2012.648447.8]
   Khoshabeh Ramsin, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P259, DOI 10.1109/ITSC.2007.4357750
   Kim IS, 2010, INT J CONTROL AUTOM, V8, P926, DOI 10.1007/s12555-010-0501-4
   Kim N, 2006, IEEE IMAGE PROC, P1761, DOI 10.1109/ICIP.2006.312723
   Ko TH, 2005, TAPIA '05: 2005 RICHARD TAPIA CELEBRATION OF DIVERSITY IN COMPUTING CONFERENCE, P40
   Konda K. R., 2013, 2013 7 INT C DISTR S, P1
   Krumm J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P3, DOI 10.1109/VS.2000.856852
   Kulkarni P., 2005, 13th Annual ACM International Conference on Multimedia, P229, DOI 10.1145/1101149.1101191
   Kurillo G., 2009, P IMMERSCON 2009, P1
   Lai YC, 2010, IEEE IMAGE PROC, P4317, DOI 10.1109/ICIP.2010.5652444
   Lee Huang., 2006, ACM INT WORKSHOP VID, P9
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   Lewis PR, 2013, INT CONF SELF SELF, P209, DOI 10.1109/SASO.2013.20
   Li L., 2009, PROCEEDING 17 IEEEAC, P1, DOI DOI 10.1109/BMEI.2009.5305169
   Li YM, 2012, INT C PATT RECOG, P2698
   Li YM, 2011, IEEE SENS J, V11, P676, DOI 10.1109/JSEN.2010.2051148
   Bustamante AL, 2014, INT J SYST SCI, V45, P741, DOI 10.1080/00207721.2013.795632
   Mantzel W. E., 2004, Conference Record of the Thirty-Eighth Asilomar Conference on Signals, Systems and Computers (IEEE Cat. No.04CH37592), P1381
   Matsuyama T, 2002, P IEEE, V90, P1136, DOI 10.1109/JPROC.2002.801442
   Micheloni C, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P480
   Micheloni C, 2010, IEEE SIGNAL PROC MAG, V27, P78, DOI 10.1109/MSP.2010.937333
   Mittal A, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P3, DOI 10.1109/MOT.2001.937975
   Monari Eduardo, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P339, DOI 10.1109/AVSS.2008.21
   Morioka K, 2008, EUROGR TECH REP SER, P773, DOI 10.1109/HSI.2008.4581538
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Morye AA, 2013, P AMER CONTR CONF, P6294
   NANDHAKUMAR N, 1988, IEEE T PATTERN ANAL, V10, P469, DOI 10.1109/34.3911
   NANDHAKUMAR N, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P446, DOI 10.1109/ICPR.1992.201814
   Natarajan P., 2014, P 8 ACM IEEE INT C D, P1
   Natarajan P., 2012, P 6 ACM IEEE INT C D
   Natarajan P, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1521
   Natarajan P, 2014, FRONT ARTIF INTEL AP, V263, P1155, DOI 10.3233/978-1-61499-419-0-1155
   Ngoc HBB, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P230
   Nguyen N. T., 2003, Acta Automatica Sinica, V29, P408
   NORTH DW, 1968, IEEE T SYST SCI CYB, VSSC4, P200, DOI 10.1109/TSSC.1968.300114
   Paek I, 2007, INT C WAVEL ANAL PAT, P12
   Parupati S., 2011, 2011 5 ACM INT C, P1
   Pasqualetti F, 2014, IEEE T CONTR SYST T, V22, P1669, DOI 10.1109/TCST.2013.2290708
   Petrushin VA, 2006, KNOWL INF SYST, V10, P229, DOI 10.1007/s10115-006-0025-7
   Pflugfelder R, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P393, DOI 10.1109/AVSS.2007.4425343
   Piciarelli C, 2009, 2009 THIRD ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P108
   Pletzer Felix, 2010, 2010 Fourth IEEE International Conference on Self-Adaptive and Self-Organizing Systems Workshop (SASOW), P59, DOI 10.1109/SASOW.2010.41
   Possegger H., 2012, P 17 COMP VIS WINT W
   Prati A., 2005, P 3 ACM INT WORKSHOP, P95, DOI [10.1145/1099396.1099415, DOI 10.1145/1099396.1099415]
   Qureshi F., 2005, P 3 ACM WORKSH VID S, P131
   Qureshi F.Z., 2009, ACM/IEEE International Conference on Distributed Smart Cameras, P1
   Qureshi F, 2008, P IEEE, V96, P1640, DOI 10.1109/JPROC.2008.928932
   Qureshi FaisalZ., 2010, Proceedings of the Fourth ACM/IEEE International Conference on Distributed Smart Cameras - ICDSC '10, P190, DOI DOI 10.1145/1865987.1866017
   Raimondo DM, 2011, IEEE DECIS CONTR P, P2064, DOI 10.1109/CDC.2011.6161534
   Reddy K. K., 2014, P 8 INT C DISTR SMAR, P175
   Rinner B, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P1, DOI 10.1109/ICDSC.2008.4635674
   Saini M, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P262, DOI 10.1109/AVSS.2009.51
   SanMiguel JC, 2014, COMPUTER, V47, P67, DOI 10.1109/MC.2014.133
   Santos TT, 2008, SIBGRAPI, P53, DOI 10.1109/SIBGRAPI.2008.25
   Schreiber D, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P432, DOI 10.1109/AVSS.2013.6636678
   Seema A, 2011, IEEE COMMUN SURV TUT, V13, P462, DOI 10.1109/SURV.2011.102910.00098
   Shen  R., 2008, P 8 WORKSH OMN VIS C
   Singh VK, 2008, MACH VISION APPL, V19, P375, DOI 10.1007/s00138-007-0082-2
   Snidaro L, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P364, DOI 10.1109/AVSS.2003.1217944
   Snidaro L, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P364, DOI 10.1109/AVSS.2009.67
   Sommerlade E, 2010, IEEE INT CONF ROBOT, P440, DOI 10.1109/ROBOT.2010.5509736
   Song B, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940441
   Song B, 2008, IEEE J-STSP, V2, P582, DOI 10.1109/JSTSP.2008.925992
   Song B, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P548
   Song M., 2013, ARXIV130204462013
   Soro S, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P81, DOI 10.1109/AVSS.2007.4425290
   Soto C, 2009, PROC CVPR IEEE, P1486, DOI 10.1109/CVPRW.2009.5206773
   Spaan M. T. J., 2009, P NIPS WORKSH AD SEN
   Starzyk W., 2012, 2012 Canadian Conference on Computer and Robot Vision, P306, DOI 10.1109/CRV.2012.47
   Starzyk W., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P154, DOI 10.1109/AVSS.2011.6027311
   Starzyk W., 2011, ACM/IEEE International Conference on Distributed Smart Cameras, P1
   Starzyk W., 2012, P 9 C COMP ROB VIS
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   Taylor G.R., 2007, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit
   Tu P, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P57, DOI 10.1109/AVSS.2007.4425286
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang Jun., 2003, First ACM SIGMM international workshop on Video surveillance, P77
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang Y., 2011, P PAC RIM C MULT
   Wang Y, 2011, INT CONF ACOUST SPEE, P1, DOI 10.1109/PLASMA.2011.5993071
   Winkler T, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2545883
   Wu Chun, 2010, Proceedings 2010 International Conference on Challenges in Environmental Science and Computer Engineering (CESCE 2010), P142, DOI 10.1109/CESCE.2010.72
   Yamazoe H., 2002, P 5 AS C COMP VIS, P23
   Yan Lu, 2008, 2008 Canadian Conference on Electrical and Computer Engineering - CCECE, P001365, DOI 10.1109/CCECE.2008.4564764
   Yuan XJ, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P199, DOI 10.1109/AVSS.2003.1217922
   Zongjie Tu, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P474, DOI 10.1109/AVSS.2011.6027379
NR 140
TC 53
Z9 57
U1 1
U2 29
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2015
VL 11
IS 4
AR 57
DI 10.1145/2710128
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CK0ZF
UT WOS:000355933700010
DA 2024-07-18
ER

PT J
AU Chen, K
   Zhou, Z
   Wu, W
AF Chen, Ke
   Zhou, Zhong
   Wu, Wei
TI Progressive Motion Vector Clustering for Motion Estimation and Auxiliary
   Tracking
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Progressive clustering; block matching; motion estimation;
   auxiliary tracking
ID SEARCH ALGORITHM; OBJECT TRACKING; COLOR
AB The motion vector similarity between neighboring blocks is widely used in motion estimation algorithms. However, for nonneighboring blocks, they may also have similar motions due to close depths or belonging to the same object inside the scene. Therefore, the motion vectors usually have several kinds of patterns, which reveal a clustering structure. In this article, we propose a progressive clustering algorithm, which periodically counts the motion vectors of the past blocks to make incremental clustering statistics. These statistics are used as the motion vector predictors for the following blocks. It is proved to be much more efficient for one block to find the best-matching candidate with the predictors. We also design the clustering based search with CUDA for GPU acceleration. Another interesting application of the clustering statistics is persistent static object tracking. Based on the statistics, several auxiliary tracking areas are created to guide the object tracking. Even when the target object has significant changes in appearance or it disappears occasionally, its position still can be predicted. The experiments on Xiph.org Video Test Media dataset illustrate that our clustering based search algorithm outperforms the mainstream and some state-of-the-art motion estimation algorithms. It is 33 times faster on average than the full search algorithm with only slightly higher mean-square error values in the experiments. The tracking results show that the auxiliary tracking areas help to locate the target object effectively.
C1 [Chen, Ke; Zhou, Zhong; Wu, Wei] Beihang Univ, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhou, Z (corresponding author), 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM zz@buaa.edu.cn
FU National 863 Programs of China [2012AA011801, 2012AA011803]; National
   Natural Science Foundation of China [61170188]
FX This work is supported by the National 863 Programs of China under Grant
   No. 2012AA011801 and No. 2012AA011803 and the National Natural Science
   Foundation of China under Grant No. 61170188.
CR [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Chen Z, 2002, JVTF017, P5
   Comaniciu D, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P70, DOI 10.1109/ICIP.2000.899297
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Cucchiara R, 2003, PROC CVPR IEEE, P405
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Du W, 2008, LECT NOTES COMPUT SC, V5303, P225, DOI 10.1007/978-3-540-88688-4_17
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Gelgon M, 2000, PATTERN RECOGN, V33, P725, DOI 10.1016/S0031-3203(99)00083-7
   Hennebert C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P218, DOI 10.1109/ICPR.1996.546022
   Huang YW, 2003, IEEE T CIRC SYST VID, V13, P111, DOI 10.1109/TCSVT.2002.808093
   Ke Chen, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P622, DOI 10.1109/ICME.2012.88
   Koga T., 1981, P NAT TEL C IEEE
   Krause E.F., 1987, Taxicab Geometry: Na adventure in Non-Euclidean Geometry
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Porto M, 2013, MULTIMED TOOLS APPL, V63, P107, DOI 10.1007/s11042-012-1033-0
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shi ZR, 2011, IEEE T CONSUM ELECTR, V57, P1354, DOI 10.1109/TCE.2011.6018894
   Shi ZR, 2010, IEEE INT CON MULTI, P667, DOI 10.1109/ICME.2010.5582997
   Subakan Ö, 2007, IEEE I CONF COMP VIS, P708
   Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885
   Wu YW, 2012, SCI CHINA INFORM SCI, V55, P2635, DOI 10.1007/s11432-012-4701-9
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin Zhaozheng., 2008, Proceedings of Computer Vision and Pattern Recognition, P1
   Yuan Zhou, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P359, DOI 10.1007/978-3-642-34778-8_33
   Zhu C, 2001, INT CONF ACOUST SPEE, P1593, DOI 10.1109/ICASSP.2001.941239
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 34
TC 7
Z9 7
U1 0
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2015
VL 11
IS 3
AR 33
DI 10.1145/2700296
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CB8BF
UT WOS:000349852500001
OA Bronze
DA 2024-07-18
ER

PT J
AU Yin, YF
   Seo, B
   Zimmermann, R
AF Yin, Yifang
   Seo, Beomjoo
   Zimmermann, Roger
TI Content vs. Context: Visual and Geographic Information Use in Video
   Landmark Retrieval
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Experimentation; Content-based analysis; geo-referenced videos; landmark
   retrieval
AB Due to the ubiquity of sensor-equipped smartphones, it has become increasingly feasible for users to capture videos together with associated geographic metadata, for example the location and the orientation of the camera. Such contextual information creates new opportunities for the organization and retrieval of geo-referenced videos. In this study we explore the task of landmark retrieval through the analysis of two types of state-of-the-art techniques, namely media-content-based and geocontext-based retrievals. For the content-based method, we choose the Spatial Pyramid Matching (SPM) approach combined with two advanced coding methods: Sparse Coding (SC) and Locality-Constrained Linear Coding (LLC). For the geo-based method, we present the Geo Landmark Visibility Determination (GeoLVD) approach which computes the visibility of a landmark based on intersections of a camera's field-of-view (FOV) and the landmark's geometric information available from Geographic Information Systems (GIS) and services. We first compare the retrieval results of the two methods, and discuss the strengths and weaknesses of each approach in terms of precision, recall and execution time. Next we analyze the factors that affect the effectiveness for the content-based and the geo-based methods, respectively. Finally we propose a hybrid retrieval method based on the integration of the visual (content) and geographic (context) information, which is shown to achieve significant improvements in our experiments. We believe that the results and observations in this work will enlighten the design of future geo-referenced video retrieval systems, improve our understanding of selecting the most appropriate visual features for indexing and searching, and help in selecting between the most suitable methods for retrieval based on different conditions.
C1 [Yin, Yifang; Zimmermann, Roger] NUS, Sch Comp, Singapore 117417, Singapore.
   [Seo, Beomjoo] Hongik Univ, Seoul, South Korea.
C3 National University of Singapore; Hongik University
RP Yin, YF (corresponding author), NUS, Sch Comp, 13 Comp Dr, Singapore 117417, Singapore.
EM yifang@comp.nus.edu.sg; bseo@hongik.ac.kr; rogerz@comp.nus.edu.sg
RI Zimmermann, Roger/D-7944-2015
OI Zimmermann, Roger/0000-0002-7410-2590; yin, yifang/0000-0002-6525-6133
FU Singapore National Research Foundation under its International Research
   Centre @ Singapore Funding Initiative; Hongik University new faculty
   research support fund
FX This research has been supported by the Singapore National Research
   Foundation under its International Research Centre @ Singapore Funding
   Initiative and administered by the IDM Programme Office through the
   Centre of Social Media Innovations for Communities (COSMIC). This work
   was also supported by the Hongik University new faculty research support
   fund.
CR Amato G, 2012, COMM COM INF SC, V247, P1
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], P 2011 ACM WORKSH SO
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Avrithis Yannis, 2010, P 18 ACM INT C MULTI, P153, DOI 10.1145/1873951.1873973Place
   Ay S., 2008, Proceedings of the 16th ACM international conference on Multimedia (MM '08), P309
   Ay SA, 2010, MULTIMEDIA SYST, V16, P105, DOI 10.1007/s00530-009-0177-x
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Chen T, 2011, IEEE T CIRC SYST VID, V21, P1476, DOI 10.1109/TCSVT.2011.2161413
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Feng Shaolei., 2008, CIVR, P427
   Gavves E, 2012, COMPUT VIS IMAGE UND, V116, P238, DOI 10.1016/j.cviu.2011.10.004
   Hao Q, 2012, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2012.6248104
   Hecht Eugene., 2001, OPTICS, V1
   Hoàng NV, 2010, PATTERN RECOGN, V43, P3013, DOI 10.1016/j.patcog.2010.03.024
   Huang Z, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852108
   Jain R., 2010, INT C MULTIMEDIA, P1259, DOI DOI 10.1145/1873951.1874199
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kim Y., 2012, P ACM INT C KNOWL DI, P1540
   Kuo YH, 2012, IEEE T MULTIMEDIA, V14, P1079, DOI 10.1109/TMM.2012.2190386
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li Z, 2012, IEEE SIGNAL PROC LET, V19, P459, DOI 10.1109/LSP.2012.2203120
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Penatti O.A. B., 2012, Proceedings of the 2nd ACM International Conference on Multimedia Retrieval, P1
   Penatti OAB, 2014, PATTERN RECOGN, V47, P705, DOI 10.1016/j.patcog.2013.08.012
   Rae Adam, 2011, WORKING NOTES PLACIN
   Shen Z., 2011, MM, P93
   Simon R., 2007, 16th International World Wide Web Conference, WWW2007, P381, DOI DOI 10.1145/1242572.1242624
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Souvannavong Fabrice, 2005, P INT WORKSH CONT BA, P21
   Tian X., 2008, ACM INT C MULTIMEDIA, P131, DOI DOI 10.1145/1459359.1459378.ISBN
   Viitaniemi V, 2008, LECT NOTES COMPUT SC, V5188, P126, DOI 10.1007/978-3-540-85891-1_16
   Xiaotao Liu, 2005, 13th Annual ACM International Conference on Multimedia, P618
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yap KH, 2010, IEEE INTELL SYST, V25, P48, DOI 10.1109/MIS.2010.12
   Zhang B., 2010, P 18 SIGSPATIAL INT, P260
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 39
TC 14
Z9 14
U1 0
U2 15
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2015
VL 11
IS 3
AR 39
DI 10.1145/2700287
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CB8BF
UT WOS:000349852500007
DA 2024-07-18
ER

PT J
AU Lee, YL
   Tsai, WH
AF Lee, Ya-Lin
   Tsai, Wen-Hsiang
TI A New Data Hiding Method via Revision History Records on Collaborative
   Writing Platforms
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Security; Algorithms; Data hiding; Wikipedia mining; collaborative
   writing; revision history; Huffman coding
ID DOCUMENTS
AB A new data hiding method via collaboratively-written articles with forged revision history records on collaborative writing platforms is proposed. The hidden message is camouflaged as a stego-document consisting of a stego-article and a revision history created through a simulated process of collaborative writing. The revisions are forged using a database constructed by mining word sequences used in real cases from an English Wikipedia XML dump. Four characteristics of article revisions are identified and utilized to embed secret messages, including the author of each revision, the number of corrected word sequences, the content of the corrected word sequences, and the word sequences replacing the corrected ones. Related problems arising in utilizing these characteristics for data hiding are identified and solved skillfully, resulting in an effective multiway method for hiding secret messages into the revision history. To create more realistic revisions, Huffman coding based on the word sequence frequencies collected from Wikipedia is applied to encode the word sequences. Good experimental results show the feasibility of the proposed method.
C1 [Lee, Ya-Lin] Natl Chiao Tung Univ, Inst Comp Sci & Engn, Hsinchu 30010, Taiwan.
   [Tsai, Wen-Hsiang] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
   [Tsai, Wen-Hsiang] Asia Univ, Taichung, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University; Asia University Taiwan
RP Lee, YL (corresponding author), Natl Chiao Tung Univ, Inst Comp Sci & Engn, Hsinchu 30010, Taiwan.
EM yllee.cs98g@g2.nctu.edu.tw; whtsai@cis.nctu.edu.tw
FU NSC, Taiwan [101-3113-P-009-006]; Ministry of Education, Taiwan
FX This research was supported in part by the NSC, Taiwan under Grant No.
   101-3113-P-009-006 and in part by the Ministry of Education, Taiwan
   under the 5-year Project II of "Aiming for the Top University" from 2011
   through 2015.
CR Alattar AM, 2004, P SOC PHOTO-OPT INS, V5306, P685, DOI 10.1117/12.527147
   [Anonymous], 2004, P ACM C HUMAN FACTOR, DOI [DOI 10.1145/985692.985765, 10.1145/985692.985765]
   [Anonymous], P NATL ACAD SCI
   [Anonymous], 1883, J SCI MILITAIRES
   [Anonymous], 2014, ACM T MULTIMEDIA COM, V10
   Bennett Krista, 2004, Linguistic steganography: survey, analysis, and robustness concerns for hiding information in text
   Bergroth L, 2000, SPIRE 2000: SEVENTH INTERNATIONAL SYMPOSIUM ON STRING PROCESSING AND INFORMATION RETRIEVAL - PROCEEDINGS, P39, DOI 10.1109/SPIRE.2000.878178
   Biryukov A, 2009, LECT NOTES COMPUT SC, V5912, P1, DOI 10.1007/978-3-642-10366-7_1
   Bogdanov A, 2011, LECT NOTES COMPUT SC, V7073, P344, DOI 10.1007/978-3-642-25385-0_19
   Bolshakov IA, 2004, LECT NOTES COMPUT SC, V3200, P180
   Bronner Amit, 2012, P 13 C EUR CHAPT ASS, P356
   Chapman Mark, 2001, LECT NOTES COMPUTER, P156, DOI DOI 10.1007/3-540-45439-X
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   Dutrey C., 2010, PROCESAMIENTO LENGUA, V46, P51
   Erdmann M., 2009, ACM T MULTIM COMPUT, V5
   Kim YW, 2003, PROC INT CONF DOC, P775
   Lee IS, 2010, SIGNAL PROCESS, V90, P557, DOI 10.1016/j.sigpro.2009.07.022
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Lin P. Y., 2011, ACM T MULTIM COMPUT, V7
   Liu TY, 2007, IEEE T INF FOREN SEC, V2, P24, DOI 10.1109/TIFS.2006.890310
   Madnani N, 2010, COMPUT LINGUIST, V36, P341, DOI 10.1162/coli_a_00002
   Max A, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3143
   Mohanty S. P., 2008, ACM T MULTIM COMPUT, V5
   Nelken Rani., 2008, Proceedings of the AAAI Workshop on Wikipedia and Artificial Intelligence: An Evolving Synergy, P31
   Shirali-Shahreza MH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1524, DOI 10.1109/IIH-MSP.2008.6
   Stutsman R., 2006, P 2006 ACM S APPL CO, P338
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Wayner P., 1992, Cryptologia, V16, P193, DOI 10.1080/0161-119291866883
   Wayner Peter., 2002, DISAPPEARING CRYPTOG
NR 30
TC 3
Z9 3
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2014
VL 10
IS 2
AR 20
DI 10.1145/2534408
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB6DY
UT WOS:000331879000005
DA 2024-07-18
ER

PT J
AU Shenoy, P
AF Shenoy, Prashant
TI Multimedia Systems Research: The First Twenty Years and Lessons for the
   Next Twenty
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Performance; Multimedia systems
AB This retrospective article examines the past two decades of multimedia systems research through the lens of three research topics that were in vogue in the early days of the field and offers perspectives on the evolution of these research topics. We discuss the eventual impact of each line of research and offer lessons for future research in the field.
C1 Univ Massachusetts, Sch Comp Sci, Amherst, MA 01003 USA.
C3 University of Massachusetts System; University of Massachusetts Amherst
RP Shenoy, P (corresponding author), Univ Massachusetts, Sch Comp Sci, 140 Governors Dr, Amherst, MA 01003 USA.
EM shenoy@cs.umass.edu
OI Shenoy, Prashant/0000-0002-5435-1901
CR AMIR E, 1995, PROCEEDINGS OF THE A
   BOLSOKY W, 1996, PROCEEDINGS OF THE 6, P97
   Bruno J, 1998, PROCEEDINGS OF THE USENIX 1998 ANNUAL TECHNICAL CONFERENCE, P235
   Gong F.-M., 1994, Journal of High Speed Networks, V3, P261
   Goyal P., 1996, Computer Communication Review, V26, P157, DOI 10.1145/248157.248171
   JEFFAY K, 1992, COMPUT COMMUN, V15, P388, DOI 10.1016/0140-3664(92)90014-6
   KESHAV S, 1995, J ITNERNETWORKING RE, V2, P157
   LIN C., 1998, PROCEEDINGS OF THE 2
   MARTIN C, 1996, MULTIMEDIA INFORMATI
   MAYERPATEL K, 1997, P MULT COMP NETW, P194
   PADHYE J., 1999, PROCEEDINGS OF THE I
   SCHMITT J., 2002, PROCEEDINGS OF THE I, P73
   SCHULZRINNE H., 1998, STANDARDS TRACK RFC
   SGI, 1999, REACT IRIX REAL TIME
   SHENOY PJ, 1998, P ACM SPIE MULT COMP, P124
   SITARAM D., 1999, MULTIMEDIA SERVERS A
   Steinmetz R., 1995, MULTIMEDIA COMPUTING
   SUNDARAM V., 2000, PROCEEDINGS OF THE 8
   Talley T, 1996, CONF LOCAL COMPUT NE, P374, DOI 10.1109/LCN.1996.558166
   VERNICK M., 1996, PROCEEDINGS OF THE A
   YAVATKAR R, 1994, COMPUT COMMUN, V17, P205, DOI 10.1016/0140-3664(94)90006-X
NR 21
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2013
VL 9
IS 1
SU S
AR 38
DI 10.1145/2490859
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 241SJ
UT WOS:000326187700008
DA 2024-07-18
ER

PT J
AU Ho, ESL
   Chan, JCP
   Komura, T
   Leung, H
AF Ho, Edmond S. L.
   Chan, Jacky C. P.
   Komura, Taku
   Leung, Howard
TI Interactive Partner Control in Close Interactions for Real-Time
   Applications
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Performance; Close interactions; motion capture; character animation;
   virtual partner
ID MOTION SYNTHESIS
AB This article presents a new framework for synthesizing motion of a virtual character in response to the actions performed by a user-controlled character in real time. In particular, the proposed method can handle scenes in which the characters are closely interacting with each other such as those in partner dancing and fighting. In such interactions, coordinating the virtual characters with the human player automatically is extremely difficult because the system has to predict the intention of the player character. In addition, the style variations from different users affect the accuracy in recognizing the movements of the player character when determining the responses of the virtual character. To solve these problems, our framework makes use of the spatial relationship-based representation of the body parts called interaction mesh, which has been proven effective for motion adaptation. The method is computationally efficient, enabling real-time character control for interactive applications. We demonstrate its effectiveness and versatility in synthesizing a wide variety of motions with close interactions.
C1 [Ho, Edmond S. L.] Hong Kong Baptist Univ, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Chan, Jacky C. P.; Leung, Howard] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Komura, Taku] Univ Edinburgh, Sch Informat, IF1 23, Edinburgh EH8 9AB, Midlothian, Scotland.
C3 Hong Kong Baptist University; City University of Hong Kong; University
   of Edinburgh
RP Ho, ESL (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, RRS633, Kowloon, Hong Kong, Peoples R China.
EM Edmond@comp.hkbu.edu.hk
RI chan, jacky/JVP-2299-2024; Ho, Edmond S. L./JDW-1835-2023
OI Ho, Edmond S. L./0000-0001-5862-106X; LEUNG, Wing Ho
   Howard/0000-0002-2633-2965; Chan, Chun Pong/0000-0002-6180-9853
FU EPSRC [EP/H012338/1]; EU FP7 TOMSY; Hong Kong Baptist University's
   Research Committee start-up grant; EPSRC [EP/H012338/1] Funding Source:
   UKRI
FX This work was partially supported by grants from EPSRC (EP/H012338/1),
   EU FP7 TOMSY, and the Hong Kong Baptist University's Research Committee
   start-up grant.
CR [Anonymous], P IEEE RSJ INT C INT
   [Anonymous], 2010, SCA'10: proceedings of the 2010 ACM SIGGRAPH/Eurographics symposium on computer animation, DOI [10.2312/SCA/SCA10/001-010, DOI 10.2312/SCA/SCA10/001-010]
   Aoki T, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P40, DOI 10.1109/IROS.2007.4399584
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Davis TA, 2004, ACM T MATH SOFTWARE, V30, P196, DOI 10.1145/992200.992206
   Deng LQ, 2011, COMPUT ANIMAT VIRT W, V22, P229, DOI 10.1002/cav.397
   Dongheui Lee, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P1535, DOI 10.1109/ROBOT.2009.5152857
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Goto K, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1377603.1377607
   GROSS R., 2001, CMURITR0118 DAT ROB
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Ho ESL, 2011, COMPUT ANIMAT VIRT W, V22, P435, DOI 10.1002/cav.376
   Ho ESL, 2009, COMPUT GRAPH FORUM, V28, P299, DOI 10.1111/j.1467-8659.2009.01369.x
   Ho ESL, 2009, IEEE T VIS COMPUT GR, V15, P481, DOI 10.1109/TVCG.2008.199
   Hsu Eugene, 2004, P ACM SIGGRAPH EUR S, P69, DOI DOI 10.1145/1028523.1028534
   IKEMOTO L, 2007, P 2007 S INT 3D GRAP, P145
   Inamura T, 2004, INT J ROBOT RES, V23, P363, DOI 10.1177/0278364904042199
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lee Jehee., 2004, SCA 2004: Proceedings of the 2004 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P79
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Liu Karen, 2006, P 2006 ACM SIGGRAPHE, P215
   Magnenat-Thalmann N, 2008, LECT NOTES COMPUT SC, V4823, P1, DOI 10.1007/978-3-540-78139-4_1
   Mount D.M., 2006, Ann: A library for approximate nearest neighbor searching
   NAKAMURA AND YAMANE LABORATORY, 2005, AN HUM ROB PROJ PROT
   Nakayama D, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS ( ICAL 2009), VOLS 1-3, P191, DOI 10.1109/ICAL.2009.5262935
   Sakai Yasuo, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3264, DOI 10.1109/IROS.2007.4399290
   Shum HPH, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P131
   Shum HPH, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P65
   Si H, 2005, PROCEEDINGS OF THE 14TH INTERNATIONAL MESHING ROUNDTABLE, P147, DOI 10.1007/3-540-29090-7_9
   Sugihara T, 2005, IEEE INT CONF ROBOT, P305
   Sugihara T., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2869
   Takano W, 2011, IEEE INT CONF ROBOT, P1970
   Takeda T, 2007, IEEE T IND ELECTRON, V54, P699, DOI 10.1109/TIE.2007.891642
   Tang J.K., 2011, P 5 INT C UB INF MAN, P1
   TREUILLE A., 2007, ACM SIGGRAPH PAPERS
   Tsuruta S, 2007, 17TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE, ICAT 2007, PROCEEDINGS, P23, DOI 10.1109/ICAT.2007.37
NR 37
TC 26
Z9 28
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2013
VL 9
IS 3
AR 21
DI 10.1145/2487268.2487274
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 175GL
UT WOS:000321218800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bhatt, CA
   Atrey, PK
   Kankanhalli, MS
AF Bhatt, Chidansh A.
   Atrey, Pradeep K.
   Kankanhalli, Mohan S.
TI A Reward-and-Punishment-Based Approach for Concept Detection Using
   Adaptive Ontology Rules
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Design; Experimentation; Adaptive ontology rules; multimedia
   data mining; dynamic correlation; concept detection; model
AB Despite the fact that performance improvements have been reported in the last years, semantic concept detection in video remains a challenging problem. Existing concept detection techniques, with ontology rules, exploit the static correlations among primitive concepts but not the dynamic spatiotemporal correlations. The proposed method rewards (or punishes) detected primitive concepts using dynamic spatiotemporal correlations of the given ontology rules and updates these ontology rules based on the accuracy of detection. Adaptively learned ontology rules significantly help in improving the overall accuracy of concept detection as shown in the experimental result.
C1 [Bhatt, Chidansh A.; Kankanhalli, Mohan S.] Natl Univ Singapore, Singapore 117548, Singapore.
   [Atrey, Pradeep K.] Univ Winnipeg, Winnipeg, MB R3B 2E9, Canada.
C3 National University of Singapore; University of Winnipeg
RP Bhatt, CA (corresponding author), Natl Univ Singapore, Singapore 117548, Singapore.
EM chidansh@gmail.com
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
CR Amir A., 2003, P TREC VID RETR EV N
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P TREC VID RETR EV T
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], 2011, PASCAL VISUAL OBJECT
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Bai L, 2008, LECT NOTES COMPUT SC, V4918, P237
   Ballan L., 2011, MULTIMED TOOLS APPL, V51, P1
   Ballan L, 2010, IEEE MULTIMEDIA, V17, P80, DOI 10.1109/MMUL.2010.4
   Bather John, 2000, Decision Theory: An Introduction to Dynamic Programming and Sequential Decisions
   Bhatt CA, 2011, MULTIMED TOOLS APPL, V51, P35, DOI 10.1007/s11042-010-0645-5
   Brand M, 2000, IEEE T PATTERN ANAL, V22, P844, DOI 10.1109/34.868685
   Castano S., 2007, P INT WORKSH ONT DYN
   Castano S, 2009, J LOGIC COMPUT, V19, P859, DOI 10.1093/logcom/exn049
   Chao C, 2005, P INT C AC SPEECH SI
   Dasiopoulou S, 2005, IEEE T CIRC SYST VID, V15, P1210, DOI 10.1109/TCSVT.2005.854238
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V49, P167, DOI 10.1007/s11042-009-0393-6
   Fanagawa A., 2007, 2222006 COL U
   Harte N., 2009, J IMAGE VIDEO PROCES, V6, P13
   Haubold A, 2007, P ACM INT C IM VID R, P178
   Hossain M. A., 2009, IEEE T INSTRUM MEAS, V58, P5
   Kohlmorgen J, 1999, IEE CONF PUBL, P204, DOI 10.1049/cp:19991109
   Li L., 2010, PROC VLDB ENDOW, V3, P1
   Oca V. M. D., 2010, J SYST SOFTW, V83, P7
   Petridis S., 2011, SERIES COGNITIVE NEU
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Shyu ML, 2008, IEEE T MULTIMEDIA, V10, P252, DOI 10.1109/TMM.2007.911830
   Smith JR, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P445
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wu Y., 2004, P INT C MULT EXP
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Xu P., 2001, P INT C MULT EXP
   Yan R, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P834
   Yang K., 2004, P ACM INT WORKSH MUL
   Zha Z.-J., 2007, P ACM INT WORKSH MUL
   Zhou X., 2008, P ACM INT C MULT
NR 38
TC 3
Z9 3
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2013
VL 9
IS 2
AR 10
DI 10.1145/2457450.2457452
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 144MS
UT WOS:000318944400002
DA 2024-07-18
ER

PT J
AU Zheng, YT
   Yan, SC
   Zha, ZJ
   Li, YQ
   Zhou, XD
   Chua, TS
   Jain, R
AF Zheng, Yan-Tao
   Yan, Shuicheng
   Zha, Zheng-Jun
   Li, Yiqun
   Zhou, Xiangdong
   Chua, Tat-Seng
   Jain, Ramesh
TI GPSView: A Scenic Driving Route Planner
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithm; Experimentation; Scenic driving; route planning; geo-mining
AB GPS devices have been widely used in automobiles to compute navigation routes to destinations. The generated driving route targets the minimal traveling distance, but neglects the sightseeing experience of the route. In this study, we propose an augmented GPS navigation system, GPSView, to incorporate a scenic factor into the routing. The goal of GPSView is to plan a driving route with scenery and sightseeing qualities, and therefore allow travelers to enjoy sightseeing on the drive. To do so, we first build a database of scenic roadways with vistas of landscapes and sights along the roadside. Specifically, we adapt an attention-based approach to exploit community-contributed GPS-tagged photos on the Internet to discover scenic roadways. The premise is: a multitude of photos taken along a roadway imply that this roadway is probably appealing and catches the public's attention. By analyzing the geospatial distribution of photos, the proposed approach discovers the roadside sight spots, or Points-Of-Interest (POIs), which have good scenic qualities and visibility to travelers on the roadway. Finally, we formulate scenic driving route planning as an optimization task towards the best trade-off between sightseeing experience and traveling distance. Testing in the northern California area shows that the proposed system can deliver promising results.
C1 [Zheng, Yan-Tao; Li, Yiqun] Inst Infocomm Res, Singapore 138632, Singapore.
   [Yan, Shuicheng; Zha, Zheng-Jun; Chua, Tat-Seng] Natl Univ Singapore, Singapore 117548, Singapore.
   [Zhou, Xiangdong] Fudan Univ, Shanghai, Peoples R China.
   [Jain, Ramesh] Univ Calif Irvine, Irvine, CA USA.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); National University of Singapore; Fudan
   University; University of California System; University of California
   Irvine
RP Zheng, YT (corresponding author), Inst Infocomm Res, Fusionopolis Way, Singapore 138632, Singapore.
EM yantaozheng@gmail.com
RI Zha, Zheng-Jun/AAF-8667-2020; Yan, Shuicheng/HCI-1431-2022; Zha,
   Zheng-Jun/AAE-8408-2020
OI Zha, Zheng-Jun/0000-0003-2510-8993
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], P C ACM MULT
   [Anonymous], 2009, P 2 INT WORKSH LOC W
   [Anonymous], P IEEE INT C COMP VI
   Asakura Y, 2007, TRANSPORT RES A-POL, V41, P684, DOI 10.1016/j.tra.2006.07.003
   Bellman R., 1958, Q APPL MATH, V16, P87
   Chippendale P, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P188, DOI 10.1109/CVMP.2009.30
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   De Choudhury M., 2010, Proceedings of the 21st ACM Conference on Hypertext and Hypermedia-HT'10, P35, DOI DOI 10.1145/1810617.1810626
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Elias B, 2006, LECT NOTES COMPUT SC, V4197, P65
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   GOESELE M, 2007, P IEEE C COMP VIS
   Hao Q., 2010, P 19 INT C WORLD WID, P401, DOI [DOI 10.1145/1772690.1772732, 10.1145/1772690.1772732]
   Hao Qiang., 2009, Proceedings of the ACM International Conference on Multimedia, P801
   Hochmair H., 2008, P GEOINF FOR SALZB
   Hochmair H. H., 2007, P WORKSH ADV GEOGR I
   Jesdanun A., 2008, GPS ADDS DIMENSION O
   Joliffe I.T., 1986, Principal Component Analysis
   Kawai Y, 2009, IEEE INT CON MULTI, P990, DOI 10.1109/ICME.2009.5202663
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   Lew A, 2006, ANN TOURISM RES, V33, P403, DOI 10.1016/j.annals.2005.12.002
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Rattenbury Tye, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P103, DOI 10.1145/1277741.1277762
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Sander J, 1998, DATA MIN KNOWL DISC, V2, P169, DOI 10.1023/A:1009745219419
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Torniai C., 2007, SHARING DISCOVERING
   Winter S, 2002, GEOINFORMATICA, V6, P345, DOI 10.1023/A:1020853410145
   Zhang JW, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON UNIVERSAL COMMUNICATION, P154, DOI 10.1109/ISUC.2008.19
   Zheng Y., 2009, WWW, P791, DOI [10.1145/1526709.1526816, DOI 10.1145/1526709.1526816]
   ZHENG YT, 2009, P INT C COMP VIS PAT
NR 33
TC 38
Z9 44
U1 1
U2 17
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2013
VL 9
IS 1
AR 3
DI 10.1145/2422956.2422959
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 097EO
UT WOS:000315457000003
DA 2024-07-18
ER

PT J
AU Liu, SJ
   Chen, CW
AF Liu, Shujie
   Chen, Chang Wen
TI A Novel 3D Video Transcoding Scheme for Adaptive 3D Video Transmission
   to Heterogeneous Terminals
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Design; Multiview video; 3D video; transcoding; adaptive 3D
   video
AB Three-dimensional video (3DV) is attracting many interests with its enhanced viewing experience and more user driven features. 3DV has several unique characteristics different from 2D video: (1) It has a much larger amount of data captured and compressed, and corresponding video compression techniques can be much more complicated in order to explore data redundancy. This will lead to more constraints on users' network access and computational capability, (2) Most users only need part of the 3DV data at any given time, while the users' requirements exhibit large diversity, (3) Only a limited number of views are captured and transmitted for 3DV. View rendering is thus necessary to generate virtual views based on the received 3DV data. However, many terminal devices do not have the functionality to generate virtual views. To enable 3DV experience for the majority of users with limited capabilities, adaptive 3DV transmission is necessary to extract/generate the required data content and represent it with supported formats and bitrates for heterogeneous terminal devices. 3DV transcoding is an emerging and effective technique to achieve desired adaptive 3DV transmission. In this article, we propose the first efficient 3DV transcoding scheme that can obtain any desired view, either an encoded one or a virtual one, and compress it with more universal H. 264/AVC. The key idea of the proposed scheme is to appropriately utilize motion information contained in the bitstream to generate candidate motion information. Original information of both the desired view and reference views are used to obtain this candidate information and a proper motion refinement process is carried out for certain blocks. Simulation results show that, compared to the straightforward cascade algorithm, the proposed scheme is able to output compressed bitstream of the required view with significantly reduced complexity while incurring negligible performance loss. Such a 3DV transcoding can be applied to most gateways that usually have constraints on computational complexity and time delay.
C1 [Liu, Shujie; Chen, Chang Wen] SUNY Buffalo, Buffalo, NY 14260 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo
RP Liu, SJ (corresponding author), SUNY Buffalo, 338 Davis Hall, Buffalo, NY 14260 USA.
EM sL252@buffalo.edu; chencw@buffalo.edu
FU US NSF [0915842]; Technicolor (Thompson); Directorate For Engineering;
   Div Of Electrical, Commun & Cyber Sys [0915842] Funding Source: National
   Science Foundation
FX This research was supported in part by US NSF under Grant 0915842 and by
   a Gift Funding from Technicolor (Thompson).
CR AHMAND I., 2005, IEEE T MULTIMED, V7, P5
   [Anonymous], MICR 3D VID TEST SEQ
   [Anonymous], JTC1SC29WG11 ISOIEC
   Bai B., 2005, 13th Annual ACM International Conference on Multimedia, P503, DOI 10.1145/1101149.1101262
   Cha J, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1596990.1596993
   CHEN C. W., 2010, P ACM MULT
   CHEN C. W., 2009, P PICT COD S PCS 09
   CHEUNG G., 2011, IEEE T IMAGE PROCESS, V20, P3
   Fehn C., 2004, SPIE Stereoscopic Displays and Virtual Reality Systems XI
   FLORENCIO D., 2009, P ICASSP 09
   Hou JG, 2007, INT J NANOTECHNOL, V4, P1
   HUANG Q., 2009, SIGNAL PROCESS-IMAGE, V24, P8
   IKUTA Y., 2011, P ICC
   *JVT, 2008, JVTAA209
   *JVT, 2006, JVTT207
   KURUTEPE E., 2007, IEEE T CIRCUITE SYST, V17
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Lou JG, 2007, ADV MULTIMED, V2007, DOI 10.1155/2007/97535
   Maitre M, 2008, IEEE IMAGE PROC, P1768, DOI 10.1109/ICIP.2008.4712118
   MPEG VIDEO AND REQUIREMENTS SUBGROUP, 2009, W11061 MPEG VID REQ
   Oh H., 2006, ADV IMAGE VIDEO TECH, V4319
   Shum H.-Y., 2006, IMAGE BASED RENDERIN
   Smolic A., 2008, P IEEE INT C IM PROC
   SMOLIC A., 2009, P PICT COD S
   TANG X.-L., 2010, P ICGCS
   TIAN D., 2011, IEEE T, V57, P2
   ULLER K., 2008, P IEEE INT WORKSH MU
   VETRO A., 2004, P PICT COD S
   ZHANG C., 2010, P VCIP
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
   [No title captured]
NR 31
TC 2
Z9 2
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2012
VL 8
IS 3
SU S
AR 43
DI 10.1145/2348816.2348822
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 021VG
UT WOS:000309912900006
DA 2024-07-18
ER

PT J
AU Verdugo, R
   Nussbaum, M
   Corro, P
   Nuñez, P
   Navarrete, P
AF Verdugo, Renato
   Nussbaum, Miguel
   Corro, Pablo
   Nunez, Pablo
   Navarrete, Paula
TI Interactive Films and Coconstruction
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Experimentation; Human Factors; Interactive film;
   coconstruction; storytelling; filmmaking
AB Interactive Filmmaking is both an aesthetic and technological challenge. Steerable plots, where audiences are not passive viewers but active participants of the narrative experience, require an engaging narrative model as well as a technologically feasible structure. This article discusses the connection between aesthetics, cinema, and interactivity and presents a model for interactive narration that is based on the audience's ability to read and interpret footage differently according to its context. Through a detour narrative model it is possible to engage audiences in a coconstructive hypermedia experience while at the same time minimizing the amount of footage required. An interface model that allows seamless hypervideo navigation through graphic interaction is also discussed, and the interactive short film The Crime or Revenge of Fernando Moreno is presented, along with user experience and usability studies that experimentally prove our hypothesis.
C1 [Verdugo, Renato; Nussbaum, Miguel; Navarrete, Paula] Pontificia Univ Catolica Chile, Dept Comp Sci, Sch Engn, Santiago, Chile.
   [Corro, Pablo] Pontificia Univ Catolica Chile, Inst Aesthet, Sch Philosophy, Santiago, Chile.
   [Nunez, Pablo] Pontificia Univ Catolica Chile, Audiovisual Dept, Sch Commun, Santiago, Chile.
C3 Pontificia Universidad Catolica de Chile; Pontificia Universidad
   Catolica de Chile; Pontificia Universidad Catolica de Chile
RP Verdugo, R (corresponding author), Pontificia Univ Catolica Chile, Dept Comp Sci, Sch Engn, Santiago, Chile.
EM rverdugo@ing.puc.cl; mn@ing.puc.cl; pcorro@uc.cl; pfnunez@uc.cl;
   pcnavarr@uc.cl
RI Nussbaum, Miguel/D-1341-2013
OI Nussbaum, Miguel/0000-0001-5617-5983
FU Center for Research on Educational Policy and Practice [CIE01-CONICYT]
FX The research was partly supported by the Center for Research on
   Educational Policy and Practice, Grant CIE01-CONICYT.
CR [Anonymous], 1984, CROWDS POWER
   Atkinson S., 2008, P 3 INT C DIG INT ME, P537
   BRAND J, 2005, P DIGRA C CHANG VIEW
   Brooks K. M., 1996, Proceedings ACM Multimedia 96, P317, DOI 10.1145/244130.244233
   Csikszentmihalyi M., 2008, FLOW PSYCHOL OPTIMAL
   DAVENPORT G, 2002, P C STOR TELL DIG AG
   DOMIKE S, 2002, NARRATIVE INTELLIGEN
   DORFLES Gillo., 1984, El intervalo Perdido. Ed
   Eco Umberto., 1989, OPEN WORK 1962
   Figgis Mike., 2000, TIME CODE
   Godard Jean-Luc., 1960, BOUT SOUFFLE
   GREENAWAY P, 1996, PILLOW BOOK
   Halliwell Leslie, 1988, HALLIWELLS FILMGOERS
   HANDLER C, 2008, DIGITAL STORYTELLING
   Haneke Michael., 1997, FUNNY GAMES
   Jauss Robert., 1982, Toward an Aesthetic of Reception
   Johnson Kirsten, 2008, P 16 ACM INT C MULT, P569
   Knoller Noam, 2004, P 1 ACM WORKSH STOR, P63
   Kurosawa A., 1950, RASHOMON
   LEW M, 2004, P INT C COMP GRAPH I, P117
   MACFADYEN A, 2007, P 4 AUSTR C INT ENT
   MARQUEZ M, 2007, P 2 INT C DIG INT ME, P181
   MONGOMERY R, 1947, LADY LAKE
   Nack F., 2003, Proceedings of the 1st ACM MM WS on Experiential Telepresence (ETP'03), P53, DOI DOI 10.1145/982484.982492
   Perniola M., 2001, ESTETICA SIGLO 20
   Polaine Andrew., 2005, IE '05 Proceedings of the second Australasian conference on Interactive entertainment, P151
   SAWHNEY N., 1996, P 7 ACM C HYPERTEXT, P1, DOI DOI 10.1145/234828.234829
   SCHIPMAN F, 2008, ACM T MULTIM COMPUT, V5, P2
   Stenzler M. K., 1996, SIGCHI Bulletin, V28, P76, DOI 10.1145/226650.226676
   SZILLAS N, 2005, P 2 AUSTR C INT ENT, P139
   TOKUHISA S, 2005, P ACM SIGCHI INT C A, P314
   Vattimo Gianni., 1997, Beyond Interpretation: The Meaning of Hermeneutics for Philosophy
   XU RYD, 2003, PAN SYDN WORKSH VIS, V22, P113
   2011, ACM T MULTIMEDIA COM, V7, P39
NR 34
TC 7
Z9 7
U1 2
U2 29
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2011
VL 7
IS 4
AR 39
DI 10.1145/2043612.2043617
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856ZS
UT WOS:000297684000005
DA 2024-07-18
ER

PT J
AU Yang, ZY
   Wu, WM
   Nahrstedt, K
   Kurillo, G
   Bajcsy, R
AF Yang, Zhenyu
   Wu, Wanmin
   Nahrstedt, Klara
   Kurillo, Gregorij
   Bajcsy, Ruzena
TI Enabling Multi-Party 3D Tele-Immersive Environments with <i>ViewCast</i>
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Performance; Experimentation; 3D tele-immersion; networking
   protocol; distributed multimedia system; multi-stream coordination; QoS
   adaptation; application level multicast
AB Three-dimensional tele-immersive (3DTI) environments have great potential to promote collaborative work among geographically distributed users. However, most existing 3DTI systems only work with two sites due to the huge demand of resources and the lack of a simple yet powerful networking model to handle connectivity, scalability, and quality-of-service (QoS) guarantees.
   In this article, we explore the design space from the angle of multi-stream management to enable multi-party 3DTI communication. Multiple correlated 3D video streams are employed to provide a comprehensive representation of the physical scene in each 3DTI environment, and are rendered together to establish a common cyberspace among all participating 3DTI environments. The existence of multi-stream correlation provides the unique opportunity for new approaches in QoS provisioning. Previous work mostly concentrated on compression and adaptation techniques on the per-stream basis while ignoring the application layer semantics and the coordination required among streams. We propose an innovative and generalized ViewCast model to coordinate the multi-stream content dissemination over an overlay network. ViewCast leverages view semantics in 3D free-viewpoint video systems to fill the gap between high-level user interest and low-level stream management. In ViewCast, only the view information is specified by the user/application, while the underlying control dynamically performs stream differentiation, selection, coordination, and dissemination. We present the details of ViewCast and evaluate it through both simulation and 3DTI sessions among tele-immersive environments residing in different institutes across the Internet2. Our experimental results demonstrate the implementation feasibility and performance enhancement of ViewCast in supporting multi-party 3DTI collaboration.
C1 [Yang, Zhenyu; Wu, Wanmin; Nahrstedt, Klara] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
   [Kurillo, Gregorij; Bajcsy, Ruzena] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign;
   University of California System; University of California Berkeley
RP Yang, ZY (corresponding author), Univ Illinois, Dept Comp Sci, 201 N Goodwin, Urbana, IL 61801 USA.
EM zyang2@uiuc.edu; wwu23@uiuc.edu; clara@uiuc.edu;
   gregorij@eecs.berkeley.edu; bajcsy@eecs.berkeley.edu
FU National Science Foundation [NSF SCI 05-49042, NSF CNS 05-20182, NSF IIS
   07-03756]; Directorate For Engineering [0941382] Funding Source:
   National Science Foundation; Division Of Computer and Network Systems;
   Direct For Computer & Info Scie & Enginr [0834480] Funding Source:
   National Science Foundation; Div Of Electrical, Commun & Cyber Sys
   [0941382] Funding Source: National Science Foundation
FX This research is supported by the National Science Foundation (NSF SCI
   05-49042, NSF CNS 05-20182, and NSF IIS 07-03756). The views presented
   are those of the authors and do not represent the position of NSF.
CR *3DAV, 2003, JTC1SC29WG11N5878 3D
   [Anonymous], P 8 INT C DISTR MULT
   [Anonymous], P 9 ACM INT C MULT M
   [Anonymous], P SIGCHI C HUM FACT
   [Anonymous], P 15 INT C MULT ACM
   [Anonymous], 1995, ACM Transactions on Computer-Human Interaction (TOCHI), DOI DOI 10.1145/210079.210088
   [Anonymous], P ACM NOSSDAV 2003 M
   Baker HH, 2005, ACM T MULTIM COMPUT, V1
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   Bauer F, 1997, IEEE J SEL AREA COMM, V15, P382, DOI 10.1109/49.564136
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Chu YH, 2000, PERF E R SI, V28, P1, DOI 10.1145/345063.339337
   Daniilidis K., 2000, CONFLUENCE COMPUTER, P253
   Gross M, 2003, ACM T GRAPHIC, V22, P819, DOI 10.1145/882262.882350
   Hosseini M., 2003, Proceedings of the eleventh ACM international conference on Multimedia, MULTIMEDIA '03, P480
   Jannotti J, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE FOURTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P197
   Kauff Peter, 2002, P 4 INT C COLLABORAT, P105
   Müller-Schärer H, 2001, MOL ECOL, V10, P17, DOI 10.1046/j.1365-294X.2001.01169.x
   Ott DavidE., 2004, MULTIMEDIA '04: Proceedings of the 12th annual ACM inter- national conference on Multimedia, P596
   Raskar R., 1998, Computer Graphics, P179, DOI 10.1145/280814.280861
   Schreer O., 2001, Proc. Intl. Conf. eWork and eBusiness, P184
   Shi SL, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID - CCGRID 2004, P699
   Sripanidkulchai K., 2004, Proc. ACM Internet Measurement Conference, P41
   Sriram R, 1999, IEEE INFOCOM SER, P1073, DOI 10.1109/INFCOM.1999.751662
   *TEEVE, TEEV PROJ
   WURMLIN S, 2003, 397 ETH I SCI COMP
   Yang XJ, 2006, IEEE GEOSCI REMOTE S, V3, P6, DOI 10.1109/LGRS.2005.853929
   YANG Z, 2006, P SPIE MULT COMP NET, P12
   Yang ZY, 2005, IEEE INT SYM MULTIM, P112
NR 29
TC 11
Z9 13
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR 10
PY 2010
VL 6
IS 2
AR 7
DI 10.1145/1671962.1671963
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 579PA
UT WOS:000276382700001
DA 2024-07-18
ER

PT J
AU Wang, B
   Wei, W
   Guo, Z
   Towsley, D
AF Wang, Bing
   Wei, Wei
   Guo, Zheng
   Towsley, Don
TI Multipath Live Streaming via TCP: Scheme, Performance and Benefits
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Performance; Performance modeling; multimedia streaming
AB Motivated by the wide use of TCP for multimedia streaming in practice and the increasing availability of multipath between end hosts, we study multipath live streaming via TCP in this article. We first design a simple and practical TCP-based multipath streaming scheme, named Dynamic MPath-streaming (DMP-streaming), which dynamically distributes packets over multiple paths by implicitly inferring the available bandwidths on these paths. To allow systematic performance study, we develop an analytical model for DMP-streaming and validate the model using extensive ns simulation and Internet experiments. We explore the parameter space of this model and find that DMP-streaming generally provides satisfactory performance when the aggregate achievable TCP throughput is 1.6 times the video bitrate, when allowing a few seconds of startup delay. Last, we comment on the benefits of using multipath versus single path for TCP-based streaming.
C1 [Wang, Bing; Wei, Wei; Guo, Zheng] Univ Connecticut, Dept Comp Sci & Engn, Storrs, CT 06269 USA.
   [Towsley, Don] Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA.
C3 University of Connecticut; University of Massachusetts System;
   University of Massachusetts Amherst
RP Wang, B (corresponding author), Univ Connecticut, Dept Comp Sci & Engn, Storrs, CT 06269 USA.
EM bing@engr.uconn.edu; weiwei@engr.uconn.edu; guozheng@engr.uconn.edu;
   towsley@cs.umass.edu
OI Towsley, Donald/0000-0002-7808-7375
FU UCONN; National Science Foundation [ANI-0325868, ANI-0240487,
   ANI-0085848, EIA-0080119, 0746841]; Division Of Computer and Network
   Systems; Direct For Computer & Info Scie & Enginr [0746841] Funding
   Source: National Science Foundation
FX This work was supported in part by UCONN large grant, the National
   Science Foundation under ANI-0325868, ANI-0240487, ANI-0085848, and
   EIA-0080119, and NSF CAREER award 0746841. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the authors and do not necessarily reflect the views of the funding
   agencies.
CR Altman E, 2000, ACM SIGCOMM COMP COM, V30, P231, DOI 10.1145/347057.347549
   [Anonymous], P ACM SIGCOMM 98
   APOSTOLOPOULOS J, 2002, ANN JOINT C IEEE COM
   BOHACEK S, 2003, P ANN JOINT C IEEE C
   CARDWELL N, 2000, ANN JOINT C COMP COM, P1742
   CHESTERFIELD J, 2005, P ANN JOINT C IEEE C
   DECUETOS P, 2002, P INT C MULT EXP
   DECUETOS P, 2002, P INT WORKSH NETW OP
   FIGUEIREDO DR, 2002, COMPUT NETW J
   GOLUBCHIK L, 2002, PERFORM EVAL
   HSIEH HY, 2002, P ACM ANN INT C MOB
   JURCA D, 2006, IEEE T MULTIMEDIA
   Kim T, 2006, PROC SPIE, V6077, DOI 10.1117/12.643583
   KRASIC C, 2001, P ACM MULT DOCT S
   LI M, 2003, WPICSTR0318 COMP SCI
   LIANG YJ, 2001, P ACM MULT C
   MATHIS M, 1997, COMPUT COMMUN REV, V27
   Mellia M, 2002, IEEE COMMUN LETT, V6, P85, DOI 10.1109/4234.984705
   Nguyen T, 2004, IEEE T MULTIMEDIA, V6, P315, DOI 10.1109/TMM.2003.822790
   PADHYE J, 1999, 9902 U MASS DEP COMP
   REJAIE R, 2003, P INT WORKSH NETW OP
   RIBEIRO B, 2005, 0519 U MASS DEP COMP
   SEELAM N, 2001, P C MAN MULT NETW SE
   SHARMA V, 2008, P IEEE ANN JOINT C C
   SILVA EDE, 2000, P 11 INT C MOD TOOLS
   Sripanidkulchai K., 2004, Proc. ACM Internet Measurement Conference, P41
   Tullimas S, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352016
   VANDERMERWE J, 2002, P INT WEB CONT CACH
   VERSCHEURE O, 1998, P INT WORKSH NETW OP
   WANG B, 2004, P ACM MULT
   WANG B, 2007, P ACM CONEXT C
   Wang JL, 2006, BMC INFECT DIS, V6, DOI 10.1186/1471-2334-6-7
   WANG Y, 2001, P ACM SIGCOMM INT ME
   Zhang Q, 2001, IEEE T MULTIMEDIA, V3, P339, DOI 10.1109/6046.944477
NR 34
TC 39
Z9 64
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2009
VL 5
IS 3
AR 25
DI 10.1145/1556134.1556142
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 504DV
UT WOS:000270595600008
DA 2024-07-18
ER

PT J
AU Yiu, WPK
   Chan, SHG
AF Yiu, Wai-Pun Ken
   Chan, Shueng-Han Gary
TI Offering Data Confidentiality for Multimedia Overlay Multicast: Design
   and Analysis
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Experimentation; Performance; Security; Key management;
   multicast security; overlay multicast; performance analysis
AB Application layer multicast (ALM) has been proposed to overcome current limitations in IP multicast for large-group multimedia communication. We address offering data confidentiality tailored for ALM. To achieve confidentiality, a node may need to continuously re-encrypt packets before forwarding them downstream. Furthermore, keys have to be changed whenever there is a membership change, leading to rekey processing overhead at the nodes. For a large and dynamic group, these reencryption and rekeying operations incur high processing overhead at the nodes. We propose and analyze a scalable scheme called Secure Overlay Multicast (SOM) which clusters ALM peers so as to localize rekeying within a cluster and to limit re-encryption at cluster boundaries, thereby minimizing the total nodal processing overhead. We describe the operations of SOM and compare its nodal processing overhead with two other basic approaches, namely, host-to-host encryption and whole group encryption. We also present a simplified analytic model for SOM and show that there exists an optimal cluster size to minimize the total nodal processing overhead. By comparing with a recently proposed ALM scheme (DT protocol), SOM achieves a substantial reduction in nodal processing overhead with similar network performance in terms of network stress and delay.
C1 [Yiu, Wai-Pun Ken] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Yiu, WPK (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
OI Chan, Gary Shueng Han/0000-0003-4207-764X
FU Hong Kong Innovation and Technology Commission; Hong Kong Research Grant
   Council [611107];  [GHP/045/05]
FX This work was supported in part by the Hong Kong Innovation and
   Technology Commission (GHP/045/05) and the Hong Kong Research Grant
   Council (611107).
CR [Anonymous], 1988, Distance Vector Multicast Routing Protocol
   [Anonymous], P ACM SIGCOM SAN FRA
   Badishi G, 2006, IEEE T DEPEND SECURE, V3, P45, DOI 10.1109/TDSC.2006.12
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   Basagni S, 1999, FOURTH INTERNATIONAL SYMPOSIUM ON PARALLEL ARCHITECTURES, ALGORITHMS, AND NETWORKS (I-SPAN'99), PROCEEDINGS, P310, DOI 10.1109/ISPAN.1999.778957
   Canetti R, 1999, IEEE INFOCOM SER, P708, DOI 10.1109/INFCOM.1999.751457
   Chan KC, 2003, IEEE NETWORK, V17, P30, DOI 10.1109/MNET.2003.1233915
   Chan KC, 2002, IEEE J SEL AREA COMM, V20, P1500, DOI 10.1109/JSAC.2002.803966
   Chang I, 1999, IEEE INFOCOM SER, P689, DOI 10.1109/INFCOM.1999.751455
   Chu YH, 2002, IEEE J SEL AREA COMM, V20, P1456, DOI 10.1109/JSAC.2002.803066
   DABEK F, 2004, P ACM SIGCOMM DAT CO
   Deering S., 1994, Computer Communication Review, V24, P126, DOI 10.1145/190809.190326
   Ganjam A., 2004, NOSSDAV 04, P54
   HUANG J, 2003, P IEEE GLOB TEL C
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Kim HW, 2004, MAT SCI SEMICON PROC, V7, P1, DOI 10.1016/j.mssp.2003.12.001
   Kleinrock L., 1975, Queueing Systems-Volume 1: Theory, V1
   Kranakis E., 1999, P 11 CAN C COMP GEOM, V11, P51
   Lee PPC, 2006, IEEE ACM T NETWORK, V14, P263, DOI 10.1109/TNET.2006.872575
   Liebeherr J, 2002, IEEE J SEL AREA COMM, V20, P1472, DOI 10.1109/JSAC.2002.803067
   Lim H, 2005, IEEE ACM T NETWORK, V13, P513, DOI 10.1109/TNET.2005.850197
   LIN C, 1997, IEEE J SELECT AREAS, V15
   Lin HC, 2000, 2000 IEEE 51ST VEHICULAR TECHNOLOGY CONFERENCE, PROCEEDINGS, VOLS 1-3, P1545, DOI 10.1109/VETECS.2000.851386
   MATHY L, 2004, P ANN JOINT C IEEE C
   Mittra S., 1997, Computer Communication Review, V27, P277, DOI 10.1145/263109.263179
   Ng ISE, 2002, IEEE INFOCOM SER, P170, DOI 10.1109/INFCOM.2002.1019258
   Sahni S., 1998, DATA STRUCTURES ALGO
   Shields C, 1999, COMP COMM R, V29, P53, DOI 10.1145/316194.316206
   SRIPANIDKULCHAI K, 2004, P ACM SIGCOMM PORTL
   TRAN DA, 2003, P ANN JOINT C IEEE C
   Wong CK, 2000, IEEE ACM T NETWORK, V8, P16, DOI 10.1109/90.836475
   WONG WC, 2003, P IEEE GLOB TEL C
   Yiu WPK, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1451, DOI 10.1109/ICC.2004.1312752
   YIU WPK, 2006, IEEE T MULTIMED, V8
   Zegura EW, 1996, IEEE INFOCOM SER, P594, DOI 10.1109/INFCOM.1996.493353
   Zhu Y, 2004, IEEE J SEL AREA COMM, V22, P107, DOI 10.1109/JSAC.2003.818801
NR 36
TC 0
Z9 0
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2008
VL 5
IS 2
AR 13
DI 10.1145/1413862.1413866
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 376AU
UT WOS:000261155900004
DA 2024-07-18
ER

PT J
AU Gill, P
   Shi, LQ
   Mahanti, A
   Li, ZP
   Eager, DL
AF Gill, Phillipa
   Shi, Liqi
   Mahanti, Anirban
   Li, Zongpeng
   Eager, Derek L.
TI Scalable On-Demand Media Streaming for Heterogeneous Clients
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT ACM Multimedia Conference 2007
CY SEP 24-29, 2007
CL Augsburg, GERMANY
SP ACM
DE Design; Performance; Scalable streaming; periodic broadcasts; linear
   programming; quality-of-service
ID CONGESTION CONTROL; RECOVERY; INTERNET; SERVICE
AB Periodic broadcast protocols enable efficient streaming of highly popular media files to large numbers of concurrent clients. Most previous periodic broadcast protocols, however, assume that all clients can receive at the same rate, and also assume that reception bandwidth is not time-varying. In this article, we first develop a new periodic broadcast protocol, Optimized Heterogeneous Periodic Broadcast (OHPB), that can be optimized for a given population of clients with heterogeneous reception bandwidths and quality-of-service requirements. The OHPB protocol utilizes an optimized segment size progression determined by solving a linear optimization model that takes as input the client population characteristics and an objective function such as mean client startup delay. We then develop a generalization of the OHPB linear optimization model that allows optimal server bandwidth allocation among multiple concurrent OHPB broadcasts, wherein each media file and its clients may have different characteristics. Finally, we propose complementary client protocols employing work-ahead buffering of data during playback, so as to enable more uniform playback quality when the reception bandwidth is time-varying.
C1 [Gill, Phillipa; Li, Zongpeng] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
   [Shi, Liqi] Univ Calgary, Dept Elect & Comp Engn, Calgary, AB T2N 1N4, Canada.
   [Mahanti, Anirban] Indian Inst Technol, Dept Comp Sci & Engn, New Delhi 110016, India.
   [Eager, Derek L.] Univ Saskatchewan, Dept Comp Sci, Saskatoon, SK S7N 5C9, Canada.
C3 University of Calgary; University of Calgary; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Delhi; University of Saskatchewan
RP Gill, P (corresponding author), Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
EM psessini@cpsc.ucalgary.ca; lishi@ucalgary.ca; mahanti@cse.iitd.ac.in;
   zongpeng@cpsc.ucalgary.ca; eager@cs.usask.ca
RI YANG, DAN/KCL-5217-2024
CR ALMEIDA J, 2002, P IEEE INFOCOM
   [Anonymous], P IEEE INFOCOM
   BARNOY A, 2002, P INT C MULT COMP NE
   Bertsimas D., 1997, INTRO LINEAR OPTIMIZ, V6
   BYERS J, 2001, P INT WORKSH NETW GR
   Byers J. W., 1998, P ACM SIGCOMM
   CHEUNG S, 1996, P IEEE INFOCOM
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   EAGER D, 1999, P ACM MULT C
   EAGER D, 2000, P INT C MULT COMP NE
   EAGER D, 1999, P INT C MULT COMP NE
   EAGER D, 1998, P INT WORKSH ADV MUL
   Eager DL, 2000, PERFORM EVALUATION, V42, P163, DOI 10.1016/S0166-5316(00)00029-8
   Floyd S, 1999, IEEE ACM T NETWORK, V7, P458, DOI 10.1109/90.793002
   GAO L, 1998, P ACM INT WORKSH NET
   HU A, 1999, P IEEE INT S MOD AN
   Hu A., 2001, P IEEE INFOCOM
   Hua K., 1997, P ACM SIGCOMM
   HUA KA, 2003, P INT C MULT COMP NE
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   KIM T, 2001, P ACM INT WORKSH NET
   LEGOUT A, 2000, P ACM SIGMETRICS
   Li X, 1999, IEEE NETWORK, V13, P46, DOI 10.1109/65.768488
   LI X, 1996, P IEEE INT S HIGH PE
   LUBY M, 2002, P ACM SIGCOMM
   Mahanti A, 2005, COMPUT NETW, V48, P113, DOI 10.1016/j.comnet.2004.04.005
   Mahanti A, 2003, IEEE ACM T NETWORK, V11, P195, DOI 10.1109/TNET.2003.810311
   MAHANTI A, 2004, THESIS U SASKATCHEWA
   McCanne S., 1996, P ACM SIGCOMM
   Mitzenmacher M., 2004, P IEEE INF THEOR WOR
   PARIS J, 1998, P IEEE INT S MOD AN
   QUDAH B, 2006, P ACM MULT C
   REJAIE R., 1999, P ACM SIGCOMM
   Rejaie R., 1999, P IEEE INFOCOM
   RIZZO L, 1997, P IEEE WORKSH HIGH P
   Sherali HD, 1996, OPER RES LETT, V19, P105, DOI 10.1016/0167-6377(96)00019-3
   Tantaoui MA, 2004, IEEE T BROADCAST, V50, P289, DOI 10.1109/TBC.2004.834202
   TURLETTI T, 1997, 3296 INRIA
   Vicisano L., 1998, P IEEE INFOCOM
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Wang B., 2002, P IEEE INFOCOM
   Widmer J, 2001, IEEE NETWORK, V15, P28, DOI 10.1109/65.923938
   ZHAO Y, 2002, P IEEE INFOCOM
   ZINK M, 2003, P IEEE INT WORKSH QU
NR 44
TC 8
Z9 9
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2008
VL 5
IS 1
AR 8
DI 10.1145/1404880.1404888
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 376AS
UT WOS:000261155700008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jung, D
   Kim, J
   Kim, JS
   Lee, J
AF Jung, Dawoon
   Kim, Jaegeuk
   Kim, Jin-Soo
   Lee, Joonwon
TI ScaleFFS: A Scalable Log-Structured Flash File System for Mobile
   Multimedia Systems
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT ACM Multimedia Conference 2007
CY SEP 24-29, 2007
CL Augsburg, GERMANY
SP ACM
DE Design; Performance; File system; flash memory; NAND; storage system
AB NAND flash memory has become one of the most popular storage media for mobile multimedia systems. A key issue in designing storage systems for mobile multimedia systems is handling large-capacity storage media and numerous large files with limited resources such as memory. However, existing flash file systems, including JFFS2 and YAFFS in particular, exhibit many limitations in addressing the storage capacity of mobile multimedia systems.
   In this article, we design and implement a scalable flash file system, called ScaleFFS, for mobile multimedia systems. ScaleFFS is designed to require only a small fixed amount of memory space and to provide fast mount time, even if the file system size grows to more than tens of gigabytes. The measurement results show that ScaleFFS can be instantly mounted regardless of the file system size, while achieving the same write bandwidth and up to 22% higher read bandwidth compared to JFFS2.
C1 [Jung, Dawoon; Kim, Jaegeuk] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
   [Kim, Jin-Soo; Lee, Joonwon] Sungkyunkwan Univ, Sch Informat & Commun Engn, Suwon 440746, Gyeonggi Do, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Sungkyunkwan
   University (SKKU)
RP Jung, D (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, 335 Gwahangno, Taejon 305701, South Korea.
EM dwjung@calab.kaist.ac.kr; jgkim@calab.kaist.ac.kr; jinsookim@skku.edu;
   joowon@skku.edu
RI KIM, Heejae/J-2173-2015
CR *AL LTD, 2003, YET AN FLASH FIL SYS
   Card R., 1994, PROCESSDINGS 1 DUTCH, P5
   Douglis F., 1994, Proceedings of the First USENIX Symposium on Operating Systems Design and Implementation (OSDI), P25
   GUMMADI KP, 2003, P 19 ACM S OP SYST P, P314
   Huang H, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE GENERAL TRACK, P57
   *HYN SEM INC, 2006, HYN NAND FLASH DAT S
   Kang J., 2006, Proceedings of the International Conference on Embedded Software (EMSOFT), P161
   Kim J, 2002, IEEE T CONSUM ELECTR, V48, P366
   Lim SH, 2006, IEEE T COMPUT, V55, P906, DOI 10.1109/TC.2006.96
   Marsh B., 1994, Proceedings of the Twenty-Seventh Hawaii Internation Conference on System Sciences Vol. I: Architecture (Cat. No.94TH0607-2), P451, DOI 10.1109/HICSS.1994.323153
   MCKUSICK MK, 1984, ACM T COMPUT SYST, V2, P181, DOI 10.1145/989.990
   *MTD, 1999, MEM TECHN DEV MTD SU
   Park CI, 2004, ISLPED '04: PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P338, DOI 10.1145/1013235.1013317
   Paulson L.D., 2005, IEEE Computer, V38, P14, DOI [10.1109/MC.2005.330., DOI 10.1109/MC.2005]
   ROSENBLUM M, 1992, ACM T COMPUT SYST, V10, P26, DOI 10.1145/146941.146943
   *SAMS EL CO LTD, 2007, SAMS NAND FLASH DAT
   Saroiu S, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE FIFTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P315, DOI 10.1145/1060289.1060319
   Seltzer M., 1993, USENIX Association. Proceedings of the Winter 1993 USENIX Conference, P307
   Sivathanu M, 2004, USENIX Association Proceedings of the Sixth Symposium on Operating Systems Design and Implementation (OSDE '04), P379
   *STMICROELECTRONIC, 2007, STMICROELECTRONICS E
   WOODHOUSE D, 2001, OTTAWA LIN S
NR 21
TC 10
Z9 13
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2008
VL 5
IS 1
AR 9
DI 10.1145/1404880.1404889
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 376AS
UT WOS:000261155700009
DA 2024-07-18
ER

PT J
AU Lim, SH
   Jeong, YW
   Park, KH
AF Lim, Seung-Ho
   Jeong, Yo-Won
   Park, Kyu Ho
TI Data placement and prefetching with accurate bit rate control for
   interactive media server
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE algorithms; management; interactive media server; disk array; stripe
   size; video rate; bit count control
ID HIGH-PERFORMANCE; VIDEO; STORAGE
AB An interactive Media Server should support unrestricted control to viewers with their service level agreements. It is important to manage video data effectively to facilitate efficient retrieval. In this paper, we propose an efficient placement algorithm as part of an effective retrieval scheme to increase the number of clients who can be provided with interactive service. The proposed management schemes are incorporated with a bit count control method that is based on repeated tuning of quantization parameters to adjust the actual bit count to the target bit count. The encoder using this method can generate coded frames whose sizes are synchronized with the RAID stripe size, so that when various fast-forward levels are accessed we can reduce the seek and rotational latency and enhance the disk throughput of each disk in the RAID system. Experimental results demonstrate that the proposed schemes can significantly improve the average service time and guarantee more users service of quality, and the interactive media server can thereby efficiently service a large number of clients.
C1 [Lim, Seung-Ho; Jeong, Yo-Won; Park, Kyu Ho] Korea Adv Inst Sci & Technol, Dept Elect Engn & Comp Sci, Comp Engn Res Lab, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lim, SH (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn & Comp Sci, Comp Engn Res Lab, 373-1 Guseong Dong, Taejon 305701, South Korea.
EM shlim@core.kaist.ac.kr; ywjeong@core.kaist.ac.kr; kpark@ee.kaist.ac.kr
RI Park, Kyu Ho/C-1869-2011
CR BERSON S, 1994, P ACM SIGMOD, P79
   Bovet D. P., 2005, Understanding the Linux Kernel: from I/O ports to process management
   Carter SR, 2001, INT CON DISTR COMP S, P657
   Chang E, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P496
   CHEN M, 1995, P MULTIMEDIA 95, P121
   Chervenak D. A., 1995, 3 ACM INT C MULTIMED, P109
   CHOI JH, 1994, IEEE T IMAGE PROCESS, V3, P546, DOI 10.1109/83.334986
   DAIGLE SJ, 1994, P SPIE C HIGH SPEED
   GANGER GR, 1994, COMPUTER, V27, P30, DOI 10.1109/2.268882
   Gopalan K, 2002, PROC SPIE, V4673, P34
   Huang XM, 2004, IEEE T CONSUM ELECTR, V50, P1119, DOI 10.1109/TCE.2004.1362508
   KATZ RH, 1989, P IEEE, V77, P1842, DOI 10.1109/5.48827
   Kim TY, 2000, SIGNAL PROCESS-IMAGE, V15, P479, DOI 10.1016/S0923-5965(99)00008-9
   KWON J, 2003, P 9 AS PAC C COMM, P521
   Lee JS, 2002, MAR BIOTECHNOL, V4, P1, DOI 10.1007/s10126-001-0077-3
   Lee WY, 1996, ELECTRON LETT, V32, P1871, DOI 10.1049/el:19961285
   Liu JCL, 1999, IEEE T KNOWL DATA EN, V11, P406, DOI 10.1109/69.774101
   *MPEG, 1996, MPEG SOFTW SIM GROUP
   ORTEGA A, 1994, IEEE T IMAGE PROCESS, V3, P26, DOI 10.1109/83.265978
   Ramanathan S., 1994, IEEE Multimedia, V1, P37, DOI 10.1109/93.295266
   RANGAN PV, 1992, IEEE COMMUN MAG, V30, P56, DOI 10.1109/35.144778
   Rangaswami R, 2003, IEEE T MULTIMEDIA, V5, P558, DOI [10.1109/TMM.2003.814722, 10.1109/TTM.2003.814722]
   Reisslein M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P635, DOI 10.1109/MMCS.1999.778558
   Shenoy PJ, 1999, MULTIMEDIA SYST, V7, P241, DOI 10.1007/s005300050126
   Shenoy PJ, 1997, PROCEEDINGS OF THE IEEE 7TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEM SUPPORT FOR DIGITAL AUDIO AND VIDEO, P25, DOI 10.1109/NOSDAV.1997.629332
   TIWARI P, 1996, P 1996 IEEE INT C AC
   Tran DA, 2003, 2003 SYMPOSIUM ON APPLICATIONS AND THE INTERNET, PROCEEDINGS, P172, DOI 10.1109/SAINT.2003.1183046
   Wang YW, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P160, DOI 10.1109/MMCS.1996.534969
NR 28
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2008
VL 4
IS 3
AR 21
DI 10.1145/1386109.1386114
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 351OI
UT WOS:000259433300005
DA 2024-07-18
ER

PT J
AU Luo, HZ
   Gao, YL
   Xue, XY
   Peng, JY
   Fan, JP
AF Luo, Hangzai
   Gao, Yuli
   Xue, Xiangyang
   Peng, Jinye
   Fan, Jianping
TI Incorporating feature hierarchy and boosting to achieve more effective
   classifier training and concept-oriented video summarization and
   skimming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE algorithms; experimentation
ID SCENE SEGMENTATION; EXTRACTION; RETRIEVAL
AB For online medical education purposes, we have developed a novel scheme to incorporate the results of semantic video classification to select the most representative video shots for generating concept-oriented summarization and skimming of surgery education videos. First, salient objects are used as the video patterns for feature extraction to achieve a good representation of the intermediate video semantics. The salient objects are defined as the salient video compounds that can be used to characterize the most significant perceptual properties of the corresponding real world physical objects in a video, and thus the appearances of such salient objects can be used to predict the appearances of the relevant semantic video concepts in a specific video domain. Second, a novel multi-modal boosting algorithm is developed to achieve more reliable video classifier training by incorporating feature hierarchy and boosting to dramatically reduce both the training cost and the size of training samples, thus it can significantly speed up SVM (support vector machine) classifier training. In addition, the unlabeled samples are integrated to reduce the human efforts on labeling large amount of training samples. Finally, the results of semantic video classification are incorporated to enable concept-oriented video summarization and skimming. Experimental results in a specific domain of surgery education videos are provided.
C1 [Luo, Hangzai] E China Normal Univ, Inst Software Engn, Shanghai, Peoples R China.
   [Gao, Yuli; Fan, Jianping] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
   [Xue, Xiangyang] Fudan Univ, Dept Comp Sci, Shanghai, Peoples R China.
   [Peng, Jinye] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
C3 East China Normal University; University of North Carolina; University
   of North Carolina Charlotte; Fudan University; Northwestern
   Polytechnical University
RP Luo, HZ (corresponding author), E China Normal Univ, Inst Software Engn, Shanghai, Peoples R China.
EM jfan@uncc.edu
RI Peng, Jin/HZH-6965-2023
CR Adams B, 2002, IEEE T MULTIMEDIA, V4, P472, DOI 10.1109/TMM.2002.802016
   Alatan AA, 1998, IEEE T CIRC SYST VID, V8, P802, DOI 10.1109/76.735378
   [Anonymous], 2000, ICML
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], ADV LARGE MARGIN CLA
   [Anonymous], EURASIP J ADV SIGNAL
   ARMAN F, 1994, ACM MULTIMEDIA 94, P97
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Chang SF, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P531, DOI 10.1109/ICIP.1998.727321
   CHANG SF, 2002, P INT TYRRH WORKSH D
   Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127
   Correia PL, 2004, IEEE T CIRC SYST VID, V14, P735, DOI 10.1109/TCSVT.2004.826778
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Deshpande S. G., 2001, IEEE Transactions on Multimedia, V3, P432, DOI 10.1109/6046.966115
   Dimitrova N., 2000, ACM MULTIMEDIA, P499
   DJERABA C, 2000, MDM KDD, P73
   DJERABA C, 2002, MULTIMEDIA MINING HI
   EBADOLLAHI S, 2002, P INT C IM PROC LOS
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Fan JP, 2004, IEEE T IMAGE PROCESS, V13, P974, DOI 10.1109/TIP.2004.827232
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   FISCHER S, 1995, ACM MULTIMEDIA, P367
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Gatica-Perez D, 2003, IEEE T CIRC SYST VID, V13, P539, DOI 10.1109/TCSVT.2003.813428
   Greenspan H, 2004, IEEE T PATTERN ANAL, V26, P384, DOI 10.1109/TPAMI.2004.1262334
   Haering N, 2000, IEEE T CIRC SYST VID, V10, P857, DOI 10.1109/76.867923
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   JAIMES A, 2001, INT J IMAGE GRAPHICS, V1, P415
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Kender JR, 1998, PROC CVPR IEEE, P367, DOI 10.1109/CVPR.1998.698632
   Lew M.S., 2001, PRINCIPLES VISUAL IN
   LI Y, 2006, ACM MULTIMEDIA, P53
   Lienhart R, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P685, DOI 10.1109/MMCS.1999.779282
   LIU T, 2004, IEEE INT S MULT SOFT, P574
   Liu Z, 1998, J VLSI SIG PROC SYST, V20, P61, DOI 10.1023/A:1008066223044
   LUO H, 2004, P ACM CIVR, P374
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   QI Y, 2003, INT C MULT EXP LOS A
   Sebe N, 2003, COMPUT VIS IMAGE UND, V92, P141, DOI 10.1016/j.cviu.2003.08.003
   SMITH M, 1995, TUCMUCS95186
   Snoek C., 2003, MULTIMED TOOLS APPL, V25, P5
   Sundaram H, 2002, IEEE T MULTIMEDIA, V4, P482, DOI 10.1109/TMM.2002.802017
   SUNDARAM H, 2002, P INT C IM PROC LOS
   Sundaram Hari., 2002, COMUNICA O APRESENTA, DOI [DOI 10.1145/641007.641042, 10.1145/641007.641042]
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   XIE L, 2003, PATTERN RECOGNITI LE, V24, P767
   Zhang DS, 2004, IEEE T MULTIMEDIA, V6, P450, DOI 10.1109/TMM.2004.827505
   ZHANG H, 1993, INT C MULT SYST LOS, V1, P45
   Zhou W., 2000, ACM Workshops on Multimedia, P213
NR 52
TC 1
Z9 2
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2008
VL 4
IS 1
AR 1
DI 10.1145/1324287.1324288
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 264UK
UT WOS:000253315700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yan, WQ
   Kankanhalli, MS
AF Yan, Wei-Qi
   Kankanhalli, Mohan S.
TI Multimedia simplification for optimized MMS synthesis
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE documentation; languages; multimedia simplification; MMS synthesis;
   soccer video; home care monitoring; hypermedia coherence; mobile phone;
   experiential sampling
ID ADAPTATION
AB We propose a novel transcoding technique called multimedia simplification which is based on experiential sampling. Multimedia simplification helps optimize the synthesis of MMS (multimedia messaging service) messages for mobile phones. Transcoding is useful in overcoming the limitations of these compact devices. The proposed approach aims at reducing the redundancy in the multimedia data captured by multiple types of media sensors. The simplified data is first stored into a gallery for further usage. Once a request for MMS is received, the MMS server makes use of the simplified media from the gallery. The multimedia data is aligned with respect to the timeline for MMS message synthesis. We demonstrate the use of the proposed techniques for two applications, namely, soccer video and home care monitoring video. The MMS sent to the receiver can basically reflect the gist of important events of interest to the user. Our technique is targeted towards users who are interested in obtaining salient multimedia information via mobile devices.
C1 Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
   Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore.
C3 University of California System; University of California Irvine;
   National University of Singapore
RP Yan, WQ (corresponding author), Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
EM weiqi.yan@uci.edu
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
CR Atrey P. K., 2004, P ACM MULT NY US OCT, P408
   Bennett E P., 2003, Proceedings o fACM Multimedia, P177
   Boll S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P37, DOI 10.1145/319463.319468
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   CHEVALLET JP, 2005, P ECIR C SANT COMP, P530
   CHU WT, 2002, P 10 ACM INT C MULT, P57
   Cochran W.G., 1977, Sampling techniques, V3rd ed.
   Coulombe S, 2004, IEEE COMMUN MAG, V42, P120, DOI 10.1109/MCOM.2004.1316543
   Davis Marc., 2004, P 12 ANN ACM INT C M, P188, DOI DOI 10.1145/1027527.1027572
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   Duda R., 1973, Pattern Classification and Scene Analysis
   DUYGULU P, 2003, P ACM SIG C TOR
   DUYGULU P, 2003, P WORKSH MULT CONT D
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Gao S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1307, DOI 10.1109/ICME.2004.1394467
   Jacobs O., 1993, Introduction to control theory, V2nd
   JUN S, 2003, P ACM MULTIMEDIA, P464
   Kankanhalli MS, 2006, IEEE T MULTIMEDIA, V8, P937, DOI 10.1109/TMM.2006.879876
   LIN CY, 2005, P IEEE ISC C KOB
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   Pan J.-Y., 2004, Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P653, DOI [DOI 10.1145/1014052.1014135, 10.1145/1014052, DOI 10.1145/1014052]
   ROSENFELD A, 1969, PICTURE PROCESSING C
   WANG J, 2003, P ACM MULT, P319
   WANG J, 2004, P IEEE ICM C TAIP, P84
   WELCKRAMASURIYA J, 2001, P ACM MULT C NEW YOR
   XIE L, 2002, O IEEE IC C ORL, V4, P4096
   XIE LX, 2004, P IEEE IC C SING
   Xu Peng., 2001, Proceedings of the 2001 IEEE International Conference on Multimedia and Expo (ICME), P721, DOI [10.1109/ICME.2001.1237822, DOI 10.1109/ICME.2001.1237822]
   Yan Wei-Qi., 2002, MULTIMEDIA 02, P107
   ZHANG HJ, 1993, ACM MULTIMEDIA SYSTE, V1, P10
   [No title captured]
NR 31
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2007
VL 3
IS 1
AR 5
DI 10.1145/1198302.1198307
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 230IZ
UT WOS:000250871500005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, H
   Li, M
   Prabhakaran, B
AF Li, H.
   Li, M.
   Prabhakaran, B.
TI Middleware for streaming 3D progressive meshes over lossy networks
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE algorithm; 3D streaming; progressive compression
AB Streaming 3D graphics have been widely used in multimedia applications such as online gaming and virtual reality. However, a gap exists between the zero-loss-tolerance of the existing compression schemes and the lossy network transmissions. In this article, we propose a generic 3D middleware between the 3D application layer and the transport layer for the transmission of triangle-based progressively compressed 3D models. Significant features of the proposed middleware include. 1) handling 3D compressed data streams from multiple progressive compression techniques. 2) considering end user hardware capabilities for effectively saving the data size for network delivery. 3) a minimum cost dynamic reliable set selector to choose the transport protocol for each sublayer based on the real-time network traffic. Extensive simulations with TCP/UDP and SCTP show that the proposed 3D middleware can achieve the dual objectives of maintaining low transmission delay and small distortion, and thus supporting high quality 3D streaming with high flexibility.
C1 Univ Texas, Dept Comp Sci, Richardson, TX 75083 USA.
C3 University of Texas System; University of Texas Dallas
RP Li, H (corresponding author), Univ Texas, Dept Comp Sci, Richardson, TX 75083 USA.
EM hxl015300@utdallas.edu; mingli@utdallas.edu; praba@utdallas.edu
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   ALLIEZ P, 2001, P SIGGRAPH
   Alregib G, 2005, ACM T GRAPHIC, V24, P182, DOI 10.1145/1061347.1061349
   ALREGIB G, 2004, P 9 INT C 3D WEB TEC
   ALREGIB G, 2002, P INFOCOM
   ALREGIB G, 2003, P IEEE INT C MULT EX
   ALREGIB G, 2002, P INT C IM PROC
   Bischoff S, 2002, COMPUT GRAPH-UK, V26, P665, DOI 10.1016/S0097-8493(02)00122-X
   Chen Z., 2003, Proc. Web3D, P161
   Choi JS, 2000, IEEE T CIRC SYST VID, V10, P312, DOI 10.1109/76.825730
   CHOW M, 1997, P IEEE VIS, P346
   DEERING M, 1995, P 22 ANN C COMP GRAP, P13
   Devillers O, 2000, IEEE VISUAL, P319, DOI 10.1109/VISUAL.2000.885711
   Fleishman S, 2003, ACM T GRAPHIC, V22, P997, DOI 10.1145/944020.944023
   GANDOIN P, 2002, ACM T GRAPH
   GARLAND M, 1997, P SIGGRAPH, P2096
   HOPPE H, 1998, MSRTR9802
   HOPPE H, 1998, P SIGGRAPH, P99
   Isenburg M, 2003, ACM T GRAPHIC, V22, P935, DOI 10.1145/882262.882366
   ISENBURG M, 2002, CODING POLYGON MESHE
   KHODAKOVSKY A, 2000, P SIGGRAPH
   Li H., 2004, Proceedings of DMS/VLC'04, P275
   LI J, 1997, MULTIMEDIA COMPUTING
   LIPMAN R, 2002, P INT S AUT ROB CONS, P53
   MARTIN IM, 2002, P IEEE INT C MULT EX
   Mascolo S., 2000, TCP WESTWOOD CONGEST
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   PORTEL M, 2003, IEEE COMPUT GRAPH, V23, P14
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   ROSSIGNAC J, 2004, HDB DISCRETE COMPUTA, pCH54
   SOUTHERN R, 2001, P WEB3D S
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   TAUBIN G, 1998, P SIGGRAPH 98, P123
   VALETTE S, 2004, IEEE T VIS COMPUT GR, P10
   YAN Z, 2001, IEEE T CIRC SYST VID, P11
   Yang S, 2004, IEEE T CIRC SYST VID, V14, P1249, DOI 10.1109/TCSVT.2004.835153
NR 36
TC 12
Z9 16
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2006
VL 2
IS 4
BP 282
EP 317
DI 10.1145/1201730.1201733
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 230IY
UT WOS:000250871400003
DA 2024-07-18
ER

PT J
AU Du, YC
   Wang, M
   Lu, ZB
   Zhou, WG
   Li, HQ
AF Du, Yongchao
   Wang, Min
   Lu, Zhenbo
   Zhou, Wengang
   Li, Houqiang
TI Weakly Supervised Hashing with Reconstructive Cross-modal Attention
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Weakly supervised hashing; attention
ID QUANTIZATION
AB On many popular social websites, images are usually associated with some meta-data such as textual tags, which involve semantic information relevant to the image and can be used to supervise the representation learning for image retrieval. However, these user-provided tags are usually polluted by noise, therefore the main challenge lies in mining the potential useful information from those noisy tags. Many previous works simply treat different tags equally to generate supervision, which will inevitably distract the network learning. To this end, we propose a new framework, termed as Weakly Supervised Hashing with Reconstructive Cross-modal Attention (WSHRCA), to learn compact visual-semantic representation with more reliable supervision for retrieval task. Specifically, for each image-tag pair, the weak supervision from tags is refined by cross-modal attention, which takes image feature as query to aggregate the most content-relevant tags. Therefore, tags with relevant content will be more prominent while noisy tags will be suppressed, which provides more accurate supervisory information. To improve the effectiveness of hash learning, the image embedding in WSHRCA is reconstructed from hash code, which is further optimized by cross-modal constraint and explicitly improves hash learning. The experiments on two widely-used datasets demonstrate the effectiveness of our proposed method for weakly-supervised image retrieval. The code is available at https://github.com/duyc168/weakly-supervised-hashing.
C1 [Du, Yongchao; Zhou, Wengang; Li, Houqiang] Univ Sci & Technol China, Hefei 230027, Peoples R China.
   [Wang, Min; Lu, Zhenbo] Hefei Comprehens Natl Sci Ctr, Inst Artificial Intelligence, Hefei, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Du, YC (corresponding author), Univ Sci & Technol China, Hefei 230027, Peoples R China.
EM ycdu2020@mail.ustc.edu.cn; wangmin@iai.ustc.edu.cn;
   luzhenbo_2018@163.com; zhwg@ustc.edu.cn; lihq@ustc.edu.cn
RI li, wenjing/JMP-7498-2023; chen, chen/JGD-3057-2023; Li,
   Jiawei/JOJ-9277-2023
OI Wang, Min/0000-0003-3048-6980
FU National Natural Science Foundation of China [62102128, 62021001];
   Fundamental Research Funds for the Central Universities [WK3490000007];
   GPU cluster built by MCC Lab of Information Science and Technology
   Institution; Supercomputing Center of the USTC
FX This work was supported in part by the National Natural Science
   Foundation of China under Contract 62102128 and 62021001, and in part by
   the Fundamental Research Funds for the Central Universities under
   contract WK3490000007. It was also supported by the GPU cluster built by
   MCC Lab of Information Science and Technology Institution and the
   Supercomputing Center of the USTC.
CR Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124
   Cao Y, 2018, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2018.00134
   Cao Y, 2017, PROC CVPR IEEE, P916, DOI 10.1109/CVPR.2017.104
   Cao Y, 2016, AAAI CONF ARTIF INTE, P3457
   Chiu CY, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2990504
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Cui H, 2020, IEEE T IMAGE PROCESS, V29, P1271, DOI 10.1109/TIP.2019.2940693
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A., 2020, INT C LEARNING REPRE
   Gattupalli V, 2019, PROC CVPR IEEE, P10367, DOI 10.1109/CVPR.2019.01062
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hoe JT, 2021, ADV NEUR IN, V34
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jang Y K., 2021, IEEE INT C COMPUTER, P12085
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jin L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P916, DOI 10.1145/3394171.3414022
   Klein B, 2019, PROC CVPR IEEE, P5036, DOI 10.1109/CVPR.2019.00518
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li K, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152126
   Li WJ, 2016, IJCAI, P1711
   Li YQ, 2021, AAAI CONF ARTIF INTE, V35, P2002
   Liu DR, 2013, ALLERGY ASTHMA CL IM, V9, DOI 10.1186/1710-1492-9-30
   Liu SG, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3355394
   Matsui Y, 2018, ITE TRANS MEDIA TECH, V6, P2, DOI 10.3169/mta.6.2
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Min Wang, 2019, ACM T MULTIM COMPUT, V15, P1
   Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388
   Qiu ZX, 2021, Arxiv, DOI arXiv:2105.06138
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen L, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3356316
   Shen YM, 2020, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR42600.2020.00289
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang JH, 2018, IEEE T CIRC SYST VID, V28, P2730, DOI 10.1109/TCSVT.2017.2715227
   Tian Qi, 2021, IEEE T MULTIMEDIA
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang JP, 2021, AAAI CONF ARTIF INTE, V35, P2755
   Weiss Yair, 2008, P ADV NEURAL INFORM, V4
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Yang EK, 2019, PROC CVPR IEEE, P2941, DOI 10.1109/CVPR.2019.00306
   Yang EK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1064
   Yuan L, 2020, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR42600.2020.00315
   Zhang HW, 2016, AAAI CONF ARTIF INTE, P3669
   Zhang Junjie, 2018, P AAAI C ARTIFICIAL
   Zhang T, 2014, PR MACH LEARN RES, V32, P838
   Zhu H, 2016, AAAI CONF ARTIF INTE, P2415
   Zhu L, 2021, IEEE T CIRC SYST VID, V31, P1478, DOI 10.1109/TCSVT.2020.3001583
NR 50
TC 0
Z9 0
U1 4
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2023
VL 19
IS 6
AR 208
DI 10.1145/3589185
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N3AP4
UT WOS:001035785200031
DA 2024-07-18
ER

PT J
AU Man, X
   Shao, J
   Chen, F
   Zhang, M
   Shen, HT
AF Man, Xin
   Shao, Jie
   Chen, Feiyu
   Zhang, Mingxing
   Shen, Heng Tao
TI TEVL: Trilinear Encoder for Video-language Representation Learning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Self-supervised learning; vision and language (V-L) representation
   learning; pre-training techniques; trilinear encoder
AB Pre-training model on large-scale unlabeled web videos followed by task-specific fine-tuning is a canonical approach to learning video and language representations. However, the accompanying Automatic Speech Recognition (ASR) transcripts in these videos are directly transcribed from audio, which may be inconsistent with visual information and would impair the language modeling ability of the model. Meanwhile, previous V-L models fuse visual and language modality features using single- or dual-stream architectures, which are not suitable for the current situation. Besides, traditional V-L research focuses mainly on the interaction between vision and language modalities and leaves the modeling of relationships within modalities untouched. To address these issues andmaintain a smallmanual labor cost, we add automatically extracted dense captions as a supplementary text and propose a new trilinear video-language interaction framework TEVL (Trilinear Encoder for Video-Language representation learning). TEVL contains three unimodal encoders, a TRIlinear encOder (TRIO) block, and a temporal Transformer. TRIO is specially designed to support effective text-vision-text interaction, which encourages inter-modal cooperation while maintaining intra-modal dependencies. We pre-train TEVL on the HowTo100M and TV datasets with four task objectives. Experimental results demonstrate that TEVL can learn powerful video-text representation and achieve competitive performance on three downstream tasks, including multimodal video captioning, video Question Answering (QA), as well as video and language inference. Implementation code is available at https://github.com/Gufrannn/TEVL.
C1 [Man, Xin; Shao, Jie; Zhang, Mingxing; Shen, Heng Tao] Univ Elect Sci & Technol China, 2006 Xiyuan Ave, Chengdu, Peoples R China.
   [Chen, Feiyu] Univ Elect Sci & Technol China, 2006 Xiyuan Ave, Chengdu, Peoples R China.
   [Chen, Feiyu] Intelligent Terminal Key Lab Sichuan Prov, Yibin, Peoples R China.
   [Zhang, Mingxing; Shen, Heng Tao] Sichuan Artificial Intelligence Res Inst, Yibin, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China
RP Man, X; Shao, J (corresponding author), Univ Elect Sci & Technol China, 2006 Xiyuan Ave, Chengdu, Peoples R China.
EM manxin@std.uestc.edu.cn; shaojie@uestc.edu.cn; chenfeiyu@uestc.edu.cn;
   minsingcheong@gmail.com; shenhengtao@hotmail.com
RI Shen, Heng Tao/ABD-5331-2021
OI Chen, Feiyu/0000-0002-0928-6899
FU National Natural Science Foundation of China [61832001, 62276047]; Open
   Fund of Intelligent Terminal Key Laboratory of Sichuan Province
   [SCITLAB-20008]; Sichuan Science and Technology Program [2022JDRC0064]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61832001 and No. 62276047), Open Fund of Intelligent Terminal
   Key Laboratory of Sichuan Province (No. SCITLAB-20008), and Sichuan
   Science and Technology Program (No. 2022JDRC0064).
CR Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Chadha A, 2020, Arxiv, DOI arXiv:2011.07735
   Chen JW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2001, DOI 10.1109/ICCV48922.2021.00203
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong JF, 2022, IEEE T CIRC SYST VID, V32, P5680, DOI 10.1109/TCSVT.2022.3150959
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao LL, 2022, IEEE T IMAGE PROCESS, V31, P202, DOI 10.1109/TIP.2021.3120867
   Ging Simon, 2020, ANN C NEURAL INFORM
   Gupta S, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3436494
   Li LH, 2019, Arxiv, DOI [arXiv:1908.03557, DOI 10.48550/ARXIV.1908.03557]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2485
   Jie Lei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P447, DOI 10.1007/978-3-030-58589-1_27
   Jingzhou Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10897, DOI 10.1109/CVPR42600.2020.01091
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Jozefowicz R, 2016, Arxiv, DOI arXiv:1602.02410
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Kim H., 2020, P 58 ANN M ACL, P4812
   Kim H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3606
   Kim J, 2019, IEEE IJCNN, DOI [10.1109/ijcnn.2019.8852087, 10.1007/s00779-019-01299-w]
   Kim J, 2019, PROC CVPR IEEE, P8329, DOI 10.1109/CVPR.2019.00853
   Korbar B, 2020, Arxiv, DOI arXiv:2006.07203
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lei J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1369
   Lei Jie, 2020, P 58 ANN M ASS COMPU, P8211
   Li G., 2021, arXiv
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li LJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2046
   Li Linjie, 2021, ANN C NEURAL INFORM
   Li MH, 2022, IEEE T CIRC SYST VID, V32, P5438, DOI 10.1109/TCSVT.2022.3149329
   Li YH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3473140
   Li YJ, 2022, IEEE T CIRC SYST VID, V32, P3190, DOI 10.1109/TCSVT.2021.3103782
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin K, 2022, PROC CVPR IEEE, P17928, DOI 10.1109/CVPR52688.2022.01742
   Liu Yinhan, 2019, ARXIV190711692
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Lu JS, 2019, ADV NEUR IN, V32
   Luo JJ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5600, DOI 10.1145/3474085.3475703
   Maharaj T, 2017, PROC CVPR IEEE, P7359, DOI 10.1109/CVPR.2017.778
   Messina N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3451390
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Pan YW, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P7070, DOI 10.1145/3503161.3551581
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Radford A, 2021, PR MACH LEARN RES, V139
   Shin M, 2021, Arxiv, DOI arXiv:2110.06476
   Sun C, 2019, Arxiv, DOI arXiv:1906.05743
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Tang JH, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3291925
   Tang ZN, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2415
   Tian FZ, 2022, IEEE T CIRC SYST VID, V32, P1751, DOI 10.1109/TCSVT.2021.3080928
   Tilk O, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P683
   Do T, 2019, IEEE I CONF COMP VIS, P392, DOI 10.1109/ICCV.2019.00048
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu YH, 2016, Arxiv, DOI [arXiv:1609.08144, DOI 10.48550/ARXIV.1609.08144]
   Yang LJ, 2017, PROC CVPR IEEE, P1978, DOI 10.1109/CVPR.2017.214
   Yang ZK, 2020, IEEE WINT CONF APPL, P1545, DOI [10.1109/wacv45572.2020.9093596, 10.1109/WACV45572.2020.9093596]
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Yuan ZQ, 2021, IEEE T MULTIMEDIA, V23, P1744, DOI 10.1109/TMM.2020.3002667
   Zeng PP, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P5210, DOI 10.1145/3503161.3548024
   Zeng PP, 2022, IEEE T IMAGE PROCESS, V31, P5936, DOI 10.1109/TIP.2022.3205212
   Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
   Zhu JK, 2023, IEEE T CIRC SYST VID, V33, P4362, DOI 10.1109/TCSVT.2023.3235523
   Zhu L., 2020, P IEEE CVF C COMP VI, DOI 10.1109/CVPR42600.2020.00877
   Zolfaghari M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1430, DOI 10.1109/ICCV48922.2021.00148
NR 73
TC 1
Z9 1
U1 11
U2 15
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2023
VL 19
IS 5
SU S
AR 168
DI 10.1145/3585388
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L0SK0
UT WOS:001020437100004
DA 2024-07-18
ER

PT J
AU Abdussalam, A
   Ye, ZF
   Hawbani, A
   Al-Qatf, M
   Khan, R
AF Abdussalam, Amr
   Ye, Zhongfu
   Hawbani, Ammar
   Al-Qatf, Majjed
   Khan, Rashid
TI NumCap: A Number-controlled Multi-caption Image Captioning Network
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Numbers incorporation strategy; encoder-decoder framework; image
   captioning; order-embedding
ID ATTENTION; GENERATION
AB Image captioning is a promising task that attracted researchers in the last few years. Existing image captioning models are primarily trained to generate one caption per image. However, an image may contain rich contents, and one caption cannot express its full details. A better solution is to describe an image with multiple captions, with each caption focusing on a specific aspect of the image. In this regard, we introduce a new number-based image captioning model that describes an image with multiple sentences. An image is annotated with multiple ground-truth captions; thus, we assign an external number to each caption to distinguish its order. Given an image-number pair as input, we could achieve different captions for the same image under different numbers. First, a number is attached to the image features to form an image-number vector (INV). Then, this vector and the corresponding caption are embedded using the order-embedding approach. Afterward, the INV's embedding is fed to a language model to generate the caption. To show the efficiency of the numbers incorporation strategy, we conduct extensive experiments using MS-COCO, Flickr30K, and Flickr8K datasets. The proposed model attains 24.1 in METEOR on MS-COCO. The achieved results demonstrate that our method is competitive with a range of state-of-the-art models and validate its ability to produce different descriptions under different given numbers.
C1 [Abdussalam, Amr; Ye, Zhongfu; Khan, Rashid] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Peoples R China.
   [Hawbani, Ammar; Al-Qatf, Majjed] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Abdussalam, A (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Peoples R China.
EM amr2010@mail.ustc.edu.cn; yezf@ustc.edu.cn; anmande@ustc.edu.cn;
   malqatf@mail.ustc.edu.cn; rashidkhan@mail.ustc.edu.cn
RI khan, Rashid/HSF-9463-2023; Hawbani, Ammar/S-3356-2019
OI khan, Rashid/0000-0002-2410-044X; Hawbani, Ammar/0000-0002-1069-3993;
   ALQATF, MAJJED/0000-0002-1796-344X
FU CAS-TWAS President's Fellowship
FX This work was supported by the CAS-TWAS President's Fellowship for Ph.D.
CR Al-Qatf M, 2023, IEEE T MULTIMEDIA, V25, P5984, DOI 10.1109/TMM.2022.3202690
   Amirian S, 2020, IEEE ACCESS, V8, P218386, DOI 10.1109/ACCESS.2020.3042484
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Bae JW, 2022, IEEE ACCESS, V10, P45219, DOI 10.1109/ACCESS.2022.3169781
   Cui CR, 2017, MULTIMED TOOLS APPL, V76, P8831, DOI 10.1007/s11042-016-3512-1
   Dai B, 2017, IEEE I CONF COMP VIS, P2989, DOI 10.1109/ICCV.2017.323
   Dash SK, 2020, ARAB J SCI ENG, V45, P3025, DOI 10.1007/s13369-019-04262-2
   Dutta T, 2019, IEEE T IMAGE PROCESS, V28, P5953, DOI 10.1109/TIP.2019.2923287
   Fu JL, 2017, APSIPA TRANS SIGNAL, V6, DOI 10.1017/ATSIP.2017.12
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Guo LT, 2020, IEEE T MULTIMEDIA, V22, P2149, DOI 10.1109/TMM.2019.2951226
   Guo R, 2019, MULTIMED TOOLS APPL, V78, P24321, DOI 10.1007/s11042-018-7118-7
   Han ZM, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109512
   Hanjie Wu, 2022, ACM Transactions on Multimedia Computing, Communications and Applications, V18, DOI 10.1145/3478024
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Huang YQ, 2020, IEEE T IMAGE PROCESS, V29, P4013, DOI 10.1109/TIP.2020.2969330
   Ji JZ, 2020, IEEE T IMAGE PROCESS, V29, P7615, DOI 10.1109/TIP.2020.3004729
   Jian MW, 2021, INFORM SCIENCES, V576, P819, DOI 10.1016/j.ins.2021.08.069
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jiang WT, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3460474
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Li XL, 2021, IEEE T CYBERNETICS, V51, P913, DOI 10.1109/TCYB.2019.2914351
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H, 2021, IEEE T IMAGE PROCESS, V30, P2450, DOI 10.1109/TIP.2021.3051476
   Liu MF, 2022, IEEE T CYBERNETICS, V52, P1247, DOI 10.1109/TCYB.2020.2997034
   Lu HM, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3422668
   Mao YZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4258
   Qi GJ, 2022, IEEE T PATTERN ANAL, V44, P2168, DOI 10.1109/TPAMI.2020.3031898
   Shen J, 2011, ACM MULTIMEDIA, P639, DOI DOI 10.1145/2072298.2072405
   Shen JL, 2016, MULTIMEDIA SYST, V22, P99, DOI 10.1007/s00530-014-0399-4
   Tang JH, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2501643.2501651
   Vendrov I., 2016, ICLR, P1
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wang Q., 2018, P IEEECVF C COMPUTER, P1
   Wang S, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3314577
   Wang XJ, 2010, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2010.5540046
   Wei HY, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3439734
   Wu J, 2021, IEEE T MULTIMEDIA, V23, P2413, DOI 10.1109/TMM.2020.3011317
   Wu LX, 2020, IEEE T MULTIMEDIA, V22, P808, DOI 10.1109/TMM.2019.2931815
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xiao XY, 2019, IEEE T MULTIMEDIA, V21, P2942, DOI 10.1109/TMM.2019.2915033
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu N, 2020, IEEE T MULTIMEDIA, V22, P1372, DOI 10.1109/TMM.2019.2941820
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yang L, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3386725
   Yang M, 2020, IEEE T IMAGE PROCESS, V29, P9627, DOI 10.1109/TIP.2020.3028651
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Yu LT, 2022, IEEE T MULTIMEDIA, V24, P1775, DOI 10.1109/TMM.2021.3072479
   Yu NG, 2019, IEEE T IMAGE PROCESS, V28, P2743, DOI 10.1109/TIP.2018.2889922
   Yuan J, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3394955
   Zhang J, 2021, IEEE T MULTIMEDIA, V23, P92, DOI 10.1109/TMM.2020.2976552
   Zhang JX, 2019, NEURAL PROCESS LETT, V50, P1891, DOI 10.1007/s11063-019-09978-8
   Zhang MX, 2019, IEEE T IMAGE PROCESS, V28, P32, DOI 10.1109/TIP.2018.2855415
   Zhao WT, 2021, IEEE T IMAGE PROCESS, V30, P1180, DOI 10.1109/TIP.2020.3042086
   Zhou L, 2020, IEEE T IMAGE PROCESS, V29, P694, DOI 10.1109/TIP.2019.2928144
   Zia U, 2020, NEURAL COMPUT APPL, V32, P10471, DOI 10.1007/s00521-019-04587-x
NR 61
TC 2
Z9 2
U1 17
U2 35
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUL
PY 2023
VL 19
IS 4
AR 148
DI 10.1145/3576927
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FX8
UT WOS:001011937600010
DA 2024-07-18
ER

PT J
AU Wang, K
   Ding, CX
   Pang, JX
   Xu, XM
AF Wang, Kan
   Ding, Changxing
   Pang, Jianxin
   Xu, Xiangmin
TI Context Sensing Attention Network for Video-based Person
   Re-identification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Video-based person re-identification; channel attention; feature
   aggregation
AB Video-based person re-identification (ReID) is challenging due to the presence of various interferences in video frames. Recent approaches handle this problem using temporal aggregation strategies. In this work, we propose a novel Context Sensing Attention Network (CSA-Net), which improves both the frame feature extraction and temporal aggregation steps. First, we introduce the Context Sensing Channel Attention (CSCA) module, which emphasizes responses from informative channels for each frame. These informative channels are identified with reference not only to each individual frame, but also to the content of the entire sequence. Therefore, CSCA explores both the individuality of each frame and the global context of the sequence. Second, we propose the Contrastive Feature Aggregation (CFA) module, which predicts frame weights for temporal aggregation. Here, the weight for each frame is determined in a contrastive manner: i.e., not only by the quality of each individual frame, but also by the average quality of the other frames in a sequence. Therefore, it effectively promotes the contribution of relatively good frames. Extensive experimental results on four datasets show that CSA-Net consistently achieves state-of-the-art performance.
C1 [Wang, Kan; Pang, Jianxin] UBTECH Robot Inc, UBTECH Res, Floor 13,Bldg B1,Nanshan iPark,1001 Xueyuan Ave, Shenzhen 518055, Peoples R China.
   [Wang, Kan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Guangdong Prov Key Lab Robot & Intelligent Syst, Shenzhen 518055, Peoples R China.
   [Ding, Changxing] South China Univ Technol, Room 601,Bldg 30,381 Wushan Rd, Guangzhou 510641, Peoples R China.
   [Xu, Xiangmin] South China Univ Technol, Sch Future Technol, Room 626,Bldg 30,381 Wushan Rd, Guangzhou 510641, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; South China University of Technology; South China University of
   Technology
RP Ding, CX (corresponding author), South China Univ Technol, Room 601,Bldg 30,381 Wushan Rd, Guangzhou 510641, Peoples R China.
EM kan.wang@ubtrobot.com; chxding@scut.edu.cn; walton@ubtrobot.com;
   xmxu@scut.edu.cn
OI Pang, Jianxin/0000-0002-3985-5802
FU National Natural Science Foundation of China [62076101, U2013601];
   Guangdong Provincial Key Laboratory of Human Digital Twin
   [2022B1212010004]; Key-Area Research and Development Program of
   Guangdong Province, China [2019B010154003]; Program of Guangdong
   Provincial Key Laboratory of Robot Localization and Navigation
   Technology [2020B121202011]; Natural Science Foundation of China
   [U21A20487]; Shenzhen Technology Project [JCYJ20180507182610734,
   KCXFZ20201221173411032, Y795001001]; Guangdong Technology Project
   [2016B010125003]; CAS Key Technology Talent Program
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62076101 and U2013601, the Guangdong Provincial Key
   Laboratory of Human Digital Twin (2022B1212010004), and Key-Area
   Research and Development Program of Guangdong Province, China
   (2019B010154003), and the Program of Guangdong Provincial Key Laboratory
   of Robot Localization and Navigation Technology (2020B121202011), and
   the Natural Science Foundation of China (U21A20487), and Shenzhen
   Technology Project (JCYJ20180507182610734, KCXFZ20201221173411032,
   Y795001001), and CAS Key Technology Talent Program, and Guangdong
   Technology Project (No. 2016B010125003).
CR Aich A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P152, DOI 10.1109/ICCV48922.2021.00022
   Chen CQ, 2022, IEEE T CIRC SYST VID, V32, P6100, DOI 10.1109/TCSVT.2022.3157130
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen ZQ, 2020, AAAI CONF ARTIF INTE, V34, P10591
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding CX, 2022, IEEE T PATTERN ANAL, V44, P1474, DOI 10.1109/TPAMI.2020.3024900
   Eom C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12016, DOI 10.1109/ICCV48922.2021.01182
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fang PF, 2021, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV48630.2021.00051
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Gao YJ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5257, DOI 10.1145/3474085.3475643
   Ge WH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3644, DOI 10.1145/3474085.3475382
   Gu XQ, 2022, IEEE T IMAGE PROCESS, V31, P3908, DOI 10.1109/TIP.2022.3175593
   Gu XQ, 2019, IEEE I CONF COMP VIS, P9646, DOI 10.1109/ICCV.2019.00974
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P660, DOI 10.1007/978-3-030-58598-3_39
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou RB, 2021, PROC CVPR IEEE, P2014, DOI 10.1109/CVPR46437.2021.00205
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu K., 2022, Pattern Recognition and Computer Vision, P42, DOI [DOI 10.1007/978-3-031-18907-4_4, 10.1007/978-3-031-18907-4_4]
   KANWANG P, 2021, IEEE T IMAGE PROCESS, V30, P3405, DOI DOI 10.1109/TIP.2021.3060909
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li JN, 2020, IEEE T IMAGE PROCESS, V29, P4461, DOI 10.1109/TIP.2020.2972108
   Li JN, 2019, AAAI CONF ARTIF INTE, P8618
   Li ML, 2020, IEEE WINT CONF APPL, P3365, DOI [10.1109/WACV45572.2020.9093413, 10.1109/wacv45572.2020.9093413]
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li ZJ, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3362988
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Liu JW, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231741
   Liu LC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P227, DOI 10.1145/3474085.3475566
   Liu XH, 2021, PROC CVPR IEEE, P13329, DOI 10.1109/CVPR46437.2021.01313
   Liu YH, 2019, AAAI CONF ARTIF INTE, P8786
   Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499
   MATIYALI N, 2020, P IEEECVF WINTER C A, P2655
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Pang B, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3485061
   Qin ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P763, DOI 10.1109/ICCV48922.2021.00082
   Raychaudhuri Dripta S., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P258, DOI 10.1007/978-3-030-58583-9_16
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Ruan WJ, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3402666
   Ruibing Hou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P388, DOI 10.1007/978-3-030-58595-2_24
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen C, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3309881
   Song GL, 2018, AAAI CONF ARTIF INTE, P7347
   Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tang ZM, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3501405
   Wang HZ, 2021, NEUROCOMPUTING, V463, P226, DOI 10.1016/j.neucom.2021.08.053
   Wang HR, 2021, IEEE T IMAGE PROCESS, V30, P6583, DOI 10.1109/TIP.2021.3096333
   Wang HR, 2022, IEEE T NEUR NET LEAR, V33, P145, DOI 10.1109/TNNLS.2020.3027589
   Wang K., 2022, P ASIAN C COMPUTER V, P177
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P3416, DOI 10.1109/TIP.2019.2959923
   Wang PF, 2023, IEEE T INTELL TRANSP, V24, P1075, DOI 10.1109/TITS.2022.3141885
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xinqian Gu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P228, DOI 10.1007/978-3-030-58536-5_14
   Xu S, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3473340
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yan YC, 2020, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR42600.2020.00297
   Yang JR, 2020, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR42600.2020.00335
   Yang X, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3089249
   Zhang GW, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P516, DOI 10.1145/3474085.3475202
   Zhang WY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5231, DOI 10.1145/3474085.3475640
   Zhang ZZ, 2020, INT CONF CONDIT MON, P404, DOI 10.1109/CVPR42600.2020.01042
   Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 74
TC 2
Z9 2
U1 9
U2 15
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUL
PY 2023
VL 19
IS 4
AR 143
DI 10.1145/3573203
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FX8
UT WOS:001011937600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, YP
   Yang, Q
   Xu, YL
   Yang, L
AF Liu, Yipeng
   Yang, Qi
   Xu, Yiling
   Yang, Le
TI Point Cloud Quality Assessment: Dataset Construction and Learning-based
   No-reference Metric
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Blind quality assessment; point cloud; large-scale dataset; sparse
   convolution; learning-based metric
ID IMAGE; HISTOGRAMS; ERROR
AB Full-reference (FR) point cloud quality assessment (PCQA) has achieved impressive progress in recent years. However, in many cases, obtaining the reference point clouds is difficult, so no-reference (NR) metrics have become a research hotspot. Few researches about NR-PCQA are carried out due to the lack of a large-scale PCQA dataset. In this article, we first build a large-scale PCQA dataset named LS-PCQA, which includes 104 reference point clouds and more than 22,000 distorted samples. In the dataset, each reference point cloud is augmented with 31 types of impairments (e.g., Gaussian noise, contrast distortion, local missing, and compression loss) at 7 distortion levels. Besides, each distorted point cloud is assigned with a pseudo-quality score as its substitute of Mean Opinion Score. Inspired by the hierarchical perception system and considering the intrinsic attributes of point clouds, we propose a NR metric ResSCNN based on sparse convolutional neural network (CNN) to accurately estimate the subjective quality of point clouds. We conduct several experiments to evaluate the performance of the proposed NR metric. The results demonstrate that ResSCNN exhibits the state-of-the-art performance among all the existing NR-PCQA metrics and even outperforms some FR metrics. The dataset presented in this work will be made publicly accessible at http://smt.sjtu.edu.cn. The source code for the proposed ResSCNN can be found at https://github.com/lyp22/ResSCNN.
C1 [Liu, Yipeng; Yang, Qi; Xu, Yiling] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Dongchuan Rd 800, Shanghai, Peoples R China.
   [Yang, Le] Univ Canterbury, Dept Elect & Comp Engn, Christchurch 8041, New Zealand.
C3 Shanghai Jiao Tong University; University of Canterbury
RP Xu, YL (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Dongchuan Rd 800, Shanghai, Peoples R China.
EM liuyipeng@sjtu.edu.cn; yang_littleqi@sjtu.edu.cn; yl.xu@sjtu.edu.cn;
   le.yang@canterbury.ac.nz
RI Yang, Le/GZG-6603-2022
OI Yang, Le/0000-0001-7945-6323; Yang, Qi/0000-0002-4274-3457
FU National Key Research and Development Program of China [2018YFE0206700];
   National Natural Science Foundation of China [61971282, U20A20185]
FX This article is supported in part by National Key Research and
   Development Program of China (Grant No. 2018YFE0206700), National
   Natural Science Foundation of China (Grants No. 61971282 and No.
   U20A20185).
CR Alexiou E, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123121
   Alexiou E, 2020, IEEE INT CONF MULTI
   Alexiou E, 2018, IEEE INT CON MULTI
   [Anonymous], Image Video Quality Assessment at LIVELaboratory for Image Video Engineering
   [Anonymous], MPEG STATIC OBJECT S
   [Anonymous], 2015, SIGNAL IMAGE PROCESS
   Bai S, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102759
   Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Demisse GG, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3176649
   Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Duan HY, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351786
   Gao F, 2016, SIGNAL PROCESS, V124, P210, DOI 10.1016/j.sigpro.2015.08.012
   Graham B, 2017, Arxiv, DOI arXiv:1706.01307
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   ITU-R, 2012, ITU-R Recommendation BT.500-13
   ITU-T P., 2012, P1401 ITUT, P1401
   Javaheri A, 2021, Arxiv, DOI arXiv:2108.02481
   Javaheri A, 2021, IEEE T MULTIMEDIA, V23, P4049, DOI 10.1109/TMM.2020.3037481
   Javaheri A, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123087
   Javaloy A., 2021, Proc. ICLR, P1
   Jiang QP, 2020, IEEE T INSTRUM MEAS, V69, P9784, DOI 10.1109/TIM.2020.3005111
   Jiang QP, 2020, IEEE T INSTRUM MEAS, V69, P7398, DOI 10.1109/TIM.2020.2984928
   Jiang QP, 2018, IEEE T MULTIMEDIA, V20, P2035, DOI 10.1109/TMM.2017.2763321
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Khoury M, 2017, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2017.26
   Liu Q, 2021, IEEE T CIRC SYST VID, V31, P4645, DOI 10.1109/TCSVT.2021.3100282
   Liu Q, 2021, IEEE T IMAGE PROCESS, V30, P6623, DOI 10.1109/TIP.2021.3096060
   Liu Qi, 2022, IEEE T VISUAL COMPUT, V2022, P1
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mekuria Rufael, 2016, ISOIEC MPEG W16332
   Meynet G, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123147
   Meynet G, 2019, INT WORK QUAL MULTIM
   Min XK, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3470970
   Min XK, 2019, IEEE T INTELL TRANSP, V20, P2879, DOI 10.1109/TITS.2018.2868771
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P6054, DOI 10.1109/TIP.2020.2988148
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P3790, DOI 10.1109/TIP.2020.2966081
   Min XK, 2019, IEEE T MULTIMEDIA, V21, P2319, DOI 10.1109/TMM.2019.2902097
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Nouri Anass, 2017, TECHNICAL REPORT
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Su HL, 2019, IEEE IMAGE PROC, P3182, DOI [10.1109/ICIP.2019.8803298, 10.1109/icip.2019.8803298]
   Sun J, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3282833
   Sun W, 2020, IEEE J-STSP, V14, P64, DOI 10.1109/JSTSP.2019.2955024
   Sun Wei, 2021, P IEEE INT C MULTIME, P1
   Tao WX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5266, DOI 10.1145/3474085.3475645
   Tian Dong, 2017, ISOIEC JTC M74008
   Tombari F., 2010, P ACM WORKSH 3D OBJ, P57, DOI DOI 10.1145/1877808.1877821
   Torlig EM, 2018, PROC SPIE, V10752, DOI 10.1117/12.2322741
   Video Quality Experts Group, 2010, P VQEG M
   Viola I, 2020, IEEE SIGNAL PROC LET, V27, P1660, DOI 10.1109/LSP.2020.3024065
   Viola I, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123089
   VQEG, 2000, VQEG M OTT CAN MAR
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2020, IEEE T IMAGE PROCESS, V29, P7414, DOI 10.1109/TIP.2020.3002478
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang Q, 2022, Arxiv, DOI arXiv:2103.02850
   Yang Q, 2022, IEEE T PATTERN ANAL, V44, P3015, DOI 10.1109/TPAMI.2020.3047083
   Yang Q, 2022, PROC CVPR IEEE, P21147, DOI 10.1109/CVPR52688.2022.02050
   Yang Q, 2021, IEEE T MULTIMEDIA, V23, P3877, DOI 10.1109/TMM.2020.3033117
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhang YJ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1230, DOI 10.1145/3474085.3475294
   Zhang ZC, 2022, Arxiv, DOI arXiv:2107.02041
NR 73
TC 9
Z9 10
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2023
VL 19
IS 2
SU S
AR 80
DI 10.1145/3550274
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FS5
UT WOS:001011932300005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zeng, DH
   Wu, JM
   Hattori, G
   Xu, R
   Yu, Y
AF Zeng, Donghuo
   Wu, Jianming
   Hattori, Gen
   Xu, Rong
   Yu, Yi
TI Learning Explicit and Implicit Dual Common Subspaces for Audio-visual
   Cross-modal Retrieval
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Modality-common; modality-specific; explicit and implicit; audio-visual
   cross-modal retrieval
ID CANONICAL CORRELATION-ANALYSIS
AB Audio-visual tracks in video contain rich semantic information with potential in many applications and research. Since the audio-visual data have inconsistent distributions and because of the heterogeneous nature of representations, the heterogeneous gap between modalities makes them impossible to compare directly. To bridge the modality gap, a frequently adopted approach is to simultaneously project audio-visual data into a common subspace to capture the commonalities and characteristics of modalities for measurement, which has been extensively studied in relation to the issues of modality-common andmodality-specific feature learning in previous research. However, it is difficult for existing methods to address the tradeoff between both issues; e.g., the modality-common feature is learned from the latent commonalities of audio-visual data or the correlated features as aligned projections, in which the modality-specific feature can be lost. To solve the tradeoff, we propose a novel end-to-end architecture, which synchronously projects audio-visual data into the explicit and the implicit dual common subspaces. The explicit subspace is used to learn modality-common features and reduce the modality gap of explicitly paired audio-visual data, where the representation-specific details are abandoned to retain the common underlying structure of audio-visual data. The implicit subspace is used to learn modality-specific features, where each modality privately pulls apart the feature distances between different categories to maintain the category-based distinctions, by minimizing the distance between audio-visual features and corresponding labels. The comprehensive experimental results on two audio-visual datasets, VEGAS and AVE, demonstrate that our proposed model for using two different common subspaces for audio-visual cross-modal learning is effective and significantly outperforms the state-of-the-art crossmodal models that learn features from a single common subspace by 4.30% and 2.30% in terms of average MAP on the VEGAS and AVE datasets, respectively.
C1 [Zeng, Donghuo] Natl Inst Informat, 2-1-2 Hitotsubashi, Tokyo, Tokyo 1018430, Japan.
   [Wu, Jianming; Hattori, Gen] KDDI Res Inc, 2-1-15 Ohara, Fujimino, Saitama 3568502, Japan.
   [Xu, Rong] Waseda Univ, Totsukamachi,Shinjuku Ku, Tokyo 1698050, Japan.
   [Yu, Yi] SOKENDAI, Natl Inst Informat, 2-1-2 Hitotsubashi,Chiyoda Ku, Tokyo 1018430, Japan.
C3 Research Organization of Information & Systems (ROIS); National
   Institute of Informatics (NII) - Japan; KDDI Corporation; KDDI Research,
   Inc.; Waseda University; Research Organization of Information & Systems
   (ROIS); National Institute of Informatics (NII) - Japan
RP Yu, Y (corresponding author), SOKENDAI, Natl Inst Informat, 2-1-2 Hitotsubashi,Chiyoda Ku, Tokyo 1018430, Japan.
OI Zeng, Donghuo/0000-0002-6425-6270; WU, JIANMING/0000-0002-1720-8516
FU JSPS Scientific Research [19K11987]; KDDI research, Inc. Project
FX This work was partially supported by JSPS Scientific Research (C) under
   Grant No. 19K11987 and supported by KDDI research, Inc. Project.
CR Abu-El-Haija Sami, 2016, arXiv, DOI [DOI 10.48550/ARXIV.1609.08675, DOI 10.48550/-ARXIV.1609.08675]
   Andrew G., 2013, ICML, P1247
   [Anonymous], 2015, P 2015 SIAM INT C DA, DOI DOI 10.1137/1.9781611974010.23
   [Anonymous], 2011, P ICML
   Ayyavaraiah M., 2019, INT C COMPUTATIONAL, P1125, DOI DOI 10.1007/978-3-030-37218-7_118
   Ayyavaraiah M., 2018, INT J ENG TECHNOLOGY, V7, P257, DOI [10.14419/ijet.v7i2.7.10592, DOI 10.14419/IJET.V7I2.7.10592]
   Bousmalis K, 2016, ADV NEUR IN, V29
   Cao WM, 2019, NEUROCOMPUTING, V345, P45, DOI 10.1016/j.neucom.2018.10.082
   Cao Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1445, DOI 10.1145/2939672.2939812
   Carvalho M, 2018, ACM/SIGIR PROCEEDINGS 2018, P35, DOI 10.1145/3209978.3210036
   Chen HL, 2020, INT CONF ACOUST SPEE, P721, DOI [10.1109/ICASSP40776.2020.9053174, 10.1109/icassp40776.2020.9053174]
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Chuang Gan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P758, DOI 10.1007/978-3-030-58621-8_44
   Chuang Gan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10475, DOI 10.1109/CVPR42600.2020.01049
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Donghuo Zeng, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P1070, DOI 10.1109/ICDMW.2019.00156
   Dorfer M, 2018, INT J MULTIMED INF R, V7, P117, DOI 10.1007/s13735-018-0151-5
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gan C, 2021, Arxiv, DOI arXiv:2007.04954
   Geigle G, 2022, T ASSOC COMPUT LING, V10, P503, DOI 10.1162/tacl_a_00473
   Gu W, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/3323873.3325045
   Han N, 2022, Arxiv, DOI arXiv:2110.15609
   Harada S, 2019, IEEE ACCESS, V7, P144292, DOI 10.1109/ACCESS.2019.2934928
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hazarika D, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1122, DOI 10.1145/3394171.3413678
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hsieh WW, 2000, NEURAL NETWORKS, V13, P1095, DOI 10.1016/S0893-6080(00)00067-8
   Jiang XY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P69, DOI 10.1145/2733373.2806240
   KaiyeWang Qiyue Yin, 2016, arXiv, DOI DOI 10.48550/ARXIV.1607.06215
   Karpathy A, 2014, ADV NEUR IN, V27
   Kaur P, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100336
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Lai PL, 2000, IEEE IJCNN, P614
   Liu PF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1, DOI 10.18653/v1/P17-1001
   Liu XB, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1678, DOI 10.1109/ICASSP.2018.8462454
   Lu R, 2018, IEEE SIGNAL PROC LET, V25, P1315, DOI 10.1109/LSP.2018.2853566
   Ma XH, 2020, IEEE T MULTIMEDIA, V22, P3101, DOI 10.1109/TMM.2020.2969792
   Morgado P, 2021, PROC CVPR IEEE, P12929, DOI 10.1109/CVPR46437.2021.01274
   Müller M, 2019, IEEE SIGNAL PROC MAG, V36, P52, DOI 10.1109/MSP.2018.2868887
   Nie XS, 2021, IEEE T CIRC SYST VID, V31, P401, DOI 10.1109/TCSVT.2020.2974877
   Peng YX, 2017, FRONT INFORM TECH EL, V18, P44, DOI 10.1631/FITEE.1601787
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P5585, DOI 10.1109/TIP.2018.2852503
   Radford A, 2021, PR MACH LEARN RES, V139
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rasiwasia N, 2014, JMLR WORKSH CONF PRO, V33, P823
   Roy A, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1315, DOI 10.1145/3340531.3411995
   Ruder S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1044
   Shao J, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P332, DOI 10.1145/3126686.3126726
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Tian YP, 2018, LECT NOTES COMPUT SC, V11206, P252, DOI 10.1007/978-3-030-01216-8_16
   Vilaca L, 2022, arXiv
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang J, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P347, DOI 10.1145/2671188.2749341
   Wu F, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107335
   Xie D, 2020, IEEE T IMAGE PROCESS, V29, P3626, DOI 10.1109/TIP.2020.2963957
   Xiong HX, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02177-7
   Xu GW, 2020, IEEE ACCESS, V8, P14278, DOI 10.1109/ACCESS.2020.2966220
   Xu HM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3893, DOI 10.1145/3394171.3413581
   Xu X, 2020, IEEE T CYBERNETICS, V50, P2400, DOI 10.1109/TCYB.2019.2928180
   Yanagi R, 2020, IEEE ACCESS, V8, P96777, DOI 10.1109/ACCESS.2020.2995815
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Yu Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3281746
   Yu Y, 2019, IEEE T NEUR NET LEAR, V30, P1250, DOI 10.1109/TNNLS.2018.2856253
   Zeng DH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3387164
   Zeng DH, 2018, IEEE INT SYM MULTIM, P143, DOI 10.1109/ISM.2018.00-21
   Zeng Donghuo, 2020, NATL C SOUND MUSIC T, P78
   Zhang J, 2018, AAAI CONF ARTIF INTE, P539
   Zhang L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1355, DOI 10.1145/2964284.2964336
   Zhang X, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P213, DOI 10.1145/3206025.3206042
   Zhao H, 2018, LECT NOTES COMPUT SC, V11205, P587, DOI 10.1007/978-3-030-01246-5_35
   Zhao H, 2019, IEEE I CONF COMP VIS, P1735, DOI 10.1109/ICCV.2019.00182
   Zhen LL, 2022, IEEE T NEUR NET LEAR, V33, P798, DOI 10.1109/TNNLS.2020.3029181
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
   Zhou YP, 2018, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2018.00374
NR 77
TC 1
Z9 1
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2023
VL 19
IS 2
SU S
AR 97
DI 10.1145/3564608
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FS5
UT WOS:001011932300022
DA 2024-07-18
ER

PT J
AU Alharbi, A
   Aljebreen, M
   Tolba, A
   Lizos, KA
   Abd El-Atty, S
   Shawki, F
AF Alharbi, Abdullah
   Aljebreen, Mohammed
   Tolba, Amr
   Lizos, Konstantinos A.
   Abd El-Atty, Saied
   Shawki, Farid
TI A Normalized Slicing-assigned Virtualization Method for 6G-based
   Wireless Communication Systems
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE 6G; federated learning; network slicing; virtualization
ID RESOURCE-MANAGEMENT; 6G; CYBERTWIN; NETWORKS
AB The next generation of wireless communication systems will rely on advantageous sixth-generation wireless network (6G) features and sophisticated edge Internet-of-Things technology to provide continuous service delegation and resource allocation. Network slicing and virtualization are common in these scenarios to meet user demands and application services. This article introduces a Normalized Slicing-assigned Virtualization Method for satisfying the 6G features in future generation systems. The proposed method relies on available resource roots and time intervals for replications. Based on the availability and Accessibility, the resource virtualization and network slicing processes are forwarded. The proposed method exploits federated learning for determining availability and accessibility models in detecting slicing, virtualization, or both the requirements throughout the resource sharing process. This improves the resource sharing rate, with less latency and high processing despite the user and application demands. The learning models are trained to balance replication and network slicing for confining complexity across different resources. The proposed method's performance is validated using the above metrics for varying users and intervals.
C1 [Alharbi, Abdullah; Aljebreen, Mohammed; Tolba, Amr] King Saud Univ, Community Coll, Dept Comp Sci, POB 28095, Riyadh 11437, Saudi Arabia.
   [Lizos, Konstantinos A.] Univ Oslo UiO, Fac Math & Nat Sci, Dept Informat, Oslo, Norway.
   [Abd El-Atty, Saied; Shawki, Farid] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia, Egypt.
C3 King Saud University; University of Oslo; Egyptian Knowledge Bank (EKB);
   Menofia University
RP Abd El-Atty, S (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia, Egypt.
EM arharbi@ksu.edu.sa; maljebreen@ksu.edu.sa; atolba@ksu.edu.sa;
   klizos@ifi.uio.no; sabdelatty@el-eng.menofia.edu.eg;
   farid_shawki@yahoo.com
RI Aljebreen, Mohammed/IAP-6212-2023; Tolba, Amr/O-8464-2016; Abd El-atty,
   Saied/AAI-6029-2020
OI Tolba, Amr/0000-0003-3439-6413; Abd El-atty, Saied/0000-0003-0979-4292;
   Alharbi, Abdullah/0000-0001-8617-1430; Aljebreen,
   Mohammed/0000-0002-6295-733X
FU King Saud University, Riyadh, Saudi Arabia [RSP2022R444]
FX This work was funded by the Researchers Supporting Project No.
   (RSP2022R444) King Saud University, Riyadh, Saudi Arabia.
CR Alotaibi D., 2021, Procedia Computer Science, V194, P114, DOI DOI 10.1016/J.PROCS.2021.10.064
   Alves MP, 2020, WORLD WIDE WEB, V23, P1127, DOI 10.1007/s11280-019-00722-9
   Barbieri L, 2022, VEH COMMUN, V33, DOI 10.1016/j.vehcom.2021.100396
   Bruschi R, 2019, IEEE J SEL AREA COMM, V37, P499, DOI 10.1109/JSAC.2019.2894236
   Cao HT, 2021, IEEE T VEH TECHNOL, V70, P3846, DOI 10.1109/TVT.2021.3065967
   Dilli R, 2022, INT J WIREL INF NETW, V29, P93, DOI 10.1007/s10776-021-00546-3
   Dogra A, 2021, IEEE ACCESS, V9, P67512, DOI 10.1109/ACCESS.2020.3031234
   Duan MX, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3506852
   Escolar AM, 2021, IEEE ACCESS, V9, P14048, DOI 10.1109/ACCESS.2021.3051940
   Feng J, 2020, IEEE T VEH TECHNOL, V69, P7863, DOI 10.1109/TVT.2020.2992607
   Ghai KS, 2020, J AMB INTEL HUM COMP, V11, P3963, DOI 10.1007/s12652-019-01630-6
   Gur G, 2020, J COMMUN NETW-S KOR, V22, P444, DOI 10.23919/JCN.2020.000037
   Hao M, 2021, PHYS COMMUN-AMST, V49, DOI 10.1016/j.phycom.2021.101470
   Hussain M, 2021, SUSTAIN COMPUT-INFOR, V30, DOI 10.1016/j.suscom.2021.100517
   Jiang LL, 2022, PEER PEER NETW APPL, V15, P1090, DOI 10.1007/s12083-021-01285-1
   Jie Mei, 2020, Intelligent and Converged Networks, V1, P281, DOI 10.23919/ICN.2020.0019
   kaggle, ANURAGTHANTHARATE
   Kim Y, 2021, IEEE ACCESS, V9, P56178, DOI 10.1109/ACCESS.2021.3072435
   Kuklinski S, 2021, J COMMUN NETW-S KOR, V23, P442, DOI 10.23919/JCN.2021.000025
   Li JL, 2021, IEEE INTERNET THINGS, V8, P16313, DOI 10.1109/JIOT.2021.3097053
   Li YT, 2022, ACM T SENSOR NETWORK, V18, DOI 10.1145/3485060
   Liu C., 2021, arXiv
   Magoula L, 2021, COMPUT NETW, V195, DOI 10.1016/j.comnet.2021.108157
   Mei J, 2021, IEEE T COMMUN, V69, P6063, DOI 10.1109/TCOMM.2021.3090423
   Montero R, 2020, PHOTONIC NETW COMMUN, V40, P221, DOI 10.1007/s11107-020-00897-6
   Raddo TR, 2021, EURASIP J WIREL COMM, V2021, DOI 10.1186/s13638-021-01973-9
   Rodrigues TK, 2021, IEEE INTERNET THINGS, V8, P16231, DOI 10.1109/JIOT.2021.3095308
   Saad A, 2020, COMPUT COMMUN, V160, P749, DOI 10.1016/j.comcom.2020.07.025
   Sheth K, 2020, COMPUT COMMUN, V161, P279, DOI 10.1016/j.comcom.2020.07.035
   Shi QHY, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3485665
   Shinde SS, 2021, COMPUT NETW, V201, DOI 10.1016/j.comnet.2021.108598
   Son J, 2019, J SYST SOFTWARE, V152, P24, DOI 10.1016/j.jss.2019.02.030
   Wang Q, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3506710
   Wu J. Jiang, 2022, ACM Trans. Multimedia Comput., Commun. Appl., V18, P1
   Xu H, 2020, DIGIT COMMUN NETW, V6, P261, DOI 10.1016/j.dcan.2020.06.002
NR 35
TC 0
Z9 0
U1 2
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2022
VL 18
IS 3
SU S
SI SI
AR 134
DI 10.1145/3546077
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A0AE2
UT WOS:000951829800003
DA 2024-07-18
ER

PT J
AU Zhao, J
   Liu, XH
   Zhao, WD
AF Zhao, Jian
   Liu, Xianhui
   Zhao, Weidong
TI Balanced and Accurate Pseudo-Labels for Semi-Supervised Image
   Classification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Deep Co-Training; Balanced Module; Gaussian Mixture Module;
   semi-supervised classification
ID ENSEMBLE ALGORITHM
AB Image classification by semi-supervised learning has recently become a hot spot, and the Co-Training framework is an important method of semi-supervised image classification. In the traditional Co-Training structure, the sub-networks will generate pseudo-labels for each other, and these pseudo-labels will further be used as a supervisory signal for model training. However, the pseudo-labels will hurt classification performance because of their low accuracy and unbalanced distribution. In this article, we are trying to solve the preceding two problems by designing the Balanced Module (BM) and Gaussian Mixture Module (GMM), and propose BAPS (the Balanced and Accurate Pseudo-labels for Semi-supervised image classification). In BM, the two sub-networks jointly predict the unlabeled images, then select the pseudo-labels with a high-confidence threshold to perform the balancing operation to obtain the initial samples with balanced distribution of each category. In GMM, referring to the common practice of the Learning from Noise Labels task, we use GMM to fit the loss distribution of images with pseudo-labels output by BM, then clean samples and noise samples are divided based on the observation that the loss of correctly labeled images is generally smaller than that of wrongly labeled ones. Through BM and GMM, pseudo-labels with balanced distribution and high accuracy are obtained for the subsequent model training process. Our model has achieved better classification accuracy than most state-of-the-art semi-supervised image classification algorithms on the CIFAR-10/100 and SVHN datasets, and further ablation experiments demonstrate the effectiveness of our BAPS. The source code of BAPS will be available at https://github.com/zhaojianaaa.
C1 [Zhao, Jian; Liu, Xianhui; Zhao, Weidong] Tongji Univ, 4800 Caoan Rd, Shanghai 201804, Peoples R China.
C3 Tongji University
RP Liu, XH (corresponding author), Tongji Univ, 4800 Caoan Rd, Shanghai 201804, Peoples R China.
EM zjtju1919@gmail.com; 1910678@tongji.edu.cn; wd@tongji.edu.cn
RI Zhao, Jian/GYU-6898-2022
FU National High-Technology Research and Development Program of China
   [2017YFB0304102]; Shanghai Innovation Action Project of Science and
   Technology [21511104300]; Fundamental Research Funds for the Central
   Universities
FX This work was supported by the National High-Technology Research and
   Development Program of China (no. 2017YFB0304102), the Shanghai
   Innovation Action Project of Science and Technology (no. 21511104300),
   and the Fundamental Research Funds for the Central Universities.
CR [Anonymous], 2011, NEUR INF PROC SYST N
   Arazo E, 2019, PR MACH LEARN RES, V97
   Arpit D, 2017, PR MACH LEARN RES, V70
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Berthelot D, 2019, ADV NEUR IN, V32
   Berthelot David, 2020, ICLR
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cevikalp H, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107164
   Chen DD, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2014
   Chen JM, 2021, NEUROCOMPUTING, V453, P731, DOI 10.1016/j.neucom.2020.06.133
   Chen PF, 2019, PR MACH LEARN RES, V97
   Chen YP, 2017, Arxiv, DOI [arXiv:1707.01629, 10.48550/arXiv.1707.01629, DOI 10.48550/ARXIV.1707.01629]
   Cubuk ED, 2019, Arxiv, DOI arXiv:1909.13719
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo H., 2004, SIGKDD EXPLORATIONS, V6, P30, DOI DOI 10.1145/1007730.1007736
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou Y, 2019, INTELL DATA ANAL, V23, P1205, DOI 10.3233/IDA-184354
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Krawczyk B, 2016, APPL SOFT COMPUT, V38, P714, DOI 10.1016/j.asoc.2015.08.060
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kwon Yeong-Dae, 2021, arXiv
   Landu Jiang, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3161179
   Li Junnan, 2020, ARXIV200207394
   Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472
   Malach E, 2017, ADV NEUR IN, V30
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Mo JW, 2021, IEEE ACCESS, V9, P36522, DOI 10.1109/ACCESS.2021.3063176
   Nguyen D.T., 2020, P INT C LEARNING REP
   Odena Augustus, 2016, ArXiv, P1
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Park S, 2021, PROC CVPR IEEE, P12273, DOI 10.1109/CVPR46437.2021.01210
   Qian Y, 2014, NEUROCOMPUTING, V143, P57, DOI 10.1016/j.neucom.2014.06.021
   Qiao SY, 2018, LECT NOTES COMPUT SC, V11219, P142, DOI 10.1007/978-3-030-01267-0_9
   Raffel C., 2020, P C NEUR INF PROC SY, P1
   Reed Scott, 2015, ICLR
   Salimans Tim, 2016, P C NEURAL INFORM PR, P1
   Samuli L., 2017, ICLR, P1
   Sandler M, 2019, Arxiv, DOI arXiv:1801.04381
   Tarvainen A, 2017, ADV NEUR IN, V30
   Wang L, 2022, VISUAL COMPUT, V38, P2009, DOI 10.1007/s00371-021-02262-8
   Wei C, 2021, PROC CVPR IEEE, P10852, DOI 10.1109/CVPR46437.2021.01071
   Xie Z., 2020, 34th Conference on Neural Information Processing Systems (NeurIPS), P1, DOI DOI 10.48550/ARXIV.1904.12848
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang XC, 2017, PROC CVPR IEEE, P3900, DOI 10.1109/CVPR.2017.415
   Zhong ZS, 2021, PROC CVPR IEEE, P16484, DOI 10.1109/CVPR46437.2021.01622
   Zoph B, 2018, Arxiv, DOI arXiv:1707.07012
NR 49
TC 3
Z9 3
U1 1
U2 21
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2022
VL 18
IS 3
SU S
SI SI
AR 145
DI 10.1145/3506711
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A0AE2
UT WOS:000951829800015
DA 2024-07-18
ER

PT J
AU Liu, DB
   Yang, LT
   Wang, PM
   Zhao, RN
   Zhang, QC
AF Liu, Debin
   Yang, Laurence T.
   Wang, Puming
   Zhao, Ruonan
   Zhang, Qingchen
TI TT-TSVD: A Multi-modal Tensor Train Decomposition with Its Application
   in Convolutional Neural Networks for Smart Healthcare
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Tensor decomposition; convolutional neural network compression; tensor
   train-tensor singular value decomposition; Medical auxiliary diagnosis
AB Smart healthcare systems are generating a large scale of heterogenous high-dimensional data with complex relationships. It is hard for current methods to analyze such high-dimensional healthcare data. Specifically, the traditional data reduction methods can not keep the correlation among different modalities of data objects, while the latest methods based on tensor singular value decomposition are not effective for data reduction, although they can keep the correlation. This article presents a tensor train-tensor singular value decomposition err-TsvD) algorithm for data reduction. Particularly, the presented algorithm balances the correlation-preservation ability of modalities and data reduction ability by combining the advantages of the train structure of the tensor train decomposition and the association relationship between the tensor singular value decomposition retention mode. Extensive experiments are conducted on the convolutional neural network and the results clearly show that the presented algorithm performs effectively for data reduction with a low-loss classification accuracy; what is more, classification accuracy on medical image dataset has been improved a little.
C1 [Liu, Debin; Yang, Laurence T.] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, 1037 Guanshan Rd, Wuhan, Peoples R China.
   [Yang, Laurence T.; Zhang, Qingchen] St Francis Xavier Univ, Antigonish, NS, Canada.
   [Wang, Puming] Yunnan Univ, Sch Software, East Outer Ring Rd, Kunming, Yunnan, Peoples R China.
   [Zhao, Ruonan] Huazhong Univ Sci & Technol, Sch Cyber Sci & Engn, 1037 Guanshan Rd, Wuhan, Peoples R China.
C3 Huazhong University of Science & Technology; Saint Francis Xavier
   University - Canada; Yunnan University; Huazhong University of Science &
   Technology
RP Yang, LT (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, 1037 Guanshan Rd, Wuhan, Peoples R China.; Yang, LT (corresponding author), St Francis Xavier Univ, Antigonish, NS, Canada.
EM debinliuhust@gmail.com; ltyang@gmail.com; pumingwang@gmail.com;
   zhaoruonan@hust.edu.cn; qzhang@stfx.ca
RI Laurence T. Yang, FCAE/AAA-1898-2019; wang, puming/HSF-8613-2023
OI Laurence T. Yang, FCAE/0000-0002-7986-4244; puming,
   wang/0000-0003-1261-8687; Liu, debin/0000-0001-5233-9637
FU National Natural Science Foundation of China [61932010]; Artificial
   Intelligence and Intelligent Transportation Joint Technical Center of
   HUST; Hubei Chutian Intelligent Transportation Co., LTD under project
   Intelligent Transportation Operation Monitoring Network and System
   [0231129029]
FX This work was supported in part by the National Natural Science
   Foundation of China (grant no. 61932010) and in part by Artificial
   Intelligence and Intelligent Transportation Joint Technical Center of
   HUST and Hubei Chutian Intelligent Transportation Co., LTD under project
   Intelligent Transportation Operation Monitoring Network and System
   (grant no. 0231129029.
CR [Anonymous], 2016, arXiv
   Badeau R, 2008, SIAM J MATRIX ANAL A, V30, P1008, DOI 10.1137/060655936
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Brazell M, 2013, SIAM J MATRIX ANAL A, V34, P542, DOI 10.1137/100804577
   CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   De Lathauwer L., 1997, SIGNAL PROCESSING BA
   Denton E, 2014, ADV NEUR IN, V27
   Guo ZW, 2021, IEEE T FUZZY SYST, V29, P3650, DOI 10.1109/TFUZZ.2021.3052109
   HARSHMAN RA, 1994, COMPUT STAT DATA AN, V18, P39, DOI 10.1016/0167-9473(94)90132-5
   Hitchcock F. L., 1927, J MATH PHYS, V6, P189, DOI [10.1002/sapm192761164, DOI 10.1002/SAPM192761164]
   Hu Hengyuan, 2016, Network trimming: A data-driven neuron pruning approach towards efficient deep architectures
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kolda TG, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P242, DOI 10.1109/ICDM.2005.77
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Li H, 2022, IEEE J BIOMED HEALTH, V26, P1949, DOI 10.1109/JBHI.2021.3075995
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Sidiropoulos ND, 2000, IEEE T SIGNAL PROCES, V48, P2377, DOI 10.1109/78.852018
   Sun Jian-Tao., 2005, PROC WWW 05, P382, DOI DOI 10.1145/1060745.1060803
   Tang MJ, 2019, IEEE T BIG DATA, V5, P317, DOI 10.1109/TBDATA.2017.2723570
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Vasilescu MAO, 2002, LECT NOTES COMPUT SC, V2350, P447
   Veeling BS, 2018, LECT NOTES COMPUT SC, V11071, P210, DOI 10.1007/978-3-030-00934-2_24
   Venkatraman S, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1728303
   Wang PM, 2020, IEEE T NETW SCI ENG, V7, P713, DOI 10.1109/TNSE.2019.2929155
   Weissman C, 2018, ISR J HEALTH POLICY, V7, DOI 10.1186/s13584-018-0218-z
   Wu XD, 2014, IEEE T KNOWL DATA EN, V26, P97, DOI 10.1109/TKDE.2013.109
   Zhang J, 2021, CMC-COMPUT MATER CON, V66, P2087, DOI 10.32604/cmc.2020.014220
NR 30
TC 10
Z9 10
U1 2
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2022
VL 18
IS 1
SU S
SI SI
AR 41
DI 10.1145/3491223
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5PV
UT WOS:000772639300018
DA 2024-07-18
ER

PT J
AU Mishra, P
   Kumar, S
   Chaube, MK
AF Mishra, Prerna
   Kumar, Santosh
   Chaube, Mithilesh Kumar
TI Dissimilarity-Based Regularized Learning of Charts
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Dissimilarity index; chart image classification; regularization; deep
   learning
ID FIGURE CLASSIFICATION; ROTATION-INVARIANT; SCENE; RECOGNITION; NETWORKS;
   FUSION
AB Chart images exhibit significant variabilities that make each image different from others even though they belong to the same class or categories. Classification of charts is a major challenge because each chart class has variations in features, structure, and noises. However, due to the lack of affiliation between the dissimilar features and the structure of the chart, it is a challenging task to model these variations for automatic chart recognition. In this article, we present a novel dissimilarity-based learning model for similar structured but diverse chart classification. Our approach jointly learns the features of both dissimilar and similar regions. The model is trained by an improved loss function, which is fused by a structural variation-aware dissimilarity index and incorporated with regularization parameters, making the model more prone toward dissimilar regions. The dissimilarity index enhances the discriminative power of the learned features not only from dissimilar regions but also from similar regions. Extensive comparative evaluations demonstrate that our approach significantly outperforms other benchmark methods, including both traditional and deep learning models, over publicly available datasets.
C1 [Mishra, Prerna; Kumar, Santosh; Chaube, Mithilesh Kumar] DSPM IIITNR, Raipur, Madhya Pradesh, India.
RP Mishra, P (corresponding author), DSPM IIITNR, Raipur, Madhya Pradesh, India.
EM prerna@iiitnr.edu.in; santosh@iiitnr.edu.in; mithilesh@iiitnr.edu.in
RI mishra, prerna/GPW-6915-2022; Chaube, Mithilesh/AAV-7844-2020
OI Chaube, Mithilesh/0000-0001-7086-1277; mishra,
   prerna/0000-0003-2895-6146
CR Abouelenien M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING (GRC), P4, DOI 10.1109/GrC.2013.6740371
   Amara JH, 2017, COMPUT SCI RES NOTES, V2701, P83
   [Anonymous], 2011, P 24 ANN ACM S US IN
   Atkinson A., 2017, Figureqa: An annotated figure dataset for visual reasoning
   Beddoe Jennifer, 2014, STUDY COM BAR GRAPH
   Cao J, 2019, ASIAPAC SIGN INFO PR, P75, DOI 10.1109/APSIPAASC47483.2019.9023268
   Chagas P, 2018, IEEE IJCNN
   Chen M, 2016, IEEE T VIS COMPUT GR, V22, P2619, DOI 10.1109/TVCG.2015.2513410
   Cheng BB, 2013, PROC INT CONF DOC, P693, DOI 10.1109/ICDAR.2013.142
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davila Kenny, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1594, DOI 10.1109/ICDAR.2019.00203
   Demirkaya A, 2020, 2020 54TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), P36, DOI 10.1109/CISS48834.2020.1570627167
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   Hinton G., 2018, Neural Networks for Machine Learning
   Hong CQ, 2015, INFORM SCIENCES, V320, P395, DOI 10.1016/j.ins.2015.03.032
   Huang W., 2007, IEEE WORKSHOP APPL C, P27
   Huang WH, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P9
   Huang WH, 2004, IEEE IMAGE PROC, P2889
   Jiang B., 2018, ARXIV180909839
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Jurio A, 2014, SOFT COMPUT, V18, P1055, DOI 10.1007/s00500-013-1126-3
   Karthikeyani V., 2012, INT J COMPUT APPL, V39, P1, DOI DOI 10.5120/4789-6997
   Kim D, 2011, J BIOMED INFORM, V44, P848, DOI 10.1016/j.jbi.2011.05.003
   Kotu V., 2018, Data science: concepts and practice, DOI [DOI 10.1016/C2017-0-02113-4, 10.1016/c2017-0-02113-4]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu WF, 2019, IEEE T CYBERNETICS, V49, P2927, DOI 10.1109/TCYB.2018.2833843
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mishchenko Ales, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P476, DOI 10.1007/978-3-642-24031-7_48
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pandey RK, 2019, TENCON IEEE REGION, P1159, DOI [10.1109/TENCON.2019.8929485, 10.1109/tencon.2019.8929485]
   Peng Y, 2015, NEUROCOMPUTING, V149, P340, DOI 10.1016/j.neucom.2013.12.065
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Prasad VSN, 2007, INT WORK CONTENT MUL, P85
   Redko Alla, 2014, ORACLE DOCS
   Sandryhaila A, 2013, IEEE GLOB CONF SIG, P495, DOI 10.1109/GlobalSIP.2013.6736923
   Setty S, 2013, NAT CONF COMPUT VIS
   Shao Mingyan., 2005, Proc. of GREC
   Shukla S, 2008, INT J DOC ANAL RECOG, V11, P111, DOI 10.1007/s10032-008-0065-5
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Simonyan K., 2014, 14091556 ARXIV
   Song KK, 2018, IEEE ACCESS, V6, P44268, DOI 10.1109/ACCESS.2018.2862464
   Starr Ben., 2015, DESIGN AREA CHARTS
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang BB, 2016, SIGNAL PROCESS, V124, P156, DOI 10.1016/j.sigpro.2015.09.027
   Vinh Thong Ta, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P1160
   Wang L, 2020, IEEE ACCESS, V8, P81142, DOI 10.1109/ACCESS.2020.2991237
   Williams Shannon., LUCID CHARTS
   Xu Y, 2017, IEEE T NEUR NET LEAR, V28, P2233, DOI 10.1109/TNNLS.2016.2580572
   Ye MX, 2019, INT CONF ACOUST SPEE, P3537, DOI [10.1109/icassp.2019.8682725, 10.1109/ICASSP.2019.8682725]
   Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471
   Zhang SL, 2019, INT CONF ACOUST SPEE, P6570, DOI 10.1109/ICASSP.2019.8682566
   Zhou YP., 2001, 4th IAPR International Workshop on Graphics Recognition, GREC, P482
NR 57
TC 0
Z9 0
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2021
VL 17
IS 4
AR 131
DI 10.1145/3458884
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP8GI
UT WOS:000748857800015
DA 2024-07-18
ER

PT J
AU Yan, CG
   Teng, T
   Liu, YT
   Zhang, YB
   Wang, HQ
   Ji, XY
AF Yan, Chenggang
   Teng, Tong
   Liu, Yutao
   Zhang, Yongbing
   Wang, Haoqian
   Ji, Xiangyang
TI Precise No-Reference Image Quality Evaluation Based on Distortion
   Identification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment (IQA); distortion identification; no-reference
   (NR)/blind; deep learning; noisiness; sharpness
ID FREE-ENERGY PRINCIPLE; STATISTICS; LEVEL
AB The difficulty of no-reference image quality assessment (NR IQA) often lies in the lack of knowledge about the distortion in the image, which makes quality assessment blind and thus inefficient. To tackle such issue, in this article, we propose a novel scheme for precise NR IQA, which includes two successive steps, i.e., distortion identification and targeted quality evaluation. In the first step, we employ the well-known InceptionResNet-v2 neural network to train a classifier that classifies the possible distortion in the image into the four most common distortion types, i.e., Gaussian white noise (WN), Gaussian blur (GB), jpeg compression (JPEG), and jpeg2000 compression (JP2K). Specifically, the deep neural network is trained on the large-scale Water-loo Exploration database, which ensures the robustness and high performance of distortion classification. In the second step, after determining the distortion type of the image, we then design a specific approach to quantify the image distortion level, which can estimate the image quality specially and more precisely. Extensive experiments performed on LIVE, TID2013, CSIQ, and Waterloo Exploration databases demonstrate that (1) the accuracy of our distortion classification is higher than that of the state-of-the-art distortion classification methods, and (2) the proposed NR IQA method outperforms the state-of-the-art NR IQA methods in quantifying the image quality.
C1 [Yan, Chenggang; Teng, Tong] Hangzhou Dianzi Univ, Hangzhou 310018, Peoples R China.
   [Liu, Yutao] Ocean Univ China, Qingdao 266100, Peoples R China.
   [Zhang, Yongbing] Harbin Inst Technol, Shenzhen 518055, Peoples R China.
   [Wang, Haoqian] Tsinghua Shenzhen Int Grad Sch, Shenzhen 518055, Peoples R China.
   [Ji, Xiangyang] Tsinghua Univ, Beijing 100084, Peoples R China.
C3 Hangzhou Dianzi University; Ocean University of China; Harbin Institute
   of Technology; Tsinghua Shenzhen International Graduate School; Tsinghua
   University
RP Liu, YT (corresponding author), Ocean Univ China, Qingdao 266100, Peoples R China.
EM cgyan@hdu.edu.cn; tengtong@hdu.edu.cn; liuyutao2008@gmail.com;
   ybzhang08@hit.edu.cn; wangyizhai@sz.tsinghtia.edu.cn;
   xyji@tsinghua.edu.cn
RI Huang, Liancheng/KDN-5718-2024; Teng, 滕腾/GLT-1286-2022; Liu,
   Zhiyu/JNR-8043-2023
OI Liu, Zhiyu/0000-0001-8351-1268
FU National Key Research and Development Program of China [2020YFB1406604];
   National Natural Science Foundation of China [61931008, 61671196,
   62071415, 62001146, 61701149, 61801157, 61971268, 61901145, 61901150,
   61972123, 61922048, 62031023]; China Postdoctoral Science Foundation
   [2019M650686]; Zhejiang Province Natural Science Foundation of China
   [LR17F030006, Q19F010030]; 111 Project [D17019]; Shenzhen Science and
   Technology Project [JCYJ20200109142808034]; Guangdong Special Support
   [2019TX05X187]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant (2020YFB1406604);National
   Natural Science Foundation of China (61931008, 61671196, 62071415,
   62001146, 61701149, 61801157, 61971268, 61901145, 61901150, 61972123,
   61922048, 62031023); China Postdoctoral Science Foundation
   (2019M650686); Zhejiang Province Natural Science Foundation of China
   (LR17F030006, Q19F010030); 111 Project (No. D17019); Shenzhen Science
   and Technology Project (No. JCYJ20200109142808034); and Guangdong
   Special Support (No. 2019TX05X187).
CR Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   COHEN A, 1992, COMMUN PUR APPL MATH, V45, P485, DOI 10.1002/cpa.3160450502
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P918, DOI 10.1109/LSP.2014.2320743
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Liu YT, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3414837
   Liu YT, 2020, IEEE ACCESS, V8, P84105, DOI 10.1109/ACCESS.2020.2991842
   Liu YT, 2020, IEEE T CIRC SYST VID, V30, P929, DOI 10.1109/TCSVT.2019.2900472
   Liu YT, 2019, IEEE T MULTIMEDIA, V21, P135, DOI 10.1109/TMM.2018.2849602
   Liu YT, 2018, IEEE T MULTIMEDIA, V20, P379, DOI 10.1109/TMM.2017.2729020
   Liu YT, 2017, J VIS COMMUN IMAGE R, V46, P70, DOI 10.1016/j.jvcir.2017.03.007
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Min XK, 2016, IEEE INT CON MULTI
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073
   MORRONE MC, 1986, NATURE, V324, P250, DOI 10.1038/324250a0
   Pan F, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P925
   Perra C, 2005, IEEE IMAGE PROC, P73
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rohaly A.M., 2000, ITU T STANDARDS CONT, P9
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2013, PROC SPIE, V8653, DOI 10.1117/12.2005420
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Wu JJ, 2020, IEEE T IMAGE PROCESS, V29, P7414, DOI 10.1109/TIP.2020.3002478
   Wu QB, 2015, IEEE IMAGE PROC, P339, DOI 10.1109/ICIP.2015.7350816
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan QS, 2019, IEEE T IMAGE PROCESS, V28, P2200, DOI 10.1109/TIP.2018.2883741
   Yutao Liu, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457858
   Zhai GT, 2013, PICT COD SYMP, P29, DOI 10.1109/PCS.2013.6737675
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang WX, 2021, IEEE T IMAGE PROCESS, V30, P3474, DOI 10.1109/TIP.2021.3061932
   Zhang Y, 2018, IEEE T IMAGE PROCESS, V27, P5433, DOI 10.1109/TIP.2018.2857413
   Zhu Y, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3183512
   Zhu ZJ, 2019, IEEE INT CON MULTI, P7, DOI 10.1109/ICME.2019.00010
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 67
TC 80
Z9 80
U1 5
U2 36
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2021
VL 17
IS 3
SU S
SI SI
AR 110
DI 10.1145/3468872
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YA4BM
UT WOS:000738280600012
DA 2024-07-18
ER

PT J
AU Singh, A
   Dhillon, A
   Kumar, N
   Hossain, MS
   Muhammad, G
   Kumar, M
AF Singh, Ashima
   Dhillon, Arwinder
   Kumar, Neeraj
   Hossain, M. Shamim
   Muhammad, Ghulam
   Kumar, Manoj
TI eDiaPredict: An Ensemble-based Framework for Diabetes Prediction
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Diabetes prediction; ensembled models; XGBoost; decision tree; random
   forest
AB Medical systems incorporate modern computational intelligence in healthcare. Machine learning techniques are applied to predict the onset and reoccurrence of the disease, identify biomarkers for survivability analysis depending upon certain health conditions of the patient. Early prediction of diseases like diabetes is essential as the number of diabetic patients of all age groups is increasing rapidly. To identify underlying reasons for the onset of diabetes in its early stage has become a challenging task for medical practitioners. Continuously increasing diabetic patient data has necessitated for the applications of efficient machine learning algorithms, which learns from the trends of the underlying data and recognizes the critical conditions in patients. In this article, an ensemble-based framework named eDiaPredict is proposed. It uses ensemble modeling, which includes an ensemble of different machine learning algorithms comprising XGBoost, Random Forest, Support Vector Machine, Neural Network, and Decision tree to predict diabetes status among patients. The performance of eDiaPredict has been evaluated using various performance parameters like accuracy, sensitivity, specificity, Gini Index, precision, area under curve, area under convex hull, minimum error rate, and minimum weighted coefficient. The effectiveness of the proposed approach is shown by its application on the PIMA Indian diabetes dataset wherein an accuracy of 95% is achieved.
C1 [Singh, Ashima; Dhillon, Arwinder; Kumar, Neeraj] Thapar Univ, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Hossain, M. Shamim] King Saud Univ, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
   [Hossain, M. Shamim] King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
   [Muhammad, Ghulam] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh, Saudi Arabia.
   [Kumar, Manoj] SMVD Univ, Katra, India.
C3 Thapar Institute of Engineering & Technology; King Saud University; King
   Saud University; King Saud University; Shri Mata Vaishno Devi University
RP Hossain, MS (corresponding author), King Saud Univ, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.; Hossain, MS (corresponding author), King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
EM ashima@thapar.edu; arvinder@thapar.edu; neeraj.kumar@thapar.edu;
   mshossain@ksu.edu.sa; ghulam@ksu.edu.sa; manoj.kumar@smvdu.ac.in
RI Kumar, Neeraj/L-3500-2016; Guizani, Mohsen/AAX-4534-2021; DHILLON,
   ARWINDER/JGE-2273-2023; Muhammad, Ghulam/H-5884-2011; Dhillon,
   Arwinder/GZA-4367-2022; Hossain, M. Shamim/K-1362-2014
OI Kumar, Neeraj/0000-0002-3020-3947; Guizani, Mohsen/0000-0002-8972-8094;
   DHILLON, ARWINDER/0000-0002-6276-7181; Hossain, M.
   Shamim/0000-0001-5906-9422; Kumar, Manoj/0000-0001-9959-5988
FU Deanship of Scientific Research at King Saud University, Riyadh, Saudi
   Arabia
FX The authors are grateful to the Deanship of Scientific Research at King
   Saud University, Riyadh, Saudi Arabia for funding this work through the
   Vice Deanship of Scientific Research Chairs: Chair of Pervasive and
   Mobile Computing.
CR Ahmed AM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194168
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   Amin SU, 2019, IEEE ACCESS, V7, P10745, DOI 10.1109/ACCESS.2019.2891390
   Anand A, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P673, DOI 10.1109/NGCT.2015.7375206
   [Anonymous], Ensemble Learning to Improve Machine Learning Results
   [Anonymous], Decision Tree Classification: Everything You Need to Know
   [Anonymous], THINKING BUILDING XG
   [Anonymous], DOES CONTINUOUS GLUC
   [Anonymous], FEATURE SELECTION IS
   [Anonymous], GESTATIONAL DIABETES
   Anuja Kumari V., 2018, International Journal of Engineering Research and Applications, V3, P1797
   Aujla G. S., 2019, IEEE ICC, P1, DOI DOI 10.1109/icc.2019.8761416
   Belkeziz R., 2017, 2016 3 INT C SYSTEMS, DOI DOI 10.1109/SYSCO.2016.7831328
   Bhatia N., 2015, Advances in Life Science and Technology, V29, P71
   Chen M, 2018, IEEE COMMUN MAG, V56, P14, DOI 10.1109/MCOM.2018.1700571
   Choudhury Ambika, 2019, RECENT DEV MACHINE L, DOI [10.1007/978-981-13-1280-9, DOI 10.1007/978-981-13-1280-9]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dhillon A, 2022, ENTERP INF SYST-UK, V16, DOI 10.1080/17517575.2020.1820583
   Dhillon A, 2020, IET SYST BIOL, V14, P160, DOI 10.1049/iet-syb.2019.0087
   Dhillon Arwinder, 2019, MACH LEARN HEALTHCAR, V8, P92
   Douali N., 2015, 2015 IEEE INT C FUZZ, P1, DOI DOI 10.1109/FUZZ-IEEE.2015.7337813
   Gandhi K.K., 2014, INT J ADV ENG RES DE, V1, P1, DOI DOI 10.21090/IJAERD.0105110
   Gandhi UD, 2018, WIRELESS PERS COMMUN, V103, P1179, DOI 10.1007/s11277-018-5307-3
   Han Wu, 2018, Informatics in Medicine Unlocked, V10, P100, DOI 10.1016/j.imu.2017.12.006
   Hashi EK, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P396, DOI 10.1109/ECACE.2017.7912937
   Heydari M, 2016, INT J DIABETES DEV C, V36, P167, DOI 10.1007/s13410-015-0374-4
   Hossain MS, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3241056
   Hossain MS, 2017, IEEE SYST J, V11, P118, DOI 10.1109/JSYST.2015.2470644
   Husain A., 2018, INT C ADV COMP DAT S, P95, DOI DOI 10.1007/978-981-13-1810-8_10
   Jakhmola S, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P744, DOI 10.1145/2791405.2791572
   Jarullah A. A. A, 2011, P 2011 INT C INNOV I
   Kaur P, 2021, ARCH COMPUT METHOD E, V28, P4595, DOI 10.1007/s11831-021-09547-0
   Kaur P, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P654, DOI 10.1109/IEMCON.2018.8614775
   Komi M, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P1006, DOI 10.1109/ICIVC.2017.7984706
   Muhammad G, 2021, IEEE J SEL AREA COMM, V39, P603, DOI 10.1109/JSAC.2020.3020654
   Nilashi M, 2017, COMPUT CHEM ENG, V106, P212, DOI 10.1016/j.compchemeng.2017.06.011
   Osman AH, 2017, INT J ADV COMPUT SC, V8, P236
   Panwar M, 2016, 2016 SIXTH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2016), P132, DOI 10.1109/ISED.2016.7977069
   Perveen S, 2016, PROCEDIA COMPUT SCI, V82, P115, DOI 10.1016/j.procs.2016.04.016
   Plis Kevin, 2014, AAAI WORKSH MOD ART, V31, P35
   Pratt KP, 2018, ANTIBODIES, V7, DOI 10.3390/antib7020019
   Ramesh S., 2017, Int J Database Theory Appl, V10, P47, DOI DOI 10.14257/IJDTA.2017.10.9.05
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Sharma N, 2019, COMM COM INF SC, V955, P471, DOI 10.1007/978-981-13-3140-4_42
   Sowjanya K, 2015, IEEE INT ADV COMPUT, P397, DOI 10.1109/IADCC.2015.7154738
   Srivastava Suyash, 2019, Engineering Vibration, Communication and Information Processing. ICoEVCI 2018, India. Lecture Notes in Electrical Engineering (LNEE 478), P679, DOI 10.1007/978-981-13-1642-5_59
   Swain A, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P3312, DOI 10.1109/ICEEOT.2016.7755319
   Vijayan VV, 2015, PROCEEDINGS OF THE 2015 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P122, DOI 10.1109/RAICS.2015.7488400
   Zheng T, 2017, INT J MED INFORM, V97, P120, DOI 10.1016/j.ijmedinf.2016.09.014
   Zou Q, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00515
NR 50
TC 24
Z9 24
U1 5
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2021
VL 17
IS 2
SU S
SI SI
AR 66
DI 10.1145/3415155
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1XY
UT WOS:000671890900001
DA 2024-07-18
ER

PT J
AU Liu, YW
   Liu, JX
   Argyriou, A
   Ma, SW
   Wang, LM
   Xu, Z
AF Liu, Yanwei
   Liu, Jinxia
   Argyriou, Antonios
   Ma, Siwei
   Wang, Liming
   Xu, Zhen
TI 360-Degree VR Video Watermarking Based on Spherical Wavelet Transform
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE 360 degrees VR video; watermarking; spherical wavelet; just noticeable
   difference
ID IMAGE WATERMARKING; SCALE
AB Similar to conventional video, the increasingly popular 360 degrees virtual reality (VR) video requires copyright protection mechanisms. The classic approach for copyright protection is the introduction of a digital watermark into the video sequence. Due to the nature of spherical panorama, traditional watermarking schemes that are dedicated to planar media cannot work efficiently for 360 degrees VR video. In this article, we propose a spherical wavelet watermarking scheme to accommodate 360 degrees VR video. With our scheme, the watermark is first embedded into the spherical wavelet transform domain of the 360 degrees VR video. The spherical geometry of the 360 degrees VR video is used as the host space for the watermark so that the proposed watermarking scheme is compatible with the multiple projection formats of 360 degrees VR video. Second, the just noticeable difference model, suitable for head-mounted displays (HMDs), is used to control the imperceptibility of the watermark on the viewport. Third, besides detecting the watermark from the spherical projection, the proposed watermarking scheme also supports detecting watermarks robustly from the viewport projection. The watermark in the spherical domain can protect not only the 360 degrees VR video but also its corresponding viewports. The experimental results show that the embedded watermarks are reliably extracted both from the spherical and the viewport projections of the 360 degrees VR video, and the robustness of the proposed scheme to various copy-right attacks is significantly better than that of the competing planar-domain approaches when detecting the watermark from viewport projection.
C1 [Liu, Yanwei; Wang, Liming; Xu, Zhen] Chinese Acad Sci, Inst Informat Engn, Beijing 10093, Peoples R China.
   [Liu, Jinxia] Zhejiang Wanli Univ, Ningbo, Peoples R China.
   [Argyriou, Antonios] Univ Thessaly, Volos, Greece.
   [Ma, Siwei] Peking Univ, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Zhejiang Wanli University; University of
   Thessaly; Peking University
RP Liu, JX (corresponding author), Zhejiang Wanli Univ, Ningbo, Peoples R China.
EM liuyanwei@iie.ac.cn; liujinxia1969@126.com; anargyr@uth.gr;
   swma@pke.edu.cn; wangliming@iie.ac.cn; xuzhen@iie.ac.cn
RI Liu, Jinxia/H-1794-2011; Argyriou, Antonios/AAF-9586-2021
OI Argyriou, Antonios/0000-0002-2510-3124
FU National Natural Science Foundation of China [61771469]; Ningbo Natural
   Science Foundation [2019A610109]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61771469 and the Ningbo Natural Science
   Foundation under Grant 2019A610109.
CR Alshina E., 2017, JVET, pH1030
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   [Anonymous], 2012, 10180 GOST
   Baldoni S, 2019, INT SYMP IMAGE SIG, P240, DOI 10.1109/ISPA.2019.8868789
   Beausoleil L. E., 2017, COPYRIGHT ISSUES IMP
   Bradley AP, 1999, IEEE T IMAGE PROCESS, V8, P717, DOI 10.1109/83.760338
   Burini C., 2014, P SPIE, V9028
   Chou CH, 2010, IEEE T IMAGE PROCESS, V19, P2966, DOI 10.1109/TIP.2010.2052261
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cruz-Mota J, 2012, INT J COMPUT VISION, V98, P217, DOI 10.1007/s11263-011-0505-4
   Daniilidis K., 2004, P EUR C COMP VIS ECC
   Doérr G, 2004, IEEE T SIGNAL PROCES, V52, P2955, DOI 10.1109/TSP.2004.833867
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Eade E., 2017, LIE GROUPS 2D 3D TRA
   Garcia E, 2003, IEEE T CIRC SYST VID, V13, P853, DOI 10.1109/TCSVT.2003.815963
   Halici E, 2009, IEEE IMAGE PROC, P4217, DOI 10.1109/ICIP.2009.5413525
   He Y., 2016, SG16WP3 ITUT JOINT V
   High Efficiency Video Coding (HEVC), 2013, 230082 ISOIEC HEVC
   Hua G, 2015, IEEE-ACM T AUDIO SPE, V23, P227, DOI 10.1109/TASLP.2014.2387385
   Huawei-iLab, 2018, CLOUD VR NETW SOL WH
   Jin Jian-Qiu, 2004, J Zhejiang Univ Sci, V5, P251, DOI 10.1631/jzus.2004.0251
   Kalker T., 2008, DIGITAL WATERMARKING
   Kang J, 2020, IEEE ACCESS, V8, P127477, DOI 10.1109/ACCESS.2020.3006980
   Kang J, 2019, LECT NOTES COMPUT SC, V11378, P95, DOI 10.1007/978-3-030-11389-6_8
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Koz A, 2010, IEEE T IMAGE PROCESS, V19, P1785, DOI 10.1109/TIP.2010.2045024
   Lee YS, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8357251
   Li X., 2018, IEEE T IND ELECTRON, P1
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Liu YW, 2019, IEEE T MULTIMEDIA, V21, P1302, DOI 10.1109/TMM.2018.2876044
   Mallat S, 1996, P IEEE, V84, P604, DOI 10.1109/5.488702
   McEwen JD, 2007, IEEE T SIGNAL PROCES, V55, P520, DOI 10.1109/TSP.2006.887148
   McEwen JD, 2018, APPL COMPUT HARMON A, V44, P59, DOI 10.1016/j.acha.2016.03.009
   McEwen JD, 2013, PROC SPIE, V8858, DOI 10.1117/12.2022889
   Miller ML, 2000, LECT NOTES COMPUT SC, V1768, P146
   MPEG Experts, 2016, 1SC29WG11 ISOIECJTC
   Raake A., 2018, P HUM VIS EL IM HVEI
   Schroder P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P161, DOI 10.1145/218380.218439
   Sheppard Nicholas Paul, 2002, J LAW INFORM SCI, V12, P110
   Simons FJ, 2011, GEOPHYS J INT, V187, P969, DOI 10.1111/j.1365-246X.2011.05190.x
   Tsai JS, 2011, IEEE T IMAGE PROCESS, V20, P735, DOI 10.1109/TIP.2010.2073475
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Voloshynovskiy S, 2000, PROC SPIE, V3971, P358, DOI 10.1117/12.384990
   Wang Z, 2004, COMPUT VIS IMAGE UND, V96, P327, DOI 10.1016/j.cviu.2004.03.017
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Yang X., 2017, IEEE GLOB COMM CONF, P1
NR 48
TC 5
Z9 6
U1 3
U2 26
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2021
VL 17
IS 1
AR 38
DI 10.1145/3425605
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RO6SX
UT WOS:000641174200018
DA 2024-07-18
ER

PT J
AU Xu, T
   Zhou, PL
   Hu, LK
   He, XN
   Hu, Y
   Chen, EH
AF Xu, Tong
   Zhou, Peilun
   Hu, Linkang
   He, Xiangnan
   Hu, Yao
   Chen, Enhong
TI Socializing the Videos: A Multimodal Approach for Social Relation
   Recognition
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Social relation recognition; multimodal learning; person search; natural
   language processing
AB As a crucial task for video analysis, social relation recognition for characters not only provides semantically rich description of video content but also supports intelligent applications, e.g., video retrieval and visual question answering. Unfortunately, due to the semantic gap between visual and semantic features, traditional solutions may fail to reveal the accurate relations among characters. At the same time, the development of social media platforms has now promoted the emergence of crowdsourced comments, which may enhance the recognition task with semantic and descriptive cues. To that end, in this article, we propose a novel multimodal-based solution to deal with the character relation recognition task. Specifically, we capture the target character pairs via a search module and then design a multistream architecture for jointly embedding the visual and textual information, in which feature fusion and attention mechanism are adapted for better integrating the multimodal inputs. Finally, supervised learning is applied to classify character relations. Experiments on real-world data sets validate that our solution outperforms several competitive baselines.
C1 [Xu, Tong; Zhou, Peilun; Hu, Linkang; He, Xiangnan; Chen, Enhong] Univ Sci & Technol China, Hefei 230026, Peoples R China.
   [Hu, Yao] Alibaba Inc, Alibaba Youku Cognit & Intelligent Lab, Beijing 100016, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Alibaba Group
RP Chen, EH (corresponding author), Univ Sci & Technol China, Hefei 230026, Peoples R China.
EM tongxu@ustc.edu.cn; zpl@mail.ustc.edu.cn; hulk@mail.ustc.edu.cn;
   xiangnanhe@gmail.com; yaoohu@alibaba-inc.com; cheneh@ustc.edu.cn
RI Hu, Yao/KEH-3649-2024
OI Chen, Enhong/0000-0002-4835-4102
FU National Key Research and Development Program of China [2018YFB1402600];
   National Natural Science Foundation of China [61727809, 62072423,
   U19A2079]
FX This research was partially supported by grants fromthe National Key
   Research and Development Program of China (Grant No. 2018YFB1402600) and
   the National Natural Science Foundation of China (Grant No. 61727809,
   62072423, U19A2079).
CR [Anonymous], 2015, ARXIVCSCV151203385
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   [陈卓 Chen Joya], 2020, [中国科学. 信息科学, Scientia Sinica Informationis], V50, P862
   Dai PL, 2019, IEEE INT CON MULTI, P1132, DOI 10.1109/ICME.2019.00198
   Ding L, 2010, LECT NOTES COMPUT SC, V6314, P410, DOI 10.1007/978-3-642-15561-1_30
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   Guangyi Lv, 2019, IEEE T BIG DATA
   Hamdoun O, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P140
   Hermans Alexander, 2017, ARXIV170307737
   Hu A, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P350, DOI 10.1145/3219819.3219853
   Huang Qingqiu, 2018, ABS180710510 CORR
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Lajugie R., 2014, ADV NEURAL INFORM PR
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu Wu, 2018, P IEEE CVF C COMP VI
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Lv GY, 2016, AAAI CONF ARTIF INTE, P3000
   Lv Guangyi, 2019, 23 PAC AS C KNOWL DI
   Lv JN, 2019, LECT NOTES COMPUT SC, V11296, P390, DOI 10.1007/978-3-030-05716-9_32
   Lv JN, 2018, LECT NOTES COMPUT SC, V10704, P355, DOI 10.1007/978-3-319-73603-7_29
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Park SB, 2012, MULTIMED TOOLS APPL, V59, P601, DOI 10.1007/s11042-011-0725-1
   Poria S, 2017, IEEE DATA MINING, P1033, DOI 10.1109/ICDM.2017.134
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shang XD, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P279, DOI 10.1145/3323873.3325056
   Shang XD, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1300, DOI 10.1145/3123266.3123380
   Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Sun QR, 2017, PROC CVPR IEEE, P435, DOI 10.1109/CVPR.2017.54
   Tanisik Gokhan, 2015, ABS150905366 ARXIV
   Tran QD, 2015, J UNIVERS COMPUT SCI, V21, P796
   Vielzeuf V., 2017, P 19 ACM INT C MULT, P569
   Wei YW, 2020, IEEE T IMAGE PROCESS, V29, P1, DOI 10.1109/TIP.2019.2923608
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Wu H, 2019, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2019.00677
   Xu YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P937, DOI 10.1145/2647868.2654965
   Yan Y., 2018, P 27 INT JOINT C ART
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474
   Zhang ZP, 2015, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2015.414
   Zhou PL, 2020, IEEE T MULTIMEDIA, V22, P2684, DOI 10.1109/TMM.2019.2960594
NR 42
TC 8
Z9 8
U1 2
U2 20
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2021
VL 17
IS 1
AR 23
DI 10.1145/3416493
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RO6SX
UT WOS:000641174200003
DA 2024-07-18
ER

PT J
AU Singh, AK
AF Singh, A. K.
TI Data Hiding: Current Trends, Innovation and Potential Challenges
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Watermarking; copyright; telemedicine; cloud; biometric; encryption;
   compression; cyber physical systems; 3D objects; mobile
ID MEDICAL IMAGE WATERMARKING; NETWORK FLOW WATERMARKING; REVERSIBLE
   WATERMARKING; STEGANALYTIC ALGORITHM; LOSSLESS COMPRESSION; SECURE
   WATERMARKING; IP CORES; ROBUST; SCHEME; STEGANOGRAPHY
AB With the widespread growth of digital information and improved internet technologies, the demand for improved information security techniques has significantly increased due to privacy leakage, identity theft, illegal copying, and data distribution. Because of this, data hiding approaches have received much attention in several application areas. However, those approaches are unable to solve many issues that are necessary to measure in future investigations. This survey provides a comprehensive survey on data hiding techniques and their new trends for solving new challenges in real-world applications. The notable applications are telemedicine, 3D objects, mobile devices, cloud/distributed computing and data mining environments, chip and hardware protection, cyber physical systems, Internet traffic, fusion of watermarking and encryption, joint compression and watermarking, biometric watermarking, watermarking at the physical layer, and many other perspectives. Further, the potential issues that existing approaches of data hiding face are identified. I believe that this survey will provide a valuable source of information for finding research directions for fledgling researchers and developers.
C1 [Singh, A. K.] NIT Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, AK (corresponding author), NIT Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM amit.singh@nitp.ac.in
FU Defence Electronics Research Laboratory (DLRL), Ministry of Defence,
   DRDO, Hyderabad [DLRL/21CR0003/SWCCENT/GN/LP]
FX I gratefully acknowledge the authorities of the National Institute of
   Technology Patna, India, for their kind support and inspiration for this
   article. Further, this work is supported by research project entitled
   "Copyright protection tool for digital data" order no.
   DLRL/21CR0003/SWCC&ENT/GN/LP dt. 29 August, 2020, Defence Electronics
   Research Laboratory (DLRL), Ministry of Defence, DRDO, Hyderabad.
CR Ai QS, 2009, SIGNAL PROCESS, V89, P2159, DOI 10.1016/j.sigpro.2009.04.031
   Al-Haj A, 2017, MEASUREMENT, V95, P405, DOI 10.1016/j.measurement.2016.10.016
   Aleksandrova M, 2017, INT SPR SEM ELECT TE
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   [Anonymous], 2016, CIRCUITS SYSTEMS
   Anwar A.S., 2015, INT J BIOMED INFORM, V3, P7
   Aparna P, 2019, IET IMAGE PROCESS, V13, P421, DOI 10.1049/iet-ipr.2018.5288
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Asikuzzaman M, 2016, IEEE T MULTIMEDIA, V18, P1733, DOI 10.1109/TMM.2016.2589208
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Bhowmik D, 2016, IEEE T IMAGE PROCESS, V25, P5158, DOI 10.1109/TIP.2016.2599785
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Borra S, 2020, COMP M BIO BIO E-IV, V8, P345, DOI 10.1080/21681163.2019.1595730
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Cao XY, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/3219042
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chao MW, 2009, IEEE T VIS COMPUT GR, V15, P274, DOI 10.1109/TVCG.2008.94
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Etemad E, 2018, MULTIMED TOOLS APPL, V77, P2033, DOI 10.1007/s11042-016-4278-1
   Farfoura Mahmoud E., 2010, 2010 International Symposium on Parallel and Distributed Processing with Applications (ISPA 2010), P563, DOI 10.1109/ISPA.2010.63
   Farfoura M. E., 2010, P INT S PAR DISTR PR
   Feng J., 2003, P SPIE INT SOC OPTIC
   Fu YG, 2008, COMPUT STAND INTER, V30, P115, DOI 10.1016/j.csi.2007.08.013
   Gandomi AH, 2013, NEURAL COMPUT APPL, V22, P1239, DOI 10.1007/s00521-012-1028-9
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Guo Jing-Ming, 2015, IEEE Trans Image Process, V24, P2009, DOI 10.1109/TIP.2014.2387417
   Harjito B., 2012, P 8 INT C SEM KNOWL
   Heidari S, 2016, INT J THEOR PHYS, V55, P4205, DOI 10.1007/s10773-016-3046-3
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu DH, 2019, IEEE T KNOWL DATA EN, V31, P1024, DOI 10.1109/TKDE.2018.2851517
   Iacovazzi A, 2017, IEEE COMMUN SURV TUT, V19, P512, DOI 10.1109/COMST.2016.2604405
   Iftikhar S., 2015, IEEE SYSTEMS J, V11, P197
   Iftikhar S, 2015, IEEE T KNOWL DATA EN, V27, P1132, DOI 10.1109/TKDE.2014.2349911
   Imamoglu MB, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/1387375
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jawad K, 2013, J SYST SOFTWARE, V86, P2742, DOI 10.1016/j.jss.2013.06.023
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kejariwal A, 2006, IEEE T VLSI SYST, V14, P625, DOI 10.1109/TVLSI.2006.878218
   Khadam U, 2019, IEEE ACCESS, V7, P64955, DOI 10.1109/ACCESS.2019.2916674
   Khor HL, 2016, INT J BIOMED IMAGING, V2016, DOI 10.1155/2016/9583727
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Kleider J. E., 2004, P IEEE INT C AC SPEE
   Koushanfar F, 2005, ACM T DES AUTOMAT EL, V10, P523, DOI 10.1145/1080334.1080338
   Lee MJ, 2010, IEEE T MULTIMEDIA, V12, P605, DOI 10.1109/TMM.2010.2061221
   Lei BY, 2013, J SYST SOFTWARE, V86, P1638, DOI 10.1016/j.jss.2013.02.022
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li X., 2013, P IEEE MIL COMM C
   Li XW, 2013, OPT LASER ENG, V51, P1310, DOI 10.1016/j.optlaseng.2013.06.001
   Liu K., 2017, SECUR COMM NETWORKS, V2017
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   Lu TB, 2016, INT J SECUR APPL, V10, P129, DOI 10.14257/ijsia.2016.10.3.12
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ma ZF, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0307-5
   Meng ZX, 2018, P INT COMP SOFTW APP, P359, DOI 10.1109/COMPSAC.2018.10258
   Mishra A, 2019, MULTIMED TOOLS APPL, V78, P22127, DOI 10.1007/s11042-019-7452-4
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Nie TY, 2013, IETE TECH REV, V30, P367, DOI 10.4103/0256-4602.123116
   Nishchal NK, 2009, J OPT-INDIA, V38, P22, DOI 10.1007/s12596-009-0003-z
   Nyeem H, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/1475-925X-14-7
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Salameh JNB, 2019, INT J COMPUT SCI NET, V19, P28
   Sankaran K. Sakthidasan, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0568, DOI 10.1109/ICCSP.2019.8698057
   Sarkar P, 2019, IEEE CONSUM ELECTR M, V8, P92, DOI 10.1109/MCE.2018.2867978
   Satchidanandan B, 2017, P IEEE, V105, P219, DOI 10.1109/JPROC.2016.2575064
   Sengupta A, 2016, IEEE ACCESS, V4, P2198, DOI 10.1109/ACCESS.2016.2552058
   Shehab M, 2008, IEEE T KNOWL DATA EN, V20, P116, DOI 10.1109/TKDE.2007.190668
   Shen JJ, 2010, DIGIT SIGNAL PROCESS, V20, P1408, DOI 10.1016/j.dsp.2009.10.015
   Shini SG, 2012, PROCEDIA ENGINEER, V38, P3454, DOI 10.1016/j.proeng.2012.06.399
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P3871, DOI 10.1007/s11042-016-4048-0
   Srivastava R, 2018, MULTIMED TOOLS APPL, V77, P16447, DOI 10.1007/s11042-017-5214-8
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Sun YY, 2015, IET IMAGE PROCESS, V9, P173, DOI 10.1049/iet-ipr.2014.0224
   Tao Z, 2010, ARCH ACOUST, V35, P481, DOI 10.2478/v10168-010-0037-x
   Thakur S., 2018, CONCURRENCY COMPUTAT
   Thakur S., 2018, MULTIMED TOOLS APPL, V79, P4263
   Thakur S., 2018, Cryptographic and Information Security Approaches for Images and Videos, P467
   Tong XJ, 2017, MULTIMED TOOLS APPL, V76, P13995, DOI 10.1007/s11042-016-3775-6
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tufail H, 2019, COMPUT INTELL-US, V35, P693, DOI 10.1111/coin.12209
   Vatsa M, 2009, IMAGE VISION COMPUT, V27, P293, DOI 10.1016/j.imavis.2007.05.003
   Wang XY, 2006, IEEE T SIGNAL PROCES, V54, P4835, DOI 10.1109/TSP.2006.881258
   Wang XY, 2012, APPL SOFT COMPUT, V12, P887, DOI 10.1016/j.asoc.2011.10.003
   Wu CC, 2011, J SYST SOFTWARE, V84, P2196, DOI 10.1016/j.jss.2011.06.021
   Yang Y, 2014, OXID MED CELL LONGEV, V2014, DOI 10.1155/2014/145641
   Yang Y, 2017, IEEE T VIS COMPUT GR, V23, P1002, DOI 10.1109/TVCG.2016.2525771
   Yang Y, 2014, IEEE IMAGE PROC, P4782, DOI 10.1109/ICIP.2014.7025969
   Yu PL, 2008, IEEE T INF FOREN SEC, V3, P38, DOI 10.1109/TIFS.2007.916273
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng SL, 2016, MULTIMED TOOLS APPL, V75, P13765, DOI 10.1007/s11042-015-2920-y
   Ziener D, 2008, J SIGNAL PROCESS SYS, V51, P123, DOI 10.1007/s11265-007-0136-8
NR 102
TC 43
Z9 50
U1 2
U2 44
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2021
VL 16
IS 3
SU S
AR 101
DI 10.1145/3382772
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PZ2RB
UT WOS:000612586300009
DA 2024-07-18
ER

PT J
AU Yan, CG
   Li, ZS
   Zhang, YB
   Liu, YT
   Ji, XY
   Zhang, YD
AF Yan, Chenggang
   Li, Zhisheng
   Zhang, Yongbing
   Liu, Yutao
   Ji, Xiangyang
   Zhang, Yongdong
TI Depth Image Denoising Using Nuclear Norm and Learning Graph Model
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Learning graph model; low-rank; nonlocal self-similarity; ADMM
ID MATRIX COMPLETION; SPARSE; TRANSFORM
AB Depth image denoising is increasingly becoming the hot research topic nowadays, because it reflects the three-dimensional scene and can be applied in various fields of computer vision. But the depth images obtained from depth camera usually contain stains such as noise, which greatly impairs the performance of depth-related applications. In this article, considering that group-based image restoration methods are more effective in gathering the similarity among patches, a group-based nuclear norm and learning graph (GNNLG) model was proposed. For each patch, we find and group the most similar patches within a searching window. The intrinsic low-rank property of the grouped patches is exploited in our model. In addition, we studied the manifold learning method and devised an effective optimized learning strategy to obtain the graph Laplacian matrix, which reflects the topological structure of image, to further impose the smoothing priors to the denoised depth image. To achieve fast speed and high convergence, the alternating direction method of multipliers is proposed to solve our GNNLG. The experimental results show that the proposed method is superior to other current state-of-the-art denoising methods in both subjective and objective criterion.
C1 [Yan, Chenggang; Li, Zhisheng] Hangzhou Dianzi Univ, Hangzhou, Peoples R China.
   [Zhang, Yongbing; Liu, Yutao] Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China.
   [Ji, Xiangyang] Tsinghua Univ, Beijing, Peoples R China.
   [Zhang, Yongdong] Univ Sci & Technol China, Hefei, Peoples R China.
C3 Hangzhou Dianzi University; Tsinghua Shenzhen International Graduate
   School; Tsinghua University; Tsinghua University; Chinese Academy of
   Sciences; University of Science & Technology of China, CAS
RP Zhang, YB; Liu, YT (corresponding author), Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China.
EM cgyan@hdu.edu.cn; zhisheng.li.go0411@outlook.com;
   zhang.yongbing@sz.tsinghua.edu.cn; ytliu18@sz.tsinghua.edu.cn;
   xyji@tsinghua.edu.cn; zhyd73@ustc.edu.cn
RI li, zhisheng/O-6845-2014
FU National Nature Science Foundation of China [61931008, 61671196,
   61701149, 61801157, 61971268, 61901145, 61901150, 61972123, 61922048];
   National Natural Science Major Foundation of Research Instrumentation of
   PR China [61427808]; Zhejiang Province Nature Science Foundation of
   China [LR17F030006, Q19F010030]; 111 Project [D17019]; China
   Postdoctoral Science Foundation [2019M650686]
FX This work was supported by National Nature Science Foundation of China
   (61931008, 61671196, 61701149, 61801157, 61971268, 61901145, 61901150,
   61972123, 61922048), by the National Natural Science Major Foundation of
   Research Instrumentation of PR China under Grants 61427808, Zhejiang
   Province Nature Science Foundation of China (LR17F030006, Q19F010030),
   111 Project, No. D17019, and the China Postdoctoral Science Foundation
   under Grant 2019M650686.
CR [Anonymous], 2017, IEEE SIGNAL PROCESSI
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Chaudhuri B, 2016, IEEE GEOSCI REMOTE S, V13, P987, DOI 10.1109/LGRS.2016.2558289
   Chen Rong, 2017, International Forum on Digital TV and Wireless Multimedia Communications, P128
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deng C, 2014, IEEE T MULTIMEDIA, V16, P785, DOI 10.1109/TMM.2014.2298841
   Dong WS, 2017, IEEE T MULTIMEDIA, V19, P293, DOI 10.1109/TMM.2016.2613824
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gogna A, 2014, IEEE IMAGE PROC, P1302, DOI 10.1109/ICIP.2014.7025260
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hao BB, 2014, INT C INTEL HUM MACH, P249, DOI 10.1109/IHMSC.2014.68
   Hu Wei, 2013, P 2013 IEEE 15 INTER, P001
   Huang DA, 2014, IEEE T MULTIMEDIA, V16, P83, DOI 10.1109/TMM.2013.2284759
   Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849
   Kalofolias V, ARXIV14081717
   Kamilov US, 2017, IEEE T IMAGE PROCESS, V26, P539, DOI 10.1109/TIP.2016.2629449
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Li Z, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/5891759
   Liu J, 2013, IEEE T IMAGE PROCESS, V22, P1108, DOI 10.1109/TIP.2012.2227766
   Liu XM, 2017, IEEE T IMAGE PROCESS, V26, P509, DOI 10.1109/TIP.2016.2627807
   Liu YP, 2019, IEEE T MULTIMEDIA, V21, P338, DOI 10.1109/TMM.2018.2859026
   Lu S, 2014, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2014.433
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Rousseau F, 2011, IEEE T MED IMAGING, V30, P1852, DOI 10.1109/TMI.2011.2156806
   Selesnick I, 2017, IEEE SIGNAL PROC LET, V24, P216, DOI 10.1109/LSP.2017.2647948
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Starck Jean-Luc, 2004, CMP00052061
   Tian D, 2009, PROC SPIE, V7443, DOI 10.1117/12.829372
   Tomassi D, 2015, SIGNAL PROCESS, V106, P73, DOI 10.1016/j.sigpro.2014.07.001
   Wang SP, 2017, IEEE T MULTIMEDIA, V19, P1454, DOI 10.1109/TMM.2017.2663324
   Wang Shuyang, 2017, IEEE Transactions on Image Processing, V27, P500
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Xue HY, 2017, IEEE T IMAGE PROCESS, V26, P4311, DOI 10.1109/TIP.2017.2718183
   Yan C., 2020, 3D ROOM LAYOUT ESTIM
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan Chenggang, 2020, IEEE Trans. Pattern Anal. Machine Intell.
   Yankelevsky Y, 2016, IEEE T SIGNAL INF PR, V2, P611, DOI 10.1109/TSIPN.2016.2605763
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang XD, 2013, IEEE T IMAGE PROCESS, V22, P408, DOI 10.1109/TIP.2012.2214043
   Zhu ZL, 2014, IEEE T MULTIMEDIA, V16, P2178, DOI 10.1109/TMM.2014.2364976
NR 49
TC 147
Z9 149
U1 9
U2 57
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2021
VL 16
IS 4
AR 122
DI 10.1145/3404374
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QB4CR
UT WOS:000614088800006
OA Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Wang, X
   Tian, Y
   Zhao, XR
   Yang, T
   Gelernter, J
   Wang, JL
   Cheng, GH
   Hu, W
AF Wang, Xun
   Tian, Yan
   Zhao, Xuran
   Yang, Tao
   Gelernter, Judith
   Wang, Jialei
   Cheng, Guohua
   Hu, Wei
TI Improving Multiperson Pose Estimation by Mask-aware Deep Reinforcement
   Learning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Computer vision; deep learning; regularization; reinforcement learning
AB Research on single-person pose estimation based on deep neural networks has recently witnessed progress in both accuracy and execution efficiency. However, multiperson pose estimation is still a challenging topic, partially because the object regions are selected greedily from proposals via class-agnostic nonmaximum suppression (NMS), and the misalignment in the redundant detection yields inaccurate human poses. Therefore, we consider how to obtain the optimal input in human pose estimation under conditions in which intermediate label information is not available. As supervised learning-based alignment does not generalize well to unseen samples in the human pose space, in this article, we present a mask-aware deep reinforcement learning approach to modify the detection result. We use mask information to remove the adverse effects from the cluttered background and to select the optimal action according to the revised reward function. We also propose a new regularization term to punish joints that are outside of the silhouette region in the human pose estimation stage. We evaluate our approach on the MPII Multiperson dataset and the MS-COCO Keypoints Challenge. The results show that our approach yields competing inference results when it is compared to the other state-of-the-art approaches.
C1 [Wang, Xun; Tian, Yan; Zhao, Xuran; Yang, Tao] Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, 18 Xuezheng Rd, Hangzhou 310018, Peoples R China.
   [Gelernter, Judith] Rutgers State Univ, Sch Commun & Informat, 620 George St, New Brunswick, NJ 08901 USA.
   [Wang, Jialei] Shining3D Tech Co Ltd, Shining3D Res, 701 Gudun Rd, Hangzhou 310018, Peoples R China.
   [Cheng, Guohua] Fudan Univ, Inst Sci & Technol Brain Inspired Intelligence, Minist Educ, Key Lab Computat Neurosci & Brain Inspired Intell, 220 Handan Rd, Shanghai 200433, Peoples R China.
   [Hu, Wei] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, 199 Xiongchu Rd, Wuhan 430065, Peoples R China.
C3 Zhejiang Gongshang University; Rutgers University System; Rutgers
   University New Brunswick; Fudan University; Wuhan University of Science
   & Technology
RP Tian, Y (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, 18 Xuezheng Rd, Hangzhou 310018, Peoples R China.
EM wx@zjgsu.edu.cn; tianyan@zjgsu.edu.cn; zxr@zjgsu.edu.cn;
   yangt@zjgsu.edu.cn; gelern@comminfo.rutgers.edu;
   wangjialei@shining3d.com; 17110850005@fudan.edu.cn; huwei@wust.edu.cn
OI Qu, Gang/0000-0001-6759-8949
FU National Natural Science Foundation of China [U1609215, 61972351,
   61976188, 61702453]; Natural Science Foundation of Zhejiang Province
   [LY19F030005, LY18F020008, LQ17F030001, LQ20F020008]; Key R&D Program of
   Zhejiang Province [2018C01112]
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant U1609215, Grant 61972351, Grant
   61976188, and Grant 61702453, in part by the Natural Science Foundation
   of Zhejiang Province under Grant LY19F030005, Grant LY18F020008, Grant
   LQ17F030001, and Grant LQ20F020008, in part by the Key R&D Program of
   Zhejiang Province under Grant 2018C01112.
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], P NIPS WORKSH
   [Anonymous], DATABASE OXFORD
   Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286
   Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180
   Cao Zhe, 2017, P CVPR, P3641
   Chen YT, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P574, DOI 10.1109/ICASI.2018.8394318
   Chu X., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1831, DOI DOI 10.1109/CVPR.2017.601
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025
   Das A, 2017, IEEE I CONF COMP VIS, P2970, DOI 10.1109/ICCV.2017.321
   Fang Hao-Shu, 2017, P ICCV, P1640
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Harley AW, 2017, IEEE I CONF COMP VIS, P5048, DOI 10.1109/ICCV.2017.539
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hong C, 2015, AAAI CONF ARTIF INTE, P4239
   Huang C, 2017, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2017.21
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Insafutdinov Eldar, 2017, P CVPR, P520
   Iqbal U, 2016, LECT NOTES COMPUT SC, V9914, P627, DOI 10.1007/978-3-319-48881-3_44
   Ke LP, 2018, LECT NOTES COMPUT SC, V11206, P731, DOI 10.1007/978-3-030-01216-8_44
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Levinkov Evgeny, 2017, P CVPR
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu SY, 2014, ADV MECH ENG, DOI 10.1155/2014/868041
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Newell A, 2017, ADV NEUR IN, V30
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Rao YM, 2017, IEEE I CONF COMP VIS, P3951, DOI 10.1109/ICCV.2017.424
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tian Y, 2013, IMAGE VISION COMPUT, V31, P223, DOI 10.1016/j.imavis.2012.06.009
   Wang ZP, 2016, AER ADV ENG RES, V63, P560
   Xiao B, 2015, IEEE T MULTIMEDIA, V17, P1107, DOI 10.1109/TMM.2015.2432671
   Xie Shuqin, 2018, P CVPR, P472
   Yang Wei, 2017, P ICCV, P840
   Yi X, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1450, DOI 10.1109/CompComm.2017.8322782
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
NR 41
TC 9
Z9 9
U1 1
U2 20
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2020
VL 16
IS 3
AR 84
DI 10.1145/3397340
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NO3HD
UT WOS:000569375200010
DA 2024-07-18
ER

PT J
AU Panetta, K
   Bao, L
   Agaian, S
   Oludare, V
AF Panetta, Karen
   Bao, Long
   Agaian, Sos
   Oludare, Victor
TI Color Theme-based Aesthetic Enhancement Algorithm to Emulate the Human
   Perception of Beauty in Photos
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Aesthetic enhancement; color theme; fine art photography; human
   aesthetic perception; big data
ID IMAGE; PALETTES
AB Fine Art Photography is one of the most popular art forms, which creates lasting impressions that elicit various human emotional reactions. Photo aesthetic enhancement aims at improving the aesthetic level of the photo to please humans by updating color appearance or modifying the geometry structure of objects within that photo. Even though several aesthetic enhancement methods have been proposed, to our knowledge, there is no research to explore, highlight, and accentuate photos' intrinsic aesthetic value to elicit a stronger response from the human observer about the photos' theme. To meet this challenge, a new multimedia technology called automatic color theme-based aesthetic enhancement (CT-AEA) is proposed by leveraging big online data to perform timely collection and learning of humans' current aesthetic perception-behavior over photos and color themes in art, fashion, and design. Unlike existing aesthetic enhancement that examines the composition, such as the geometric structure of the image contents and color/luminance-related (color tone and luminance distribution) characteristics, this CT-AEA takes into consideration the importance of a suitable color theme, namely a set of dominant colors for the design when assessing the aesthetic appearance of a photo. This algorithm is composed of (1) utilizing the knowledge gained from the human evaluator's perception of beauty from existing online datasets, rather than simply applying prior existing knowledge of color harmony theory; (2) developing a new color theme difference equation that exhibits order-invariance and percentage-sensitive properties; (3) designing an optimal color theme recommendation to maximize the aesthetic performance, while minimizing the color modification cost to solve the problems of color inconsistencies and distortion. Experimental results, quantitative measure, and comparison tests demonstrate the algorithm's effectiveness, advantages, and potential for use in many color-related art and design applications.
C1 [Panetta, Karen; Bao, Long] Tufts Univ, Dept Elect & Comp Engn, Medford, MA 02155 USA.
   [Agaian, Sos] CUNY, New York, NY 10021 USA.
   [Oludare, Victor] Tufts Univ, Medford, MA 02155 USA.
   [Agaian, Sos] Univ Texas San Antonio, Dept Elect Engn, San Antonio, TX 78249 USA.
C3 Tufts University; City University of New York (CUNY) System; Tufts
   University; University of Texas System; University of Texas at San
   Antonio (UTSA)
RP Bao, L (corresponding author), Tufts Univ, Dept Elect & Comp Engn, Medford, MA 02155 USA.
EM karen@ece.tufts.edu; baolonghnu@gmail.com; Sos.Agaian@csi.cuny.edu
RI Agaian, Sos s/IZE-1724-2023
OI Agaian, Sos s/0000-0003-4601-4507
CR Agarwala A., 2014, P WORKSH COMP AESTH
   Bao L., 2017, Proceedings of the IEEE International Symposium on Technologies for Homeland Security (HST'17), P1
   Bao L., 2015, 2015 IEEE International Conference on Technologies for Practical Robot Applications (TePRA), P1
   Bao L, 2016, PROC SPIE, V9869, DOI 10.1117/12.2224210
   Bhattacharya S, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037678
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chen JS, 2016, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.2016.61
   Choi JH, 2016, WORLD J SURG ONCOL, V14, DOI 10.1186/s12957-016-0829-1
   Chong P. T. -F., 2015, U. S. Patent No, Patent No. 9134179
   Datta R., 2006, Studying Aesthetics in Photographic Images Using a Computational Approach, P288
   Deng Y., 2017, AESTHETIC DRIVEN IMA
   Gao Y., 2016, P INT C INT MULT COM
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Guo YW, 2012, COMPUT GRAPH FORUM, V31, P2193, DOI 10.1111/j.1467-8659.2012.03212.x
   Hasler D., 2003, P C HUM VIS EL IM 8, VVIII
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P1124, DOI 10.1109/TIP.2016.2514499
   Islam MB, 2017, MULTIMED TOOLS APPL, V76, P9517, DOI 10.1007/s11042-016-3561-5
   Islam MB, 2015, Proceedings 3rd IAPR Asian Conference on Pattern Recognition ACPR 2015, P645, DOI 10.1109/ACPR.2015.7486582
   Jeong K, 2016, CLUSTER COMPUT, V19, P939, DOI 10.1007/s10586-016-0547-z
   Kaya N., 2004, COLL STUD J, V38, P396
   Lant K., 2017, Colors in marketing and advertising
   Lim S. H., 2016, U. S. Patent, Patent No. 9369684
   Liu CF, 2019, IEEE T FUZZY SYST, V27, P72, DOI 10.1109/TFUZZ.2018.2859184
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu Ligang, 2010, COMPUT GRAPH FORUM, V29, P2
   Liu L, 2010, IEEE INT CONF GROUP, P7, DOI 10.1109/GROUP4.2010.5643444
   Liu SG, 2016, COLOR RES APPL, V41, P513, DOI 10.1002/col.21988
   Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498
   Mota J. F., 2017, P 6 SIGN PROC AD SPA
   Nayak J, 2015, SMART INNOV SYST TEC, V32, P133, DOI 10.1007/978-81-322-2208-8_14
   Nishiyama M, 2011, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2011.5995539
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321
   Panetta K, 2016, IEEE T CONSUM ELECTR, V62, P292, DOI 10.1109/TCE.2016.7613196
   Panetta K, 2016, IEEE INSTRU MEAS MAG, V19, P34, DOI 10.1109/MIM.2016.7477952
   Phan HQ, 2018, IEEE T VIS COMPUT GR, V24, P1942, DOI 10.1109/TVCG.2017.2697948
   Schifanella R., 2015, P INT AAAI C WEB SOC
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Yan JZ, 2013, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2013.130
   Yeh CH, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2584105
   Ying Zhang, 2014, ACM Transactions on Multimedia Computing, Communications and Applications, V11, DOI 10.1145/2659520
   Zhang FL, 2013, IEEE T MULTIMEDIA, V15, P1480, DOI 10.1109/TMM.2013.2268051
NR 44
TC 3
Z9 3
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2019
VL 15
IS 2
SU S
SI SI
AR 62
DI 10.1145/3328991
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS2RO
UT WOS:000482001900015
OA Bronze
DA 2024-07-18
ER

PT J
AU Yang, XS
   Xu, CS
AF Yang, Xiaoshan
   Xu, Changsheng
TI Image Captioning by Asking Questions
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image captioning; visual question answering; attention networks
ID VIDEO
AB Image captioning and visual question answering are typical tasks that connect computer vision and natural language processing. Both of them need to effectively represent the visual content using computer vision methods and smoothly process the text sentence using natural language processing skills. The key problem of these two tasks is to infer the target result based on the interactive understanding of the word sequence and the image. Though they practically use similar algorithms, they are studied independently in the past few years. In this article, we attempt to exploit the mutual correlation between these two tasks. We propose the first VQA-improved image-captioning method that transfers the knowledge learned from the VQA corpora to the image-captioning task. A VQA model is first pretrained on image-question-answer instances. Then, the pretrained VQA model is used to extract VQA-grounded semantic representations according to selected free-form open-ended visual question-answer pairs. The VQA-grounded features are complementary to the visual features, because they interpret images from a different perspective. We incorporate the VQA model into the image-captioning model by adaptively fusing the VQA-grounded feature and the attended visual feature. We show that such simple VQA-improved image-captioning (VQA-IIC) models perform better than conventional image-captioning methods on large-scale public datasets.
C1 [Yang, Xiaoshan; Xu, Changsheng] Univ Chinese Acad Sci, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Institute of Automation, CAS
RP Yang, XS (corresponding author), Univ Chinese Acad Sci, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM xiaoshan.yang@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn
RI xu, cj/HJZ-3488-2023; Xu, Chang/GQP-7280-2022
FU National Key Research and Development Program of China [2017YFB1002804];
   National Natural Science Foundation of China [61702511, 61720106006,
   61620106003, 61432019, 61632007, U1705262, U1836220]; Key Research
   Program of Frontier Sciences, CAS [QYZDJSSWJSC039]; Research Program of
   National Laboratory of Pattern Recognition [Z-2018007]; CCF-Tencent Open
   Fund
FX This work was supported in part by National Key Research and Development
   Program of China (No. 2017YFB1002804), National Natural Science
   Foundation of China (No. 61702511, 61720106006, 61620106003, 61432019,
   61632007, U1705262, U1836220) and Key Research Program of Frontier
   Sciences, CAS, Grant NO. QYZDJSSWJSC039. This work was also supported by
   Research Program of National Laboratory of Pattern Recognition (No.
   Z-2018007) and CCF-Tencent Open Fund.
CR Andreas J., 2016, P 2016 C N AM CHAPT, P1545, DOI DOI 10.18653/V1/N16-1181
   Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12
   [Anonymous], 2015, P INT C MACH LEARN
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], ABS150502074 CORR
   [Anonymous], ABS160605433 CORR
   [Anonymous], ABS150505612 CORR
   [Anonymous], 2004, P WORKSH TEXT SUMM B
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2014, ABS14112539 CORR
   [Anonymous], 2018, P IEEE C COMP VIS PA
   [Anonymous], 2015, P IEEE INT C PEER PE
   [Anonymous], ABS151105676 CORR
   [Anonymous], 2014, ABS14126632 CORR
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Hong RC, 2017, IEEE T IMAGE PROCESS, V26, P4128, DOI 10.1109/TIP.2017.2710635
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hong RC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2043612.2043613
   Karpathy A, 2014, ADV NEUR IN, V27
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kim JH, 2016, ADV NEUR IN, V29
   Kingma D. P., 2014, arXiv
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin X, 2016, LECT NOTES COMPUT SC, V9906, P261, DOI 10.1007/978-3-319-46475-6_17
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Ma L, 2016, AAAI CONF ARTIF INTE, P3567
   Malinowski M, 2014, ADV NEUR IN, V27
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Tu K, 2014, IEEE MULTIMEDIA, V21, P42, DOI 10.1109/MMUL.2014.29
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang P, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1290
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Wu Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1029, DOI 10.1145/3240508.3240640
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Xu K., 2015, COMPUTER SCI, P2048
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, T ASSOC COMPUT LING, V2, P67, DOI [DOI 10.1162/TACL_A_00166, 10.1162/tacl_a_00166]
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 62
TC 7
Z9 8
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2019
VL 15
IS 2
SU S
SI SI
AR 55
DI 10.1145/3313873
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS2RO
UT WOS:000482001900008
DA 2024-07-18
ER

PT J
AU Chen, YD
   Hao, CY
   Liu, AX
   Wu, EH
AF Chen, Yadang
   Hao, Chuanyan
   Liu, Alex X.
   Wu, Enhua
TI Appearance-consistent Video Object Segmentation Based on a Multinomial
   Event Model
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multinomial event model; appearance consistency; Markov random field
ID TRACKING
AB In this study, we propose an effective and efficient algorithm for unconstrained video object segmentation, which is achieved in a Markov random field (MRF). In the MRF graph, each node is modeled as a superpixel and labeled as either foreground or background during the segmentation process. The unary potential is computed for each node by learning a transductive SVM classifier under supervision by a few labeled frames. The pairwise potential is used for the spatial-temporal smoothness. In addition, a high-order potential based on the multinomial event model is employed to enhance the appearance consistency throughout the frames. To minimize this intractable feature, we also introduce a more efficient technique that simply extends the original MRF structure. The proposed approach was evaluated in experiments with different measures and the results based on a benchmark demonstrated its effectiveness compared with other state-of-the-art algorithms.
C1 [Chen, Yadang] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Hao, Chuanyan] Nanjing Univ Posts & Telecommun, Sch Educ Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Liu, Alex X.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
   [Liu, Alex X.] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210044, Jiangsu, Peoples R China.
   [Wu, Enhua] Univ Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100864, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Posts & Telecommunications; Michigan State University;
   Nanjing University; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Chen, YD (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
EM cyd4511632@gmail.com; hcy@njupt.edu.cn; alexliu@cse.msu.edu;
   ehwu@umac.mo
RI Liu, xuefeng/IUP-1483-2023
FU National Natural Science Foundation of China [61802197, 61702278,
   61872082, 61472184, 61703212, 61602252]; National Science Foundation
   [CNS-1837146]; Natural Science Foundation of Jiangsu Province of China
   [BK20160964, BK20160902, BK20160971, BK20160967]; Priority Academic
   Program Development (PAPD) of Jiangsu Higher Education Institutions;
   Jiangsu Innovation and Entrepreneurship (Shuangchuang) Program
FX This work is partially supported by the National Natural Science
   Foundation of China (Grants No. 61802197, No. 61702278, No. 61872082,
   No. 61472184, No. 61703212, and No. 61602252), the National Science
   Foundation (Grant No. CNS-1837146), the Natural Science Foundation of
   Jiangsu Province of China (Grants No. BK20160964, No. BK20160902, No.
   BK20160971, and No. BK20160967), the Project through the Priority
   Academic Program Development (PAPD) of Jiangsu Higher Education
   Institutions, and the Jiangsu Innovation and Entrepreneurship
   (Shuangchuang) Program.
CR [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], 1998, P AAAI WORKSH LEARN
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2016, CVPR
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2017, 2017 DAVIS CHALLENGE
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2018, 2018 DAVIS CHALLENGE
   [Anonymous], 2016, P IEEE CVPR
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   Chen YD, 2019, IEEE T MULTIMEDIA, V21, P1934, DOI 10.1109/TMM.2018.2890361
   Chen YD, 2018, MULTIMED TOOLS APPL, V77, P6117, DOI 10.1007/s11042-017-4520-5
   Faktor A., 2014, P BRIT MACHINE VISIO
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Giordano D, 2015, PROC CVPR IEEE, P4814, DOI 10.1109/CVPR.2015.7299114
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hussein F, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3063532
   Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43
   Kiess J, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3231598
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Pan ZQ, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159170
   Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369
   Simonyan K., 2015, P ICLR
   Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5
   Tsai Yao-Hung Hubert, 2016, P IEEE C COMP VIS PA
   Valem LP, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3241053
   Wang BT, 2017, IEEE T CIRC SYST VID, V27, P992, DOI 10.1109/TCSVT.2016.2527378
   Wen LY, 2015, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2015.7298835
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Xu CL, 2016, INT J COMPUT VISION, V119, P272, DOI 10.1007/s11263-016-0906-5
   Xu Z., 2007, Advances in Neural Information Processing Systems, P1641
   Yang J, 2016, IEEE T IMAGE PROCESS, V25, P503, DOI 10.1109/TIP.2015.2500820
NR 40
TC 2
Z9 2
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2019
VL 15
IS 2
AR 40
DI 10.1145/3321507
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IM3ZV
UT WOS:000477935400011
OA Bronze
DA 2024-07-18
ER

PT J
AU Hu, CS
   Hsieh, YT
   Lin, HW
   Yeh, MC
AF Hu, Chuan-Shen
   Hsieh, Yi-Tsung
   Lin, Hsiao-Wei
   Yeh, Mei-Chen
TI Virtual Portraitist: An Intelligent Tool for Taking Well-Posed Selfies
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Smart photography; selfie; computational aesthetics; pose recommendation
ID FACIAL ATTRACTIVENESS; BEAUTY
AB Smart photography carries the promise of quality improvement and functionality extension in making aesthetically appealing pictures. In this article, we focus on self-portrait photographs and introduce new methods that guide a user in how to best pose while taking a selfie. While most of the current solutions use a post processing procedure to beautify a picture, the developed tool enables a novel function of recommending a good look before the photo is captured. Given an input face image, the tool automatically estimates the pose-based aesthetic score, finds the most attractive angle of the face, and suggests how the pose should be adjusted. The recommendation results are determined adaptively to the appearance and initial pose of the input face. We apply a data mining approach to find distinctive, frequent itemsets and association rules from online profile pictures, upon which the aesthetic estimation and pose recommendation methods are developed. A simulated and a real image set are used for experimental evaluation. The results show the proposed aesthetic estimation method can effectively select user-favorable photos. Moreover, the recommendation performance for the vertical adjustment is moderately related to the degree of conformity among the professional photographers' recommendations. This study echoes the trend of instant photo sharing, in which a user takes a picture and then immediately shares it on a social network without engaging in tedious editing.
C1 [Hu, Chuan-Shen; Hsieh, Yi-Tsung; Lin, Hsiao-Wei; Yeh, Mei-Chen] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, 88,Sec 4,Tingzhou Rd, Taipei, Taiwan.
C3 National Taiwan Normal University
RP Hu, CS (corresponding author), Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, 88,Sec 4,Tingzhou Rd, Taipei, Taiwan.
EM peterbill26@hotmail.com; boboandyao1001@gmail.com;
   allison1125@hotmail.com; myeh@csie.ntnu.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST 104-2221-E-003-020,
   MOST 105-2221-E-003-023]
FX This work was supported by the Ministry of Science and Technology of
   Taiwan (MOST 104-2221-E-003-020, MOST 105-2221-E-003-023).
CR Agrawal  R., 1993, ACM INT C SIGMOD
   Agrawal  R., 1994, INT C VER LARG DAT B
   [Anonymous], 2012, INTRO DATA COMPRESSI
   Bottino A, 2010, LECT NOTES COMPUT SC, V6111, P425, DOI 10.1007/978-3-642-13772-3_43
   Cao  Q., 2018, IEEE C AUT FAC GEST
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309
   Frey B., 2007, MULTI DATABASE RETRI, Vvol. 315, ppp, DOI [DOI 10.1126/SCIENCE.1136800, 10.1126/science.1136800]
   Frosh P., 2015, INT J COMMUNICATION, V9
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Horprasert  T., 1996, IEEE INT C AUT FAC G
   Hsieh Y. T., 2017, ACM INT WORKSH MULT
   Hu Y., 2014, INT AAAI C WEB SOC M
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Kagian A, 2008, VISION RES, V48, P235, DOI 10.1016/j.visres.2007.11.007
   Kalayeh M. M., 2015, ACM INT C MULT
   Khosla A, 2013, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2013.397
   Koscinski K., 2009, ANTHROPOL REV, V72, P45, DOI [10. 2478/v10044-008-0015-3, DOI 10.2478/V10044-008-0015-3, 10.2478/v10044-008-0015-3]
   Laurentini A, 2014, COMPUT VIS IMAGE UND, V125, P184, DOI 10.1016/j.cviu.2014.04.006
   Li  Q., 2017, ACM C DES INT SYST
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Nguyen TV, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2501643.2501650
   Pallett PM, 2010, VISION RES, V50, P149, DOI 10.1016/j.visres.2009.11.003
   Quack T, 2007, IEEE I CONF COMP VIS, P612
   Rhodes G, 2006, ANNU REV PSYCHOL, V57, P199, DOI 10.1146/annurev.psych.57.102904.190208
   Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79
   Utts J.M., 2006, Statistical Ideas and Methods
   Valenzano DR, 2006, VISION RES, V46, P1282, DOI 10.1016/j.visres.2005.10.024
   Walpole R., 2010, Probability and statistics for engineers and scientists, V9th
   Wang  S., 2014, ACM INT C MULT
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yeh  M., 2014, ACM INT C MULT
NR 34
TC 3
Z9 3
U1 0
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2019
VL 15
IS 1
SU S
AR 12
DI 10.1145/3288760
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HM9IU
UT WOS:000459798100012
DA 2024-07-18
ER

PT J
AU Hu, H
   Jin, YC
   Wen, YG
   Westphal, C
AF Hu, Han
   Jin, Yichao
   Wen, Yonggang
   Westphal, Cedric
TI Orchestrating Caching, Transcoding and Request Routing for Adaptive
   Video Streaming Over ICN
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Information Centric Networking (ICN); adaptive video streaming; partial
   caching; video transcoding
ID INFORMATION-CENTRIC NETWORKING; SOCIAL TV; CLOUD; STRATEGIES
AB Information-centric networking (ICN) has been touted as a revolutionary solution for the future of the Internet, which will be dominated by video traffic. This work investigates the challenge of distributing video content of adaptive bitrate (ABR) over ICN. In particular, we use the in-network caching capability of ICN routers to serve users; in addition, with the help of named function, we enable ICN routers to transcode videos to lower-bitrate versions to improve the cache hit ratio. Mathematically, we formulate this design challenge into a constrained optimization problem, which aims to maximize the cache hit ratio for service providers and minimize the service delay for endusers. We design a two-step iterative algorithm to find the optimum. First, given a content management scheme, we minimize the service delay via optimally configuring the routing scheme. Second, we maximize the cache hits for a given routing policy. Finally, we rigorously prove its convergence. Through extensive simulations, we verify the convergence and the performance gains over other algorithms. We also find that more resources should be allocated to ICN routers with a heavier request rate, and the routing scheme favors the shortest path to schedule more traffic.
C1 [Hu, Han] Beijing Inst Technol, Sch Informat & Elect, 5 South zhongguancun St, Beijing 100008, Peoples R China.
   [Jin, Yichao; Wen, Yonggang] Nanyang Technol Univ, Sch Comp Sci & Engn, Blk N4-02c-95,Nanyang Ave, Singapore 639798, Singapore.
   [Westphal, Cedric] Univ Calif Santa Cruz, Sch Comp Sci & Engn, 1156 High St, Santa Cruz, CA 95064 USA.
C3 Beijing Institute of Technology; Nanyang Technological University;
   University of California System; University of California Santa Cruz
RP Hu, H (corresponding author), Beijing Inst Technol, Sch Informat & Elect, 5 South zhongguancun St, Beijing 100008, Peoples R China.
EM hhu@bit.edu.cn; yjin3@ntu.edu.sg; ygwen@ntu.edu.sg; cedric@soe.ucsc.edu
RI Wen, Yonggang/P-9406-2017
OI Wen, Yonggang/0000-0002-2751-5114; Hu, Han/0000-0001-7532-0496
CR Abani N, 2017, PROCEEDINGS OF THE 4TH ACM CONFERENCE ON INFORMATION-CENTRIC NETWORKING (ICN 2017), P88, DOI 10.1145/3125719.3125728
   [Anonymous], 2016, 7933 RFC
   [Anonymous], 2017, Cisco Visual Networking Index: Global Mobile Data Traffic Forecast Update, 2016-2021 White Paper
   [Anonymous], P IEEE C COMP COMM
   [Anonymous], 2013, 2013 OCEANS SAN DIEG
   [Anonymous], 2006, HDB OPTIMIZATION TEL, DOI DOI 10.1007/978-0-387-30165-5_24
   Badov M., 2014, Proceedings of the 1st ACM Conference on Information-Centric Networking, P37
   Bertsekas Dimitri P, 1989, PARALLEL DISTRIBUTED, V23
   Cofano G, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092836
   Dabirmoghaddam A, 2014, Proceedings of the 1st ACM conference on Information-Centric Networking, P47
   Deloitte, 2017, MED CONS SURV 2017
   Din IU, 2018, IEEE COMMUN SURV TUT, V20, P1443, DOI 10.1109/COMST.2017.2787609
   Eum S., 2012, Proceedings of the second edition of the ICN workshop on Informationcentric networking, P49
   Fayazbakhsh SK, 2013, ACM SIGCOMM COMP COM, V43, P147, DOI 10.1145/2534169.2486023
   Gao GY, 2017, IEEE T MULTIMEDIA, V19, P836, DOI 10.1109/TMM.2016.2635019
   Guo S, 2012, LECT NOTES COMPUT SC, V7289, P41, DOI 10.1007/978-3-642-30045-5_4
   Hajimirsadeghi M, 2017, IEEE J SEL AREA COMM, V35, P654, DOI 10.1109/JSAC.2017.2672161
   Hu H, 2017, IEEE J SEL AREA COMM, V35, P935, DOI 10.1109/JSAC.2017.2676598
   Hu H, 2017, IEEE J SEL AREA COMM, V35, P545, DOI 10.1109/JSAC.2017.2659478
   Hu H, 2014, IEEE MULTIMEDIA, V21, P10, DOI 10.1109/MMUL.2014.2
   Huang BX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061750
   Internet2, 2016, INTERNET2 NETW ADV L
   Jin YC, 2015, IEEE T CIRC SYST VID, V25, P1914, DOI 10.1109/TCSVT.2015.2402892
   Jin YC, 2014, 2014 IEEE 22ND INTERNATIONAL SYMPOSIUM OF QUALITY OF SERVICE (IWQOS), P208, DOI 10.1109/IWQoS.2014.6914321
   Jin YC, 2014, IEEE T MULTIMEDIA, V16, P1739, DOI 10.1109/TMM.2014.2329370
   Jin Yichao, 2015, IEEE IFIP NETW C, P150
   Jo SK, 2018, E-ENERGY'18: PROCEEDINGS OF THE 9TH ACM INTERNATIONAL CONFERENCE ON FUTURE ENERGY SYSTEMS, P414, DOI 10.1145/3208903.3212043
   Kulinski Derek, 2012, TECHNICAL REPORT
   Lederer S., 2013, Proceedings of the 4th ACM Multimedia Systems Conference (MMSys '13), P131
   Lederer S, 2014, IEEE NETWORK, V28, P91, DOI 10.1109/MNET.2014.6963810
   Li YH, 2013, INT CON DISTR COMP S, P62, DOI 10.1109/ICDCS.2013.71
   Majeed MF, 2017, COMPUT NETW, V125, P103, DOI 10.1016/j.comnet.2017.05.030
   Miller K, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2990505
   Muhammad B., 2018, IEEE SYSTEMS J, P1
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Psaras I, 2014, IEEE T PARALL DISTR, V25, P2920, DOI 10.1109/TPDS.2013.304
   Rossi D, 2012, IEEE CONF COMPUT, P280, DOI 10.1109/INFCOMW.2012.6193506
   Rossini G., 2014, P 1 INT C INFORM CEN, P127
   Sifalakis M, 2014, P 1 ACM C INFORM CEN, P137, DOI [10.1145/2660129.2660150, DOI 10.1145/2660129.2660150]
   Sobhani A, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3052822
   Su K, 2014, IEEE ICC, P3178, DOI 10.1109/ICC.2014.6883810
   Sun Y, 2014, PROCEEDINGS OF THE 2014 CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT'14), P363, DOI 10.1145/2674005.2675003
   Tschudin Christian, 2014, 2014 IEEE 11th Consumer Communications and Networking Conference (CCNC), P851, DOI 10.1109/CCNC.2014.6940518
   Yeh E., 2014, Proceedings of the 1st ACM Conference on Information-Centric Networking, P117, DOI DOI 10.1145/2660129.2660151
   Yiu WPK, 2007, IEEE J SEL AREA COMM, V25, P1717, DOI 10.1109/JSAC.2007.071210
   Zhang WW, 2014, IEEE T VEH TECHNOL, V63, P2002, DOI 10.1109/TVT.2014.2310394
   Zhou L, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886776
NR 47
TC 10
Z9 11
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2019
VL 15
IS 1
AR 24
DI 10.1145/3289184
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HM9JB
UT WOS:000459798800008
DA 2024-07-18
ER

PT J
AU Duan, H
   Min, X
   Fang, Y
   Fan, L
   Yang, X
   Zhai, G
AF Duan, Huiyu
   Min, Xiongkuo
   Fang, Yi
   Fan, Lei
   Yang, Xiaokang
   Zhai, Guangtao
TI Visual Attention Analysis and Prediction on Human Faces for Children
   with Autism Spectrum Disorder
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Visual attention; saliency prediction; human faces; autism spectrum
   disorder (ASD)
ID BLIND QUALITY ASSESSMENT; SOCIAL ATTENTION; AMYGDALA LESIONS; SALIENCY;
   MODEL; RECOGNITION; IMPAIRMENT; FIXATIONS; PATTERNS; INSIGHTS
AB The focus of this article is to analyze and predict the visual attention of children with Autism Spectrum Disorder (ASD) when looking at human faces. Social difficulties are the hallmark features of ASD and will lead to atypical visual attention toward various stimuli more or less, especially on human faces. Learning the visual attention of children with ASD could contribute to related research in the field of medical science, psychology, and education. We first construct a Visual Attention on Faces for Autism Spectrum Disorder (VAFA) database, which consists of 300 natural scene images with human faces and corresponding eye movement data collected from 13 children with ASD. Compared with matched typically developing (TD) controls, we quantify atypical visual attention on human faces in ASD. Statistics show that some high-level factors such as face size, facial features, face pose, and facial emotions have different impacts on the visual attention of children with ASD. Combining the feature maps extracted from the state-of-the-art saliency models, we get the visual attention model on human faces for individuals with ASD. The proposed model shows the best performance among all competitors. With the help of our proposed model, researchers in related fields could design specialized education contents containing human faces for the children with ASD or produce the specific model for rapidly screening ASD using their eye movement data.
C1 [Duan, Huiyu; Min, Xiongkuo; Fang, Yi; Fan, Lei; Yang, Xiaokang; Zhai, Guangtao] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Zhai, G (corresponding author), Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM huiyuduan@sjtu.edu.cn; minxiongkuo@gmail.com; yifang@sjtu.edu.cn;
   lei.fan@sjtu.edu.cn; xkyang@sjtu.edu.cn; zhaiguangtao@sjtu.edu.cn
RI Yang, Xiaokang/C-6137-2009; Zhai, Guangtao/X-5949-2019; Min,
   Xiongkuo/A-7097-2019
OI Yang, Xiaokang/0000-0003-4029-3322; Zhai, Guangtao/0000-0001-8165-9322;
   Duan, Huiyu/0000-0002-6519-4067; Min, Xiongkuo/0000-0001-5693-0416
FU National Natural Science Foundation of China [61831015, 61527804];
   National Key Research and Development Program of China [2016YFB1001003];
   STCSM [18DZ1112300]; Shanghai Municipal Commission of Health and Family
   Planning [2018ZHYL0210]; China Postdoctoral Science Foundation
   [BX20180197, 2019M651496]
FX Thiswork was supported in part by the National Natural Science
   Foundation of China under Grants 61831015 and 61527804, in part by the
   National Key Research and Development Program of China under Grant
   2016YFB1001003, in part by the STCSM under Grant 18DZ1112300, in part by
   the Shanghai Municipal Commission of Health and Family Planning under
   Grant 2018ZHYL0210, and in part by the China Postdoctoral Science
   Foundation under Grants BX20180197 and 2019M651496.
CR Amso D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085701
   [Anonymous], 2018, P IEEE INT S CIRC SY
   [Anonymous], 2013, DIAGNOSTIC STAT MANU, VFifth, P1000
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2018, IEEE T PATTERN ANAL
   [Anonymous], 2018, IEEE T AFFECTIVE COM
   [Anonymous], 2018, ARXIV180500611
   [Anonymous], P ACM MULT SYST C MM
   [Anonymous], 2017, ARXIV170101081
   [Anonymous], 2018, IEEE T IMAGE PROCESS
   Baltrusaitis T, 2015, IEEE INT CONF AUTOMA
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Bar-Haim Y, 2006, J AUTISM DEV DISORD, V36, P131, DOI 10.1007/s10803-005-0046-1
   Birmingham E, 2011, SOC NEUROSCI-UK, V6, P420, DOI 10.1080/17470919.2011.561547
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Bundesen C, 2015, VISION RES, V116, P210, DOI 10.1016/j.visres.2014.11.005
   Chawarska K, 2013, BIOL PSYCHIAT, V74, P195, DOI 10.1016/j.biopsych.2012.11.022
   Chawarska K, 2010, ARCH GEN PSYCHIAT, V67, P178, DOI 10.1001/archgenpsychiatry.2009.194
   Chevallier C, 2015, AUTISM RES, V8, P620, DOI 10.1002/aur.1479
   Corden B, 2008, NEUROPSYCHOLOGIA, V46, P137, DOI 10.1016/j.neuropsychologia.2007.08.005
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Dawson G, 2005, DEV NEUROPSYCHOL, V27, P403, DOI 10.1207/s15326942dn2703_6
   Duan HY, 2018, IEEE IMAGE PROC, P704, DOI 10.1109/ICIP.2018.8451338
   Eisenbarth H, 2011, EMOTION, V11, P860, DOI 10.1037/a0022758
   Falck-Ytter T, 2013, J NEURODEV DISORD, V5, DOI 10.1186/1866-1955-5-28
   Falck-Ytter T, 2011, PROG BRAIN RES, V189, P209, DOI 10.1016/B978-0-444-53884-0.00026-9
   Falck-Ytter T, 2010, DEVELOPMENTAL SCI, V13, P864, DOI 10.1111/j.1467-7687.2009.00942.x
   Fan SJ, 2018, PROC CVPR IEEE, P7521, DOI 10.1109/CVPR.2018.00785
   Gepner B, 1996, CHILD NEUROPSYCHOL, V2, P123, DOI 10.1080/09297049608401357
   Guillon Q, 2014, NEUROSCI BIOBEHAV R, V42, P279, DOI 10.1016/j.neubiorev.2014.03.013
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang M, 2017, IEEE I CONF COMP VIS, P3287, DOI 10.1109/ICCV.2017.354
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Johnels JÅ, 2017, AUTISM RES, V10, P901, DOI 10.1002/aur.1730
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Klin A, 1999, J AUTISM DEV DISORD, V29, P499, DOI 10.1023/A:1022299920240
   Klin A, 2008, DEVELOPMENTAL SCI, V11, P40, DOI 10.1111/j.1467-7687.2007.00608.x
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Li ZQ, 2010, SCI CHINA INFORM SCI, V53, P738, DOI 10.1007/s11432-010-0055-3
   Liang M, 2015, IEEE T IMAGE PROCESS, V24, P1178, DOI 10.1109/TIP.2015.2395713
   Marois R, 2005, TRENDS COGN SCI, V9, P296, DOI 10.1016/j.tics.2005.04.010
   McPartland JC, 2011, J AUTISM DEV DISORD, V41, P148, DOI 10.1007/s10803-010-1033-8
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Min XK, 2017, INFORM SCIENCES, V420, P417, DOI 10.1016/j.ins.2017.08.040
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Min XK, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2996463
   OSTERLING J, 1994, J AUTISM DEV DISORD, V24, P247, DOI 10.1007/BF02172225
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Rice K, 2012, J AM ACAD CHILD PSY, V51, P238, DOI 10.1016/j.jaac.2011.12.017
   Robertson CE, 2017, NAT REV NEUROSCI, V18, P671, DOI 10.1038/nrn.2017.112
   Samad MD, 2018, IEEE T NEUR SYS REH, V26, P353, DOI 10.1109/TNSRE.2017.2768482
   Sasson NJ, 2014, J AUTISM DEV DISORD, V44, P584, DOI 10.1007/s10803-013-1910-z
   Sasson NJ, 2011, J AUTISM DEV DISORD, V41, P242, DOI 10.1007/s10803-010-1038-3
   Simmons DR, 2009, VISION RES, V49, P2705, DOI 10.1016/j.visres.2009.08.005
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Vabalas A, 2016, J AUTISM DEV DISORD, V46, P305, DOI 10.1007/s10803-015-2546-y
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang S, 2015, NEURON, V88, P604, DOI 10.1016/j.neuron.2015.09.042
   Wang S, 2014, NEUROPSYCHOLOGIA, V63, P259, DOI 10.1016/j.neuropsychologia.2014.09.002
   Yi L, 2014, AUTISM RES, V7, P72, DOI 10.1002/aur.1340
   Yi L, 2013, J VISION, V13, DOI 10.1167/13.10.5
   Zadeh A, 2017, IEEE INT CONF COMP V, P2519, DOI 10.1109/ICCVW.2017.296
   Zhai GT, 2012, IEEE T IMAGE PROCESS, V21, P41, DOI 10.1109/TIP.2011.2161092
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhu WH, 2019, IEEE T MULTIMEDIA, V21, P2334, DOI 10.1109/TMM.2019.2902484
NR 72
TC 32
Z9 34
U1 6
U2 28
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2019
VL 15
IS 3
SU S
SI SI
AR 90
DI 10.1145/3337066
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA LR5EU
UT WOS:000535718800006
DA 2024-07-18
ER

PT J
AU She, DY
   Sun, M
   Yang, JF
AF She, Dongyu
   Sun, Ming
   Yang, Jufeng
TI Learning Discriminative Sentiment Representation from Strongly- and
   Weakly Supervised CNNs
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Visual sentiment analysis; convolutional neural network; multiple kernel
   learning
ID IMAGES; EMOTIONS
AB Visual sentiment analysis is attracting increasing attention with the rapidly growing amount of images uploaded to social networks. Learning rich visual representations often requires training deep convolutional neural networks (CNNs) on massive manually labeled data, which is expensive or scarce especially for a subjective task like visual sentiment analysis. Meanwhile, a large quantity of social images is quite available yet noisy by querying social networks using the sentiment categories as keywords, where various types of images related to the specific sentiment can be easily collected. In this article, we propose a multiple kernel network for visual sentiment recognition, which learns representation from strongly- and weakly supervised CNNs. Specifically, the weakly supervised deep model is trained using the large-scale data from social images, whereas the strongly supervised deep model is fine tuned on the affecitve datasets with manual annotation. We employ the multiple kernel scheme on the multiple layers of CNNs, which can automatically select the discriminative representation by learning a linear combination from a set of pre-defined kernels. In addition, we introduce a large-scale dataset collected from popular comics of various countries, such as America, Japan, China, and France, which consists of 11,821 images with various artistic styles. Experimental results show that the multiple kernel network achieves consistent improvements over the state-of-the-art methods on the public affective datasets, as well as the newly established Comics dataset. The Comics dataset can be found at http://cv.nankai.edu.cn/projects/Comic.
C1 [She, Dongyu; Yang, Jufeng] Nankai Univ, 38 Tongyan Rd, Tianjin 300350, Peoples R China.
   [Sun, Ming] SenseTime, 1 East Zhongguancun Rd, Beijing 100084, Peoples R China.
C3 Nankai University
RP She, DY (corresponding author), Nankai Univ, 38 Tongyan Rd, Tianjin 300350, Peoples R China.
EM sherry6656@163.com; m_sunming@163.com; yangjufeng@nankai.edu.cn
FU NSFC [61876094]; Natural Science Foundation of Tianjin, China
   [18JCYBJC15400, 18ZXZNGX00110]; Open Project Program of the National
   Laboratory of Pattern Recognition (NLPR); Fundamental Research Funds for
   the Central Universities
FX This work was supported by the NSFC (No. 61876094), Natural Science
   Foundation of Tianjin, China (Nos. 18JCYBJC15400 and 18ZXZNGX00110), the
   Open Project Program of the National Laboratory of Pattern Recognition
   (NLPR), and the Fundamental Research Funds for the Central Universities.
CR AHSAN U, 2017, P 2017 INT JOINT C N
   Ahsan Unaiza, 2017, IEEE SIGNAL PROCESSI
   Alarcao SM, 2018, MULTIMED TOOLS APPL, V77, P17413, DOI 10.1007/s11042-017-5311-8
   [Anonymous], 2017, IEEE TMM, DOI DOI 10.1109/TMM.2016.2617741
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2013, P ACM INT C MULT
   [Anonymous], 2010, P ACM INT C MULT
   Borth Damian, 2013, P INT WORKSH AFF SEN
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Ming, 2015, P IEEE INT C MULT EX
   Chen Tao, 2014, P ACM INT C MULT
   Chen Tao, 2014, P ACM INT C MULT
   Chen YX, 2015, APPL BIONICS BIOMECH, V2015, DOI 10.1155/2015/609132
   CHO YM, 2009, P ANN C NEUR INF PRO
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Fan SJ, 2018, PROC CVPR IEEE, P7521, DOI 10.1109/CVPR.2018.00785
   He K., 2014, P EUR C COMP VIS
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He XY, 2018, NEUROCOMPUTING, V291, P187, DOI 10.1016/j.neucom.2018.02.073
   Jia Jia, 2012, P IEEE INT C AC SPEE
   Jia Yangqing, 2014, P ACM INT C MULT
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Xin, 2012, P ACM INT C MULT
   Lu Xin, 2012, ARXIV151106062
   Machajdik Jana, 2010, P ANN C NEUR INF PRO
   Mairal Julien, 2014, J POP CULT
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Ming C, 2015, IEEE INT FUZZY SYST
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   PANDA R, 2018, P EUR C COMP VIS
   Peng KC, 2015, P IEEE C COMP VIS PA
   Peng KC, 2015, IEEE INT CON MULTI
   Peng Kuan-Chuan, 2015, P IEEE INT C MULT EX
   Poria S, 2017, NEUROCOMPUTING, V261, P217, DOI 10.1016/j.neucom.2016.09.117
   RAKOTOMAMONJY A, 2007, P INT C MACH LEARN
   Rao Tianrong, 2016, NEURAL PROCESSING LE, P1
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   SARTORI A, 2015, P ACM INT C MULT
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song KK, 2018, NEUROCOMPUTING, V312, P218, DOI 10.1016/j.neucom.2018.05.104
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Sydorov V., 2014, P IEEE C COMP VIS PA
   Sydorov Vladyslav, 2014, ARXIV14108586
   Truong Quoc-Tuan, 2017, P 2006 IEEE INT C SY
   Wang Wei-Ning, 2006, P IEEE INT C IM PROC
   YANG JF, 2017, P AAAI C ART INT
   Yang JF, 2018, PROC CVPR IEEE, P7584, DOI 10.1109/CVPR.2018.00791
   Yang JF, 2018, IEEE T MULTIMEDIA, V20, P2513, DOI 10.1109/TMM.2018.2803520
   Yang Jufeng, 2018, P INT JOINT C ART IN
   Yang Jufeng, 2018, P AAAI C ART INT
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   You Quanzeng, 2017, P INT WORKSH ISS SEN
   You Quanzeng, 2016, P AAAI C ART INT
   You Quanzeng, 2015, P AAAI C ART INT
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler Matthew D., 2014, IEEE CONF COMP VIS P, DOI DOI 10.1109/CVPR.2016.128
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   ZHAO SC, 2014, IEEE INT CON MULTI, pNI255
   Zhao S, 2017, PROC ASME DES ENG TE
   Zhao SC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5534
   Zhao SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1319, DOI 10.1145/3240508.3240591
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P3218, DOI 10.1109/TCYB.2017.2762344
   Zhao Sicheng, 2017, P ACM INT C MULT
   ZHENG HL, 2017, P IEEE INT C IM PROC
   Zhu XG, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3595
   Zhu Xinge, 2017, J MACH LEARN RES
NR 72
TC 8
Z9 9
U1 4
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2019
VL 15
IS 3
SU S
SI SI
AR 96
DI 10.1145/3326335
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA LR5EU
UT WOS:000535718800012
DA 2024-07-18
ER

PT J
AU Valem, LP
   De Oliveira, CR
   Pedronette, DCG
   Almeida, J
AF Valem, Lucas Pascotti
   De Oliveira, Carlos Renan
   Guimaraes Pedronette, Daniel Carlos
   Almeida, Jurandy
TI Unsupervised Similarity Learning through Rank Correlation and kNN Sets
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; unsupervised learning; kNN sets; rank
   correlation
ID IMAGE RE-RANKING; DIFFUSION PROCESS; RETRIEVAL; CLASSIFICATION;
   DESCRIPTORS; RECOGNITION
AB The increasing amount of multimedia data collections available today evinces the pressing need for methods capable of indexing and retrieving this content. Despite the continuous advances in multimedia features and representation models, to establish an effective measure for comparing different multimedia objects still remains a challenging task. While supervised and semi-supervised techniques made relevant advances on similarity learning tasks, scenarios where labeled data are non-existent require different strategies. In such situations, unsupervised learning has been established as a promising solution, capable of considering the contextual information and the dataset structure for computing new similarity/dissimilarity measures. This article extends a recent unsupervised learning algorithm that uses an iterative re-ranking strategy to take advantage of different k-Nearest Neighbors (kNN) sets and rank correlation measures. Two novel approaches are proposed for computing the kNN sets and their corresponding top-k lists. The proposed approaches were validated in conjunction with various rank correlation measures, yielding superior effectiveness results in comparison with previous works. In addition, we also evaluate the ability of the method in considering different multimedia objects, conducting an extensive experimental evaluation on various image and video datasets.
C1 [Valem, Lucas Pascotti; De Oliveira, Carlos Renan; Guimaraes Pedronette, Daniel Carlos] Sao Paulo State Univ UNESP, Dept Stat Appl Math & Comp, Av 24-A,1515, BR-13506900 Rio Claro, SP, Brazil.
   [Almeida, Jurandy] Univ Fed Sao Paulo UNIFESP, Inst Ciencia & Tecnol, Av Cesare MG Lattes 1201, BR-12247014 Sao Jose Dos Campos, SP, Brazil.
C3 Universidade Estadual Paulista; Universidade Federal de Sao Paulo
   (UNIFESP)
RP Valem, LP (corresponding author), Sao Paulo State Univ UNESP, Dept Stat Appl Math & Comp, Av 24-A,1515, BR-13506900 Rio Claro, SP, Brazil.
EM lucasvalem@rc.unesp.br; c.renan.o@gmail.com; daniel@rc.unesp.br;
   jurandy.almeida@unifesp.br
RI Almeida, Jurandy/I-2177-2012
OI Almeida, Jurandy/0000-0002-4998-6996
FU Sao Paulo Research Foundation -FAPESP [2013/08645-0, 2016/06441-7,
   2017/25908-6, 2017/02091-4]; Brazilian National Council for Scientific
   and Technological Development -CNPq [423228/2016-1, 308194/2017-9,
   313122/2017-2]
FX We thank the Sao Paulo Research Foundation -FAPESP (grants
   #2013/08645-0, #2016/06441-7, #2017/25908-6, and #2017/02091-4) and the
   Brazilian National Council for Scientific and Technological Development
   -CNPq (grants #423228/2016-1, #308194/2017-9, and #313122/2017-2) for
   financial support.
CR Almeida Jurandy, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3673, DOI 10.1109/ICIP.2011.6116516
   Almeida J, 2014, LECT NOTES COMPUT SC, V8827, P604, DOI 10.1007/978-3-319-12568-8_74
   Almeida J, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1180
   [Anonymous], 2013, THESIS
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Bai S, 2017, AAAI CONF ARTIF INTE, P3967
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Bai X, 2015, INFORM SCIENCES, V325, P342, DOI 10.1016/j.ins.2015.07.022
   Bai XA, 2010, LECT NOTES COMPUT SC, V6313, P328
   Beecks C, 2010, IEEE INT CON MULTI, P1552, DOI 10.1109/ICME.2010.5582949
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Chen YZ, 2014, PATTERN RECOGN, V47, P1349, DOI 10.1016/j.patcog.2013.09.011
   Deng C, 2013, IEEE I CONF COMP VIS, P2600, DOI 10.1109/ICCV.2013.323
   Donoser M, 2013, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2013.174
   Duarte LA, 2016, SIBGRAPI, P257, DOI [10.1109/SIBGRAPI.2016.043, 10.1109/SIBGRAPI.2016.40]
   Fagin R, 2003, SIAM PROC S, P28
   GOODMAN LA, 1954, J AM STAT ASSOC, V49, P732, DOI 10.2307/2281536
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   Pedronette DCG, 2016, PATTERN RECOGN LETT, V83, P357, DOI 10.1016/j.patrec.2016.05.021
   Pedronette DCG, 2014, INFORM SCIENCES, V265, P91, DOI 10.1016/j.ins.2013.12.030
   Pedronette DCG, 2014, IMAGE VISION COMPUT, V32, P120, DOI 10.1016/j.imavis.2013.12.009
   Pedronette DCG, 2013, PATTERN RECOGN, V46, P2350, DOI 10.1016/j.patcog.2013.01.004
   Pedronette DCG, 2012, INFORM SCIENCES, V207, P19, DOI 10.1016/j.ins.2012.04.032
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Jiang JY, 2011, IEEE I CONF COMP VIS, P794, DOI 10.1109/ICCV.2011.6126318
   Kontschieder Peter, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P655
   Kovalev V, 1998, 1998 MULTIMEDIA MODELING, PROCEEDINGS, P32, DOI 10.1109/MULMM.1998.722972
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling HB, 2010, LECT NOTES COMPUT SC, V6313, P411
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Nister David, 2006, CVPR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Okada CY, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P331, DOI 10.1145/2671188.2749335
   Pedronette D.C.G., 2010, INT JOINT C COMP VIS, V1, p197 
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Song Bai, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P774, DOI 10.1109/ICCV.2017.90
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tao B, 2000, J VIS COMMUN IMAGE R, V11, P327, DOI 10.1006/jvci.1999.0448
   Thomee B, 2012, INT J MULTIMED INF R, V1, P71, DOI 10.1007/s13735-012-0014-4
   Torres RD, 2007, IMAGE VISION COMPUT, V25, P3, DOI 10.1016/j.imavis.2005.12.010
   Valem LP, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P51, DOI 10.1145/2671188.2749336
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang B, 2012, PROC CVPR IEEE, P2997, DOI 10.1109/CVPR.2012.6248029
   Wang JY, 2011, PATTERN RECOGN, V44, P2367, DOI 10.1016/j.patcog.2011.02.007
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Webber W, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852106
   Xie LX, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P3, DOI 10.1145/2671188.2749289
   Yang XW, 2008, LECT NOTES COMPUT SC, V5305, P788, DOI 10.1007/978-3-540-88693-8_58
   Yang XW, 2013, IEEE T PATTERN ANAL, V35, P28, DOI 10.1109/TPAMI.2012.60
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201
   Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3604, DOI 10.1109/TIP.2014.2329182
NR 60
TC 7
Z9 7
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2018
VL 14
IS 4
AR 80
DI 10.1145/3241053
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ4JB
UT WOS:000457139200002
DA 2024-07-18
ER

PT J
AU Bentaleb, A
   Begen, AC
   Zimmermann, R
AF Bentaleb, Abdelhak
   Begen, Ali C.
   Zimmermann, Roger
TI ORL-SDN: Online Reinforcement Learning for SDN-Enabled HTTP Adaptive
   Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE HAS; SDN; reinforcement learning; QoE optimization; POMDP; HAS
   scalability issues; fastMPC
ID VIDEO
AB In designing an HTTP adaptive streaming (HAS) system, the bitrate adaptation scheme in the player is a key component to ensure a good quality of experience (QoE) for viewers. We propose a new online reinforcement learning optimization framework, called ORL-SDN, targeting HAS players running in a software-defined networking (SDN) environment. We leverage SDN to facilitate the orchestration of the adaptation schemes for a set of HAS players. To reach a good level of QoE fairness in a large population of players, we cluster them based on a perceptual quality index. We formulate the adaptation process as a Partially Observable Markov Decision Process and solve the per-cluster optimization problem using an online Q-learning technique that leverages model predictive control and parallelism via aggregation to avoid a per-cluster suboptimal selection and to accelerate the convergence to an optimum. This framework achieves maximum long-term revenue by selecting the optimal representation for each cluster under time-varying network conditions. The results show that ORL-SDN delivers substantial improvements in viewer QoE, presentation quality stability, fairness, and bandwidth utilization over well-known adaptation schemes.
C1 [Bentaleb, Abdelhak] NUS Sch Comp, Comp 1, AS6, Media Lab 1, 13 Comp Dr, Singapore 117417, Singapore.
   [Begen, Ali C.] Cekmekoy Campus Nisantepe Dist,Orman St, TR-34794 Turkey, Turkey.
   [Zimmermann, Roger] NUS Sch Comp, Comp 1, 13 Comp Dr, Singapore 117417, Singapore.
RP Bentaleb, A (corresponding author), NUS Sch Comp, Comp 1, AS6, Media Lab 1, 13 Comp Dr, Singapore 117417, Singapore.
EM bentaleb@comp.nus.edu.sg; ali.begen@ozyegin.edu.tr;
   rogerz@comp.nus.edu.sg
RI Zimmermann, Roger/D-7944-2015; Bentaleb, Abdelhak/ABI-3704-2020; Begen,
   Ali C./R-5897-2016
OI Zimmermann, Roger/0000-0002-7410-2590; Begen, Ali
   C./0000-0002-0835-3017; Bentaleb, Abdelhak/0000-0002-5382-6530
FU National Natural Science Foundation of China [61472266]; National
   University of Singapore (Suzhou) Research Institute, Suzhou Industrial
   Park, Jiang Su, People's Republic of China
FX This research was supported in part by the National Natural Science
   Foundation of China under Grant No. 61472266 and by the National
   University of Singapore (Suzhou) Research Institute, 377 Lin Quan
   Street, Suzhou Industrial Park, Jiang Su, People's Republic of China,
   215123.
CR [Anonymous], SPIE IS T ELECT IMAG
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], SSIMWAVES VID QOE MO
   [Anonymous], 2015, 12 USENIX S NETW SYS
   [Anonymous], 2007, PACKET SAMPLING NETW
   [Anonymous], DEEP PACK INSP DPI
   [Anonymous], SFLOW
   [Anonymous], 1984, QUANTITATIVE MEASURE
   [Anonymous], MININET
   [Anonymous], GUID IMPL DASH AVC 2
   [Anonymous], 2022, TWARC 294 PYTHON PAC
   [Anonymous], 2016, CISC VIS NETW IND GL
   [Anonymous], 1998, REINFORCEMENT LEARNI
   [Anonymous], DASH 264 JAV REF CLI
   [Anonymous], RYU SDN FRAMEWORK
   Arefin Ahsan, 2013, 21 IEEE INT C NETWOR, P1, DOI [10.1109/ICNP.2013.6733616, DOI 10.1109/ICNP.2013.6733616]
   Bentaleb A, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1296, DOI 10.1145/2964284.2964332
   Bouten N, 2015, COMPUT NETW, V81, P96, DOI 10.1016/j.comnet.2015.02.007
   Carela-Español V, 2011, COMPUT NETW, V55, P1083, DOI 10.1016/j.comnet.2010.11.002
   Chiariotti F, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P77, DOI 10.1145/2910017.2910603
   Claeys M, 2014, CONNECT SCI, V26, DOI 10.1080/09540091.2014.885273
   Claeys Maxim., 2013, Design of a q-learning-based client quality selection algorithm for http adaptive video streaming. pages, P30
   De Vriendt J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1288
   Dimopoulos G., 2016, P 2016 INT MEAS C SA, P513, DOI DOI 10.1145/2987443.2987459
   Duanmu ZF, 2017, IEEE J-STSP, V11, P154, DOI 10.1109/JSTSP.2016.2608329
   Eckert Marcus, 2013, Advances in Communication Networking. 19th EUNICE/IFIP WG 6.6 International Workshop. Proceedings: LNCS 8115, P112, DOI 10.1007/978-3-642-40552-5_11
   Feng Z., 2004, AAAI-04 Workshop on Learning and Planning in Markov Processes-Advances and Challenges, P7
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Georgopoulos P., 2013, Proceedings of the 2013 ACM SIGCOMM Workshop on Future Human-centric Multimedia Networking, FhMN '13, (New York, NY, USA), P15, DOI DOI 10.1145/2491172.2491181
   Haykin S., 1998, NEURAL NETWORKS COMP
   Heorhiadi V, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P223
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Huang TY, 2014, ACM SIGCOMM COMP COM, V44, P187, DOI 10.1145/2740070.2626296
   Jiang JC, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P393
   Jiang JC, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P137
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Kleinrouweler JW, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P36, DOI 10.1145/2910017.2910599
   Kreutz D, 2015, P IEEE, V103, P14, DOI 10.1109/JPROC.2014.2371999
   Lederer S., 2012, P 3 MULT SYST C, P89
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Liu X, 2012, ACM SIGCOMM COMP COM, V42, P359, DOI 10.1145/2377677.2377752
   Liu XM, 2007, IEEE NETWORK, V21, P32, DOI 10.1109/MNET.2007.364256
   Mastronarde N, 2011, IEEE T SIGNAL PROCES, V59, P6262, DOI 10.1109/TSP.2011.2165211
   McKeown N, 2008, ACM SIGCOMM COMP COM, V38, P69, DOI 10.1145/1355734.1355746
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Mu M, 2016, IEEE J SEL AREA COMM, V34, P2168, DOI 10.1109/JSAC.2016.2577318
   Mukerjee MK, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P311, DOI 10.1145/2785956.2787475
   Oktian YE, 2017, COMPUT NETW, V121, P100, DOI 10.1016/j.comnet.2017.04.038
   Petrangeli S, 2016, INT J NETW MANAG, V26, P8, DOI 10.1002/nem.1931
   Petrangeli S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818361
   Petrangeli Stefano., 2014, 2014 IEEE Network Operations and Management Symposium (NOMS), P1
   Powell WB, 2009, NAV RES LOG, V56, P239, DOI 10.1002/nav.20347
   Riedmiller M, 2005, LECT NOTES ARTIF INT, V3720, P317, DOI 10.1007/11564096_32
   Sherry J, 2015, ACM SIGCOMM COMP COM, V45, P213, DOI 10.1145/2829988.2787502
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Sun Y, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P272, DOI 10.1145/2934872.2934898
   Thomas Emmanuel, 2017, Motion Imaging Journal, V126, P22, DOI 10.5594/JMI.2016.2632338
   Tokic M, 2011, LECT NOTES ARTIF INT, V7006, P335, DOI 10.1007/978-3-642-24455-1_33
   van der Hooft J, 2015, PROCEEDINGS OF THE 2015 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM), P131, DOI 10.1109/INM.2015.7140285
   Wang Y, 2010, IEEE T CONTR SYST T, V18, P267, DOI 10.1109/TCST.2009.2017934
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Zhou C, 2016, IEEE T MULTIMEDIA, V18, P738, DOI 10.1109/TMM.2016.2522650
   Zhou W, 2014, 2014 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P358, DOI 10.1109/WAINA.2014.153
NR 66
TC 11
Z9 11
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2018
VL 14
IS 3
AR 71
DI 10.1145/3219752
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GT7CI
UT WOS:000444677600004
DA 2024-07-18
ER

PT J
AU Claypool, M
AF Claypool, Mark
TI Game Input with Delay-Moving Target Selection with a Game Controller
   Thumbstick
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Delay; lag
ID FITTS LAW; PERFORMANCE; TIME
AB Hosting interactive video-based services, such as computer games, in the Cloud poses particular challenges given user sensitivity to delay. A better understanding of the impact of delay on player-game interactions can help design cloud systems and games that accommodate delays inherent in cloud systems. Previous top-down studies of delay using full-featured games have helped understand the impact of delay, but often do not generalize or lend themselves to analytic modeling. Bottom-up studies isolating user input and delay can better generalize and be used in models, but have yet to be applied to cloud-hosted computer games. In order to better understand delay impact in cloud-hosted computer games, we conduct a large bottom-up user study centered on a fundamental game interaction-selecting a moving target with user input impeded by delay. Our work builds a custom game that controls both the target speed and input delay and has players select the target using a game controller analog thumbstick. Analysis of data from over 50 users shows target selection time exponentially increases with delay and target speed and is well-fit by an exponential model that includes a delay and target speed interaction term. A comparison with two previous studies, both using a mouse instead of a thumbstick, suggests the model's relationship between selection time, delay, and target speed holds more broadly, providing a foundation for a potential law explaining moving target selection with delay encountered in cloud-hosted games.
C1 [Claypool, Mark] Worcester Polytech Inst, Worcester, MA 01609 USA.
C3 Worcester Polytechnic Institute
RP Claypool, M (corresponding author), 100 Inst Rd, Worcester, MA 01609 USA.
RI Claypool, Mark/ABC-5316-2020
CR Accot Johnny, 1997, P ACM SIGCHI C HUMAN, P295, DOI [10.1145/258549.258760, DOI 10.1145/258549.258760]
   Al Hajri Abir, 2011, P IFIP TC HUM COMP I
   Amin Rahul, 2013, Human-Computer Interaction. Users and Contexts of Use. 15th International Conference, HCI International 2013. Proceedings: LNCS 8006, P97, DOI 10.1007/978-3-642-39265-8_11
   Armitage Grenville.J., 2003, P 11 IEEE INT C NETW
   Beigbeder Tom, 2004, P ACM NETW SYST SUPP
   BERNIER Y, 2001, P GAM DEV C
   Brady Kyle J., 2015, THESIS
   Chen K., 2006, P IEEE INFOCOM
   Chen Kuan-Ta, 2014, IEEE T MULTIMEDIA, V26, P2
   Claypool M, 2005, COMPUT NETW, V49, P52, DOI 10.1016/j.comnet.2005.04.008
   Claypool M., 2006, COMMUN ACM, V49, P11
   Claypool M., 2017, P 23 INT C MULTIMEDI
   Claypool M, 2014, P 13 ACM NETW SYST S
   Claypool Mark, 2015, P 25 ACM INT WORKSH
   Claypool Mark, 2016, P ACM ANN S COMP HUM
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Fritsch T., 2005, P 4 ACM NETW SYST SU
   HOFFMANN ER, 1991, ERGONOMICS, V34, P211, DOI 10.1080/00140139108967307
   HOFFMANN ER, 1992, ERGONOMICS, V35, P37, DOI 10.1080/00140139208967796
   IVKOVIC Z, 2015, P 33 ANN ACM C HUM F, P135
   JAGACINSKI RJ, 1980, HUM FACTORS, V22, P225, DOI 10.1177/001872088002200211
   Jota Ricardo, 2013, P ACM SIGCHI C HUM F
   KERR R, 1973, J MOTOR BEHAV, V5, P175, DOI 10.1080/00222895.1973.10734962
   Looser I., 2005, People Comput. XIX, V2, P33
   MacKenzie I. S., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P219, DOI 10.1145/142750.142794
   MacKenzie I. Scott, 1993, P CHI C HUM FACT COM, P6
   Murata Atsuo, 2001, ELSEVIER HUMAN MOVEM, V20, P719
   Nichols J., 2004, PROC 14 INT WORKSHOP, P146
   Pantel Lothar, 2002, P WORKSH NETW OP SYS
   Raaen K., 2015, P ACM MULT SYST
   Raaen K., 2015, P 17 HCI INT C
   Shea R, 2013, IEEE NETWORK, V27, P16, DOI 10.1109/MNET.2013.6574660
   So RHY, 2002, ERGONOMICS, V45, P105, DOI 10.1080/00140130110115354
   Soukoreff RW, 2004, INT J HUM-COMPUT ST, V61, P751, DOI 10.1016/j.ijhcs.2004.09.001
   Ware C., 1987, P SIGCHIGI C HUM FAC
   Ware Colin, 1994, P CAND INF PROC SOC
   Welford A.T., 1968, FUNDAMENTALS SKILL
NR 37
TC 12
Z9 12
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2018
VL 14
IS 3
SU S
AR 57
DI 10.1145/3187288
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA HG9GD
UT WOS:000455314500005
DA 2024-07-18
ER

PT J
AU Hu, W
   Seifi, M
   Reinhard, E
AF Hu, Wei
   Seifi, Mozhdeh
   Reinhard, Erik
TI Over- and Under-Exposure Reconstruction of a Single Plenoptic Capture
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Light field acquisition; light field reconstruction; declipping;
   overexposure; under-exposure; dynamic range
ID HIGH DYNAMIC-RANGE; FIELD
AB Light field images, for example, taken with plenoptic cameras, offer interesting post-processing opportunities, including depth-of-field management, depth estimation, viewpoint selection, and 3D image synthesis. Like most capture devices, however, plenoptic cameras have a limited dynamic range, so that over- and under-exposed areas in plenoptic images are commonplace. We therefore present a straightforward and robust plenoptic reconstruction technique based on the observation that vignetting causes peripheral views to receive less light than central views. Thus, corresponding pixels in different views can be used to reconstruct illumination, especially in areas where information missing in one view is present in another. Our algorithm accurately reconstructs under- and over-exposed regions (known as declipping), additionally affording an increase in peak luminance by up to two f-stops, and a comparable lowering of the noise floor. The key advantages of this approach are that no hardware modifications are necessary to improve the dynamic range, that no multiple exposure techniques are required, and therefore that no ghosting or other artifacts are introduced.
C1 [Hu, Wei] Peking Univ, 128 Zhongguancun North St, Beijing, Peoples R China.
   [Seifi, Mozhdeh; Reinhard, Erik] Technicolor France, 975 Ave Champs Blancs, F-35576 Cesson Sevigne, France.
C3 Peking University
RP Hu, W (corresponding author), Peking Univ, 128 Zhongguancun North St, Beijing, Peoples R China.
EM forhuwei@pku.edu.cn; mozhde.seifi@gmail.com;
   Erik.Reinhard@technicolor.com
OI Reinhard, Erik/0000-0001-9079-6572
FU National Natural Science Foundation of China [U1636206]; Alibaba
   Innovative Research [XTG201800108]; MSRA Collaborative Research
   [FY18-Research-Sponsorship-029]
FX This article was supported by National Natural Science Foundation of
   China under Contract No. U1636206, Alibaba Innovative Research under
   Contract No. XTG201800108 and MSRA Collaborative Research under Project
   ID FY18-Research-Sponsorship-029.
CR Abebe Mekides Assefa, 2015, EUR S REND EXP ID IM
   ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783
   Akeley Kurt Barton, 2014, Patent No, Patent No. [US 9386288 B2, 9386288]
   [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], 2014, EUROPEAN C COMPUTER
   [Anonymous], 2013, P IEEE C COMP VIS PA
   [Anonymous], INTRINSIC LIGHT FIEL
   [Anonymous], 2009, INT C COMP PHOT
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2013, IEEE signal processing magazine
   [Anonymous], 2008, P GRAPHICS INTERFACE
   Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168
   Bishop TomE., 2009, ICCP, IEEE International Conference on Computational Photography, P1, DOI DOI 10.1109/ICCPHOT.2009.5559010
   Cho D, 2013, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2013.407
   Chung F. R., 1997, Spectral Graph Theory, V92, DOI DOI 10.1090/CBMS/092
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Debevec Paul E, 2008, ACM SIGGRAPH 2008 CL, P1, DOI DOI 10.1145/1401132.1401174
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Fiss Juliet, 2014, Computational Photography (ICCP), 2014 IEEE International Conference on, P1
   Gallo O., 2009, P IEEE INT C COMP PH, P1
   Georgiev T., 2010, Computational Photography (ICCP), 2010 IEEE International Conference on, P1
   Georgiev T. G., 2006, P 17 EUROGRAPHICS C, V2006
   Georgiev Todor, 2009, P SIGN REC SYNTH
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Hahne C, 2016, OPT EXPRESS, V24, P21521, DOI 10.1364/OE.24.021521
   Horstmeyer R., 2009, Computational Photography (ICCP), 2009 IEEE International Conference on, P1, DOI DOI 10.1109/ICCPHOT.2009.5559016
   Hu W., 2013, P IEEE INT WORKSH MU
   Hu W, 2017, IEEE INT WORKSH MULT
   Hu W, 2016, IEEE SIGNAL PROC LET, V23, P242, DOI 10.1109/LSP.2015.2510379
   Ihrke I, 2008, JOURNAL WSCG, V16, P25
   Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929
   Ives Frederic E, 1903, US Patent, Patent No. [725,567, 725567]
   Khan EA, 2006, IEEE IMAGE PROC, P2005, DOI 10.1109/ICIP.2006.312892
   Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Levoy M., 2006, ACM SIGGRAPH 2006 PA, DOI [DOI 10.1145/1141911.1141976, 10.1145/1179352.1141976., DOI 10.1145/1179352.1141976]
   Liang CK, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2665075
   Lumsdaine A., 2008, Full resolution lightfield rendering
   Malvar HS, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P485
   Manakov A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461937
   Mann S, 1995, P IS T, V48, P422
   Masood SZ, 2009, COMPUT GRAPH FORUM, V28, P1861, DOI 10.1111/j.1467-8659.2009.01564.x
   Masselus V, 2003, ACM T GRAPHIC, V22, P613, DOI 10.1145/882262.882315
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Nayar SK, 2002, LECT NOTES COMPUT SC, V2353, P636
   Ng R, 2005, RES REPORT, DOI DOI 10.1145/3097571
   Pitts Colvin, 2015, US Patent, Patent No. [US8971625, 8971625]
   Raskar Ramesh, 2008, ACM T GRAPHIC, V27, P56
   Reinhard E, 2005, IEEE T VIS COMPUT GR, V11, P13, DOI 10.1109/TVCG.2005.9
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Reinhard E., 2008, Color Imaging: Fundamentals and Applications
   Robertson MA, 2003, J ELECTRON IMAGING, V12, P219, DOI 10.1117/1.1557695
   Schechner YY, 2003, INT J COMPUT VISION, V53, P245, DOI 10.1023/A:1023082924255
   Schedl DC, 2014, COMPUT GRAPH FORUM, V33, P33, DOI 10.1111/cgf.12288
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Tan TK, 2006, IEEE IMAGE PROC, P1693, DOI 10.1109/ICIP.2006.312685
   Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89
   Unger J., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P141
   Unger J., 2008, COMPUT GRAPH FORUM, V27, P4
   Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang L., 2007, Rendering Techniques, P321
   Wang TC, 2016, LECT NOTES COMPUT SC, V9907, P121, DOI 10.1007/978-3-319-46487-9_8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Ward G., 2003, Journal of Graphics Tools, V8, P17, DOI 10.1080/10867651.2003.10487583
   Wei LY, 2001, COMP GRAPH, P355, DOI 10.1145/383259.383298
   Yu Z, 2013, IEEE I CONF COMP VIS, P2792, DOI 10.1109/ICCV.2013.347
   Yu Z, 2012, PROC CVPR IEEE, P901, DOI 10.1109/CVPR.2012.6247764
   Zheng YJ, 2009, IEEE T PATTERN ANAL, V31, P2243, DOI 10.1109/TPAMI.2008.263
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 72
TC 5
Z9 5
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2018
VL 14
IS 2
AR 52
DI 10.1145/3199514
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GG9BS
UT WOS:000432996000009
DA 2024-07-18
ER

PT J
AU Pan, ZQ
   Lei, JJ
   Zhang, YJ
   Wang, FL
AF Pan, Zhaoqing
   Lei, Jianjun
   Zhang, Yajuan
   Wang, Fu Lee
TI Adaptive Fractional-Pixel Motion Estimation Skipped Algorithm for
   Efficient HEVC Motion Estimation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Fast motion estimation; fractional-pixel motion estimation; HEVC; video
   coding; visual communication
ID MANY-CORE PROCESSORS; PARALLEL FRAMEWORK; DECISION
AB High-Efficiency Video Coding (HEVC) efficiently addresses the storage and transmit problems of high-definition videos, especially for 4K videos. The variable-size Prediction Units (PUs)-based Motion Estimation (ME) contributes a significant compression rate to the HEVC encoder and also generates a huge computation load. Meanwhile, high-level encoding complexity prevents widespread adoption of the HEVC encoder in multimedia systems. In this article, an adaptive fractional-pixel ME skipped scheme is proposed for low-complexity HEVC ME. First, based on the property of the variable-size PUs-based ME process and the video content partition relationship among variable-size PUs, all inter-PU modes during a coding unit encoding process are classified into root-type PU mode and children-type PU modes. Then, according to the ME result of the root-type PU mode, the fractional-pixel ME of its children-type PU modes is adaptively skipped. Simulation results show that, compared to the original ME in HEVC reference software, the proposed algorithm reduces ME encoding time by an average of 63.22% while encoding efficiency performance is maintained.
C1 [Pan, Zhaoqing] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Pan, Zhaoqing] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher, Nanjing 210044, Jiangsu, Peoples R China.
   [Lei, Jianjun] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Zhang, Yajuan] Hebei Univ Technol, Sch Comp Sci & Engn, Tianjin 300401, Peoples R China.
   [Wang, Fu Lee] Caritas Inst Higher Educ, Sch Comp & Informat Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Tianjin University;
   Hebei University of Technology; Saint Francis University Hong Kong
RP Lei, JJ (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM zqpan3-c@my.cityu.edu.hk; jjlei@tju.edu.cn;
   zhangyajuan@scse.hebut.edu.cn; pwang@cihe.edu.hk
RI Wang, Fu Lee/AAD-9782-2021; Lei, Jianjun/P-2539-2018
OI Wang, Fu Lee/0000-0002-3976-0053; 
FU National Natural Science Foundation of China [61501246, 61271324];
   Natural Science Foundation of Jiangsu Province of China [BK20150930];
   Natural Science Foundation of the Jiangsu Higher Education Institutions
   of China [15KJB510019]; Research Grants Council of the Hong Kong Special
   Administrative Region of China [UGC/FDS/E04/16]; Priority Academic
   Program Development of Jiangsu Higher Education Institutions; Six Talent
   Peaks Project of Jiangsu Province [XYDXXJS-041]; Fund Program for the
   Scientific Activities of Selected Returned Overseas Professionals in
   Nanjing; Collaborative Innovation Center of Atmospheric Environment and
   Equipment Technology; Startup Foundation for Introducing Talent of
   NUIST; Natural Science Foundation of Hebei Province of China
   [F2015202311]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 61501246, Grant No. 61271324, in
   part by the Natural Science Foundation of Jiangsu Province of China
   under Grant No. BK20150930, in part by the Natural Science Foundation of
   the Jiangsu Higher Education Institutions of China under Grant No.
   15KJB510019, in part by the Research Grants Council of the Hong Kong
   Special Administrative Region of China under Grant No. UGC/FDS/E04/16,
   in part by the Project through the Priority Academic Program Development
   of Jiangsu Higher Education Institutions, in part by the Six Talent
   Peaks Project of Jiangsu Province under Grant No. XYDXXJS-041, in part
   by the Fund Program for the Scientific Activities of Selected Returned
   Overseas Professionals in Nanjing, in part by the Collaborative
   Innovation Center of Atmospheric Environment and Equipment Technology,
   in part by the Startup Foundation for Introducing Talent of NUIST, and
   in part by the Natural Science Foundation of Hebei Province of China
   under Grant No. F2015202311.
CR Abdelazim A., 2014, P SOC PHOTO-OPT INS, V9029
   Bjontegaard G., 2001, P ITU T VCEG 13 VCEG
   Blasi SG, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P144, DOI 10.1109/PCS.2015.7170064
   Bossen F., 2012, ITU T ISO IEC JOINT
   Dai W, 2012, INT CONF ACOUST SPEE, P1197, DOI 10.1109/ICASSP.2012.6288102
   Dutta T, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3002178
   Gao LF, 2015, IEEE IMAGE PROC, P2810, DOI 10.1109/ICIP.2015.7351315
   Hu N, 2014, IEEE T CIRC SYST VID, V24, P1310, DOI 10.1109/TCSVT.2014.2306035
   Lee TK, 2014, INT CONF DIGIT SIG, P919, DOI 10.1109/ICDSP.2014.6900803
   Li H, 2013, INT CONF ACOUST SPEE, P1399, DOI 10.1109/ICASSP.2013.6637881
   Li XF, 2015, IEEE INT SYMP CIRC S, P2784, DOI 10.1109/ISCAS.2015.7169264
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Shen LQ, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700298
   Sotetsumoto T., 2013, P IEEE INT C SIGN PR, P1
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang S., 2014, IEEE T THZ SCI TECHN, P1
   Zuo XG, 2015, 2015 Picture Coding Symposium (PCS) with 2015 Packet Video Workshop (PV), P80, DOI 10.1109/PCS.2015.7170051
NR 22
TC 68
Z9 70
U1 0
U2 47
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2018
VL 14
IS 1
AR 12
DI 10.1145/3159170
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FW9HO
UT WOS:000425646500012
DA 2024-07-18
ER

PT J
AU Wang, PS
   Hu, QH
   Fang, ZW
   Zhao, CY
   Cheng, J
AF Wang, Peisong
   Hu, Qinghao
   Fang, Zhiwei
   Zhao, Chaoyang
   Cheng, Jian
TI DeepSearch: A Fast Image Search Framework for Mobile Devices
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; acceleration; image retrieval; tensor
   decomposition
ID HIGHER-ORDER TENSOR; RETRIEVAL; DECOMPOSITIONS; SIMILARITY
AB Content-based image retrieval (CBIR) is one of the most important applications of computer vision. In recent years, there have been many important advances in the development of CBIR systems, especially Convolutional Neural Networks (CNNs) and other deep-learning techniques. On the other hand, current CNN-based CBIR systems suffer from high computational complexity of CNNs. This problem becomes more severe as mobile applications become more and more popular. The current practice is to deploy the entire CBIR systems on the server side while the client side only serves as an image provider. This architecture can increase the computational burden on the server side, which needs to process thousands of requests per second. Moreover, sending images have the potential of personal information leakage. As the need of mobile search expands, concerns about privacy are growing. In this article, we propose a fast image search framework, named DeepSearch, which makes complex image search based on CNNs feasible on mobile phones. To implement the huge computation of CNN models, we present a tensor Block Term Decomposition (BTD) approach as well as a nonlinear response reconstruction method to accelerate the CNNs involving in object detection and feature extraction. The extensive experiments on the ImageNet dataset and Alibaba Large-scale Image Search Challenge dataset show that the proposed accelerating approach BTD can significantly speed up the CNN models and further makes CNN-based image search practical on common smart phones.
C1 [Wang, Peisong; Hu, Qinghao; Fang, Zhiwei; Zhao, Chaoyang; Cheng, Jian] Chinese Acad Sci, Inst Automat, 95 East Zhongguancun Rd, Beijing 100190, Peoples R China.
   [Wang, Peisong; Hu, Qinghao; Fang, Zhiwei; Zhao, Chaoyang; Cheng, Jian] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Cheng, Jian] CAS Ctr Excellence Brain Sci & Intelligence Techn, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Wang, PS (corresponding author), Chinese Acad Sci, Inst Automat, 95 East Zhongguancun Rd, Beijing 100190, Peoples R China.
EM peisong.wang@nlpr.ia.ac.cn; qinghao.hu@nlpr.ia.ac.cn;
   zhiwei.fang@nlpr.ia.ac.cn; chaoyang.zhao@nlpr.ia.ac.cn;
   jcheng@nlpr.ia.ac.cn
RI , chengjian/KGL-5551-2024; Hu, Qinghao/IWD-6615-2023
OI , chengjian/0000-0003-1289-2758; 
FU National Natural Science Foundation of China [61332016]; Jiangsu Key
   Laboratory of Big Data Analysis Technology; 863 program [2014AA015105]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61332016), the Jiangsu Key Laboratory of Big
   Data Analysis Technology, and the 863 program (No. 2014AA015105).
CR [Anonymous], P EUR S ART NEUR NET
   [Anonymous], 2014, BRIT MACH VIS C
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2016, Bitwise neural networks
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], IEEE T PATT AN MACH
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2017, PROC INT C LEARN REP
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2015, TRAINING BINARY MULT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, CoRR
   [Anonymous], 2015, ARXIV151106530
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Cheng J, 2007, PATTERN RECOGN, V40, P330, DOI 10.1016/j.patcog.2006.06.005
   Cheng J, 2014, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2014.8
   Cheng J, 2014, COMPUT VIS IMAGE UND, V124, P12, DOI 10.1016/j.cviu.2014.04.001
   Courbariaux M., 2016, BinaryNet: Training deep neural networks with weights and activa
   Courbariaux M, 2015, ADV NEUR IN, V28
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995
   De Lathauwer L, 2008, SIAM J MATRIX ANAL A, V30, P1067, DOI 10.1137/070690730
   De Lathauwer L, 2008, SIAM J MATRIX ANAL A, V30, P1033, DOI 10.1137/070690729
   De Lathauwer L, 2008, SIAM J MATRIX ANAL A, V30, P1022, DOI 10.1137/060661685
   Denil M., 2013, P 26 INT C NEUR INF, P2148
   Denton E, 2014, ADV NEUR IN, V27
   Fang ZW, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P405, DOI 10.1145/2911996.2912027
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   GOWER J., 2004, Procrustes Problems
   Han S, 2015, P ADV NEUR INF PROC, V2015, P1135
   Horster E., 2008, Proceedings of the 16th ACM international conference on Multimedia, P643
   Hubara I, 2016, ADV NEUR IN, V29
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Lebedev V., 2014, INT C LEARNING REPRE
   Lebedev V, 2016, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2016.280
   Lin D. D., 2015, CoRR
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mathieu Michael, 2013, ARXIV13125851
   Novikov A, 2015, ADV NEUR IN, V28
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Romero A., 2014, 3 INT C LEARN REPRES
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, IEEE INT C ICLR
   Takane Yoshio., 2006, Behaviormetrika, V33, P179
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang P., 2016, P 24 ACM INT C MULT, P541
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Zhang X., 2017, ARXIV170701083
NR 61
TC 11
Z9 11
U1 0
U2 19
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2018
VL 14
IS 1
AR 6
DI 10.1145/3152127
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FW9HO
UT WOS:000425646500006
DA 2024-07-18
ER

PT J
AU Bao, BK
   Xu, CS
   Min, WQ
   Hossain, MS
AF Bao, Bing-Kun
   Xu, Changsheng
   Min, Weiqing
   Hossain, Mohammod Shamim
TI Cross-Platform Emerging Topic Detection and Elaboration from Multimedia
   Streams
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Topic detection; cross-platform; cross-media; coclustering
AB With the explosive growth of online media platforms in recent years, it becomes more and more attractive to provide users a solution of emerging topic detection and elaboration. And this posts a real challenge to both industrial and academic researchers because of the overwhelming information available in multiple modalities and with large outlier noises. This article provides a method on emerging topic detection and elaboration using multimedia streams cross different online platforms. Specifically, Twitter, New York Times and Flickr are selected for the work to represent the microblog, news portal and imaging sharing platforms. The emerging keywords of Twitter are firstly extracted using aging theory. Then, to overcome the nature of short length message in microblog, Robust Cross-Platform Multimedia Co-Clustering (RCPMM-CC) is proposed to detect emerging topics with three novelties: 1) The data from different media platforms are in multimodalities; 2) The coclustering is processed based on a pairwise correlated structure, in which the involved three media platforms are pairwise dependent; 3) The noninformative samples are automatically pruned away at the same time of coclustering. In the last step of cross-platform elaboration, we enrich each emerging topic with the samples from New York Times and Flickr by computing the implicit links between social topics and samples from selected news and Flickr image clusters, which are obtained by RCPMM-CC. Qualitative and quantitative evaluation results demonstrate the effectiveness of our method.
C1 [Bao, Bing-Kun; Xu, Changsheng; Min, Weiqing] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100864, Peoples R China.
   [Hossain, Mohammod Shamim] King Saud Univ, SWE Dept, Coll Comp & Informat Sci, Riyadh 11451, Saudi Arabia.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; King Saud
   University
RP Bao, BK (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100864, Peoples R China.
EM bkbao@mail.nlpr.ia.ac.cn; csxu@mail.nlpr.ia.ac.cn;
   wqmin@mail.nlpr.ia.ac.cn; mshossain@ksu.edu.sa
RI Hossain, M. Shamim/K-1362-2014; xu, cj/HJZ-3488-2023; Guizani,
   Mohsen/AAX-4534-2021
OI Hossain, M. Shamim/0000-0001-5906-9422; Guizani,
   Mohsen/0000-0002-8972-8094
FU National Program on Key Basic Research Project 973 Program
   [2012CB316304]; National Natural Science Foundation of China [61201374,
   61432019, 61225009]; Beijing Natural Science Foundation [4152053,
   4131004]; Deanship of Scientific Research at King Saud University,
   Riyadh, Saudi Arabia [RGP VPP-228]
FX This work was supported in part by National Program on Key Basic
   Research Project 973 Program, Project 2012CB316304, in part by the
   National Natural Science Foundation of China under Grant 61201374, Grant
   61432019, and Grant 61225009, in part by Beijing Natural Science
   Foundation (4152053 and 4131004). The authors extend their appreciation
   to the Deanship of Scientific Research at King Saud University, Riyadh,
   Saudi Arabia for funding this work through the research group Project
   No. RGP VPP-228.
CR Alvanaki F., 2011, P 2011 ACM SIGMOD IN, P1271
   [Anonymous], 2000, Icml, DOI DOI 10.1007/3-540-44491-2_3
   [Anonymous], 2012, SIG 2012 WORKSH TIM
   [Anonymous], 3 INT AAAI C WEBL SO
   [Anonymous], 2006, PROC 12 ACM SIGKDD I
   Banerjee A, 2007, J MACH LEARN RES, V8, P1919
   Bansal Romil, 2012, P ACM INT C MULT, P1355
   Bao B.-K., 2013, Proceedings of the International Conference on Multimedia Retrieval, P135
   Bao B.-K., 2012, P 20 ACM INT C MULT, P1357
   Bao BK, 2015, IEEE T CYBERNETICS, V45, P15, DOI 10.1109/TCYB.2014.2317514
   Cai R, 2008, IEEE T MULTIMEDIA, V10, P596, DOI 10.1109/TMM.2008.921739
   Chen CC, 2003, LECT NOTES ARTIF INT, V2837, P47
   Chen KY, 2007, IEEE T KNOWL DATA EN, V19, P1016, DOI 10.1109/TKDE.2007.1040
   Deodhar M., 2008, IDEALTR09 U TEX AUST
   Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550
   Dhillon I. S., 2003, P INT C KNOWL DISC D
   Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971
   Gamon M., 2008, P AAAI C WEBL SOC ME
   Gao B, 2006, IEEE DATA MINING, P880
   Greco G, 2010, IEEE T KNOWL DATA EN, V22, P1649, DOI 10.1109/TKDE.2009.207
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jegelka S, 2009, LECT NOTES ARTIF INT, V5809, P368, DOI 10.1007/978-3-642-04414-4_30
   Kasiviswanathan S.P., 2011, CIKM, P745, DOI DOI 10.1145/2063576.2063686
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Li T., 2015, IEEE T CIRCUITS SYST
   Long B, 2005, P 11 ACM SIGKDD INT, V5, P635, DOI [DOI 10.1145/1081870.1081949, 10.1145/1081870.1081949]
   Aiello LM, 2013, IEEE T MULTIMEDIA, V15, P1268, DOI 10.1109/TMM.2013.2265080
   Roy S. D., 2012, P IEEE INT C MULT EX
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Serres G. K. F., 2013, P SBMO IEEE MTT S IN, P1
   Takama Y, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WORKSHOPS PROCEEDINGS, P413, DOI 10.1109/WI-IATW.2006.142
   Tan S, 2011, P 19 ACM INT C MULT, P243
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Zhu Jianke., 2008, P 16 ACM INT C MULTI, P41
NR 35
TC 29
Z9 32
U1 5
U2 47
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2015
VL 11
IS 4
AR 54
DI 10.1145/2730889
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CK0ZF
UT WOS:000355933700007
DA 2024-07-18
ER

PT J
AU Guan, GL
   Wang, ZY
   Mei, SH
   Ott, M
   He, MY
   Feng, DD
AF Guan, Genliang
   Wang, Zhiyong
   Mei, Shaohui
   Ott, Max
   He, Mingyi
   Feng, David Dagan
TI A Top-Down Approach for Video Summarization
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Design; Experimentation; Keyframe extraction; scene
   identification; clustering; keypoint; local visual word
ID FRAMEWORK
AB While most existing video summarization approaches aim to identify important frames of a video from either a global or local perspective, we propose a top-down approach consisting of scene identification and scene summarization. For scene identification, we represent each frame with global features and utilize a scalable clustering method. We then formulate scene summarization as choosing those frames that best cover a set of local descriptors with minimal redundancy. In addition, we develop a visual word-based approach to make our approach more computationally scalable. Experimental results on two benchmark datasets demonstrate that our proposed approach clearly outperforms the state-of-the-art.
C1 [Guan, Genliang; Wang, Zhiyong; Feng, David Dagan] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
   [Mei, Shaohui; He, Mingyi] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
   [Ott, Max] Natl ICT Australia NICTA, Melbourne, Vic, Australia.
C3 University of Sydney; Northwestern Polytechnical University; NICTA
RP Wang, ZY (corresponding author), Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
EM zhiyong.wang@sydney.edu.au
RI Mei, Shao-Hui/AAB-9154-2022; He, Mingyi/AGX-2464-2022; He,
   Mingyi/B-4138-2011; Mingyi, HE/IXN-2319-2023
OI He, Mingyi/0000-0003-2051-6955; He, Mingyi/0000-0003-2051-6955; Mingyi,
   HE/0000-0003-2051-6955; Feng, Dagan/0000-0002-3381-214X; Wang,
   Zhiyong/0000-0002-8043-0312; Ott, Maximilian/0000-0002-3526-6736
FU ARC (Australian Research Council); Natural Science Foundation of Shaanxi
   Province [2010JZ011]; Fundamental Research Funds for the Central
   Universities [3102014JCQ01054]; National ICT Australia (NICTA)
FX The work presented in this article is partially supported by ARC
   (Australian Research Council) grants, Natural Science Foundation of
   Shaanxi Province grant (no. 2010JZ011), the Fundamental Research Funds
   for the Central Universities (3102014JCQ01054), and National ICT
   Australia (NICTA).
CR Achantay R., 2009, P IEEE C COMP VIS PA
   [Anonymous], PROC ICML
   [Anonymous], 2013, P IEEE C COMP VIS PA
   Besiris D, 2009, MULTIMED TOOLS APPL, V44, P161, DOI 10.1007/s11042-009-0277-9
   Bian JW, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1807, DOI 10.1145/2505515.2505652
   Cao L., 2012, P EUR C COMP VIS ECC
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Chatzichristofis S. A., 2008, P INT C COMP VIS SYS
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Chen F, 2014, IEEE T MULTIMEDIA, V16, P455, DOI 10.1109/TMM.2013.2291967
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Dementhon D. F., 1998, P ACM INT C MULT
   EVANGELOPOULOS G, 2008, P IEEE INT C IM PROC
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gong Y. H., 2000, P IEEE C COMP VIS PA
   Guan G., 2012, P IEEE INT C MULT EX
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Hong RC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2043612.2043613
   Li J., 2010, J DIGITAL CONTENT TE, P202, DOI DOI 10.4156/JDCTA.VOL4.ISSUE3.20
   Li Y., 2011, P 19 ACM INT C MULT, P1573
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1245, DOI 10.1109/TCSVT.2005.854230
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Liu G., 2009, P IEEE ACIS INT C CO
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu S., 2013, P ICME WORKSH EM MUL
   Lu Shiyang, 2014, IEEE T MULT IN PRESS
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mei SH, 2014, IEEE INT CON MULTI
   Mei T, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487269
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Muja M., 2009, P INT C COMP VIS THE
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Zheng Y.-T., 2007, P ACM INT C IM VID R
   Zhuang Y., 1998, P IEEE INT C IM PROC
NR 44
TC 33
Z9 35
U1 0
U2 20
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2014
VL 11
IS 1
AR 4
DI 10.1145/2632267
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AP2XQ
UT WOS:000341939800004
DA 2024-07-18
ER

PT J
AU Li, ZC
   Liu, J
   Wang, M
   Xu, CS
   Lu, HQ
AF Li, Zechao
   Liu, Jing
   Wang, Meng
   Xu, Changsheng
   Lu, Hanqing
TI Enhancing News Organization for Convenient Retrieval and Browsing
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Human Factors; News organization; matrix factorization;
   geo-location; image enrichment; GeoVisNews
AB To facilitate users to access news quickly and comprehensively, we design a news search and browsing system named GeoVisNews, in which the news elements of "Where", "Who", "What" and "When" are enhanced via news geo-localization, image enrichment and joint ranking, respectively. For news geo-localization, an Ordinal Correlation Consistent Matrix Factorization (OCCMF) model is proposed to maintain the relevance rankings of locations to a specific news document and simultaneously capture intra-relations among locations and documents. To visualize news, we develop a novel method to enrich news documents with appropriate web images. Specifically, multiple queries are first generated from news documents for image search, and then the appropriate images are selected from the collected web images by an intelligent fusion approach based on multiple features. Obtaining the geo-localized and image enriched news resources, we further employ a joint ranking strategy to provide relevant, timely and popular news items as the answer of user searching queries. Extensive experiments on a large-scale news dataset collected from the web demonstrate the superior performance of the proposed approaches over related methods.
   Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; H.5.1 [Information Interfaces and Presentation]: Multimedia Information System
C1 [Li, Zechao] Nanjing Univ Sci & Technol, Sch Comp Sci, Nanjing, Jiangsu, Peoples R China.
   [Liu, Jing; Xu, Changsheng; Lu, Hanqing] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China.
   [Wang, Meng] Hefei Univ Technol, Sch Comp & Informat, Hefei, Peoples R China.
C3 Nanjing University of Science & Technology; Chinese Academy of Sciences;
   Institute of Automation, CAS; Hefei University of Technology
RP Liu, J (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China.
EM zechao.li@gmail.com; jliu@nlpr.ia.ac.en; eric.mengwang@gmail.com;
   csxu@nlpr.ia.ac.en; luhq@nlpr.ia.ac.en
RI xu, cj/HJZ-3488-2023; Wang, Meng/ITR-8699-2023
FU 973 Program [2012CB316304]; National Natural Science Foundation of China
   [61272329, 90920303, 61070104, 61272393]; Program for New Century
   Excellent Talents in University [NCET-12-0836]; National Laboratory of
   Pattern Recognition (NLPR)
FX This work was supported by the 973 Program (2012CB316304), the National
   Natural Science Foundation of China (61272329, 90920303, 61070104, and
   61272393), the Program for New Century Excellent Talents in University
   under grant NCET-12-0836, and the Open Project Program of the National
   Laboratory of Pattern Recognition (NLPR).
CR Amitay E., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P273, DOI 10.1145/1008992.1009040
   Andogah G, 2010, THESIS U GRONINGEN
   [Anonymous], MIR 04
   [Anonymous], STAT REASONING PSYCH
   [Anonymous], MM 08
   [Anonymous], THESIS
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Christel M.G., 2002, ACM Multimedia, P561
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Coyne B, 2001, COMP GRAPH, P487, DOI 10.1145/383259.383316
   Delgado D., 2010, Proceedings of the 18th ACM International Conference on Multimedia, P1647, DOI DOI 10.1145/1873951.1874311
   Deschacht K., 2008, P ECIR
   DING J, 2000, P 26 INT C VER LARG, P545
   Gey F.C., 2005, Proceedings of CLEF, P908
   Gravier G, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/689780
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jiao BX, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P499
   Joachims T., 2002, P KDD, P31
   Kumaran G, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P564, DOI 10.1145/1571941.1572038
   LI Z, 2010, P CIKM
   Li Z., 2011, P MM
   Li Zheng, 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1187, DOI 10.1145/1873951.1874183
   Liu SX, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089101
   Lu X., 2009, P INT WORKSH LOC BAS
   Martins B, 2009, THESIS U LISBON
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mnih A., 2007, ADV NEURAL INFORM PR, V20
   Ohtsuki K, 2006, IEEE SIGNAL PROC MAG, V23, P69, DOI 10.1109/MSP.2006.1621450
   Okuoka T, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P501, DOI 10.1109/ISM.2009.67
   Page L., 1999, PAGERANK CITATION RA
   Rother C., 2006, P SIGGRAPH
   Sparck-Jones K, 2000, INFORM PROCESS MANAG, V36, P779, DOI 10.1016/S0306-4573(00)00015-7
   Strobelt H, 2009, IEEE T VIS COMPUT GR, V15, P1145, DOI 10.1109/TVCG.2009.139
   Sturm J. F, 2009, SITE MATTERS VALUE L
   Teevan J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2023
   uston S., 2010, ACM T MULTIM COMPUT, V10
   Wang B, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P353, DOI 10.1109/ICME.2006.262509
   Wang J., 2006, P CVPR
   Yan R., 2003, P 11 ACM INT C MULT, V3, P339, DOI DOI 10.1145/957013.957086
   Zhang L., 2006, Proceedings of the 14th ACM International Conference on Multimedia, P367, DOI [10.1145/1180639, DOI 10.1145/1180639]
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
   Zong WB, 2005, ACM-IEEE J CONF DIG, P354, DOI 10.1145/1065385.1065464
NR 42
TC 11
Z9 12
U1 3
U2 19
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2013
VL 10
IS 1
AR 1
DI 10.1145/2488732
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 280JP
UT WOS:000329025400001
DA 2024-07-18
ER

PT J
AU Effelsberg, W
AF Effelsberg, Wolfgang
TI A Personal Look Back at Twenty Years of Research in Multimedia Content
   Analysis
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Human Factors; Algorithms; Music analysis; query by example; video
   analysis; user feedback; face recognition; text recognition;
   brain-computer interface; multimedia content analysis
AB This paper is a personal look back at twenty years of research in multimedia content analysis. It addresses the areas of audio, photo and video analysis for the purpose of indexing and retrieval from the perspective of a multimedia researcher. Whereas a general analysis of content is impossible due to the personal bias of the user, significant progress was made in the recognition of specific objects or events. The paper concludes with a brief outlook on the future.
C1 Univ Mannheim, D-68131 Mannheim, Germany.
C3 University of Mannheim
RP Effelsberg, W (corresponding author), Univ Mannheim, A 5,6, D-68131 Mannheim, Germany.
EM effelsberg@informatik.uni-mannheim.de
CR [Anonymous], P ACM MULT FIR IT
   [Anonymous], 2007, P 15 ACM INT C MULTI
   [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], P NIST TRECVID WORKS
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001
   Ghias A., 1995, PROC ACM MULTIMEDIA, P231
   Han JG, 2008, IEEE T CIRC SYST VID, V18, P1628, DOI 10.1109/TCSVT.2008.2005611
   Lienhart R, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P509, DOI 10.1109/MMCS.1997.609763
   Moore BE, 2011, COMMUN ACM, V54, P64, DOI 10.1145/2043174.2043192
   NIBLACK C. W., 1993, P SPIE
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   UITDENBOGERD A., 1995, P ACM MULT C, P57
   Wactlar HD, 1999, COMPUTER, V32, P66, DOI 10.1109/2.745722
   Wang G, 2012, IEEE T PATTERN ANAL, V34, P2177, DOI 10.1109/TPAMI.2012.29
   [No title captured]
NR 17
TC 3
Z9 3
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2013
VL 9
IS 1
SU S
AR 43
DI 10.1145/2502434
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 241SJ
UT WOS:000326187700013
DA 2024-07-18
ER

PT J
AU Valdes, V
   Martinez, JM
AF Valdes, Victor
   Martinez, Jose M.
TI Automatic Evaluation of Video Summaries
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Automatic evaluation; skimming; summarization; summarization
   algorithms evaluation
AB This article describes a method for the automatic evaluation of video summaries based on the training of individual predictors for different quality measures from the TRECVid 2008 BBC Rushes Summarization Task. The obtained results demonstrate that, with a large set of evaluation data, it is possible to train fully automatic evaluation systems based on visual features automatically extracted from the summaries. The proposed approach will enable faster and easier estimation of the results of newly developed abstraction algorithms and the study of which summary characteristics influence their perceived quality.
C1 [Valdes, Victor; Martinez, Jose M.] Univ Autonoma Madrid, Escuela Politecn Super, Video Proc & Understanding Lab, Madrid, Spain.
C3 Autonomous University of Madrid
RP Valdes, V (corresponding author), Univ Autonoma Madrid, Escuela Politecn Super, Video Proc & Understanding Lab, Madrid, Spain.
EM victor.valdes@uam.es; josem.martinez@uam.es
RI Martinez, Jose/A-1185-2008
OI Martinez, Jose/0000-0002-2236-1769
FU Spanish Government [TEC2007-65400]; Consejeria de Educacion of the
   Communidad de Madrid; European Social Fund
FX This work was supported by the Spanish Government (TEC2007-65400 -
   SemanticVideo), Consejeria de Educacion of the Communidad de Madrid and
   by the European Social Fund.
CR [Anonymous], P 2 ACM TREC VID RET
   Bai L, 2008, LECT NOTES COMPUT SC, V5392, P3
   Bredin H., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P45
   Breiman L, 1998, BIOMETRICS, DOI [10.1201/9781315139470, DOI 10.2307/2530946]
   Christel M. G., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P171, DOI 10.1145/274644.274670
   CHRISTEL MG, 2008, P 2 ACM TRECVID VID, P35
   Dumont E., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P55
   DUMONT E, 2007, P INT WORKSH TRECVID, P55
   Dumont E, 2008, INT WORK CONTENT MUL, P502
   Dumont E, 2010, MULTIMED TOOLS APPL, V48, P51, DOI 10.1007/s11042-009-0374-9
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   Hauptmann A.G., 2007, Proceedings of the international workshop on TRECVID video summarization, P20
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   MARCHIONINI G., 1997, P INT S RES DEV PRAC, P151
   Over P., 2008, Proc. of the 2nd ACM TRECVid Video Summarization Workshop, P1, DOI [DOI 10.1145/1463563.1463564, 10.1145/1463563.1463564]
   Over P., 2007, TVS '07: Proc. of the International Workshop on TRECVID Video Summarization, P1, DOI DOI 10.1145/1290031.1290032
   Taskiran CM, 2006, IEEE T MULTIMEDIA, V8, P775, DOI 10.1109/TMM.2006.876282
   Tongwei Ren, 2008, 2008 IEEE International Conference on Data Mining Workshops, P874, DOI 10.1109/ICDMW.2008.55
   Valdes V., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P134, DOI [10.1145/1463563.1463588, DOI 10.1145/1463563.1463588]
   Yamasaki K., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P129
NR 21
TC 8
Z9 11
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUL
PY 2012
VL 8
IS 3
AR 25
DI 10.1145/2240136.2240138
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 986AM
UT WOS:000307311700002
DA 2024-07-18
ER

PT J
AU Olsen, DR
   Bunn, D
   Boulter, T
   Walz, R
AF Olsen, Dan R.
   Bunn, Derek
   Boulter, Trent
   Walz, Robert
TI Interactive Television News
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Human Factors; Interactive television; interactive news
AB A new interactive television experience has been created for watching television news. The goal is to create a news experience that is similar to the way people watch television in their living rooms while giving viewers the power to make choices about what they see. We partnered with existing news organizations to create tools consistent with current news production practices. The viewer experience allows selection of the order of news content, skipping unwanted content and exploring stories in more depth. These tools were used to produce seven days of interactive commercial news that were viewed in ten homes.
C1 [Olsen, Dan R.; Bunn, Derek; Boulter, Trent; Walz, Robert] Brigham Young Univ, Provo, UT 84602 USA.
C3 Brigham Young University
RP Olsen, DR (corresponding author), Brigham Young Univ, Provo, UT 84602 USA.
EM olsen@cs.byu.edu
RI Akalugwu, Kenneth/F-4815-2014; Bunn, David/H-4932-2018
CR [Anonymous], 2009, BBC
   AVID, 2009, AVID INEWS NRCS
   Barkhuus L, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1592440.1592444
   BYWATER J., 2004, P EUR C INT TEL ENR
   Dowman M., 2005, P WORKSH MULT SEM WE
   Haas N, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P9
   HAUPTMANN AG, 1997, INTELLIGENT MULTIMED
   Hughes J., 2000, Personal Technologies, V4, P25, DOI 10.1007/BF01613596
   JENSEN J. F., 2005, P 3 AUSTR C INT ENT
   Kraut R, 1996, COMMUN ACM, V39, P55, DOI 10.1145/240483.240493
   Larsson H, 2008, LECT NOTES COMPUT SC, V5066, P30, DOI 10.1007/978-3-540-69478-6_4
   MICROSOFT CORPORATION, 2009, SMOOTH STREAM OFF MI
   O'Brien J., 1999, ACM Transactions on Computer-Human Interaction, V6, P282, DOI 10.1145/329693.329698
   OEHLBERG L., 2006, P EUR C CHANG TEL EN
   WILLIAMS D., 2007, P 4 INT C VIRT STOR, P153
NR 15
TC 1
Z9 2
U1 3
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2012
VL 8
IS 2
AR 19
DI 10.1145/2168996.2168999
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 945BX
UT WOS:000304248900003
DA 2024-07-18
ER

PT J
AU Lin, YR
   Sundaram, H
   De Choudhury, M
   Kelliher, A
AF Lin, Yu-Ru
   Sundaram, Hari
   De Choudhury, Munmun
   Kelliher, Aisling
TI Discovering Multirelational Structure in Social Media Streams
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Experimentation; Measurement; Algorithms; Human Factors; Social media;
   social network analysis; structure mining; multirelational learning;
   nonnegative matrix factorization
ID SYMMETRY
AB In this article, we present a novel algorithm to discover multirelational structures from social media streams. A media item such as a photograph exists as part of a meaningful interrelationship among several attributes, including time, visual content, users, and actions. Discovery of such relational structures enables us to understand the semantics of human activity and has applications in content organization, recommendation algorithms, and exploratory social network analysis.
   We are proposing a novel nonnegative matrix factorization framework to characterize relational structures of group photo streams. The factorization incorporates image content features and contextual information. The idea is to consider a cluster as having similar relational patterns; each cluster consists of photos relating to similar content or context. Relations represent different aspects of the photo stream data, including visual content, associated tags, photo owners, and post times. The extracted structures minimize the mutual information of the predicted joint distribution. We also introduce a relational modularity function to determine the structure cost penalty, and hence determine the number of clusters. Extensive experiments on a large Flickr dataset suggest that our approach is able to extract meaningful relational patterns from group photo streams. We evaluate the utility of the discovered structures through a tag prediction task and through a user study. Our results show that our method based on relational structures, outperforms baseline methods, including feature and tag frequency based techniques, by 35%-420%. We have conducted a qualitative user study to evaluate the benefits of our framework in exploring group photo streams. The study indicates that users found the extracted clustering results clearly represent major themes in a group; the clustering results not only reflect how users describe the group data but often lead the users to discover the evolution of the group activity.
C1 [Lin, Yu-Ru; Sundaram, Hari; De Choudhury, Munmun; Kelliher, Aisling] Arizona State Univ, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Lin, YR (corresponding author), Arizona State Univ, Tempe, AZ 85287 USA.
EM yu-ru.lin@asu.edu
OI Kelliher, Aisling/0000-0001-9175-2176; Sundaram,
   Hari/0000-0003-3315-6055
CR Ahern S, 2007, ACM-IEEE J CONF DIG, P1, DOI 10.1145/1255175.1255177
   [Anonymous], 2004, Proceedings of the 12th ACM International Conference on Multimedia, DOI DOI 10.1145/1027527.1027747
   [Anonymous], 2006, Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P424, DOI [DOI 10.1145/1150402.1150450, 10.1145/1150402.1150450]
   Backstrom L., 2006, P 12 ACM SIGKDD INT, P44, DOI DOI 10.1145/1150402.1150412
   Banerjee A, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P145
   Bekkerman Ron., 2005, Proceedings of the 22nd international conference on Machine learning, P41
   BLEI D., 2006, ICML, P120
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   CHEN H., 2008, SHEEPDOG GROUP TAG R
   Dhillon IS, 2003, P 9 ACM SIGKDD INT C, P89, DOI DOI 10.1145/956750.956764
   DOREIAN P, 2001, STRUCTURES SUP UNPUB
   Garg N, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P67
   Hanghang Tong, 2005, 13th Annual ACM International Conference on Multimedia, P862, DOI 10.1145/1101149.1101337
   Jarvelin Kalervo, 2000, P 23 ANN INT ACM SIG, P41, DOI DOI 10.1145/345508.345545
   Kemp C, 2008, P NATL ACAD SCI USA, V105, P10687, DOI 10.1073/pnas.0802631105
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   Kirsten M., 1998, Inductive Logic Programming. 8th International Conference, ILP-98. Proceedings, P261, DOI 10.1007/BFb0027330
   Kumar R., 2006, P 12 ACM SIGKDD INT, P611, DOI DOI 10.1007/978-1-4419-6515-8_13
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li T., 2007, P 16 ACM C C INF KNO, P147
   Liu Z, 2007, PATTERN RECOGN LETT, V28, P166, DOI 10.1016/j.patrec.2006.06.019
   Long B., 2006, SIGKDD, P317, DOI DOI 10.1145/1150402.1150439
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601
   McCowan I, 2005, IEEE T PATTERN ANAL, V27, P305, DOI 10.1109/TPAMI.2005.49
   Negoescu R.A., 2008, Proc. Content-based Image and Video Retrieval, P417, DOI DOI 10.1145/1386352.1386406
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   PALLA G., 2007, ARXIV07040744
   REGE M., 2008, P 17 INT WORLD WID W
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   SHAMMA D., 2007, P INT WORKSH MULT IN
   Shenghuo Zhu, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P487
   SIGURBJORNSSON B, 2008, P 17 INT WORLD WID W
   STAR SL, 1989, SOC STUD SCI, V19, P387, DOI 10.1177/030631289019003001
   Sun JM, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P687
   SUNDARAM H, 2009, P INT C WEBL SOC MED
   SUNDARAM H, 2008, P INT WORLD WID WEB
   SUNDARAM H., 2009, P IEEE INT C MULT EX
   Tang Lei, 2010, Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD'08), P677, DOI 10.1145/1401890.1401972
   Wang X., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P236, DOI 10.1145/1148170.1148214
   Xiao ZT, 2005, PATTERN RECOGN LETT, V26, P1985, DOI 10.1016/j.patrec.2005.02.003
   Xie LX, 2002, INT CONF ACOUST SPEE, P4096
   ZUNJARWARD A., 2007, P ACM MULT
NR 43
TC 9
Z9 9
U1 1
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2012
VL 8
IS 1
AR 4
DI 10.1145/2071396.2071400
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 894AV
UT WOS:000300400200004
DA 2024-07-18
ER

PT J
AU Bagchi, S
AF Bagchi, Susmit
TI A Fuzzy Algorithm for Dynamically Adaptive Multimedia Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Performance; Fuzzy logic; VoD; QoS; multimedia streaming;
   buffering; data prefetch; multithread
AB The QoS-aware delivery model of multimedia is an interesting research area. The wireless networking systems connecting mobile clients and media servers have created the paradigm of mobile multimedia. In mobile multimedia systems, the media delivery model has to maintain two diagonally opposite objectives, such as maintaining QoS of playback and saving energy consumption of the mobile devices. The traditional pull, push, and the hybrid push-pull models of media delivery are not completely suitable to offer consistent QoS of playback while saving the energy consumptions at mobile devices. This article proposes a novel multimedia delivery system based on the Fuzzy Adaptive Buffering (FAB) algorithm using pull model. The FAB algorithm employs a fuzzy inference technique and dynamically adapts to the execution environments. The experimental results illustrate that the FAB algorithm successfully adapts to dynamic execution contexts while maintaining playback-QoS and saving the energy consumption of the mobile clients by keeping the data prefetching thread in the sleeping mode from 31.44% to 97.4% of streaming time depending on the execution environments.
C1 Samsung Elect Ltd SISO, CVR Nagar, Bangalore, Karnataka, India.
RP Bagchi, S (corresponding author), Samsung Elect Ltd SISO, CVR Nagar, Bangalore, Karnataka, India.
EM susmitbagchi@yahoo.co.uk
OI Bagchi, Susmit/0000-0003-2667-1446
CR ACHARYA S, 1995, P ACM SIGMOD DAT COM
   Adams J., 2007, P IEEE INT C COMM IC
   ANASTASI G, 2005, J PERVAS COMPUT COMM, V1, P1
   ARSAN T, 2008, INT J COMPUT SCI ENG, V2, P2
   BOSE S, 2007, J COMPUT INF TECHNOL, V15, P3
   CHANDRA S, 2002, P GEN TRACK ANN USEN
   CHEN CS, 2003, P 23 INT C DISTR COM
   FENG W, 1997, P ANN JOINT C IEEE C
   HOONG KP, 2008, J APPL SCI, V8, P4
   KORHONEN J, 2005, P 15 INT WORKSH NETW
   KWON JB, 2003, LECT NOTES COMPUTER, V2790
   Lee JYB, 2000, IEEE T PARALL DISTR, V11, P1217, DOI 10.1109/71.895790
   MOGHAL RM, 2003, P IEEE INT MULT C IN
   REDDY A, 1995, P 2 IEEE INT C MULT
   SHOJANIA H, 2001, P 9 ACM MULT C ACM M, P492
   TEWARI R, 1995, 20020 RC IBM
   WU X, 2005, IEEE T MOBILE COMPUT, V4, P4
   WU YS, 2009, IEEE T MOBILE COMPUT, V8, P2
NR 18
TC 13
Z9 13
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2011
VL 7
IS 2
AR 11
DI 10.1145/1925101.1925106
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 729AT
UT WOS:000287919200005
DA 2024-07-18
ER

PT J
AU Cheng, W
   Ooi, WT
   Mondet, S
   Grigoras, R
   Morin, G
AF Cheng, Wei
   Ooi, Wei Tsang
   Mondet, Sebastien
   Grigoras, Romulus
   Morin, Geraldine
TI Modeling Progressive Mesh Streaming: Does Data Dependency Matter?
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Performance; Design; 3D data; streaming; progressive meshes;
   packetization
ID ERROR; TRANSMISSION
AB 3D triangular meshes are becoming an increasingly prevalent data type in networked applications such as digital museums, online games, and virtual worlds. In these applications, a 3D mesh is typically coded progressively, yielding a multiresolution representation suitable for streaming. While such progressive coding allows incremental rendering for users while data is being transmitted, it introduces dependencies between data, causing delay in rendering when packets are lost. This article quantitatively analyzes the effects of such dependency by modeling the distribution of decoding time as a function of mesh properties and network parameters. We apply our model to study two extreme cases of dependency in progressive meshes and show that the effect of dependencies on decoded mesh quality diminishes with time. Our model provides the expected decoded mesh quality at the receiver at a given time. Based on this expected value, we propose a packetization strategy that improves the decoded mesh quality during the initial stage of streaming. We validate the accuracy of our model under a variety of network conditions, including bursty losses, fluctuating RTT, and varying sending rate. The values predicted from our model match the measured value reasonably well in all cases except when losses are too bursty.
C1 [Cheng, Wei; Ooi, Wei Tsang] Natl Univ Singapore, Singapore 119077, Singapore.
   [Mondet, Sebastien; Grigoras, Romulus; Morin, Geraldine] Univ Toulouse, IRIT, F-31000 Toulouse, France.
C3 National University of Singapore; Universite de Toulouse; Universite
   Toulouse III - Paul Sabatier; Universite Federale Toulouse Midi-Pyrenees
   (ComUE); Institut National Polytechnique de Toulouse
RP Cheng, W (corresponding author), Natl Univ Singapore, 21 Lower Kent Ridge Rd, Singapore 119077, Singapore.
EM rivercheng@gmail.com
RI Ooi, Wei Tsang/HLW-5142-2023; Ooi, Wei Tsang/AAE-7810-2019
OI Ooi, Wei Tsang/0000-0001-8994-1736; Ooi, Wei Tsang/0000-0001-8994-1736
FU National University of Singapore [R-252-000-306-112]; French National
   Research Agency [ANR 05-MMSA-0004-01]
FX This project is supported by National University of Singapore Academic
   Research Fund R-252-000-306-112 and by the French National Research
   Agency project: NatSim (ANR 05-MMSA-0004-01).
CR Al-Regib G, 2002, IEEE INFOCOM SER, P743, DOI 10.1109/INFCOM.2002.1019320
   Alliez P, 2001, COMP GRAPH, P195, DOI 10.1145/383259.383281
   Alregib G, 2005, IEEE T MULTIMEDIA, V7, P1149, DOI 10.1109/TMM.2005.858404
   [Anonymous], 2003, Level of detail for 3D graphics
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   BOYCE JM, 1998, ACM MULTIMEDIA, P181
   CHEN BY, 2002, P 7 INT C 3D WEB TEC, P35
   Chen ZH, 2005, MULTIMEDIA SYST, V10, P230, DOI 10.1007/s00530-004-0154-3
   CHENG W, 2008, P INT WORKSH NETW OP
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cohen-Or D., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P67
   DEROOS H, 2004, COMPUT INF SCI, V9, P2
   GU Y, 2005, P INT C COMP COMM NE
   Guo YH, 2007, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON HEALTH MONITORING OF STRUCTURE, MATERIALS AND ENVIRONMENT, VOLS 1 AND 2, P738
   Harris A F., 2002, Proc. NOSSDAV, P43
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Hoppe H., 1997, P SIGGRAPH 97, P189, DOI DOI 10.1145/258734.258843
   KOHLER E, 2006, P ACM SIGCOMM DAT CO
   Koller D, 2004, ACM T GRAPHIC, V23, P695, DOI 10.1145/1015706.1015782
   Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849
   Miyazaki D, 2006, LECT NOTES COMPUT SC, V4270, P399
   MONDET S, 2008, P ACM MULT C
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Park SB, 2006, IEEE T MULTIMEDIA, V8, P885, DOI 10.1109/TMM.2006.879914
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Yan ZD, 2001, IEEE T CIRC SYST VID, V11, P860, DOI 10.1109/76.931112
NR 26
TC 5
Z9 6
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2011
VL 7
IS 2
AR 10
DI 10.1145/1925101.1925105
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 729AT
UT WOS:000287919200004
DA 2024-07-18
ER

PT J
AU Chen, YP
   Xu, WW
   Sundaram, H
   Rikakis, T
   Liu, SM
AF Chen, Yinpeng
   Xu, Weiwei
   Sundaram, Hari
   Rikakis, Thanassis
   Liu, Sheng-Min
TI A Dynamic Decision Network Framework for Online Media Adaptation in
   Stroke Rehabilitation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT ACM Multimedia Conference 2007
CY SEP 24-29, 2007
CL Augsburg, GERMANY
SP ACM
DE Algorithms; Experimentation; Human Factors; Biofeedback; media
   adaptation; dynamic decision network; mixture of experts
AB In this article, we present a media adaptation framework for an immersive biofeedback system for stroke patient rehabilitation. In our biofeedback system, media adaptation refers to changes in audio/visual feedback as well as changes in physical environment. Effective media adaptation frameworks help patients recover generative plans for arm movement with potential for significantly shortened therapeutic time. The media adaptation problem has significant challenges-(a) high dimensionality of adaptation parameter space; (b) variability in the patient performance across and within sessions; (c) the actual rehabilitation plan is typically a non-first-order Markov process, making the learning task hard.
   Our key insight is to understand media adaptation as a real-time feedback control problem. We use a mixture-of-experts based Dynamic Decision Network (DDN) for online media adaptation. We train DDN mixtures per patient, per session. The mixture models address two basic questions-(a) given a specific adaptation suggested by the domain experts, predict the patient performance, and (b) given the expected performance, determine the optimal adaptation decision. The questions are answered through an optimality criterion based search on DDN models trained in previous sessions. We have also developed new validation metrics and have very good results for both questions on actual stroke rehabilitation data.
C1 [Chen, Yinpeng; Xu, Weiwei; Sundaram, Hari; Rikakis, Thanassis; Liu, Sheng-Min] Arizona State Univ, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Chen, YP (corresponding author), Arizona State Univ, Tempe, AZ 85287 USA.
EM Hari.Sundaram@asu.edu
OI Sundaram, Hari/0000-0003-3315-6055
CR Abowd G. D., 2002, IEEE Pervasive Computing, V1, P48, DOI 10.1109/MPRV.2002.993144
   [Anonymous], P NAT C ART INT
   [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   BARRAQUAND J, 1991, INT J ROBOT RES, V10, P628, DOI 10.1177/027836499101000604
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   BROOKS RA, 1997, P 2 INT COGN TECHN C
   Brooks RA., 1991, P 12 INT JOINT C ART, P569
   BUI H, 2003, P INT JOINT C ART IN
   Burridge RR, 1999, INT J ROBOT RES, V18, P534, DOI 10.1177/02783649922066385
   CHEN Y, 2006, SIG ACM MULTIMEDIA
   CHEN Y, 2007, SIG ACM MULTIMEDIA
   Darwiche A, 2001, INT J APPROX REASON, V26, P161, DOI 10.1016/S0888-613X(00)00067-0
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dourish P., 2001, ACTION IS FDN EMBODI
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fox M, 2006, ARTIF INTELL, V170, P59, DOI 10.1016/j.artint.2005.05.007
   Gallichio J., 2004, PHYS THER REV, V9, P207
   Grout DonaldJay., 2001, A History of Western Music
   Grupen RA, 2002, ADV ROBOTICS, V16, P427, DOI 10.1163/15685530260182927
   HE X, 2003, IEEE T CIRC SYST VID
   Holden M., 1999, NEUROLOGY REPORT, V23, P57
   HOLDEN M.K., 2002, NEUROL REPORT, V26, P62
   Hollan J., 2000, ACM Transactions on Computer-Human Interaction, V7, P174, DOI 10.1145/353485.353487
   HSIAO K, 2007, P IEEE C ROB AUT
   Huber Peter J, 2011, ROBUST STAT, P1248
   Hutchins E., 1995, Cognition in the Wild
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Ishii H., 1998, P CHI 98 C SUMMARY H, P173, DOI DOI 10.1145/286498.286652
   Jack D, 2001, IEEE T NEUR SYS REH, V9, P308, DOI 10.1109/7333.948460
   Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X
   KIRSH D, 1995, ARTIF INTELL, V73, P31, DOI 10.1016/0004-3702(94)00017-U
   KJAERULFF U, 1995, INT J FORECASTING, V11, P89, DOI 10.1016/0169-2070(94)02003-8
   LAVALLE S.M., 2006, Planning algorithms, DOI DOI 10.1017/CBO9780511546877
   Mazalek Ali., 2002, P 10 ACM INT C MULTI, P153
   Merians AS, 2002, PHYS THER, V82, P898, DOI 10.1093/ptj/82.9.898
   MURPHY K, 2003, P NIPS 03 NEUR INF P
   Murphy K. P., 2002, Ph.D. Thesis,
   Pineau J., 2003, P 18 INT JOINT C ART
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Russell S., 2016, Artificial intelligence a modern approach
   SIMMONS R, 1995, INT JOINT C ART INT
   SMITH T, 2004, P 20 C UNC ART INT
   Spaan MTJ, 2005, J ARTIF INTELL RES, V24, P195, DOI 10.1613/jair.1659
   SUN Y, 2002, P 10 ACM INT C MULT, P81, DOI DOI 10.1145/641007.641022
   Sundaram H., 2000, Proceedings ACM Multimedia 2000, P95, DOI 10.1145/354384.354440
   Sundaram H., 2006, Encyclopedia of Multimedia
   Theocharous G, 2004, ADV NEUR IN, V16, P775
   THEOCHAROUS G, 2004, P INT C ROB AUT
   Ullmer B, 2000, IBM SYST J, V39, P915, DOI 10.1147/sj.393.0915
   WEISER M, 1993, COMMUN ACM, V36, P75, DOI 10.1145/159544.159617
   WHITE D, 2005, P IEEE INT C MECH AU
   XIE L, 2003, P IEEE C MULT EXP 20
   XU W, 2006, P 3 WORKSH CAPT ARCH
NR 53
TC 15
Z9 18
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2008
VL 5
IS 1
AR 4
DI 10.1145/1404880.1404884
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 376AS
UT WOS:000261155700004
DA 2024-07-18
ER

PT J
AU He, XF
   Cai, D
   Wen, JR
   Ma, WY
   Zhang, HJ
AF He, Xiaofei
   Cai, Deng
   Wen, Ji-Rong
   Ma, Wei-Ying
   Zhang, Hong-Jiang
TI Clustering and searching WWW images using link and page layout analysis
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE algorithms; management; performance; experimentation; web mining; image
   search; image clustering; link analysis
AB Due to the rapid growth of the number of digital images on the Web, there is an increasing demand for an effective and efficient method for organizing and retrieving the available images. This article describes iFind, a system for clustering and searching WWW images. By using a vision-based page segmentation algorithm, a Web page is partitioned into blocks, and the textual and link information of an image can be accurately extracted from the block containing that image. The textual information is used for image indexing. By extracting the page-to-block, block-to-image, block-to-page relationships through link structure and page layout analysis, we construct an image graph. Our method is less sensitive to noisy links than previous methods like PageRank, HITS, and PicASHOW, and hence the image graph can better reflect the semantic relationship between images. Using the notion of Markov Chain, we can compute the limiting probability distributions of the images, ImageRanks, which characterize the importance of the images. The ImageRanks are combined with the relevance scores to produce the final ranking for image search. With the graph models, we can also use techniques from spectral graph theory for image clustering and embedding, or 2-D visualization. Some experimental results on 11.6 million images downloaded from the Web are provided in the article.
C1 Yahoo Res Labs, Burbank, CA 91504 USA.
   Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
   Microsoft Res Asia, Beijing, Peoples R China.
C3 Yahoo! Inc; Yahoo! Inc United States; University of Illinois System;
   University of Illinois Urbana-Champaign; Microsoft Research Asia;
   Microsoft
RP He, XF (corresponding author), Yahoo Res Labs, 3333 Empire Ave, Burbank, CA 91504 USA.
EM hex@yahoo-inc.com; dengcai2@cs.uiuc.edu; jrwen@microsoft.com;
   wyma@microsoft.com; hjzhang@microsoft.com
CR [Anonymous], 2001, ADV NEURAL INFORM PR
   [Anonymous], 2001, P ADV NEURAL INFORM
   BREW C, 2002, P C EMP METH NAT LAN
   BRIN S, 1998, P 7 ACM C WORLD WID
   CAI D, 2004, P ACM SIGIR C INF RE
   CAI D, 2004, IEEE INT C MULT EXP
   CAI D, 2003, MSRTR200379 MICR
   CAI D, 2004, P ACM SIGIR C INFO R
   CAI D, 2003, P 5 AS PAC WEB C
   Chang, 1997, IEEE MULTIMEDIA
   Chung F. R. K., 1997, AM MATH SOC, V92, DOI DOI 10.1090/CBMS/092
   FRANKEL C, 1996, TR9614 U CHIC DEP CO
   *GOOGLE, GOOGL ZEITG SEARCH P
   Guattery S, 2000, SIAM J MATRIX ANAL A, V21, P703, DOI 10.1137/S0895479897329825
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Lempel R., 2001, P 10 INT C WORLD WID, P438
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Ma WY, 1996, PROC CVPR IEEE, P425, DOI 10.1109/CVPR.1996.517107
   Mohar B., 1997, GRAPH SYMMETRY ALGEB
   ROBERTSON SE, 1999, 8 TEXT RETR C TREC 8, P151
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   SCLAROFF S, 1994, IEEE WORKSH CONT BAS
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SMITH JR, 1996, P ACM C MULT NEW YOR
   SONG R, 2004, P 13 ACM C WORLD WID
   WEN JR, 2003, 12 TEXT RETR C TREC
NR 27
TC 29
Z9 32
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2007
VL 3
IS 2
AR 10
DI 10.1145/1230812.1230816
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 230JA
UT WOS:000250871600004
DA 2024-07-18
ER

PT J
AU Ott, DE
   Mayer-Patel, K
AF Ott, David E.
   Mayer-Patel, Ketan
TI An open architecture for transport-level protocol coordination in
   distributed multimedia applications
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE design; algorithms; performance; experimentation; network protocols;
   distributed applications; flow coordination
ID SERVICE
AB We consider the problem of flow coordination in distributed multimedia applications. Most transport-level protocols are designed to operate independently and lack mechanisms for sharing information with other flows and coordinating data transport in various ways. This limitation becomes problematic in distributed applications that employ numerous flows between two computing clusters sharing the same intermediary forwarding path across the Internet. In this article, we propose an open architecture that supports the sharing of network state information, peer flow information, and application-specific information. Called simply the coordination protocol (CP), the scheme facilitates coordination of network resource usage across flows belonging to the same application, as well as aiding other types of coordination. The effectiveness of our approach is illustrated in the context of multistreaming in 3D tele-immersion where consistency of network information across flows both greatly improves frame transport synchrony and minimizes buffering delay.
C1 Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Ott, DE (corresponding author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.
EM kmp@cs.unc.edu
CR Alexander D.S., 1997, Proc. of ACM SIGCOMM'97, P101, DOI DOI 10.1145/263105.263149
   [Anonymous], 2003, 3448 RFC
   BALAKRISHNAN H, 1999, P ACM SIGCOMM DAT CO
   BLACK D, 1998, INTERNET RFC
   CALVERT KL, 2002, P ACM SIGCOMM DAT CO
   CHRISTIANSEN M, 2000, P ACM SIGCOMM DAT CO
   DECASPER D, 1998, P ACM SIGCOMM C SIGC, P229
   ESCOBAR J, 1994, IEEE ACM T NETWORK, V2, P111, DOI 10.1109/90.298430
   FLOYD S, 1995, IEEE ACM T NETWORK, V3, P365, DOI 10.1109/90.413212
   Floyd S, 2000, ACM SIGCOMM COMP COM, V30, P43, DOI 10.1145/347057.347397
   Floyd S, 1999, IEEE ACM T NETWORK, V7, P458, DOI 10.1109/90.793002
   Georgiadis L, 1996, IEEE ACM T NETWORK, V4, P482, DOI 10.1109/90.532860
   GRUDIN J, 1994, COMPUTER, V27, P19, DOI 10.1109/2.291294
   KUM SU, 2003, ACM MULT C
   KUNG H, 1999, P 7 ANN INT C NETW P
   LE L, 2003, P ACM SIGCOMM DAT CO
   OTT D, 2002, P USENIX TECHN C
   OTT D, 2004, ACM MULT C
   OTT D, 2004, P ANN JOINT C IEEE C
   OTT D, 2001, P INT DISTR MULT SYS
   PADHYE J, 1998, P ACM SIGCOMM DAT CO
   PARRIS M, 1999, P SPIE C MULT COMP N
   Rizzo Luigi, 1997, ACM COMPUTER COMMUNI, V27
   ROTHERMEL K, 1995, P 5 INT WORKSH NETW, P178
   TENNEHOUSE DL, 1996, MULT COMP NETW C
   van der Merwe JE, 1998, IEEE J SEL AREA COMM, V16, P424, DOI 10.1109/49.669051
   van der Merwe JE, 1998, IEEE NETWORK, V12, P20, DOI 10.1109/65.690958
   WEISER M, 1993, COMMUN ACM, V36, P75, DOI 10.1145/159544.159617
   Wetherall D, 1999, OPERATING SYSTEMS REVIEW, VOL 33, NO 5, DECEMBER 1999, P64, DOI 10.1145/319344.319156
   YAVATKAR R, 1992, P IEEE ICDCS, V12, P606
   YU TP, 2001, P SPIE C MULT COMP N
   ZHANG H, 1995, P IEEE, V83, P1374, DOI 10.1109/5.469298
NR 32
TC 3
Z9 3
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2007
VL 3
IS 3
AR 17
DI 10.1145/1236471.1236476
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 230JB
UT WOS:000250871700005
DA 2024-07-18
ER

PT J
AU Gulliver, SR
   Ghinea, G
AF Gulliver, Stephen R.
   Ghinea, Gheorghita
TI Defining user perception of distributed multimedia quality
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE design; experimentation; human factors; human-computer interaction;
   multimedia quality; quality of perception
AB This article presents the results of a study that explored the human side of the multimedia experience. We propose a model that assesses quality variation from three distinct levels: the network, the media and the content levels; and from two views: the technical and the user perspective. By facilitating parameter variation at each of the quality levels and from each of the perspectives, we were able to examine their impact on user quality perception. Results show that a significant reduction in frame rate does not proportionally reduce the user's understanding of the presentation independent of technical parameters, that multimedia content type significantly impacts user information assimilation, user level of enjoyment, and user perception of quality, and that the device display type impacts user information assimilation and user perception of quality. Finally, to ensure the transfer of information, low-level abstraction (network-level) parameters, such as delay and jitter, should be adapted; to maintain the user's level of enjoyment, high-level abstraction quality parameters (content-level), such as the appropriate use of display screens, should be adapted.
C1 Brunel Univ, Sch Informat Syst, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Gulliver, SR (corresponding author), Brunel Univ, Sch Informat Syst, Uxbridge UB8 3PH, Middx, England.
EM stephen.gulliver@brunel.ac.uk; george.ghineal@brunel.ac.uk
RI Ghinea, Gheorghita/AAG-6770-2020; Gulliver, Stephen/AAE-9133-2021
OI Ghinea, Gheorghita/0000-0003-2578-5580; Gulliver,
   Stephen/0000-0002-4503-5448
CR *ACM T MULT COMP, 2006, COMM APPL, V2
   [Anonymous], P INT ACM SIGGROUP C
   [Anonymous], IMPROVING USER COMPR
   APTEKER RT, 1995, IEEE MULTIMEDIA, V2, P32, DOI 10.1109/93.410510
   ARDITO M, 1994, P INT WORKSH HDTV 94
   Barnett B, 1996, J ELECTRON IMAGING, V5, P129, DOI 10.1117/12.238676
   Bouch A, 2001, LONDON COMMUNICATIONS SYMPOSIUM 2001, PROCEEDINGS, P47
   CLAYPOOL M, 1999, ACM MULTIMEDIA 99, P115
   de Groot A.D., 1966, PROBLEM SOLVING RES
   Georganas ND, 1996, IEEE J SEL AREA COMM, V14, P1, DOI 10.1109/JSAC.1996.481690
   Ghinea G., 1998, Proceedings ACM Multimedia 98, P49, DOI 10.1145/290747.290754
   GHINEA G, 2000, P IEEE INT C MULT EX, V2, P847
   Gulliver S.R., 2003, Universal Access Information Society, V2, P374, DOI DOI 10.1007/S10209-003-0067-5
   Gulliver SR, 2004, IEEE T SYST MAN CY A, V34, P472, DOI 10.1109/TSMCA.2004.826309
   GULLIVER SR, 2003, UNIVERSAL ACCESS INF, V4, P374
   Hollier MP, 1997, BT TECHNOL J, V15, P162
   HOLLIER MP, 1995, BT TECHNOL J, V4, P162
   KAWALEK JA, 1995, P QOS WORKSH 3 INT C
   Kies JK, 1997, COMPUT EDUC, V28, P79, DOI 10.1016/S0360-1315(97)00004-3
   Koodli R, 1998, INTERNATIONAL SOCIETY FOR COMPUTERS AND THEIR APPLICATIONS 13TH INTERNATIONAL CONFERENCE ON COMPUTERS AND THEIR APPLICATIONS, P234
   Lambrecht CJV, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P885, DOI 10.1109/ICIP.1996.559641
   LAMBRECHT CJV, 1996, P EUSIPCO TRIEST IT, P1175
   Lindh P, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P331, DOI 10.1109/ICIP.1996.560498
   MACKWORTH NH, 1967, PERCEPT PSYCHOPHYS, V2, P547, DOI 10.3758/BF03210264
   Masry M, 2001, PROC SPIE, V4299, P102, DOI 10.1117/12.429539
   NAHRSTEDT K, 1995, COMPUTER, V28, P52, DOI 10.1109/2.384118
   QUAGLIA D, 2002, P IEEE INT C MULT EX, V2, P85
   RIMMELL AM, 1999, IEEE SIGN PROC SOC 1, P509
   TEO PC, 1994, IST SPIE S EL IM SCI, V2179, P127
   VERSCHEURE O, 1996, WORKSH MULT TEL APPL
   Wang YB, 2001, IMW 2001: PROCEEDINGS OF THE FIRST ACM SIGCOMM INTERNET MEASUREMENT WORKSHOP, P295
   Watson A., 2000, Proceedings ACM Multimedia 2000, P269, DOI 10.1145/354384.354503
   WATSON A, 1997, P AVSPN 97 INT WORKS, P189
   Watson AB, 1998, P SOC PHOTO-OPT INS, V3299, P139, DOI 10.1117/12.320105
   Wijesekera D, 1999, MULTIMEDIA SYST, V7, P486, DOI 10.1007/s005300050149
   Wijesekera D, 1996, MULTIMED TOOLS APPL, V3, P127, DOI 10.1007/BF00429748
   WIKSTRAND G, 2002, P 2 NORD C HUM COMP, P255
   Wilson G. M., 2000, Affective Interactions. Towards a New Generation of Computer Interfaces (Lecture Notes in Artificial Intelligence Vol.1814), P9
   Wilson GM, 2000, BCS CONFERENCE S, P327
   Winkler S, 2001, PROC SPIE, V4299, P114, DOI 10.1117/12.429540
   Yarbus A.L., 1967, EYE MOVEMENT VISION
NR 41
TC 55
Z9 58
U1 0
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2006
VL 2
IS 4
BP 241
EP 257
DI 10.1145/1201730.1201731
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 230IY
UT WOS:000250871400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, G
   Sun, T
   Gerla, M
   Sanadidi, MY
   Chen, LJ
AF Yang, Guang
   Sun, Tony
   Gerla, Mario
   Sanadidi, M. Y.
   Chen, Ling-Jyh
TI Smooth and efficient real-time video transport in the presence of
   wireless errors
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE design; performance; measurement; video transport protocol; TCP friendly
   rate control; real-time video; wireless networks
ID CONGESTION
AB In this article we study a smooth and efficient transport protocol for real-time video over wireless networks. The proposed scheme, named the video transport protocol (VTP), has a new and unique end-to-end rate control mechanism that aims to avoid drastic rate fluctuations while maintaining friendliness to legacy protocols. VTP is also equipped with an achieved rate estimation scheme and a loss discrimination algorithm, both end-to-end, to cope with random errors in wireless networks efficiently. We show by analysis that VTP preserves most of the convergence properties of AIMD and converges to its fair share fast. VTP is compared to two recent TCP friendly rate control (TFRC) extensions, namely TFRC Wireless and MULTFRC, in wired-cum-wireless scenarios in Ns-2. Results show that VTP excels in all tested scenarios in terms of smoothness, fairness, and opportunistic friendliness. VTP is also implemented to work with a video camera and an H.263 video codec as part of our hybrid testbed, where its good performance as a transport layer protocol is confirmed by measurement results.
C1 Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.
   Acad Sinica, Inst Informat Sci, Taipei 11529, Taiwan.
C3 University of California System; University of California Los Angeles;
   Academia Sinica - Taiwan
RP Yang, G (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.
EM yangg@cs.ucla.edu; tonysun@cs.ucla.edu; gerla@cs.ucla.edu;
   medy@cs.ucla.edu; cclljj@iis.sinica.edu.tw
RI Chen, Ling-Jyh/A-6311-2009
OI Chen, Ling-Jyh/0000-0001-5667-7764
CR Allman M., 1999, IETF RFC 2581
   [Anonymous], 2000, 2914 RFC
   [Anonymous], 2000, 2960 RFC
   [Anonymous], 2003, 3448 RFC
   BANSAL D, 2001, P IEEE INF C IEEE AN
   BIAZ S, 1999, P IEEE S APPL SPEC S
   Cen S, 2003, IEEE ACM T NETWORK, V11, P703, DOI 10.1109/TNET.2003.818187
   CEN S, 1998, P SPIE MMCN C
   CHEN M, 2004, P IEEE INF C
   CHIU DM, 1989, COMPUT NETWORKS ISDN, V17, P1, DOI 10.1016/0169-7552(89)90019-6
   FEAMSTER N, 2001, P INT PACK VID WORKS
   Gerla M, 2004, COMPUT COMMUN, V27, P41, DOI 10.1016/S0140-3664(03)00114-2
   Hsu CY, 1999, IEEE J SEL AREA COMM, V17, P756, DOI 10.1109/49.768193
   KAZANTZIDIS M, 2002, THESIS U CALIFORNIA
   KOHLER E, 2004, IN PRESS DATAGRAM CO
   Kurose J.F., 2004, COMPUTER NETWORKING, V3rd
   Loguinov D, 2003, IEEE ACM T NETWORK, V11, P564, DOI 10.1109/TNET.2003.815291
   MEHRA P, 2003, P INT PACK VID WORKS
   *NS2, NETW SIM
   REJAIE R, 1999, P IEEE INF C
   REJAIE R, 1999, P ACM SIGCOMM C
   Schulzrinne H., 2003, RFC 3550, DOI 10.17487/RFC3550
   SUN M, 2001, COMPRESSED VIDEO OVE
   TANG J, 2001, P IEEE INF C
   TOBE Y, 2000, P IEEE LCN C
   WIDMER J, 2003, TCP FRIENDLY MULTICA
   Yang F, 2004, IEEE J SEL AREA COMM, V22, P777, DOI 10.1109/JSAC.2004.826008
   YANG G, 2004, P IPIF IEEE MMNS C
   YANG G, 2005, P IEEE ISCC C
   YANG Y, 2001, P IEEE INF C
   ZHANG Y, 2004, P ACM NOSSDAV C
NR 31
TC 9
Z9 14
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2006
VL 2
IS 2
BP 109
EP 126
DI 10.1145/1142020.1142022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 230IX
UT WOS:000250871300002
DA 2024-07-18
ER

PT J
AU Tu, YC
   Sun, JZ
   Hefeeda, M
   Prabhakar, S
AF Tu, Yi-Cheng
   Sun, Jianzhong
   Hefeeda, Mohamed
   Prabhakar, Sunil
TI An Analytical Study of Peer-to-Peer Media Streaming Systems
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Performance; Media streaming; peer-to-peer; media-on-demand
AB Recent research efforts have demonstrated the great potential of building cost-effective media streaming systems on top of peer-to-peer (P2P) networks. A P2P media streaming architecture can reach a large streaming capacity that is difficult to achieve in conventional server-based streaming services. Hybrid streaming systems that combine the use of dedicated streaming servers and P2P networks were proposed to build on the advantages of both paradigms. However, the dynamics of such systems and the impact of various factors on system behavior are not totally clear. In this article, we present an analytical framework to quantitatively study the features of a hybrid media streaming model. Based on this framework, we derive an equation to describe the capacity growth of a single-file streaming system. We then extend the analysis to multi-file scenarios. We also show how the system achieves optimal allocation of server bandwidth among different media objects. The unpredictable departure/failure of peers is a critical factor that affects the performance of P2P systems. We utilize the concept of peer lifespan to model peer failures. The original capacity growth equation is enhanced with coefficients generated from peer lifespans that follow an exponential distribution. We also propose a failure model under arbitrarily distributed peer lifespan. Results from large-scale simulations support our analysis.
C1 [Tu, Yi-Cheng; Prabhakar, Sunil] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
   [Sun, Jianzhong] Univ N Carolina, Dept Math, Wilmington, NC 28403 USA.
   [Hefeeda, Mohamed] Simon Fraser Univ, Sch Comp Sci, Surrey, BC V3T 2W1, Canada.
C3 Purdue University System; Purdue University; University of North
   Carolina; University of North Carolina Wilmington; Simon Fraser
   University
RP Tu, YC (corresponding author), Purdue Univ, Dept Comp Sci, 250 N Univ St, W Lafayette, IN 47907 USA.
EM tuyc@cs.purdue.edu; lsjason@gmail.com; mhefeeda@cs.sfu.ca;
   sunil@cs.purdue.edu
FU NSF [IIS-9985019]
FX This work is supported by NSF fund IIS-9985019.
CR [Anonymous], 2013, Wiley Series in Discrete Mathematics and Optimization
   [Anonymous], P INT WORKSH WEB CON
   [Anonymous], P 3 ACM C EL COMM
   [Anonymous], P SIGCOMM 01, DOI DOI 10.1145/383059.383071
   Antony I., 2001, LECT NOTES COMPUTER, P329, DOI DOI 10.1007/3-540-45518-3_18
   Bhagwan R., 2003, P 2 INT WORKSH PEER
   Biliris A, 2002, COMPUT COMMUN, V25, P393, DOI 10.1016/S0140-3664(01)00411-X
   Burden R.L., 2010, Numerical Analysis
   COOPER R. B., 1981, Introduction to Queueing Theory
   Crowcroft J., 2002, NETWORKING 2002. Networking Technologies, Services, and Protocols; Performance of Computer and Communication Networks; Mobile and Wireless Communications. Second International IFIP-TC6 Networking Conference. Proceedings (Lecture Notes in Computer Science Vol.2345), P1
   DABEK F, 2001, P 18 ACM S OP SYST P, P202
   Feldmann A, 1997, IEEE INFOCOM SER, P1096, DOI 10.1109/INFCOM.1997.631130
   Francis P, 2001, IEEE ACM T NETWORK, V9, P525, DOI 10.1109/90.958323
   Golle P., 2001, Proceedings of the 3rd ACM Conference on Electronic Commerce. EC'01, P264, DOI DOI 10.1145/501158.501193
   Hefeeda M., 2003, Proceedings of the eleventh ACM international conference on Multimedia, ser. MULTIMEDIA '03, P45, DOI [DOI 10.1145/957013.957022, 10.1145/957013.957022]
   Hefeeda MM, 2004, COMPUT NETW, V44, P353, DOI 10.1016/j.comnet.2003.10.002
   Milojicic Dejan S., 2002, Technical Report
   Nguyen TP, 2002, PROC SPIE, V4673, P186
   Padmanabhan V.N., 2002, P 12 INT WORKSHOP NE, P177
   Qiu D., 2004, Computer Communication Review, V34, P367, DOI 10.1145/1030194.1015508
   Ramachandran K.K., 2005, P IEEE INFOCOM
   Ratnasamy S., 2001, Proceedings of the 2001 conference on applications, technologies, architectures, and protocols for computer communications, P161
   Ripeanu M, 2002, IEEE INTERNET COMPUT, V6, P50, DOI 10.1109/4236.978369
   ROWSTRON A, 2001, P 18 ACM S OP SYST P, P188
   Saroiu S, 2003, MULTIMEDIA SYST, V9, P170, DOI 10.1007/s00530-003-0088-1
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   Tu YC, 2004, PROC SPIE, V5305, P69
   TU YC, 2005, CSDTR05011 PURD U
   WU D, 2001, IEEE T CIRCUITS SYST, V11, P1
   XU D, 2003, P SPIE ACM MMCN
   Xu DY, 2002, INT CON DISTR COMP S, P363, DOI 10.1109/ICDCS.2002.1022274
   Yang XY, 2004, IEEE INFOCOM SER, P2242
NR 32
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2005
VL 1
IS 4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA V74DX
UT WOS:000205012500003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, CC
   Ma, WB
   Xiao, J
   Zhang, HW
   Shao, J
   Zhuang, YT
   Chen, L
AF Zhang, Chenchi
   Ma, Wenbo
   Xiao, Jun
   Zhang, Hanwang
   Shao, Jian
   Zhuang, Yueting
   Chen, Long
TI VL-NMS: Breaking Proposal Bottlenecks in Two-stage Visual-language
   Matching
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Text-guided region proposal generation; visual grounding; image-text
   matching; non-maximum suppression
AB The prevailing framework for matching multimodal inputs is based on a two-stage process: (1) detecting proposals with an object detector and (2) matching text queries with proposals. Existing two-stage solutions mostly focus on the matching step. In this article, we argue that these methods overlook an obvious mismatch between the roles of proposals in the two stages: they generate proposals solely based on the detection confidence (i.e., query-agnostic), hoping that the proposals contain all instances mentioned in the text query (i.e., query-aware). Due to this mismatch, chances are that proposals relevant to the text query are suppressed during the filtering process, which in turn bounds the matching performance. To this end, we propose VL-NMS, which is the first method to yield query-aware proposals at the first stage. VL-NMS regards all mentioned instances as critical objects and introduces a lightweight module to predict a score for aligning each proposal with a critical object. These scores can guide the NMS operation to filter out proposals irrelevant to the text query, increasing the recall of critical objects, and resulting in a significantly improved matching performance. Since VL-NMS is agnostic to the matching step, it can be easily integrated into any state-of-the-art two-stage matching method. We validate the effectiveness of VL-NMS on three multimodal matching tasks, namely referring expression grounding, phrase grounding, and image-text matching. Extensive ablation studies on several baselines and benchmarks consistently demonstrate the superiority of VL-NMS.
C1 [Zhang, Chenchi; Ma, Wenbo; Xiao, Jun; Shao, Jian; Zhuang, Yueting] Zhejiang Univ, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zhang, Hanwang] Nanyang Technol Univ, Singapore 639798, Singapore.
   [Chen, Long] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Zhejiang University; Nanyang Technological University; Hong Kong
   University of Science & Technology
RP Chen, L (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM chenchiz@zju.edu.cn; mwb@zju.edu.cn; junx@zju.edu.cn;
   hanwangzhang@ntu.edu.sg; jshao@zju.edu.cn; yzhuang@zju.edu.cn;
   zjuchenlong@gmail.com
RI Chen, Long/HZJ-7271-2023; Ma, Wenbo/ABA-5095-2020
OI Chen, Long/0000-0001-6148-9709; Ma, Wenbo/0000-0002-2209-4752; Shao,
   Jian/0000-0002-7842-7616; Zhuang, Yueting/0000-0001-9017-2508
FU National Key Research & Development Project of China [2021ZD0110700];
   National Natural Science Foundation of China [U19B2043, 61976185];
   Zhejiang Innovation Foundation [2019R52002]; Fundamental Research Funds
   for the Central Universities [226-2022-00051]
FX This work was supported by the National Key Research & Development
   Project of China (2021ZD0110700), the National Natural Science
   Foundation of China (U19B2043, 61976185), Zhejiang Innovation Foundation
   (2019R52002), and the Fundamental Research Funds for the Central
   Universities (226-2022-00051).
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cao M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9810
   Chen DJ, 2019, IEEE I CONF COMP VIS, P7453, DOI 10.1109/ICCV.2019.00755
   Chen H, 2019, PROC CVPR IEEE, P12530, DOI 10.1109/CVPR.2019.01282
   Chen K, 2018, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2018.00425
   Chen K, 2017, IEEE I CONF COMP VIS, P824, DOI 10.1109/ICCV.2017.95
   Chen L, 2022, LECT NOTES COMPUT SC, V13696, P95, DOI 10.1007/978-3-031-20059-5_6
   Chen L, 2023, Arxiv, DOI arXiv:2110.01013
   Chen L, 2021, AAAI CONF ARTIF INTE, V35, P1036
   Chen L, 2020, AAAI CONF ARTIF INTE, V34, P10551
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen XP, 2018, Arxiv, DOI arXiv:1812.03426
   Datta S, 2019, IEEE I CONF COMP VIS, P2601, DOI 10.1109/ICCV.2019.00269
   Deng J., 2021, Proceedings of the IEEE/CVF International Conference on Computer Vision, P1769
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding HH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16301, DOI 10.1109/ICCV48922.2021.01601
   Faghri F, 2018, Arxiv, DOI arXiv:1707.05612
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Gen Luo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10031, DOI 10.1109/CVPR42600.2020.01005
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hong RC, 2022, IEEE T PATTERN ANAL, V44, P684, DOI 10.1109/TPAMI.2019.2911066
   Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu RH, 2017, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2017.470
   Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7
   Hu ZW, 2020, PROC CVPR IEEE, P4423, DOI 10.1109/CVPR42600.2020.00448
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Jing Y, 2021, PROC CVPR IEEE, P9853, DOI 10.1109/CVPR46437.2021.00973
   Kamath A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1760, DOI 10.1109/ICCV48922.2021.00180
   Kazemzadeh Sahar, 2014, P 2014 C EMPIRICAL M
   Kim J, 2019, PROC CVPR IEEE, P10583, DOI [10.1109/CVP8.2019.01084, 10.1109/CVPR.2019.01084]
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li Q, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3300938
   Li RY, 2018, PROC CVPR IEEE, P5745, DOI 10.1109/CVPR.2018.00602
   Li XY, 2018, IEEE T MULTIMEDIA, V20, P2749, DOI 10.1109/TMM.2018.2811621
   Liao Yue, 2020, P IEEECVF C COMPUTER
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Chunxiao, 2020, P IEEECVF C COMPUTER
   Liu DQ, 2020, Arxiv, DOI arXiv:1906.03561
   Liu DQ, 2019, IEEE I CONF COMP VIS, P4672, DOI 10.1109/ICCV.2019.00477
   Liu ST, 2019, PROC CVPR IEEE, P6452, DOI 10.1109/CVPR.2019.00662
   Liu XH, 2019, PROC CVPR IEEE, P1950, DOI 10.1109/CVPR.2019.00205
   Long Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10797, DOI 10.1109/CVPR42600.2020.01081
   Lu JS, 2019, ADV NEUR IN, V32
   Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9
   Mao Yangjun, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P4374, DOI 10.1145/3503161.3548358
   Margffoy-Tuay E, 2018, LECT NOTES COMPUT SC, V11215, P656, DOI 10.1007/978-3-030-01252-6_39
   Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48
   Niu YL, 2021, IEEE T PATTERN ANAL, V43, P347, DOI 10.1109/TPAMI.2019.2926266
   Plummer BA, 2018, LECT NOTES COMPUT SC, V11216, P258, DOI 10.1007/978-3-030-01258-8_16
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Qiu S, 2020, IEEE T MULTIMEDIA, V22, P1333, DOI 10.1109/TMM.2019.2942480
   Qu MX, 2022, Arxiv, DOI arXiv:2207.13325
   Akula AR, 2020, Arxiv, DOI arXiv:2005.01655
   Sadhu A, 2019, IEEE I CONF COMP VIS, P4693, DOI 10.1109/ICCV.2019.00479
   ShaofeiHuang Tianrui Hui, 2020, P IEEE CVF C COMPUTE
   Shi HC, 2018, LECT NOTES COMPUT SC, V11210, P38, DOI 10.1007/978-3-030-01231-1_3
   Tan ZY, 2019, IEEE I CONF COMP VIS, P8272, DOI 10.1109/ICCV.2019.00836
   Tychsen-Smith L, 2018, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR.2018.00719
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Guoqing, 2022, 2022 IEEE INT C MULT
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang P, 2019, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2019.00206
   Wu YL, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P825, DOI 10.1145/3240508.3240521
   Wu YH, 2016, Arxiv, DOI [arXiv:1609.08144, DOI 10.48550/ARXIV.1609.08144]
   Xiao SN, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4008
   Xiao SN, 2021, AAAI CONF ARTIF INTE, V35, P2986
   Xu X, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3458281
   Yang CHY, 2020, Arxiv, DOI arXiv:1912.01674
   Yang Li, 2022, PROC IEEECVF C COMPU, P9499
   Yang SB, 2019, IEEE I CONF COMP VIS, P4643, DOI 10.1109/ICCV.2019.00474
   Yang Sibei, 2020, P IEEECVF C COMPUTER
   Yang ZY, 2019, IEEE I CONF COMP VIS, P4682, DOI 10.1109/ICCV.2019.00478
   Yang Zhengyuan, 2020, EUROPEAN C COMPUTER
   Ye Jiabo, 2022, PROC IEEECVF C COMPU, P15502
   Ye LW, 2020, IEEE T MULTIMEDIA, V22, P3224, DOI 10.1109/TMM.2020.2971171
   Ye LW, 2019, PROC CVPR IEEE, P10494, DOI 10.1109/CVPR.2019.01075
   Young Peter, 2014, From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions
   Yu DF, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3316767
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Yu LC, 2017, PROC CVPR IEEE, P3521, DOI 10.1109/CVPR.2017.375
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   [余宙 Yu Zhou], 2022, [中国图象图形学报, Journal of Image and Graphics], V27, P2761
   Yu Z, 2018, Arxiv, DOI [arXiv:1805.03508, 10.24963/ijcai.2018/155]
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Zhang HW, 2018, PROC CVPR IEEE, P4158, DOI 10.1109/CVPR.2018.00437
   Zhang LL, 2020, IEEE T MULTIMEDIA, V22, P775, DOI 10.1109/TMM.2019.2931352
   Zhu CY, 2022, Arxiv, DOI arXiv:2203.16265
   Zhuang BH, 2018, PROC CVPR IEEE, P4252, DOI 10.1109/CVPR.2018.00447
NR 94
TC 0
Z9 0
U1 1
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2023
VL 19
IS 5
SU S
AR 166
DI 10.1145/3579095
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L0SK0
UT WOS:001020437100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chakareski, J
   Khan, M
   Ropitault, T
   Blandino, S
AF Chakareski, Jacob
   Khan, Mahmudur
   Ropitault, Tanguy
   Blandino, Steve
TI Millimeter Wave and Free-space-optics for Future Dual-connectivity 6DOF
   Mobile Multi-user VR Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE 6DOF virtual reality; visible light communication; MMWAVE communication;
   WiFi-VLC dual connectivity wireless streaming; scalable 360 degree video
   tiling
ID VIDEO; CHALLENGES; DIVERSITY; SYSTEM
AB Dual-connectivity streaming is a key enabler of next-generation six Degrees Of Freedom (6DOF) Virtual Reality (VR) scene immersion. Indeed, using conventional sub-6 GHz WiFi only allows to reliably stream a low-quality baseline representation of the VR content, while emerging high-frequency communication technologies allow to stream in parallel a high-quality user viewport-specific enhancement representation that synergistically integrates with the baseline representation to deliver high-quality VR immersion. We investigate holistically as part of an entire future VR streaming system two such candidate emerging technologies, Free Space Optics (FSO) and millimeter-Wave (mmWave), that benefit from a large available spectrum to deliver unprecedented data rates. We analytically characterize the key components of the envisioned dualconnectivity 6DOF VR streaming system that integrates in addition edge computing and scalable 360 degrees video tiling, and we formulate an optimization problem to maximize the immersion fidelity delivered by the system, given the WiFi and mmWave/FSO link rates, and the computing capabilities of the edge server and the users' VR headsets. This optimization problem is mixed integer programming of high complexity and we formulate a geometric programming framework to compute the optimal solution at low complexity. We carry out simulation experiments to assess the performance of the proposed system using actual 6DOF navigation traces from multiple mobile VR users that we collected. Our results demonstrate that our system considerably advances the traditional state of the art and enables streaming of 8K-120 frames-per-second (fps) 6DOF content at high fidelity.
C1 [Chakareski, Jacob] New Jersey Inst Technol, Newark, NJ 07102 USA.
   [Khan, Mahmudur] York Coll Penn, York, PA USA.
   [Ropitault, Tanguy; Blandino, Steve] NIST, Wireless Networks Div, Bethesda, MD USA.
C3 New Jersey Institute of Technology; York College Pennsylvania; National
   Institute of Standards & Technology (NIST) - USA
RP Chakareski, J (corresponding author), New Jersey Inst Technol, Newark, NJ 07102 USA.
EM jacobcha@njit.edu; mkhan17@ycp.edu; tanguy.ropitault@nist.gov;
   steve.blandino@nist.gov
RI Blandino, Steve/KGL-4431-2024; Ropitault, Tanguy/JXN-4646-2024
OI Blandino, Steve/0000-0003-0250-8337; Ropitault,
   Tanguy/0000-0003-3177-8715
FU National Science Foundation [CCF-2031881, ECCS-2032387, CNS-2040088,
   CNS-2032033, CNS-2106150]; National Institutes of Health [R01EY030470];
   Panasonic Chair of Sustainability at the New Jersey Institute for
   Technology
FX The work of Jacob Chakareski and Mahmudur Khan has been supported in
   part by the National Science Foundation under awards CCF-2031881,
   ECCS-2032387, CNS-2040088, CNS-2032033, and CNS-2106150; by the National
   Institutes of Health under award R01EY030470; and by the Panasonic Chair
   of Sustainability at the New Jersey Institute for Technology.
CR Abari O, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P531
   Apostolopoulos JG, 2012, P IEEE, V100, P974, DOI 10.1109/JPROC.2011.2182069
   Assasa H, 2019, WORKSHOP ON NEXT-GENERATION WIRELESS WITH NS-3 (WNGW 2019), P22, DOI 10.1145/3337941.3337946
   Assasa H, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON NS-3 (WNS3 2019), P33, DOI 10.1145/3321349.3321354
   Begole Bo, 2016, Forbes Magazine
   Beysens J, 2020, IEEE ACM T NETWORK, V28, P461, DOI 10.1109/TNET.2020.2966322
   Blandino S, 2022, IEEE OPEN J VEH TECH, V3, P26, DOI 10.1109/OJVT.2021.3138697
   Blandino S, 2019, IEEE T CIRCUITS-I, V66, P848, DOI 10.1109/TCSI.2018.2866933
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Brennan DG, 2003, P IEEE, V91, P331, DOI 10.1109/JPROC.2002.808163
   Chakareski J, 2004, IEEE T COMMUN, V52, P1675, DOI 10.1109/TCOMM.2004.836436
   Chakareski J, 2006, IEEE T MULTIMEDIA, V8, P207, DOI 10.1109/TMM.2005.864284
   Chakareski J, 2005, IEEE T CIRC SYST VID, V15, P1257, DOI 10.1109/TCSVT.2005.854227
   Chakareski J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P1001
   Chakareski J., 2018, PROC IEEE INT C COMM, P1
   Chakareski J, 2006, IEEE ACM T NETWORK, V14, P1302, DOI 10.1109/TNET.2006.886299
   Chakareski J, 2008, IEEE T MULTIMEDIA, V10, P858, DOI 10.1109/TMM.2008.921846
   Chakareski J, 2017, DRONET'17: PROCEEDINGS OF THE 3RD WORKSHOP ON MICRO AERIAL VEHICLE NETWORKS, SYSTEMS, AND APPLICATIONS, P21, DOI 10.1145/3086439.3086448
   Chakareski J, 2020, IEEE T IMAGE PROCESS, V29, P6330, DOI 10.1109/TIP.2020.2986547
   Chakareski J, 2019, IEEE T IMAGE PROCESS, V28, P5977, DOI 10.1109/TIP.2019.2921869
   Clemm A, 2020, IEEE COMMUN MAG, V58, P93, DOI 10.1109/MCOM.001.1900272
   Corbillon X, 2017, IEEE ICC, DOI 10.1109/ICC.2017.7996611
   Cuervo E, 2018, HOTMOBILE'18: PROCEEDINGS OF THE 19TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS & APPLICATIONS, P7, DOI 10.1145/3177102.3177115
   developer.nvidia.com, NVIDIA VIDEO ENCODE
   Dimitrov S, 2015, PRINCIPLES OF LED LIGHT COMMUNICATIONS: TOWARDS NETWORKED LI-FI, P1, DOI 10.1017/CBO9781107278929
   github.com, OPENTRACK TRACKING
   github.com/, STEAMVR SDK
   GPU Systems, US
   Hosseini M, 2016, IEEE INT SYM MULTIM, P107, DOI [10.1109/ISM.2016.45, 10.1109/ISM.2016.0028]
   Hussein AT, 2015, J OPT COMMUN NETW, V7, P718, DOI 10.1364/JOCN.7.000718
   Khan M., NJIT 6DOF VR NAVIGAT
   Khan M., 2019, IEEE INT CONF COMM, P1
   Liu Z, 2021, IEEE NETWORK, V35, P202, DOI 10.1109/MNET.101.2000364
   Maltsev A, 2014, IEEE GLOBE WORK, P966, DOI 10.1109/GLOCOMW.2014.7063558
   NIST and Universita di Padova, Q D REAL SOFTW
   Petrangeli S, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P225, DOI 10.1145/3083187.3083224
   PUNNEN AP, 1994, DISCRETE APPL MATH, V55, P91, DOI 10.1016/0166-218X(94)90039-6
   qualcomm, QUALCOMM ADRENO 650
   Rahman M. S., 2018, P WORKSH WEAR SYST A
   Reis A. B., 2010, P IEEE INFOCOM INT W
   Stockhammer Champel T., 2016, PROC 116 MPEG M ISOI, V116
   Strinati EC, 2019, IEEE VEH TECHNOL MAG, V14, P42, DOI 10.1109/MVT.2019.2921162
   techpowerup, NVIDIA GEFORCE GTX 9
   Virtual Museum, US
   Willebrand H., 2002, FREE SPACE OPTICS EN
   Xu GX, 2014, EUR J OPER RES, V233, P500, DOI 10.1016/j.ejor.2013.10.016
   Zeng ZH, 2019, IEEE ICC
   Zhong RG, 2017, PROCEEDINGS OF THE 8TH ASIA-PACIFIC WORKSHOP ON SYSTEMS (APSYS '17), DOI 10.1145/3124680.3124723
NR 49
TC 3
Z9 3
U1 1
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2023
VL 19
IS 2
AR 57
DI 10.1145/3544494
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J7DP3
UT WOS:001011190000007
DA 2024-07-18
ER

PT J
AU Nousias, S
   Arvanitis, G
   Lalos, A
   Moustakas, K
AF Nousias, Stavros
   Arvanitis, Gerasimos
   Lalos, Aris
   Moustakas, Konstantinos
TI Deep Saliency Mapping for 3D Meshes and Applications
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Saliency mapping estimation; compression and simplification
ID COMPRESSION; RECONSTRUCTION
AB Nowadays, three-dimensional (3D) meshes are widely used in various applications in different areas (e.g., industry, education, entertainment and safety). The 3D models are captured with multiple RGB-D sensors, and the sampled geometric manifolds are processed, compressed, simplified, stored, and transmitted to be reconstructed in a virtual space. These low-level processing applications require the accurate representation of the 3D models that can be achieved through saliency estimation mechanisms that identify specific areas of the 3D model representing surface patches of importance. Therefore, saliency maps guide the selection of feature locations facilitating the prioritization of 3D manifold segments and attributing to vertices more bits during compression or lower decimation probability during simplification, since compression and simplification are counterparts of the same process. In this work, we present a novel deep saliency mapping approach applied to 3D meshes, emphasizing decreasing the execution time of the saliency map estimation, especially when compared with the corresponding time by other relevant approaches. Our method utilizes baseline 3D importance maps to train convolutional neural networks. Furthermore, we present applications that utilize the extracted saliency, namely feature-aware multiscale compression and simplification frameworks.
C1 [Nousias, Stavros; Lalos, Aris] Athena Res Ctr, Ind Syst Inst, Patras Sci Pk, Platani 26504, Achaia, Greece.
   [Arvanitis, Gerasimos; Moustakas, Konstantinos] Univ Patras, Dept Elect & Comp Engn, Rion 26504, Achaia, Greece.
C3 University of Patras
RP Nousias, S (corresponding author), Athena Res Ctr, Ind Syst Inst, Patras Sci Pk, Platani 26504, Achaia, Greece.
EM nousias@isi.gr; arvani-tis@ece.upatras.gr; lalos@isi.gr;
   moustakas@upatras.gr
RI Nousias, Stavros/JQV-8222-2023
OI Nousias, Stavros/0000-0002-2811-235X; Moustakas,
   Konstantinos/0000-0001-7617-227X; ARVANITIS,
   GERASIMOS/0000-0001-8149-5188; Lalos, Aris/0000-0003-0511-9302
FU European Union [777981]
FX This work was supported by European Union Horizon 2020 Research and
   innovation program "WARMEST -or loW Altitude Remote sensing for the
   Monitoring of the state of cultural hEritage Sites: building an
   inTegrated model for maintenance" under Marie Sklodowska grant agreement
   No 777981.
CR Alexiadis DS, 2017, IEEE T CIRC SYST VID, V27, P798, DOI 10.1109/TCSVT.2016.2576922
   Alexiadis DS, 2013, 2013 IEEE 11TH IVMSP WORKSHOP: 3D IMAGE/VIDEO TECHNOLOGIES AND APPLICATIONS (IVMSP 2013)
   Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   An GM, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P231, DOI 10.1109/CW.2016.47
   Arvanitis G, 2021, IEEE T IND INFORM, V17, P1307, DOI 10.1109/TII.2020.3003455
   Arvanitis G, 2019, IEEE INTL CONF IND I, P683, DOI [10.1109/indin41052.2019.8972024, 10.1109/INDIN41052.2019.8972024]
   Arvanitis G, 2019, COMPUT AIDED GEOM D, V73, P70, DOI 10.1016/j.cagd.2019.07.005
   Asano T, 1997, THEOR COMPUT SCI, V181, P3, DOI 10.1016/S0304-3975(96)00259-9
   Cornia M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177745
   Doumanoglou A, 2019, IEEE J EM SEL TOP C, V9, P190, DOI 10.1109/JETCAS.2019.2898768
   Doumanoglou A, 2018, IEEE T BROADCAST, V64, P379, DOI 10.1109/TBC.2018.2823909
   [Фаворская М.Н. Favorskaya M.N.], 2019, [Информационно-управляющие системы, Informatsionno-upravliaiushchie sistemy [Information and Control Systems], Informatsionno-upravlyayushchie sistemy], P10
   Guo Y, 2018, VISUAL COMPUT, V34, P1325, DOI 10.1007/s00371-017-1416-3
   He JL, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3382506
   Hu XJ, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3395620
   Lalos AS, 2018, IEEE INT CON MULTI
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Liu SJ, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348822
   Luo GL, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377475
   Maimone A, 2011, INT SYM MIX AUGMENT
   Maimone A, 2012, COMPUT GRAPH-UK, V36, P791, DOI 10.1016/j.cag.2012.04.011
   Maimone Andrew, 2012, P 3DTV C TRUE VIS CA, P1
   Mamou K, 2009, COMPUT ANIMAT VIRT W, V20, P343, DOI 10.1002/cav.319
   Milani S, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037680
   Nordfang M, 2014, ATTEN PERCEPT PSYCHO, V76, P1535, DOI 10.3758/s13414-014-0715-2
   Nouri A, 2015, IEEE IMAGE PROC, P2820, DOI 10.1109/ICIP.2015.7351317
   Nousias S., 2020, 2020 IEEE INT C MULT, P1
   Nousias S, 2020, IEEE ACCESS, V8, P169982, DOI 10.1109/ACCESS.2020.3023167
   Pingping Tao, 2016, 2016 6th International Conference on Digital Home (ICDH), P288, DOI 10.1109/ICDH.2016.065
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Song R, 2018, VISUAL COMPUT, V34, P323, DOI 10.1007/s00371-016-1334-9
   Song R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2530691
   Sorkine O., 2003, Symposium on Geometry Processing, P42
   Watanabe H., 2020, SMPTE MOTION IMAG J, V129, P24, DOI [10.5594/JMI.2020.3010391, DOI 10.5594/JMI.2020.3010391]
   Wei N, 2018, IEEE ACCESS, V6, P54536, DOI 10.1109/ACCESS.2018.2872168
   Wu JL, 2013, GRAPH MODELS, V75, P255, DOI 10.1016/j.gmod.2013.05.002
   Xing SJ, 2020, IEEE ACCESS, V8, P85750, DOI 10.1109/ACCESS.2020.2992511
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zhao YT, 2012, IEEE IMAGE PROC, P633, DOI 10.1109/ICIP.2012.6466939
NR 40
TC 3
Z9 3
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2023
VL 19
IS 2
AR 71
DI 10.1145/3550073
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J7DP3
UT WOS:001011190000021
OA Bronze, Green Submitted
DA 2024-07-18
ER

PT J
AU Xu, SX
   Sun, K
   Liu, D
   Xiong, ZW
   Zha, ZJ
AF Xu, Shunxin
   Sun, Ke
   Liu, Dong
   Xiong, Zhiwei
   Zha, Zheng-Jun
TI Synergy between Semantic Segmentation and Image Denoising via Alternate
   Boosting
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Alternate boosting; deep learning; image denoising; semantic
   segmentation
ID SPARSE
AB The capability of image semantic segmentation may be deteriorated due to the noisy input image, where image denoising prior to segmentation may help. Both image denoising and semantic segmentation have been developed significantly with the advance of deep learning. In this work, we are interested in the synergy between these two tasks by using a holistic deep model. We observe that not only denoising helps combat the drop of segmentation accuracy due to the noisy input, but also pixel-wise semantic information boosts the capability of denoising. We then propose a boosting network to perform denoising and segmentation alternately. The proposed network is composed of multiple segmentation and denoising blocks (SDBs), each of which estimates a semantic map and then uses the map to regularize denoising. Experimental results show that the denoised image quality is improved substantially and the segmentation accuracy is improved to close to that on clean images, and segmentation and denoising are both boosted as the number of SDBs increases. On the Cityscapes dataset, using three SDBs improves the denoising quality to 34.42 dB in PSNR, and the segmentation accuracy to 66.5 in mIoU, when the additive white Gaussian noise level is 50.
C1 [Xu, Shunxin; Sun, Ke; Liu, Dong; Xiong, Zhiwei; Zha, Zheng-Jun] Univ Sci & Technol China, 443 Huangshan Rd, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Liu, D (corresponding author), Univ Sci & Technol China, 443 Huangshan Rd, Hefei 230027, Anhui, Peoples R China.
EM sxu@mail.ustc.edu.cn; sunk@mail.ustc.edu.cn; dongeliu@ustc.edu.cn;
   zwxiong@ustc.edu.cn; zhazj@ustc.edu.cn
RI Liu, Jinyu/JYQ-6274-2024; SUN, YANLING/JTT-9082-2023; Zha,
   Zheng-Jun/AAF-8667-2020; Yang, Tian/JFB-1008-2023; Wang,
   Minghao/JMD-0670-2023; WANG, YANG/JFA-8821-2023; cheng,
   chen/JHS-9462-2023; Liu, Dong/K-7488-2012; Jiang, Yu/JEZ-9814-2023
OI Liu, Dong/0000-0001-9100-2906
FU Natural Science Foundation of China [62022075, 62021001]; Fundamental
   Research Funds for the Central Universities [WK3490000006]
FX This work was supported by the Natural Science Foundation of China under
   Grants 62022075 and 62021001, and by the Fundamental Research Funds for
   the Central Universities under Grant WK3490000006.
CR Abdelhamed A, 2018, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2018.00182
   Abdolghader Pedram, 2021, ARXIV
   Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Anwar S, 2017, IEEE T IMAGE PROCESS, V26, P5506, DOI 10.1109/TIP.2017.2733739
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Buchholz Tim-Oliver, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12535), P324, DOI 10.1007/978-3-030-66415-2_21
   Charest MR, 2006, 2006 40TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-4, P452, DOI 10.1109/CISS.2006.286510
   Chen C, 2020, IEEE T PATTERN ANAL, V42, P3071, DOI 10.1109/TPAMI.2019.2921548
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LY, 2021, IEEE COMPUT SOC CONF, P182, DOI 10.1109/CVPRW53098.2021.00027
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Glorot X., 2010, 13 INT C ARTIFICIAL, V9, P249
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   Han S., 2016, ADV NEURAL INF PROCE, P109
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosotani F, 2015, IEEE T IMAGE PROCESS, V24, P6025, DOI 10.1109/TIP.2015.2494461
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim Y, 2020, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR42600.2020.00354
   Kingma D. P., 2014, arXiv
   Krull A, 2019, PROC CVPR IEEE, P2124, DOI 10.1109/CVPR.2019.00223
   Larrazabal AJ, 2019, LECT NOTES COMPUT SC, V11769, P585, DOI 10.1007/978-3-030-32226-7_65
   Latif Ghazanfar, 2018, Int J Eng Technol, V7, P37, DOI DOI 10.1109/ASAR.2018.8480289
   Lehtinen J, 2018, PR MACH LEARN RES, V80
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin Xiaoyu, 2021, ARXIV
   Liu D, 2020, IEEE T IMAGE PROCESS, V29, P3695, DOI 10.1109/TIP.2020.2964518
   Liu D, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P842
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mao XJ, 2016, ADV NEUR IN, V29
   Moghimi M., 2016, BMVC, P1, DOI 10.5244/C.30.24
   Paszke A, 2019, ADV NEUR IN, V32
   Plötz T, 2017, PROC CVPR IEEE, P2750, DOI 10.1109/CVPR.2017.294
   Remez T, 2018, IEEE T IMAGE PROCESS, V27, P5707, DOI 10.1109/TIP.2018.2859044
   Ren WQ, 2017, IEEE I CONF COMP VIS, P1086, DOI 10.1109/ICCV.2017.123
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shao J., 2020, Adv. Neural Inf. Process. Syst., V33, P13434, DOI DOI 10.24843/LKJITI.2020.V11.I03.P01
   Sharma V, 2018, PROC CVPR IEEE, P4033, DOI 10.1109/CVPR.2018.00424
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P372, DOI 10.1109/ICIP.1999.821633
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Talebi H, 2013, IEEE T IMAGE PROCESS, V22, P1468, DOI 10.1109/TIP.2012.2231691
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Vaswani A, 2017, ADV NEUR IN, V30
   Vatsa M., 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P561
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang L, 2020, PROC CVPR IEEE, P3773, DOI 10.1109/CVPR42600.2020.00383
   Wang SC, 2019, Arxiv, DOI arXiv:1905.08965
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang ZD, 2021, Arxiv, DOI arXiv:2106.03106
   Xu ZY, 2018, MED IMAGE ANAL, V46, P229, DOI 10.1016/j.media.2018.03.007
   Xu ZY, 2014, LECT NOTES COMPUT SC, V8673, P698, DOI 10.1007/978-3-319-10404-1_87
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang HC, 2019, IEEE I CONF COMP VIS, P8798, DOI 10.1109/ICCV.2019.00889
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang ZY, 2018, LECT NOTES COMPUT SC, V11214, P238, DOI 10.1007/978-3-030-01249-6_15
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
NR 76
TC 2
Z9 2
U1 4
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2023
VL 19
IS 2
AR 69
DI 10.1145/3548459
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J7DP3
UT WOS:001011190000019
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, DH
   Gao, W
   Li, G
   Yuan, H
   Hou, JH
   Kwong, S
AF Yang, Dinghao
   Gao, Wei
   Li, Ge
   Yuan, Hui
   Hou, Junhui
   Kwong, Sam
TI Exploiting Manifold Feature Representation for Efficient Classification
   of 3D Point Clouds
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Point cloud classification; manifold learning; feature representation;
   deep neural network; 3D vision
AB In this paper, we propose an efficient point cloud classification method via manifold learning based feature representation. Different from conventional methods, we use manifold learning algorithms to embed point cloud features for better considering the geometric continuity on the surface. Then, the nature of point cloud can be acquired in low dimensional space, and after being concatenated with features in the original three-dimensional (3D) space, both the capability of feature representation and the classification network performance can be improved. We explore three traditional manifold algorithms (i.e., Isomap, Locally-Linear Embedding, and Laplacian eigenmaps) in detail, and finally, we select the Locally-Linear Embedding (LLE) algorithm due to its low complexity and locality consistency preservation. Furthermore, we propose a neural network based manifold learning (NNML) method to implement manifold learning based non-linear projection. Experiments demonstrate that the proposed two manifold learning methods can obtain better performances than the state-of-the-art methods, and the obtained mean class accuracy (mA) and overall accuracy (oA) can reach 91.4% and 94.4%, respectively. Moreover, because of the improved feature learning capability, the proposed NNML method can also have better classification accuracy on models with prominent geometric shapes. To further demonstrate the advantages of PointManifold, we extend it as a plug and play method for point cloud classification task, which can be directly used with existing methods and gain a significant improvement.
C1 [Yang, Dinghao; Gao, Wei; Li, Ge] Peking Univ, Sch Elect & Comp Engn, Shenzhen 518055, Peoples R China.
   [Yang, Dinghao; Gao, Wei] Peng Cheng Lab, Shenzhen 518055, Peoples R China.
   [Yuan, Hui] Shandong Univ, Sch Control Sci & Engn, 17923 JingShi Rd, Jinan 250061, Shandong, Peoples R China.
   [Hou, Junhui; Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, B6417,6-F Blue Zone,Yeung Kin Man Acad Bldg, Hong Kong, Peoples R China.
C3 Peking University; Peng Cheng Laboratory; Shandong University; City
   University of Hong Kong
RP Gao, W (corresponding author), Peking Univ, Sch Elect & Comp Engn, Shenzhen 518055, Peoples R China.; Gao, W (corresponding author), Peng Cheng Lab, Shenzhen 518055, Peoples R China.
EM ding-haoyang@stu.pku.edu.cn; gaowei262@pku.edu.cn; geli@pku.edu.cn;
   huiyuan@sdu.edu.cn; jh.hou@cityu.edu.hk; cssamk@cityu.edu.hk
RI Kwong, Sam/C-9319-2012; Yuan, Hui/HDO-3699-2022
OI Kwong, Sam/0000-0001-7484-7261; Yuan, Hui/0000-0001-5212-3393; Hou,
   Junhui/0000-0003-3431-2021
FU Guangdong Basic and Applied Basic Research Foundation [2019A1515012031];
   Shenzhen Fundamental Research Program
   [GXWD20201231165807007-20200806163656003]; Shenzhen Science and
   Technology Plan Basic Research Project [JCYJ20190808161805519]; Natural
   Science Foundation of China [62031013]; Hong Kong GRF-RGC General
   Research Fund [11209819 (CityU 9042816), 11203820 (9042598)]; Major Key
   Project of PCL
FX This work was supported by The Major Key Project of PCL, Guangdong Basic
   and Applied Basic Research Foundation (2019A1515012031), Shenzhen
   Fundamental Research Program (GXWD20201231165807007-20200806163656003),
   Shenzhen Science and Technology Plan Basic Research Project
   (JCYJ20190808161805519), Natural Science Foundation of China (62031013),
   the Hong Kong GRF-RGC General Research Fund under Grant 11209819 (CityU
   9042816) and Grant 11203820 (9042598).
CR [Anonymous], Manifold
   [Anonymous], NONLINEAR DIMENSIONA
   Fu Chunyang, 2022, P AAAI C ARTIFICIAL
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Han WK, 2020, AAAI CONF ARTIF INTE, V34, P10925
   Hu Qingyong, 2021, IEEE Trans. Pattern Anal. Mach. Intell.
   Hu SM, 2020, IEEE T VIS COMPUT GR, V26, P2485, DOI 10.1109/TVCG.2018.2889944
   Jakovljevic Z, 2015, IEEE T IND INFORM, V11, P342, DOI 10.1109/TII.2015.2389195
   Jiang MY, 2018, Arxiv, DOI [arXiv:1807.00652, 10.48550/arXiv.1807.00652]
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Li Ge, 2022, IEEE T CIRC SYST VID, P1
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li YZ, 2018, ADV NEUR IN, V31
   Li ZH, 2022, IEEE INTERNET THINGS, V9, P17844, DOI 10.1109/JIOT.2022.3161943
   Lin YQ, 2020, PROC CVPR IEEE, P4292, DOI 10.1109/CVPR42600.2020.00435
   Liu KC, 2021, Arxiv, DOI arXiv:2012.09439
   Luo RC, 2016, IEEE T IND INFORM, V12, P51, DOI 10.1109/TII.2015.2496140
   Luo ST, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1330, DOI 10.1145/3394171.3413727
   Lyu Yecheng, 2021, IEEE T PATTERN ANAL
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nie Weizhi, 2020, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), V16, P1
   Qi C.R., 2017, ABS170602413 CORR, P5099
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Ran HX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15457, DOI 10.1109/ICCV48922.2021.01519
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Song F, 2022, IEEE SIGNAL PROC LET, V29, P922, DOI 10.1109/LSP.2022.3161868
   Song F, 2021, IEEE T CIRC SYST VID, V31, P4603, DOI 10.1109/TCSVT.2021.3098832
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiang TG, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P895, DOI 10.1109/ICCV48922.2021.00095
   Xie SN, 2018, PROC CVPR IEEE, P4606, DOI 10.1109/CVPR.2018.00484
   Xu MT, 2021, PROC CVPR IEEE, P3172, DOI 10.1109/CVPR46437.2021.00319
   Xu YF, 2018, LECT NOTES COMPUT SC, V11212, P90, DOI 10.1007/978-3-030-01237-3_6
   Yavartanoo M, 2019, LECT NOTES COMPUT SC, V11365, P691, DOI 10.1007/978-3-030-20873-8_44
   Zhang C., 2021, arXiv
   Zhang YH, 2018, IEEE T INTELL TRANSP, V19, P3981, DOI 10.1109/TITS.2018.2789462
   Zhang YX, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6279, DOI 10.1109/ICASSP.2018.8462291
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
NR 45
TC 0
Z9 0
U1 1
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2023
VL 19
IS 1
SU S
AR 50
DI 10.1145/3539611
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Q4HK
UT WOS:000927169800024
DA 2024-07-18
ER

PT J
AU Zhang, TJ
   Deng, H
   Zhang, L
   Zhao, SJ
   Liu, X
   Zhou, YC
AF Zhang, Tianjun
   Deng, Hao
   Zhang, Lin
   Zhao, Shengjie
   Liu, Xiao
   Zhou, Yicong
TI Online Correction of Camera Poses for the Surround-view System: A Sparse
   Direct Approach
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Surround-view system; direct method; cascade structure; photometric
   error minimization
AB The surround-view module is an indispensable component of a modern advanced driving assistance system. By calibrating the intrinsics and extrinsics of the surround-view cameras accurately, a top-down surround-view can be generated from raw fisheye images. However, poses of these cameras sometimes may change. At present, how to correct poses of cameras in a surround-view system online without re-calibration is still an open issue. To settle this problem, we introduce the sparse direct framework and propose a novel optimization scheme of a cascade structure. This scheme is actually composed of two levels of optimization and two corresponding photometric error based models are proposed. The model for the first-level optimization is called the ground model, as its photometric errors are measured on the ground plane. For the second level of the optimization, it's based on the so-called ground-camera model, in which photometric errors are computed on the imaging planes. With these models, the pose correction task is formulated as a nonlinear least-squares problem to minimize photometric errors in overlapping regions of adjacent bird's-eye-view images. With a cascade structure of these two levels of optimization, an appropriate balance between the speed and the accuracy can be achieved. Experiments show that our method can effectively eliminate the misalignment caused by cameras' moderate pose changes in the surround-view system. Source code and test cases are available online at https://cslinzhang.github.io/CamPoseCorrection/.
C1 [Zhang, Tianjun; Deng, Hao; Zhang, Lin; Zhao, Shengjie] Tongji Univ, Sch Software Engn, 4800 Caoan RD, Shanghai 200092, Peoples R China.
   [Liu, Xiao] Univ Massachusetts, Coll Informat & Comp Sci, 141 Commonwealth Ave, Amherst, MA 01002 USA.
   [Zhou, Yicong] Univ Macau, Dept Comp & Informat Sci, Ave Univ, Taipa, Macao, Peoples R China.
C3 Tongji University; University of Massachusetts System; University of
   Massachusetts Amherst; University of Macau
RP Deng, H; Zhang, L (corresponding author), Tongji Univ, Sch Software Engn, 4800 Caoan RD, Shanghai 200092, Peoples R China.
EM 1911036@tongji.edu.cn; denghao1984@tongji.edu.cn;
   cslinzhang@tongji.edu.cn; shengjiezhao@tongji.edu.cn;
   xiaoliu1990@cs.umass.edu; yicongzhou@um.edu.mo
RI Zhou, Yicong/A-8017-2009
OI Zhou, Yicong/0000-0002-4487-6384; Zhang, Lin/0000-0002-4360-5523
FU National Natural Science Foundation of China [61973235, 61936014];
   Natural Science Foundation of Shanghai [19ZR1461300]; Shanghai Science
   and Technology Innovation Plan [20510760400]; Dawn Program of Shanghai
   Municipal Education Commission [21SG23]; Shanghai Municipal Science and
   Technology Major Project [2021SHZDZX0100]; Fundamental Research Funds
   for the Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61973235 and 61936014, in part by the
   Natural Science Foundation of Shanghai under Grant 19ZR1461300, in part
   by the Shanghai Science and Technology Innovation Plan under Grant
   20510760400, in part by the Dawn Program of Shanghai Municipal Education
   Commission under Grant 21SG23, in part by the Shanghai Municipal Science
   and Technology Major Project under Grant 2021SHZDZX0100, and in part by
   the Fundamental Research Funds for the Central Universities.
CR BATTITI R, 1992, NEURAL COMPUT, V4, P141, DOI 10.1162/neco.1992.4.2.141
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Choi K, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103590
   Collado JM, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P156, DOI 10.1109/IVS.2006.1689621
   DANG T, 2006, JOINT DAGM S, P627
   Dennis J. E., 1983, NUMERICAL METHODS UN, V28, P417
   Du F., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P477, DOI 10.1109/CVPR.1993.341087
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Gressmann M, 2011, IEEE INT C INTELL TR, P1317, DOI 10.1109/ITSC.2011.6082895
   Hansen P, 2012, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2012.6247784
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Heng L, 2014, IEEE INT CONF ROBOT, P4912, DOI 10.1109/ICRA.2014.6907579
   Heng L, 2013, IEEE INT C INT ROBOT, P1793, DOI 10.1109/IROS.2013.6696592
   HOFFMAN WC, 1966, J MATH PSYCHOL, V3, P65, DOI 10.1016/0022-2496(66)90005-8
   Hold S, 2009, 2009 12TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC 2009), P420
   Hou C., 2007, P AS C COMP VIS, P18
   Irani M., 1999, P WORKSH VIS ALG THE, P267
   Klette R., 1998, COMPUTER VISION 3 DI, V1st
   Knorr M, 2013, IEEE INT VEH SYM, P236, DOI 10.1109/IVS.2013.6629476
   Lebraly Pierre, 2011, 2011 IEEE International Conference on Robotics and Automation, P221
   Li LS, 2017, IEEE INT CON MULTI, P649, DOI 10.1109/ICME.2017.8019419
   Lin CC, 2012, SENSORS-BASEL, V12, P4431, DOI 10.3390/s120404431
   Ling YG, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1771, DOI 10.1109/IROS.2016.7759283
   Liu X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P383, DOI 10.1145/3343031.3350885
   Lourakis M. I. A., 2019, PROC EUROPEAN C COMP, P43
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nedevschi S, 2007, IEEE T INTELL TRANSP, V8, P651, DOI 10.1109/TITS.2007.908576
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Nielsen F, 2005, VISUAL COMPUT, V21, P92, DOI 10.1007/s00371-004-0273-z
   Nocedal J., 1992, ACTA NUMER, V1, P199, DOI DOI 10.1017/S0962492900002270
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schneider S, 2013, IEEE INT C INT ROBOT, P1287, DOI 10.1109/IROS.2013.6696515
   Shao X, 2019, IEEE INT CON MULTI, P1486, DOI 10.1109/ICME.2019.00257
   WEDDERBURN RWM, 1974, BIOMETRIKA, V61, P439, DOI 10.2307/2334725
   Xu J, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P725, DOI 10.1109/IVS.2000.898435
   Zhang L, 2018, IEEE T IMAGE PROCESS, V27, P5350, DOI 10.1109/TIP.2018.2857407
   Zhao K, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1490, DOI 10.1109/ITSC.2014.6957643
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
   Zhu HJ, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER SCIENCE, VOL 1, PROCEEDINGS, P321, DOI 10.1109/ITCS.2009.72
NR 45
TC 1
Z9 1
U1 2
U2 23
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2022
VL 18
IS 4
AR 106
DI 10.1145/3505252
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0E1KA
UT WOS:000776441600017
DA 2024-07-18
ER

PT J
AU Yuan, D
   Chang, XJ
   Li, ZH
   He, ZY
AF Yuan, Di
   Chang, Xiaojun
   Li, Zhihui
   He, Zhenyu
TI Learning Adaptive Spatial-Temporal Context-Aware Correlation Filters for
   UAV Tracking
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE UAV tracking; discriminative correlation filters; adaptive
   spatial-temporal context-aware
ID SEGMENTATION MODEL; OBJECT TRACKING
AB Tracking in the unmanned aerial vehicle (UAV) scenarios is one of the main components of target-tracking tasks. Different from the target-tracking task in the general scenarios, the target-tracking task in the UAV scenarios is very challenging because of factors such as small scale and aerial view. Although the discriminative correlation filter (DCF)-based tracker has achieved good results in tracking tasks in general scenarios, the boundary effect caused by the dense sampling method will reduce the tracking accuracy, especially in UAV-tracking scenarios. In this work, we propose learning an adaptive spatial-temporal context-aware (ASTCA) model in the DCF-based tracking framework to improve the tracking accuracy and reduce the influence of boundary effect, thereby enabling our tracker to more appropriately handle UAV-tracking tasks. Specifically, our ASTCA model can learn a spatial-temporal context weight, which can precisely distinguish the target and background in the UAV-tracking scenarios. Besides, considering the small target scale and the aerial view in UAV-tracking scenarios, our ASTCA model incorporates spatial context information within the DCF-based tracker, which could effectively alleviate background interference. Extensive experiments demonstrate that our ASTCA method performs favorably against state-of-the-art tracking methods on some standard UAV datasets.
C1 [Yuan, Di; He, Zhenyu] Harbin Inst Technol, Shenzhen 518055, Peoples R China.
   [Chang, Xiaojun] RMIT Univ, Melbourne, Vic 3046, Australia.
   [Li, Zhihui] Qilu Univ Technol, Shandong Artificial Intelligence Inst, Shandong Acad Sci, Jinan 250353, Peoples R China.
C3 Harbin Institute of Technology; Royal Melbourne Institute of Technology
   (RMIT); Qilu University of Technology
RP He, ZY (corresponding author), Harbin Inst Technol, Shenzhen 518055, Peoples R China.
EM dyuanhit@gmail.com; cxj273@gmail.com; zhihuilics@gmail.com;
   zhenyuhe@hit.edu.cn
RI Li, Zhihui/AAB-7394-2020; Chang, Xiaojun/A-2055-2015; Yuan,
   Di/Q-6521-2019
OI Li, Zhihui/0000-0001-9642-8009; Chang, Xiaojun/0000-0002-7778-8807;
   Yuan, Di/0000-0001-9403-1112
FU National Natural Science Foundation of China [62172126, 61906109];
   Shenzhen Research Council [JCYJ20210324120202006]; Special Research
   project on COVID-19 Prevention and Control of Guangdong Province
   [2020KZDZDX1227]; China Scholarship Council (CSC) [201906120405];
   Australian Research Council (ARC) Discovery Early Career Researcher
   Award (DECRA) [DE190100626]
FX This research was supported by National Natural Science Foundation of
   China under Nos. 62172126, 61906109, by the Shenzhen Research Council
   under No. JCYJ20210324120202006, by the Special Research project on
   COVID-19 Prevention and Control of Guangdong Province under No.
   2020KZDZDX1227. Di Yuan was supported by a scholarship from China
   Scholarship Council (CSC) under No. 201906120405. Dr Xiaojun Chang was
   partially supported by Australian Research Council (ARC) Discovery Early
   Career Researcher Award (DECRA) under grant no. DE190100626.
CR An N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3441656
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen KX, 2020, IEEE T NEUR NET LEAR, V31, P1747, DOI 10.1109/TNNLS.2019.2927224
   Chen K, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700296
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Fan JQ, 2021, IEEE T CIRC SYST VID, V31, P1296, DOI 10.1109/TCSVT.2020.2987601
   Fengda Zhu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10009, DOI 10.1109/CVPR42600.2020.01003
   Fu CH, 2019, IEEE INT C INT ROBOT, P4415, DOI [10.1109/iros40897.2019.8967674, 10.1109/IROS40897.2019.8967674]
   Fu Sichao, ACM T MULTIM COMPUT, V17, P1
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Guo CY, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3360308
   Guo JT, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3131342
   Han JW, 2018, PROC CVPR IEEE, P9080, DOI 10.1109/CVPR.2018.00946
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li SY, 2017, AAAI CONF ARTIF INTE, P4140
   Li X, 2020, NEURAL NETWORKS, V132, P364, DOI 10.1016/j.neunet.2020.09.011
   Li Y, 2019, AAAI CONF ARTIF INTE, P8666
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Li ZH, 2019, PATTERN RECOGN, V88, P595, DOI 10.1016/j.patcog.2018.12.010
   Liu KK, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808208
   Liu Q, 2021, IEEE T MULTIMEDIA, V23, P2114, DOI 10.1109/TMM.2020.3008028
   Luo MN, 2019, IEEE T IMAGE PROCESS, V28, P4701, DOI 10.1109/TIP.2019.2913081
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Mingfei Han, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P431, DOI 10.1007/978-3-030-58589-1_26
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ren PZ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447582
   Shu X, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108293
   Shu X, 2021, NEUROCOMPUTING, V453, P438, DOI 10.1016/j.neucom.2021.01.081
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang Yong, 2019, ICCV WORKSH, P1
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu TY, 2019, IEEE I CONF COMP VIS, P7949, DOI 10.1109/ICCV.2019.00804
   Yan CX, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3418284
   Yan CX, 2020, IEEE T IMAGE PROCESS, V29, P8163, DOI 10.1109/TIP.2020.3011807
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645
   Yang YY, 2020, APPL MATH MODEL, V83, P357, DOI 10.1016/j.apm.2020.02.028
   Yiming Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11920, DOI 10.1109/CVPR42600.2020.01194
   Yu E, 2019, IEEE T MULTIMEDIA, V21, P1276, DOI 10.1109/TMM.2018.2877127
   Yuan D, 2021, IEEE T IMAGE PROCESS, V30, P976, DOI 10.1109/TIP.2020.3037518
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105554
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105526
   Yuan D, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105697
   Zhang DL, 2020, IEEE T CYBERNETICS, V50, P3033, DOI 10.1109/TCYB.2019.2905157
   Zhang F., 2020, ACM MULTIMEDIA, V2020, P3367
   Zhang KH, 2019, IEEE T IMAGE PROCESS, V28, P479, DOI 10.1109/TIP.2018.2868561
   Zhang LL, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107348
   Zhang LL, 2020, IEEE T MULTIMEDIA, V22, P775, DOI 10.1109/TMM.2019.2931352
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhong BN, 2019, IEEE T IMAGE PROCESS, V28, P2331, DOI 10.1109/TIP.2018.2885238
   Zhou RW, 2020, IEEE T NEUR NET LEAR, V31, P1592, DOI 10.1109/TNNLS.2019.2920905
NR 80
TC 94
Z9 94
U1 24
U2 119
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2022
VL 18
IS 3
AR 70
DI 10.1145/3486678
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5UA
UT WOS:000772650600004
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Fan, CL
   Hung, TH
   Hsu, CH
AF Fan, Ching-Ling
   Hung, Tse-Hou
   Hsu, Cheng-Hsin
TI Modeling the User Experience of Watching 360° Videos with Head-Mounted
   Displays
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; user study; mean opinion score; individual score
ID QOE
AB Conducting user studies to quantify the Quality of Experience (QoE) of watching the increasingly more popular 360' videos in Head-Mounted Displays (HMDs) is time-consuming, tedious, and expensive. Deriving QoE models, however, is very challenging because of the diverse viewing behaviors and complex QoE features and factors. In this article, we compile a wide spectrum of QoE features and factors that may contribute to the overall QoE. We design and conduct a user study to build a dataset of the overall QoE, QoE features, and QoE factors. Using the dataset, we derive the QoE models for both the Mean Opinion Score (MOS) and Individual Score (IS), where MOS captures the aggregated QoE across all subjects, while IS captures the QoE of individual subjects. Our derived overall QoE models achieve 0.98 and 0.91 in Pearson's Linear Correlation Coefficient (PLCC) for MOS and IS, respectively. Besides, we make several new observations on our user study results, such as (1) content factors dominate the overall QoE across all factor categories, (2) Video Multi-Method Assessment Fusion (VMAF) is the dominating factor among content factors, and (3) the perceived cybersickness is affected by human factors more among others. Our proposed user study design is useful for QoE modeling (specifically) and subjective evaluations (in general) of emerging 360 degrees tiled video streaming to HMDs.
C1 [Fan, Ching-Ling; Hung, Tse-Hou; Hsu, Cheng-Hsin] Natl Tsing Hua Univ, 101 Sec 2 Kuang Fu Rd, Hsinchu 300, Taiwan.
C3 National Tsing Hua University
RP Fan, CL (corresponding author), Natl Tsing Hua Univ, 101 Sec 2 Kuang Fu Rd, Hsinchu 300, Taiwan.
EM ch.ling.fan@gmail.com; tsehou.nthu@gmail.com; chsu@cs.nthu.edu.tw
FU Ministry of Science and Technology of Taiwan [107-2221-E-007-091-MY3];
   NOVATEK Fellowship
FX This work was partially supported by the Ministry of Science and
   Technology of Taiwan (#107-2221-E-007-091-MY3) and by a NOVATEK
   Fellowship.
CR [Anonymous], 2012, 2300912012 ISO
   [Anonymous], 2009, Cambridge University Press, DOI DOI 10.1017/CBO9780511815867
   [Anonymous], 2017, JTC1SC29WG11N17197 I
   Anwar MS, 2020, IEEE ACCESS, V8, P204585, DOI 10.1109/ACCESS.2020.3037253
   Anwar MS, 2020, IEEE ACCESS, V8, P148084, DOI 10.1109/ACCESS.2020.3015556
   Aroussi S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P200, DOI 10.1109/ComManTel.2014.6825604
   Awad M., 2015, Neural Information Processing-Letters and Reviews, P67, DOI [DOI 10.1007/978-1-4302-5990-94, 10.1007/978-1-4302-5990-9_4, DOI 10.1007/978-1-4302-5990-9_4]
   Bessa Maximino, 2016, P INT C HUM COMP INT
   Bouraqia K, 2020, IEEE ACCESS, V8, P13341, DOI 10.1109/ACCESS.2020.2965099
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   BUSH LK, 1993, PSYCHOL BULL, V113, P566, DOI 10.1037/0033-2909.113.3.566
   Channappayya Sumohana S., 2008, P IEEE INT C AC SPEE
   Croci S, 2019, INT WORK QUAL MULTIM
   Croci Simone, 2020, QUAL USER EXP, V5, DOI DOI 10.1007/S41233-020-00032-3
   Egan D, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Fan CL, 2021, IEEE T CIRC SYST VID, V31, P1632, DOI 10.1109/TCSVT.2020.3007288
   Fan CL, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329119
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Fremerey S, 2020, IEEE INT WORKSH MULT, DOI 10.1109/MMSP48831.2020.9287065
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Hakkinen Jukka, 2002, IEEE INT C SYST MAN, V1
   Hossfeld T., 2016, Quality and User Experience, V1, P1, DOI [10.1007/S41233-016-0002-1, DOI 10.1007/S41233-016-0002-1, 10.1007/s41233-016-0002-1]
   Hsu Chih-Fan, 2017, P ACM INT C MULT
   HTC Co, 2019, VIVE DISC VIRT REAL
   HTC Corporation, 2020, VIV PRO EYE
   HTC Corporation, 2020, EYE TRACK SDK SRANIP
   Huang MK, 2018, IEEE T IMAGE PROCESS, V27, P6039, DOI 10.1109/TIP.2018.2865089
   ITU, 2019, JVET JOINT VID EXP T
   ITU COM 9-80-E, 2000, 980E2000 COM ITU
   ITU Telecommunication Standardization Sector, 2008, ITU T RECOMMENDATION
   ITU Telecommunication Standardization Sector, 1999, ITU T RECOMMENDATION
   ITU Telecommunication Standardization Sector, 2016, ITU T RECOMMENDATION
   John B, 2019, INT J SEMANT COMPUT, V13, P329, DOI 10.1142/S1793351X19400142
   Juluri P, 2016, IEEE COMMUN SURV TUT, V18, P401, DOI 10.1109/COMST.2015.2401424
   Jumisko-Pyykkö S, 2010, INT J MOB HUM COMPUT, V2, P1, DOI 10.4018/jmhci.2010100101
   Kempf Marina, 2018, P IEEE INT C QUAL MU
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Ketyko Istvan, 2010, P WORKSH MOB VID DEL
   Kim HG, 2019, IEEE T IMAGE PROCESS, V28, P1646, DOI 10.1109/TIP.2018.2880509
   Kim J, 2018, INT WORK QUAL MULTIM, P13
   Lee TM, 2019, IEEE T VIS COMPUT GR, V25, P1919, DOI 10.1109/TVCG.2019.2899186
   LLC, 2019, OCULUS VR
   Lo WC, 2017, ASIA-PAC NETW OPER M, P205, DOI 10.1109/APNOMS.2017.8094203
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   MATLAB 2020, MATLAB MATHWORKS
   Misra K, 2013, IEEE J-STSP, V7, P969, DOI 10.1109/JSTSP.2013.2271451
   Moller S, 2014, T-LAB SER TELECOMMUN, P1, DOI 10.1007/978-3-319-02681-7
   Nardi Bonnie A., 1995, Context and Consciousness: Activity Theory and Human-computer Interaction, P69
   Netflix Inc, 2019, VMAF VID MULT ASS FU
   Netflix Inc, 2016, NFLX DAT
   nmsl nthu, 2020, QOE MOD 360 DEGR VID
   Orduna M, 2020, IEEE T CONSUM ELECTR, V66, P22, DOI 10.1109/TCE.2019.2957987
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Pedregosa F, 2011, J. Mach. Learn. Res., V12, P2825
   Raake Alexander, 2020, P IEEE C VIRT REAL 3
   Rahman MA, 2011, IEEE T INSTRUM MEAS, V60, P345, DOI 10.1109/TIM.2010.2084190
   Rai Y, 2017, INT WORK QUAL MULTIM
   Regal Georg, 2018, QOMEX
   Reiter U, 2014, T-LAB SER TELECOMMUN, P55, DOI 10.1007/978-3-319-02681-7_4
   SHIFFLER RE, 1988, AM STAT, V42, P79, DOI 10.2307/2685269
   Singla A, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P232, DOI 10.1145/3304109.3306218
   Singla A, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P511, DOI 10.1145/3126686.3126768
   Singla A, 2017, INT WORK QUAL MULTIM
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Song Wei., 2015, P ACM INT C MULT MM
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Tcha-Tokey K, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927955
   Trejkaz, 2020, EQ ANG CUB SKYB UN
   Tucker Izabela., 2011, THESIS U BERLIN GERM
   Unity, 2020, UNITY
   Unity Technologies, 2020, STEAMVR PLUG
   Upenik E, 2017, INT WORK QUAL MULTIM
   Upenik E, 2016, PICT COD SYMP
   Varela M, 2014, T-LAB SER TELECOMMUN, P85, DOI 10.1007/978-3-319-02681-7_6
   Viitanen M, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1179, DOI 10.1145/2964284.2973796
   Vlahovic Sara, 2018, P IEEE INT C QUAL MU
   Wang Hui, 2014, P ACM WORKSH NETW OP
   Weier M, 2016, COMPUT GRAPH FORUM, V35, P289, DOI 10.1111/cgf.13026
   WEYMOUTH FW, 1958, AM J OPHTHALMOL, V46, P102, DOI 10.1016/0002-9394(58)90042-4
   Xie L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P315, DOI 10.1145/3123266.3123291
   Xie SW, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350961
   Yao SH, 2019, INT WORK QUAL MULTIM
   Yu Matt, 2015, P ACM INT IMM MED EX
NR 83
TC 4
Z9 5
U1 3
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2022
VL 18
IS 1
AR 3
DI 10.1145/3463825
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5OX
UT WOS:000772636900003
DA 2024-07-18
ER

PT J
AU Song, YG
   Gao, JY
   Yang, XS
   Xu, CS
AF Song, Yaguang
   Gao, Junyu
   Yang, Xiaoshan
   Xu, Changsheng
TI Learning Hierarchical Video Graph Networks for One-Stop Video Delivery
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Cross modal; video retrieval; deep learning; graph neural networks
ID LANGUAGE; TEXT; VISION; MODEL
AB The explosive growth of video data has brought great challenges to video retrieval, which aims to find out related videos from a video collection. Most users are usually not interested in all the content of retrieved videos but have a more fine-grained need. In the meantime, most existing methods can only return a ranked list of retrieved videos lacking a proper way to present the video content. In this paper, we introduce a distinctively new task, namely One-Stop Video Delivery (OSVD) aiming to realize a comprehensive retrieval system with the following merits: it not only retrieves the relevant videos but also filters out irrelevant information and presents compact video content to users, given a natural language query and video collection. To solve this task, we propose an end-to-end Hierarchical Video Graph Reasoning framework (HVGR), which considers relations of different video levels and jointly accomplishes the one-stop delivery task. Specifically, we decompose the video into three levels, namely the video-level, moment-level, and the clip-level in a coarse-to-fine manner, and apply Graph Neural Networks (GNNs) on the hierarchical graph to model the relations. Furthermore, a pairwise ranking loss named Progressively Refined Loss is proposed based on prior knowledge that there is a relative order of the similarity of query-video, query-moment, and query-clip due to the different granularity of matched information. Extensive experimental results on benchmark datasets demonstrate that the proposed method achieves superior performance compared with baseline methods.
C1 [Song, Yaguang; Gao, Junyu; Yang, Xiaoshan; Xu, Changsheng] Chinese Acad Sci CASIA, Univ Chinese Acad Sci UCAS, Natl Lab Pattern Recognit, Inst Automat,Sch Artificial Intelligence, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   [Yang, Xiaoshan; Xu, Changsheng] Peng Cheng Lab, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Song, YG (corresponding author), Chinese Acad Sci CASIA, Univ Chinese Acad Sci UCAS, Natl Lab Pattern Recognit, Inst Automat,Sch Artificial Intelligence, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
EM songyaguang2019@ia.ac.cn; gaojunyu@ia.ac.cn;
   xiaoshan.yang@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn
RI Song, Yaguang/JOZ-6925-2023; Gao, Junyu/HDO-5516-2022; xu,
   cj/HJZ-3488-2023; Xu, Chang/GQP-7280-2022
OI Song, Yaguang/0000-0002-9300-8110; Yang, Xiaoshan/0000-0001-5453-9755
FU National Key Research and Development Program of China [2018AAA0100604];
   National Natural Science Foundation of China [61720106006, 62036012,
   61721004, 62072455, U1836220, U1705262]; Key Research Program of
   Frontier Sciences of CAS [QYZDJ-SSW-JSC039]; Beijing Natural Science
   Foundation [L201001]
FX This work was supported by National Key Research and Development Program
   of China (No. 2018AAA0100604), National Natural Science Foundation of
   China (No. 61720106006, 62036012, 61721004, 62072455, U1836220,
   U1705262), Key Research Program of Frontier Sciences of CAS
   (QYZDJ-SSW-JSC039), Beijing Natural Science Foundation (L201001),
   CASIA-LLVision Joint Lab.
CR An-An Liu, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Chen S., 2020, P IEEE CVF C COMP VI, P10638
   Cheng Q, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1452546
   Chunxi Liu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2449, DOI 10.1109/ICIP.2011.6116155
   Dong JF, 2019, PROC CVPR IEEE, P9338, DOI 10.1109/CVPR.2019.00957
   Dong JF, 2018, IEEE T MULTIMEDIA, V20, P3377, DOI 10.1109/TMM.2018.2832602
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Escorcia V., 2019, ARXIV PREPRINT ARXIV
   Faghri Fartash, 2017, ARXIV170705612
   Fan HH, 2020, AAAI CONF ARTIF INTE, V34, P10754
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fan HH, 2017, IEEE I CONF COMP VIS, P736, DOI 10.1109/ICCV.2017.86
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gao JY, 2017, IEEE I CONF COMP VIS, P5277, DOI 10.1109/ICCV.2017.563
   Gao JY, 2021, IEEE T PATTERN ANAL, V43, P3476, DOI 10.1109/TPAMI.2020.2985708
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Gao JY, 2019, AAAI CONF ARTIF INTE, P8303
   Gao Y, 2009, MULTIMED TOOLS APPL, V42, P233, DOI 10.1007/s11042-008-0236-x
   Gao YL, 2009, IEEE IMAGE PROC, P4333
   Ge RZ, 2019, IEEE WINT CONF APPL, P245, DOI 10.1109/WACV.2019.00032
   Ghosh S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1984
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   Gygli M, 2016, PROC CVPR IEEE, P1001, DOI 10.1109/CVPR.2016.114
   He DL, 2019, AAAI CONF ARTIF INTE, P8393
   Hendricks LA, 2017, IEEE I CONF COMP VIS, P5804, DOI 10.1109/ICCV.2017.618
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu RH, 2019, IEEE I CONF COMP VIS, P10293, DOI 10.1109/ICCV.2019.01039
   Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645
   Ji Z, 2020, IEEE T CIRC SYST VID, V30, P1709, DOI 10.1109/TCSVT.2019.2904996
   Jiang B, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P217, DOI 10.1145/3323873.3325019
   Jiao YF, 2018, IEEE T MULTIMEDIA, V20, P2693, DOI 10.1109/TMM.2018.2815998
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kim H, 2018, IEEE T MULTIMEDIA, V20, P2415, DOI 10.1109/TMM.2018.2806224
   Kipf TN, 2017, INT C LEARN REPR
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Liu M, 2018, ACM/SIGIR PROCEEDINGS 2018, P15, DOI 10.1145/3209978.3210003
   Liu W., 2019, Neural Inf. Process. Syst., P536
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mei T., 2015, PROC CVPR IEEE, P3707
   Min WQ, 2017, IEEE T MULTIMEDIA, V19, P1100, DOI 10.1109/TMM.2016.2639382
   Mithun NC, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/3206025.3206064
   Niu K, 2019, MULTIMED TOOLS APPL, V78, P21133, DOI 10.1007/s11042-019-7442-6
   Ou WH, 2020, MULTIMED TOOLS APPL, V79, P14733, DOI 10.1007/s11042-019-7343-8
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Rochan M, 2019, PROC CVPR IEEE, P7894, DOI 10.1109/CVPR.2019.00809
   Rodriguez-Opazo C, 2020, IEEE WINT CONF APPL, P2453, DOI [10.1109/WACV45572.2020.9093328, 10.1109/wacv45572.2020.9093328]
   Shao D, 2018, LECT NOTES COMPUT SC, V11213, P202, DOI 10.1007/978-3-030-01240-3_13
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song Y, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P659, DOI 10.1145/2983323.2983349
   Vasudevan AB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P582, DOI 10.1145/3123266.3123297
   Velickovic Petar, 2017, ARXIV171010903, DOI DOI 10.48550/ARXIV.1710.10903
   Wang Jiayun, 2019, ARXIV PREPRINT ARXIV
   Wang P, 2019, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2019.00206
   Wang X, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2022, DOI 10.1145/3308558.3313562
   Wei HW, 2018, AAAI CONF ARTIF INTE, P216
   Xu HJ, 2019, AAAI CONF ARTIF INTE, P9062
   Xu K., 2018, P INT C LEARN REPR
   Xu N, 2020, IEEE T MULTIMEDIA, V22, P1372, DOI 10.1109/TMM.2019.2941820
   Xu R, 2015, AAAI CONF ARTIF INTE, P2346
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yu Y, 2018, LECT NOTES COMPUT SC, V11211, P487, DOI 10.1007/978-3-030-01234-2_29
   Yuan YT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2332, DOI 10.1145/3343031.3350985
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zhang BW, 2018, LECT NOTES COMPUT SC, V11217, P385, DOI 10.1007/978-3-030-01261-8_23
   Zhang D, 2019, PROC CVPR IEEE, P1247, DOI 10.1109/CVPR.2019.00134
   Zhang K, 2018, LECT NOTES COMPUT SC, V11212, P391, DOI 10.1007/978-3-030-01237-3_24
   Zhang S., 2019, ARXIV PREPRINT ARXIV
   Zhang SY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1230, DOI 10.1145/3343031.3350879
   Zhang WG, 2014, MULTIMED TOOLS APPL, V73, P547, DOI 10.1007/s11042-013-1607-5
   Zhang Y., 2017, ARXIV PREPRINT ARXIV
   Zhang Y., 2018, ARXIV PREPRINT ARXIV
   Zhang YJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040750
   Zhang Z, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P655, DOI 10.1145/3331184.3331235
   Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773
   Zhou Jie, 2018, arXiv preprint arXiv:1812.08434
NR 80
TC 0
Z9 0
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2022
VL 18
IS 1
AR 10
DI 10.1145/3466886
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5OX
UT WOS:000772636900010
DA 2024-07-18
ER

PT J
AU Chen, YZ
   Hu, HF
AF Chen, Yizhen
   Hu, Haifeng
TI Y-Net: Dual-branch Joint Network for Semantic Segmentation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE "U-shaped" structure; Y-net; dual-branch; semantic enhancing module;
   channel-selective decoder
AB Most existing segmentation networks are built upon a "U-shaped" encoder-decoder structure, where the multi-level features extracted by the encoder are gradually aggregated by the decoder. Although this structure has been proven to be effective in improving segmentation performance, there are two main drawbacks. On the one hand, the introduction of low-level features brings a significant increase in calculations without an obvious performance gain. On the other hand, general strategies of feature aggregation such as addition and concatenation fuse features without considering the usefulness of each feature vector, which mixes the useful information with massive noises. In this article, we abandon the traditional "U-shaped" architecture and propose Y-Net, a dual-branch joint network for accurate semantic segmentation. Specifically, it only aggregates the high-level features with low-resolution and utilizes the global context guidance generated by the first branch to refine the second branch. The dual branches are effectively connected through a Semantic Enhancing Module, which can be regarded as the combination of spatial attention and channel attention. We also design a novel Channel-Selective Decoder (CSD) to adaptively integrate features from different receptive fields by assigning specific channelwise weights, where the weights are input-dependent. Our Y-Net is capable of breaking through the limit of singe-branch network and attaining higher performance with less computational cost than "U-shaped" structure. The proposed CSD can better integrate useful information and suppress interference noises. Comprehensive experiments are carried out on three public datasets to evaluate the effectiveness of our method. Eventually, our Y-Net achieves state-of-the-art performance on PASCAL VOC 2012, PASCAL Person-Part, and ADE20K dataset without pre-training on extra datasets.
C1 [Chen, Yizhen; Hu, Haifeng] Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Hu, HF (corresponding author), Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM chenyzh28@mail2.sysu.edu.cn; huhaif@mail.sysu.edu.cn
OI Hu, Haifeng/0000-0002-4884-323X
FU National Natural Science Foundation of China [62076262, 61673402,
   61273270, 60802069]; Natural Science Foundation of Guangdong Province
   [2017A030311029]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62076262, Grant 61673402, Grant
   61273270, and Grant 60802069 and in part by the Natural Science
   Foundation of Guangdong Province under Grant 2017A030311029.
CR Ahn I, 2016, IEEE T MULTIMEDIA, V18, P1414, DOI 10.1109/TMM.2016.2551698
   [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2011, ADV NEURAL INF PROCE
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254
   Chen YZ, 2020, NEURAL PROCESS LETT, V51, P1081, DOI 10.1007/s11063-019-10129-2
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang Y, 2019, IEEE ASME INT C ADV, P30, DOI [10.1109/AIM.2019.8868787, 10.1109/aim.2019.8868787]
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   GILBERT CD, 1992, NATURE, V356, P150, DOI 10.1038/356150a0
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huo SW, 2018, IEEE T MULTIMEDIA, V20, P1350, DOI 10.1109/TMM.2017.2769801
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Li H., 2018, ARXIV
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   PETTET MW, 1992, P NATL ACAD SCI USA, V89, P8366, DOI 10.1073/pnas.89.17.8366
   Poudel R. P., 2018, ARXIV180504554
   Qin Huang, 2017, ARXIV PREPRINT ARXIV
   Qiurui Wang, 2019, IEEE Transactions on Multimedia, V21, P1839, DOI 10.1109/TMM.2018.2890360
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K., 2014, 14091556 ARXIV
   Spillmann L, 2015, J VISION, V15, DOI 10.1167/15.9.7
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang WG, 2016, IEEE T MULTIMEDIA, V18, P1011, DOI 10.1109/TMM.2016.2545409
   Xia FT, 2016, LECT NOTES COMPUT SC, V9909, P648, DOI 10.1007/978-3-319-46454-1_39
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang PP, 2019, PATTERN RECOGN, V88, P702, DOI 10.1016/j.patcog.2018.12.021
   Zhang ZY, 2016, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2016.79
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
NR 55
TC 4
Z9 4
U1 2
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2021
VL 17
IS 4
AR 137
DI 10.1145/3460940
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP8GI
UT WOS:000748857800021
DA 2024-07-18
ER

PT J
AU Shen, XJ
   Zhou, JH
   Ma, ZC
   Bao, BK
   Zha, ZJ
AF Shen, Xiangjun
   Zhou, Jinghui
   Ma, Zhongchen
   Bao, Bingkun
   Zha, Zhengjun
TI Cross-Domain Object Representation via Robust Low-Rank Correlation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Cross-domain; object representation; low-rank; correlation analysis
ID CANONICAL CORRELATION-ANALYSIS; SUBSPACE; RECOGNITION
AB Cross-domain data has become very popular recently since various viewpoints and different sensors tend to facilitate better data representation. In this article, we propose a novel cross-domain object representation algorithm (RLRCA) which not only explores the complexity of multiple relationships of variables by canonical correlation analysis (CCA) but also uses a low rank model to decrease the effect of noisy data. To the best of our knowledge, this is the first try to smoothly integrate CCA and a low-rank model to uncover correlated components across different domains and to suppress the effect of noisy or corrupted data. In order to improve the flexibility of the algorithm to address various cross-domain object representation problems, two instantiation methods of RLRCA are proposed from feature and sample space, respectively. In this way, a better cross-domain object representation can be achieved through effectively learning the intrinsic CCA features and taking full advantage of cross-domain object alignment information while pursuing low rank representations. Extensive experimental results on CMU PIE, Office-Caltech, Pascal VOC 2007, and NUS-WIDE-Object datasets, demonstrate that our designed models have superior performance over several state-of-the-art cross-domain low rank methods in image clustering and classification tasks with various corruption levels.
C1 [Shen, Xiangjun; Zhou, Jinghui; Ma, Zhongchen] Jiangsu Univ, Sch Comp Sci & Commun Engn, 301 Xuefu Rd, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Bao, Bingkun] Nanjing Univ Posts & Telecommun, Sch Telecommun & Informat Engn, 9 Wenyuan Rd, Nanjing 210023, Jiangsu, Peoples R China.
   [Zha, Zhengjun] Univ Sci & Technol China, Sch Informat Sci & Technol, 443 Huangshan Rd, Hefei 230027, Anhui, Peoples R China.
C3 Jiangsu University; Nanjing University of Posts & Telecommunications;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zha, ZJ (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, 443 Huangshan Rd, Hefei 230027, Anhui, Peoples R China.
EM xjshen@ujs.edu.cn; 937422126@qq.com; zhongchen_ma@ujs.edu.cn;
   bingkunbao@njupt.edu.cn; zhazj@ustc.edu.cn
RI Zha, Zheng-Jun/AAF-8667-2020; Ma, Zhongchen/AAA-4180-2020
OI Ma, Zhongchen/0000-0002-6646-7370
FU National Key Research and Development Program of China [2020AAA0105702];
   National Natural Science Foundation of China [61572240, 61872424,
   6193000388, U19B2038]; Primary Research and Development Plan of Jiangsu
   Province [BE2018627]
FX This work was funded by National Key Research and Development Program of
   China under Grant No. 2020AAA0105702, National Natural Science
   Foundation of China under Grants No. 61572240, 61872424, 6193000388,
   U19B2038, and the Primary Research and Development Plan of Jiangsu
   Province under Grant No. BE2018627.
CR Abeo TA, 2019, PATTERN RECOGN, V90, P1, DOI 10.1016/j.patcog.2019.01.012
   Akaho Shotaro, 2006, ARXIV
   Andrew G., 2013, P ICML, P1247
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2008, Proceedings of the 25th international conference on Machine learning
   Bai C, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102835
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Brbic M, 2018, PATTERN RECOGN, V73, P247, DOI 10.1016/j.patcog.2017.08.024
   Cai D, 2007, IEEE I CONF COMP VIS, P214
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chandrasekaran V, 2012, FOUND COMPUT MATH, V12, P805, DOI 10.1007/s10208-012-9135-7
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   Ding ZM, 2016, AAAI CONF ARTIF INTE, P1181
   Dorfer M, 2018, INT J MULTIMED INF R, V7, P117, DOI 10.1007/s13735-018-0151-5
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Hardoon D. R., 2003, P INT WORKSH CONT BA, P22
   Hardoon DR, 2011, MACH LEARN, V83, P331, DOI 10.1007/s10994-010-5222-7
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591
   Li W, 2018, IEEE T PATTERN ANAL, V40, P1114, DOI 10.1109/TPAMI.2017.2704624
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu J, 2013, INT SYMP ASYNCHRON C, P1, DOI 10.1109/ASYNC.2013.29
   Liu JW, 2019, PROC CVPR IEEE, P7195, DOI 10.1109/CVPR.2019.00737
   Liu JM, 2014, IEEE T IMAGE PROCESS, V23, P4022, DOI 10.1109/TIP.2014.2343458
   Lu CY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2380155
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Samat A, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040337
   Shen XJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107023
   Shen XB, 2015, NEUROCOMPUTING, V148, P397, DOI 10.1016/j.neucom.2014.06.015
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Sun SL, 2011, INT J PATTERN RECOGN, V25, P1113, DOI 10.1142/S0218001411008981
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Wang W, 2007, LECT NOTES ARTIF INT, V4701, P454
   WangWei Zhi Hua, 2010, P 27 INT C MACH LEAR
   Wei CP, 2014, IEEE T IMAGE PROCESS, V23, P3294, DOI 10.1109/TIP.2014.2329451
   Witten DM, 2009, BIOSTATISTICS, V10, P515, DOI 10.1093/biostatistics/kxp008
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2149
   Xu C, 2013, ARXIV PREPRINT ARXIV
   Xu C, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2490539
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Zha ZJ, 2020, IEEE T NEUR NET LEAR, V31, P2398, DOI 10.1109/TNNLS.2020.2967471
   Zhang B, 2013, IEEE INT CONF BIG DA, DOI 10.1109/BigData.2013.6691612
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
   Zhou P., 2020, IEEE INTERNET THINGS, V2020, P1, DOI [10.1109/JIOT.2020.2996009, DOI 10.1109/JIOT.2020.2996009]
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 51
TC 0
Z9 0
U1 2
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2021
VL 17
IS 4
AR 126
DI 10.1145/3458825
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP8GI
UT WOS:000748857800010
DA 2024-07-18
ER

PT J
AU Amato, F
   Casola, V
   Cozzolino, G
   Benedictis, AD
   Mazzocca, NI
   Moscato, F
AF Amato, Flora
   Casola, Valentina
   Cozzolino, Giovanni
   Benedictis, Alessandra De
   Mazzocca, N. Icola
   Moscato, Francesco
TI A Security and Privacy Validation Methodology for e-Health Systems
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE e-Health management systems; security and privacy for e-Health data;
   security and privacy validation; formal methods for security validation
ID MODEL-CHECKING; VERIFICATION
AB e-Health applications enable one to acquire, process, and share patient medical data to improve diagnosis, treatment, and patient monitoring. Despite the undeniable benefits brought by the digitization of health systems, the transmission of and access to medical information raises critical issues, mainly related to security and privacy. While several security mechanisms exist that can be applied in an e-Health system, they may not be adequate due to the complexity of involved workflows, and to the possible inherent correlation among health-related concepts that may be exploited by unauthorized subjects. In this article, we propose a novel methodology for the validation of security and privacy policies in a complex e-Health system, that leverages a formal description of clinical workflows and a semantically enriched definition of the data model used by the workflows, in order to build a comprehensive model of the system that can be analyzed with automated model checking and ontology-based reasoning techniques. To validate the proposed methodology, we applied it to two case studies, subjected to the directives of the EU GDPR regulation for the protection of health data, and demonstrated its ability to correctly verify the fulfillment of desired policies in different scenarios.
C1 [Amato, Flora; Casola, Valentina; Cozzolino, Giovanni; Benedictis, Alessandra De; Mazzocca, N. Icola] Univ Naples Federico II, Dept Elect Engn & Informat Technol, Via Claudio 21, I-80125 Naples, NA, Italy.
   [Moscato, Francesco] Univ Salerno, Dept Informat Technol & Elect Engn & Appl Math, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
C3 University of Naples Federico II; University of Salerno
RP Amato, F (corresponding author), Univ Naples Federico II, Dept Elect Engn & Informat Technol, Via Claudio 21, I-80125 Naples, NA, Italy.
EM flora.amato@unina.it; casolav@unina.it; giovanni.cozzolino@unina.it;
   alessandra.debenedictis@unina.it; nicola.mazzocca@unina.it;
   francesco.moscato@unicampania.it
RI Casola, Valentina/I-6967-2013; Amato, Flora/N-1408-2016
OI Amato, Flora/0000-0002-5128-5558
CR Abu Jabal A, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295749
   ALUR R, 1994, THEOR COMPUT SCI, V126, P183, DOI 10.1016/0304-3975(94)90010-8
   ALUR R, 1993, INFORM COMPUT, V104, P2, DOI 10.1006/inco.1993.1024
   Amato F, 2020, IEEE INTERNET THINGS, V7, P4655, DOI 10.1109/JIOT.2019.2960316
   Asim M, 2018, J SOFTW-EVOL PROC, V30, DOI 10.1002/smr.1944
   Basin D, 2015, J ACM, V62, DOI 10.1145/2699444
   Behrmann G, 2004, LECT NOTES COMPUT SC, V3185, P200
   Ben Attia H, 2020, INT J INF SECUR, V19, P163, DOI 10.1007/s10207-019-00448-9
   Chenthara S, 2019, IEEE ACCESS, V7, P74361, DOI 10.1109/ACCESS.2019.2919982
   Choi J, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, MINING AND SEMANTICS (WIMS 2019), DOI 10.1145/3326467.3326496
   Croll PR, 2011, INT J MED INFORM, V80, pE32, DOI 10.1016/j.ijmedinf.2010.10.006
   Cuomo Salvatore, 2018, INT C NETW BAS INF S, P944
   Farahani B, 2020, MICROPROCESS MICROSY, V72, DOI 10.1016/j.micpro.2019.102938
   Gouglidis A, 2014, INT J INF SECUR, V13, P97, DOI 10.1007/s10207-013-0205-x
   Guerriero M, 2018, 2018 IEEE/ACM 13TH INTERNATIONAL SYMPOSIUM ON SOFTWARE ENGINEERING FOR ADAPTIVE AND SELF-MANAGING SYSTEMS (SEAMS), P172, DOI 10.1145/3194133.3194140
   Hathaliya JJ, 2020, COMPUT COMMUN, V153, P311, DOI 10.1016/j.comcom.2020.02.018
   Hu VC, 2016, PROCEEDINGS OF 2016 IEEE 17TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI), P315, DOI 10.1109/IRI.2016.49
   Hu VC, 2011, INT J SOFTW ENG KNOW, V21, P103, DOI 10.1142/S021819401100513X
   Khan FA, 2019, J AMB INTEL HUM COMP, V10, P3795, DOI 10.1007/s12652-019-01292-4
   Ma J., 2010, Proceedings of the 2010 Second International Workshop on Intelligent Systems and Applications (ISA), P1, DOI [10.1109/IWISA.2010.5473291, DOI 10.1109/IWISA.2010.5473291]
   Mehmood I, 2019, INT J INFORM MANAGE, V45, P246, DOI 10.1016/j.ijinfomgt.2018.10.020
   Mens T, 2006, ELECTRON NOTES THEOR, V152, P125, DOI 10.1016/j.entcs.2005.10.021
   Mondal S, 2011, COMPUT SECUR, V30, P128, DOI 10.1016/j.cose.2010.09.002
   Piccialli F, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4700
   Ranchal R, 2019, IEEE T SERV COMPUT, V12, P415, DOI 10.1109/TSC.2018.2797277
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   van der Aalst WMP, 2012, SOFTW SYST MODEL, V11, P319, DOI 10.1007/s10270-012-0233-4
NR 27
TC 8
Z9 8
U1 1
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2021
VL 17
IS 2
SU S
SI SI
AR 67
DI 10.1145/3412373
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TA7ZH
UT WOS:000667464100009
DA 2024-07-18
ER

PT J
AU Rossi, S
   Ozcinar, C
   Smolic, A
   Toni, L
AF Rossi, Silvia
   Ozcinar, Cagri
   Smolic, Aljosa
   Toni, Laura
TI Do Users Behave Similarly in VR? Investigation of the User Influence on
   the System Design
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Omnidirectional video dataset; user behaviour analysis; integer linear
   program; viewport-based adaptive streaming
AB With the overarching goal of developing user-centric Virtual Reality (VR) systems, a new wave of studies focused on understanding how users interact in VR environments has recently emerged. Despite the intense efforts, however, current literature still does not provide the right framework to fully interpret and predict users' trajectories while navigating in VR scenes. This work advances the state-of-the-art on both the study of users' behaviour in VR and the user-centric system design. In more detail, we complement current datasets by presenting a publicly available dataset that provides navigation trajectories acquired for heterogeneous omnidirectional videos and different viewing platforms-namely, head-mounted display, tablet, and laptop. We then present an exhaustive analysis on the collected data to better understand navigation in VR across users, content, and, for the first time, across viewing platforms. The novelty lies in the user-affinity metric, proposed in this work to investigate users' similarities when navigating within the content. The analysis reveals useful insights on the effect of device and content on the navigation, which could be precious considerations from the system design perspective. As a case study of the importance of studying users' behaviour when designing VR systems, we finally propose a user-centric server optimisation. We formulate an integer linear program that seeks the best stored set of omnidirectional content that minimises encoding and storage cost while maximising the user's experience. This is posed while taking into account network dynamics, type of video content, and also user population interactivity. Experimental results prove that our solution outper-forms common company recommendations in terms of experienced quality but also in terms of encoding and storage, achieving a savings up to 70%. More importantly, we highlight a strong correlation between the storage cost and the user-affinity metric, showing the impact of the latter in the system architecture design.
C1 [Rossi, Silvia; Toni, Laura] Univ Coll London UCL, London, England.
   [Ozcinar, Cagri; Smolic, Aljosa] Trinity Coll Dublin TCD, Dublin, Ireland.
C3 University of London; University College London; Trinity College Dublin
RP Rossi, S (corresponding author), Univ Coll London UCL, London, England.
EM s.rossi@ucl.ac.uk; ozcitinrc@scss.tcd.ie; smolica@scss.tcd.ie;
   l.toni@ucl.ac.uk
OI Rossi, Silvia/0000-0002-2779-2314
FU Adobe under Academic Donation scheme; Science Foundation Ireland (SFI)
   [15/RP/2776]
FX This work has been partially funded by Adobe under Academic Donation
   scheme. Also, this publication has emanated from research supported in
   part by a research grant from Science Foundation Ireland (SFI) under the
   Grant Number 15/RP/2776.
CR Almquist M, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P258, DOI 10.1145/3204949.3204970
   Amazon, 2019, EL TRANSC PRIC
   Amazon, 2019, CLOUD STOR PRIC
   [Anonymous], SALIENT360 VIS ATT M
   [Anonymous], P ACM C HUM FACT COM
   [Anonymous], 2013, ILOG CPLEX OPT STUD
   Apple, 2018, HLS AUTH SPEC APPL D
   Carvalho Marcelo M., 2019, P 10 ACM MULT SYST C
   Chao FY, 2018, IEEE INT CONF MULTI
   Corbillon X, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P943, DOI 10.1145/3123266.3123372
   Corbillon X, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P199, DOI 10.1145/3083187.3083215
   Croci Simone, 2019, P IEEE 11 INT C QUAL
   David EJ, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P432, DOI 10.1145/3204949.3208139
   De Abreu Ana, 2017, P 9 INT C QUAL MULT
   De Simone Francesca, 2019, ELECT IMAG, V2019, P12
   Duanmu F, 2018, IEEE INT CON MULTI
   Fan CL, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329119
   Fearghail CO, 2018, 2018 INTERNATIONAL CONFERENCE ON 3D IMMERSION (IC3D), DOI 10.1109/IC3D.2018.8657901
   Fearghail Colm O., 2018, STORYTELLING
   Fei Q, 2020, J MOL CELL CARDIOL, V145, P1, DOI 10.1016/j.yjmcc.2020.05.016
   Fremerey S, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P403, DOI 10.1145/3204949.3208134
   Graf M, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P261, DOI 10.1145/3083187.3084016
   Harth J, 2018, IEEE CONSUM ELECTR M, V7, P36, DOI 10.1109/MCE.2018.2816218
   ITU-T, 2008, SUBJ VID QUAL ASS ME
   Jacob Chakareski, 2018, P IEEE INT C COMM IC
   Knorr Sebastian, 2018, P 15 ACM SIGGRAPH EU
   Li C, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P932, DOI 10.1145/3240508.3240581
   Lo WC, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P211, DOI 10.1145/3083187.3083219
   Loschky LC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142474
   Mahzari A., 2018, P 26 ACM INT C MULT
   Maniotis Pantelis, 2019, IEEE T MULTIMEDIA, V2019, P12
   Misra K, 2013, IEEE J-STSP, V7, P969, DOI 10.1109/JSTSP.2013.2271451
   MulticoreWare Inc, 2018, X265 HEVC ENC H 265
   Netflix, 2015, PerTitle Encode Optimization
   Nguyen DV, 2019, IEEE J EM SEL TOP C, V9, P29, DOI 10.1109/JETCAS.2019.2899488
   Niamut OA, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P46, DOI 10.1145/2910017.2910606
   Ohm J.-R., 2011, JTC1SC29WG11 ISOIEC
   Ozcinar Cagri, 2017, P IEEE INT S MULT IS
   Ozcinar Cagri, 2019, IEEE J EMERG SELECT, V9, P1
   Ozcinar Cagri, 2017, P IEEE INT C IM PROC
   Ozcinar Cagri, 2018, P IEEE 10 INT C QUAL
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Petrangeli S., 2018, P IEEE INT C ART INT
   Ramey MM, 2019, COGNITION, V185, P71, DOI 10.1016/j.cognition.2019.01.007
   Rossi S, 2017, IEEE INT WORKSH MULT
   Rossi Silvia, 2019, P IEEE INT C AC SPEE
   Rubio-Tamayo Jose Luis, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040021
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Sun Yule, 2017, IEEE SIGNAL PROC LET, V24, P9
   Timmerer C., 2017, IEEE COMMUN STAND MA, V1, P4
   Toni Laura, 2015, ACM T MULTIM COMPUT, V11, p2s
   Tse Audrey, 2017, P ACM C HUM FACT COM
   Wu CL, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P193, DOI 10.1145/3083187.3083210
   Xiao Mengbai, 2017, P 25 ACM INT C MULT
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
   Yu Matt, 2015, P IEEE INT S MIX AUG
   Zhang ZH, 2018, LECT NOTES COMPUT SC, V11211, P504, DOI 10.1007/978-3-030-01234-2_30
NR 58
TC 11
Z9 11
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2020
VL 16
IS 2
AR 46
DI 10.1145/3381846
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1EO
UT WOS:000583710600007
OA Green Published
DA 2024-07-18
ER

PT J
AU Chaudhary, C
   Goyal, P
   Goyal, N
   Chen, YPP
AF Chaudhary, Chandramani
   Goyal, Poonam
   Goyal, Navneet
   Chen, Yi-Ping Phoebe
TI Image Retrieval for Complex Queries Using Knowledge Embedding
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; query expansion; knowledge base; knowledge embedding;
   diversity; ambiguous query; complex query
ID WEB; SEARCH
AB With the increase in popularity of image-based applications, users are retrieving images using more sophisticated and complex queries. We present three types of complex queries, namely, long, ambiguous, and abstract. Each type of query has its own characteristics/complexities and thus leads to imprecise and incomplete image retrieval. Existing methods for image retrieval are unable to deal with the high complexity of such queries. Search engines need to integrate their image retrieval process with knowledge to obtain rich semantics for effective retrieval. We propose a framework, Image Retrieval using Knowledge Embedding (ImReKE), for embedding knowledge with images and queries, allowing retrieval approaches to understand the context of queries and images in a better way. ImReKE (IR_Approach, Knowledge_Base) takes two inputs, namely, an image retrieval approach and a knowledge base. It selects quality concepts (concepts that possess properties such as rarity, newness, etc.) from the knowledge base to provide rich semantic representations for queries and images to be leveraged by the image retrieval approach. For the first time, an effective knowledge base that exploits both the visual and textual information of concepts has been developed. Our extensive experiments demonstrate that the proposed framework improves image retrieval significantly for all types of complex queries. The improvement is remarkable in the case of abstract queries, which have not yet been dealt with explicitly in the existing literature. We also compare the quality of our knowledge base with the existing text-based knowledge bases, such as ConceptNet, ImageNet, and the like.
C1 [Chaudhary, Chandramani; Goyal, Poonam; Goyal, Navneet] BITS Pilani, Dept Comp Sci & Informat Syst, Pilani Campus, Pilani, Rajasthan, India.
   [Chen, Yi-Ping Phoebe] La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic, Australia.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); La Trobe
   University
RP Chaudhary, C; Goyal, P; Goyal, N (corresponding author), BITS Pilani, Dept Comp Sci & Informat Syst, Pilani Campus, Pilani, Rajasthan, India.
EM chandramani.chaudhary@pilani.bits-pilani.ac.in;
   poonam@pilani.bits-pilani.ac.in; goel@pilani.bits-pilani.ac.in;
   phoebe.chen@latrobe.edu.au
RI Chaudhary, Chandramani/AAZ-2568-2021; Chen, Yi-Ping Phoebe/B-8844-2008
OI Chen, Yi-Ping Phoebe/0000-0002-4122-3767
CR Aly R., 2007, MULT INF RETR WORKSH, P40
   [Anonymous], 1992, COLING 1992, DOI DOI 10.3115/992133.992154
   [Anonymous], 2005, Advances in neural information processing systems
   [Anonymous], 2009, P 17 ACM INT C MULTI
   [Anonymous], 2008, COLING 2008 P WORKSH
   Belongie S, 2016, PATTERN RECOGN LETT, V72, P15, DOI 10.1016/j.patrec.2015.11.023
   Bin Gao, 2005, 13th Annual ACM International Conference on Multimedia, P112
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Chaudhary C, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P257, DOI 10.1145/3206025.3206050
   Chen WF, 2013, IEEE INT CONF CON AU, P1274
   Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178
   Chowdhury SN, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P117, DOI 10.1145/3159652.3159693
   Chua Tat-Seng., 2009, P 8 ACM INT C IMAGE
   Cui CR, 2018, NEUROCOMPUTING, V274, P19, DOI 10.1016/j.neucom.2016.05.118
   Cui P, 2018, IEEE T MULTIMEDIA, V20, P198, DOI 10.1109/TMM.2017.2724843
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Etzioni O, 2004, P 13 INT C WORLD WID, P100, DOI DOI 10.1145/988672.988687
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Guo D, 2016, WORLD WIDE WEB, V19, P247, DOI 10.1007/s11280-015-0357-x
   Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001
   Hoque E, 2011, ADV INTEL SOFT COMPU, V86, P73, DOI 10.1007/978-3-642-18029-3_8
   Hua X. S., 2013, P ACM INT C MULT, P393
   Isola P, 2014, LECT NOTES COMPUT SC, V8691, P799, DOI 10.1007/978-3-319-10578-9_52
   Joshi D., 2006, VLDB, V6, P1163
   Ksibi A, 2014, INT J MULTIMED INF R, V3, P29, DOI 10.1007/s13735-013-0045-5
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Mathews A, 2015, IEEE WINT CONF APPL, P595, DOI 10.1109/WACV.2015.85
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Milne D., 2008, P AAAI WORKSH WIK AR, P25
   Mitchell T., 2015, AAAI C ART INT
   Moellic P., 2008, P CIVR 08 NIAGARA FA, P269
   Myoupo D., 2009, LECT NOTES COMPUTER, P177
   Natsev A., 2005, 13th Annual ACM International Conference on Multimedia, P598, DOI 10.1145/1101149.1101288
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Ordonez V, 2015, INT J COMPUT VISION, V115, P29, DOI 10.1007/s11263-015-0815-z
   Qian XM, 2017, IEEE T IMAGE PROCESS, V26, P3734, DOI 10.1109/TIP.2017.2699623
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Shu GW, 2017, POLYMERS-BASEL, V9, DOI 10.3390/polym9120733
   Siddiquie Behjat., 2014, Proceedings of the International Conference on Multimedia Retrieval, page, P321
   Simonyan K., 2014, 14091556 ARXIV
   Tandon N, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P523, DOI 10.1145/2556195.2556245
   Tandon N, 2016, AAAI CONF ARTIF INTE, P243
   Tang XO, 2012, IEEE T PATTERN ANAL, V34, P1342, DOI 10.1109/TPAMI.2011.242
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang S, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700292
   Wang SH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1398, DOI 10.1145/3240508.3240535
   Wu W T, 2012, P 2012 ACM SIGMOD IN, P481, DOI DOI 10.1145/2213836.2213891
   Wu YL, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P825, DOI 10.1145/3240508.3240521
   Xia Q, 2012, IET IMAGE PROCESS, V6, P910, DOI 10.1049/iet-ipr.2011.0174
NR 50
TC 9
Z9 9
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2020
VL 16
IS 1
AR 13
DI 10.1145/3375786
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1FD
UT WOS:000583712100012
DA 2024-07-18
ER

PT J
AU Nguyen, DV
   Tran, HTT
   Thang, TC
AF Nguyen, Duc, V
   Tran, Huyen T. T.
   Truong Cong Thang
TI An Evaluation of Tile Selection Methods for Viewport-Adaptive Streaming
   of 360-Degree Video
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Virtual Reality; 360-degree Video; Viewport Adaptive Streaming
AB 360-degree video has become increasingly popular nowadays. For effective transmission of bandwidth-intensive 360-degree video over networks, viewport-adaptive streaming has been introduced. In this article, we evaluate, for the first time, ten existing methods to understand the effectiveness of tile-based viewport adaptive streaming of 360-degree video. Experimental results show that tile-based methods can improve the average V-PSNR by up to 4.3 dB compared to a non-tiled method under low delay settings. Here, the V-PSNR is computed as the peak signal-to-noise ratio of the adapted viewport compared to the corresponding origin viewport. Also, different methods show different tradeoffs between average viewport quality and viewport quality variations. Especially, the performances of most tile-based methods decrease quickly as the segment duration and/or buffer size increase for the content with no main focus. Even, under long delay settings like HTTP Adaptive Streaming, it is found that the simple non-tiled method appears to be the best one. For the content with a strong viewing focus, it is found that the tile-based methods are less influenced by the segment duration and the buffer size. In addition, a comparison of the performances of the tile selection methods using two popular viewport estimation methods is conducted. It is interesting that there is only little difference found in performances of tile selection methods. The findings of this study are useful for service providers to make decisions on deployment of streaming solutions.
C1 [Nguyen, Duc, V; Tran, Huyen T. T.; Truong Cong Thang] Univ Aizu, 965-8580 Ikkimachi, Aizu Wakamatsu, Fukushima, Japan.
C3 University of Aizu
RP Nguyen, DV (corresponding author), Univ Aizu, 965-8580 Ikkimachi, Aizu Wakamatsu, Fukushima, Japan.
EM nvduc712@gmail.com; tranhuyen1191@gmail.com; thang@u-aizu.ac.jp
CR Alface PR, 2012, BELL LABS TECH J, V16, P135, DOI 10.1002/bltj.20538
   Nguyen A, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1190, DOI 10.1145/3240508.3240669
   Bao YN, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1161, DOI 10.1109/BigData.2016.7840720
   Berger C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE WORKSHOPS (ICSAW), P7, DOI 10.1109/ICSAW.2017.56
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Boyce J., 2017, JVET ITU T SG 16 WP3
   Chakareski J., 2018, IEEE 5 INT C EM APPL
   Corbillon X, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P199, DOI 10.1145/3083187.3083215
   Corbillon X, 2017, IEEE ICC, DOI 10.1109/ICC.2017.7996611
   Csipa Attila, 2017, OPENTRACK V2 2
   Domanski M, 2017, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2017.7965623
   Fan C, 2017, SIXTEENTH WUHAN INTERNATIONAL CONFERENCE ON E-BUSINESS, P67
   Fraunhofer HHI, 2016, HEVC REFERENCE SOFTW
   Graf M, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P261, DOI 10.1145/3083187.3084016
   Tran HA, 2017, INT CONF KNOWL SYS, P1, DOI 10.1109/KSE.2017.8119425
   He D., 2018, P ACM SIGCOMM WORKSH, P27, DOI DOI 10.1145/3229625.3229630
   He J, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P482, DOI 10.1145/3210240.3210323
   Hosseini M, 2016, IEEE INT SYM MULTIM, P107, DOI [10.1109/ISM.2016.45, 10.1109/ISM.2016.0028]
   Huang C, 2013, NEPHROLOGY, V18, P36
   Le HT, 2017, IEICE T INF SYST, VE100D, P379, DOI 10.1587/transinf.2016EDL8172
   Liu CM, 2018, IEEE IMAGE PROC, P3264, DOI 10.1109/ICIP.2018.8451447
   Liu X, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P154, DOI 10.1145/3304109.3306220
   Lo WC, 2017, ASIA-PAC NETW OPER M, P205, DOI 10.1109/APNOMS.2017.8094203
   Nguyen D.T.C., 2019, J CHEM, V2019, P1
   Nguyen DV, 2017, IEEE INT SYM MULTIM, P38, DOI 10.1109/ISM.2017.16
   Nguyen DV, 2016, INT CONF UBIQ FUTUR, P972, DOI 10.1109/ICUFN.2016.7536942
   Ozcinar C, 2017, IEEE IMAGE PROC, P2174, DOI 10.1109/ICIP.2017.8296667
   Petrangeli S, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P306, DOI 10.1145/3123266.3123453
   Qian F., 2016, Proceedings of the 5th Workshop on All Things Cellular: Operations, Applications and Challenges, P1, DOI DOI 10.1145/2980055.2980056
   Qian F, 2018, MOBICOM'18: PROCEEDINGS OF THE 24TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P99, DOI 10.1145/3241539.3241565
   Rizzo L., 1997, Computer Communication Review, V27, P31, DOI 10.1145/251007.251012
   Stockhammer T., MPEG IMMERSIVE MEDIA
   Tran HTT, 2017, INT CONF UBIQ FUTUR, P7
   Thang TC, 2014, IEEE J SEL AREA COMM, V32, P693, DOI 10.1109/JSAC.2014.140403
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Xie L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P315, DOI 10.1145/3123266.3123291
   Yi J, 2019, PROCEEDINGS OF THE 29TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'19), P49, DOI 10.1145/3304112.3325613
   Zare A, 2017, IEEE IMAGE PROC, P1432, DOI 10.1109/ICIP.2017.8296518
   Zhou C, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P27, DOI 10.1145/3083187.3083190
NR 39
TC 12
Z9 15
U1 3
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2020
VL 16
IS 1
AR 8
DI 10.1145/3373359
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1FD
UT WOS:000583712100007
DA 2024-07-18
ER

PT J
AU Ozcelik, IM
   Ersoy, C
AF Ozcelik, Ihsan Mert
   Ersoy, Cem
TI Chunk Duration-Aware SDN-Assisted DASH
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Dynamic adaptive streaming HTTP; SDN; central adaptive video bitrate
   optimization; QoE; chunk duration diversity
ID VIDEO; QOE
AB Although Dynamic Adaptive Streaming over HTTP (DASH) is the pillar of multimedia content delivery mechanisms, its purely client-based adaptive video bitrate mechanisms have quality-of-experience fairness and stability problems in the existence of multiple DASH clients and highly fluctuating background traffic on the same shared bottleneck link. Varying chunk duration among different titles of multiple video providers exacerbates this problem. With the help of the global network view provided by the software-defined networking paradigm, we propose a centralized joint optimization module-assisted adaptive video bitrate mechanism that takes diversity of chunk sizes among different content into account. Our system collects possible video bitrate levels and chunk duration from DASH clients and simply calculates the optimal video bitrates per client based on the available capacity and chunk duration of each client's selected content while not invading users' privacy. By continuously following the background traffic flows, it asynchronously updates the target video bitrate levels to avoid both buffer stall events and network underutilization issues rather than bandwidth slicing, which brings about scalability problems in practice. It also guarantees fair startup delays for video sessions with various chunk duration. Our experiments clearly show that our proposed approach considering diversity of chunk duration and that background traffic fluctuations can significantly provide a better and fair quality of experience in terms of structural similarity-based video quality and startup delay compared to both purely client-based and state-of-the-art software-defined networking-based adaptive bitrate mechanisms.
C1 [Ozcelik, Ihsan Mert; Ersoy, Cem] Bogazici Univ, TR-34323 Istanbul, Turkey.
C3 Bogazici University
RP Ozcelik, IM (corresponding author), Bogazici Univ, TR-34323 Istanbul, Turkey.
EM mert.ozcelik@boun.edu.tr; ersoy@boun.edu.tr
RI Ersoy, Cem/G-9218-2011; Ozcelik, Ihsan Mert/AAF-4401-2021
OI Ersoy, Cem/0000-0001-7632-7067; Ozcelik, Ihsan Mert/0000-0002-6641-8544
CR [Anonymous], 4180 RFC
   [Anonymous], DASH JS JAVASCRIPT R
   [Anonymous], WHIT PAP CISC VNI FO
   [Anonymous], 2015, P IBC, DOI DOI 10.1049/IBC.2015.0014
   [Anonymous], FLOODL IS OP SDN CON
   [Anonymous], OP VSWITCH HOM PAG
   Bagci KT, 2017, IEEE T MULTIMEDIA, V19, P2152, DOI 10.1109/TMM.2017.2736638
   Bentaleb A, 2019, IEEE COMMUN SURV TUT, V21, P562, DOI 10.1109/COMST.2018.2862938
   Bentaleb A, 2018, IEEE T BROADCAST, V64, P575, DOI 10.1109/TBC.2018.2816789
   Bentaleb A, 2017, IEEE T MULTIMEDIA, V19, P2136, DOI 10.1109/TMM.2017.2733344
   Bentaleb A, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1296, DOI 10.1145/2964284.2964332
   Bhat D, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3183516
   BROWN RG, 1957, OPER RES, V5, P145
   Claeys M, 2014, IEEE COMMUN LETT, V18, P716, DOI 10.1109/LCOMM.2014.020414.132649
   Cofano G, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P24, DOI 10.1145/2910017.2910597
   Cofano G, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092836
   Georgopoulos P., 2013, Proceedings of the 2013 ACM SIGCOMM Workshop on Future Human-centric Multimedia Networking, FhMN '13, (New York, NY, USA), P15, DOI DOI 10.1145/2491172.2491181
   Jiang JY, 2018, MULTIMED TOOLS APPL, V77, P10787, DOI 10.1007/s11042-017-4917-1
   Kleinrouweler JW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092838
   Kleinrouweler JW, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P36, DOI 10.1145/2910017.2910599
   Kua J, 2017, IEEE COMMUN SURV TUT, V19, P1842, DOI 10.1109/COMST.2017.2685630
   Lederer S., 2012, P 3 MULT SYST C, P89
   Lu Z, 2018, IEEE T MULTIMEDIA, V20, P1848, DOI 10.1109/TMM.2017.2772802
   Sobhani A, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3052822
   Spiteri K, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P123, DOI 10.1145/3204949.3204953
   Spiteri Kevin, 2016, P 35 ANN IEEE INT C, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xia WF, 2015, IEEE COMMUN SURV TUT, V17, P27, DOI 10.1109/COMST.2014.2330903
NR 28
TC 4
Z9 4
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2019
VL 15
IS 3
AR 82
DI 10.1145/3337681
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JJ6YR
UT WOS:000494301200012
DA 2024-07-18
ER

PT J
AU Chen, DY
   El-Zarki, M
AF Chen, De-Yu
   El-Zarki, Magda
TI A Framework for Adaptive Residual Streaming for Single-Player Cloud
   Gaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Collaborative rendering; progressive meshes; 3D image warping
ID BIT-RATE
AB Applying cloud technology to 3D interactive multimedia applications is a promising way to provide flexible and cost-efficient online high-bandwidth immersive services to a large population of end users. One main reason cloud systems are popular among users is the fact that it relaxes the hardware requirements for high-end interactive visual applications. As most of the computational tasks are done on cloud servers, users no longer need to upgrade their hardware as frequently to keep up with the ever-increasing high-end computing requirements of the latest applications. Moreover, cloud systems make it easier for a user to enjoy applications on different platforms, including mobile devices that are usually not powerful enough to run high-end, memory-intensive services. In short, applying cloud technology to high-end immersive applications has advantages in cost-efficiency and flexibility both for the end users and the service providers. However, there are two main drawbacks to applying cloud technology to 3D interactive multimedia services: (1) high-bandwidth utilization and (2) latency. In this article, we propose a framework that addresses the two problems for single-player cloud gaming by using a combination of collaborative rendering, progressive meshes, and 3D image warping techniques. The experimental results show that the proposed system can reduce the bandwidth usage and improve the visual quality by utilizing local computing power on the client. The results also show that the interaction latency can be reduced somewhat by sacrificing some degree of visual quality in the end system.
C1 [Chen, De-Yu; El-Zarki, Magda] Univ Calif Irvine, Sch Informat & Comp Sci, Dept Comp Sci, Irvine, CA 92697 USA.
C3 University of California System; University of California Irvine
RP Chen, DY (corresponding author), Univ Calif Irvine, Sch Informat & Comp Sci, Dept Comp Sci, Irvine, CA 92697 USA.
EM teyuc@uci.edu; elzarki@uci.edu
CR Ahmadi H, 2014, MULTIMEDIA SYST, V20, P485, DOI 10.1007/s00530-014-0381-1
   [Anonymous], IEEE COMSOC MULTIMED
   [Anonymous], 2014, P INT WORKSH MASS MU, DOI DOI 10.1145/2577387.2577395
   [Anonymous], PC UPGRADE CYCLE SLO
   [Anonymous], 2014, 2014 IEEE INT C MULT
   [Anonymous], P 7 ACM SIGCOMM WORK
   [Anonymous], 2018, P 10 INT C QUAL MULT
   Beigbeder T., 2004, P ACM NETGAMES, P144
   Cai W, 2015, IEEE T CIRC SYST VID, V25, P2038, DOI 10.1109/TCSVT.2015.2450171
   Chen D., 2017, P 15 ANN WORKSHOP NE, P1, DOI [10.1109/NetGames.2017.7991543, DOI 10.1109/NETGAMES.2017.7991543]
   Chen DY, 2018, PROCEEDINGS OF THE 10TH ACM WORKSHOP ON IMMERSIVE MIXED AND VIRTUAL ENVIRONMENT SYSTEMS (MMVE'18), P28, DOI 10.1145/3210438.3210440
   Claypool M., 2012, P ACM WORKSH NETW SY, P1, DOI DOI 10.1109/NETGAMES.2012.6404013
   Crassin Cyril., 2015, Journal of Computer Graphics Techniques Vol, V4, P1
   Cuervo Eduardo, 2015, P 13 ANN INT C MOB S, P121
   Dick M., 2005, NetGames'05, P1
   Eu, 2016, P 2016 ACM MULT C MM, P737, DOI [10.1145/2964284.2973827, DOI 10.1145/2964284.2973827]
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Hemmati M., 2013, Proceeding of the 23rd ACM Workshop on Network and Operating Systems Support for Digital Audio and Video, P7
   Hong HJ, 2015, IEEE T CIRC SYST VID, V25, P2078, DOI 10.1109/TCSVT.2015.2450173
   Hoppe H, 1998, VISUALIZATION '98, PROCEEDINGS, P35, DOI 10.1109/VISUAL.1998.745282
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Hoppe H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P189, DOI 10.1145/258734.258843
   Huang CY, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2537855
   Lee K., 2015, ANAL CLOUD GAMING PL, P151
   Levenberg J, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P259, DOI 10.1109/VISUAL.2002.1183783
   Levoy M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P21, DOI 10.1145/218380.218392
   Liao XF, 2016, IEEE ACM T NETWORK, V24, P2128, DOI 10.1109/TNET.2015.2450254
   Liu Y, 2015, IEEE T CIRC SYST VID, V25, P1960, DOI 10.1109/TCSVT.2015.2450175
   McMillan Leonard, 1997, THESIS
   Messaoudi Farouk., 2015, 2015 international workshop on network and systems support for games (NetGames), P1
   Moller S., 2018, 2018 Tenth International Conference on Quality of Multimedia Experience (QoMEX), P1, DOI DOI 10.1109/QOMEX.2018.8463404
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Nave I, 2008, I SYMP CONSUM ELECTR, P205
   Quax Peter., 2004, NETGAMES 04, P152
   Schmidt S., 2018, P 10 INT C QUALITY M, P1, DOI [10.1109/QoMEX.2018.8463417, DOI 10.1109/QOMEX.2018.8463417]
   Shi Shu., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P103, DOI [10.1145/2072298.2072313, DOI 10.1145/2072298.2072313]
   Wang S., 2010, GLOB TEL C GLOBECOM, P1, DOI DOI 10.1109/GEOINFORMATICS.2010.5567608
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wilson AD, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P100, DOI 10.1145/3132272.3134144
   Zadtootaghaj S, 2018, INT WORK QUAL MULTIM, P210
   Zadtootaghaj S, 2018, IEEE INT SYM MULTIM, P131, DOI 10.1109/ISM.2018.00031
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
NR 43
TC 5
Z9 8
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2019
VL 15
IS 2
SU S
SI SI
AR 66
DI 10.1145/3336498
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IS2RO
UT WOS:000482001900019
OA Bronze
DA 2024-07-18
ER

PT J
AU Hu, J
   Qian, SS
   Fang, Q
   Liu, XL
   Xu, CS
AF Hu, Jun
   Qian, Shengsheng
   Fang, Quan
   Liu, Xueliang
   Xu, Changsheng
TI A<SUP>2</SUP> CMHNE: Attention-Aware Collaborative Multimodal
   Heterogeneous Network Embedding
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Network embedding; multimodal; heterogeneous network
AB Network representation learning is playing an important role in network analysis due to its effectiveness in a variety of applications. However, most existing network embedding models focus on homogeneous networks and neglect the diverse properties such as different types of network structures and associated multimedia content information. In this article, we learn node representations for multimodal heterogeneous networks, which contain multiple types of nodes and/or links as well as multimodal content such as texts and images. We propose a novel attention-aware collaborative multimodal heterogeneous network embedding method (A(2)CMHNE), where an attention-based collaborative representation learning approach is proposed to promote the collaboration of structure-based embedding and content-based embedding, and generate the robust node representation by introducing an attention mechanism that enables informative embedding integration. In experiments, we compare our model with existing network embedding models on two real-world datasets. Our method leads to dramatic improvements in performance by 5%, and 9% compared with five state-of-the-art embedding methods on one benchmark (M10 Dataset), and on a multi-modal heterogeneous network dataset (WeChat dataset) for node classification, respectively. Experimental results demonstrate the effectiveness of our proposed method on both node classification and link prediction tasks.
C1 [Hu, Jun; Liu, Xueliang] HeFei Univ Technol, 193 Tunxi Rd, Hefei 230009, Anhui, Peoples R China.
   [Qian, Shengsheng; Fang, Quan] Chinese Acad Sci, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   [Xu, Changsheng] Univ Chinese Acad Sci, HeFei Univ Technol, Chinese Acad Sci, Inst Automat, Shenzhen, Peoples R China.
   [Xu, Changsheng] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Xu, Changsheng] 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
C3 Hefei University of Technology; Chinese Academy of Sciences; Institute
   of Automation, CAS; Hefei University of Technology; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS; Peng Cheng
   Laboratory
RP Hu, J (corresponding author), HeFei Univ Technol, 193 Tunxi Rd, Hefei 230009, Anhui, Peoples R China.
EM hujunxianligong@gmail.com; shengsheng.qian@nlpr.ia.ac.cn;
   qfang@nlpr.ia.ac.cn; liuxueliang@hfut.edu.cn; csxu@nlpr.ia.ac.cn
RI Xu, Chang/GQP-7280-2022; xu, cj/HJZ-3488-2023; ARSLAN,
   Okan/AAA-3232-2020
FU National Natural Science Foundation of China [61432019, 61702509,
   61802405, 61720106006, 61572503, 61772170, 61632007]; Key Research
   Program of Frontier Sciences, CAS [QYZDJ-SSW-JSC039]; K. C. Wong
   Education Foundation
FX This work was supported in part by the National Natural Science
   Foundation of China (61432019, 61702509, 61802405, 61720106006,
   61572503, 61772170 and 61632007), the Key Research Program of Frontier
   Sciences, CAS (QYZDJ-SSW-JSC039), and the K. C. Wong Education
   Foundation.
CR [Anonymous], 2016, CORR
   [Anonymous], P 3 INT C LEARN REPR
   [Anonymous], USER CENTRIC SOCIAL
   Bhagat S, 2011, SOCIAL NETWORK DATA ANALYTICS, P115
   Cao SS, 2016, AAAI CONF ARTIF INTE, P1145
   Chang SY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P119, DOI 10.1145/2783258.2783296
   Chen T, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P295, DOI 10.1145/3018661.3018735
   Dong YX, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P135, DOI 10.1145/3097983.3098036
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoff PD, 2002, J AM STAT ASSOC, V97, P1090, DOI 10.1198/016214502388618906
   Hu J, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P456, DOI 10.1145/3240508.3240626
   Huang FR, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P108, DOI 10.1145/3206025.3206035
   Kipf T. N., 2017, ARXIV
   Le Quoc V., 2014, P INT C MACH LEARN I
   Liang B, 2015, INT CONF SOFTW ENG, P894, DOI 10.1109/ICSESS.2015.7339198
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Lou ML, 2015, M2D2015: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON MECHANICS AND MATERIALS IN DESIGN, P1165
   Mao-Draayer Y, 2016, MULT SCLER J, V22, P13
   Pan S., 2016, P 25 INT JOINT C ART, P1895, DOI DOI 10.1109/TKDE.2015.2391115
   Perozzi B., 2014, KDD, P701, DOI DOI 10.1145/2623330.2623732
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Qu M, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1767, DOI 10.1145/3132847.3133021
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun YB, 2012, ELECTRON J QUAL THEO, P1
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tu CC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1722, DOI 10.18653/v1/P17-1158
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wu F, 2016, IEEE T IMAGE PROCESS, V25, P630, DOI 10.1109/TIP.2015.2507401
   Xu LC, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P741, DOI 10.1145/3018661.3018723
   Yang C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2111
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
NR 32
TC 5
Z9 5
U1 1
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2019
VL 15
IS 2
AR 45
DI 10.1145/3321506
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IM3ZV
UT WOS:000477935400016
DA 2024-07-18
ER

PT J
AU Ma, RJ
   Hu, HF
   Wang, WX
   Xu, J
   Li, ZM
AF Ma, Ruijun
   Hu, Haifeng
   Wang, Weixuan
   Xu, Jia
   Li, Zhengming
TI Photorealistic Face Completion with Semantic Parsing and Face
   Identity-Preserving Features
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Deep learning; face Completion; face identity-preserving feature;
   semantic parsing; adversarial loss; local details
AB Tremendous progress on deep learning has shown exciting potential for a variety of face completion tasks. However, most learning-based methods are limited to handle general or structure specified face images (e.g., well-aligned faces). In this article, we propose a novel face completion algorithm, called Learning and Preserving Face Completion Network (LP-FCN), which simultaneously parses face images and extracts face identity-preserving (FIP) features. By tackling these two tasks in a mutually boosting way, the LP-FCN can guide an identity preserving inference and ensure pixel faithfulness of completed faces. In addition, we adopt a global discriminator and a local discriminator to distinguish real images from synthesized ones. By training with a combined identity preserving, semantic parsing and adversarial loss, the LP-FCN encourages the completion results to be semantically valid and visually consistent for more complicated image completion tasks. Experiments show that our approach obtains similar visual quality, but achieves better performance on unaligned faces completion and fine detailed synthesis against the state-of-the-art methods.
C1 [Ma, Ruijun; Hu, Haifeng; Wang, Weixuan; Xu, Jia] Sun Yat Sen Univ, Higher Educ Mega Ctr, 132 East Waihuan Rd, Guangzhou 510006, Guangdong, Peoples R China.
   [Li, Zhengming] Guangdong Polytech Normal Univ, 293 Zhongshan Ave, Guangzhou 510665, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Guangdong Polytechnic Normal University
RP Hu, HF (corresponding author), Sun Yat Sen Univ, Higher Educ Mega Ctr, 132 East Waihuan Rd, Guangzhou 510006, Guangdong, Peoples R China.
RI Wang, Xiaoman/JYP-1144-2024
OI Hu, Haifeng/0000-0002-4884-323X; Ma, Ruijun/0000-0001-6876-8153
FU National Natural Science Foundation of China [61673402]; Natural Science
   Foundation of Guangdong Province [2017A030311029, 2016B010109002];
   Science and Technology Program of Guangzhou, China [201704020180];
   Fundamental Research Funds for the Central Universities of China
FX This work was supported in part by the National Natural Science
   Foundation of China, under Grant 61673402, the Natural Science
   Foundation of Guangdong Province (2017A030311029 and 2016B010109002),
   and by the Science and Technology Program of Guangzhou, China, under
   Grant 201704020180, and the Fundamental Research Funds for the Central
   Universities of China.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2013, P INT C LEARN REPR
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], C NEUR INF PROC SYST
   [Anonymous], C NEUR INF PROC SYST
   [Anonymous], GERM C PATT REC
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, OPENFACE GEN PURPOSE
   [Anonymous], C NEUR INF PROC SYST
   [Anonymous], ARXIV1704040862
   [Anonymous], 2005, ACM T GRAPH SIGGRAPH
   [Anonymous], IEEE T INFORM FORENS
   [Anonymous], 2018, IEEE WINT C APPL COM
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Dosovitskiy A, 2016, PROC CVPR IEEE, P4829, DOI 10.1109/CVPR.2016.522
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo YX, 2016, ELECTRON J QUAL THEO, P1, DOI 10.14232/ejqtde.2016.1.118
   Hanhart P, 2013, INT CONF DIGIT SIG
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jia JY, 2003, PROC CVPR IEEE, P643
   Kingma D. P, 2015, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1412.6980
   Kundu D, 2015, IEEE IMAGE PROC, P2374, DOI 10.1109/ICIP.2015.7351227
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li RJ, 2014, LECT NOTES COMPUT SC, V8675, P305, DOI 10.1007/978-3-319-10443-0_39
   Liu SF, 2016, LECT NOTES COMPUT SC, V9908, P560, DOI 10.1007/978-3-319-46493-0_34
   Liu SF, 2015, PROC CVPR IEEE, P3451, DOI 10.1109/CVPR.2015.7298967
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Radford A., 2015, ARXIV
   Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Whyte O., 2009, BMVC
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie J., 2012, ADV NEURAL INFORM PR, P341
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667
   Yu X, 2017, AAAI CONF ARTIF INTE, P4327
   Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21
   Zhu Zhenyao, 2014, ADV NEURAL INFORM PR, DOI DOI 10.5555/2968826.2968851
   Zhuang BH, 2017, PROC CVPR IEEE, P2915, DOI 10.1109/CVPR.2017.311
NR 47
TC 3
Z9 3
U1 0
U2 17
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2019
VL 15
IS 1
AR 28
DI 10.1145/3300940
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HM9JB
UT WOS:000459798800012
DA 2024-07-18
ER

PT J
AU Zhao, SC
   Gholaminejad, A
   Ding, GG
   Gao, Y
   Han, JG
   Keutzer, K
AF Zhao, Sicheng
   Gholaminejad, Amir
   Ding, Guiguang
   Gao, Yue
   Han, Jungong
   Keutzer, Kurt
TI Personalized Emotion Recognition by Personality-Aware High-Order
   Learning of Physiological Signals
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Personalized emotion recognition; personality-sensitive learning;
   physiological signal analysis; multi-modal fusion; hypergraph learning
ID DATABASE; FUSION
AB Due to the subjective responses of different subjects to physical stimuli, emotion recognition methodologies from physiological signals are increasingly becoming personalized. Existing works mainly focused on modeling the involved physiological corpus of each subject, without considering the psychological factors, such as interest and personality. The latent correlation among different subjects has also been rarely examined. In this article, we propose to investigate the influence of personality on emotional behavior in a hypergraph learning framework. Assuming that each vertex is a compound tuple (subject, stimuli), multi-modal hypergraphs can be constructed based on the personality correlation among different subjects and on the physiological correlation among corresponding stimuli. To reveal the different importance of vertices, hyperedges, and modalities, we learn the weights for each of them. As the hypergraphs connect different subjects on the compound vertices, the emotions of multiple subjects can be simultaneously recognized. In this way, the constructed hypergraphs are vertex-weighted multi-modal multi-task ones. The estimated factors, referred to as emotion relevance, are employed for emotion recognition. We carry out extensive experiments on the ASCERTAIN dataset and the results demonstrate the superiority of the proposed method, as compared to the state-of-the-art emotion recognition approaches.
C1 [Zhao, Sicheng; Ding, Guiguang; Gao, Yue] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
   [Zhao, Sicheng; Gholaminejad, Amir; Keutzer, Kurt] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
   [Han, Jungong] Univ Lancaster, Sch Comp & Commnicat, Lancaster LA1 4YW, England.
C3 Tsinghua University; University of California System; University of
   California Berkeley; Lancaster University
RP Gao, Y (corresponding author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
EM schzhao@gmail.com; amirgh@berkeley.edu; dinggg@tsinghua.edu.cn;
   gaoyue@tsinghua.edu.cn; jungonghan77@gmail.com; keutzer@berkeley.edu
RI Ding, Guiguang/KIL-3528-2024; Gao, Yue/B-3376-2012; Han,
   Jungong/ABE-6812-2020
FU National Natural Science Foundation of China [61701273, 61571269,
   61671267]; China Postdoctoral Science Foundation [2018T110100,
   2017M610897]; Royal Society Newton Mobility Grant [IE150997]; National
   Key R&D Program of China [2017YFC011300]; Berkeley Deep Drive
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61701273, 61571269, 61671267), the Project Funded by China
   Postdoctoral Science Foundation (Nos. 2018T110100, 2017M610897), the
   Royal Society Newton Mobility Grant (No. IE150997), the National Key R&D
   Program of China (Grant No. 2017YFC011300), and the Berkeley Deep Drive.
   The authors would also like to thank the Handling Guest Editor X.
   Alameda-Pineda and the anonymous reviewers for their insightful comments
   to help us improve the article.
CR Abadi Mojtaba Khomami, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163100
   Abadi MK, 2015, IEEE T AFFECT COMPUT, V6, P209, DOI 10.1109/TAFFC.2015.2392932
   Al Osman Hussein., 2017, Emotion and Attention Recognition Based on Biological Signals and Images, DOI DOI 10.5772/65683
   ALAMEDAPINEDA X, 2016, PROC CVPR IEEE, P5240, DOI DOI 10.1109/CVPR.2016.566
   [Anonymous], 2015, P 1 INT WORKSH AFF S
   [Anonymous], 2012, ACM T INTEL SYST TEC, DOI DOI 10.1145/2168752.2168754
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Baveye Y, 2015, IEEE T AFFECT COMPUT, V6, P43, DOI 10.1109/TAFFC.2015.2396531
   Camilleri E, 2017, INT CONF AFFECT, P333, DOI 10.1109/ACII.2017.8273621
   Costa P.T., 1992, REVISED NEO PERSONAL
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Frijda N., 1986, EMOTIONS
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Giachanou A, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2938640
   Gunes H, 2005, IEEE SYS MAN CYBERN, P3437
   Henriques Rui, 2014, International Conference on Physiological Computing Systems (PhyCS 2014). Proceedings, P75
   Henriques R, 2013, INT CONF AFFECT, P43, DOI 10.1109/ACII.2013.14
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   Joho H, 2011, MULTIMED TOOLS APPL, V51, P505, DOI 10.1007/s11042-010-0632-x
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Kehoe EG, 2012, SOC COGN AFFECT NEUR, V7, P858, DOI 10.1093/scan/nsr059
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Kim Y, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808204
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Lee JT, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127199
   Lisetti CL, 2004, EURASIP J APPL SIG P, V2004, P1672, DOI 10.1155/S1110865704406192
   Martínez HP, 2013, IEEE COMPUT INTELL M, V8, P20, DOI 10.1109/MCI.2013.2247823
   Miranda-Correa J. A., 2017, ARXIV170202510
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Perugini M, 2002, BIG FIVE ASSESSMENT, P281
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Purkait P, 2017, IEEE T PATTERN ANAL, V39, P1697, DOI 10.1109/TPAMI.2016.2614980
   Shu YY, 2017, INT CONF ACOUST SPEE, P2871, DOI 10.1109/ICASSP.2017.7952681
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Solomon R.C., 1993, PASSIONS EMOTIONS ME, V2nd
   Su LF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2779
   Subramanian R, 2018, IEEE T AFFECT COMPUT, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Subramanian R, 2014, J VISION, V14, DOI 10.1167/14.3.31
   Tognetti Simone, 2010, 2010 IEEE Information Theory Workshop (ITW 2010), P321, DOI 10.1109/ITW.2010.5593337
   van Lankveld G, 2011, IEEE CONF COMPU INTE, P197, DOI 10.1109/CIG.2011.6032007
   Vinciarelli A, 2014, IEEE T AFFECT COMPUT, V5, P273, DOI 10.1109/TAFFC.2014.2330816
   Wagner J, 2011, IEEE T AFFECT COMPUT, V2, P206, DOI 10.1109/T-AFFC.2011.12
   Wang C., 2010, P 18 ACM INT C MULT, P391, DOI [10.1145/ 1873951.1874005, DOI 10.1145/1873951.1874005]
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wang SF, 2015, IEEE T AFFECT COMPUT, V6, P410, DOI 10.1109/TAFFC.2015.2432791
   Wen LY, 2014, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2014.167
   Winter KA, 1997, CLIN PSYCHOL REV, V17, P791, DOI 10.1016/S0272-7358(97)00057-3
   Yang Y, 2014, AAAI CONF ARTIF INTE, P306
   Yannakakis GN, 2017, INT CONF AFFECT, P248, DOI 10.1109/ACII.2017.8273608
   Yao C, 2016, IEEE T MULTIMEDIA, V18, P2015, DOI 10.1109/TMM.2016.2594145
   You QZ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1008, DOI 10.1145/2964284.2964288
   Zhao SC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1660
   Zhao SC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P369, DOI 10.1145/3123266.3130858
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P3218, DOI 10.1109/TCYB.2017.2762344
   Zhao SC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4669
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
   Zhou Dengyong, 2006, 19 INT C NEURAL INFO, V19, P1601
NR 64
TC 42
Z9 46
U1 5
U2 48
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2019
VL 15
IS 1
SU S
AR 14
DI 10.1145/3233184
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HM9IU
UT WOS:000459798100014
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Dos Santos, JAF
   Muchaluat-Saade, DC
   Roisin, C
   Layaïda, N
AF Dos Santos, Joel A. F.
   Muchaluat-Saade, Debora C.
   Roisin, Cecile
   Layaida, Nabil
TI A Hybrid Approach for Spatio-Temporal Validation of Declarative
   Multimedia Documents
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Interactive multimedia applications; multimedia authoring; multimedia
   document validation; spatio-temporal validation
AB Declarative multimedia documents represent the description of multimedia applications in terms of media items and relationships among them. Relationships specify how media items are dynamically arranged in time and space during runtime. Although a declarative approach usually facilitates the authoring task, authors can still make mistakes due to incorrect use of language constructs or inconsistent or missing relationships in a document. In order to properly support multimedia application authoring, it is important to provide tools with validation capabilities. Document validation can indicate possible inconsistencies in a given document to an author so that it can be revised before deployment. Although very useful, multimedia validation tools are not often provided by authoring tools.
   This work proposes a multimedia validation approach that relies on a formal model called Simple Hypermedia Model (SHM). SHM is used for representing a document for the purpose of validation. An SWM document is validated using a hybrid approach based on two complementary techniques. The first one captures the document's spatio-temporal layout in terms of its state throughout its execution by means of a rewrite theory, and validation is performed through model-checking. The second one captures the document's layout in terms of intervals and event occurrences by means of Satisfiability Modulo Theories (SMT) formulas, and validation is performed through SMT solving. Due to different characteristics of both approaches, each validation technique complements the other in terms of expressiveness of SLIM and tests to be checked.
   We briefly present validation tools that use our approach. They were evaluated with real NCL documents and by usability tests.
C1 [Dos Santos, Joel A. F.] CEFET RJ, Sch Comp & Informat, Av Maracana 229,Bloco E,5 Andar, BR-20271110 Maracana, RJ, Brazil.
   [Muchaluat-Saade, Debora C.] Univ Fed Fluminense, MediaCom Lab, Rua Passo da Patria 156, BR-24210240 Niteroi, RJ, Brazil.
   [Roisin, Cecile; Layaida, Nabil] Univ Grenoble Alpes, Inria, LIG, CNRS,Grenoble INP, F-38000 Grenoble, France.
C3 Centro Federal de Educacao Tecnologica Celso Suckow da Fonseca
   (CEFET-RJ); Universidade Federal Fluminense; Inria; Communaute
   Universite Grenoble Alpes; Institut National Polytechnique de Grenoble;
   Universite Grenoble Alpes (UGA); Centre National de la Recherche
   Scientifique (CNRS)
RP Dos Santos, JAF (corresponding author), CEFET RJ, Sch Comp & Informat, Av Maracana 229,Bloco E,5 Andar, BR-20271110 Maracana, RJ, Brazil.
EM jsantos@eic.cefet-rj.br; debora@midiacom.uff.br; cecile.roisin@inria.fr;
   nabil.layaida@inria.fr
RI dos Santos, Joel A. F./O-6246-2016; Muchaluat-Saade, Débora
   Christina/E-7794-2014
OI dos Santos, Joel A. F./0000-0001-7234-613X; 
FU CNPq; FAPERJ; CAPES; Inria in the context of Science without Borders
   Program
FX We thank the support of CNPq and Inria in the context of Science without
   Borders Program. We also thank FAPERJ, CAPES and CNPq for their support.
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Amorim Glauco F., 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P642, DOI 10.1007/978-3-319-27671-7_54
   [Anonymous], 2011, 1560622011 ABNT NBR
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2011, SCAL VECT GRAPH SVG
   [Anonymous], 2006, Programming in lua
   Barreto F., 2016, P 22 BRAZ S MULT WEB, P91
   Belouaer L., 2012, P ICAPS 2012 WORKSH, P6
   Bertino E, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P578, DOI 10.1109/ICME.2005.1521489
   Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691
   Bouyakoub S, 2008, UKSIM INT CONF COMP, P106, DOI 10.1109/UKSIM.2008.54
   Bouyakoub S, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1870121.1870123
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Clavel M., 2007, All About Maude, A High-Performance Logical Framework, volume 4350 of Lecture Notes in Computer Science, V4350
   De Moura L, 2011, COMMUN ACM, V54, P69, DOI 10.1145/1995376.1995394
   dos Santos Joel, 2013, Formal Methods: Foundations and Applications. 16th Brazilian Symposium, SBMF 2013. Proceedings: LNCS 8195, P67, DOI 10.1007/978-3-642-41071-0_6
   dos Santos J.A.F., 2012, SLE DOCT S DRESD GER, P37
   dos Santos J, 2015, SCI COMPUT PROGRAM, V107, P64, DOI 10.1016/j.scico.2015.04.006
   dos Santos Joel A. F., 2012, P 18 BRAZ S MULT WEB
   dosSantos Joel A. F., 2015, DOCENG 15, P133, DOI DOI 10.1145/2682571.2797060
   Dutertre B, 2014, LECT NOTES COMPUT SC, V8559, P737, DOI 10.1007/978-3-319-08867-9_49
   Felix M. F., 2004, THESIS
   Gaggi O, 2011, MULTIMEDIA SYST, V17, P487, DOI 10.1007/s00530-011-0233-1
   Green TRG, 1996, J VISUAL LANG COMPUT, V7, P131, DOI 10.1006/jvlc.1996.0009
   Hardman H. L., 1998, THESIS
   ITU, 2009, NON TRADITIONAL REF
   Jourdan M., 1998, Proceedings ACM Multimedia 98, P267, DOI 10.1145/290747.290780
   Junior D. P., 2012, P 18 BRAZ S M ULT WE, P223, DOI 10.1145/2382636.2382685
   Kostalas Ioannis, 1999, DATABASE SEMANTICS, V11, P169
   Laborie S, 2011, MULTIMED TOOLS APPL, V55, P379, DOI 10.1007/s11042-010-0552-9
   Lima Guilherme Augusto Ferreira, 2013, P 19 BRAZ S MULT WEB, P201
   Ma HD, 2004, IEEE T MULTIMEDIA, V6, P565, DOI 10.1109/tmm.2004.830807
   Meseguer J, 2012, J LOGIC ALGEBR PROGR, V81, P721, DOI 10.1016/j.jlap.2012.06.003
   Pnueli A., 1977, 18th Annual Symposium on Foundations of Computer Science, P46, DOI 10.1109/SFCS.1977.32
   Randell D. A., 1992, Principles of Knowledge Representation and Reasoning: Proceedings of the Third International Conference (KR '92), P165
   SANTOS FILHO Joao Ribeiro dos, 2016, THESIS
   Soares LFG, 2010, MULTIMED TOOLS APPL, V50, P465, DOI 10.1007/s11042-010-0478-2
   Susan Elias, 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1380, DOI 10.1145/1141277.1141596
   W3C, 2008, NON TRADITIONAL REF
   W3C, 2014, NON TRADITIONAL REF
   W3C, 2014, WEB AN 1 0
NR 41
TC 2
Z9 2
U1 1
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2018
VL 14
IS 4
AR 86
DI 10.1145/3267127
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ4JB
UT WOS:000457139200008
OA Green Published
DA 2024-07-18
ER

PT J
AU Strezoski, G
   Worring, M
AF Strezoski, Gjorgji
   Worring, Marcel
TI OmniArt: A Large-scale Artistic Benchmark
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Dataset; multimedia; computer vision; artistic data
ID DATABASE
AB Baselines are the starting point of any quantitative multimedia research, and benchmarks are essential for pushing those baselines further. In this article, we present baselines for the artistic domain with a new benchmark dataset featuring over 2 million images with rich structured metadata dubbed OmniArt. OmniArt contains annotations for dozens of attribute types and features semantic context information through concepts, IconClass labels, color information, and (limited) object-level bounding boxes. For our dataset we establish and present baseline scores on multiple tasks such as artist attribution, creation period estimation, type, style, and school prediction. In addition to our metadata related experiments, we explore the color spaces of art through different types and evaluate a transfer learning object recognition pipeline.
C1 [Strezoski, Gjorgji; Worring, Marcel] Univ Amsterdam, Informat Inst, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
C3 University of Amsterdam
RP Strezoski, G (corresponding author), Univ Amsterdam, Informat Inst, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
EM g.strezoski@uva.nl; m.worring@uva.nl
RI Worring, Marcel/JRW-7059-2023
OI Worring, Marcel/0000-0003-4097-4136
FU Netherlands Organization for Scientific Research through Netherlands
   Institute for Conservation, Art and Science
FX This research is part of the VISTORY project supported by Netherlands
   Organization for Scientific Research through Netherlands Institute for
   Conservation, Art and Science.
CR [Anonymous], P MEDIAEVAL 2014 WOR
   [Anonymous], 2016, P IEEE C COMPUTER VI
   [Anonymous], IEEE SIGN PROCESS MA
   [Anonymous], Recognizing image style
   [Anonymous], 2017, ARXIV170800684
   [Anonymous], 2017, ARXIV171103536
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 4 CIT
   [Anonymous], STUD ART ED
   [Anonymous], ARXIVCSAI180107729
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, P VADL VIS AN DEEP L
   [Anonymous], ARXIV150600711
   [Anonymous], P MEDIAEVAL 2015 WOR
   [Anonymous], P 7 INT C MULT SYST
   Awad G., 2017, P TREC VID RETR EV G
   Bar Y, 2015, LECT NOTES COMPUT SC, V8925, P71, DOI 10.1007/978-3-319-16178-5_5
   Baveye Y, 2015, IEEE T AFFECT COMPUT, V6, P43, DOI 10.1109/TAFFC.2015.2396531
   Berns RS, 2010, COLOR IMAG CONF, P27
   Couprie L., 1983, ART LIB J, V8, P32, DOI [DOI 10.1017/S0307472200003436, 10.1017/S0307472200003436]
   Crowley EJ, 2015, LECT NOTES COMPUT SC, V8925, P54, DOI 10.1007/978-3-319-16178-5_4
   Demarty CH, 2015, MULTIMED TOOLS APPL, V74, P7379, DOI 10.1007/s11042-014-1984-4
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ginosar S., 2014, Proc. European Conf. on Computer Vision (ECCV) Workshops, P101
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Ignatov DI, 2009, LECT NOTES ARTIF INT, V5662, P185, DOI 10.1007/978-3-642-03079-6_15
   Escalante HJ, 2016, INT C PATT RECOG, P67, DOI 10.1109/ICPR.2016.7899609
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   King DB, 2015, ACS SYM SER, V1214, P1
   Larson M, 2017, IEEE MULTIMEDIA, V24, P93, DOI 10.1109/MMUL.2017.9
   Lecoutre A., 2017, ASIAN C MACHINE LEAR, P327
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mao H, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1183, DOI 10.1145/3123266.3123405
   Mensink T, 2014, P INT C MULT RETR, P451, DOI DOI 10.1145/2578726.2578791
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Simonyan K., 2014, 14091556 ARXIV
   Smeaton A. F., 2002, Research and Advanced Technology for Digital Libraries. 6th European Conference, ECDL 2002. Proceedings (Lecture Notes in Computer Science Vol.2458), P266
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   van Noord N, 2015, IEEE SIGNAL PROC MAG, V32, P46, DOI 10.1109/MSP.2015.2406955
   Westlake Nicholas, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P825, DOI 10.1007/978-3-319-46604-0_57
NR 46
TC 41
Z9 44
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2018
VL 14
IS 4
AR 88
DI 10.1145/3273022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ4JB
UT WOS:000457139200010
DA 2024-07-18
ER

PT J
AU Gupta, A
   Singhal, D
AF Gupta, Abhinav
   Singhal, Divya
TI Analytical Global Median Filtering Forensics Based on Moment Histograms
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Median filter; passive image forensics; skewness and kurtosis
   histograms; tamper detection
ID BLIND DETECTION
AB Median filtering forensics in images has gained wide attention from researchers in recent years because of its inherent nature of preserving visual traces. Although many forensic methods are developed for median filtering detection, probability of detection reduces under JPEG compression at low-quality factors and for low-resolution images. The feature set reduction is also a challenging issue among existing detectors. In this article, a 19-dimensional feature set is analytically derived fromimage skewness and kurtosis histograms. This new feature set is exploited for the purpose of global median filtering forensics and verified with exhaustive experimental results. The efficacy of the method is tested on six popular databases (UCID, BOWS2, BOSSBase, NRCS, RAISE, and DID) and found that the new feature set uncovers filtering traces for moderate, low JPEG post-compression and low-resolution operation. Our proposed method yields lowest probability of error and largest area under the ROC curve for most of the test cases in comparison with previous approaches. Some novel test cases are introduced to thoroughly assess the benefits and limitations of the proposed method. The obtained results indicate that the proposed method would provide an important tool to the field of passive image forensics.
C1 [Gupta, Abhinav; Singhal, Divya] Jaypee Inst Informat Technol, Dept Elect & Commun, A-10,Sect 62, Noida 201309, Uttar Pradesh, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Gupta, A (corresponding author), Jaypee Inst Informat Technol, Dept Elect & Commun, A-10,Sect 62, Noida 201309, Uttar Pradesh, India.
EM abhinav.gupta@jiit.ac.in; singhal_dia@yahoo.com
RI Singhal, Divya/ADN-8363-2022
OI GUPTA, ABHINAV/0000-0002-1939-5407
CR [Anonymous], THESIS
   Bas P., 2007, Bows-2
   Bas Patrick, 2011, BREAK OUR STEGANOGRA, P59, DOI [10.1007/978-3-642-24178-9_5, DOI 10.1007/978-3-642-24178-9_5]
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   DeCarlo LT, 1997, PSYCHOL METHODS, V2, P292, DOI 10.1037/1082-989X.2.3.292
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   DOANE DP, 1976, AM STAT, V30, P181, DOI 10.2307/2683757
   Gloe T., 2010, P SAC 10 2010 ACM S, P1584
   HOPKINS KD, 1990, EDUC PSYCHOL MEAS, V50, P717, DOI 10.1177/0013164490504001
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Rhee KH, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053039
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shen ZY, 2016, MULTIMED TOOLS APPL, V75, P2327, DOI 10.1007/s11042-014-2407-2
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Sturges HA, 1926, J AM STAT ASSOC, V21, P65, DOI 10.1080/01621459.1926.10502161
   Thai TH, 2017, IEEE T INF FOREN SEC, V12, P123, DOI 10.1109/TIFS.2016.2604208
   USDA NRCS, 2014, NAT RES CONS SERV PH
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
NR 27
TC 8
Z9 8
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2018
VL 14
IS 2
AR 44
DI 10.1145/3176650
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GG9BS
UT WOS:000432996000002
DA 2024-07-18
ER

PT J
AU Duan, JL
   Wan, J
   Zhou, S
   Guo, XY
   Li, SZ
AF Duan, Jiali
   Wan, Jun
   Zhou, Shuai
   Guo, Xiaoyuan
   Li, Stan Z.
TI A Unified Framework for Multi-Modal Isolated Gesture Recognition
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multi-modal; consensus-voting; 3D convolution; isolated gesture
   recognition
ID REAL-TIME
AB In this article, we focus on isolated gesture recognition and explore different modalities by involving RGB stream, depth stream, and saliency stream for inspection. Our goal is to push the boundary of this realm even further by proposing a unified framework that exploits the advantages of multi-modality fusion. Specifically, a spatial-temporal network architecture based on consensus-voting has been proposed to explicitly model the long-term structure of the video sequence and to reduce estimation variance when confronted with comprehensive inter-class variations. In addition, a three-dimensional depth-saliency convolutional network is aggregated in parallel to capture subtle motion characteristics. Extensive experiments are done to analyze the performance of each component and our proposed approach achieves the best results on two public benchmarks, ChaLearn IsoGD and RGBD-HuDaAct, outperforming the closest competitor by a margin of over 10% and 15%, respectively. Our project and codes will be released at https:// davidsonic.github. io/index/acm_tomm_2017.html.
C1 [Duan, Jiali; Wan, Jun; Li, Stan Z.] Chinese Acad Sci, CBSR, Inst Automat, Beijing, Peoples R China.
   [Duan, Jiali; Wan, Jun; Li, Stan Z.] Chinese Acad Sci, NLPR, Inst Automat, Beijing, Peoples R China.
   [Zhou, Shuai] Macau Univ Sci & Technol, Taipa, Macao, Peoples R China.
   [Guo, Xiaoyuan] Univ Chinese Acad Sci, Sch Engn Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; Institute of Automation, CAS; Macau University of
   Science & Technology; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Wan, J (corresponding author), Chinese Acad Sci, CBSR, Inst Automat, Beijing, Peoples R China.; Wan, J (corresponding author), Chinese Acad Sci, NLPR, Inst Automat, Beijing, Peoples R China.
EM jli.duan@gmail.com; jun.wan@ia.ac.cn; shuaizhou.palm@gmail.com;
   xiaoyuanguo.ucas@gmail.com; szli@nlpr.ia.ac.cn
RI Li, SY/JPK-3839-2023; Guo, Xiaoyuan/AAC-2406-2019
OI Li, SY/0009-0000-9254-7115; 
FU National Key Research and Development Plan [2016YFC0801002]; Chinese
   National Natural Science Foundation [61502491, 61473291, 61572501,
   61572536, 61673052]; Science and Technology Development Fund of Macau
   [112/2014/A3]; NVIDIA GPU; AuthenMetric RD Funds
FX This work was supported by the National Key Research and Development
   Plan (Grant No. 2016YFC0801002), the Chinese National Natural Science
   Foundation Projects #61502491, #61473291, #61572501, #61572536,
   #61673052, Science and Technology Development Fund of Macau (No.
   112/2014/A3), NVIDIA GPU donation program and AuthenMetric R&D Funds.
CR Achanta R., 2009, FREQUENCY TUNED SALI
   [Anonymous], 2014, LARGE SCALE VIDEO CL
   [Anonymous], 2016, Ntu rgb+d: A large scale dataset for 3d human activity analysis
   Chai XJ, 2016, INT C PATT RECOG, P31, DOI 10.1109/ICPR.2016.7899603
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Davis James W., 2000, P IEEE C COMP VIS PA, P928
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   DUTRAN LB, 2015, LEARNING SPATIOTEMPO
   Evangelidis GD, 2015, LECT NOTES COMPUT SC, V8925, P595, DOI 10.1007/978-3-319-16178-5_42
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   HENG W, 2013, ACTION RECOGNITION I
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Joe Yue-HeiNg., 2015, Beyond short snippets: Deep networks for video classification
   JUN W, 2016, P IEEE C COMP VIS PA
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Molchanov Pavlo, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163132
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Neverova Natalia, 2015, MULTISCALE DEEP LEAR, P474
   Ni Bingbing., 2011, Rgbd-hudaact: A color-depth video database for human daily activity recognition
   Nishida Noriki, 2015, MULTIMODAL GESTURE R
   Ohn-Bar E, 2014, IEEE T INTELL TRANSP, V15, P2368, DOI 10.1109/TITS.2014.2337331
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Pigou Lionel, 2015, INT J COMPUT VISION, P1
   Ponce-Lpez V, 2016, P INT C PATT REC
   Ponce-Lpez V, 2016, CHALEARN LAP LARGE S
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Trindade P., 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P71, DOI 10.1109/MFI.2012.6343032
   Wan J, 2016, IEEE T PATTERN ANAL, V38, P1626, DOI 10.1109/TPAMI.2015.2513479
   Wan J, 2014, IEEE T IMAGE PROCESS, V23, P3152, DOI 10.1109/TIP.2014.2328181
   Wan J, 2013, J MACH LEARN RES, V14, P2549
   Wang Pichao, 2016, 2016 23 INT C PATT R, P27
   Wang S.B., 2006, P IEEE COMP SOC C CO
   Wedel Andreas, 2009, Statistical and Geometrical Approaches to Visual Motion Analysis. International Dagstuhl Seminar. Revised Papers, P23, DOI 10.1007/978-3-642-03061-1_2
   Wei Li, 2014, J ELECTRON IMAGING, V23, P1709
   Xiong Yuanjun, 2016, TEMPORAL SEGMENT NET
   Yi Zhu, 2016, DEPTH2ACTION EXPLORI
   Yin Y, 2014, S VIS LANG HUM CEN C, P113, DOI 10.1109/VLHCC.2014.6883032
   ZHANG BW, 2016, REAL TIME ACTION REC
NR 46
TC 24
Z9 25
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2018
VL 14
IS 1
SU S
AR 21
DI 10.1145/3131343
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GH5ZK
UT WOS:000433517100007
DA 2024-07-18
ER

PT J
AU Yang, HF
   Lin, BY
   Chang, KY
   Chen, CS
AF Yang, Huei-Fang
   Lin, Bo-Yao
   Chang, Kuang-Yu
   Chen, Chu-Song
TI Joint Estimation of Age and Expression by Combining Scattering and
   Convolutional Networks
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Age estimation; deep learning; convolutional networks; expression
   recognition; multi-task learning; multi-level regression; scattering
   network; transfer learning
ID FACIAL EXPRESSIONS; RANK ESTIMATION; RECOGNITION; APPEARANCE; DATABASE
AB This article tackles the problem of joint estimation of human age and facial expression. This is an important yet challenging problem because expressions can alter face appearances in a similar manner to human aging. Different from previous approaches that deal with the two tasks independently, our approach trains a convolutional neural network (CNN) model that unifies ordinal regression and multi-class classification in a single framework. We demonstrate experimentally that our method performs more favorably against state-of-the-art approaches.
C1 [Yang, Huei-Fang; Lin, Bo-Yao] Acad Sinica, Taipei, Taiwan.
   [Chang, Kuang-Yu; Chen, Chu-Song] Acad Sinica, Inst Informat Sci, Taipei, Taiwan.
   [Yang, Huei-Fang] Howard Hughes Med Inst, Janelia Res Campus, Ashburn, VA 20147 USA.
   [Lin, Bo-Yao] Univ Michigan, Elect & Comp Engn Dept, Ann Arbor, MI 48109 USA.
C3 Academia Sinica - Taiwan; Academia Sinica - Taiwan; Howard Hughes
   Medical Institute; University of Michigan System; University of Michigan
RP Yang, HF (corresponding author), Acad Sinica, Taipei, Taiwan.; Yang, HF (corresponding author), Howard Hughes Med Inst, Janelia Res Campus, Ashburn, VA 20147 USA.
EM yangh3@janelia.hhmi.org; boyaolin@umich.edu; kuangyu@iis.sinica.edu.tw;
   song@iis.sinica.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST 105-2218-E-001-006,
   MOST 106-2221-E-001-016]
FX This work is supported in part by the Ministry of Science and Technology
   of Taiwan under Contract MOST 105-2218-E-001-006 and MOST
   106-2221-E-001-016.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2016, ACCV 3
   [Anonymous], P BMVC
   [Anonymous], 2014, P AS C COMP VIS
   [Anonymous], P CVPRW
   [Anonymous], PROC IEEE BTAS
   [Anonymous], P ACCV
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.532
   Antipov G, 2016, IEEE COMPUT SOC CONF, P801, DOI 10.1109/CVPRW.2016.105
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379
   Chang KY, 2013, IEEE SYS MAN CYBERN, P3157, DOI 10.1109/SMC.2013.538
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dibeklioglu H, 2015, IEEE T IMAGE PROCESS, V24, P1928, DOI 10.1109/TIP.2015.2412377
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Freedman D. A, 2005, STAT MODELS THEORY P, DOI DOI 10.1017/CBO9781139165495
   Gao BB, 2017, IEEE T IMAGE PROCESS, V26, P2825, DOI 10.1109/TIP.2017.2689998
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Guo GD, 2014, PROC CVPR IEEE, P4257, DOI 10.1109/CVPR.2014.542
   Guo GD, 2013, IEEE T AFFECT COMPUT, V4, P291, DOI 10.1109/T-AFFC.2013.13
   Guo GD, 2012, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2012.6247972
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Hadid Abdenour, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P52, DOI 10.1007/978-3-642-25446-8_6
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Huerta I, 2015, PATTERN RECOGN LETT, V68, P239, DOI 10.1016/j.patrec.2015.06.006
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kuang-Yu Chang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3396, DOI 10.1109/ICPR.2010.829
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Li CS, 2015, IEEE T CYBERNETICS, V45, P2522, DOI 10.1109/TCYB.2014.2376517
   Li CS, 2012, PROC CVPR IEEE, P2570, DOI 10.1109/CVPR.2012.6247975
   Lin HT, 2012, NEURAL COMPUT, V24, P1329, DOI 10.1162/NECO_a_00265
   Malli RC, 2016, IEEE COMPUT SOC CONF, P714, DOI 10.1109/CVPRW.2016.94
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Peng Yang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3404, DOI 10.1109/ICPR.2010.831
   Pontes JK, 2016, PATTERN RECOGN, V54, P34, DOI 10.1016/j.patcog.2015.12.003
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang JW, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P17, DOI 10.1109/UIC-ATC.2013.19
   Wang SF, 2016, MULTIMED TOOLS APPL, V75, P3937, DOI 10.1007/s11042-015-3107-2
   Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77
   Yang H.-F., 2015, P BRIT MACH VIS C
   Ye Q, 2015, DIS MARKERS, V2015, P1, DOI 10.1155/2015/387382
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
NR 50
TC 13
Z9 13
U1 0
U2 21
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2018
VL 14
IS 1
AR 9
DI 10.1145/3152118
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FW9HO
UT WOS:000425646500009
DA 2024-07-18
ER

PT J
AU Pontello, LF
   Holanda, PHF
   Guilherme, B
   Cardoso, JPV
   Goussevskaia, O
   Da Silva, APC
AF Pontello, Luciana Fujii
   Holanda, Pedro H. F.
   Guilherme, Bruno
   Cardoso, Joao Paulo V.
   Goussevskaia, Olga
   Couto Da Silva, Ana Paula
TI Mixtape: Using Real-Time User Feedback to Navigate Large Media
   Collections
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Media collection; collaborative filtering; content similarity; graph
   embedding; navigation
AB In this work, we explore the increasing demand for novel user interfaces to navigate large media collections. We implement a geometric data structure to store and retrieve item-to-item similarity information and propose a novel navigation framework that uses vector operations and real-time user feedback to direct the outcome. The framework is scalable to large media collections and is suitable for computationally constrained devices. In particular, we implement this framework in the domain of music. To evaluate the effectiveness of the navigation process, we propose an automatic evaluation framework, based on synthetic user profiles, which allows us to quickly simulate and compare navigation paths using different algorithms and datasets. Moreover, we perform a real user study. To do that, we developed and launched Mixtape, a simple web application that allows users to create playlists by providing real-time feedback through liking and skipping patterns.
C1 [Pontello, Luciana Fujii; Holanda, Pedro H. F.; Guilherme, Bruno; Cardoso, Joao Paulo V.; Goussevskaia, Olga; Couto Da Silva, Ana Paula] Univ Fed Minas Gerais, Comp Sci Dept, Av Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Minas Gerais
RP Pontello, LF (corresponding author), Univ Fed Minas Gerais, Comp Sci Dept, Av Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
EM lucianafujii@dcc.ufmg.br; holanda@dcc.ufmg.br;
   brunoguilherme@dcc.ufmg.br; jpcardoso@dcc.ufmg.br; olga@dcc.ufmg.br;
   ana.coutosilva@dcc.ufmg.br
RI Silva, Ana/JGM-6679-2023; da Silva, Ana/GXH-4851-2022
OI Goussevskaia, Olga/0000-0001-5676-4972; Couto, Ana
   Paula/0000-0001-5951-3562
FU CNPq; CAPES; Fapemig
FX This work is supported in part by the Brazilian agencies CNPq, CAPES and
   Fapemig.
CR Ahmed Amr, 2013, WWW
   Andersen K., 2016, ISMIR, P122
   [Anonymous], 2004, Tech. Rep.
   [Anonymous], P ISMIR
   [Anonymous], 2014, P INT C INT C MACH L
   Aucouturier JJ, 2005, IEEE T MULTIMEDIA, V7, P1028, DOI 10.1109/TMM.2005.858380
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cano P., 2005, 13th Annual ACM International Conference on Multimedia, P211, DOI 10.1145/1101149.1101181
   Cardoso J.P.V., 2016, P 17 INT SOC MUS INF, P454
   Chen S., 2012, P 18 ACM SIGKDD INT, P714, DOI [DOI 10.1145/2339530.2339643, 10.1145/2339530.2339643]
   Chen S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P865
   Chung Chia-Hao, 2016, P 17 INT SOC MUS INF, P323
   Cox T. F., 2000, Multidimensional scaling
   Farrahi K., 2014, P 15 INT SOC MUS INF, P483
   Flexer Arthur, 2014, P INT SOC MUS INF RE
   Goussevskaia Olga, 2008, P C WEB INT INT AG T, V1
   Holanda P, 2015, LECT NOTES COMPUT SC, V9114, P182, DOI 10.1007/978-3-319-19890-3_13
   Holanda Pedro, 2015, P BRAZ S COMP NETW D, P1
   Konstas I, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P195, DOI 10.1145/1571941.1571977
   Kuhn Michael, 2010, P INT C MULT NEW YOR, P411
   Logan Beth, 2001, P 2001 IEEE INT C MU, V190
   Logan Beth, 2002, P 3 INT C MUS INF RE
   Maillet F., 2009, P INT SOC MUSIC INFO, P345
   McFee B, 2012, IEEE T AUDIO SPEECH, V20, P2207, DOI 10.1109/TASL.2012.2199109
   Moore J.L., 2012, P ISMIR, P349
   Moore Joshua L, 2013, ISMIR, P401
   Pampalk Elias, 2005, P INT S MUS INF RET
   Panteli M., 2016, P 17 INT SOC MUS INF, P538
   Parker Michael C., 2015, 2015 20th European Conference on Networks and Optical Communications (NOC), P1, DOI 10.1109/NOC.2015.7238620
   Perozzi B., 2014, KDD, P701, DOI DOI 10.1145/2623330.2623732
   Shepitsen A, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P259
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Turnbull DouglasR., 2014, CHI'14 Extended Abstracts on Human Factors in Computing Systems, P2023
   Van den Oord Aaron, 2013, P C ADV NEUR INF PRO
   Van Der Maaten Laurens, 2009, Journal of Machine Learning Research, V10, P13
NR 36
TC 2
Z9 2
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2017
VL 13
IS 4
AR 50
DI 10.1145/3105969
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FL6JZ
UT WOS:000414352300004
DA 2024-07-18
ER

PT J
AU Zhou, ML
   Zhang, YF
   Li, B
   Lin, XP
AF Zhou, Mingliang
   Zhang, Yongfei
   Li, Bo
   Lin, Xupeng
TI Complexity Correlation-Based CTU-Level Rate Control with Direction
   Selection for HEVC
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Complexity correlation; model parameter; CTU level; HEVC; optimal
   direction; reference CTU
ID RATE CONTROL ALGORITHM; RATE CONTROL SCHEME; BIT ALLOCATION; VIDEO;
   MODELS
AB Rate control is a crucial consideration in high-efficiency video coding (HEVC). The estimation of model parameters is very important for coding tree unit (CTU)-level rate control, as it will significantly affect bit allocation and thus coding performance. However, the model parameters in the CTU-level rate control sometimes fails because of inadequate consideration of the correlation between model parameters and complexity characteristic. In this study, we establish a novel complexity correlation-based CTU-level rate control for HEVC. First, we formulate the model parameter estimation scheme as a multivariable estimation problem; second, based on the complexity correlation of the neighbouring CTU, an optimal direction is selected in five directions for reference CTU set selection during model parameter estimation to further improve the prediction accuracy of the complexity of the current CTU. Third, to improve their precision, the relationship between the model parameters and the complexity of the reference CTU set in the optimal direction is established by using least square method (LS), and the model parameters are solved via the estimated complexity of the current CTU. Experimental results show that the proposed algorithm can significantly improve the accuracy of the CTU-level rate control and thus the coding performance; the proposed scheme consistently outperforms HM 16.0 and other state-of-the-art algorithms in a variety of testing configurations. More specifically, up to 8.4% and on average 6.4% BD-Rate reduction is achieved compared to HM 16.0 and up to 4.7% and an average of 3.4% BD-Rate reduction is achieved compared to other algorithms, with only a slight complexity overhead.
C1 [Zhou, Mingliang; Zhang, Yongfei; Li, Bo; Lin, Xupeng] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhang, YF (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
EM zml-0913yy@163.com; yfzhang@buaa.edu.cn; boli@buaa.edu.cn;
   1524629813@qq.com
RI Li, Bo/AAA-8968-2020; Zhou, Mingliang/HPC-0298-2023; Li,
   bo/IWL-9318-2023; Zhang, Yongfei/A-1505-2010
OI Li, Bo/0000-0002-7294-6888; Zhang, Yongfei/0000-0002-5080-1733; Zhou,
   Mingliang/0000-0002-1874-3641
FU National Key Research and Development Plan [2016YFC0801001]; NSFC
   [61632001]
FX This work is supported by the National Key Research and Development Plan
   (Grant No. 2016YFC0801001) and the NSFC Key Project (No. 61632001).
CR [Anonymous], 2017, ACM T MULTIMEDIA COM, V13
   [Anonymous], 2012, 2012 VISUAL COMMUNIC
   [Anonymous], 2014, HM REFERENCE SOFTWAR
   [Anonymous], 2013, PROC VIS COMMUN IMAG
   Bross B., 2012, JCTVCH1004 8 JCTVC M
   Cen F, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P54
   Chang Y, 2013, IEEE T BROADCAST, V59, P265, DOI 10.1109/TBC.2013.2240731
   Choi H., 2012, JOINT COLL TEAM VID
   Dong JP, 2009, IEEE T CIRC SYST VID, V19, P1108, DOI 10.1109/TCSVT.2009.2020338
   He ZH, 2008, IEEE T MULTIMEDIA, V10, P1237, DOI 10.1109/TMM.2008.2004903
   Jing X, 2008, IEEE SIGNAL PROC LET, V15, P373, DOI 10.1109/LSP.2008.920010
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li Binghao, 2013, J GUIZHOU COLL FINAN, P1
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Li ZG, 2006, J VIS COMMUN IMAGE R, V17, P376, DOI 10.1016/j.jvcir.2005.04.004
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Lin WY, 2008, IEEE T CIRC SYST VID, V18, P1128, DOI 10.1109/TCSVT.2008.927111
   Liu JY, 2010, IEEE T CIRC SYST VID, V20, P967, DOI 10.1109/TCSVT.2010.2045924
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Liu YW, 2011, IEEE T BROADCAST, V57, P562, DOI 10.1109/TBC.2011.2105652
   Mansour H, 2011, IEEE T MULTIMEDIA, V13, P165, DOI 10.1109/TMM.2010.2099648
   Shao F, 2013, IEEE T MULTIMEDIA, V15, P1843, DOI 10.1109/TMM.2013.2269897
   Si JJ, 2013, PICT COD SYMP, P89, DOI 10.1109/PCS.2013.6737690
   Soh Y. C., 2006, P IEEE INT C AC SPEE, V2, pII905
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang F, 2014, OXID MED CELL LONGEV, V2014, DOI 10.1155/2014/203458
   Wang MH, 2016, IEEE T IMAGE PROCESS, V25, P2943, DOI 10.1109/TIP.2016.2552646
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Wang P., 2013, Interactive information seeking, behaviour and retrieval, P15
   Wang SS, 2013, IEEE J-STSP, V7, P1101, DOI 10.1109/JSTSP.2013.2272240
   Wang X., 2013, JCTVCM0257
   Wang ZY, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P559, DOI 10.1109/CISP.2008.542
   Yan B, 2009, IEEE SIGNAL PROC LET, V16, P145, DOI 10.1109/LSP.2008.2010813
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Zhao DD, 2011, COMPUT ELECTR ENG, V37, P550, DOI 10.1016/j.compeleceng.2011.04.009
   Zhao TS, 2013, IEEE J-STSP, V7, P1135, DOI 10.1109/JSTSP.2013.2271421
   Zhou ML, 2016, J VIS COMMUN IMAGE R, V34, P204, DOI 10.1016/j.jvcir.2015.11.011
NR 39
TC 15
Z9 16
U1 1
U2 15
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2017
VL 13
IS 4
AR 53
DI 10.1145/3107616
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FL6JZ
UT WOS:000414352300007
DA 2024-07-18
ER

PT J
AU Zhang, QC
   Yang, LT
   Liu, XG
   Chen, ZK
   Li, P
AF Zhang, Qingchen
   Yang, Laurence T.
   Liu, Xingang
   Chen, Zhikui
   Li, Peng
TI A Tucker Deep Computation Model for Mobile Multimedia Feature Learning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Tucker decomposition; deep computation; mobile
   multimedia; back-propagation
ID DATA-MANAGEMENT
AB Recently, the deep computation model, as a tensor deep learning model, has achieved super performance for multimedia feature learning. However, the conventional deep computation model involves a large number of parameters. Typically, training a deep computation model with millions of parameters needs high-performance servers with large-scale memory and powerful computing units, limiting the growth of the model size for multimedia feature learning on common devices such as portable CPUs and conventional desktops. To tackle this problem, this article proposes a Tucker deep computation model by using the Tucker decomposition to compress the weight tensors in the full-connected layers for multimedia feature learning. Furthermore, a learning algorithm based on the back-propagation strategy is devised to train the parameters of the Tucker deep computation model. Finally, the performance of the Tucker deep computation model is evaluated by comparing with the conventional deep computation model on two representative multimedia datasets, that is, CUAVE and SNAE2, in terms of accuracy drop, parameter reduction, and speedup in the experiments. Results imply that the Tucker deep computation model can achieve a large-parameter reduction and speedup with a small accuracy drop for multimedia feature learning.
C1 [Zhang, Qingchen; Yang, Laurence T.] Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China.
   [Zhang, Qingchen; Yang, Laurence T.] St Francis Xavier Univ, Dept Comp Sci, Antigonish, NS B2G 2W5, Canada.
   [Liu, Xingang] Univ Elect Sci & Technol China, Sch Elect Engn, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
   [Chen, Zhikui; Li, Peng] Dalian Univ Technol, Sch Software Technol, 321 Tuqiang St, Dalian, Peoples R China.
C3 University of Electronic Science & Technology of China; Saint Francis
   Xavier University - Canada; University of Electronic Science &
   Technology of China; Dalian University of Technology
RP Zhang, QC (corresponding author), Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China.; Zhang, QC (corresponding author), St Francis Xavier Univ, Dept Comp Sci, Antigonish, NS B2G 2W5, Canada.
EM qzhang@stfx.ca; ltyang@gmail.com; hanksliu@uestc.edu.cn;
   zkchen@dlut.edu.cn; lipeng2015@mail.dlut.edu.cn
RI Laurence T. Yang, FCAE/AAA-1898-2019
OI Laurence T. Yang, FCAE/0000-0002-7986-4244
CR Ademoye OA, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2957753
   [Anonymous], ACM T KNOWLEDGE DISC
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], IEEE CLOUD COMPUTING
   [Anonymous], 2011, P ICML
   [Anonymous], NATURE
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Cichocki A., 2014, Era of big data processing: a new approach via tensor networks and tensor decompositions. arXiv, P1
   Deng L, 2012, INT CONF ACOUST SPEE, P2133, DOI 10.1109/ICASSP.2012.6288333
   Denil M., 2013, P 26 INT C NEUR INF, P2148
   Dong MX, 2016, IEEE INTERNET THINGS, V3, P511, DOI 10.1109/JIOT.2016.2517405
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Ilarri S, 2014, IEEE MULTIMEDIA, V21, P10, DOI 10.1109/MMUL.2014.12
   Lebedev V., 2014, INT C LEARNING REPRE
   Liu XL, 2015, IEEE T COMMUN, V63, P1432, DOI 10.1109/TCOMM.2015.2402660
   Liu Z, 2017, MOBILE NETW APPL, V22, P98, DOI 10.1007/s11036-016-0694-8
   Meng L, 2014, IEEE T KNOWL DATA EN, V26, P2293, DOI 10.1109/TKDE.2013.47
   Novikov A, 2015, ADV NEUR IN, V28
   Ouyang WL, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.299
   Patterson EK, 2002, INT CONF ACOUST SPEE, P2017
   Raina R., 2009, ICML, P1
   Ren A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC)
   Sainath TN, 2013, INT CONF ACOUST SPEE, P6655, DOI 10.1109/ICASSP.2013.6638949
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shin K, 2017, IEEE T KNOWL DATA EN, V29, P100, DOI 10.1109/TKDE.2016.2610420
   Wiesler Simon, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P180, DOI 10.1109/ICASSP.2014.6853582
   Wong WK, 2015, IEEE T CYBERNETICS, V45, P2425, DOI 10.1109/TCYB.2014.2374452
   Wu J, 2016, IEEE ACCESS, V4, P416, DOI 10.1109/ACCESS.2016.2517321
   Wu QB, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P20, DOI 10.1109/BigMM.2015.27
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Zhang QC, 2016, IEEE T COMPUT, V65, P1351, DOI 10.1109/TC.2015.2470255
   Zhang QC, 2016, IEEE T SERV COMPUT, V9, P161, DOI 10.1109/TSC.2015.2497705
   Zhang YB, 2017, IEEE T MED IMAGING, V36, P142, DOI 10.1109/TMI.2016.2600249
   Zhao XY, 2015, IEEE SIGNAL PROC LET, V22, P1487, DOI 10.1109/LSP.2015.2410134
   Zhou YC, 2015, NEUROCOMPUTING, V168, P408, DOI 10.1016/j.neucom.2015.05.086
   Zhu CS, 2014, WIREL COMMUN MOB COM, V14, P19, DOI 10.1002/wcm.1219
NR 38
TC 31
Z9 31
U1 1
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2017
VL 13
IS 3
SU S
AR 39
DI 10.1145/3063593
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FP1UO
UT WOS:000417400400007
DA 2024-07-18
ER

PT J
AU Ye, J
   Hu, H
   Qi, GJ
   Hua, KA
AF Ye, Jun
   Hu, Hao
   Qi, Guo-Jun
   Hua, Kien A.
TI A Temporal Order Modeling Approach to Human Action Recognition from
   Multimodal Sensor Data
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; temporal order modeling; optimization;
   multimodal sensor data
AB From wearable devices to depth cameras, researchers have exploited various multimodal data to recognize human actions for applications, such as video gaming, education, and healthcare. Although there many successful techniques have been presented in the literature, most current approaches have focused on statistical or local spatiotemporal features and do not explicitly explore the temporal dynamics of the sensor data. However, human action data contain rich temporal structure information that can characterize the unique underlying patterns of different action categories. From this perspective, we propose a novel temporal order modeling approach to human action recognition. Specifically, we explore subspace projections to extract the latent temporal patterns from different human action sequences. The temporal order between these patterns are compared, and the index of the pattern that appears first is used to encode the entire sequence. This process is repeated multiple times and produces a compact feature vector representing the temporal dynamics of the sequence. Human action recognition can then be efficiently solved by the nearest neighbor search based on the Hamming distance between these compact feature vectors. We further introduce a sequential optimization algorithm to learn the optimized projections that preserve the pairwise label similarity of the action sequences. Experimental results on two public human action datasets demonstrate the superior performance of the proposed technique in both accuracy and efficiency.
C1 [Ye, Jun; Hu, Hao; Qi, Guo-Jun; Hua, Kien A.] Univ Cent Florida, Dept Comp Sci, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Ye, J; Qi, GJ (corresponding author), Univ Cent Florida, Dept Comp Sci, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.
EM jye@ucf.edu; hao_hu@knights.ucf.edu; guojun.qi@ucf.edu;
   kienhua@eecs.ucf.edu
RI Qi, Guo-Jun/AAH-8294-2019; Cataldi, Antonio/AAM-7411-2021
OI Qi, Guo-Jun/0000-0003-3508-1851
FU NASA [NNX15AV40A]
FX This material is based on work that was partially supported by NASA
   under grant NNX15AV40A. Any opinions, findings, and conclusions or
   recommendations expressed in this material are those of the authors and
   do not necessarily reflect the views of NASA.
CR Altun K, 2010, PATTERN RECOGN, V43, P3605, DOI 10.1016/j.patcog.2010.04.019
   [Anonymous], 2013, P 21 ACM INT C MULT
   [Anonymous], 2015, LASAGNE 1 RELEASE
   [Anonymous], P IEEE C COMP VIS PA
   Barshan B, 2014, COMPUT J, V57, P1649, DOI 10.1093/comjnl/bxt075
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Gupta Raj., 2013, P 21 ACM INT C MULTI, P283, DOI DOI 10.1145/2502081.2502099
   Han L, 2010, IMAGE VISION COMPUT, V28, P836, DOI 10.1016/j.imavis.2009.08.003
   He ZY, 2009, IEEE SYS MAN CYBERN, P5041, DOI 10.1109/ICSMC.2009.5346042
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hossain MA, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1870121.1870124
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Jun Ye, 2015, ARXIV150602184
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Preece SJ, 2009, IEEE T BIO-MED ENG, V56, P871, DOI 10.1109/TBME.2008.2006190
   Rahman AMM, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1865106.1865112
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Ye J, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P99, DOI 10.1145/2671188.2749340
   Ye J, 2015, IEEE INT SYM MULTIM, P184, DOI 10.1109/ISM.2015.11
   Yin J, 2008, IEEE T KNOWL DATA EN, V20, P1082, DOI 10.1109/TKDE.2007.1042
   Yu Zhu, 2013, P 2013 IEEE C COMP V
   Zhang B, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2750780
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 35
TC 11
Z9 11
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2017
VL 13
IS 2
AR 14
DI 10.1145/3038917
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EV1VK
UT WOS:000401537300002
DA 2024-07-18
ER

PT J
AU Amiri, M
   Al Osman, H
   Shirmohammadi, S
   Abdallah, M
AF Amiri, Maryam
   Al Osman, Hussein
   Shirmohammadi, Shervin
   Abdallah, Maha
TI Toward Delay-Efficient Game-Aware Data Centers for Cloud Gaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Design; Performance; Cloud gaming; software defined network
   (SDN)
ID OPTIMIZATION
AB Gaming on demand is an emerging service that has recently started to garner prominence in the gaming industry. Cloud-based video games provide affordable, flexible, and high-performance solutions for end-users with constrained computing resources and enables them to play high-end graphic games on low-end thin clients. Despite its advantages, cloud gaming's Quality of Experience (QoE) suffers from high and varying end-to-end delay. Since the significant part of computational processing, including game rendering and video compression, is performed in data centers, controlling the transfer of information within the cloud has an important impact on the quality of cloud gaming services. In this article, a novel method for minimizing the end-to-end latency within a cloud gaming data center is proposed. We formulate an optimization problem for reducing delay, and propose a Lagrangian Relaxation (LR) time-efficient heuristic algorithm as a practical solution. Simulation results indicate that the heuristic method can provide close-to-optimal solutions. Also, the proposed model reduces end-to-end delay and delay variation by almost 11% and 13.5%, respectively, and outperforms the existing server-centric and network-centric models. As a byproduct, our proposed method also achieves better fairness among multiple competing players by almost 45%, on average, in comparison with existing methods.
C1 [Amiri, Maryam; Al Osman, Hussein; Shirmohammadi, Shervin] Univ Ottawa, Sch Comp & Elect Engn, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
   [Abdallah, Maha] Sorbonne Univ, UPMC Univ Paris 06, CNRS, UMR Maison Pedagogie LIP6 7606, 2e Etage Porte B207 4 Pl Jussieu, F-75005 Paris, France.
C3 University of Ottawa; Centre National de la Recherche Scientifique
   (CNRS); Sorbonne Universite
RP Amiri, M (corresponding author), Univ Ottawa, Sch Comp & Elect Engn, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM mamir097@uottawa.ca; Hussein.AlOsman@uottawa.ca; drshervin@gmail.com;
   Maha.Abdallah@lip6.fr
RI Shirmohammadi, Shervin/E-6945-2012
OI Shirmohammadi, Shervin/0000-0002-3973-4445
CR Al-Fares M, 2008, ACM SIGCOMM COMP COM, V38, P63, DOI 10.1145/1402946.1402967
   Alizadeh M, 2010, ACM SIGCOMM COMP COM, V40, P63, DOI 10.1145/1851275.1851192
   Amiri M., 2015, 14 INT WORKSH NETW S
   Amiri M, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1043, DOI 10.1145/2733373.2806397
   [Anonymous], CISC GLOB CLOUD IND
   [Anonymous], 2010, 2010 P IEEE INFOCOM, DOI DOI 10.1109/INFCOM.2010.5461933
   [Anonymous], 2010, INFOCOM, DOI 10.1109/INFCOM.2010.5461930
   [Anonymous], [No title captured]
   [Anonymous], 2015, PROC 7 INT WORKSHOP
   Armitage G, 2003, ICON 2003: 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORKS, P137
   Baier G, 2002, LECT NOTES COMPUT SC, V2461, P101
   Beloglazov Anton, 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P826, DOI 10.1109/CCGRID.2010.46
   Casas P, 2012, IEEE GLOBE WORK, P1269, DOI 10.1109/GLOCOMW.2012.6477764
   Chalmet L., 1976, P EUR 2 C, P103
   Choy S, 2014, MULTIMEDIA SYST, V20, P503, DOI 10.1007/s00530-014-0367-z
   Claypool M., 2012, P ACM WORKSH NETW SY, P1, DOI DOI 10.1109/NETGAMES.2012.6404013
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Claypool Mark, 2010, Proceedings of the 1st Annual ACM SIGMM Conference on Multimedia Systems, P215, DOI [10.1145/1730836.1730863, DOI 10.1145/1730836.1730863]
   Claypool Mark., 2009, Proceedings of the 4th International Conference on Foundations of Digital Games, P34, DOI DOI 10.1145/1536513.1536529
   Dick M., 2005, NetGames'05, P1
   Dong MX, 2014, IEEE CONF COMPUT, P529, DOI 10.1109/INFCOMW.2014.6849287
   FISHER ML, 1985, INTERFACES, V15, P10, DOI 10.1287/inte.15.2.10
   Floudas C.A., 2008, Encyclopedia of optimization
   Fox J., 2015, Applied regression and generalized linear models
   Fraps, 2014, FRAPS REAL TIM VID C
   Funge J., 2013, U.S. Patent, Patent No. [20130159498 A1, 20130159498]
   Geoffrion A.M., 1974, Lagrangean relaxation for integer programming
   Grant M., 2014, CVX MATLAB SOFTWARE
   Greenberg A, 2009, ACM SIGCOMM COMP COM, V39, P51, DOI 10.1145/1594977.1592576
   Greenberg A, 2009, ACM SIGCOMM COMP COM, V39, P68, DOI 10.1145/1496091.1496103
   Guignard M., 2003, Top, V11, P151, DOI DOI 10.1007/BF02579036
   Guo CX, 2009, SIGCOMM 2009, P63
   Held M., 1974, Mathematical Programming, V6, P62, DOI 10.1007/BF01580223
   Hemmati M., 2012, INT C INF SCI COMP A, P19
   Hong HJ, 2015, IEEE T CLOUD COMPUT, V3, P42, DOI 10.1109/TCC.2014.2338295
   Huang Chun-Ying, 2013, P 4 ACM MULT SYST C, P36, DOI DOI 10.1145/2483977.2483981
   Jarschel M, 2013, MATH COMPUT MODEL, V57, P2883, DOI 10.1016/j.mcm.2011.12.014
   Kandula S, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P202
   Lampe U, 2014, COMM COM INF SC, V453, P52, DOI 10.1007/978-3-319-11561-0_4
   Lee JW, 2005, IEEE ACM T NETWORK, V13, P827, DOI 10.1109/TNET.2005.852876
   Liu L, 2009, 6TH INTERNATIONAL CONFERENCE ON AUTONOMIC COMPUTING AND COMMUNICATION, ICAC-INDUST'09, P29
   Luo GY, 2014, LECT NOTES COMPUT SC, V8630, P255, DOI 10.1007/978-3-319-11197-1_20
   Mysore RN, 2009, ACM SIGCOMM COMP COM, V39, P39
   Nelson R, 2010, GAIKAI WILL BE FEE F
   Semsarzadeh M., 2014, IEEE INT CON MULTI, P1
   Shaik Tariq, 2015, GLOBAL CLOUD GAMING
   Shi Shu., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P103, DOI [10.1145/2072298.2072313, DOI 10.1145/2072298.2072313]
   Shirmohammadi S, 2015, IEEE T CIRC SYST VID, V25, P1955, DOI 10.1109/TCSVT.2015.2473075
   Sun KR, 2015, J VIS COMMUN IMAGE R, V30, P234, DOI 10.1016/j.jvcir.2015.03.012
   Tizon N, 2011, P 16 INT C 3D WEB TE, P45
   Vamanan B, 2012, ACM SIGCOMM COMP COM, V42, P115, DOI 10.1145/2377677.2377709
   Wang FG, 2015, IEEE ICC, P460, DOI 10.1109/ICC.2015.7248364
   Wang J., 2012, NVIDIA GEFORCE GRID
   Wang XD, 2012, IEEE INFOCOM SER, P1125, DOI 10.1109/INFCOM.2012.6195471
   Waxman Olivia B., 2012, ONLIVE LAUNCHES NEW
   Wei Cai, 2012, 2012 IEEE 4th International Conference on Cloud Computing Technology and Science (CloudCom). Proceedings, P640, DOI 10.1109/CloudCom.2012.6427515
   Wilson C, 2011, ACM SIGCOMM COMP COM, V41, P50, DOI 10.1145/2043164.2018443
   Zander S., 2004, P AUSTR TELECOMMUNIC, P511
   Zander S., 2005, P 2005 ACM SIGCHI IN, P117, DOI DOI 10.1145/1178477.1178493
NR 59
TC 28
Z9 30
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2016
VL 12
IS 5
SU S
AR 71
DI 10.1145/2983639
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ0VT
UT WOS:000392929700002
DA 2024-07-18
ER

PT J
AU Jia, AL
   Shen, SQ
   Epema, DHJ
   Iosup, A
AF Jia, Adele Lu
   Shen, Siqi
   Epema, Dick H. J.
   Iosup, Alexandru
TI When Game Becomes Life: The Creators and Spectators of Online Game
   Replays and Live Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Online game communities; gamecast sharing sites; repository
   characteristics; popularity dynamics; user behaviors
AB Online gaming franchises such as World of Tanks, Defense of the Ancients, and StarCraft have attracted hundreds of millions of users who, apart from playing the game, also socialize with each other through gaming and viewing gamecasts. As a form of User Generated Content (UGC), gamecasts play an important role in user entertainment and gamer education. They deserve the attention of both industrial partners and the academic communities, corresponding to the large amount of revenue involved and the interesting research problems associated with UGC sites and social networks. Although previous work has put much effort into analyzing general UGC sites such as YouTube, relatively little is known about the gamecast sharing sites. In this work, we provide the first comprehensive study of gamecast sharing sites, including commercial streaming-based sites such as Amazon's Twitch.tv and community-maintained replay-based sites such as WoTreplays. We collect and share a novel dataset on WoTreplays that includes more than 380,000 game replays, shared by more than 60,000 creators with more than 1.9 million gamers. Together with an earlier published dataset on Twitch.tv, we investigate basic characteristics of gamecast sharing sites, and we analyze the activities of their creators and spectators. Among our results, we find that (i) WoTreplays and Twitch.tv are both fast-consumed repositories, with millions of gamecasts being uploaded, viewed, and soon forgotten; (ii) both the gamecasts and the creators exhibit highly skewed popularity, with a significant heavy tail phenomenon; and (iii) the upload and download preferences of creators and spectators are different: while the creators emphasize their individual skills, the spectators appreciate team-wise tactics. Our findings provide important knowledge for infrastructure and service improvement, for example, in the design of proper resource allocation mechanisms that consider future gamecasting and in the tuning of incentive policies that further help player retention.
C1 [Jia, Adele Lu] China Agr Univ, Coll Informat & Elect Engn, Beijing, Peoples R China.
   [Shen, Siqi] Natl Univ Def Technol, Parallel & Distributed Proc Lab, Changsha, Hunan, Peoples R China.
   [Shen, Siqi] Natl Univ Def Technol, Sch Comp, Changsha, Hunan, Peoples R China.
   [Shen, Siqi; Epema, Dick H. J.; Iosup, Alexandru] Delft Univ Technol, Software & Comp Technol Dept, NL-2600 AA Delft, Netherlands.
   [Shen, Siqi] Natl Univ Def Technol, Coll Comp, Changsha, Hunan, Peoples R China.
C3 China Agricultural University; National University of Defense Technology
   - China; National University of Defense Technology - China; Delft
   University of Technology; National University of Defense Technology -
   China
RP Shen, SQ (corresponding author), Natl Univ Def Technol, Parallel & Distributed Proc Lab, Changsha, Hunan, Peoples R China.; Shen, SQ (corresponding author), Natl Univ Def Technol, Sch Comp, Changsha, Hunan, Peoples R China.; Shen, SQ (corresponding author), Natl Univ Def Technol, Coll Comp, Changsha, Hunan, Peoples R China.
EM ljia@cau.edu.cn; shensiqi@nudt.edu.cn; D.H.J.Epema@tudelft.nl;
   A.Iosup@tudelft.nl
RI Iosup, Alexandru/G-4069-2012
OI Iosup, Alexandru/0000-0001-8030-9398
FU National Science Foundation for Young Scholars of China (NSFYSC)
   [61502500]; National Basic Research Program of China [2014CB340303];
   NSFYSC [61303064]; TU Delft; NWO/STW Veni grant large [11881]; COMMIT NL
   project [P20]
FX This work was partially supported by the National Science Foundation for
   Young Scholars of China (NSFYSC) No. 61502500, by the National Basic
   Research Program of China (Grant No. 2014CB340303), NSFYSC No. 61303064,
   by TU Delft, by the NWO/STW Veni grant large (11881), and by the COMMIT
   NL project P20.
CR Abrahamsson H., 2012, P 2012 INT MEAS C IM, P199
   [Anonymous], 2014, WALL STREET J
   [Anonymous], 2004, WIRED MAGAZINE
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI DOI 10.1145/2433396.2433443
   [Anonymous], 2015, P 6 ACM MULTIMEDIA S, DOI DOI 10.1145/2713168.2713195
   Aparicio-Pardo Ramon., 2015, Proceedings of the 6th ACM Multimedia Systems Conference, MMSys'15, P49
   Armitage G., 2006, P 5 ACM SIGCOMM WORK, P1
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Cha M, 2009, IEEE ACM T NETWORK, V17, P1357, DOI 10.1109/TNET.2008.2011358
   Chambers C, 2010, IEEE ACM T NETWORK, V18, P899, DOI 10.1109/TNET.2009.2034371
   Chen KT, 2014, IEEE T MULTIMEDIA, V16, P480, DOI 10.1109/TMM.2013.2291532
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Cheung G, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P763
   Clauset A, 2009, SIAM REV, V51, P661, DOI 10.1137/070710111
   Claypool M, 2014, MULTIMEDIA SYST, V20, P471, DOI 10.1007/s00530-014-0362-4
   Davidson James, 2010, P 4 ACM C REC SYST, P293, DOI [DOI 10.1145/1864708.1864770, 10.1145/1864708]
   Downs J., 2013, P 25 AUSTR COMPUTER, P217
   Figueiredo Flavio, 2011, P 4 ACM INT C WEB SE, P745, DOI DOI 10.1145/1935826.1935925
   Gill P, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P15
   Guo Y, 2012, ANN WORK NETW
   Hamilton WA, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1315, DOI 10.1145/2556288.2557048
   Henderson T., 2001, MULTIMEDIA 01, P212
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Huang Y, 2008, ACM SIGCOMM COMP COM, V38, P375, DOI 10.1145/1402946.1403001
   Iosup A, 2014, IEEE INTERNET COMPUT, V18, P36, DOI 10.1109/MIC.2014.19
   Jia AL, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2736698
   Kaytoue M., 2012, Proceedings of the 21st International Conference Companion on World Wide Web-WWW'12 Companion, P1181, DOI [DOI 10.1145/2187980.2188259, 10.1145/2187980.2188259]
   Kim I, 2014, IEEE INT CONF COMMUN, P1, DOI 10.1109/ICCChinaW.2014.7107856
   Li B, 2008, IEEE INFOCOM SER, P1705
   Li JX, 2015, TSINGHUA SCI TECHNOL, V20, P81, DOI 10.1109/TST.2015.7040517
   Lu XC, 2013, FUTURE GENER COMP SY, V29, P309, DOI 10.1016/j.future.2011.08.005
   Mahanti A, 2013, IEEE NETWORK, V27, P59, DOI 10.1109/MNET.2013.6423193
   McGonical Jane., 2011, REALITY IS BROKEN WH
   Nae V, 2011, IEEE T PARALL DISTR, V22, P380, DOI 10.1109/TPDS.2010.82
   Newman MEJ, 2005, CONTEMP PHYS, V46, P323, DOI 10.1080/00107510500052444
   Pouwelse J, 2005, LECT NOTES COMPUT SC, V3640, P205, DOI 10.1007/11558989_19
   Shen S., 2011, P IEEE INT WORKSH HA, P1
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Suznjevic M, 2013, MULTIMEDIA SYST, V19, P199, DOI 10.1007/s00530-012-0270-4
   Van Dolah R.F., 2013, The Condition of South Carolina's Estuarying and Coastal Habitats During 2009-2010, P1
NR 40
TC 28
Z9 37
U1 3
U2 97
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2016
VL 12
IS 4
AR 47
DI 10.1145/2957750
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DV4EH
UT WOS:000382877500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhong, SH
   Liu, Y
   Hua, KA
AF Zhong, Sheng-Hua
   Liu, Yan
   Hua, Kien A.
TI Field Effect Deep Networks for Image Recognition with Incomplete Data
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image recognition; incomplete data; missing features; deep learning
ID CLASSIFICATION; IMPUTATION
AB Image recognition with incomplete data is a well-known hard problem in computer vision and machine learning. This article proposes a novel deep learning technique called Field Effect Bilinear Deep Networks (FEBDN) for this problem. To address the difficulties of recognizing incomplete data, we design a novel second-order deep architecture with the Field Effect Restricted Boltzmann Machine, which models the reliability of the delivered information according to the availability of the features. Based on this new architecture, we propose a new three-stage learning procedure with field effect bilinear initialization, field effect abstraction and estimation, and global fine-tuning with missing features adjustment. By integrating the reliability of features into the new learning procedure, the proposed FEBDN can jointly determine the classification boundary and estimate the missing features. FEBDN has demonstrated impressive performance on recognition and estimation tasks in various standard datasets.
C1 [Zhong, Sheng-Hua] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518000, Peoples R China.
   [Liu, Yan] Hong Kong Polytech Univ, Dept Comp, Kowloon 999077, Hong Kong, Peoples R China.
   [Hua, Kien A.] Univ Cent Florida, Dept Elect Engn & Comp Sci, Orlando, FL 32816 USA.
C3 Shenzhen University; Hong Kong Polytechnic University; State University
   System of Florida; University of Central Florida
RP Liu, Y (corresponding author), Hong Kong Polytech Univ, Dept Comp, Kowloon 999077, Hong Kong, Peoples R China.
EM csshzhong@szu.edu.cn; csyliu@comp.polyu.edu.hk; kienhua@cs.ucf.edu
RI liu, yan/HGV-1365-2022
OI LIU, Yan/0000-0003-4242-4840
FU National Natural Science Foundation of China [61502311, 61373122];
   Natural Science Foundation of Guangdong Province [2016A030310053];
   Special Program for Applied Research on Super Computation of the
   NSFC-Guangdong Joint Fund; Science and Technology Innovation Commission
   of Shenzhen [JCYJ20150324141711640]; Shenzhen University [201535]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61502311, No. 61373122), Natural Science Foundation of
   Guangdong Province (No. 2016A030310053), Special Program for Applied
   Research on Super Computation of the NSFC-Guangdong Joint Fund (the
   second phase), the Science and Technology Innovation Commission of
   Shenzhen under Grant (No. JCYJ20150324141711640), and Shenzhen
   University research funding (201535).
CR Aleman A, 2003, SCHIZOPHR RES, V64, P175, DOI 10.1016/S0920-9964(03)00060-4
   [Anonymous], ICANN
   [Anonymous], 2007, Proceedings of the International Conference on Machine Learning (ICML)
   [Anonymous], 2015, AAAI
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2006, NIPS
   [Anonymous], ACM MM
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia, DOI [DOI 10.1145/2072298.2072344, 10.1145/2072298.2072344.URL, DOI 10.1145/2072298.2072344.URL]
   [Anonymous], TIP
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2008, P 25 INT C MACH LEAR
   [Anonymous], ICMR
   [Anonymous], 2005, P 22 INT C MACH LEAR, DOI DOI 10.1145/1102351.1102474
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chechik G, 2008, J MACH LEARN RES, V9, P1
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Chen YJ, 2015, IEEE COMMUN SURV TUT, V17, P1126, DOI 10.1109/COMST.2014.2363139
   Dick U., 2008, P 25 INT C MACHINE L, P232
   Ding HJ, 2015, SPEECH COMMUN, V71, P62, DOI 10.1016/j.specom.2015.02.001
   Folguera L, 2015, CHEMOMETR INTELL LAB, V143, P146, DOI 10.1016/j.chemolab.2015.03.002
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295
   Li K, 2015, IEEE T CYBERNETICS, V45, P1401, DOI 10.1109/TCYB.2014.2351831
   Malik NorbertR., 1995, Electronic Circuits: Analysis, Simulation, and Design
   Natarajan P, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2710128
   Purwar A, 2015, EXPERT SYST APPL, V42, P5621, DOI 10.1016/j.eswa.2015.02.050
   Ranzato M, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995710
   Salakhutdinov R., 2007, P 24 INT C MACHINE L, P791
   Salakhutdinov R., 2007, AISTATS, V2, P412
   Sohn K., 2013, ICML
   Tang Y., 2010, ICML 2010, P1055
   Williams D, 2007, IEEE T PATTERN ANAL, V29, P427, DOI 10.1109/TPAMI.2007.52
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Yang XS, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700286
   Zhong SH, 2015, EXPERT SYST APPL, V42, P8146, DOI 10.1016/j.eswa.2015.05.034
NR 40
TC 12
Z9 13
U1 3
U2 21
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2016
VL 12
IS 4
AR 52
DI 10.1145/2957754
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DV4EH
UT WOS:000382877500006
DA 2024-07-18
ER

PT J
AU Baldauf, M
   Fröhlich, P
   Adegeye, F
   Suette, S
AF Baldauf, Matthias
   Froehlich, Peter
   Adegeye, Florence
   Suette, Stefan
TI Investigating On-Screen Gamepad Designs for Smartphone-Controlled Video
   Games
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Experimentation; Human Factors; Touchscreen; smartphone;
   gamepad; game controller
AB On-screen gamepads are increasingly used as controllers for video games on distant screens, yet lack the typical tactile feedback known from hardware controllers. We conducted a comparative lab study to investigate four smartphone gamepads inspired by traditional game controllers and mobile game controls (directional buttons, directional pad, floating joystick, tilt control). The study consisted of both completing a formal control test as well as controlling two popular video games of different genres (Pac-Man and Super Mario Bros.). The results indicate that the directional buttons require the most attention of the user, however, work precisely for direction-restricted navigational tasks. Directional pad and joystick showed a similar performance, yet they encourage drifting and unintended operations when the user is focused on the remote screen. While currently unfamiliar to many users, the floating joystick can reduce the glances at the device. Tilt turned out to be not sufficiently precise and quick for the investigated tasks. The article concludes with derived design guidelines with easily realizable measures for typical contexts such as casual gaming at home or spontaneous gaming on public displays.
C1 [Baldauf, Matthias] Vienna Univ Technol, Res Grp Ind Software, A-1040 Vienna, Austria.
   [Froehlich, Peter] AIT Austria Inst Technol, A-1210 Vienna, Austria.
   [Adegeye, Florence; Suette, Stefan] FTW Telecommun Res Ctr Vienna, A-1220 Vienna, Austria.
C3 Technische Universitat Wien
RP Baldauf, M (corresponding author), Vienna Univ Technol, Res Grp Ind Software, Wiedner Hauptstr 76, A-1040 Vienna, Austria.
EM atthias.bakdau@inso.tuwien.ac.at
RI Suette, Stefan/AAY-8548-2021
OI Suette, Stefan/0000-0002-6044-5939; Baldauf,
   Matthias/0000-0002-1876-5082; Frohlich, Peter/0000-0002-2502-5947
FU netidee initiative of the Internet Foundation Austria (IPA); FTW
   Forschungszentrum TelekommunikationWien GmbH within the program COMET by
   BMVIT; FTW Forschungszentrum TelekommunikationWien GmbH within the
   program COMET by BMWA; FTW Forschungszentrum TelekommunikationWien GmbH
   within the program COMET by City of Vienna
FX This work has been carried out within the project ATREUS financed by the
   netidee initiative of the Internet Foundation Austria (IPA). FTW
   Forschungszentrum TelekommunikationWien GmbH is funded within the
   program COMET by BMVIT, BMWA, and the City of Vienna. The COMET program
   is managed by the FFG.
CR Baldauf M., 2013, P HUM FACT COMP SYST, P3015
   Baldauf M, 2013, INT J MOB HUM COMPUT, V5, P1, DOI 10.4018/jmhci.2013040101
   Ballagas R, 2006, IEEE PERVAS COMPUT, V5, P70, DOI 10.1109/MPRV.2006.18
   Bohmer Matthias, 2011, P 13 INT C HUM COMP, P605, DOI [10.1145/2037373.2037468, DOI 10.1145/2037373.2037468]
   BORING S, 2007, P 21 ANN C AUSTR COM, P161, DOI DOI 10.1145/1738826.1738853
   Boring Sebastian, 2011, P SIGCHI C HUM FACT, P2721, DOI DOI 10.1145/1978942.1979342
   Brown M, 2010, HUM-COMPUT INT-SPRIN, P209, DOI 10.1007/978-1-84882-963-3_12
   Browne K, 2012, ENTERTAIN COMPUT, V3, P1, DOI 10.1016/j.entcom.2011.06.001
   Cao X, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P77
   Chehimi Fadi, 2008, P ACE 08, P267, DOI [10.1145/1501750.1501813, DOI 10.1145/1501750.1501813]
   Chu K., 2011, Proceedings of the 2011 International Conference on User Science and Engineering (i-USEr 2011), P83, DOI 10.1109/iUSEr.2011.6150542
   Chu K, 2013, LECT NOTES COMPUT SC, V8237, P347, DOI 10.1007/978-3-319-02958-0_32
   Chui Yin Wong, 2010, Proceedings of 2010 International Symposium on Information Technology (ITSim 2010), P1093, DOI 10.1109/ITSIM.2010.5561513
   Douglas S. A., 2009, P SIGCHI C HUM FACT, P215
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Gilbertson P., 2008, COMPUTER ENTERTAINME, V6
   Hurst Wolfgang, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P93, DOI 10.1007/978-3-319-03161-3_7
   Joselli M, 2012, 2012 IEEE INT GAM IN, P1
   Katzakis N, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P139, DOI 10.1109/3DUI.2010.5444700
   Lee S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P309
   Lorenz Andreas, 2010, P 9 INT C MOB UB MUL
   Lubitz Kolja, 2012, Entertainment Computing, 11th International Conference (ICEC - 2012). Proceedings, P473, DOI 10.1007/978-3-642-33542-6_56
   Luojus Petri., 2013, Proceedings of the 2nd ACM International Symposium on Pervasive Displays, P109
   Medryk S., PROC MHCI 2013
   Natapov D., 2009, Proceedings of Graphics Interface 2009, P223
   Oshita M., 2012, P WASA 2012 WORKSH S, V1, P27, DOI [10.1145/2425296.2425301, DOI 10.1145/2425296.2425301]
   Rashid U, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P99, DOI 10.1145/2254556.2254577
   Scheible J., 2005, MULTIMEDIA 05, P199, DOI DOI 10.1145/1101149.1101178
   Vajk T, 2008, INT J COMPUT GAMES T, V2008, DOI 10.1155/2008/539078
   Valente Luis, 2009, Journal of the Brazilian Computer Society, V15, P45, DOI 10.1007/BF03192576
   Zaman Loutfouz, 2013, P INT C MULT HUM COM, P691
   Zaman Loutfouz., 2010, Proceedings of the International Academic Conference on the Future of Game Design and Technology, Futureplay '10, P183
NR 32
TC 17
Z9 20
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2015
VL 12
IS 1
SU S
SI SI
AR 22
DI 10.1145/2808202
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CU6PH
UT WOS:000363654100012
DA 2024-07-18
ER

PT J
AU Bianco, S
   Ciocca, G
AF Bianco, Simone
   Ciocca, Gianluigi
TI User Preferences Modeling and Learning for Pleasing Photo Collage
   Generation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Algorithms; Experimentation; Performance; Automatic collage
   creation; optimization algorithm; preference modeling; subjective
   experiment; user modeling; visual features extraction
ID DIRECT SEARCH; OPTIMIZATION; LAYOUT; VIDEO
AB In this article, we consider how to automatically create pleasing photo collages created by placing a set of images on a limited canvas area. The task is formulated as an optimization problem. Differently from existing state-of-the-art approaches, we here exploit subjective experiments to model and learn pleasantness from user preferences. To this end, we design an experimental framework for the identification of the criteria that need to be taken into account to generate a pleasing photo collage. Five different thematic photo datasets are used to create collages using state-of-the-art criteria. A first subjective experiment where several subjects evaluated the collages, emphasizes that different criteria are involved in the subjective definition of pleasantness. We then identify new global and local criteria and design algorithms to quantify them. The relative importance of these criteria are automatically learned by exploiting the user preferences, and new collages are generated. To validate our framework, we performed several psycho-visual experiments involving different users. The results shows that the proposed framework allows to learn a novel computational model which effectively encodes an inter-user definition of pleasantness. The learned definition of pleasantness generalizes well to new photo datasets of different themes and sizes not used in the learning. Moreover, compared with two state-of-the-art approaches, the collages created using our framework are preferred by the majority of the users.
C1 [Bianco, Simone; Ciocca, Gianluigi] Univ Milano Bicocca, Dept Informat Syst & Commun DISCo, Milan, Italy.
C3 University of Milano-Bicocca
RP Bianco, S (corresponding author), Univ Milano Bicocca, Dept Informat Syst & Commun DISCo, Milan, Italy.
EM bianco@disco.unimib.it; ciocca@disco.unimib.it
RI Bianco, Simone/T-1224-2019; Ciocca, Gianluigi/U-8771-2019
OI Bianco, Simone/0000-0002-7070-1545; Ciocca,
   Gianluigi/0000-0003-2878-2131
CR Ali Borji, 2014, ARXIV14115878CSCV
   [Anonymous], 2006, P CVPR
   [Anonymous], 2013, AS PAC SIGN INF PROC, DOI DOI 10.1109/APSIPA.2013.6694305
   [Anonymous], 1989, GENETIC ALGORITHMS S
   Battiato S, 2008, LECT NOTES COMPUT SC, V4918, P211, DOI 10.1007/978-3-540-79860-6_17
   Bianco S, 2012, IEEE T IMAGE PROCESS, V21, P4868, DOI 10.1109/TIP.2012.2211029
   Bianco S, 2012, PROC SPIE, V8300, DOI 10.1117/12.911021
   Calic J, 2007, IEEE T CIRC SYST VID, V17, P931, DOI 10.1109/TCSVT.2007.897466
   Chao H, 2010, DOCENG2010: PROCEEDINGS OF THE 2010 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P111
   Chen Jun-Cheng, 2006, P 14 ACM INT C MULTI, P25
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Ciocca Gianluigi, 2010, DIGITAL PHOTOGRAPHY, V7537
   Diakopoulos Nicholas., 2005, P 18 ANN ACM S USER, P183
   Duncan K, 2012, IET COMPUT VIS, V6, P514, DOI 10.1049/iet-cvi.2012.0032
   Eberhart R., 1995, MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science (Cat. No.95TH8079), P39, DOI 10.1109/MHS.1995.494215
   Ekhtiyar Hesam, 2011, INT J COMPUT SCI, V8, P165
   Fan J, 2012, IEEE INT CONF MULTI, P308, DOI 10.1109/ICMEW.2012.59
   Girgensohn Andreas, 2003, P IEEE INT C IM PROC, V2, P871
   Goferman S, 2010, COMPUT GRAPH FORUM, V29, P459, DOI 10.1111/j.1467-8659.2009.01615.x
   HOOKE R, 1961, J ACM, V8, P212, DOI 10.1145/321062.321069
   Huang H, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024189
   Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Khosla Aditya, 2012, NIPS, V2
   Kimura A, 2013, IEICE T INF SYST, VE96D, P562, DOI 10.1587/transinf.E96.D.562
   Kolda TG, 2003, SIAM REV, V45, P385, DOI [10.1137/S003614450242889, 10.1137/S0036144502428893]
   Lee M. H., 2010, P IEEE COMP SOC C CO
   Liu T, 2009, IEEE T MULTIMEDIA, V11, P1225, DOI 10.1109/TMM.2009.2030741
   Luo SJ, 2013, IEEE T CIRC SYST VID, V23, P2044, DOI 10.1109/TCSVT.2013.2270392
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Mei T, 2009, VISUAL COMPUT, V25, P39, DOI 10.1007/s00371-008-0282-4
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Ou LC, 2006, COLOR RES APPL, V31, P191, DOI 10.1002/col.20208
   Rother C, 2005, PROC CVPR IEEE, P589
   Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965
   Sandhaus P, 2011, LECT NOTES COMPUT SC, V6523, P84
   Solli Martin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1885, DOI 10.1109/ICCVW.2009.5457512
   Wei Y., 2009, MSRTR-2009-59
   Yang YZ, 2009, VISUAL COMPUT, V25, P431, DOI 10.1007/s00371-009-0346-0
   Yu ZQ, 2014, IEEE T VIS COMPUT GR, V20, P182, DOI 10.1109/TVCG.2013.106
   Zhipeng Wu, 2014, Journal of Multimedia, V9, P4, DOI 10.4304/jmm.9.1.4-13
NR 42
TC 13
Z9 14
U1 2
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2015
VL 12
IS 1
AR 6
DI 10.1145/2801126
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CP9LG
UT WOS:000360215200006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, Y
   Boukerche, A
AF Li, Yang
   Boukerche, Azzedine
TI QuGu: A Quality Guaranteed Video Dissemination Protocol Over Urban
   Vehicular Ad Hoc Networks
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Experimentation; Performance; Vehicular network; video
   streaming; QoS; network coding; connected dominating set; interleaving;
   routing protocols
AB Video dissemination over Vehicular Ad Hoc Networks is an attractive technology that supports many novel applications. The merit of this work lies in the design of an efficient video dissemination protocol that provides high video quality at different data rates for urban scenarios. Our objective is to improve received video quality while meeting delay and packet loss. In this work, we first employ a reliable scheme known as connected dominating set, which is an efficient receiver-based routing scheme for broadcasting video content. To avoid repeated computing of the connected dominating set, we add three statuses to each node. In nonscalable video coding, the distribution of lost frames can cause a major impact on video quality at the receiver's end. Therefore, for the second step, we employ Interleaving to spread out the burst losses and to reduce the influence of loss distributions. Although Interleaving can reduce the influence of cluster frame loss, single packet loss is also a concern due to collisions, and to intermittent disconnection in the topology. In order to fix these single packet losses, we propose a store-carry-forward scheme for the nodes in order to retransmit the local buffer stored packets. The results, when compared to the selected base protocols, show that our proposed protocol is an efficient solution for video dissemination over urban Vehicular Ad Hoc Networks.
C1 [Li, Yang; Boukerche, Azzedine] Univ Ottawa, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Li, Y (corresponding author), Univ Ottawa, Ottawa, ON K1N 6N5, Canada.
EM seraph1713@gmail.com
FU NSERC; Canada Research Chairs Program; NSERC-DIVA Strategy Research
   Network
FX This work is partially supported by NSERC, Canada Research Chairs
   Program, NSERC-DIVA Strategy Research Network.
CR [Anonymous], THESIS U OTTAWA
   [Anonymous], 2012, P 15 ACM INT C MOD A
   [Anonymous], DIGITAL SIGNAL PROCE
   [Anonymous], END END QOS NETWORK
   [Anonymous], 2013, 2013 INT C INF SCI A
   Chang CL, 2011, COMPUT COMMUN, V34, P1195, DOI 10.1016/j.comcom.2010.12.005
   Claypool M, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P508
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Ho T, 2006, IEEE T INFORM THEORY, V52, P4413, DOI 10.1109/TIT.2006.881746
   Issariyakul T., 2011, Introduction to network simulator NS2
   Keller L, 2013, ACM T SENSOR NETWORK, V9, DOI 10.1145/2422966.2422982
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Krajzewicz D., 2012, Int. J. Adv. Syst. Meas., V5, P128
   Lysiuk I.S., 2010, WIR COMM NETW C WCNC, P1, DOI [10.1109/WCNC.2010.5506346, DOI 10.1109/WCNC.2010.5506346]
   Maia G, 2013, IEEE ICC, P5997, DOI 10.1109/ICC.2013.6655559
   Maia Guilherme, 2013, P 16 ACM INT C MOD A, P419, DOI DOI 10.1145/2507924.2507962
   Mammeri A, 2014, IEEE ICC, P1854, DOI 10.1109/ICC.2014.6883593
   Mariyasagayam MN., 2007, 7 INT C ITS TELECOMM, P1, DOI DOI 10.1109/ITST.2007.4295866
   Naeimipoor F, 2014, IEEE ICC, P112, DOI 10.1109/ICC.2014.6883304
   Naeimipoor F, 2012, PROCEEDINGS OF THE 37TH ANNUAL IEEE CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN 2012), P694, DOI 10.1109/LCNW.2012.6424052
   Park J.-S., 2006, PROC ACM VANET 2006, P102
   Pazzi RW, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2602222
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   R Core Team, 2020, R FDN STAT COMPUTING
   Rezende C, 2014, AD HOC NETW, V17, P1, DOI 10.1016/j.adhoc.2013.12.011
   Rezende Cristiano, P IEEE INT C COMMUNI, P698
   Ribeiro F, 2011, INT CONF ACOUST SPEE, P2416
   Rossi D, 2011, SECUR COMMUN NETW, V4, P329, DOI 10.1002/sec.211
   Soldo F, 2011, IEEE T PARALL DISTR, V22, P1085, DOI 10.1109/TPDS.2010.173
   Venkataraman M, 2011, IEEE NETWORK, V25, P4, DOI 10.1109/MNET.2011.5687947
   Viriyasitavat W., 2010, Proceedings 2010 IEEE Vehicular Networking Conference (VNC 2010), P25, DOI 10.1109/VNC.2010.5698266
   Wang RF, 2012, 2012 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS (ISCC), P436, DOI 10.1109/ISCC.2012.6249335
   Whaiduzzaman M, 2014, J NETW COMPUT APPL, V40, P325, DOI 10.1016/j.jnca.2013.08.004
   Wu J, 2001, TELECOMMUN SYST, V18, P13, DOI 10.1023/A:1016783217662
   Xie F, 2007, IEEE VTS VEH TECHNOL, P2121, DOI 10.1109/VETECF.2007.445
NR 35
TC 4
Z9 4
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2015
VL 11
IS 4
AR 55
DI 10.1145/2725469
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CK0ZF
UT WOS:000355933700008
DA 2024-07-18
ER

PT J
AU Ghinea, G
   Timmerer, C
   Lin, WS
   Gulliver, SR
AF Ghinea, Gheorghita
   Timmerer, Christian
   Lin, Weisi
   Gulliver, Stephen R.
TI Mulsemedia: State of the Art, Perspectives, and Challenges
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Human Factors; Experimentation; Theory; Mulsemedia;
   multisensory; contour perception; flow visualization; perceptual theory;
   visual cortex; visualization
ID QUALITY ASSESSMENT; SENSORY EXPERIENCE; PERCEPTION; MODELS;
   SYNCHRONIZATION; ATTENTION; FRAMEWORK; SPEECH
AB Mulsemedia-multiple sensorial media-captures a wide variety of research efforts and applications. This article presents a historic perspective on mulsemedia work and reviews current developments in the area. These take place across the traditional multimedia spectrum-from virtual reality applications to computer games-as well as efforts in the arts, gastronomy, and therapy, to mention a few. We also describe standardization efforts, via the MPEG-V standard, and identify future developments and exciting challenges the community needs to overcome.
C1 [Ghinea, Gheorghita] Dept Comp Sci, Uxbridge UB8 3PH, Middx, England.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Gulliver, Stephen R.] Henley Business Sch, Reading RG6 6UR, Berks, England.
   [Ghinea, Gheorghita] Brunel Univ, Uxbridge UB8 3PH, Middx, England.
   [Timmerer, Christian] Alpen Adria Univ, Klagenfurt, Austria.
   Nanyang Technol Univ, Singapore, Singapore.
   [Gulliver, Stephen R.] Univ Reading, Reading RG6 2AH, Berks, England.
C3 Nanyang Technological University; Brunel University; University of
   Klagenfurt; Nanyang Technological University; University of Reading
RP Ghinea, G (corresponding author), Dept Comp Sci, Kingston Lane, Uxbridge UB8 3PH, Middx, England.
EM george.ghinea@brunel.ac.uk; christian.timmerer@itec.uni-klu.ac.at;
   wslin@ntu.edu.sg; s.r.gulliver@henley.reading.ac.uk
RI Lin, Weisi/A-3696-2011; Gulliver, Stephen/AAE-9133-2021; Ghinea,
   Gheorghita/AAG-6770-2020; Lin, Weisi/A-8011-2012
OI Lin, Weisi/0000-0001-9866-1947; Ghinea, Gheorghita/0000-0003-2578-5580;
   Gulliver, Stephen/0000-0002-4503-5448
CR Aarts E, 2009, J AMB INTEL SMART EN, V1, P5, DOI 10.3233/AIS-2009-0001
   Ademoye OA, 2009, IEEE T MULTIMEDIA, V11, P561, DOI 10.1109/TMM.2009.2012927
   Anderson J.R., 2004, COGNITIVE PSYCHOL IT, V6th
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], P 7 IEEE WORKSH MULT
   [Anonymous], 1992, PRESENCE
   Apostolopoulos JG, 2012, P IEEE, V100, P974, DOI 10.1109/JPROC.2011.2182069
   Ayabe-Kanamura S, 1998, CHEM SENSES, V23, P31, DOI 10.1093/chemse/23.1.31
   Bodnar A, 2004, P 6 INT C MULTIMODAL, P183, DOI [10.1145/1027933.1027965, DOI 10.1145/1027933.1027965]
   Boyd-Davis S., 2006, P HUM FACT ERG SOC 2, P25
   Brewster S., 2006, SIGCHI C, P653, DOI [10.1145/1124772.1124869, DOI 10.1145/1124772.1124869]
   Campbell D, 2009, SIGNAL PROCESS, V89, P1489, DOI 10.1016/j.sigpro.2009.02.015
   Carbon CC, 2013, P IEEE, V101, P2123, DOI 10.1109/JPROC.2012.2219831
   Chang Angela., 2005, CHI 05 EXTENDED ABST, P1264, DOI [DOI 10.1145/1056808.1056892, 10.1145/1056808.1056892]
   Choi S, 2013, P IEEE, V101, P2093, DOI 10.1109/JPROC.2012.2221071
   Craig AD, 2003, CURR OPIN NEUROBIOL, V13, P500, DOI 10.1016/S0959-4388(03)00090-4
   DAMASIO AR, 1989, COGNITION, V33, P25, DOI 10.1016/0010-0277(89)90005-X
   DiMaggio P, 1997, ANNU REV SOCIOL, V23, P263, DOI 10.1146/annurev.soc.23.1.263
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Fadel C., 2008, Multimodal learning through media, what the research says
   Ghinea G., 2010, P INT C MAN EM DIG E, P277, DOI DOI 10.1145/1936254.1936308
   Ghinea G, 2011, MULTIMED TOOLS APPL, V55, P601, DOI 10.1007/s11042-010-0581-4
   Ghinea G, 2010, IEEE T SYST MAN CY A, V40, P657, DOI 10.1109/TSMCA.2010.2041224
   Goldstein E., 2013, SENSATION PERCEPTION
   Gray R, 2013, P IEEE, V101, P2113, DOI 10.1109/JPROC.2012.2225811
   Grega Michal, 2008, Przeglad Telekomunikacyjny + Wiadomosci Telekomunicayjne, V81, P142
   Gumtau S., 2011, THESIS U PORTSMOUTH
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Heilig M, 1962, Patent No. [3,050,870, 3050870]
   Hinterseer P, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P35
   Ho C, 2005, NEUROSCI LETT, V389, P35, DOI 10.1016/j.neulet.2005.07.003
   Hossfeld T., 2008, P 18 ITC SPEC SEM QU
   Ishibashi Y., 2004, P 12 ANN ACM INT C M, P604
   ISO, 2011, 230053 ISOIEC 3
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   ITU, 2008, RECP910 ITUT, P910
   ITU, 2008, RECP911 ITUT, P911
   Jain R, 2003, COMMUN ACM, V46, P48, DOI 10.1145/792704.792729
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Jones L, 2004, HUMAN PERFORMANCE, SITUATION AWARENESS AND AUTOMATION: CURRENT RESEARCH AND TRENDS, VOL 2, P282
   Kahneman D, 2003, AM PSYCHOL, V58, P697, DOI 10.1037/0003-066X.58.9.697
   Kahol K, 2006, ACM T MULTIM COMPUT, V2, P219, DOI 10.1145/1152149.1152153
   Kammerl J, 2010, PRESENCE-TELEOP VIRT, V19, P450, DOI 10.1162/pres_a_00008
   Klatzky RL, 2013, P IEEE, V101, P2081, DOI 10.1109/JPROC.2013.2248691
   Kyoungro Yoon, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P257, DOI 10.1109/MMSP.2010.5662029
   Le Callet P., 2013, Qualinet White Paper on Definitions of Quality of Experience
   Lin W., 2006, DIGITAL VIDEO IMAGE
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu K., 2013, INTELLIGENT BUILDING
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Marois R, 2005, TRENDS COGN SCI, V9, P296, DOI 10.1016/j.tics.2005.04.010
   Mayer R. E., 2003, Journal of Educational Computing Research, V29, P297, DOI 10.2190/YJLG-09F9-XKAX-753D
   Metzinger Thomas., 1995, CONSCIOUS EXPERIENCE
   Mochizuki A., 2004, P ACM SIGGRAPH SIGGR, P123
   Möller S, 2011, IEEE SIGNAL PROC MAG, V28, P18, DOI 10.1109/MSP.2011.942469
   Morrot G, 2001, BRAIN LANG, V79, P309, DOI 10.1006/brln.2001.2493
   Nakamoto T, 2008, IEEE COMPUT GRAPH, V28, P75, DOI 10.1109/MCG.2008.3
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Narwaria M, 2012, IEEE T AUDIO SPEECH, V20, P1217, DOI 10.1109/TASL.2011.2174223
   Nothdurft HC, 2000, VISION RES, V40, P1183, DOI 10.1016/S0042-6989(00)00031-6
   Otaduy MA, 2013, P IEEE, V101, P2068, DOI 10.1109/JPROC.2013.2246131
   Pyo S, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P1129
   Rainer B, 2012, INT WORK QUAL MULTIM, P278, DOI 10.1109/QoMEX.2012.6263842
   Reinhard E, 2013, P IEEE, V101, P1998, DOI 10.1109/JPROC.2013.2260711
   Rowe LA, 2005, ACM T MULTIM COMPUT, V1, P3, DOI 10.1145/1047936.1047938
   Rubinstein JS, 2001, J EXP PSYCHOL HUMAN, V27, P763, DOI 10.1037//0096-1523.27.4.763
   Ruyter B.D., 2004, P WORKING C ADV VISU, P203, DOI DOI 10.1145/989863.989897
   Sarter N, 2013, P IEEE, V101, P2105, DOI 10.1109/JPROC.2013.2245852
   SCHILLER PH, 1986, VISION RES, V26, P1351, DOI 10.1016/0042-6989(86)90162-8
   SMYTHIES J, 1994, WALLS PLATOS CAVE
   SMYTHIES JR, 1994, INQUIRY, V37, P311, DOI 10.1080/00201749408602356
   Stamper R.K., 1973, INFORM BUSINESS ADM
   Steinbach E, 2012, P IEEE, V100, P937, DOI 10.1109/JPROC.2011.2182100
   Suk CB, 2009, 2009 FOURTH INTERNATIONAL CONFERENCE ON INTERNET AND WEB APPLICATIONS AND SERVICES, P649, DOI 10.1109/ICIW.2009.104
   Timmerer C, 2012, SIGNAL PROCESS-IMAGE, V27, P909, DOI 10.1016/j.image.2012.01.016
   Tortell R., 2007, Virtual Reality, V11, P61, DOI 10.1007/s10055-006-0056-0
   Vetro A, 2005, IEEE T MULTIMEDIA, V7, P418, DOI 10.1109/TMM.2005.846795
   Waltl M, 2013, SIGNAL PROCESS-IMAGE, V28, P136, DOI 10.1016/j.image.2012.10.009
   Waltl M, 2012, INT WORK QUAL MULTIM, P115, DOI 10.1109/QoMEX.2012.6263841
   WILLIAMS AA, 1984, J I BREWING, V90, P250, DOI 10.1002/j.2050-0416.1984.tb04266.x
   Wu HR, 2013, P IEEE, V101, P2025, DOI 10.1109/JPROC.2013.2262911
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yarbus A.L., 1967, EYE MOVEMENTS VISION, DOI [10.1007/978-1-4899-5379-7, DOI 10.1007/978-1-4899-5379-7]
   Yazdani A, 2012, INT WORK QUAL MULTIM, P272, DOI 10.1109/QoMEX.2012.6263860
   Yost W.A., 1985, FUNDAMENTALS HEARING
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
   Zhang L., 2013, Selective visual attention: Computational models and applications
NR 89
TC 107
Z9 110
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2014
VL 11
IS 1
SU S
SI SI
AR 17
DI 10.1145/2617994
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA AS0RG
UT WOS:000343984800009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Katti, H
   Rajagopal, AK
   Kankanhalli, M
   Kalpathi, R
AF Katti, Harish
   Rajagopal, Anoop Kolar
   Kankanhalli, Mohan
   Kalpathi, Ramakrishnan
TI Online Estimation of Evolving Human Visual Interest
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Human Factors; Video retargeting; video captioning; gaze; visual
   attention
AB Regions in video streams attracting human interest contribute significantly to human understanding of the video. Being able to predict salient and informative Regions of Interest (ROIs) through a sequence of eye movements is a challenging problem. Applications such as content-aware retargeting of videos to different aspect ratios while preserving informative regions and smart insertion of dialog (closed-caption text) into the video stream can significantly be improved using the predicted ROIs. We propose an interactive human-in-the-loop framework to model eye movements and predict visual saliency into yet-unseen frames. Eye tracking and video content are used to model visual attention in a manner that accounts for important eye-gaze characteristics such as temporal discontinuities due to sudden eye movements, noise, and behavioral artifacts. A novel statistical-and algorithm-based method gaze buffering is proposed for eye-gaze analysis and its fusion with content-based features. Our robust saliency prediction is instantiated for two challenging and exciting applications. The first application alters video aspect ratios on-the-fly using content-aware video retargeting, thus making them suitable for a variety of display sizes. The second application dynamically localizes active speakers and places dialog captions on-the-fly in the video stream. Our method ensures that dialogs are faithful to active speaker locations and do not interfere with salient content in the video stream. Our framework naturally accommodates personalisation of the application to suit biases and preferences of individual users.
C1 [Katti, Harish; Rajagopal, Anoop Kolar; Kalpathi, Ramakrishnan] Indian Inst Sci, Bangalore 560012, Karnataka, India.
   [Kankanhalli, Mohan] Natl Univ Singapore, Singapore 119077, Singapore.
C3 Indian Institute of Science (IISC) - Bangalore; National University of
   Singapore
RP Katti, H (corresponding author), Indian Inst Sci, New BEL Rd, Bangalore 560012, Karnataka, India.
EM harish2006@gmail.com
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
CR A1 Clip: Paris Zarcilla, 2009, ANIBOOM ONL VID CLIP
   Alfredson Tomas., 2011, Tinker Tailor Soldier Spy
   Alnajar F, 2013, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2013.24
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], 2007, P ADV NEUR INF PROC, DOI [10.1016/j.visres.2015.04.007, DOI 10.1016/J.VISRES.2015.04.007]
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Baldi P, 2010, NEURAL NETWORKS, V23, P649, DOI 10.1016/j.neunet.2009.12.007
   Chakde Clip: Dir. Shimit Amin, 2007, CHAK DE INDIA
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Feng YL, 2013, IEEE T MULTIMEDIA, V15, P1865, DOI 10.1109/TMM.2013.2272918
   Grundmann M, 2010, PROC CVPR IEEE, P569, DOI 10.1109/CVPR.2010.5540165
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hong R., 2010, Proceedings of the 18th ACM international conference on Multimedia, P421
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jain E., 2012, THESIS CARNEGIE MELL
   JBDY Clip: Dir. Kundan Shah, 1983, JAANE BHI YAARO
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Justin Lee, 2009, COMPUS MOVIEFEST OUT
   Kankanhalli MS, 2006, IEEE T MULTIMEDIA, V8, P937, DOI 10.1109/TMM.2006.879876
   Katti H., 2010, P 18 ACM INT C MULT, P667
   Kopf Stephan., 2009, MM 09, P321
   National Captioning Institute, 1970, ONL ART CAPT TEL
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   San Agustin J., 2009, Proceedings of the 27th international conference extended abstracts on Human factors in computing systems - CHI EA '09, P4453
   San Agustin J., 2010, Proceedings of the 2010 Symposium on Eye-Tracking Research Applications - ETRA '10, P77, DOI DOI 10.1145/1743666.1743685
   Santella A., 2004, P S EYE TRACKING RES, P27, DOI DOI 10.1145/968363.968368
   Shamir Ariel., 2009, ACM SIGGRAPH ASIA 20, P1, DOI DOI 10.1145/1665817.1665828
   Xu D, 2009, IEEE IMAGE PROC, P3693, DOI 10.1109/ICIP.2009.5414225
NR 30
TC 10
Z9 10
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2014
VL 11
IS 1
AR 8
DI 10.1145/2632284
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AP2XQ
UT WOS:000341939800008
DA 2024-07-18
ER

PT J
AU Wang, XY
   Rui, Y
   Kankanhalli, M
AF Wang, Xiangyu
   Rui, Yong
   Kankanhalli, Mohan
TI Up-Fusion: An Evolving Multimedia Fusion Method
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Performance; Up-fusion; portfolio theory; fusion
ID VIDEO
AB The amount of multimedia data on the Internet has increased exponentially in the past few decades and this trend is likely to continue. Multimedia content inherently has multiple information sources, therefore effective fusion methods are critical for data analysis and understanding. So far, most of the existing fusion methods are static with respect to time, making it difficult for them to handle the evolving multimedia content. To address this issue, in recent years, several evolving fusion methods were proposed, however, their requirements are difficult to meet, making them useful only in limited applications. In this article, we propose a novel evolving fusion method based on the online portfolio selection theory. The proposed method takes into account the correlation among different information sources and evolves the fusion model when new multimedia data is added. It performs effectively on both crisp and soft decisions without requiring additional context information. Extensive experiments on concept detection and human detection tasks over the TRECVID dataset and surveillance data have been conducted and significantly better performance has been obtained.
C1 [Wang, Xiangyu; Kankanhalli, Mohan] Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
C3 National University of Singapore
RP Wang, XY (corresponding author), Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
EM xywangcs@gmail.com
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
CR [Anonymous], 2013, 21 ACM INT C MULTIME
   [Anonymous], BRIEF DESCRIPTIONS V
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Atrey PK, 2008, IEEE T MULTIMEDIA, V10, P1288, DOI 10.1109/TMM.2008.2004907
   Bellman R. E., 1961, ADAPTIVE CONTROL PRO
   Benavent X, 2013, IEEE T MULTIMEDIA, V15, P2009, DOI 10.1109/TMM.2013.2267726
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen JG, 1998, IEEE T SYST MAN CY C, V28, P276, DOI 10.1109/5326.669570
   Crammer K., 2008, Proceedings of the Annual Conference on Neural Information Processing Systems, P345
   Dasarathy B.V., 1994, DECISION FUSION
   Geng X, 2010, PATTERN RECOGN, V43, P3660, DOI 10.1016/j.patcog.2010.04.012
   Helmbold DP, 1998, MATH FINANC, V8, P325, DOI 10.1111/1467-9965.00058
   Jong-Seok Lee, 2008, Speech Recognition - Technologies and Applications, P275
   KELLER JM, 1995, P SOC PHOTO-OPT INS, V2493, P178, DOI 10.1117/12.211800
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   Li B., 2012, ACM COMPUT SURV, V46, P3
   Li M, 2009, LECT NOTES COMPUT SC, V5371, P208
   Ma Justin., 2010, International Conference on Artificial Intelligence and Statistics, P493
   Movellan JR, 1998, MACH LEARN, V32, P85, DOI 10.1023/A:1007468413059
   Myers GK, 2014, MACH VISION APPL, V25, P17, DOI 10.1007/s00138-013-0527-8
   Poh N, 2005, IEEE T SIGNAL PROCES, V53, P4384, DOI 10.1109/TSP.2005.857006
   Sayedelahl A, 2013, IEEE INT CONF MULTI
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Tax DMJ, 2000, PATTERN RECOGN, V33, P1475, DOI 10.1016/S0031-3203(99)00138-7
   Wang M., 2007, ACM Multi- media, P862
   Wang X., 2011, P ACM INT C MULT, P1089
   Wang X., 2010, P ACM INT C MULT, P723
   Wang XY, 2013, IEEE T MULTIMEDIA, V15, P120, DOI 10.1109/TMM.2012.2225027
   Wu Y., 2004, ACM INT C MULTIMEDIA, P572, DOI DOI 10.1145/1027527.1027665
   Yan R, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P514
   Yanagawa A., 2007, 22220068 COL U
NR 32
TC 0
Z9 0
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2014
VL 11
IS 1
AR 6
DI 10.1145/2611777
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AP2XQ
UT WOS:000341939800006
DA 2024-07-18
ER

PT J
AU Knees, P
   Schedl, M
AF Knees, Peter
   Schedl, Markus
TI A Survey of Music Similarity and Recommendation from Music Context Data
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Music information retrieval; music context; music
   similarity; music recommendation; survey
ID RETRIEVAL
AB In this survey article, we give an overview of methods for music similarity estimation and music recommendation based on music context data. Unlike approaches that rely on music content and have been researched for almost two decades, music-context-based (or contextual) approaches to music retrieval are a quite recent field of research within music information retrieval (MIR). Contextual data refers to all music-relevant information that is not included in the audio signal itself. In this article, we focus on contextual aspects of music primarily accessible through web technology. We discuss different sources of context-based data for individual music pieces and for music artists. We summarize various approaches for constructing similarity measures based on the collaborative or cultural knowledge incorporated into these data sources. In particular, we identify and review three main types of context-based similarity approaches: text-retrieval-based approaches (relying on web-texts, tags, or lyrics), co-occurrence-based approaches (relying on playlists, page counts, microblogs, or peer-to-peer-networks), and approaches based on user ratings or listening habits. This article elaborates the characteristics of the presented context-based measures and discusses their strengths as well as their weaknesses.
   Categories and Subject Descriptors: A. 1 [Introductory and Survey]; H.5.5 [Information Interfaces and Presentation (e. g., HCI)]: Sound and Music Computing; I.2.6 [Artificial Intelligence]: Learning
C1 [Knees, Peter; Schedl, Markus] Johannes Kepler Univ Linz, Dept Computat Percept, A-4040 Linz, Austria.
C3 Johannes Kepler University Linz
RP Knees, P (corresponding author), Johannes Kepler Univ Linz, Dept Computat Percept, Altenberger Str 69, A-4040 Linz, Austria.
EM peter.knees@jku.at; markus.schedl@jku.at
OI Knees, Peter/0000-0003-3906-1292
FU Austrian Science Fund (FWF) [P22856-N23, P25655]; Austrian Science Fund
   (FWF) [P22856] Funding Source: Austrian Science Fund (FWF)
FX This research is supported by the Austrian Science Fund (FWF):
   P22856-N23 and P25655.
CR Aizenberg N., 2012, P 21 INT C WORLD WID, P1, DOI DOI 10.1145/2187836.2187838
   [Anonymous], P INT C MACH LEARN A
   [Anonymous], P 32 ACM SIGIR
   [Anonymous], 2007, P 8 INT C MUS INF RE
   [Anonymous], 2012, RECSYS
   [Anonymous], 2009, 10 INT SOC MUSIC INF
   Aucouturier J.-J., 2007, P 8 INT C MUS INF RE
   Aucouturier JJ, 2005, IEEE T MULTIMEDIA, V7, P1028, DOI 10.1109/TMM.2005.858380
   Aucouturier JJ, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P105, DOI 10.1109/ICME.2002.1035729
   Baccigalupo C., 2008, P 9 INT C MUS INF RE
   Baumann S., 2003, P 3 INT C WEB DEL MU
   Bell Robert M, 2007, Acm Sigkdd Explorations Newsletter, V9, P75, DOI [10.1145/1345448.1345465, DOI 10.1145/1345448.1345465]
   BERENZWEIG A, 2003, P 4 INT C MUS INF RE
   BRILL E, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P152, DOI 10.3115/974499.974526
   Brochu E., 2003, P 9 INT WORKSH ART I
   Cano P., 2004, P 5 INT S MUS INF RE, P466
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Celma O., 2007, ISMIR 2007 TUTORIAL
   Celma O., 2008, THESIS U POMPEU FABR
   CELMA O, 2006, P 7 INT C MUS INF RE
   Charniak E, 1997, AI MAG, V18, P33
   Chen S., 2012, P 18 ACM SIGKDD INT, P714, DOI [DOI 10.1145/2339530.2339643, 10.1145/2339530.2339643]
   Cohen WW, 2000, COMPUT NETW, V33, P685, DOI 10.1016/S1389-1286(00)00057-8
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dror Gideon, 2011, P 2011 INT C KDD CUP, P3
   Eck D., 2008, Advances in Neural Information Processing Systems 20
   Ellis D., 2002, P 3 INT C MUS INF RE
   Fields B., 2008, P INT COMP MUS C ICM
   Geleijnse G., 2007, P 8 INT C MUS INF RE
   Hofmann T., 1999, P UNC ART INT UAI
   Hu X., 2005, P 6 INT C MUS INF RE
   Jacobson K., 2008, P 9 INT C MUS INF RE
   Kim J. H., 2009, P 10 INT SOC MUS INF
   Kleedorfer F., 2008, P 9 INT C MUSIC INFO, P287
   Knees P., 2004, P ISMIR, P517
   Knees P., 2008, P 2 WORKSH LEARN SEM
   Knees P., 2006, P 8 ACM SIGMM INT WO
   Knees P., 2006, P 14 ACM INT C MULT
   KNEES P, 2007, P 30 ANN INT ACM SIG
   Koenigstein N, 2011, P 5 ACM C REC SYST, P165, DOI [DOI 10.1145/2043932.2043964, 10.1145/20]
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Law Edith, 2007, ISMIR
   Libeks J, 2011, IEEE MULTIMEDIA, V18, P30, DOI 10.1109/MMUL.2011.1
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Logan B., 2003, P 26 ANN INT ACM SIG
   Logan B., 2004, P IEEE INT C MULT EX
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mahedero J. P. G., 2005, 13th Annual ACM International Conference on Multimedia, P475, DOI 10.1145/1101149.1101255
   MANDEL M, 2007, P 8 INT C MUS INF RE
   Mayer R., 2008, P 9 INT C MUS INF RE
   McFee B., 2009, P 10 INT SOC MUS INF
   Mesnage C. S., 2011, P 2 WORKSH MUS REC D, P7
   Nanopoulos A, 2010, IEEE T AUDIO SPEECH, V18, P407, DOI 10.1109/TASL.2009.2033973
   Pachet F., 2001, P 1 INT C WEB DEL MU
   Pampalk E., 2007, P 8 INT C MUS INF RE
   Pampalk E., 2005, P 9 EUR C RES ADV TE
   Pohle T., 2007, P 5 INT WORKSH CONT
   Pohle T, 2007, IEEE T MULTIMEDIA, V9, P567, DOI 10.1109/TMM.2006.887991
   Schedl M., 2005, P 4 INT WORKSH CONT
   Schedl M., 2012, P 2 WORKSHOP CONTEXT
   Schedl M., 2006, P 28 EUR C INF RETR
   Schedl M, 2009, P 3 INT WORKSH LEARN
   Schedl M., 2012, P 21 INT WORLD WID W
   Schedl M., 2011, P 9 WORKSH AD MULT R
   Schedl M., 2008, THESIS J KEPLER U LI
   Schedl M, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1993036.1993038
   SERRA X, 2012, P 21 INT WORLD WID W
   Shavitt Y., 2009, P IEEE INT S MULT IS
   Shen JL, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P635
   Slaney M., 2007, P 8 INT C MUS INF RE
   Slaney M, 2011, IEEE MULTIMEDIA, V18, P12, DOI 10.1109/MMUL.2011.34
   SORDO M, 2007, P 8 INT C MUS INF RE, P531
   Turnbull D, 2008, P 9 INT C MUS INF RE
   Turnbull D., 2007, ISMIR, V7, P535
   Wang X, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON APAC 2011
   Whitman B., 2002, Proceedings of the 2002 International Computer Music Conference, P591
   Zadel M., 2004, P 5 INT S MUS INF RE
   ZANGERLE E, 2012, P 2 WORKSH MAK SENS, P14
   Zhang B., 2009, P 17 ACM INT C MULT, P213
   Zhao Z., 2010, P 18 ACM INT C MULT, P401, DOI [10.1145/1873951.1874006, DOI 10.1145/1873951.1874006]
   Zobel J., 1998, SIGIR Forum, V32, P18, DOI 10.1145/281250.281256
NR 81
TC 66
Z9 71
U1 3
U2 44
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2013
VL 10
IS 1
AR 2
DI 10.1145/2542205.2542206
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 280JP
UT WOS:000329025400002
OA Bronze
DA 2024-07-18
ER

PT J
AU Zhao, YL
   Chen, Q
   Yan, SC
   Chua, TS
   Zhang, DQ
AF Zhao, Yi-Liang
   Chen, Qiang
   Yan, Shuicheng
   Chua, Tat-Seng
   Zhang, Daqing
TI Detecting Profilable and Overlapping Communities with User-Generated
   Multimedia Contents in LBSNs
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Experimentation; Human Factors; Location-based social
   networks; heterogeneous hypergraph; community detection; community
   profiling
ID EIGENVECTORS
AB In location-based social networks (LBSNs), users implicitly interact with each other by visiting places, issuing comments and/or uploading photos. These heterogeneous interactions convey the latent information for identifying meaningful user groups, namely social communities, which exhibit unique location-oriented characteristics. In this work, we aim to detect and profile social communities in LBSNs by representing the heterogeneous interactions with a multimodality nonuniform hypergraph. Here, the vertices of the hypergraph are users, venues, textual comments or photos and the hyperedges characterize the k-partite heterogeneous interactions such as posting certain comments or uploading certain photos while visiting certain places. We then view each detected social community as a dense subgraph within the heterogeneous hypergraph, where the user community is constructed by the vertices and edges in the dense subgraph and the profile of the community is characterized by the vertices related with venues, comments and photos and their inter-relations. We present an efficient algorithm to detect the overlapped dense subgraphs, where the profile of each social community is guaranteed to be available by constraining the minimal number of vertices in each modality. Extensive experiments on Foursquare data well validated the effectiveness of the proposed framework in terms of detecting meaningful social communities and uncovering their underlying profiles in LBSNs.
   Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications-Data mining; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-Clustering; J.4 [Social and Behavioral Sciences]: Sociology
C1 [Zhao, Yi-Liang; Chen, Qiang; Yan, Shuicheng; Chua, Tat-Seng] Natl Univ Singapore, Singapore 117548, Singapore.
   [Zhang, Daqing] TELECOM SudParis, Paris, France.
C3 National University of Singapore; IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom SudParis
RP Zhao, YL (corresponding author), Natl Univ Singapore, Singapore 117548, Singapore.
EM zhaoyil-iang@gmail.com
RI Yan, Shuicheng/HCI-1431-2022; chen, qiang/GWZ-7308-2022; chen,
   qiang/HGU-5418-2022
FU National University of Singapore (NUS) under A*STAR Project; Microsoft
   Research Asia [R-263-000-628-597]; EU FP7 Project SOCIETIES [257493]
FX We wish to acknowledge the funding support for this work from National
   University of Singapore (NUS) under A*STAR Project "Geographical
   Information Retrieval via Spatial Annotation of Web Media". This work
   was partially supported by the grant R-263-000-628-597 from Microsoft
   Research Asia and the EU FP7 Project SOCIETIES (No. 257493).
CR Amitay E, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P199
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], 2009, Proceeding of the 18th ACM conference on Information and knowledge management, DOI 10.1145/1645953.1646094
   [Anonymous], P INT C MULTIMEDIA M
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cao LL, 2011, SOCIAL NETWORK DATA ANALYTICS, P413
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   El-Arini K., 2012, Proceedings of ACM SIGKDD, P678
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gill A. J., 2009, P 3 INT AAAI C WEBL
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Goswami S., 2009, P INT C WEB SOCIAL M
   Guimerà R, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.025101
   Gupta C, 2010, PROC INT CONF DATA, P569, DOI 10.1109/ICDE.2010.5447828
   Li N, 2009, ICCSSE 2009: PROCEEDINGS OF 2009 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION, P1029, DOI 10.1109/ICCSE.2009.5228475
   Lin YR, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071400
   Liu H., 2010, Annual Conference on Neural Information Processing Systems, P1414
   Liu X, 2011, J COMPUT SCI TECH-CH, V26, P778, DOI 10.1007/s11390-011-0177-0
   Lu CM, 2011, IEEE T SYST MAN CY A, V41, P840, DOI 10.1109/TSMCA.2011.2157128
   Mahoney Michael, 2010, P 19 INT C WORLD WID, P631, DOI DOI 10.1145/1772690.1772755
   McCallum A.K., 2002, MALLET MACHINE LEARN
   Mei T, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071402
   Murata T, 2010, ADV COMPLEX SYST, V13, P19, DOI 10.1142/S0219525910002402
   Neubauer N., 2009, P NIPS WORKSH AN NET
   Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Noulas A., 2011, P WORKSH SOC MOB WEB
   Noulas A., 2011, ICWSM, V11, P70, DOI 10.1609/icwsm.v5i1.14175
   Papadopoulos S, 2012, DATA MIN KNOWL DISC, V24, P515, DOI 10.1007/s10618-011-0224-z
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Scellato S., 2011, P 17 ACM SIGKDD INT, P1046, DOI DOI 10.1145/2020408.2020575
   Tang L., 2010, TR10002 AR STAT U SC
   Tang L, 2009, IEEE DATA MINING, P503, DOI 10.1109/ICDM.2009.20
   Vasconcelos M.A., 2012, Proceedings of the Fifth ACM International Conference on Web Search and Data Mining, P653
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Wolfe AW, 1997, AM ETHNOL, V24, P219, DOI 10.1525/ae.1997.24.1.219
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xie J., 2013, ACM Computing Surveys, VVol. 45, P1, DOI [DOI 10.1145/2501654.2501657, 10.1145/2501654.2501657]
   Xu B., 2012, P 21 INT C WORLD WID, P21
   Yang Y, 2011, PROC CVPR IEEE, P881, DOI 10.1109/CVPR.2011.5995499
   Zhao YL, 2011, LECT NOTES COMPUT SC, V6523, P392
   Zheng VW, 2010, P 19 INT C WORLD WID, P1029
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
   Zhou T, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.046115
   Zhuang JF, 2011, UBICOMP'11: PROCEEDINGS OF THE 2011 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P153
NR 48
TC 15
Z9 20
U1 1
U2 35
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2013
VL 10
IS 1
AR 3
DI 10.1145/2502415
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 280JP
UT WOS:000329025400003
DA 2024-07-18
ER

PT J
AU Zhang, QN
   Izquierdo, E
AF Zhang, Qianni
   Izquierdo, Ebroul
TI Multifeature Analysis and Semantic Context Learning for Image
   Classification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Image classification; object detection; multifeature fusion;
   semantic context modeling
ID NEIGHBORHOOD PROPAGATION; RELEVANCE FEEDBACK; RETRIEVAL; COLOR;
   FRAMEWORK; FEATURES; DATABASE; TOOL
AB This article introduces an image classification approach in which the semantic context of images and multiple low-level visual features are jointly exploited. The context consists of a set of semantic terms defining the classes to be associated to unclassified images. Initially, a multiobjective optimization technique is used to define a multifeature fusion model for each semantic class. Then, a Bayesian learning procedure is applied to derive a context model representing relationships among semantic classes. Finally, this context model is used to infer object classes within images. Selected results from a comprehensive experimental evaluation are reported to show the effectiveness of the proposed approaches.
C1 [Zhang, Qianni; Izquierdo, Ebroul] Univ London, Sch Elect Engn & Comp Sci, London, England.
C3 University of London
RP Zhang, QN (corresponding author), Univ London, Sch Elect Engn & Comp Sci, London, England.
EM qianni.zhang@elec.qmul.ac.uk
OI Zhang, Qianni/0000-0001-7685-2187
FU European Commission [FP7-287704 CUBRIK]
FX The research that led to this article was supported by the European
   Commission under contract FP7-287704 CUBRIK.
CR Aksoy S, 2005, IEEE T GEOSCI REMOTE, V43, P581, DOI 10.1109/TGRS.2004.839547
   [Anonymous], 1986, Multiple criteria optimization: Theory, computation, and application
   Athanasiadis T, 2007, IEEE T CIRC SYST VID, V17, P298, DOI 10.1109/TCSVT.2007.890636
   Berman AP, 1999, COMPUT VIS IMAGE UND, V75, P175, DOI 10.1006/cviu.1999.0772
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dagli C, 2004, INT C PATT RECOG, P1021, DOI 10.1109/ICPR.2004.1334433
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   de Jong FAG, 2007, IEEE T CIRC SYST VID, V17, P365, DOI 10.1109/TCSVT.2007.890834
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan JP, 2008, IEEE T MULTIMEDIA, V10, P167, DOI 10.1109/TMM.2007.911775
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Huiskes M., 2010, Proceedings of the international conference on Multimedia information retrieval
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jiang W, 2007, INT CONF ACOUST SPEE, P949
   Jiang YG, 2009, IEEE I CONF COMP VIS, P1420, DOI 10.1109/ICCV.2009.5459295
   Jing F, 2004, IEEE T CIRC SYST VID, V14, P672, DOI 10.1109/TCSVT.2004.826775
   Kherfi ML, 2007, IEEE T MULTIMEDIA, V9, P893, DOI 10.1109/TMM.2007.893349
   Knowles JD, 2000, EVOL COMPUT, V8, P149, DOI 10.1162/106365600568167
   Koskela M, 2007, IEEE T MULTIMEDIA, V9, P912, DOI 10.1109/TMM.2007.900137
   Lavrenko V, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1044
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li F, 2008, IEEE T MULTIMEDIA, V10, P1592, DOI 10.1109/TMM.2008.2004914
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Natsev A, 2004, IEEE T KNOWL DATA EN, V16, P301, DOI 10.1109/TKDE.2003.1262183
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Rasiwasia N, 2009, PROC CVPR IEEE, P1889, DOI 10.1109/CVPRW.2009.5206826
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tang JH, 2009, IEEE T SYST MAN CY B, V39, P409, DOI 10.1109/TSMCB.2008.2006045
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Zhang J, 2009, IEEE T IMAGE PROCESS, V18, P2370, DOI 10.1109/TIP.2009.2026669
   Zhang LH, 2011, IEEE IMAGE PROC, P197, DOI 10.1109/ICIP.2011.6115862
   Zhang Q., 2007, EURASIP J ADV SIG PR, V1, P1
   Zhang RF, 2007, IEEE T IMAGE PROCESS, V16, P562, DOI 10.1109/TIP.2006.888350
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 50
TC 4
Z9 5
U1 0
U2 15
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2013
VL 9
IS 2
AR 12
DI 10.1145/2457450.2457454
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 144MS
UT WOS:000318944400004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhao, ZW
   Ooi, WT
AF Zhao, Zhen Wei
   Ooi, Wei Tsang
TI APRICOD: An Access-Pattern-Driven Distributed Caching Middleware for
   Fast Content Discovery of Noncontinuous Media Access
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Performance; Content discovery; caching; access pattern;
   noncontinuous media access; peer-to-peer
AB Content discovery is a major source of latency in peer-to-peer (P2P) media streaming systems, especially in the presence of noncontinuous user access, such as random seek in Video-on-Demand (VoD) streaming and teleportation in a Networked Virtual Environment (NVE). After the aforementioned user interactions, streaming systems often need to initiate the content discovery process to identify where to retrieve the requested media objects. Short content lookup latency is demanded to ensure smooth user experience. Existing content discovery systems based on either a Distributed Hash Table (DHT) or gossip mechanism cannot cope with noncontinuous access efficiently due to their long lookup latency.
   In this work, we propose an access-pattern-driven distributed caching middleware named APRICOD, which caters for fast and scalable content discovery in peer-to-peer media streaming systems, especially when user interactions are present. APRICOD exploits correlations among media objects accessed by users, and adapts to shift in the user access pattern automatically. We first present a general APRICOD design that can be used with any existing content discovery system. We then present an implementation of APRICOD on top of Pastry, which we use to evaluate APRICOD. Our evaluation in a 1024-node system, using a Second Life trace with 5, 735 users and a VoD trace with 54 users, shows that APRICOD can effectively resolve all continuous access queries with a single hop deterministically with node failure as an exception, and resolve noncontinuous access queries with a single hop with high probability.
C1 [Zhao, Zhen Wei] Natl Univ Singapore, Ctr Life Sci CeLS, NUS Grad Sch Integrat Sci & Engn, Singapore 117456, Singapore.
   [Ooi, Wei Tsang] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
C3 National University of Singapore; National University of Singapore
RP Zhao, ZW (corresponding author), Natl Univ Singapore, Ctr Life Sci CeLS, NUS Grad Sch Integrat Sci & Engn, 05-01,28 Med Dr, Singapore 117456, Singapore.
EM zhaozhenwei@nus.edu.sg
RI Ooi, Wei Tsang/AAE-7810-2019; Ooi, Wei Tsang/HLW-5142-2023
OI Ooi, Wei Tsang/0000-0001-8994-1736; Ooi, Wei Tsang/0000-0001-8994-1736
FU Singapore National Research Foundation; Interactive Digital Media R&D
   Program Office of Media Development Authority [WBS:R-252-300-001-490]
FX This research is conducted under the NExT Search Center, supported by
   the Singapore National Research Foundation and the Interactive Digital
   Media R&D Program Office of Media Development Authority under research
   grant WBS:R-252-300-001-490.
CR [Anonymous], 2007, WORKSHOP PEER TO PEE
   [Anonymous], 2002, P ACM MULT JUAN LES
   [Anonymous], ACM MULTIMEDIA
   Axel Carlier, 2010, P 2010 ACM WORKSH SO, P21
   Brampton A., 2007, P INT WORKSH OP SYST, P99
   Cheng B., 2007, P INT C PEER TO PEER
   Cheng B, 2007, IEEE ICC, P1698, DOI 10.1109/ICC.2007.284
   Cheng X, 2009, IEEE INFOCOM SER, P1152, DOI 10.1109/INFCOM.2009.5062028
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Dabek F., 2001, Operating Systems Review, V35, P202, DOI 10.1145/502059.502054
   De Silva RN, 2010, NOSSDAV 2010: PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P123
   Hao Yin, 2005, 13th Annual ACM International Conference on Multimedia, P295, DOI 10.1145/1101149.1101208
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   Hu SY, 2010, IEEE INTERNET COMPUT, V14, P54, DOI 10.1109/MIC.2009.98
   Liu Y., 2010, Proceedings of the ACM Multimedia Systems (MMSys), P99, DOI DOI 10.1145/1730836.1730849
   Mavlankar A, 2010, SIGNALS COMMUN TECHN, P431, DOI 10.1007/978-3-642-12802-8_19
   Minh Khiem Ngo Quang., 2010, Proceedings of the first annual ACM SIGMM conference on Multimedia systems, P259, DOI DOI 10.1145/1730836.1730868
   NG TSE, 2004, P USENIX ANN TECHN C
   Pouwelse JA, 2008, CONCURR COMP-PRACT E, V20, P127, DOI 10.1002/cpe.1189
   Qiu XJ, 2009, NOSSDAV 09: 18TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P19
   Ramasubramanian V, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE FIRST SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'04), P99
   RAO W, 2007, CIKM, P663
   Rowstron A., 2001, Proceedings of the Middleware 2001, P329, DOI DOI 10.1007/3-540-45518-3_18
   Shen ZJ, 2011, P IEEE, V99, P2089, DOI 10.1109/JPROC.2011.2165330
   Wang D, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1397, DOI 10.1109/ICME.2006.262800
   Yang X., 2009, P INT C PEER TO PEER
   Yin H, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823750
   Yiu WPK, 2007, IEEE J SEL AREA COMM, V25, P1717, DOI 10.1109/JSAC.2007.071210
   Yu A., 2005, Proceedings of the 15th International Workshop on Network and Operating Systems Support for Digital Audio and Video. NOSSDAV 2005, P99, DOI 10.1145/1065983.1066007
   Zhao Z. W., 2011, P ACM INT C MULT MM, P1241
NR 30
TC 2
Z9 2
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2013
VL 9
IS 2
AR 15
DI 10.1145/2457450.2457457
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 144MS
UT WOS:000318944400007
DA 2024-07-18
ER

PT J
AU Liu, XB
   Yan, SC
   Cheng, B
   Tang, JH
   Chua, TS
   Jin, H
AF Liu, Xiaobai
   Yan, Shuicheng
   Cheng, Bin
   Tang, Jinhui
   Chua, Tat-Sheng
   Jin, Hai
TI Label-to-Region with Continuity-Biased Bi-Layer Sparsity Priors
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Measurement; Theory; Label-to-Region; sparse representation;
   bag-of-hierarchical-patch; image annotation
ID RECOGNITION; SELECTION; SET
AB In this work, we investigate how to reassign the fully annotated labels at image level to those contextually derived semantic regions, namely Label-to-Region (L2R), in a collective manner. Given a set of input images with label annotations, the basic idea of our approach to L2R is to first discover the patch correspondence across images, and then propagate the common labels shared in image pairs to these correlated patches. Specially, our approach consists of following aspects. First, each of the input images is encoded as a Bag-of-Hierarchical-Patch (BOP) for capturing the rich cues at variant scales, and the individual patches are expressed by patch-level feature descriptors. Second, we present a sparse representation formulation for discovering how well an image or a semantic region can be robustly reconstructed by all the other image patches from the input image set. The underlying philosophy of our formulation is that an image region can be sparsely reconstructed with the image patches belonging to the other images with common labels, while the robustness in label propagation across images requires that these selected patches come from very few images. This preference of being sparse at both patch and image level is named bi-layer sparsity prior. Meanwhile, we enforce the preference of choosing larger-size patches in reconstruction, referred to as continuity-biased prior in this work, which may further enhance the reliability of L2R assignment. Finally, we harness the reconstruction coefficients to propagate the image labels to the matched patches, and fuse the propagation results over all patches to finalize the L2R task. As a by-product, the proposed continuity-biased bi-layer sparse representation formulation can be naturally applied to perform image annotation on new testing images. Extensive experiments on three public image datasets clearly demonstrate the effectiveness of our proposed framework in both L2R assignment and image annotation.
C1 [Liu, Xiaobai; Jin, Hai] Huazhong Univ Sci & Technol, Wuhan, Peoples R China.
   [Liu, Xiaobai; Yan, Shuicheng; Cheng, Bin; Chua, Tat-Sheng] Natl Univ Singapore, Singapore 117548, Singapore.
   [Tang, Jinhui] Nanjing Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Huazhong University of Science & Technology; National University of
   Singapore; Nanjing University of Science & Technology
RP Liu, XB (corresponding author), Huazhong Univ Sci & Technol, Wuhan, Peoples R China.
EM xbliu.lhi@gmail.com
RI Tang, Jinhui/KBR-0891-2024; Yan, Shuicheng/HCI-1431-2022; liu,
   xiaobai/J-4120-2014
OI Tang, Jinhui/0000-0001-9008-222X
FU CSIDM Project [CSIDM-200803]; National Research Foundation; National
   High Technology Research and Development Program of China [2006AA01A115]
FX This work suppoted by the CSIDM Project (under grant no. CSIDM-200803,
   partially funded by a grant from the National Research Foundation
   administered by the Media Development Authority of Singapore) and the
   National High Technology Research and Development Program of China
   (under grant no. 2006AA01A115).
CR [Anonymous], 2007, ACM MULTIMEDIA, DOI DOI 10.1145/1291233.1291379
   [Anonymous], 2008, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2008.4587799, DOI 10.1109/CVPR.2008.4587799]
   [Anonymous], 2012, ACM TRANSACTIONS ON, V8
   [Anonymous], 2007, 2007 IEEE 11 INT C C
   [Anonymous], 2009, PROC 17 ACM INT C MU
   Bertsekas D. P., 1999, Nonlinear Program, V2nd
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen Yu, 2008, Instrument Techniques and Sensor, P1
   Chua Tat-Seng., 2009, P 8 ACM INT C IMAGE
   COMITE F., 2003, LNCS, V2734, P251
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Elisseeff A, 2002, ADV NEUR IN, V14, P681
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FERGUS R., 2005, PROCEEDINGS OF THE I
   Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399
   Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712
   Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727
   Haering N, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P18, DOI 10.1109/IVL.1997.629716
   JACOB L., 2009, PROCEEDINGS OF THE I
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jin R., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P892, DOI DOI 10.1145/1027527.1027732
   Kang F., 2006, CVPR, V2, P1719
   Lavrenko V, 2004, ADV NEUR IN, V16, P553
   Leibe Bastian, 2004, WORKSH STAT LEARN CO
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   LIU C., 2010, IEEE T PATTERN ANAL, V99, P1
   Liu JJ, 2007, PROCEEDINGS OF THE 2007 CHINESE CONTROL AND DECISION CONFERENCE, P605, DOI 10.1145/1291233.1291380
   LIU X., 2010, PROCEEDINGS OF THE A
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   NESTEROV Y., 2007, PROCEEDINGS OF THE I
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Russell B.C., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1605, DOI DOI 10.1109/CVPR.2006.326
   SERRE T., 2005, PROCEEDINGS OF THE I
   Shengli Yuan, 2010, Proceedings 2010 IEEE Global Communications Conference (GLOBECOM 2010), DOI 10.1109/GLOCOM.2010.5683786
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   SINGHAL A., 2003, SOUV NAT S EM TRENDS, P18
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   TSENG P., 2008, SUBMITTED TO SIAM J
   Winn J, 2005, IEEE I CONF COMP VIS, P756
   Wright J., 2009, Journal of the ACM
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan Shuicheng., 2009, SOC IND APPL MATH P, P792, DOI [10.1137/1.9781611972795.68, DOI 10.1137/1.9781611972795.68]
   YANG J., 2000, PROCEEDINGS OF THE I
   YUAN X., 2010, PROCEEDINGS OF THE I
   ZHANG J., 2006, TECH REP CMU LTI 06
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
NR 49
TC 6
Z9 7
U1 0
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2012
VL 8
IS 4
AR 50
DI 10.1145/2379790.2379792
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 052QA
UT WOS:000312211900002
DA 2024-07-18
ER

PT J
AU Liu, DY
   Li, F
   Shen, B
   Chen, SQ
AF Liu, Dongyu
   Li, Fei
   Shen, Bo
   Chen, Songqing
TI Building an Efficient Transcoding Overlay for P2P Streaming to
   Heterogeneous Devices
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Algorithms; Experimentation; P2P/overlay streaming;
   meta-transcoding; heterogeneity
AB With the increasing deployment of Internet P2P/overlay streaming systems, more and more clients use mobile devices, such as smart phones and PDAs, to access these Internet streaming services. Compared to wired desktops, mobile devices normally have a smaller screen size, a less color depth, and lower bandwidth and thus cannot correctly and effectively render and display the data streamed to desktops.
   To address this problem, in this paper, we propose PAT (Peer-Assisted Transcoding) to enable effective online transcoding in P2P/overlay streaming. PAT has the following unique features. First, it leverages active peer cooperation without demanding infrastructure support such as transcoding servers. Second, as online transcoding is computationally intensive while the various devices used by participating clients may have limited computing power and related resources (e.g., battery, bandwidth), an additional overlay, called metadata overlay, is constructed to instantly share the intermediate transcoding result of a transcoding procedure with other transcoding nodes to minimize the total computing overhead in the system. The experimental results collected within a realistically simulated testbed show that by consuming 6% extra bandwidth, PAT could save up to 58% CPU cycles for online transcoding.
C1 [Liu, Dongyu] MicroStrategy Inc, Tysons Corner, VA 22182 USA.
   [Li, Fei; Chen, Songqing] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
   [Shen, Bo] Vuclip, Milpitas, CA 95035 USA.
C3 George Mason University
RP Liu, DY (corresponding author), MicroStrategy Inc, 1850 Towers Crescent Plaza, Tysons Corner, VA 22182 USA.
EM dliu@microstrategy.com; lifei@cs.gmu.edu; boshen_99@yahoo.com;
   sqchen@cs.gmu.edu
FU U.S. AFOSR [FA9550-09-1-0071]; U.S. National Science Foundation
   [CNS-0746649, CCF-0915681, CNS-1117300, CCF-1146578]; Direct For
   Computer & Info Scie & Enginr; Division Of Computer and Network Systems
   [0746649] Funding Source: National Science Foundation
FX The work has been supported in part by U.S. AFOSR under grant
   FA9550-09-1-0071, and by the U.S. National Science Foundation under
   grants CNS-0746649, CCF-0915681, CNS-1117300, and CCF-1146578.
CR ACHARYA S, 2000, P ACM INT WORKSH NET
   AMIR E, 1995, P ACM MULT
   Castro M., 2003, P 2 INT WORKSH PEER
   CHEN S, 2006, P ACM INT WORKSH NET
   CHEN S, 2009, P IEEE INT C DISTR C
   CHU YH, 2000, P ACM SIGMETRICS JOI
   DENG D, 2006, P ANN JOINT C IEEE C
   GHANBARL M, 1989, IEEE J SELECT AREAS, P7
   Hefeeda M., 2003, P ACM MULT
   KOSTIC D, 2003, P ACM S OP SYST PRIN
   KOUVELAS I., 1998, P ACM INT WORKSH NET
   KUMAR K., 2005, P 4 INT PAR DISTR PR
   MAGHAREI N., 2007, P ANN JOINT C IEEE C
   MICKUNAS D, 2000, P SPIE ACM ANN MULT
   NAKAMURA M, 1995, P IEEE INT C IM PROC
   OOI W, 2005, P ACM SPIE ANN MULT
   PADMANABHAN V, 2003, P IEEE ANN INT C NET
   PADMANABHAN V, 2002, P ACM INT WORKSH NET
   SETTON E., 2007, P ACM INT WORKSH NET
   Shen B, 2004, IEEE T MULTIMEDIA, V6, P375, DOI 10.1109/TMM.2003.822791
   SHEN B, 2003, P IEEE INT C MULT EX
   SMALL T, 2006, P ACM MULT
   TRAN DA, 2003, P ANN JOINT C IEEE C
NR 23
TC 2
Z9 2
U1 0
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2012
VL 8
IS 1
SI SI
AR 10
DI 10.1145/2089085.2089087
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 898YN
UT WOS:000300778400002
DA 2024-07-18
ER

PT J
AU Wu, C
   Li, ZP
   Qiu, XJ
   Lau, FCM
AF Wu, Chuan
   Li, Zongpeng
   Qiu, Xuanjia
   Lau, Francis C. M.
TI Auction-Based P2P VoD Streaming: Incentives and Optimal Scheduling
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithm; Design; Performance; Peer-to-peer streaming; auction;
   incentive; optimal scheduling
AB Real-world large-scale Peer-to-Peer (P2P) Video-on-Demand (VoD) streaming applications face more design challenges as compared to P2P live streaming, due to higher peer dynamics and less buffer overlap. The situation is further complicated when we consider the selfish nature of peers, who in general wish to download more and upload less, unless otherwise motivated. Taking a new perspective of distributed dynamic auctions, we design efficient P2P VoD streaming algorithms with simultaneous consideration of peer incentives and streaming optimality. In our solution, media block exchanges among peers are carried out through local auctions, in which budget-constrained peers bid for desired blocks from their neighbors, which in turn deliver blocks to the winning bidders and collect revenue. With strategic design of a discriminative second price auction with seller reservation, a supplying peer has full incentive to maximally contribute its bandwidth to increase its budget; requesting peers are also motivated to bid in such a way that optimal media block scheduling is achieved effectively in a fully decentralized fashion. Applying techniques from convex optimization and mechanism design, we prove (a) the incentive compatibility at the selling and buying peers, and (b) the optimality of the induced media block scheduling in terms of social welfare maximization. Large-scale empirical studies are conducted to investigate the behavior of the proposed auction mechanisms in dynamic P2P VoD systems based on real-world settings.
C1 [Wu, Chuan; Qiu, Xuanjia; Lau, Francis C. M.] Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Li, Zongpeng] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
C3 University of Hong Kong; University of Calgary
RP Wu, C (corresponding author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
EM cwu@cs.hku.hk; zongpeng@ucalgary.ca; xjqiu@cs.hku.hk; fcmlau@cs.hku.hk
RI Wu, Chuan/E-9919-2010; Lau, Francis/AAN-8816-2020
FU Hong Kong RGC GRF [718710E]
FX This work is supported in part by Hong Kong RGC GRF grant under the
   contract 718710E.
CR Annapureddy S., 2007, P 16 INT WORLD WID W
   APERJIS C., 2008, P 4 ACM INT C EM NET
   Armstrong M, 1996, ECONOMETRICA, V64, P51, DOI 10.2307/2171924
   Boyd S., 2004, CONVEX OPTIMIZATION
   Chu XW, 2009, IEEE T PARALL DISTR, V20, P1816, DOI 10.1109/TPDS.2009.40
   Edelman B, 2007, AM ECON REV, V97, P242, DOI 10.1257/aer.97.1.242
   GOLLE P, 2001, P 2 INT WORKSH EL CO
   Habib A, 2006, IEEE T MULTIMEDIA, V8, P610, DOI 10.1109/TMM.2006.870724
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   HUANG Y, 2008, P ACM SIGCOMM DAT CO
   Kirkegaard R, 2008, RAND J ECON, V39, P770, DOI 10.1111/j.1756-2171.2008.00038.x
   LAI K, 2003, P WORKSH EC PEER PEE
   LAZAR A., 1999, TELECOM SYST
   LEVIN D., 2006, P ACM SIGCOMM DAT CO
   LIANG C., 2009, P ANN JOINT C IEEE C
   Liu Z., 2010, P 30 INT C DISTR COM
   MOL JJD, 2008, P ANN MULT COMP NETW
   Naicken S, 2007, ACM SIGCOMM COMP COM, V37, P95, DOI 10.1145/1232919.1232932
   Nisan N, 2007, ALGORITHMIC GAME THEORY, P1, DOI 10.1017/CBO9780511800481
   PAI V., 2006, P WORKSH EC NETW SYS
   Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI
   STILLER D. AND, 2005, P IEEE INT C COMM
   SUNG Y.- W., 2006, P ACM SIGCOMM DAT CO
   Tan G, 2008, IEEE T PARALL DISTR, V19, P940, DOI 10.1109/TPDS.2007.70778
   Turner D., 2004, P 7 INT C EL COMM RE
   VISHNUMURTHY V., 2003, P 1 WORKSH EC P2P SY
   Wu C, 2008, IEEE T PARALL DISTR, V19, P806, DOI 10.1109/TPDS.2008.30
   Wu C, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1386109.1386112
NR 28
TC 8
Z9 8
U1 0
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2012
VL 8
IS 1
SI SI
AR 14
DI 10.1145/2089085.2089091
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 898YN
UT WOS:000300778400006
DA 2024-07-18
ER

PT J
AU Tullimas, S
   Nguyen, T
   Edgecomb, R
   Cheung, SC
AF Tullimas, Sunand
   Nguyen, Thinh
   Edgecomb, Rich
   Cheung, Sen-Ching
TI Multimedia streaming using multiple TCP connections
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE design; algorithms; multimedia streaming
AB In recent years, multimedia applications over the Internet become increasingly popular. However, packet loss, delay, and time-varying bandwidth of the Internet have remained the major problems for multimedia streaming applications. As such, a number of approaches, including network infrastructure and protocol, source and channel coding, have been proposed to either overcome or alleviate these drawbacks of the Internet. In this article, we propose the MultiTCP system, a receiver-driven, TCP-based system for multimedia streaming over the Internet. Our proposed algorithm aims at providing resilience against short term insufficient bandwidth by using multiple TCP connections for the same application. Our proposed system enables the application to achieve and control the desired sending rate during congested periods, which cannot be achieved using traditional TCP. Finally, our proposed system is implemented at the application layer, and hence, no kernel modification to TCP is necessary. We analyze the proposed system, and present simulation and experimental results to demonstrate its advantages over the traditional single-TCP-based approach.
C1 [Tullimas, Sunand; Nguyen, Thinh; Edgecomb, Rich] Oregon State Univ, Corvallis, OR 97331 USA.
   [Cheung, Sen-Ching] Univ Kentucky, Lexington, KY 40506 USA.
C3 Oregon State University; University of Kentucky
RP Tullimas, S (corresponding author), Oregon State Univ, Corvallis, OR 97331 USA.
EM thinhq@eecs.oregonstate.edu
CR [Anonymous], IEEE J SEL AREAS COM
   APOSTOLOPOULOS J, 2002, P ANN JOINT C IEEE C, V4310
   Apostolopoulos JG, 2001, PROC SPIE, V4310, P392
   BLAKE S, 1998, 475 RFC
   CHEN M, 2004, P ANN JOINT C IEEE C
   CHEN M, 2006, P ANN JOINT C IEEE C
   Chen MH, 2005, IEEE WIREL COMMUN, V12, P32, DOI 10.1109/MWC.2005.1497856
   CROWCROFT J, 1998, ACM SIGCOM COMPUT CO, V28, P55
   DONG Y, 2002, PACK VID WORKSH
   Floyd S, 2000, ACM SIGCOMM COMP COM, V30, P43, DOI 10.1145/347057.347397
   Floyd S., 1999, IEEE ACM T NETW
   *INT ENG TASK FORC, 2000, 1771 RFC INT ENG TAS
   Kurose JamesF., 2005, COMPUTER NETWORKING, V3
   LEIGH J, 2001, IMM PROJ TECH EUR VI
   LIANG YJ, 2002, P IEEE 5 WORKSH MULT
   Ma H., 1998, P INT SOC OPT ENG NO, V3528, P69
   Mehra P, 2005, IEEE T MULTIMEDIA, V7, P740, DOI 10.1109/TMM.2005.846783
   MEHRA P, 2003, P ANN JOINT C IEEE C
   Nguyen T, 2004, IEEE T MULTIMEDIA, V6, P315, DOI 10.1109/TMM.2003.822790
   NGUYEN T, 2005, P IEEE INT PERF COMP
   REIBMAN AR, 2002, PACK VID WORKSH
   Semke Jeffrey., 1998, SIGCOMM
   Tan WT, 1999, IEEE T MULTIMEDIA, V1, P172, DOI 10.1109/6046.766738
   Wang Z., 2001, INTERNET QOS ARCHITE
   White PP, 1997, IEEE COMMUN MAG, V35, P100, DOI 10.1109/35.592102
NR 25
TC 22
Z9 29
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2008
VL 4
IS 2
AR 12
DI 10.1145/1352012.1352016
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 306RG
UT WOS:000256264900004
DA 2024-07-18
ER

PT J
AU Chen, DT
   Yang, J
   Malkin, R
   Wactlar, HD
AF Chen, Datong
   Yang, Jie
   Malkin, Robert
   Wactlar, Howard D.
TI Detecting social interactions of the elderly in a nursing home
   environment
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE algorithms; experimentation; multimedia processing; social interaction;
   human activity; health care; stochastic modeling; sensor
ID RECOGNITION; NETWORKS; VIDEO
AB Social interaction plays an important role in our daily lives. It is one of the most important indicators of physical or mental changes in aging patients. In this article, we investigate the problem of detecting social interaction patterns of patients in a skilled nursing facility using audio/visual records. Our studies consist of both a "Wizard of Oz" style study and an experimental study of various sensors and detection models for detecting and summarizing social interactions among aging patients and caregivers. We first simulate plausible sensors using human labeling on top of audio and visual data collected from a skilled nursing facility. The most useful sensors and robust detection models are determined using the simulated sensors. We then present the implementation of some real sensors based on video and audio analysis techniques and evaluate the performance of these implementations in detecting interactions. We conclude the article with discussions and future work.
C1 Carnegie Mellon Univ, Sch Comp Sci, Dept Comp Sci, Pittsburgh, PA 15213 USA.
   Carnegie Mellon Univ, Sch Comp Sci, Comp Interact Inst, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University; Carnegie Mellon University
RP Chen, DT (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, Dept Comp Sci, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM datong@cs.cmu.edu
RI Chen, Datong/GSN-2249-2022
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], 2002, MSRTR200263
   [Anonymous], 1994, ANNU REV GERONTOL, DOI DOI 10.1891/0198-8794.14.1.302
   [Anonymous], 2003, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/642611.642657
   [Anonymous], PERVASIVE COMPUTING
   Ayers D, 2001, IMAGE VISION COMPUT, V19, P833, DOI 10.1016/S0262-8856(01)00047-6
   BADLER N, 1975, 80 U TORONTO
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382
   Brumitt B, 2000, IEEE PERS COMMUN, V7, P41, DOI 10.1109/98.878536
   Burns A., 1999, ASSESSMENT SCALES OL
   Chang A.R., 2005, EXTENDED ABSTRACTS H, P1260
   CHEN D, 2005, P INT C COMP VIS WOR
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Clarkson B, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P38, DOI 10.1109/ICIP.2000.899278
   CLARKSON B, 1998, 471 MIT
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Consolvo S, 2004, IEEE PERVAS COMPUT, V3, P22, DOI 10.1109/MPRV.2004.1316814
   DEY AK, 2004, P C COMP HUM INT
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Emler N., 1994, GOOD GOSSIP, P119, DOI DOI 10.1111/J.1559-1816.2012.00956.X
   EPPIG FJ, 1995, HLTH CARE FINANCING, V15, P207
   ESSA IA, 1995, P IEEE INT C COMPT V, V5, P360
   Forlizzi J, 2004, HUM-COMPUT INTERACT, V19, P25, DOI 10.1207/s15327051hci1901&2_3
   Freeman W. T., 1995, P INT WORKSH AUT FAC, V12, P296
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Garg A, 2003, P IEEE, V91, P1355, DOI 10.1109/JPROC.2003.817119
   GARG A, 2003, HDB VIDEO DATABASES
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   GERMAN PS, 1992, GERONTOLOGIST, V32, P152, DOI 10.1093/geront/32.2.152
   Harter A., 1999, Proceedings of the 5th Annual ACM/IEEE International Conference on Mobile Computing and Networking. MobiCom'99, P59, DOI DOI 10.1145/313451.313476
   HARTLEY HO, 1958, BIOMETRICS, V14, P174, DOI 10.2307/2527783
   HASTIE T, 1987, J R STAT SOC C-APPL, V36, P260
   Holmquist L. E., 1999, Personal Technologies, V3, P13, DOI 10.1007/BF01305316
   Hongeng S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P84, DOI 10.1109/ICCV.2001.937608
   HOOYMAN NR, 2002, SOCIAL GERENTOLOGY M
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   JEBARA T, 1998, P IEEE WORKSH INT VI
   Jug M, 2003, LECT NOTES COMPUT SC, V2626, P534
   Kidd CD, 1999, LECT NOTES COMPUT SC, V1670, P191
   Kirishima T, 2005, IEEE T PATTERN ANAL, V27, P351, DOI 10.1109/TPAMI.2005.61
   Koile K, 2003, LECT NOTES COMPUT SC, V2864, P90
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   KONONENKO I, 1991, LECT NOTES ARTIF INT, V482, P206, DOI 10.1007/BFb0017015
   Lubinski R., 1991, DEMENTIA COMMUNICATI
   Margineantu D.D., 1997, ICML, V97, P211
   MARTIN A, 2000, EUR SIGN PROC C SEPT, P469
   MCCOWAN I, 2004, IEEE T PATTERN ANAL
   Moore D. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P80, DOI 10.1109/ICCV.1999.791201
   Nelson J, 1995, J Gerontol Nurs, V21, P19
   Nixon M. S., 2003, Sensor Review, V23, P323, DOI 10.1108/02602280310496845
   NUMMIARO K, 2000, P S PATT REC DAGM
   Oliver N, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P3, DOI 10.1109/ICMI.2002.1166960
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pentland A, 2005, COMPUTER, V38, P33, DOI 10.1109/MC.2005.104
   PEREZ P, 2001, P INT C COMP VIS VAN, P424
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   RAMANAN D, 2003, UCBCSD031262
   Redmiles D., 2002, COMPUT SUPP COOP W J, V11, P1, DOI DOI 10.1023/A:1015215726353
   Reichman WE, 1998, AM J GERIAT PSYCHIAT, V6, P320
   Rhodes BJ, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P123, DOI 10.1109/ISWC.1997.629928
   Schraudolph NicolN., 1993, Advances in neural information processing systems, P499
   Sloane P.D., 1995, TESS 2 INSTRUMENT B
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   STEELE C, 1990, AM J PSYCHIAT, V147, P1049
   TERI L, 1992, ALZHEIMERS DIS ASS D, V6, P677
   *TIM DOM CORP, 2001, PULS TECH TIM MOD UL
   Wilson A. D., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P111, DOI 10.1109/RATFG.1999.799232
   YACOOB Y, 1998, P 6 INT C COMP VIS, P232
   YANG J, 1998, CMUCS97146 CMU
   ZHANG D, 2004, P 17 INT C PATT REC
NR 75
TC 21
Z9 26
U1 1
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2007
VL 3
IS 1
AR 6
DI 10.1145/1198302.1198308
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 230IZ
UT WOS:000250871500006
DA 2024-07-18
ER

PT J
AU Colombo, C
   Comanducci, D
   Del Bimbo, A
AF Colombo, Carlo
   Comanducci, Dario
   Del Bimbo, Alberto
TI Robust tracking and remapping of eye appearance with passive computer
   vision
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE algorithms; experimentation; eye tracking and remapping; eye blink
   detection; robust fitting; eye-driven human-computer interaction
AB A single-camera iris-tracking and remapping approach based on passive computer vision is presented. Tracking is aimed at obtaining accurate and robust measurements of the iris/pupil position. To this purpose, a robust method for ellipse fitting is used, employing search constraints so as to achieve better performance with respect to the standard RANSAC algorithm. Tracking also embeds an iris localization algorithm (working as a bootstrap multiple-hypotheses generation step), and a blink detector that can detect voluntary eye blinks in human-computer interaction applications. On-screen remapping incorporates a head-tracking method capable of compensating for small user-head movements. The approach operates in real time under different light conditions and in the presence of distractors. An extensive set of experiments is presented and discussed. In particular, an evaluation method for the choice of layout of both hardware components and calibration points is described. Experiments also investigate the importance of providing a visual feedback to the user, and the benefits gained from performing head compensation, especially during image-to-screen map calibration.
C1 [Colombo, Carlo; Comanducci, Dario; Del Bimbo, Alberto] Univ Florence, Dipartimento Sistemi & Informat, Florence, Italy.
C3 University of Florence
RP Colombo, C (corresponding author), Univ Florence, Dipartimento Sistemi & Informat, Via S Marta 3, Florence, Italy.
EM colombo@dsi.unifi.it; comandu@dsi.unifi.it; delbimbo@dsi.unifi.it
RI Colombo, Carlo/AAC-6675-2019
OI DEL BIMBO, ALBERTO/0000-0002-1052-8322; COLOMBO,
   CARLO/0000-0001-9234-537X
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Beymer D, 2003, PROC CVPR IEEE, P451
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Colombo C, 2003, IEEE T SYST MAN CY B, V33, P677, DOI 10.1109/TSMCB.2003.814281
   Criminisi A, 1999, IMAGE VISION COMPUT, V17, P625, DOI 10.1016/S0262-8856(98)00183-8
   CURWEN R, 1993, ACTIVE VISION, P21
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Duchowsky A. T., 2003, EYE TRACKING METHODO
   Hansen DW, 2005, COMPUT VIS IMAGE UND, V98, P155, DOI 10.1016/j.cviu.2004.07.013
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Shih SW, 2004, IEEE T SYST MAN CY B, V34, P234, DOI 10.1109/TSMCB.2003.811128
   Trucco E, 2005, PATTERN ANAL APPL, V8, P247, DOI 10.1007/sl0044-005-0004-8
   Wang HG, 2001, IMAGE VISION COMPUT, V19, P891, DOI 10.1016/S0262-8856(01)00051-8
   XU L, 1998, P 9 BRIT MACH VIS C, P58
   Zhu ZW, 2004, MACH VISION APPL, V15, P139, DOI 10.1007/s00138-004-0139-4
NR 17
TC 15
Z9 18
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2007
VL 3
IS 4
AR 20
DI 10.1145/1314303.1314305
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 250QU
UT WOS:000252315900002
DA 2024-07-18
ER

PT J
AU Zhu, J
   Peng, B
   Li, WQ
   Shen, HF
   Huang, QM
   Lei, JJ
AF Zhu, Jie
   Peng, Bo
   Li, Wanqing
   Shen, Haifeng
   Huang, Qingming
   Lei, Jianjun
TI Modeling Long-range Dependencies and Epipolar Geometry for Multi-view
   Stereo
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multi-view stereo; Transformer; feature matching; global context;
   long-range dependency; 3D consistency; epipolar geometry
AB This article proposes a network, referred to as Multi-View Stereo TRansformer (MVSTR) for depth estimation from multi-view images. By modeling long-range dependencies and epipolar geometry, the proposedMVSTR is capable of extracting dense features with global context and 3D consistency, which are crucial for reliable matching in multi-view stereo (MVS). Specifically, to tackle the problem of the limited receptive field of existing CNN-based MVS methods, a global-context Transformer module is designed to establish intra-view long-range dependencies so that global contextual features of each view are obtained. In addition, to further enable features of each view to be 3D consistent, a 3D-consistency Transformer module with an epipolar feature sampler is built, where epipolar geometry is modeled to effectively facilitate cross-view interaction. Experimental results show that the proposed MVSTR achieves the best overall performance on the DTU dataset and demonstrates strong generalization on the Tanks & Temples benchmark dataset.
C1 [Zhu, Jie; Peng, Bo; Lei, Jianjun] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Li, Wanqing] Univ Wollongong, Adv Multimedia Res Lab, Wollongong, Australia.
   [Shen, Haifeng] Didi Chuxing, AIoT Platform, Beijing 100193, Peoples R China.
   [Huang, Qingming] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100190, Peoples R China.
C3 Tianjin University; University of Wollongong; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Lei, JJ (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM jzhu98@tju.edu.cn; bpeng@tju.edu.cn; wanqing@uow.edu.au;
   shenhaifeng@didiglobal.com; qmhuang@ucas.ac.cn; jjlei@tju.edu.cn
OI Li, Wanqing/0000-0002-4427-2687; Zhu, Jie/0000-0003-4081-2073; Peng,
   Bo/0000-0002-6616-453X
FU National Key R&D Program of China [2021YFB2802300]; National Natural
   Science Foundation of China [62125110, 62101379, 61931014]; DiDi GAIA
   Research Cooperation Initiative; Natural Science Foundation of Tianjin
   [21JCQNJC01520]; China Postdoctoral Science Foundation [2022M712371,
   2021TQ0244]
FX The work of Bo Peng and Jianjun Lei was supported in part by the
   National Key R&D Program of China (No. 2021YFB2802300), National Natural
   Science Foundation of China (No. 62125110, 62101379, 61931014), DiDi
   GAIA Research Cooperation Initiative, Natural Science Foundation of
   Tianjin under Grant (No. 21JCQNJC01520), and China Postdoctoral Science
   Foundation under Grant (No. 2022M712371, 2021TQ0244).
CR Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Bulò SR, 2018, PROC CVPR IEEE, P5639, DOI 10.1109/CVPR.2018.00591
   Campbell NDF, 2008, LECT NOTES COMPUT SC, V5302, P766, DOI 10.1007/978-3-540-88682-2_58
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen PH, 2020, IEEE T IMAGE PROCESS, V29, P7261, DOI 10.1109/TIP.2020.3000611
   Chen R, 2019, IEEE I CONF COMP VIS, P1538, DOI 10.1109/ICCV.2019.00162
   Cheng S, 2020, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR42600.2020.00260
   Cho K., 2014, ARXIV14061078
   Ding YK, 2022, PROC CVPR IEEE, P8575, DOI 10.1109/CVPR52688.2022.00839
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Fang YM, 2019, IEEE T IMAGE PROCESS, V28, P2305, DOI 10.1109/TIP.2018.2885229
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Galliani S, 2015, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2015.106
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   He Y., 2020, P IEEE C COMP VIS PA, P7779
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hongwei Yi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P766, DOI 10.1007/978-3-030-58545-7_44
   Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59
   Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253
   Jia RM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197659
   Katharopoulos A, 2020, PR MACH LEARN RES, V119
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Lei JJ, 2021, IEEE T CIRC SYST VID, V31, P2686, DOI 10.1109/TCSVT.2020.3027616
   Li S, 2018, IEEE T MULTIMEDIA, V20, P1948, DOI 10.1109/TMM.2018.2791810
   Li ZS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6177, DOI 10.1109/ICCV48922.2021.00614
   Liao J., 2022, arXiv
   Liu JW, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231741
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Luo KY, 2019, IEEE I CONF COMP VIS, P10451, DOI 10.1109/ICCV.2019.01055
   Ma XJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5712, DOI 10.1109/ICCV48922.2021.00568
   Man X, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3503927
   Padhy RP, 2024, ACM T MULTIM COMPUT, V20, DOI 10.1145/3550485
   Peng B, 2022, IEEE T CIRC SYST VID, V32, P8342, DOI 10.1109/TCSVT.2022.3190916
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Shan JY, 2023, IEEE T MULTIMEDIA, V25, P2339, DOI 10.1109/TMM.2022.3146714
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   van der Hooft J, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3362101
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang FJ, 2021, PROC CVPR IEEE, P14189, DOI 10.1109/CVPR46437.2021.01397
   Wang XF, 2022, LECT NOTES COMPUT SC, V13691, P573, DOI 10.1007/978-3-031-19821-2_33
   Wei ZZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6167, DOI 10.1109/ICCV48922.2021.00613
   Xu QS, 2020, AAAI CONF ARTIF INTE, V34, P12508
   Xu QS, 2019, PROC CVPR IEEE, P5478, DOI 10.1109/CVPR.2019.00563
   Xue YZ, 2019, IEEE I CONF COMP VIS, P4311, DOI 10.1109/ICCV.2019.00441
   Yang JY, 2020, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR42600.2020.00493
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yao Y, 2019, PROC CVPR IEEE, P5520, DOI 10.1109/CVPR.2019.00567
   Yu H, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3514248
   Yu ZH, 2020, PROC CVPR IEEE, P1946, DOI 10.1109/CVPR42600.2020.00202
NR 53
TC 0
Z9 0
U1 3
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2023
VL 19
IS 6
AR 200
DI 10.1145/3596445
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N3AP4
UT WOS:001035785200023
DA 2024-07-18
ER

PT J
AU Huang, ZJ
   Sun, J
   Guo, XP
AF Huang, Zhijie
   Sun, Jun
   Guo, Xiaopeng
TI FastCNN: Towards Fast and Accurate Spatiotemporal Network for HEVC
   Compressed Video Enhancement
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Spatiotemporal; quality enhancement; speed
AB Deep neural networks have achieved remarkable success in HEVC compressed video quality enhancement. However, most existing multiframe-based methods either deliver unsatisfactory results or consume a significant amount of resources to leverage temporal information of neighboring frames. For the sake of practicality, a thorough investigation of the architecture design of the video quality enhancement network regarding enhancement performance, model parameters, and running speed is essential. In this article, we first propose an efficient alignment module that can quickly and accurately aggregate the spatiotemporal information of neighboring frames. The proposed module estimates deformable offsets progressively in lower-resolution space motivated by the observation of offset correlations between adjacent pixels. Then, the quantization parameter (QP) that represents compression level prior knowledge is utilized to guide aligned feature enhancement. By combining alignment feature distillation with residual feature correction, we obtain an efficient QP attention block. To save the storage space of the network, we design a hash buffer to store QP embedding features. These efficient components allow our network to effectively exploit temporal redundancies and obtain favorable enhancement capability while maintaining a lightweight structure and fast running speed. Extensive experiments demonstrate that the proposed approach outperforms state-of-the-art methods over different QPs by up to 0.09 to 0.11 dB, whereas the inference time can be reduced by up to 69%.
C1 [Huang, Zhijie; Sun, Jun; Guo, Xiaopeng] Peking Univ, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.
C3 Peking University
RP Sun, J (corresponding author), Peking Univ, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.
EM zhijiehuang@pku.edu.cn; jsun@pku.edu.cn; xiaopeng.guo@stu.pku.edu.cn
OI Huang, Zhijie/0000-0002-2019-3351; Guo, Xiaopeng/0000-0003-1111-2035
FU National Natural Science Foundation of China [62071014]
FX This work was supported by National Natural Science Foundation of China
   under contract no. 62071014.
CR Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Bossen Frank, 2011, TECH REP JCTVC L1100
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Chan KCK, 2020, Arxiv, DOI arXiv:2009.07265
   Chang M., 2020, EUR C COMP VIS, P171
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Deng JN, 2020, AAAI CONF ARTIF INTE, V34, P10696
   Ding Q, 2021, IEEE T IMAGE PROCESS, V30, P6459, DOI 10.1109/TIP.2021.3092949
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Fu CM, 2012, IEEE T CIRC SYST VID, V22, P1755, DOI 10.1109/TCSVT.2012.2221529
   Galteri L, 2017, IEEE I CONF COMP VIS, P4836, DOI 10.1109/ICCV.2017.517
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Guan ZY, 2021, IEEE T PATTERN ANAL, V43, P949, DOI 10.1109/TPAMI.2019.2944806
   Hang YC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2562, DOI 10.1145/3394171.3413564
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZJ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102826
   Huang ZJ, 2022, IEEE T CIRC SYST VID, V32, P2342, DOI 10.1109/TCSVT.2021.3089498
   Huang ZJ, 2021, IEEE DATA COMPR CONF, P33, DOI 10.1109/DCC50243.2021.00011
   Jia CM, 2019, IEEE T IMAGE PROCESS, V28, P3343, DOI 10.1109/TIP.2019.2896489
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma D. P., 2014, arXiv
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lemmetti A, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P237, DOI 10.1145/3339825.3394927
   Li Y, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3529107
   Liu D, 2017, IEEE I CONF COMP VIS, P2526, DOI 10.1109/ICCV.2017.274
   Lu G, 2020, IEEE T IMAGE PROCESS, V29, P1725, DOI 10.1109/TIP.2019.2943214
   Nasiri F, 2021, IEEE OPEN J SIGNAL P, V2, P466, DOI 10.1109/OJSP.2021.3092598
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Paszke A, 2019, ADV NEUR IN, V32
   Qin ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P763, DOI 10.1109/ICCV48922.2021.00082
   Rassool R, 2017, IEEE INT SYM BROADB, P351
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian YP, 2020, PROC CVPR IEEE, P3357, DOI 10.1109/CVPR42600.2020.00342
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang YQ, 2021, IEEE T IMAGE PROCESS, V30, P1057, DOI 10.1109/TIP.2020.3042059
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu Y, 2019, IEEE I CONF COMP VIS, P7042, DOI 10.1109/ICCV.2019.00714
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yang R, 2018, PROC CVPR IEEE, P6664, DOI 10.1109/CVPR.2018.00697
   Yang R, 2017, IEEE INT CON MULTI, P817, DOI 10.1109/ICME.2017.8019299
   Yuen M, 1998, SIGNAL PROCESS, V70, P247, DOI 10.1016/S0165-1684(98)00128-5
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang Yulun, 2019, 7 INT C LEARNING REP
NR 53
TC 3
Z9 3
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2023
VL 19
IS 3
AR 111
DI 10.1145/3569583
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FQ5
UT WOS:001011930300011
DA 2024-07-18
ER

PT J
AU Li, JJ
   Yuan, J
   Li, ZY
AF Li, Junjie
   Yuan, Jin
   Li, Zhiyong
TI TP-FER: An Effective Three-phase Noise-tolerant Recognizer for Facial
   Expression Recognition
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; label noise; three-phase learning
ID NETWORK; ATTENTION
AB Single-label facial expression recognition (FER), which aims to classify single expression for facial images, usually suffers from the label noisy and incomplete problem, where manual annotations for partial training images exist wrong or incomplete labels, resulting in performance decline. Although prior work has attempted to leverage external sources or manual annotations to handle this problem, it usually requires extra costs. This article explores a simple yet effective three-phase paradigm ("warm-up," "selection," and "relabeling") for FER task. First, the warm-up phase attempts to build an initial recognition network based on noisy samples for discriminative feature extractions and facial expression predictions. Then, the second selection phase defines several rules to choose high confident samples according to prediction scores, and the third relabeling phase assigns two potential labels to those samples for network updating according to a composite two-label loss. Compared with the previous studies, the three-phase learning could effectively correct noisy labels in the ground truth without extra information and automatically assign two potential labels to single-label samples without manual annotations. As a result, the label information is purified and supplemented with few cost, yielding significant performance improvement. Extensive experiments are conducted on three datasets, and the experimental results demonstrate that our approach is robust to noisy training samples and outperforms several state-of-the-art methods.
C1 [Li, Junjie; Yuan, Jin; Li, Zhiyong] Hunan Univ, 2 Lushannan Rd, Changsha, Yuelu Qu, Peoples R China.
C3 Hunan University
RP Yuan, J; Li, ZY (corresponding author), Hunan Univ, 2 Lushannan Rd, Changsha, Yuelu Qu, Peoples R China.
EM onwaier@hnu.edu.cn; yuanjin@hnu.edu.cn; zhiyong.li@hnu.edu.cn
RI Wang, zhenhua/KFA-8731-2024; Li, Zhiyong/ABE-2142-2020; Chen,
   Haili/KHE-2315-2024; Wang, Zejun/KBB-8454-2024; Yang, Ning/KHD-1133-2024
OI Yuan, Jin/0000-0002-9600-7789
FU National Natural Science Foundation of China [U21A20518, 61976086,
   62272157]; State Grid Science and Technology Project [5100-202123009A];
   Special Project of Foshan Science and Technology Innovation Team
   [FS0AA-KJ919-4402-0069]; National Natural Science Foundation of Changsha
   [kq2202177]
FX This work was partially supported by National Natural Science Foundation
   of China (Grants No. U21A20518, No. 61976086, and No. 62272157), State
   Grid Science and Technology Project (Grant No. 5100-202123009A), Special
   Project of Foshan Science and Technology Innovation Team (Grant No.
   FS0AA-KJ919-4402-0069), and National Natural Science Foundation of
   Changsha (Grant No. kq2202177).
CR Algan G, 2021, INT C PATT RECOG, P7142, DOI 10.1109/ICPR48806.2021.9412490
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Cai J, 2018, IEEE INT CONF AUTOMA, P302, DOI 10.1109/FG.2018.00051
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Ding H, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), DOI 10.1109/ijcb48548.2020.9304923
   Gera D, 2021, PATTERN RECOGN LETT, V145, P58, DOI 10.1016/j.patrec.2021.01.029
   Gera Darshan., 2021, P 12 INDIAN C COMPUT, P1
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2019, PR MACH LEARN RES, V97
   Hu W, 2019, PROC CVPR IEEE, P11879, DOI 10.1109/CVPR.2019.01216
   Huang JC, 2019, IEEE I CONF COMP VIS, P3325, DOI 10.1109/ICCV.2019.00342
   Jaehwan L., 2019, P IEEE INT C COMP VI
   KaiWang Yuxin Gu, 2020, ARXIV
   Li J., 2019, P INT C LEARNING REP
   Li JN, 2019, PROC CVPR IEEE, P5046, DOI 10.1109/CVPR.2019.00519
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Pham L, 2021, INT C PATT RECOG, P4513, DOI 10.1109/ICPR48806.2021.9411919
   Luo ZM, 2018, INT C PATT RECOG, P3132, DOI 10.1109/ICPR.2018.8545847
   Mo RY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P779, DOI 10.1145/3474085.3475249
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Nguyen Duc Tam, 2019, P INT C LEARNING REP
   Pecoraro Roberto., 2021, Local Multi-Head Channel Self-Attention for Facial Expression Recognition
   Pramerdorfer C, 2016, Arxiv, DOI arXiv:1612.02903
   Ruan DL, 2021, PROC CVPR IEEE, P7656, DOI 10.1109/CVPR46437.2021.00757
   Sharma Karishma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P737, DOI 10.1007/978-3-030-58583-9_44
   She JH, 2021, PROC CVPR IEEE, P6244, DOI 10.1109/CVPR46437.2021.00618
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Shikai Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13981, DOI 10.1109/CVPR42600.2020.01400
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Thulasidasan Sunil, 2019, P INT C MACHINE LEAR
   Veit A, 2017, PROC CVPR IEEE, P6575, DOI 10.1109/CVPR.2017.696
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang Xinshao, 2019, IMPROVED MEAN ABSOL
   Wang YS, 2019, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2019.00041
   Xie SY, 2019, PATTERN RECOGN, V92, P177, DOI 10.1016/j.patcog.2019.03.019
   Yuan BD, 2018, IEEE WINT CONF APPL, P757, DOI 10.1109/WACV.2018.00088
   Yuan J, 2022, IEEE T IMAGE PROCESS, V31, P1723, DOI 10.1109/TIP.2022.3145158
   Zeng D, 2022, PROC CVPR IEEE, P20259, DOI 10.1109/CVPR52688.2022.01965
   Zeng JB, 2018, LECT NOTES COMPUT SC, V11217, P227, DOI 10.1007/978-3-030-01261-8_14
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang Yuhang, 2021, ADV NEURAL INFO PROC, V34
   Zhao ZQ, 2021, AAAI CONF ARTIF INTE, V35, P3510
   Zheng Songzhu, 2020, PMLR, P11447
NR 48
TC 1
Z9 1
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2023
VL 19
IS 3
AR 113
DI 10.1145/3570329
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FQ5
UT WOS:001011930300013
DA 2024-07-18
ER

PT J
AU Yang, Y
   Ding, YQ
   Cheng, M
   Zhang, WM
AF Yang, Yang
   Ding, Yingqiu
   Cheng, Ming
   Zhang, Weiming
TI No-reference Quality Assessment for Contrast-distorted Images Based on
   Gray and Color-gray-difference Space
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Contrast distortion; image quality assessment (IQA); no-reference
AB No-reference image quality assessment is a basic and challenging problem in the field of image processing. Among them, contrast distortion has a great impact on the perception of image quality. However, there are relatively few studies on no-reference quality assessment of contrast-distorted images. This article proposes a no-reference quality assessment algorithm for contrast-distorted images based on gray and color-gray-difference (CGD) space. In terms of gray space, we consider the local and global aspects, and use the distribution characteristics of the grayscale histogram to represent global features, while local features are described by the fusion of Local Binary Pattern (LBP) operator and gradient. In terms of CGD space, we first randomly extract patches from the entire image and then extract appropriate quality perception features in the patch's CGD histogram. Finally, the AdaBoosting back propagation (BP) neural network is used to train the prediction model to predict the quality of the contrast-distorted image. Extensive analysis and cross-validation are carried out on five contrast-related image databases, and the experimental results have proved the superiority of this method compared with recent related algorithms.
C1 [Yang, Yang; Ding, Yingqiu; Cheng, Ming] Anhui Univ, Hefei, Anhui, Peoples R China.
   [Yang, Yang] Hefei Comprehens Natl Sci Ctr, Inst Artificial Intelligence, Hefei 230601, Peoples R China.
   [Zhang, Weiming] Univ Sci & Technol China, Hefei 230026, Peoples R China.
C3 Anhui University; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Yang, Y (corresponding author), Anhui Univ, Hefei, Anhui, Peoples R China.; Yang, Y (corresponding author), Hefei Comprehens Natl Sci Ctr, Inst Artificial Intelligence, Hefei 230601, Peoples R China.
EM sky_yang@ahu.edu.cn; dyingqiu@foxmail.com; chengming_96@163.com;
   zhangwm@ustc.edu.cn
OI Yang, Yang/0000-0003-1048-7994; Zhang, Weiming/0000-0001-5576-6108
FU Natural Science Foundation of the Anhui Higher Education Institutions of
   China [KJ2021A0016]; Natural Science Foundation of China [61502007,
   61871411]
FX This work was supported in part by the Natural Science Foundation of the
   Anhui Higher Education Institutions of China under Grant KJ2021A0016,
   and by the Natural Science Foundation of China under Grants 61502007 and
   61871411.
CR Ahissar E, 2016, VISION RES, V118, P25, DOI 10.1016/j.visres.2014.12.004
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   Cai H, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102861
   [成孝刚 Cheng Xiaogang], 2013, [自动化学报, Acta Automatica Sinica], V39, P418
   Deng CW, 2020, IEEE T CYBERNETICS, V50, P1146, DOI 10.1109/TCYB.2018.2889376
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Ghadiyaram D, 2015, IEEE IMAGE PROC, P3851, DOI 10.1109/ICIP.2015.7351526
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Gómez-Verdejo V, 2008, IEEE T NEURAL NETWOR, V19, P3, DOI 10.1109/TNN.2007.902723
   Gu HN, 2015, IEEE INT SYM BROADB
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2013, IEEE IMAGE PROC, P383, DOI 10.1109/ICIP.2013.6738079
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2013, IEEE INT SYMP CIRC S, P1095, DOI 10.1109/ISCAS.2013.6572041
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   Gvozden G, 2018, J VIS COMMUN IMAGE R, V50, P145, DOI 10.1016/j.jvcir.2017.11.017
   He LH, 2011, SIGNAL IMAGE VIDEO P, V5, P283, DOI 10.1007/s11760-010-0200-x
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888
   Khosravi MH, 2020, IEEE T CIRC SYST VID, V30, P48, DOI 10.1109/TCSVT.2018.2890457
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li LD, 2015, J VIS COMMUN IMAGE R, V30, P153, DOI 10.1016/j.jvcir.2015.04.001
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu M, 2017, IEEE T BROADCAST, V63, P71, DOI 10.1109/TBC.2016.2597545
   Liu YT, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3414837
   Mahmoudpour S, 2020, IEEE T MULTIMEDIA, V22, P1939, DOI 10.1109/TMM.2019.2950570
   Messai O, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115772
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Oszust M, 2019, INFORM SCIENCES, V482, P334, DOI 10.1016/j.ins.2019.01.034
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Scholkopf B., 2002, Learning with Kernels
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shlens J., 2014, INT J REMOTE SENS, V51, P1593
   Shokrollahi A, 2020, MULTIMED TOOLS APPL, V79, P19193, DOI 10.1007/s11042-020-08830-9
   Simone G, 2012, J VIS COMMUN IMAGE R, V23, P491, DOI 10.1016/j.jvcir.2012.01.008
   Soundararajan R, 2011, INT CONF ACOUST SPEE, P1149
   Sun W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1228, DOI 10.1109/ICASSP.2018.8461581
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Wu YJ, 2019, MULTIMED TOOLS APPL, V78, P10057, DOI 10.1007/s11042-018-6524-1
   Yan J., 2019, ARXIV
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou F, 2019, IEEE T IMAGE PROCESS, V28, P3528, DOI 10.1109/TIP.2019.2898638
   Zhu Y, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3183512
   Zhu YM, 2021, LECT NOTES COMPUT SC, V12890, P241, DOI 10.1007/978-3-030-87361-5_20
NR 53
TC 5
Z9 5
U1 1
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2023
VL 19
IS 2
AR 64
DI 10.1145/3555355
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J7DP3
UT WOS:001011190000014
DA 2024-07-18
ER

PT J
AU Wang, HD
   He, X
   Li, ZY
   Yuan, J
   Li, ST
AF Wang, Haidong
   He, Xuan
   Li, Zhiyong
   Yuan, Jin
   Li, Shutao
TI JDAN: Joint Detection and Association Network for Real-Time Online
   Multi-Object Tracking
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Online multi-object tracking; end-to-endmodel; object detection and data
   association
ID MULTITARGET TRACKING; OBJECT TRACKING; ASSIGNMENT
AB In the last few years, enormous strides have been made for object detection and data association, which are vital subtasks for one-stage online multi-object tracking (MOT). However, the two separated submodules involved in the whole MOT pipeline are processed or optimized separately, resulting in a complex method design and requiring manual settings. In addition, few works integrate the two subtasks into a single end-toend network to optimize the overall task. In this study, we propose an end-to-end MOT network called joint detection and association network ( JDAN) that is trained and inferred in a single network. All layers in JDAN are differentiable, and can be optimized jointly to detect targets and output an association matrix for robust multi-object tracking. What's more, we generate suitable pseudo-labels to address the data inconsistency between object detection and association. The detection and association submodules could be optimized by the composite loss function that is derived from the detection results and the generated pseudo association labels, respectively. The proposed approach is evaluated on two MOT challenge datasets, and achieves promising performance compared with classic and latest methods.
C1 [Wang, Haidong; He, Xuan; Li, Zhiyong; Yuan, Jin; Li, Shutao] Hunan Univ, Changsha, Peoples R China.
C3 Hunan University
RP Li, ZY; Yuan, J (corresponding author), Hunan Univ, Changsha, Peoples R China.
EM haidong@hnu.edu.cn; 419432961@qq.com; zhiyong.li@hnu.edu.cn;
   yuanjin@hnu.edu.cn; shutao_li@hnu.edu.cn
RI Chen, Haili/KHE-2315-2024; Wang, Zejun/KBB-8454-2024; Wang,
   zhenhua/KFA-8731-2024; Li, Shutao/Y-3102-2019; li, zy/HZM-1892-2023
OI Li, Shutao/0000-0002-0585-9848; Wang, Haidong/0000-0002-4614-5817; Yuan,
   Jin/0000-0002-9600-7789
FU National Key Research and Development Program of China [2018YFB1308604];
   National Natural Science Foundation of China [U21A20518, 61976086];
   Special Project of Foshan Science and Technology Innovation Team
   [FS0AA-KJ919-4402-0069]
FX This work was partially supported by National Key Research and
   Development Program of China (No. 2018YFB1308604), National Natural
   Science Foundation of China (No. U21A20518, No. 61976086), and Special
   Project of Foshan Science and Technology Innovation Team (No.
   FS0AA-KJ919-4402-0069).
CR Ahmed EK, 2022, J INTELL TRANSPORT S, V26, P269, DOI 10.1080/15472450.2020.1852082
   An N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3441656
   [Anonymous], 2017, P ICLR
   Bae SH, 2018, IEEE T PATTERN ANAL, V40, P595, DOI 10.1109/TPAMI.2017.2691769
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Chen L, 2017, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2017.8296360
   Chu P, 2019, IEEE I CONF COMP VIS, P6171, DOI 10.1109/ICCV.2019.00627
   Dendorfer P., 2019, ARXIV
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Ess A, 2008, PROC CVPR IEEE, P1857
   Fang K, 2018, IEEE WINT CONF APPL, P466, DOI 10.1109/WACV.2018.00057
   Fu Zeyu, 2019, IEEE T MULTIMEDIA, P1
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   HaidongWang SaizhouWang, 2020, IMAGE VISION COMPUT, V2020
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Leal-Taixe L., 2015, MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking
   Li GJ, 2020, NEURAL COMPUT APPL, V32, P9047, DOI 10.1007/s00521-019-04413-4
   Li ZY, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P560, DOI 10.1109/FSKD.2016.7603234
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo ZP, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4595, DOI 10.1145/3394171.3416304
   Lv Jingyi, 2020, IMAGE VISION COMPUT
   Mahmoudi N, 2019, MULTIMED TOOLS APPL, V78, P7077, DOI 10.1007/s11042-018-6467-6
   Milan A., 2016, ARXIV160300831
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nai K, 2018, IEEE T IMAGE PROCESS, V27, P4958, DOI 10.1109/TIP.2018.2848465
   Nai Ke, 2019, KNOWL-BASED SYST
   Paszke A, 2019, ADV NEUR IN, V32
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Welch G., 1995, An introduction to the kalman filter
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Xu X, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3414839
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zhang S., 2015, Advances in Neural Information Processing Systems, P685
   Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhou ZW, 2018, INT C PATT RECOG, P1809, DOI 10.1109/ICPR.2018.8545450
   Zhu J, 2018, LECT NOTES COMPUT SC, V11209, P379, DOI 10.1007/978-3-030-01228-1_23
NR 58
TC 3
Z9 3
U1 2
U2 27
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2023
VL 19
IS 1
SU S
AR 45
DI 10.1145/3533253
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Q4HK
UT WOS:000927169800019
DA 2024-07-18
ER

PT J
AU Liu, DY
   Wu, L
   Hong, RC
   Ge, ZY
   Shen, JL
   Boussaid, F
   Bennamoun, M
AF Liu, Deyin
   Wu, Lin (Yuanbo)
   Hong, Richang
   Ge, Zongyuan
   Shen, Jialie
   Boussaid, Farid
   Bennamoun, Mohammed
TI Generative Metric Learning for Adversarially Robust Open-world Person
   Re-Identification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Adversarial attack; open-world person re-identification; generative
   metric learning; robust models
ID NETWORK
AB The vulnerability of re-identification (re-ID) models under adversarial attacks is of significant concern as criminals may use adversarial perturbations to evade surveillance systems. Unlike a closed-world re-ID setting (i.e., a fixed number of training categories), a reliable re-ID system in the open world raises the concern of training a robust yet discriminative classifier, which still shows robustness in the context of unknown examples of an identity. In this work, we improve the robustness of open-world re-ID models by proposing a generative metric learning approach to generate adversarial examples that are regularized to produce robust distance metric. The proposed approach leverages the expressive capability of generative adversarial networks to defend the re-ID models against feature disturbance attacks. By generating the target people variants and sampling the triplet units for metric learning, our learned distance metrics are regulated to produce accurate predictions in the feature metric space. Experimental results on the three re-ID datasets, i.e., Market-1501, DukeMTMC-reID, and MSMT17 demonstrate the robustness of our method.
C1 [Liu, Deyin] Anhui Univ, Sch Artificial Intelligence, Anhui Prov Key Lab Multimodal Cognit Computat, 111 Jiu Long Rd, Hefei 230601, Anhui, Peoples R China.
   [Wu, Lin (Yuanbo)] Univ Western Australia, Australia & Hefei Univ Technol, 35 Stirling Highway, Perth, WA 6009, Australia.
   [Wu, Lin (Yuanbo)] Hefei Univ Technol, Hefei, Anhui, Peoples R China.
   [Hong, Richang] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
   [Ge, Zongyuan] Monash Univ, Monash Airdoc Res, Melbourne, Vic 3000, Australia.
   [Shen, Jialie] Queens Univ, Belfast, Antrim, North Ireland.
   [Boussaid, Farid; Bennamoun, Mohammed] Univ Western Australia, Sch Engn Elect Elect & Comp Engn, 35 Stirling Highway, Perth, WA 6009, Australia.
C3 Anhui University; University of Western Australia; Hefei University of
   Technology; Hefei University of Technology; Monash University; Queens
   University Belfast; University of Western Australia
RP Wu, L (corresponding author), Univ Western Australia, Australia & Hefei Univ Technol, 35 Stirling Highway, Perth, WA 6009, Australia.; Wu, L (corresponding author), Hefei Univ Technol, Hefei, Anhui, Peoples R China.
EM iedyzzu@outlook.com; lin.wu@uwa.edu.au; hongrc.hfut@gmail.com;
   zongyuan.ge@monash.edu; j.shen@qub.ac.uk; Farid.Boussaid@uwa.edu.au;
   Mohammed.Bennamoun@uwa.edu.au
RI Yang, Lili/JTT-5215-2023; Bennamoun, Mohammed/C-2789-2013; Sun,
   Yuchen/JZD-1692-2024
OI Yang, Lili/0009-0008-2926-484X; Bennamoun, Mohammed/0000-0002-6603-3257;
   Liu, Deyin/0000-0002-0371-9921
FU Australian Research Council [DP150100294, DP150104251]; NSFC [U19A2073,
   62002096]; Co-operative Innovation Project of Colleges in Anhui
   [GXXT-2019-025]
FX This work was funded by Australian Research Council (Grants DP150100294
   and DP150104251). Lin (Yuanbo) Wu was partially supported by NSFC
   U19A2073, 62002096. This work was also partially supported by
   Co-operative Innovation Project of Colleges in Anhui (GXXT-2019-025).
CR Aditi Raghunathan, 2018, ICLR
   Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   An L, 2015, IEEE SIGNAL PROC LET, V22, P1103, DOI 10.1109/LSP.2015.2390222
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   Athalye A, 2018, PR MACH LEARN RES, V80
   Bai S, 2021, IEEE T PATTERN ANAL, V43, P2119, DOI 10.1109/TPAMI.2020.3031625
   BrendelWieland Jonas Rauber, 2018, ICLR
   Cao XY, 2017, ANN COMPUT SECURITY, P278, DOI 10.1145/3134600.3134606
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Cisse M, 2017, PR MACH LEARN RES, V70
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding WJ, 2021, IEEE T INF FOREN SEC, V16, P3442, DOI 10.1109/TIFS.2021.3081247
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Duan YQ, 2018, PROC CVPR IEEE, P2780, DOI 10.1109/CVPR.2018.00294
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gong YP, 2021, Arxiv, DOI arXiv:2101.08783
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Ilyas A., 2018, PR MACH LEARN RES, P2137
   Ilyas A, 2019, ADV NEUR IN, V32
   Kannan H, 2018, Arxiv, DOI arXiv:1803.06373
   Kaziakhmedov Edgar, 2019, 2019 International Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON). Proceedings, P0422, DOI 10.1109/SIBIRCON48586.2019.8958122
   Khan S., 2018, A Guide to Convolutional Neural Networks for Computer Vision, V1
   Kurakin A, 2017, Arxiv, DOI arXiv:1607.02533
   Li J, 2019, IEEE I CONF COMP VIS, P4898, DOI 10.1109/ICCV.2019.00500
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li X, 2018, LECT NOTES COMPUT SC, V11206, P287, DOI 10.1007/978-3-030-01216-8_18
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Madry A., 2018, ICLR
   Mao Chengzhi, 2019, ADV NEUR IN
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Mopuri KR, 2019, IEEE T PATTERN ANAL, V41, P2452, DOI 10.1109/TPAMI.2018.2861800
   Papernot N., 2016, CORR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Samangouei P, 2018, Arxiv, DOI [arXiv:1805.06605, DOI 10.48550/ARXIV.1805.06605]
   Shafahi A, 2019, ADV NEUR IN, V32
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tramer F., 2018, ICLR POST OPENREVIEW
   Wang HJ, 2020, PROC CVPR IEEE, P339, DOI 10.1109/CVPR42600.2020.00042
   Wang ZB, 2019, IEEE I CONF COMP VIS, P8340, DOI 10.1109/ICCV.2019.00843
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wong E, 2018, PR MACH LEARN RES, V80
   Wu L, 2020, IEEE T IMAGE PROCESS, V29, P1233, DOI 10.1109/TIP.2019.2940684
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Xiao K, 2019, IEEE ICC
   Xie CH, 2019, Arxiv, DOI arXiv:1812.03411
   YANG Y, 2019, ARXIV190704307
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zhang DH, 2019, ADV NEUR IN, V32
   ZHANG X, 2017, ALIGNEDREID SURPASSI
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng Z., 2018, 32 C NEURAL INFORM P
   Zheng ZD, 2020, Arxiv, DOI arXiv:1809.02681
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhu XT, 2018, IEEE T IMAGE PROCESS, V27, P2286, DOI 10.1109/TIP.2017.2740564
NR 70
TC 15
Z9 15
U1 1
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2023
VL 19
IS 1
AR 20
DI 10.1145/3522714
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Q4GM
UT WOS:000927167400020
DA 2024-07-18
ER

PT J
AU Ren, RY
   Niu, SZ
   Ren, H
   Zhang, SB
   Han, TY
   Tong, XH
AF Ren, Ruyong
   Niu, Shaozhang
   Ren, Hua
   Zhang, Shubin
   Han, Tengyue
   Tong, Xiaohai
TI ESRNet: Efficient Search and Recognition Network for Image Manipulation
   Detection
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Information security; image manipulation; novel dataset; unified
   detection network
ID RING PARTITION
AB With the widespread use of smartphones and the rise of intelligent software, we can manipulate captured photos anytime and anywhere, so the fake photos finally obtained look "Real." If these intelligent operation methods are maliciously applied to our daily life, then fake news, fake photos, rumors, slander, fraud, threats, and other information security issues around us can happen all the time. Today's intelligent retouching software can make various modifications to photos, some of which do not change the content that the photos themselves want to express, such as retouching, contrast improvement, and so on. In this article, we mainly study the three operation modes of changing the authenticity of photo contents, which are Copy-move, Splicing, and Removal. Few scholars have done relevant research due to the lack of a corresponding dataset. To address this issue, we elaborately collect a novel dataset, called the multi-realistic scene manipulation dataset (MSM30K), which consists of 30,000 images, including three types of tampering methods, and covering 32 different tampering scenes in life. In addition, we propose a unified detection network: the efficient search and recognition network (ESRNet) for three tampering methods. It mainly includes four main modules: Efficient feature pyramid network (EFPN), Residual receptive field block with attention (RFBA), Hierarchical decoding identification (HDI), and Cascaded group-reversal attention (GRA) blocks. On these three datasets, ESRNet can reach 0.81 on the S-measure, 0.72 on the F-measure, and 0.85 on the E-measure. The inference speed is similar to 53 fps on a single GPU without I/O time. ESRNet outperforms various state-of-the-art manipulation detection baselines on three image manipulation datasets.
C1 [Ren, Ruyong; Niu, Shaozhang; Ren, Hua; Han, Tengyue; Tong, Xiaohai] Beijing Univ Posts & Telecommun, 10 Xitucheng Rd, Beijing, Peoples R China.
   [Zhang, Shubin] China Agr Univ, 17 Qinghua East Rd, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; China Agricultural
   University
RP Ren, RY (corresponding author), Beijing Univ Posts & Telecommun, 10 Xitucheng Rd, Beijing, Peoples R China.
EM renruyong520@bupt.edu.cn; szniu@bupt.edu.cn; renhuahtu@163.com;
   hantengyue@bupt.edu.cn; neinstein@bupt.edu.cn
OI Zhang, Shubin/0000-0002-7985-4898
FU National Natural Science Foundation of China [61370195, U1536121]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61370195) and in part by the Joint Funds
   of the National Natural Science Foundation of China (Grant No.
   U1536121).
CR Battiato Sebastiano, 2010, P 2 ACM WORKSH MULT
   Chen L., 2021, P IEEECVF C COMPUTER
   Costanzo A, 2014, IEEE T INF FOREN SEC, V9, P1450, DOI 10.1109/TIFS.2014.2337654
   Cozzolino D., 2015, IEEE T INF FOREN SEC, V10, P2284, DOI DOI 10.1109/TIFS.2015.2455334
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fan Deng-Ping, 2021, ABS210210274 CORR
   Gallagher AC, 2008, PROC CVPR IEEE, P253
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Huang DY, 2017, MULTIMED TOOLS APPL, V76, P1509, DOI 10.1007/s11042-015-3152-x
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Islam A, 2020, PROC CVPR IEEE, P4675, DOI 10.1109/CVPR42600.2020.00473
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Korus P, 2016, IEEE INT WORKS INFOR
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu YQ, 2019, IEEE T INF FOREN SEC, V14, P2551, DOI 10.1109/TIFS.2019.2902826
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Mahmood T, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8713202
   Manu VT, 2016, ADV INTELL SYST COMP, V425, P645, DOI 10.1007/978-3-319-28658-7_55
   Morain-Nicolier F., 2019, PROC 27 EUR SIGNAL P, P1
   Novozámsky A, 2020, IEEE WINT CONF APPL, P71, DOI [10.1109/WACVW50321.2020.9096940, 10.1109/wacvw50321.2020.9096940]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen CH, 2019, NEW MEDIA SOC, V21, P438, DOI 10.1177/1461444818799526
   Tang ZJ, 2019, IEEE T KNOWL DATA EN, V31, P549, DOI 10.1109/TKDE.2018.2837745
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Wan SH, 2021, IEEE T INTELL TRANSP, V22, P4151, DOI 10.1109/TITS.2020.3017596
   Wan SH, 2020, IEEE T MULTIMEDIA, V22, P1756, DOI 10.1109/TMM.2020.2976573
   Wan SH, 2020, J SUPERCOMPUT, V76, P2518, DOI 10.1007/s11227-019-03011-4
   Wei Y, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3408299
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2019, PROC CVPR IEEE, P374, DOI 10.1109/CVPR.2019.00046
   Wu Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1480, DOI 10.1145/3123266.3123411
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Xu RK, 2021, IEEE COMPUT SOC CONF, P414, DOI 10.1109/CVPRW53098.2021.00052
   Yates A. N., NIMBLE CHALLENGE 201
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 47
TC 4
Z9 4
U1 5
U2 60
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2022
VL 18
IS 4
AR 111
DI 10.1145/3506853
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0E1KA
UT WOS:000776441600022
DA 2024-07-18
ER

PT J
AU Duanmu, ZF
   Liu, WT
   Chen, DQ
   Li, ZR
   Wang, Z
   Wang, YZ
   Gao, W
AF Duanmu, Zhengfang
   Liu, Wentao
   Chen, Diqi
   Li, Zhuoran
   Wang, Zhou
   Wang, Yizhou
   Gao, Wen
TI A Bayesian Quality-of-Experience Model for Adaptive Streaming Videos
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Quality-of-experience assessment; adaptive video streaming; quadratic
   programming
ID IMPACT; QOE; DATABASE
AB The fundamental conflict between the enormous space of adaptive streaming videos and the limited capacity for subjective experiment casts significant challenges to objective Quality-of-Experience (QoE) prediction. Existing objective QoE models either employ pre-defined parametrization or exhibit complex functional form, achieving limited generalization capability in diverse streaming environments. In this study, we propose an objective QoE model, namely, the Bayesian streaming quality index (BSQI), to integrate prior knowledge on the human visual system and human annotated data in a principled way. By analyzing the subjective characteristics towards streaming videos from a corpus of subjective studies, we show that a family of QoE functions lies in a convex set. Using a variant of projected gradient descent, we optimize the objective QoE model over a database of training videos. The proposed BSQI demonstrates strong prediction accuracy in a broad range of streaming conditions, evident by state-of-the-art performance on four publicly available benchmark datasets and a novel analysis-by-synthesis visual experiment.
C1 [Duanmu, Zhengfang; Liu, Wentao; Li, Zhuoran; Wang, Zhou] Univ Waterloo, Waterloo, ON, Canada.
   [Chen, Diqi] Chinese Acad Sci, Beijing, Peoples R China.
   [Wang, Yizhou; Gao, Wen] Peking Univ, Beijing, Peoples R China.
C3 University of Waterloo; Chinese Academy of Sciences; Peking University
RP Duanmu, ZF (corresponding author), Univ Waterloo, Waterloo, ON, Canada.
RI Chen, Diqi/JDC-1980-2023
OI Chen, Diqi/0000-0002-9341-8937; Wang, Zhou/0000-0003-4413-4441
FU Natural Sciences and Engineering Research Council (NSERC) of Canada;
   Canada Research Chair program; Alexander Graham Bell Canada Graduate
   Scholarship program
FX This work is supported in part by Natural Sciences and Engineering
   Research Council (NSERC) of Canada under the Discovery Grant, Canada
   Research Chair program, and Alexander Graham Bell Canada Graduate
   Scholarship program. Authors' addresses: Z. Duanmu, W. Liu, Z. Li, and
   Z. Wang, University of Waterloo, Canada; D. Chen, Chinese Academy of
   Sciences, China; Y. Wang and W. Gao, Peking University, China.
CR [Anonymous], 1993, ITU R BT 500 12
   [Anonymous], 2015, IEEE INT WORKSHOP MU
   [Anonymous], 2017, ITU T P 1203
   Bampis CG, 2018, PICT COD SYMP, P298, DOI 10.1109/PCS.2018.8456293
   Bampis CG, 2017, IEEE SIGNAL PROC LET, V24, P1083, DOI 10.1109/LSP.2017.2705423
   Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P5217, DOI 10.1109/TIP.2017.2729891
   Bampis Z. Li, 2018, arXiv
   Bentaleb A, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1296, DOI 10.1145/2964284.2964332
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   CiscoMobile VNI, 2017, CISCO VISUAL NETWORK
   De Cock J, 2016, IEEE IMAGE PROC, P1484, DOI 10.1109/ICIP.2016.7532605
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Domingos P, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P564
   Duanmu Z., 2019, PAIRWISE COMP OBJECT
   Duanmu Z., 2020, arXiv
   Duanmu Z., 2021, ANNU REV VIS SCI
   Duanmu Z., 2019, WATERLOO STREAMING Q
   Duanmu ZF, 2018, IEEE T IMAGE PROCESS, V27, P6135, DOI 10.1109/TIP.2018.2855403
   Duanmu ZF, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1752, DOI 10.1145/3123266.3123418
   Duanmu ZF, 2018, IEEE T BROADCAST, V64, P474, DOI 10.1109/TBC.2018.2822870
   Duanmu ZF, 2017, IEEE J-STSP, V11, P154, DOI 10.1109/JSTSP.2016.2608329
   Encoding.com, 2016, MICR SMOOTH STREAM
   Eswara N, 2020, IEEE T CIRC SYST VID, V30, P661, DOI 10.1109/TCSVT.2019.2895223
   Bampis CG, 2017, Arxiv, DOI arXiv:1703.00633
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Ghadiyaram D, 2019, IEEE T CIRC SYST VID, V29, P183, DOI 10.1109/TCSVT.2017.2768542
   Ghadiyaram D, 2018, IEEE T IMAGE PROCESS, V27, P2257, DOI 10.1109/TIP.2018.2790347
   Grafl M., 2013, Proceedings of the 4th International Workshop on Perceptual Quality of Systems (PQS 2013), P178
   Hagan MT, 1997, NEURAL NETWORK DESIG
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Hossfeld Tobias, 2013, Data Traffic Monitoring and Analysis. From Measurement, Classification, and Anomaly Detection to Quality of Experience, P264, DOI 10.1007/978-3-642-36784-7_11
   Hossfeld Tobias, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P494, DOI 10.1109/ISM.2011.87
   Huang TY, 2014, ACM SIGCOMM COMP COM, V44, P187, DOI 10.1145/2740070.2626296
   Huang TC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P429, DOI 10.1145/3343031.3351014
   Hyun Jong Kim, 2012, 2012 14th International Conference on Advanced Communication Technology (ICACT), P459
   Ishii I, 2010, IEEE INT CONF ROBOT, P1536, DOI 10.1109/ROBOT.2010.5509731
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Le Feuvre J., 2007, P 15 ACM INT C MULT, P1009, DOI [10.1145/1291233.1291452, DOI 10.1145/1291233.1291452]
   Lederer S., 2015, Optimal adaptive streaming formats mpeg-dash hls segment length
   Li Z., INT C IMAGE ANAL REC
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Li Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30338
   Liu WT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P546, DOI 10.1145/3240508.3240643
   Liu X, 2012, ACM SIGCOMM COMP COM, V42, P359, DOI 10.1145/2377677.2377752
   Liu Y, 2015, IEEE T BROADCAST, V61, P651, DOI 10.1109/TBC.2015.2460611
   Ma KD, 2020, IEEE T PATTERN ANAL, V42, P851, DOI 10.1109/TPAMI.2018.2889948
   Mao HZ, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P197, DOI 10.1145/3098822.3098843
   Mishra A. M, 2001, QUALITY SERVICE COMM
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Netflix Inc, 2015, PERT ENC OPT
   Ng R, 2005, RES REPORT, DOI DOI 10.1145/3097571
   Ni P., 2011, P 19 ACM INT C MULT, P463, DOI DOI 10.1145/2072298.2072359
   Nightingale J, 2014, IEEE T CONSUM ELECTR, V60, P242, DOI 10.1109/TCE.2014.6852000
   OLIVER RL, 1980, J MARKETING RES, V17, P460, DOI 10.2307/3150499
   Pastrana-Vidal RR, 2004, P SOC PHOTO-OPT INS, V5292, P182, DOI 10.1117/12.525746
   Paudyal P, 2016, MULTIMED TOOLS APPL, V75, P16461, DOI 10.1007/s11042-015-3214-0
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rehman A, 2015, SPIE SPIE
   Rehman A, 2013, INT WORK QUAL MULTIM, P218, DOI 10.1109/QoMEX.2013.6603240
   Riiser Haakon, 2013, P 4 ACM MULT SYST C, P114, DOI DOI 10.1145/2483977.2483991
   Rodríguez DZ, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-216
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Singh KD, 2012, CONSUM COMM NETWORK, P127, DOI 10.1109/CCNC.2012.6181070
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   Stellato B, 2020, Arxiv, DOI arXiv:1711.08013
   Duc TN, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SYSTEMS (ICISS 2019), P156, DOI 10.1145/3322645.3322687
   Toni L, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700294
   Tsukida K., 2011, UWEETR20110004 U WAS
   van der Hooft J, 2016, IEEE COMMUN LETT, V20, P2177, DOI 10.1109/LCOMM.2016.2601087
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2017, PROC SMPTE MOTION IM, P1
   Wang Z., 2017, US Patent, Patent No. [WO/2017/152274, 2017152274]
   Wang Z., 2001, INTERNET QOS ARCHITE
   Wang Z., 2016, US Patent, Patent No. [WO/2016/123721, 2016123721]
   Wang Z, 2008, J VISION, V8, DOI 10.1167/8.12.8
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Watanabe K, 2007, PROC SPIE, V6494, DOI 10.1117/12.703870
   Xue JT, 2014, IEEE INT CON MULTI
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
NR 84
TC 3
Z9 3
U1 1
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2022
VL 18
IS 3
SU S
SI SI
AR 141
DI 10.1145/3491432
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A0AE2
UT WOS:000951829800011
DA 2024-07-18
ER

PT J
AU Li, Q
   Xiao, F
   Bhanu, B
   Sheng, BY
   Hong, RC
AF Li, Qun
   Xiao, Fu
   Bhanu, Bir
   Sheng, Biyun
   Hong, Richang
TI Inner Knowledge-based Img2Doc Scheme for Visual Question Answering
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE VQA; dense image captioning; Doc2Vec; inner knowledge-based; attribute
   network
AB Visual Question Answering (VQA) is a research topic of significant interest at the intersection of computer vision and natural language understanding. Recent research indicates that attributes and knowledge can effectively improve performance for both image captioning and VQA. In this article, an inner knowledge-based Img2Doc algorithm for VQA is presented. The inner knowledge is characterized as the inner attribute relationship in visual images. In addition to using an attribute network for inner knowledge-based image representation, VQA scheme is associated with a question-guided Doc2Vec method for question-answering. The attribute network generates inner knowledge-based features for visual images, while a novel question-guided Doc2Vec method aims at converting natural language text to vector features. After the vector features are extracted, they are combined with visual image features into a classifier to provide an answer. Based on our model, the VQA problem is resolved by textual question answering. The experimental results demonstrate that the proposed method achieves superior performance on multiple benchmark datasets.
C1 [Li, Qun; Xiao, Fu; Sheng, Biyun] Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, 9 Wenyuan Rd, Nanjing 210023, Peoples R China.
   [Bhanu, Bir] Univ Calif Riverside, Ctr Res Intelligent Syst, 900 Univ Ave, Riverside, CA 92521 USA.
   [Hong, Richang] Hefei Univ Technol, Sch Comp Sci & Informat Engn, 193 Tunxi Rd, Hefei 230009, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; University of
   California System; University of California Riverside; Hefei University
   of Technology
RP Xiao, F (corresponding author), Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, 9 Wenyuan Rd, Nanjing 210023, Peoples R China.
EM liqun@njupt.edu.cn; xiaof@njupt.edu.cn; bhanu@ee.ucr.edu;
   biyunsheng@njupt.edu.cn; hongrc.hfut@gmail.com
RI Li, Qun/JEP-3834-2023
OI Li, Qun/0000-0002-8034-6030
FU National Natural Science Foundation of China [61906099, 61906098,
   61803212, 61571238, 61602193]; Nature Science Foundation of Jiangsu for
   Distinguished Young Scientist [BK20170039]; Postdoctoral Research Plan
   of Jiangsu Province [1701167B]; Postdoctoral Science Foundation of China
   [2017M621795, 2019M651915]; Nanjing University of Posts and
   Telecommunications Program [NY218026]
FX This work was partially supported by the National Natural Science
   Foundation of China under Grant No. 61906099, No. 61906098, No.
   61803212, No. 61571238, No. 61602193, the Nature Science Foundation of
   Jiangsu for Distinguished Young Scientist under Grant BK20170039, the
   Postdoctoral Research Plan of Jiangsu Province under Grant No. 1701167B
   and the Postdoctoral Science Foundation of China under Grant No.
   2017M621795, No. 2019M651915, the Nanjing University of Posts and
   Telecommunications Program under Grant No. NY218026.
CR Acharya M, 2019, AAAI CONF ARTIF INTE, P8076
   Agarwal Vedika, 2020, P IEEE CVF C COMP VI, P9690
   Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Bai ZW, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107538
   Berant J., 2013, P 2013 C EMPIRICAL M, P1533
   Biten AF, 2019, IEEE I CONF COMP VIS, P4290, DOI 10.1109/ICCV.2019.00439
   Bollacker K., 2008, P 2008 ACM SIGMOD IN, P1247, DOI 10.1145/1376616.1376746
   COHEN IB, 1987, J HIST IDEAS, V48, P571, DOI 10.2307/2709688
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Fu K, 2017, IEEE T PATTERN ANAL, V39, P2321, DOI 10.1109/TPAMI.2016.2642953
   Fukui A., 2016, P C EMP METH NAT LAN, P457
   Gao H., 2015, INT C NEURAL INF PRO, P2296
   Gokhale Tejas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P379, DOI 10.1007/978-3-030-58589-1_23
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Guo J, 2011, SCI REP-UK, V1, DOI 10.1038/srep00113
   Hudson D.A., 2018, INT C LEARN REPR ICL
   Hudson Drew, 2019, Advances in Neural Information Processing Systems, P5901
   Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005
   Kafle K, 2016, PROC CVPR IEEE, P4976, DOI 10.1109/CVPR.2016.538
   Kazemi Vahid., 2017, Show, ask, attend, and answer: A strong baseline for visual question answering
   Kim JH, 2018, ADV NEUR IN, V31
   Li Q, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1338
   Li Q, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3300938
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Malinowski M, 2014, ADV NEUR IN, V27
   Malinowski M, 2017, INT J COMPUT VISION, V125, P110, DOI 10.1007/s11263-017-1038-2
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11
   Norcliffe-Brown W, 2018, ADV NEUR IN, V31
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ren MY, 2015, ADV NEUR IN, V28
   Ren Mengye, 2015, NeurIPS, P1
   Santoro A, 2017, ADV NEUR IN, V30
   Shrestha R, 2019, PROC CVPR IEEE, P10464, DOI 10.1109/CVPR.2019.01072
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Tan H., 2019, Conference on Empirical Methods in Natural Language Processing
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang Ye Yi, 1994, COMPUTER SCI, V14, P325
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhang JL, 2018, GEOPHYS RES LETT, V45, P8665, DOI 10.1029/2018GL077787
   Zhang L, 2020, 2020 CONFERENCE ON LASERS AND ELECTRO-OPTICS PACIFIC RIM (CLEO-PR), DOI 10.1364/CLEOPR.2020.C3F_5
   Zhou Bolei, 2015, IEEE C COMP VIS PATT, P12548
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   ZHU Yu-ke, 2015, Building a large-scale multimodal knowledge base system for answering visual queries
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 61
TC 9
Z9 9
U1 2
U2 20
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2022
VL 18
IS 3
AR 76
DI 10.1145/3489142
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5UA
UT WOS:000772650600010
DA 2024-07-18
ER

PT J
AU Huang, W
   Zhang, YZ
   Wan, SH
AF Huang, Wei
   Zhang, Yuze
   Wan, Shaohua
TI A Sorting Fuzzy Min-Max Model in an Embedded System for Atrial
   Fibrillation Detection
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Sorting fuzzy min-max (SFMM) model; embedded system; electrocardiogram
   (ECG); Atrial fibrillation (AF); fuzzy min-max (FMM) model
ID NEURAL-NETWORK; CLASSIFICATION; ECG; DIAGNOSIS
AB Atrial fibrillation detection (AFD) has attracted much attention in the field of embedded systems. In this study, we propose a sorting fuzzy min-max (SFMM) model, and then develop an SFMM-based embedded system for AF detection. The proposed SFMM model is essentially enhanced the fuzzy min-max (FMM) model that have been successfully applied in many classification fields. In comparison with the typical FMM model, the proposed SFMM model can overcome the limitation of the input order problem encountered in the typical FMM model. The embedded system consists of a control chip and an analog-digital conversion (ADC) chip. The STM32F407 chip is used as the control chip and the ADS1292 chip, which has a high common-mode rejection ratio (CMRR), is used as the ADC chip. A series of machine learning benchmarks are included to evaluate the performance of the SFMM model. Experimental results on AF data further demonstrate the effectiveness of the SFMM-based embedded system.
C1 [Huang, Wei] Beijing Inst Technol, Sch Cyberspace Sci & Technol, 5 Yard,Zhong Gum Cun South St, Beijing 100081, Peoples R China.
   [Zhang, Yuze] Tianjin Univ Techonl, Sch Comp Sci & Engn, 391 Bin Shui West Rd, Tianjin 300384, Peoples R China.
   [Wan, Shaohua] Univ Elect Sci & Technol China, Shenzhen Inst Adv Study, 1301-78 Xinlan Community,Guanlan St, Shenzhen 518110, Peoples R China.
C3 Beijing Institute of Technology; University of Electronic Science &
   Technology of China; Shenzhen Institute for Advanced Study, UESTC
RP Wan, SH (corresponding author), Univ Elect Sci & Technol China, Shenzhen Inst Adv Study, 1301-78 Xinlan Community,Guanlan St, Shenzhen 518110, Peoples R China.
EM huangwabc@163.com; zhangyuzetjut@163.com; shaohua.wan@uestc.edu.cn
RI Wan, Shaohua/L-8492-2019; Wan, Shaohua/B-9243-2014
OI Wan, Shaohua/0000-0001-7013-9081; , Wei/0000-0002-4315-8487
FU Open Foundation of State Key Laboratory of Complex Electronic System
   Simulation, Beijing, China [614201001032104]; National Natural Science
   Foundation of China [61673259]
FX This work was supported by the Open Foundation of State Key Laboratory
   of Complex Electronic System Simulation, Beijing, China (Grant No.
   614201001032104), and supported by the National Natural Science
   Foundation of China (Grant No. 61673259).
CR Acharya UR, 2017, INFORM SCIENCES, V405, P81, DOI 10.1016/j.ins.2017.04.012
   Andersen RS, 2019, EXPERT SYST APPL, V115, P465, DOI 10.1016/j.eswa.2018.08.011
   [Anonymous], 2016, P IIT GUWAHATI
   Anselmino M, 2015, J CARDIOVASC MED, V16, P795, DOI 10.2459/JCM.0000000000000239
   Bargiela A., 2004, International Journal of Knowledge-Based and Intelligent Engineering Systems, V8, P91
   Berkaya SK, 2018, BIOMED SIGNAL PROCES, V43, P216, DOI 10.1016/j.bspc.2018.03.003
   Ceballos R, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152128
   Chugh SS, 2014, CIRCULATION, V129, P837, DOI 10.1161/CIRCULATIONAHA.113.005119
   de Toro F, 2002, LECT NOTES ARTIF INT, V2527, P313
   Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747
   González-Ortega D, 2014, COMPUT METH PROG BIO, V113, P620, DOI 10.1016/j.cmpb.2013.10.014
   Hossain MS, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3241056
   Jonkman AH, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102861
   Kara S, 2007, PATTERN RECOGN, V40, P2967, DOI 10.1016/j.patcog.2007.03.008
   Kim HJ, 2005, LECT NOTES COMPUT SC, V3612, P1178
   Kim HJ, 2006, LECT NOTES COMPUT SC, V4233, P177
   Kroupi E, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2637287
   Kumar AS, 2020, IEEE T FUZZY SYST, V28, P1910, DOI 10.1109/TFUZZ.2019.2924396
   Li FH, 2019, APPL SOFT COMPUT, V80, P400, DOI 10.1016/j.asoc.2019.04.007
   Lim HW, 2017, INT SOC DESIGN CONF, P90, DOI 10.1109/ISOCC.2017.8368784
   Lin CT, 2010, IEEE T INF TECHNOL B, V14, P726, DOI 10.1109/TITB.2010.2047401
   Melin P, 2014, INFORM SCIENCES, V279, P483, DOI 10.1016/j.ins.2014.04.003
   Melin P, 2013, EXPERT SYST APPL, V40, P3196, DOI 10.1016/j.eswa.2012.12.033
   Mohammed MF, 2015, IEEE T NEUR NET LEAR, V26, P417, DOI 10.1109/TNNLS.2014.2315214
   Mousavi S, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104057
   Parsi A, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104367
   Petmezas G, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102194
   Quteishat A, 2008, LECT NOTES ARTIF INT, V5179, P548, DOI 10.1007/978-3-540-85567-5_68
   Quteishat A, 2009, NEUROCOMPUTING, V72, P1639, DOI 10.1016/j.neucom.2008.08.012
   Radoglou-Grammatikis P, 2022, IEEE T IND INFORM, V18, P2041, DOI 10.1109/TII.2021.3093905
   Sani S, 2021, IEEE ICCE, DOI 10.1109/ICCE50685.2021.9427729
   SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066
   Trung TQ, 2016, ADV MATER, V28, P4338, DOI 10.1002/adma.201504244
   Wang HY, 2023, NEURAL COMPUT APPL, V35, P11583, DOI 10.1007/s00521-021-06546-x
   Wang JB, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2019.105446
   Yang DB, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472393
   Yang XD, 2017, IEEE T PATTERN ANAL, V39, P1028, DOI 10.1109/TPAMI.2016.2565479
   Zhang HG, 2011, IEEE T NEURAL NETWOR, V22, P2339, DOI 10.1109/TNN.2011.2175748
   Zhang J, 2021, IEEE INTERNET THINGS, V8, P7789, DOI 10.1109/JIOT.2020.3039359
   Zhang J, 2020, KNOWL-BASED SYST, V190, DOI 10.1016/j.knosys.2019.105402
   Zhang Y, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3542820
   Zhou M, 2021, PROC CVPR IEEE, P4905, DOI 10.1109/CVPR46437.2021.00487
   Zhu K, 2021, PROC CVPR IEEE, P6797, DOI 10.1109/CVPR46437.2021.00673
NR 43
TC 9
Z9 9
U1 4
U2 24
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2022
VL 18
IS 2
SU S
AR 126
DI 10.1145/3554737
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7R6FY
UT WOS:000910168000013
DA 2024-07-18
ER

PT J
AU Xu, X
   Yuan, X
   Wang, Z
   Zhang, K
   Hu, RM
AF Xu, Xin
   Yuan, Xin
   Wang, Zheng
   Zhang, Kai
   Hu, Ruimin
TI Rank-in-Rank Loss for Person Re-identification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; metric learning; loss function
ID MULTITARGET TRACKING; NETWORK
AB Person re-identification (re-ID) is commonly investigated as a ranking problem. However, the performance of existing re-ID models drops dramatically, when they encounter extreme positive-negative class imbalance (e.g., very small ratio of positive and negative samples) during training. To alleviate this problem, this article designs a rank-in-rank loss to optimize the distribution of feature embeddings. Specifically, we propose a Differentiable Retrieval-Sort Loss (DRSL) to optimize the re-ID model by ranking each positive sample ahead of the negative samples according to the distance and sorting the positive samples according to the angle (e.g., similarity score). The key idea of the proposed DRSL lies in minimizing the distance between samples of the same category along with the angle between them. Considering that the ranking and sorting operations are non-differentiable and non-convex, the DRSL also performs the optimization of automatic derivation and backpropagation. In addition, the analysis of the proposed DRSL is provided to illustrate that the DRSL not only maintains the inter-class distance distribution but also preserves the intra-class similarity structure in terms of angle constraints. Extensive experimental results indicate that the proposed DRSL can improve the performance of the state-of-the-art re-ID models, thus demonstrating its effectiveness and superiority in the re-ID task.
C1 [Xu, Xin; Yuan, Xin; Zhang, Kai] Wuhan Univ Sci & Technol, Wuhan 430065, Hubei, Peoples R China.
   [Wang, Zheng; Hu, Ruimin] Wuhan Univ, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University
RP Xu, X (corresponding author), Wuhan Univ Sci & Technol, Wuhan 430065, Hubei, Peoples R China.
EM xuxin@wust.edu.cn; xinyuan@wust.edu.cn; wangzwhu@whu.edu.cn;
   zhangkai@wust.edu.cn; hrm1964@163.com
RI Xu, Xin/JRW-5800-2023
OI Hu, Ruimin/0000-0002-5872-3872; Zhang, Kai/0000-0003-0318-3255; Xu,
   Xin/0000-0003-0748-3669; Yuan, Xin/0000-0003-3140-3243
FU National Nature Science Foundation of China [U1803262, 62171325,
   62176191]
FX This work was supported by National Nature Science Foundation of China
   (No. U1803262, 62171325, 62176191).
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2006, P ADV NEUR INF PROC
   [Anonymous], 2007, P IEEE INT WORKSH PE
   Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Benham R, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3345001
   Brown Andrew, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P677, DOI 10.1007/978-3-030-58545-7_39
   Cakir F, 2019, PROC CVPR IEEE, P1861, DOI 10.1109/CVPR.2019.00196
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chapelle Olivier, 2007, P NIPS WORKSHOP MACH
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Chen KA, 2021, IEEE T PATTERN ANAL, V43, P3782, DOI 10.1109/TPAMI.2020.2991457
   Chen KA, 2019, PROC CVPR IEEE, P5114, DOI 10.1109/CVPR.2019.00526
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen Yinpeng, 2021, P IEEE C COMPUTER VI, P5270
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P643, DOI 10.1007/978-3-030-58598-3_38
   Guo JY, 2019, IEEE I CONF COMP VIS, P3641, DOI 10.1109/ICCV.2019.00374
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   He K, 2018, PROC CVPR IEEE, P4023, DOI 10.1109/CVPR.2018.00423
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Kehuang Li, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4503, DOI 10.1109/ICASSP.2014.6854454
   Li HJ, 2021, PROC CVPR IEEE, P6725, DOI 10.1109/CVPR46437.2021.00666
   Li W, 2020, INT J COMPUT VISION, V128, P1635, DOI 10.1007/s11263-019-01274-1
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu Deyin, 2022, ACM Trans. Multimedia Comput., Commun., Appl., V1, P1, DOI 10.1145/3522714
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47
   Oksuz K., 2020, P ADV NEUR INF PROC, V33, P15534
   Oksuz K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2989, DOI 10.1109/ICCV48922.2021.00300
   Oksuz K, 2018, LECT NOTES COMPUT SC, V11211, P521, DOI 10.1007/978-3-030-01234-2_31
   Paszke A, 2019, ADV NEUR IN, V32
   Qin T, 2010, INFORM RETRIEVAL, V13, P375, DOI 10.1007/s10791-009-9124-x
   Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
   Ramachandran RK, 2021, IEEE T CONTROL NETW, V8, P609, DOI 10.1109/TCNS.2021.3059794
   Revaud J, 2019, IEEE I CONF COMP VIS, P5106, DOI 10.1109/ICCV.2019.00521
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Rolinek M., 2020, P IEEE CVF C COMP VI, P7620
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan HC, 2022, IEEE T CIRC SYST VID, V32, P160, DOI 10.1109/TCSVT.2021.3061412
   Ustinova E, 2016, ADV NEUR IN, V29
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P858, DOI 10.1109/TMM.2012.2187181
   Wang XS, 2019, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR.2019.00535
   Wang Z, 2020, Arxiv, DOI arXiv:2011.11506
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu L, 2021, IEEE T NEUR NET LEAR, V32, P722, DOI 10.1109/TNNLS.2020.2979190
   Wu L, 2020, IEEE T CIRC SYST VID, V30, P2081, DOI 10.1109/TCSVT.2019.2909549
   Wu L, 2020, IEEE T IMAGE PROCESS, V29, P1233, DOI 10.1109/TIP.2019.2940684
   Xie Pengyu, 2021, PROC IEEE INT C MULT, P1, DOI 10.1109/ICME51207.2021.9428200
   Xu X, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2021.107827
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yang X, 2020, AAAI CONF ARTIF INTE, V34, P287
   Yang X, 2018, IEEE T IMAGE PROCESS, V27, P791, DOI 10.1109/TIP.2017.2765836
   Yang X, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3089249
   Yang Z, 2021, NEUROCOMPUTING, V455, P255, DOI 10.1016/j.neucom.2021.04.070
   YaoweiWang Yemin, 2018, 2018 IEEE 4 INT C, P1
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yi W, 2020, IEEE T SIGNAL PROCES, V68, P1602, DOI 10.1109/TSP.2020.2976587
   Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12
   Yuan Y, 2020, IEEE COMPUT SOC CONF, P1454, DOI 10.1109/CVPRW50498.2020.00185
   Zhai Y, 2019, IEEE COMPUT SOC CONF, P1526, DOI 10.1109/CVPRW.2019.00194
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao CR, 2020, IEEE T MULTIMEDIA, V22, P3180, DOI 10.1109/TMM.2020.2972125
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou KY, 2022, IEEE T PATTERN ANAL, V44, P5056, DOI 10.1109/TPAMI.2021.3069237
NR 83
TC 9
Z9 9
U1 1
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2022
VL 18
IS 2
SU S
AR 130
DI 10.1145/3532866
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7R6FY
UT WOS:000910168000018
DA 2024-07-18
ER

PT J
AU Li, WX
   Pan, G
   Wang, C
   Xing, Z
   Han, ZJ
AF Li, Wenxu
   Pan, Gang
   Wang, Chen
   Xing, Zhen
   Han, Zhenjun
TI From Coarse to Fine: Hierarchical Structure-aware Video Summarization
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Reinforcement learning; video understanding
AB Hierarchical structure is a common characteristic for some kinds of videos (e.g., sports videos, game videos): The videos are composed of several actions hierarchically and there exist temporal dependencies among segments with different scales, where action labels can be enumerated. Our ideas are based on two observations: First, the actions are the fundamental units for people to understand these videos. Second, the humans summarize a video by iteratively observing and refining, i.e., observing segments in video and hierarchically refining the boundaries of important actions. Based on the above insights, we generate action proposals to construct the structure of the video and formulate the summarization process as a hierarchical refining process. We also train a hierarchical summarization network with deep Q-learning (HQSN) to achieve the refining process and explore temporal dependency. Besides, we collect a new dataset that consists of structured game videos with fine-grain actions and importance annotations. The experimental results demonstrate the effectiveness of the proposed method.
C1 [Li, Wenxu; Pan, Gang; Wang, Chen] Tianjin Univ, Tianjin 300110, Peoples R China.
   [Li, Wenxu] Imperial Coll London, London SW7 2AZ, England.
   [Xing, Zhen] Fudan Univ, Shanghai 200000, Peoples R China.
   [Han, Zhenjun] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Tianjin University; Imperial College London; Fudan University; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Pan, G (corresponding author), Tianjin Univ, Tianjin 300110, Peoples R China.
EM wl1520@ic.ac.uk; pangang@tju.edu.cn; tjuwangchen@tju.edu.cn;
   zxing20@fudan.edu.cn; hanzhj@ucas.ac.cn
RI Sun, Peng/KDO-4243-2024; Li, Shiyu/KHE-1376-2024
FU National cultural and tourism science and technology innovation project
   of China [2021-97]; NVIDIA Corporation
FX This work is supported by the National cultural and tourism science and
   technology innovation project of China (No. 2021-97). We thank the
   support of NVIDIA Corporation for the donation of the GPU used for this
   research.
CR Abualigah L., 2019, Recent Advances in NLP: The Case of Arabic Language, P1
   [Anonymous], 2017, Deep. Learn. Image Process. Appl, DOI DOI 10.48550/ARXIV.1611.03718
   Bettadapura Vinay., 2016, P ACM INT C MULT, P908
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Gao JY, 2018, LECT NOTES COMPUT SC, V11206, P70, DOI 10.1007/978-3-030-01216-8_5
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Gong BQ, 2014, ADV NEUR IN, V27
   GYGLI M, 2015, PROC CVPR IEEE, P3090, DOI DOI 10.1109/CVPR.2015.7298928
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211
   Hessel M, 2018, AAAI CONF ARTIF INTE, P3215
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang YD, 2019, IEEE INT CONF COMP V, P1562, DOI 10.1109/ICCVW.2019.00195
   Karaman S, 2014, ECCV THUMOS Workshop, V1, P5
   King DB, 2015, ACS SYM SER, V1214, P1
   Kulesza A, 2012, FOUND TRENDS MACH LE, V5, P123, DOI 10.1561/2200000044
   Kwon Heeseung, 2019, P IEEE INT C COMP VI, P1
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2822907
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   LiWenxu Pan Gang, 2020, P INT C PATTERN RECO, P1
   Mathe S, 2016, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2016.316
   Merler M, 2019, IEEE T MULTIMEDIA, V21, P1147, DOI 10.1109/TMM.2018.2876046
   Mnih V., 2013, P ADV C NEUR INF PRO, P1
   Otani M, 2019, PROC CVPR IEEE, P7579, DOI 10.1109/CVPR.2019.00778
   Panda R, 2017, IEEE I CONF COMP VIS, P3677, DOI 10.1109/ICCV.2017.395
   Park J, 2019, CONSUM COMM NETWORK, DOI 10.1109/ccnc.2019.8651730
   Paszke A, 2019, ADV NEUR IN, V32
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Ringer Charles., 2018, Proceedings of the 13th International Conference on the Foundations of Digital Games, page, P15
   Rochan M, 2019, PROC CVPR IEEE, P7894, DOI 10.1109/CVPR.2019.00809
   Seong Hongje, 2019, P IEEE INT C COMP VI, P1
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Takahashi N, 2018, IEEE T MULTIMEDIA, V20, P513, DOI 10.1109/TMM.2017.2751969
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Wang L, 2014, IEEE INT CONF VLSI
   Wang X, 2018, PROC CVPR IEEE, P4213, DOI 10.1109/CVPR.2018.00443
   Wang ZY, 2016, PR MACH LEARN RES, V48
   Xu Q, 2012, IEEE T MULTIMEDIA, V14, P844, DOI 10.1109/TMM.2012.2190924
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Yuan J, 2016, PROC CVPR IEEE, P3093, DOI 10.1109/CVPR.2016.337
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
   Zhou Kaiyang, 2018, P BRIT MACHINE VISIO, P1
NR 58
TC 6
Z9 6
U1 0
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2022
VL 18
IS 1
SU S
SI SI
AR 37
DI 10.1145/3485472
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5PV
UT WOS:000772639300014
DA 2024-07-18
ER

PT J
AU Rebelo, ADP
   Inês, GD
   Damion, DEV
AF Peres Rebelo, Ana Daniela
   Ines, Guedes De Oliveira
   Damion, D. E. Verboom
TI The Impact of Artificial Intelligence on the Creativity of Videos
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Creativity; real-time style transfer
AB This study explored the impact Artificial Intelligence (AI) has on the evaluation of creative elements in artistic videos. The aim was to verify to what extent the use of an AI algorithm (Style Transfer) contributes to changes in the perceived creativity of the videos. Creativity was evaluated in six quantitative items (Likert-type scale) and one qualitative question (qualitative description of the creativity expressed in the video by two words or expressions). Six videos were shown to both control (N = 49) and experimental group (N = 52) aiming at determining possible differences in creativity assessment criteria. Furthermore, both groups contained experts (Experimental, N = 27; Control, N = 25) and non-experts (Experimental, N = 25; Control, N = 24). The first round of videos composed of six videos that were the same for both the experimental and control condition (used to check for bias). No significant differences were found. In a second round, six videos were shown with AI transformation (experimental condition) and without that transformation (control group). Results showed that in two cases the perceived creativity increased in experimental condition, in one case a decrease occurred. In most evaluations no differences were observed. Qualitative evaluations reinforce the absence of a general pattern of improvements in AI transformations. Altogether, the results emphasize the importance of human mediation in the application of AI in creative production: a hybrid approach, or rather, Hybrid Intelligence.
C1 [Peres Rebelo, Ana Daniela; Ines, Guedes De Oliveira] Univ Aveiro, P-3810193 Aveiro, Portugal.
   [Damion, D. E. Verboom] Univ Utrecht, Heidelberglaan 8, NL-3584 CS Utrecht, Netherlands.
C3 Universidade de Aveiro; Utrecht University
RP Rebelo, ADP (corresponding author), Univ Aveiro, P-3810193 Aveiro, Portugal.
EM anadanielaperesrebelo@gmail.com; ines.guedes@ua.pt;
   d.e.verboom@hotmail.com
OI Verboom, Damion Evert/0000-0002-0157-7288; Rebelo, Ana
   Daniela/0000-0002-4080-9408
CR Arcas BAY, 2017, ARTS, V6, DOI 10.3390/arts6040018
   AMABILE TM, 1982, J PERS SOC PSYCHOL, V43, P997, DOI 10.1037/0022-3514.43.5.997
   [Anonymous], 2012, Computer vision: models, learning, and inference
   Armstrong RA, 2014, OPHTHAL PHYSL OPT, V34, P502, DOI 10.1111/opo.12131
   Audry S, 2019, ARTS, V8, DOI 10.3390/arts8010035
   Avdeeff M, 2019, ARTS, V8, DOI 10.3390/arts8040130
   Barbosa Nuno, 2020, VIDEO
   Basalla Marcus, 2020, ARXIV201202282
   Bishop Phillip A, 2015, Int J Exerc Sci, V8, P297
   Boden MA, 2009, AI MAG, V30, P23, DOI 10.1609/aimag.v30i3.2254
   Chen LQ, 2019, J VIS COMMUN IMAGE R, V61, P10, DOI 10.1016/j.jvcir.2019.02.009
   Cohen Harold, 2010, LECTURE
   Cropley Arthur J., 2016, QUALITATIVE RES METH
   de Winter J. F. C., 2010, PRACT ASSESS RES EVA, V15, P11, DOI DOI 10.7275/BJ1P-TS64
   Dellermann D, 2019, BUS INFORM SYST ENG+, V61, P637, DOI 10.1007/s12599-019-00595-2
   Dolese Melissa J., 2015, THESIS
   Elgammal A., 2017, ARXIV170607068
   Ellis P., 2014, Wounds UK, V10, P118
   Frigotto ML, 2011, SCIENTOMETRICS, V89, P397, DOI 10.1007/s11192-011-0431-9
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Henriksen D, 2014, TECHTRENDS, V58, P15, DOI 10.1007/s11528-013-0713-6
   Hong JW, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3326337
   IBM, 2020, MACHINE LEARNING 202
   Jin Cheng-Bin, 2018, REAL TIME STYLE TRAN
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Kok J. N., 2009, ARTIF INTELL
   Leech NL, 2009, QUAL QUANT, V43, P265, DOI 10.1007/s11135-007-9105-3
   Lomas A, 2018, ARTS, V7, DOI 10.3390/arts7030025
   Malina MA, 2011, QUAL RES ACCOUNT MAN, V8, P59, DOI 10.1108/11766091111124702
   Mazzone M, 2019, ARTS, V8, DOI 10.3390/arts8010026
   Natarajan B., 1991, Machine Learning: A Theoretical Approach
   Onwuegbuzie A.J., 2005, International Journal of Social Research Methodology, V8, P375, DOI [DOI 10.1080/13645570500402447, 10.1080/13645570500402447]
   Ornes S, 2019, P NATL ACAD SCI USA, V116, P4760, DOI 10.1073/pnas.1900883116
   OSBORNE H, 1982, J AESTHET ART CRITIC, V41, P19, DOI 10.2307/430820
   Park Y, 2019, AM J ART MEDIA STUD, V20, P113, DOI 10.25038/am.v0i20.332
   Ray SK, 2019, APPL ARTIF INTELL, V33, P979, DOI 10.1080/08839514.2019.1661576
   Runco MA, 2012, CREATIVITY RES J, V24, P92, DOI 10.1080/10400419.2012.650092
   Sarkar P., 2015, International Journal of Design Sciences and Technology, V21, P7
   Shalev-Shwartz S., 2014, UNDERSTANDING MACHIN
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Taylor S., 2017, OPEN J SOCIAL SCI, V5, P128, DOI [10.4236/jss.2017.511010, 10.4236/jss.2017.511010,05, DOI 10.4236/JSS.2017.511010]
   Walia C, 2019, CREATIVITY RES J, V31, P237, DOI 10.1080/10400419.2019.1641787
   Yingxu Wang, 2009, International Journal of Software Science and Computational Intelligence, V1, P1, DOI 10.4018/jssci.2009010101
NR 43
TC 3
Z9 3
U1 14
U2 54
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2022
VL 18
IS 1
AR 9
DI 10.1145/3462634
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5OX
UT WOS:000772636900009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, ZT
   Xie, Q
   Wei, MQ
   Long, K
   Wang, J
AF Wang, Zhoutao
   Xie, Qian
   Wei, Mingqiang
   Long, Kun
   Wang, Jun
TI Multi-feature Fusion VoteNet for 3D Object Detection
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Images; point cloud; 3D object detection; multi-feature fusion;
   occlusion
ID POINT-CLOUD; RECONSTRUCTION
AB In this article, we propose a Multi-feature Fusion VoteNet (MFFVoteNet) framework for improving the 3D object detection performance in cluttered and heavily occluded scenes. Our method takes the point cloud and the synchronized RGB image as inputs to provide object detection results in 3D space. Our detection architecture is built on VoteNet with three key designs. First, we augment the VoteNet input with point color information to enhance the difference of various instances in a scene. Next, we integrate an image feature module into the VoteNet to provide a strong object class signal that can facilitate deterministic detections in occlusion. Moreover, we propose a Projection Non-Maximum Suppression (PNMS) method in 3D object detection to eliminate redundant proposals and hence provide more accurate positioning of 3D objects. We evaluate the proposed MFFVoteNet on two challenging 3D object detection datasets, i.e., ScanNetv2 and SUN RGB-D. Extensive experiments show that our framework can effectively improve the performance of 3D object detection.
C1 [Wang, Zhoutao; Wei, Mingqiang] Nanjing Univ Aeronaut & Astronaut, 29 Jiangjun Ave, Nanjing 211100, Jiangsu, Peoples R China.
   [Xie, Qian; Long, Kun; Wang, Jun] Nanjing Univ Aeronaut & Astronaut, 29 Yudao St, Nanjing 210016, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of
   Aeronautics & Astronautics
RP Wang, J (corresponding author), Nanjing Univ Aeronaut & Astronaut, 29 Yudao St, Nanjing 210016, Jiangsu, Peoples R China.
EM wangzhoutao@nuaa.edu.cn; qianxie@nuaa.edu.cn; mingqiang.wei@gmail.com;
   kunlong@nuaa.edu.cn; wjun@nuaa.edu.cn
FU National Key Research and Development Program of China [2019YFB1707503];
   Aeronautical Science Foundation of China [2019ZE052008]; National
   Natural Science Foundation of China [61772267]; Natural Science
   Foundation of Jiangsu Province [BK20190016]
FX This work is supported in part by the National Key Research and
   Development Program of China 2019YFB1707503, Aeronautical Science
   Foundation of China under Grant 2019ZE052008, National Natural Science
   Foundation of China under Grant 61772267, and the Natural Science
   Foundation of Jiangsu Province under Grant BK20190016.
CR [Anonymous], 2016, SEQ NMS VIDEO OBJECT
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Chen JT, 2020, PROC CVPR IEEE, P389, DOI 10.1109/CVPR42600.2020.00047
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Chen XZ, 2015, ADV NEUR IN, V28
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Drost B, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P9, DOI 10.1109/3DIMPVT.2012.53
   Espinace P, 2010, IEEE INT CONF ROBOT, P1406, DOI 10.1109/ROBOT.2010.5509682
   Georgakis G., 2017, ARXIV170207836
   Gevaert CM, 2017, ISPRS J PHOTOGRAMM, V125, P225, DOI 10.1016/j.isprsjprs.2017.01.017
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hou J, 2019, PROC CVPR IEEE, P4416, DOI 10.1109/CVPR.2019.00455
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ji HW, 2019, ENVIRON EARTH SCI, V78, DOI 10.1007/s12665-019-8516-5
   Lahoud J, 2017, IEEE I CONF COMP VIS, P4632, DOI 10.1109/ICCV.2017.495
   Li B, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII
   Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu WP, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194188
   Mauri A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020532
   Meynet G, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123147
   Pang G, 2016, INT C PATT RECOG, P585, DOI 10.1109/ICPR.2016.7899697
   Park J, 2017, IEEE I CONF COMP VIS, P143, DOI 10.1109/ICCV.2017.25
   Paszke A, 2019, ADV NEUR IN, V32
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2020, PROC CVPR IEEE, P4403, DOI 10.1109/CVPR42600.2020.00446
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren Z, 2016, PROC CVPR IEEE, P1525, DOI 10.1109/CVPR.2016.169
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Wang J, 2013, COMPUT GRAPH FORUM, V32, P164, DOI 10.1111/cgf.12006
   Wang J, 2016, COMPUT AIDED GEOM D, V43, P82, DOI 10.1016/j.cagd.2016.02.012
   Wang J, 2014, COMPUT AIDED DESIGN, V50, P27, DOI 10.1016/j.cad.2014.01.003
   Wang J, 2013, COMPUT GRAPH FORUM, V32, P207, DOI 10.1111/cgf.12187
   Wang J, 2012, COMPUT IND ENG, V63, P1189, DOI 10.1016/j.cie.2012.07.009
   Wengefeld T., 2019, 2019 European Conference on Mobile Robots (ECMR), P1
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
   Xie Q, 2018, IEEE T MULTIMEDIA, V20, P580, DOI 10.1109/TMM.2017.2751965
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yi C, 2017, COMPUT AIDED DESIGN, V93, P1, DOI 10.1016/j.cad.2017.07.005
   Yi L, 2019, PROC CVPR IEEE, P3942, DOI 10.1109/CVPR.2019.00407
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Zhang J, 2013, COMPUT GRAPH-UK, V37, P697, DOI 10.1016/j.cag.2013.05.008
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 55
TC 6
Z9 6
U1 8
U2 68
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2022
VL 18
IS 1
AR 6
DI 10.1145/3462219
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5OX
UT WOS:000772636900006
DA 2024-07-18
ER

PT J
AU Wang, J
   Tian, KB
   Ding, DY
   Yang, G
   Li, XR
AF Wang, Jie
   Tian, Kaibin
   Ding, Dayong
   Yang, Gang
   Li, Xirong
TI Unsupervised Domain Expansion for Visual Categorization
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Visual categorization; domain expansion; classifier generalization
AB Expanding visual categorization into a novel domain without the need of extra annotation has been a long-term interest for multimedia intelligence. Previously, this challenge has been approached by unsupervised domain adaptation (UDA). Given labeled data from a source domain and unlabeled data from a target domain, UDA seeks for a deep representation that is both discriminative and domain-invariant. While UDA focuses on the target domain, we argue that the performance on both source and target domains matters, as in practice which domain a test example comes from is unknown. In this article, we extend UDA by proposing a new task called unsupervised domain expansion (UDE), which aims to adapt a deep model for the target domain with its unlabeled data, meanwhile maintaining the model's performance on the source domain. We propose Knowledge Distillation Domain Expansion (KDDE) as a general method for the UDE task. Its domain-adaptation module can be instantiated with any existing model. We develop a knowledge distillation-based learning mechanism, enabling KDDE to optimize a single objective where in the source and target domains are equally treated. Extensive experiments on two major benchmarks, i.e., Office-Home and DomainNet, show that KDDE compares favorably against four competitive baselines, i.e., DDC, DANN, DAAN, and CDAN, for both UDA and UDE tasks. Our study also reveals that the current UDA models improve their performance on the target domain at the cost of noticeable performance loss on the source domain.
C1 [Wang, Jie; Tian, Kaibin; Li, Xirong] Renmin Univ China, Key Lab DEKE, Beijing 100872, Peoples R China.
   [Ding, Dayong] Visionary Intelligence Ltd Beijing, Vistel AI Lab, Beijing 100872, Peoples R China.
   [Yang, Gang] Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.
C3 Renmin University of China; Renmin University of China
RP Li, XR (corresponding author), Renmin Univ China, Key Lab DEKE, Beijing 100872, Peoples R China.
EM jie.wang@ruc.edu.cn; tikibi@ruc.edu.cn; dayong.ding@vistel.cn;
   yanggang@ruc.edu.cn; xirong@ruc.edu.cn
RI Li, Xirong/AAD-3347-2019
OI Li, Xirong/0000-0002-0220-8310
FU National Natural Science Foundation of China [62172420, 61672523];
   Beijing Natural Science Foundation [4202033]; Fundamental Research Funds
   for the Central Universities; Research Funds of Renmin University of
   China [18XNLG19]; Pharmaceutical Collaborative Innovation Research
   Project of Beijing Science and Technology Commission [Z191100007719002]
FX This research was supported in part by National Natural Science
   Foundation of China (Grant No. 62172420, 61672523), Beijing Natural
   Science Foundation (Grant No. 4202033), the Fundamental Research Funds
   for the Central Universities and the Research Funds of Renmin University
   of China (Grant No. 18XNLG19), and the Pharmaceutical Collaborative
   Innovation Research Project of Beijing Science and Technology Commission
   (Grant No. Z191100007719002).
CR Asami T, 2017, INT CONF ACOUST SPEE, P5185, DOI 10.1109/ICASSP.2017.7953145
   Ben-David S., 2007, NIPS, P137
   Chen GB, 2017, ADV NEUR IN, V30
   De Fauw J, 2018, NAT MED, V24, P1342, DOI 10.1038/s41591-018-0107-6
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Ganin Y, 2016, J MACH LEARN RES, V17
   Goldblum M, 2020, AAAI CONF ARTIF INTE, V34, P3996
   Hinton G., 2015, COMPUT SCI, V2
   Jiang W, 2008, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2008.4711716
   Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Li S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P729, DOI 10.1145/3343031.3351070
   Liu Xiaofeng, 2019, P ICCV
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long Mingsheng, 2017, P ICML
   Mackiewicz Michal, 2018, P ICLR
   Meng Z, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P268, DOI [10.1109/asru46091.2019.9003776, 10.1109/ASRU46091.2019.9003776]
   Meng Z, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5949, DOI 10.1109/ICASSP.2018.8461682
   Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191
   Paszke A, 2019, ADV NEUR IN, V32
   Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149
   Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835
   Romero A., 2015, ICLR, P1, DOI DOI 10.48550/ARXIV.1412.6550
   Saito K, 2019, IEEE I CONF COMP VIS, P8049, DOI 10.1109/ICCV.2019.00814
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Saputra Muhamad Risqi U., 2019, P ICCV
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shi YY, 2019, INT CONF ACOUST SPEE, P7230, DOI 10.1109/ICASSP.2019.8683533
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tian Yonglong, 2019, INT C LEARN REPR
   Toldo M, 2020, TECHNOLOGIES, V8, DOI 10.3390/technologies8020035
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Wang Ximei, 2019, P NEURIPS
   Wang Ximei, 2019, P 3 AAAI C ART INT 3
   WeisenWang Zhiyan Xu, 2019, P MICCAI
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Yu CH, 2019, IEEE DATA MINING, P778, DOI 10.1109/ICDM.2019.00088
   Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381
   Zhang P, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P512, DOI 10.1145/3343031.3351089
   Zhang QS, 2018, AAAI CONF ARTIF INTE, P4464
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 47
TC 3
Z9 4
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2021
VL 17
IS 4
AR 121
DI 10.1145/3448108
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP8GI
UT WOS:000748857800005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, B
   Zhang, R
   Bisagno, N
   Conci, N
   De Natale, FGB
   Liu, HB
AF Zhang, Bo
   Zhang, Rui
   Bisagno, Niccolo
   Conci, Nicola
   De Natale, Francesco G. B.
   Liu, Hongbo
TI Where Are They Going? Predicting Human Behaviors in Crowded Scenes
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Crowd analysis; behavior prediction; attention mechanism; multimodality
   modeling; pedestrian grouping
ID ATTENTION
AB In this article, we propose a framework for crowd behavior prediction in complicated scenarios. The fundamental framework is designed using the standard encoder-decoder scheme, which is built upon the long short-term memory module to capture the temporal evolution of crowd behaviors. To model interactions among humans and environments, we embed both the social and the physical attention mechanisms into the long short-term memory. The social attention component can model the interactions among different pedestrians, whereas the physical attention component helps to understand the spatial configurations of the scene. Since pedestrians' behaviors demonstrate multi-modal properties, we use the generative model to produce multiple acceptable future paths. The proposed framework not only predicts an individual's trajectory accurately but also forecasts the ongoing group behaviors by leveraging on the coherent filtering approach. Experiments are carried out on the standard crowd benchmarks (namely, the ETH, the UCY, the CUHK crowd, and the CrowdFlow datasets), which demonstrate that the proposed framework is effective in forecasting crowd behaviors in complex scenarios.
C1 [Zhang, Bo; Zhang, Rui; Liu, Hongbo] Dalian Maritime Univ, 1 Linghai Rd, Dalian 116026, Peoples R China.
   [Bisagno, Niccolo; Conci, Nicola; De Natale, Francesco G. B.] Univ Trento, DISI, Via Sommarive 5, I-38123 Trento, Italy.
C3 Dalian Maritime University; University of Trento
RP Liu, HB (corresponding author), Dalian Maritime Univ, 1 Linghai Rd, Dalian 116026, Peoples R China.
EM bzhang@dlmu.edu.cn; zhangrui@dlmu.edu.cn; niccolo.bisagno@unitn.it;
   nicola.conci@unitn.it; francesco.denatale@unitn.it; lhb@dlmu.edu.cn
RI Liu, Hongbo/KIK-1780-2024
OI Liu, Hongbo/0000-0001-9296-9975; Conci, Nicola/0000-0002-7858-0928;
   zhang, bo/0000-0002-9006-1303
FU National Natural Science Foundation of China [61772102]; China
   Postdoctoral Science Foundation [2019M661079]; Liaoning Collaborative
   Fund [2020-HYLH-17]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61702073), the China Postdoctoral Science Foundation
   (Grant No. 2019M661079), the National Natural Science Foundation of
   China (Grant No. 61772102), and the Liaoning Collaborative Fund (Grant
   No. 2020-HYLH-17).
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Alahi A, 2014, PROC CVPR IEEE, P2211, DOI 10.1109/CVPR.2014.283
   Ali S, 2007, PROC CVPR IEEE, P65
   Allain Pierre, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P279
   [Anonymous], 2018, ARXIV180601482
   Bagautdinov T, 2017, PROC CVPR IEEE, P3425, DOI 10.1109/CVPR.2017.365
   Ballan L, 2016, LECT NOTES COMPUT SC, V9905, P697, DOI 10.1007/978-3-319-46448-0_42
   Bartoli F, 2018, INT C PATT RECOG, P1941, DOI 10.1109/ICPR.2018.8545447
   Fernando T, 2018, NEURAL NETWORKS, V108, P466, DOI 10.1016/j.neunet.2018.09.002
   Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176
   Grant JM, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3052930
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15
   Kok VJ, 2016, NEUROCOMPUTING, V177, P342, DOI 10.1016/j.neucom.2015.11.021
   Lawal IA, 2017, IEEE T CIRC SYST VID, V27, P2395, DOI 10.1109/TCSVT.2016.2580401
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Ma WC, 2017, PROC CVPR IEEE, P4636, DOI 10.1109/CVPR.2017.493
   Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64
   Robicquet A., 2016, ARXIV160100998
   Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33
   Rudenko A, 2020, INT J ROBOT RES, V39, P895, DOI 10.1177/0278364920917446
   Schröder G, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P7
   Shao J, 2017, IEEE T CIRC SYST VID, V27, P1290, DOI 10.1109/TCSVT.2016.2539878
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Vemula A, 2018, IEEE INT CONF ROBOT, P4601
   Wang H, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P49, DOI 10.1145/2856400.2856410
   Yi S, 2016, LECT NOTES COMPUT SC, V9905, P263, DOI 10.1007/978-3-319-46448-0_16
   Yi S, 2015, PROC CVPR IEEE, P3488, DOI 10.1109/CVPR.2015.7298971
   Zhong JH, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P801
   Zhou BL, 2015, INT J COMPUT VISION, V111, P50, DOI 10.1007/s11263-014-0735-3
   Zhou BL, 2012, LECT NOTES COMPUT SC, V7573, P857, DOI 10.1007/978-3-642-33709-3_61
NR 37
TC 8
Z9 8
U1 2
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2021
VL 17
IS 4
AR 123
DI 10.1145/3449359
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP8GI
UT WOS:000748857800007
DA 2024-07-18
ER

PT J
AU Su, G
   Lin, B
   Luo, W
   Yin, JW
   Deng, SG
   Gao, HH
   Xu, RJ
AF Su, Ge
   Lin, Bo
   Luo, Wei
   Yin, Jianwei
   Deng, Shuiguang
   Gao, Honghao
   Xu, Renjun
TI Hypomimia Recognition in Parkinson's Disease With Semantic Features
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Hypomimia detection; semantic features; visualized analysis
AB Parkinson's disease is the second most common neurodegenerative disorder, commonly affecting elderly people over the age of 65. As the cardinal manifestation, hypomimia, referred to as impairments in normal facial expressions, stays covert. Even some experienced doctors may miss these subtle changes, especially in a mild stage of this disease. The existing methods for hypomimia recognition are mainly dominated by statistical variable-based methods with the help of traditional machine learning algorithms. Despite the success of recognizing hypomimia, they show a limited accuracy and lack the capability of performing semantic analysis. Therefore, developing a computer-aided diagnostic method for semantically recognizing hypomimia is appealing. In this article, we propose a Semantic Feature based Hypomimia Recognition network, named SFHR-NET, to recognize hypomimia based on facial videos. First, a Semantic Feature Classifier (SF-C) is proposed to adaptively adjust feature maps salient to hypomimia, which leads the encoder and classifier to focus more on areas of hypomimia-interest. In SF-C, the progressive confidence strategy (PCS) ensures more reliable semantic features. Then, a two-stream framework is introduced to fuse the spatial data stream and temporal optical stream, which allows the encoder to semantically and progressively characterize the rigid process of hypomimia. Finally, to improve the interpretability of the model, Gradient-weighted Class Activation Mapping (Grad-CAM) is integrated to generate attention maps that cast our engineered features into hypomimia-interest regions. These highlighted regions provide visual explanations for decisions of our network. Experimental results based on real-world data demonstrate the effectiveness of our method in detecting hypomimia.
C1 [Su, Ge; Lin, Bo; Yin, Jianwei; Deng, Shuiguang] Zhejiang Univ, Coll Comp Sci, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
   [Luo, Wei] Zhejiang Univ, Affiliated Hosp 2, Sch Med, Hangzhou, Peoples R China.
   [Gao, Honghao] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Xu, Renjun] Zhejiang Univ, Ctr Data Sci, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University; Shanghai University; Zhejiang
   University
RP Su, G (corresponding author), Zhejiang Univ, Coll Comp Sci, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM suge@zju.edu.cn; rainbowlin@zju.edu.cn; luoweirock@zju.edu.cn;
   zjuyjw@cs.zju.edu.cn; dengsg@zju.edu.cn; gaohonghao@shu.edu.cn;
   rux@zju.edu.cn
RI Gao, Honghao/AAX-4529-2020
OI Gao, Honghao/0000-0001-6861-9684; Xu, Renjun/0000-0002-7566-7948; Su,
   Ge/0000-0003-0326-889X
FU National Key Research and Development Program of China [2017YFB1400603];
   National Natural Science Foundation of China [61825205, 61772459];
   National Science and Technology Major Project of China
   [50-D36B02-9002-16/19]
FX This research was supported by National Key Research and Development
   Program of China (No. 2017YFB1400603), National Natural Science
   Foundation of China under Grant (No. 61825205, No. 61772459) and
   National Science and Technology Major Project of China (No.
   50-D36B02-9002-16/19).
CR Argaud S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160329
   Bandini A, 2017, J NEUROSCI METH, V281, P7, DOI 10.1016/j.jneumeth.2017.02.006
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x
   Bologna M, 2013, J NEUROL NEUROSUR PS, V84, P681, DOI 10.1136/jnnp-2012-303993
   Capecci M, 2019, IEEE ICCE, P20, DOI 10.1109/ICCE-Berlin47944.2019.8966224
   Dauer W, 2003, NEURON, V39, P889, DOI 10.1016/S0896-6273(03)00568-3
   Du L, 2019, IEEE I CONF COMP VIS, P982, DOI 10.1109/ICCV.2019.00107
   Goetz CG, 2007, MOVEMENT DISORD, V22, P41, DOI 10.1002/mds.21198
   Grammatikopoulou A., 2019, 12 ACM INT C PERVASI, P517, DOI DOI 10.1145/3316782.3322756
   Gray HA, 2010, NEUROPSYCHOLOGY, V24, P176, DOI 10.1037/a0018104
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ho MWR, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61310-w
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jakab T., 2020, IEEECVF C COMPUTER V, P8787
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jin B, 2020, J MED INTERNET RES, V22, DOI 10.2196/18697
   Lilly ML, 2021, J AM ASSOC NURSE PRA, V33, P676, DOI 10.1097/JXX.0000000000000471
   Luo XF, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3381086
   Mahendran A, 2016, INT J COMPUT VISION, V120, P233, DOI 10.1007/s11263-016-0911-8
   Fernandez PDM, 2019, IEEE COMPUT SOC CONF, P837, DOI 10.1109/CVPRW.2019.00112
   Miao Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3311747
   Mullin S, 2015, NEUROL CLIN, V33, P1, DOI 10.1016/j.ncl.2014.09.010
   Noori FM, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377882
   Pepa L, 2019, 2019 IEEE 23RD INTERNATIONAL SYMPOSIUM ON CONSUMER TECHNOLOGIES (ISCT), P23, DOI [10.1109/isce.2019.8901033, 10.1109/ISCE.2019.8901033]
   Rajnoha M., 2018, 2018 10 INT C ULTRA, P1, DOI DOI 10.1109/ICUMT.2018.8631249
   Raza C, 2019, LIFE SCI, V226, P77, DOI 10.1016/j.lfs.2019.03.057
   Ricciardi L, 2020, EUR J NEUROL, V27, P2422, DOI 10.1111/ene.14452
   Ricciardi L, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169110
   Ricciardi L, 2016, NEUROL SCI, V37, P431, DOI 10.1007/s10072-015-2421-9
   Sariyanidi E, 2020, PROC CVPR IEEE, P7171, DOI [10.1109/CVPR42600.2020.00720, 10.1109/cvpr42600.2020.00720]
   Seliverstov Y, 2018, NEUROLOGY, V90
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Simonyan K., 2014, 14091556 ARXIV
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Ventura MI, 2012, NEUROPSYCHOLOGIA, V50, P1936, DOI 10.1016/j.neuropsychologia.2012.04.018
   Vinokurov N, 2016, COMM COM INF SC, V604, P63, DOI 10.1007/978-3-319-32270-4_7
   Wood A, 2016, PSYCHON B REV, V23, P1150, DOI 10.3758/s13423-015-0974-5
   Yan R, 2023, IEEE T PATTERN ANAL, V45, P6955, DOI 10.1109/TPAMI.2020.3034233
   Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 42
TC 3
Z9 3
U1 4
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2021
VL 17
IS 3
SU S
SI SI
AR 106
DI 10.1145/3476778
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA YA4BM
UT WOS:000738280600008
DA 2024-07-18
ER

PT J
AU Zhao, MQ
   Zheng, JM
   Liu, ES
AF Zhao, Meiqi
   Zheng, Jianmin
   Liu, Elvis S.
TI Server Allocation for Massively Multiplayer Online Cloud Games Using
   Evolutionary Optimization
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Cloud gaming; MMOG; server allocation; optimization; genetic algorithm
ID ARCHITECTURE; DEMAND
AB In recent years, Massively Multiplayer Online Games (MMOGs) are becoming popular, partially due to their sophisticated graphics and broad virtual world, and cloud gaming is demanded more than ever especially when entertaining with light and portable devices. This article considers the problem of server allocation for running MMOG on cloud, aiming to reduce the cost on cloud gaming service and meanwhile enhance the quality of service. The problem is formulated into minimizing an objective function involving the cost of server rental, the cost of data transfer and the network latency during the gaming time. A genetic algorithm is developed to solve the minimization problem for processing simultaneous server allocation for the players who log into the system at the same time while many existing players are playing the same game. Extensive experiments based on the player behavior in "World of Warcraft" are conducted to evaluate the proposed method and compare with the state-of-the-art as well. The experimental results show that the method gives a lower cost and a shorter network latency in most of the time.
C1 [Zhao, Meiqi; Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Liu, Elvis S.] Tencent, Interact Entertainment Grp, Shenzhen, Peoples R China.
C3 Nanyang Technological University; Tencent
RP Zhao, MQ (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
EM ZH0010QI@e.ntu.edu.sg; asjmzheng@ntu.edu.sg; elvissyliu@tencent.com
RI Zheng, Jianmin/A-3717-2011
OI Zheng, Jianmin/0000-0002-5062-6226
FU Ministry of Education, Singapore [2017-T2-1-076]
FX This work is partially supported by the Ministry of Education,
   Singapore, under its MoE Tier-2 Grant (2017-T2-1-076). Authors'
   addresses: M. Zhao and J. Zheng, School of Computer Science &
   Engineering, Nanyang Technological University, Singapore; emails:
   ZH0010QI@e.ntu.edu.sg,asjmzheng@ntu.edu.sg;E.S.Liu, Interactive
   Entertainment Group, Tencent; email: elvissyliu@tencent.com.
CR Amiri M, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2983639
   [Anonymous], 2013, PROC 12 ANN WORKSHOP
   [Anonymous], 1996, INTRO GENETIC ALGORI
   [Anonymous], 2014, P 13 ANN WORKSH NETW
   [Anonymous], 2014, STANDISH GROUP REPOR
   Brun O., 2006, P INT C NETW INT C S
   Calcavecchia N. M., 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P852, DOI 10.1109/CLOUD.2012.113
   Chen DY, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3336498
   Chen KT, 2006, COMMUN ACM, V49, P34, DOI 10.1145/1167838.1167859
   Chen YC, 2016, IEEE INT CONF CLOUD, P702, DOI [10.1109/CLOUD.2016.96, 10.1109/CLOUD.2016.0098]
   Choy S, 2014, MULTIMEDIA SYST, V20, P503, DOI 10.1007/s00530-014-0367-z
   Choy S, 2012, ANN WORK NETW
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Deng YH, 2018, IEEE T MULTIMEDIA, V20, P1233, DOI 10.1109/TMM.2017.2760621
   Deng Yunhua, 2016, P 24 ACM INT C MULT, P918
   Gao YQ, 2019, IEEE ACCESS, V7, P142574, DOI 10.1109/ACCESS.2019.2944405
   Hong HJ, 2015, IEEE T CLOUD COMPUT, V3, P42, DOI 10.1109/TCC.2014.2338295
   Huang CY, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2537855
   International Diabetes Federation, 2019, IDF Diabetes Atlas, Vninth
   Jarschel M., 2011, Proceedings of the 2011 Fifth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS), P330, DOI 10.1109/IMIS.2011.92
   Jarschel M, 2013, MATH COMPUT MODEL, V57, P2883, DOI 10.1016/j.mcm.2011.12.014
   Lee Yeng-Ting, 2011, WORLD WARCRAFT AVATA, P123
   Li FWB, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000493
   Li X, 2014, IEEE INFOCOM SER, P1842, DOI 10.1109/INFOCOM.2014.6848123
   Li YS, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3190838
   Li YS, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P805, DOI 10.1145/2733373.2807978
   Li YS, 2015, IEEE T CIRC SYST VID, V25, P2052, DOI 10.1109/TCSVT.2015.2450152
   Liao XF, 2016, IEEE ACM T NETWORK, V24, P2128, DOI 10.1109/TNET.2015.2450254
   Marzolla M, 2012, COMPUT ENTERTAIN, V10, DOI 10.1145/2381876.2381880
   Meng XQ, 2010, IEEE INFOCOM SER
   Qi ZW, 2014, ACM T ARCHIT CODE OP, V11, P61, DOI 10.1145/2632216
   Ries M, 2008, INT CONF SYST SIGNAL, P181, DOI 10.1109/IWSSIP.2008.4604397
   Ross PE, 2009, IEEE SPECTRUM, V46, P14, DOI 10.1109/MSPEC.2009.4795441
   Sadeghi J, 2014, INFORM SCIENCES, V272, P126, DOI 10.1016/j.ins.2014.02.075
   Saldana Jose, 2015, QOE LATENCY ISSUES N, DOI [10.1007/978-981-4560-52-8_23-1, DOI 10.1007/978-981-4560-52-8_23-1]
   Shea R., 2015, P 6 ACM MULT SYST C, P97
   Shea R, 2013, IEEE NETWORK, V27, P16, DOI 10.1109/MNET.2013.6574660
   Slivar I, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3132041
   Süselbeck R, 2009, ANN WORK NETW
   Tian H, 2015, IEEE T CIRC SYST VID, V25, P2064, DOI 10.1109/TCSVT.2015.2416563
   Wu JY, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152116
   Zhao Meiqi, 2018, P ANN INT C COMP GAM, P63
   Zhao Z., 2012, Proceedings of the 3rd Workshop on Scientific Cloud Computing Date. ScienceCloud '12, P23
NR 43
TC 2
Z9 2
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2021
VL 17
IS 2
AR 51
DI 10.1145/3433027
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SR4UU
UT WOS:000661037000014
DA 2024-07-18
ER

PT J
AU Lu, HM
   Yang, R
   Deng, ZR
   Zhang, YL
   Gao, GW
   Lan, RS
AF Lu, Huimin
   Yang, Rui
   Deng, Zhenrong
   Zhang, Yonglin
   Gao, Guangwei
   Lan, Rushi
TI Chinese Image Captioning via Fuzzy Attention-based DenseNet-BiLSTM
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image captioning; fuzzy attention; DenseNet; BiLSTM
ID MODELS
AB Chinese image description generation tasks usually have some challenges, such as single-feature extraction, lack of global information, and lack of detailed description of the image content. To address these limitations, we propose a fuzzy attention-based DenseNet-BiLSTM Chinese image captioning method in this article. In the proposed method, we first improve the densely connected network to extract features of the image at different scales and to enhance the model's ability to capture the weak features. At the same time, a bidirectional LSTM is used as the decoder to enhance the use of context information. The introduction of an improved fuzzy attention mechanism effectively improves the problem of correspondence between image features and contextual information. We conduct experiments on the AI Challenger dataset to evaluate the performance of the model. The results show that compared with other models, our proposed model achieves higher scores in objective quantitative evaluation indicators, including BLEU@1, BLEU@4, METEOR, ROUGEl, and CIDEr. The generated description sentence can accurately express the image content.
C1 [Lu, Huimin; Yang, Rui; Deng, Zhenrong; Zhang, Yonglin; Lan, Rushi] Guilin Univ Elect Technol, Guangxi Key Lab Image & Graph Intelligent Proc, 1 Jinji Rd, Guilin, Peoples R China.
   [Lu, Huimin] Kyushu Inst Technol, Dept Mech & Control Engn, Kitakyushu, Fukuoka, Japan.
   [Gao, Guangwei] Nanjing Univ Posts & Telecommun, Inst Adv Technol, 9 Wenyuan Rd, Nanjing, Peoples R China.
   [Lan, Rushi] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
C3 Guilin University of Electronic Technology; Kyushu Institute of
   Technology; Nanjing University of Posts & Telecommunications; South
   China University of Technology
RP Lan, RS (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Image & Graph Intelligent Proc, 1 Jinji Rd, Guilin, Peoples R China.; Lan, RS (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
EM dr.huimin.lu@ieee.org; 792481404@qq.com; 799349175@qq.com;
   14523886271@qq.com; csgwgao@njupt.edu.cn; rslan@guet.edu.cn
RI Zhang, Yonglin/ABC-3973-2021
OI Lan, Rushi/0000-0002-9488-8236
FU National Key R&D Program of China [2018AAA0100300]; National Natural
   Science Foundation of China [U1701267, 61772149, 61936002]; Guangxi
   Science and Technology Project [ZY20198016, AB20238013,
   2019GXNSFFA245014, AD18216004, AD18281079]; Guangxi Key Laboratory of
   Image and Graphic Intelligent Processing [GIIP2003]; GUET Excellent
   Graduate Thesis Program [18YJPYSS15]
FX This work was partially supported by the National Key R&D Program of
   China (No. 2018AAA0100300), National Natural Science Foundation of China
   (Grants No. U1701267, No. 61772149, and No. 61936002), Guangxi Science
   and Technology Project (Grants No. ZY20198016, No. AB20238013, No.
   2019GXNSFFA245014, No. AD18216004, and No. AD18281079), Guangxi Key
   Laboratory of Image and Graphic Intelligent Processing (GIIP2003), and
   GUET Excellent Graduate Thesis Program (Grant No. 18YJPYSS15).
CR Aker A, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1250
   Alassi D, 2013, INFORM SCIENCES, V219, P41, DOI 10.1016/j.ins.2012.07.022
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 1997, NEURAL COMPUT
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900
   Chen FH, 2018, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2018.00146
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kuznetsova P., 2013, P ANN M ASS COMPUTAT, P790
   Lavie A., 2007, P 2 WORKSH STAT MACH, P228
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang YF, 2017, PROC CVPR IEEE, P7378, DOI 10.1109/CVPR.2017.780
   Wu J., 2017, ARXIV171106475
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739
   Zaremba W., 2014, ARXIV
   Zhou LW, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P305, DOI 10.1145/3126686.3126717
NR 43
TC 60
Z9 61
U1 4
U2 52
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2021
VL 17
IS 1
SU S
SI SI
AR 14
DI 10.1145/3422668
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RW2ZT
UT WOS:000646396900014
DA 2024-07-18
ER

PT J
AU Wei, Y
   Wang, ZZ
   Xiao, B
   Liu, XM
   Yan, Z
   Ma, JF
AF Wei, Yang
   Wang, Zhuzhu
   Xiao, Bin
   Liu, Ximeng
   Yan, Zheng
   Ma, Jianfeng
TI Controlling Neural Learning Network with Multiple Scales for Image
   Splicing Forgery Detection
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image splicing forgery detection; multi-scale structure; block attention
   mechanism; shift-equivariance
ID EXPOSING DIGITAL FORGERIES; LOCALIZATION
AB The guarantee of social stability comes from many aspects of life, and image information security as one of them is being subjected to various malicious attacks. As a means of information attack, image splicing forgery refers to copying some areas of an image to another image to hide the traces of the original information and leads to grave consequences. Image splicing forgery is extremely complex since the attributes of the two images subjected to the pasting and copying operations are greatly different. In order to solve the issue mentioned above, we propose a method by applying a neural learning network controlled by multiple scales (MCNL-Net) based on U-Net to identify whether an image has been tampered and to locate the tampered regions. Firstly, the learning capacity of MCNL-Net is enhanced by the combination of a residual propagation module and a residual feedback module. An ingenious strategy is designed to control the size of local receptive field in each building block of MCNL-Net. The strategy makes MCNL-Net able to achieve properties and superiorities of multi-scale structure and learn specified features. For further improving the detection performance of MCNL-Net, a block attention mechanism is proposed to control the advanced degree of the input information in each building block. In addition, a MaxBlurPool method is applied into image splicing forgery detection for the first time, preserving the shift-equivariance of a convolutional neural network. Through experiments, we demonstrate that MCNL-Net can achieve more promising results and offer stronger robustness than the state-of-the-art splicing forgery detection methods.
C1 [Wei, Yang; Wang, Zhuzhu; Yan, Zheng; Ma, Jianfeng] Xidian Univ, Sch Cyber Engn, 2 Southern Taibai Rd Yanta Dist, Xian 710071, Shaanxi, Peoples R China.
   [Xiao, Bin] Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, 2 Chongwen Rd Nanan Dist, Chongqing 400065, Peoples R China.
   [Liu, Ximeng] Fuzhou Univ, Coll Math & Comp Sci, 2 Wulong River Ave Minhou Cty, Fuzhou 350108, Fujian, Peoples R China.
C3 Xidian University; Chongqing University of Posts & Telecommunications;
   Fuzhou University
RP Wang, ZZ (corresponding author), Xidian Univ, Sch Cyber Engn, 2 Southern Taibai Rd Yanta Dist, Xian 710071, Shaanxi, Peoples R China.; Xiao, B (corresponding author), Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, 2 Chongwen Rd Nanan Dist, Chongqing 400065, Peoples R China.
EM yalesaleng@gmail.com; zzwang_2@stu.xidian.edu.cn; xiaobin@cqupt.edu.cn;
   snbnix@gmail.com; zyan@xidian.edu.cn; jfma@mail.xidian.edu.cn
RI Ma, Jianfeng/GZB-0110-2022; yang, zheng/HGC-7753-2022; Liu,
   Ximeng/AAE-2151-2019; Xiao, Bin/E-2722-2012; zheng, yan/GQY-6668-2022
OI Liu, Ximeng/0000-0002-4238-3295; 
FU National Natural Science Foundation of China [U1764263, 61872283,
   U1804263, U1708262]; China 111 Project [B16037]; NSFC [U1405255]; Shanxi
   Science and Technology Coordination and Innovation Project
   [2016KTZDGY05-06]
FX This work was supported by the National Natural Science Foundation of
   China (Grants No. U1764263, No. 61872283, No. U1804263, and No.
   U1708262), the China 111 Project (No. B16037), the Key Program of NSFC
   Grant (Grant No. U1405255), and Shanxi Science and Technology
   Coordination and Innovation Project (Grant No. 2016KTZDGY05-06).
CR [Anonymous], 2016, CRYPTOL INF SEC SER, DOI DOI 10.3233/978-1-61499-617-0-1
   [Anonymous], 2009, CASIA V2 0
   Arnab A, 2018, PROC CVPR IEEE, P888, DOI 10.1109/CVPR.2018.00099
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bi XL, 2019, IEEE COMPUT SOC CONF, P30, DOI 10.1109/CVPRW.2019.00010
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Chen W, 2007, PROC SPIE, V6505, DOI 10.1117/12.704321
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Gou HM, 2007, IEEE IMAGE PROC, P2893
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Hu Jie, 2018, P IEEE C COMPUTER VI, P7132
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Johnson MK, 2007, LECT NOTES COMPUT SC, V4567, P311, DOI 10.1007/978-3-540-77370-2_21
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu B., 2018, P EUR C COMP VIS ECC, P237
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2008, INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCES AND ITS APPLICATIONS, PROCEEDINGS, P546, DOI 10.1109/ICCSA.2008.34
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Rao Y, 2016, IEEE INT WORKS INFOR
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan CP, 2016, IEEE T INF FOREN SEC, V11, P2664, DOI 10.1109/TIFS.2016.2594136
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zhang R, 2019, PR MACH LEARN RES, V97
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 38
TC 13
Z9 13
U1 0
U2 27
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2021
VL 16
IS 4
AR 124
DI 10.1145/3408299
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QB4CR
UT WOS:000614088800008
DA 2024-07-18
ER

PT J
AU Srivastava, G
   Srivastava, R
AF Srivastava, Gargi
   Srivastava, Rajeev
TI Design, Analysis, and Implementation of Efficient Framework for Image
   Annotation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image annotation; salient object detection; feature selection; scene
   analysis; multi-label classification
ID SALIENT OBJECT DETECTION; SELECTION; CLASSIFICATION
AB In this article, a general framework of image annotation is proposed by involving salient object detection (SOD), feature extraction, feature selection, and multi-label classification. For SOD, Augmented-Gradient Vector Flow (A-GVF) is proposed, which fuses benefits of GVF and Minimum Directional Contrast. The article also proposes to control the background information to be included for annotation. This article brings about a comprehensive study of all major feature selection methods for a study on four publicly available datasets. The study concludes with the proposition of using Fisher's method for reducing the dimension of features. Moreover, this article also proposes a set of features that are found to be strong discriminants by most of the methods. This reduced set for image annotation gives 3-4% better accuracy across all the four datasets. This article also proposes an improved multi-label classification algorithm C-MLFE.
C1 [Srivastava, Gargi; Srivastava, Rajeev] Banaras Hindu Univ, Indian Inst Technol, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Banaras Hindu University
   (BHU)
RP Srivastava, G (corresponding author), Banaras Hindu Univ, Indian Inst Technol, Varanasi 221005, Uttar Pradesh, India.
EM gargis.rs.cse16@iitbhu.ac.in; rajeev.cse@iitbhu.ac.in
RI Srivastava, Gargi/AAC-4052-2019; Srivastava, Rajeev/C-7906-2016
OI Srivastava, Gargi/0000-0001-6770-561X; Srivastava,
   Rajeev/0000-0002-0165-1556
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113
   Akhilesh K., 2016, P IEEE 7 POW IND INT, P1, DOI [10.1109/POWERI.2016.8077423, DOI 10.1109/POWERI.2016.8077423]
   Andriluka Mykhaylo, 2018, FLUID ANNOTATION HUM
   Ang KK, 2012, PATTERN RECOGN, V45, P2137, DOI 10.1016/j.patcog.2011.04.018
   [Anonymous], 1998, CORRELATION BASED FE
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P82
   Cai Deng, 2010, P ACM SPEC INT GROUP
   Chen Y, 2011, MATH COMPUT MODEL, V53, P646, DOI 10.1016/j.mcm.2010.10.001
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Deng Y, 2019, IEEE ACCESS, V7, P107096, DOI 10.1109/ACCESS.2019.2917932
   Du L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P209, DOI 10.1145/2783258.2783345
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fan JP, 2011, IEEE T IMAGE PROCESS, V20, P837, DOI 10.1109/TIP.2010.2073476
   Fan Ruochen, 2017, S4NET SINGLE STAGE S
   Gao SH, 2014, IEEE T MULTIMEDIA, V16, P762, DOI 10.1109/TMM.2014.2299516
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gu Q., 2011, 27 C UNC ART INT UAI, P266
   Guo J, 2017, IEEE INT CON MULTI, P1213, DOI 10.1109/ICME.2017.8019357
   Guo Jun, 2018, DEPENDENCE GUIDED UN
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   He X., 2005, P ADV NEURAL INFORM, V18, P507
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hu LD, 2018, C IND ELECT APPL, P2782, DOI 10.1109/ICIEA.2018.8398182
   Huang XM, 2017, IEEE T IMAGE PROCESS, V26, P4243, DOI 10.1109/TIP.2017.2710636
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, SECRETS SALIENT OBJE
   Liu Zhenqiu, 2014, EFFICIENT REGULARIZE
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Niu Yulei, 2017, MULTIMODAL MULTISCAL
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Pietikainen M., 1996, IEEE J SEL TOP QUANT, V29, P51
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Renuse S., 2017, P INT C COMP COMM CO, P1, DOI [10.1109/ICCUBEA.2017.8463659, DOI 10.1109/ICCUBEA.2017.8463659]
   Roffo G., 2017, INFINITE LATENT FEAT
   Roffo G, 2015, IEEE I CONF COMP VIS, P4202, DOI 10.1109/ICCV.2015.478
   Roffo Giorgio, 2017, RANKING LEARN FEATUR
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang FX, 2019, IEEE ACCESS, V7, P107816, DOI 10.1109/ACCESS.2019.2925383
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Zeng H, 2011, IEEE T PATTERN ANAL, V33, P1532, DOI 10.1109/TPAMI.2010.215
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang QW, 2018, AAAI CONF ARTIF INTE, P4446
   Zhang XH, 2017, NEUTROSOPHIC SETS SY, V17, P10
   Zheng Shuai, 2016, CLOSED FORM SOLUTION
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 67
TC 1
Z9 1
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2020
VL 16
IS 3
AR 89
DI 10.1145/3386249
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NO3HD
UT WOS:000569375200015
DA 2024-07-18
ER

PT J
AU Altamimi, S
   Shirmohammadi, S
AF Altamimi, Sa'di
   Shirmohammadi, Shervin
TI QoE-Fair DASH Video Streaming Using Server-side Reinforcement Learning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE DASH; video rate adaptation; QoE; DASH fairness; Dec-POMDP;
   reinforcement learning
ID FRAMEWORK
AB To design an optimal adaptive video streaming method, video service providers need to consider both the efficiency and the fairness of the Quality of Experience (QoE) of their users. In Reference [8], we proposed a server-side QoE-fair rate adaptation method that considers both efficiency and fairness of the QoE. The server uses Reinforcement Learning (RL) to select a bitrate for each client sharing the same bottleneck link to the server in a way that achieves fairness among concurrent DASH clients and imposes that bitrate by dynamically modifying the client's Media Presentation Description (MPD) file. In this article, we extend that work to minimize the number of actions the server needs to take to keep the system in its equilibrium state. By incorporating a Recurrent Neural Network, specifically an LSTM model, we modify the server's training algorithm to achieve improvements in both the quality and the quantity of actions the server takes to guide the client. Performance evaluation of the modified algorithm for clients running both homogeneous and heterogeneous adaptation algorithms showed that the number of server actions dropped by 14% and 22%, respectively, while QoE-fairness improved by at least 6% and 10%, respectively.
C1 [Altamimi, Sa'di; Shirmohammadi, Shervin] Univ Ottawa, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Altamimi, S (corresponding author), Univ Ottawa, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM saltamim@uottawa.ca; shervin@eecs.uottawa.ca
RI Altamimi, Sa'di/AAW-9713-2020; Shirmohammadi, Shervin/E-6945-2012
OI Altamimi, Sa'di/0000-0003-1517-8170; Shirmohammadi,
   Shervin/0000-0002-3973-4445
FU Cisco Systems Inc. under the Cisco University Research Program Fund
   [594320]; Natural Sciences and Engineering Research Council of Canada
   (NSERC)
FX The authors acknowledge the financial supports of Cisco Systems Inc.
   under the Cisco University Research Program Fund, Grant number
   CG#594320, and the Natural Sciences and Engineering Research Council of
   Canada (NSERC).
CR Akhshabi Saamer, 2013, Proceeding of the 23rd ACM Workshop on Network and Operating Systems Support for Digital Audio and Video-NOSSDAV'13
   Akhtar Z, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P44, DOI 10.1145/3230543.3230558
   Altamimi Sadi, 2019, P 29 ACM WORKSH NETW, P1, DOI [10.1145/3304112.3325604, DOI 10.1145/3304112.3325604]
   [Anonymous], 2020, The Global Internet Phenomena Report: COVID-19 Spotlight
   [Anonymous], 2020, MOBILE INTERNET PHEN
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], 2014, 230091 ISOIEC
   Bentaleb A, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3219752
   Chesebro T., 2016, LEARNING ATARI EXPLO
   De Cicco L., 2011, P 2 ANN ACM C MULTIM, P145
   Gadaleta M, 2017, IEEE T COGN COMMUN, V3, P703, DOI 10.1109/TCCN.2017.2755007
   Hemmati M, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1182, DOI 10.1109/SSCI.2015.170
   Hemmati Mahdi, 2017, THESIS
   Hossfeld T, 2017, IEEE COMMUN LETT, V21, P184, DOI 10.1109/LCOMM.2016.2616342
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Huang TC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P429, DOI 10.1145/3343031.3351014
   Huang TC, 2019, IEEE INT CON MULTI, P1678, DOI 10.1109/ICME.2019.00289
   Jain R. K, 1984, E RES LAB
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Konda VR, 2003, SIAM J CONTROL OPTIM, V42, P1143, DOI 10.1137/S0363012901385691
   Lederer S., 2012, P 3 MULT SYST C, P89
   Mao Hongzi, 2017, P ACM SPEC INT GROUP
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nadembega A, 2014, IEEE T WIREL COMMUN, V13, P6863, DOI 10.1109/TWC.2014.2336809
   Nathan V, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P408, DOI 10.1145/3341302.3342077
   Padhye J., 2008, TCP Friendly Rate Control (TFRC): Protocol Specification
   Riiser Haakon, 2013, P 4 ACM MULT SYST C, P114, DOI DOI 10.1145/2483977.2483991
   Seufert M., 2015, IEEE COMMUNICATIONS, V17, DOI DOI 10.1109/C0MST.2014.2360940
   Seufert M, 2019, IEEE T NETW SERV MAN, V16, P459, DOI 10.1109/TNSM.2019.2910380
   Sobhani A, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3052822
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   Sutton R., 1998, Reinforcement Learning: An Introduction
   The PyTorch team, 2020, PYTORCH NEURAL NETWO
   Yin XQ, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P325, DOI 10.1145/2785956.2787486
NR 34
TC 18
Z9 19
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUL
PY 2020
VL 16
IS 2
SU S
SI SI
AR 68
DI 10.1145/3397227
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1FH
UT WOS:000583712600011
DA 2024-07-18
ER

PT J
AU Zhu, SG
   Yang, XX
   Yu, J
   Fang, ZY
   Wang, M
   Huang, QM
AF Zhu, Suguo
   Yang, Xiaoxian
   Yu, Jun
   Fang, Zhenying
   Wang, Meng
   Huang, Qingming
TI Proposal Complementary Action Detection
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Temporal action detection; boundary proposal network; 3D convolutional
   network
AB Temporal action detection not only requires correct classification but also needs to detect the start and end times of each action accurately. However, traditional approaches always employ sliding windows or actionness to predict the actions, and it is different to train to model with sliding windows or actionness by end-toend means. In this article, we attempt a different idea to detect the actions end-to-end, which can calculate the probabilities of actions directly through one network as one part of the results. We present PCAD, a novel proposal complementary action detector to deal with video streams under continuous, untrimmed conditions. Our approach first uses a simple fully 3D convolutional network to encode the video streams and then generates candidate temporal proposals for activities by using anchor segments. To generate more precise proposals, we also design a boundary proposal network to offer some complementary information for the candidate proposals. Finally, we learn an efficient classifier to classify the generated proposals into different activities and refine their temporal boundaries at the same time. Our model can achieve end-to-end training by jointly optimizing classification loss and regression loss. When evaluating on the THUMOS'14 detection benchmark, PCAD achieves state-of-the-art performance in high-speed models.
C1 [Zhu, Suguo; Yu, Jun; Fang, Zhenying] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Peoples R China.
   [Yang, Xiaoxian] Shanghai Polytech Univ, Sch Comp & Informat Engn, Shanghai, Peoples R China.
   [Wang, Meng] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei, Peoples R China.
   [Huang, Qingming] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing, Peoples R China.
C3 Hangzhou Dianzi University; Shanghai Polytechnic University; Hefei
   University of Technology; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Zhu, SG (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Peoples R China.
EM zsg2016@hdu.edu.cn; xxyang@sspu.edu.cn; yujun@hdu.edu.cn;
   fzy19931001@gmail.com; eric.mengwang@gmail.com; qmhuang@ucas.ac.cn
RI Wang, Meng/ITR-8699-2023
FU National Natural Science Foundation of China [61902101, 61836002,
   61622205]
FX This work was supported by the National Natural Science Foundation of
   China under grants 61902101, 61836002, and 61622205.
CR [Anonymous], 2014, THUMOS CHALLENGE 201
   [Anonymous], 2013, NATURE STAT LEARNING
   [Anonymous], 2017, CVPR
   [Anonymous], 2018, P ASME INT C OCEAN
   [Anonymous], INT C COMP VIS PATT
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Buch Shyamal, 2017, P BRIT MACH VIS C BM, V2, P1
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Dai XY, 2017, IEEE I CONF COMP VIS, P5727, DOI 10.1109/ICCV.2017.610
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Gao Jiyang, 2017, P BRIT MACH VIS C BM, DOI [10.5244/C.31.52, DOI 10.5244/C.31.52]
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Pietäinen M, 2005, LECT NOTES COMPUT SC, V3540, P115
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Zhang Da, 2018, P BRIT MACHINE VISIO, P1
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
NR 26
TC 2
Z9 2
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUL
PY 2020
VL 16
IS 2
SU S
SI SI
AR 64
DI 10.1145/3361845
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1FH
UT WOS:000583712600007
DA 2024-07-18
ER

PT J
AU Tong, C
   Liang, BY
   Zhang, MZ
   Chen, RS
   Sangaiah, AK
   Zheng, ZG
   Wan, T
   Yue, CY
   Yang, XY
AF Tong, Chao
   Liang, Baoyu
   Zhang, Mengze
   Chen, Rongshan
   Sangaiah, Arun Kumar
   Zheng, Zhigao
   Wan, Tao
   Yue, Chenyang
   Yang, Xinyi
TI Pulmonary Nodule Detection Based on ISODATA-Improved Faster RCNN and
   3D-CNN with Focal Loss
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Datasets; neural networks; gaze detection; text tagging
ID IMAGES
AB The early diagnosis of pulmonary cancer can significantly improve the survival rate of patients, where pulmonary nodules detection in computed tomography images plays an important role. In this article, we propose a novel pulmonary nodule detection system based on convolutional neural networks (CNN). Our system consists of two stages, pulmonary nodule candidate detection and false positive reduction. For candidate detection, we introduce Iterative Self-Organizing Data Analysis Techniques Algorithm (ISODATA) to Faster Region-based Convolutional Neural Network (Faster R-CNN) model. For false positive reduction, a three-dimensional convolutional neural network (3D-CNN) is employed to completely utilize the three-dimensional nature of CT images. In this network, Focal Loss is used to solve the class imbalance problem in this task. Experiments were conducted on LUNA16 dataset. The results show the preferable performance of the proposed system and the effectiveness of using ISODATA and Focal loss in pulmonary nodule detection is proved.
C1 [Tong, Chao; Liang, Baoyu; Zhang, Mengze; Chen, Rongshan; Wan, Tao; Yang, Xinyi] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Tong, Chao; Liang, Baoyu; Zhang, Mengze; Chen, Rongshan] Zhengzhou Univ, Natl Engn Lab Internet Med Syst & Applicat, Affiliated Hosp 1, Zhengzhou 450052, Peoples R China.
   [Sangaiah, Arun Kumar] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Zheng, Zhigao] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Yue, Chenyang] Capital Normal Univ, Coll Informat Engn, Beijing 100089, Peoples R China.
C3 Beihang University; Zhengzhou University; Vellore Institute of
   Technology (VIT); VIT Vellore; Huazhong University of Science &
   Technology; Capital Normal University
RP Liang, BY (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.; Liang, BY (corresponding author), Zhengzhou Univ, Natl Engn Lab Internet Med Syst & Applicat, Affiliated Hosp 1, Zhengzhou 450052, Peoples R China.; Zheng, ZG (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
EM tongchao@buaa.edu.cn; liangbouyo96@buaa.edu.cn; zhangmengze@buaa.edu.cn;
   904620522@qq.com; arunkumarsangaiah@gmail.com; zhengzhigao@hust.edu.cn;
   taowan@buaa.edu.cn; 805695510@qq.com; yangxinyi@buaa.edu.cn
RI 陈, 紫月/IAP-6501-2023; chen, yue/JEF-2824-2023; Yang, Xinyi/IVH-6916-2023;
   Liang, Baoyu/HWQ-4668-2023; Sangaiah, Arun Kumar/U-6785-2019; Zheng,
   Zhigao/ITT-8238-2023
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; Zheng,
   Zhigao/0000-0002-2504-9607; Zhang, Mengze/0000-0002-8774-4568
FU National Natural Science Foundation of China [61472024, U1433203];
   National Engineering Laboratory for Internet Medical System and
   Application [NELIMSA2018P01]
FX This work was supported by the National Natural Science Foundation of
   China (61472024, U1433203), Project of National Engineering Laboratory
   for Internet Medical System and Application (NELIMSA2018P01).
CR [Anonymous], 2015, PROC 3 INT C LEARNIN
   [Anonymous], 2016, IEEE T MED IMAGING
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Cha J, 2018, MED PHYS, V45, P297, DOI 10.1002/mp.12690
   de Carvalho AO, 2017, MED BIOL ENG COMPUT, V55, P1199, DOI 10.1007/s11517-016-1582-x
   El-Baz A, 2013, INT J BIOMED IMAGING, V2013, DOI [10.1155/2013/942353, 10.1155/2013/517632]
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jia Ding, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P559, DOI 10.1007/978-3-319-66179-7_64
   Jin H., 2018, MED PHYS, V45, P5
   Lee SLA, 2010, COMPUT MED IMAG GRAP, V34, P535, DOI 10.1016/j.compmedimag.2010.03.006
   Murphy K, 2009, MED IMAGE ANAL, V13, P757, DOI 10.1016/j.media.2009.07.001
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Sivakumar S, 2013, INT J ENG TECHNOL, V5, P179
   Sui Y, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/368674
   Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029
   VENKATESWARLU NB, 1992, PATTERN RECOGN, V25, P335, DOI 10.1016/0031-3203(92)90114-X
   Wang J, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/295704
   Wang Y, 2013, INTERNATIONAL CONFERENCE ON BIOLOGICAL, MEDICAL AND CHEMICAL ENGINEERING (BMCE 2013), P253
NR 20
TC 8
Z9 8
U1 2
U2 26
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2020
VL 16
IS 1
SU S
SI SI
AR 36
DI 10.1145/3365445
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1EL
UT WOS:000583710300018
DA 2024-07-18
ER

PT J
AU Tripathi, S
   Singh, SK
AF Tripathi, Suvidha
   Singh, Satish Kumar
TI Cell Nuclei Classification in Histopathological Images using Hybrid
   O<sub>L</sub> ConvNet
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Deep learning; hybrid networks; object-level features; transfer
   learning; histopathological images; cell nuclei classification; class
   balancing; convolutional neural networks; multi layer perceptron
AB Computer-aided histopathological image analysis for cancer detection is a major research challenge in the medical domain. Automatic detection and classification of nuclei for cancer diagnosis impose a lot of challenges in developing state-of-the-art algorithms due to the heterogeneity of cell nuclei and dataset variability. Recently, a multitude of classification algorithms have used complex deep learning models for their dataset. However, most of these methods are rigid, and their architectural arrangement suffers from inflexibility and non-interpretability. In this research article, we have proposed a hybrid and flexible deep learning architecture O(L)ConvNet that integrates the interpretability of traditional object-level features and generalization of deep learning features by using a shallower Convolutional Neural Network (CNN) named as CNN3L. CNN3L reduces the training time by training fewer parameters and hence eliminating space constraints imposed by deeper algorithms. We used F1-score and multiclass Area Under the Curve (AUC) performance parameters to compare the results. To further strengthen the viability of our architectural approach, we tested our proposed methodology with state-of-the-art deep learning architectures AlexNet, VGG16, VGG19, ResNet50, InceptionV3, and DenseNet121 as backbone networks. After a comprehensive analysis of classification results from all four architectures, we observed that our proposed model works well and performs better than contemporary complex algorithms.
C1 [Tripathi, Suvidha; Singh, Satish Kumar] Indian Inst Informat Technol Allahabad, Prayagraj 211015, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Tripathi, S (corresponding author), Indian Inst Informat Technol Allahabad, Prayagraj 211015, Uttar Pradesh, India.
EM suvitri24@gmail.com; sk.singh@iiita.ac.in
RI Singh, Dr Satish Kumar/JMP-6186-2023; Tripathi, Suvidha/ABA-4736-2020
OI Singh, Dr Satish Kumar/0000-0003-1991-7727; Tripathi,
   Suvidha/0000-0002-4753-7732
FU Ministry of Human Resource and Development, Government of India; NVIDIA
   corporation
FX This research was carried out in Indian Institute of Information
   Technology, Allahabad, and was supported by the Ministry of Human
   Resource and Development, Government of India. We are also grateful to
   the NVIDIA corporation for supporting our research in this area by
   granting us TitanX (PASCAL) GPU.
CR [Anonymous], 2009, handbook of research on machine learning applications
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Boucheron Laura E., 2008, OBJECT AND SPATIAL L
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Cancer Research UK, 2017, TYP CANC
   Catoi C., 2007, COMP ONCOLOGY
   Chang Hang, 2012, P INT S BIOM IM
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen XW, 2006, IEEE T BIO-MED ENG, V53, P762, DOI 10.1109/TBME.2006.870201
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Diamond J, 2004, HUM PATHOL, V35, P1121, DOI 10.1016/j.humpath.2004.05.010
   Donahue J, 2014, PR MACH LEARN RES, V32
   Doyle S, 2007, I S BIOMED IMAGING, P1284, DOI 10.1109/ISBI.2007.357094
   Fischer A. H., 2008, CSH PROTOC, V2008, DOI [10.1101/pdb.prot4986, DOI 10.1101/PDB.PROT4986]
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karpathy A, 2018, Stanford university cs231n: Convolutional neural networks for visual recognition
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Madabhushi A, 2016, MED IMAGE ANAL, V33, P170, DOI 10.1016/j.media.2016.06.037
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Rodemann HP, 2011, TUMOR MICROENVIRON, V4, P23, DOI 10.1007/978-94-007-0659-0_2
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Shi J, 2017, IEEE J BIOMED HEALTH, V21, P1327, DOI 10.1109/JBHI.2016.2602823
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Sirinukunwattana K, 2015, PROC SPIE, V9420, DOI 10.1117/12.2082010
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tripathi S, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2062, DOI 10.1109/TENCON.2016.7848388
   VOGL TP, 1988, BIOL CYBERN, V59, P257, DOI 10.1007/BF00332914
   Wang HB, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034003
   Wang P, 2016, SIGNAL PROCESS, V122, P1, DOI 10.1016/j.sigpro.2015.11.011
   Wang SH, 2020, NEURAL COMPUT APPL, V32, P665, DOI 10.1007/s00521-018-3924-0
   Yuan YY, 2012, SCI TRANSL MED, V4, DOI 10.1126/scitranslmed.3004330
   Zhang JP, 2018, IEEE J BIOMED HEALTH, V22, P1521, DOI 10.1109/JBHI.2017.2775662
   Zink D, 2004, NAT REV CANCER, V4, P677, DOI 10.1038/nrc1430
NR 44
TC 12
Z9 12
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2020
VL 16
IS 1
SU S
SI SI
AR 32
DI 10.1145/3345318
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1EL
UT WOS:000583710300014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, AR
   Jiang, XL
   Zhang, BC
   Cao, XB
AF Zhang, Anran
   Jiang, Xiaolong
   Zhang, Baochang
   Cao, Xianbin
TI Multi-scale Supervised Attentive Encoder-Decoder Network for Crowd
   Counting
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Self-attention; representation fusion; supervised method
ID HUMANS; SEGMENTATION; TRACKING; MULTIPLE; IMAGE
AB Crowd counting is a popular topic with widespread applications. Currently, the biggest challenge to crowd counting is large-scale variation in objects. In this article, we focus on overcoming this challenge by proposing a novel Attentive Encoder-Decoder Network (AEDN), which is supervised on multiple feature scales to conduct crowd counting via density estimation. This work has three main contributions. First, we augment the traditional encoder-decoder architecture with our proposed residual attention blocks, which, beyond skip-connected encoded features, further extend the decoded features with attentive features. AEDN is better at establishing long-range dependencies between the encoder and decoder, therefore promoting more effective fusion of multi-scale features for handling scale-variations. Second, we design a new KL-divergence-based distribution loss to supervise the scale-aware structural differences between two density maps, which complements the pixel-isolated MSE loss and better optimizes AEDN to generate high-quality density maps. Third, we adopt a multi-scale supervision scheme, such that multiple KL divergences and MSE losses are deployed at all decoding stages, providing more thorough supervisions for different feature scales. Extensive experimental results on four public datasets, including ShanghaiTech Part A, ShanghaiTech Part B, UCF-CC-50, and UCF-QNRF, reveal the superiority and efficacy of the proposed method, which outperforms most state-of-the-art competitors.
C1 [Zhang, Anran; Jiang, Xiaolong; Cao, Xianbin] Beihang Univ, Sch Elect & Informat Engn, XueYuan Rd 37, Beijing, Peoples R China.
   [Zhang, Baochang] Beihang Univ, Sch Automat Sci & Elect Engn, XueYuan Rd 37, Beijing, Peoples R China.
   [Cao, Xianbin] Beihang Univ, Key Lab Adv Technol Near Space Informat Syst, Minist Ind & Informat Technol China, XueYuan Rd 37, Beijing, Peoples R China.
   [Cao, Xianbin] Beijing Adv Innovat Ctr Big Data Based Precis Med, XueYuan Rd 37, Beijing, Peoples R China.
C3 Beihang University; Beihang University; Beihang University
RP Cao, XB (corresponding author), Beihang Univ, Sch Elect & Informat Engn, XueYuan Rd 37, Beijing, Peoples R China.; Cao, XB (corresponding author), Beihang Univ, Key Lab Adv Technol Near Space Informat Syst, Minist Ind & Informat Technol China, XueYuan Rd 37, Beijing, Peoples R China.; Cao, XB (corresponding author), Beijing Adv Innovat Ctr Big Data Based Precis Med, XueYuan Rd 37, Beijing, Peoples R China.
EM zhanganran@buaa.edu.cn; jasperj1tmac@163.com; bczhang@buaa.edu.cn;
   xbcao@buaa.edu.cn
RI zhang, an/JMR-3763-2023; jiang, xiaolong/KJM-3457-2024
FU National Natural Science Foundation of China (NSFC) [91538204, 91738301,
   61827901]
FX This article was supported by the National Natural Science Foundation of
   China (NSFC) under Grants No. 91538204, No. 91738301, and No. 61827901.
CR An S, 2007, PROC CVPR IEEE, P1033
   [Anonymous], 2017, ADV NEURAL INFORM PR
   [Anonymous], 2015, ARXIV150708445
   [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen XL, 2019, IEEE I CONF COMP VIS, P2061, DOI 10.1109/ICCV.2019.00215
   Chorowski Jan, 2015, ARXIVCSCL150607503
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Haralick R. M., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V548, P2, DOI [10.1016/S0734-189X(85)90153-7, 10.1117/12.948400]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P1049, DOI 10.1109/TIP.2017.2740160
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2015, IEEE T PATTERN ANAL, V37, P1986, DOI 10.1109/TPAMI.2015.2396051
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Jiang XL, 2019, IEEE WINT CONF APPL, P101, DOI 10.1109/WACV.2019.00018
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kong D, 2006, INT C PATT RECOG, P1187
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulikov V., 2019, ARXIV190405257
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li M, 2008, INT C PATT RECOG, P1998
   Li Yuhong, 2018, ARXIVCSCV180210062
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P1666, DOI 10.1109/TIP.2017.2657118
   Liu H, 2018, NEUROCOMPUTING, V282, P52, DOI 10.1016/j.neucom.2017.12.014
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu XL, 2018, PROC CVPR IEEE, P7661, DOI 10.1109/CVPR.2018.00799
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Marana AN, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P354, DOI 10.1109/SIBGRA.1998.722773
   Meng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3401, DOI 10.1109/CVPR.2011.5995698
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Oren Michael., 1997, PROC CVPR IEEE, P193, DOI DOI 10.1109/CVPR.1997.609319
   Paragios N, 2001, PROC CVPR IEEE, P1034
   Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosten E., 2006, P 2006 9 EUR C COMP, P430, DOI DOI 10.1007/11744023_34
   Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Sindagi V. A., 2017, 2017 14 IEEE INT C A, P1
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang Ze., 2018, British Machine Vision Conference 2018, BMVC 2018, Newcastle, UK, September 3-6, 2018, page, P78
   Wilf P, 2016, P NATL ACAD SCI USA, V113, P3305, DOI 10.1073/pnas.1524473113
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Wu XY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P214, DOI 10.1109/ROBIO.2006.340379
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xiong F, 2017, IEEE I CONF COMP VIS, P5161, DOI 10.1109/ICCV.2017.551
   Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412
   Xu Dan, 2017, P IEEE C COMP VIS PA, V1
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang SP, 2017, IEEE T NEUR NET LEAR, V28, P2357, DOI 10.1109/TNNLS.2016.2586194
   Zhang SP, 2017, IEEE T CIRC SYST VID, V27, P421, DOI 10.1109/TCSVT.2016.2539860
   Zhang SP, 2015, IEEE T CIRC SYST VID, V25, P1749, DOI 10.1109/TCSVT.2015.2406194
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
   Zhao ZY, 2016, LECT NOTES COMPUT SC, V9912, P712, DOI 10.1007/978-3-319-46484-8_43
   Zhu W., 2018, ARXIV180805238
   Zhu WT, 2018, I S BIOMED IMAGING, P847, DOI 10.1109/ISBI.2018.8363704
NR 82
TC 8
Z9 8
U1 1
U2 21
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2020
VL 16
IS 1
SU S
SI SI
AR 28
DI 10.1145/3356019
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1EL
UT WOS:000583710300010
DA 2024-07-18
ER

PT J
AU Ahmad, K
   Conci, N
AF Ahmad, Kashif
   Conci, Nicola
TI How Deep Features Have Improved Event Recognition in Multimedia: A
   Survey
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; event detection; deep learning; deep features;
   social events detection; natural disaster; social media; video analysis;
   audio event analysis
ID CLASSIFICATION; REPRESENTATION; ONTOLOGY
AB Event recognition is one of the areas in multimedia that is attracting great attention of researchers. Being applicable in a wide range of applications, from personal to collective events, a number of interesting solutions for event recognition using multimedia information sources have been proposed. On the other hand, following their immense success in classification, object recognition, and detection, deep learning has been shown to perform well in event recognition tasks also. Thus, a large portion of the literature on event analysis relies nowadays on deep learning architectures. In this article, we provide an extensive overview of the existing literature in this field, analyzing how deep features and deep learning architectures have changed the performance of event recognition frameworks. The literature on event-based analysis of multimedia contents can be categorized into four groups, namely (i) event recognition in single images; (ii) event recognition in personal photo collections; (iii) event recognition in videos; and (iv) event recognition in audio recordings. In this article, we extensively review different deep-learning-based frameworks for event recognition in these four domains. Furthermore, we also review some benchmark datasets made available to the scientific community to validate novel event recognition pipelines. In the final part of the manuscript, we also provide a detailed discussion on basic insights gathered from the literature review, and identify future trends and challenges.
C1 [Ahmad, Kashif; Conci, Nicola] Univ Trento, DISI, Via Sommarive 5, I-38123 Trento, Italy.
C3 University of Trento
RP Ahmad, K (corresponding author), Univ Trento, DISI, Via Sommarive 5, I-38123 Trento, Italy.
RI ahmad, kashif/AAV-8323-2021; Conci, Nicola/AAH-4671-2020; Ahmad,
   Kashif/JJE-8424-2023
OI Conci, Nicola/0000-0002-7858-0928; Ahmad, Kashif/0000-0002-0931-9275
CR Ahmad K, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3199668
   Ahmad K, 2019, MULTIMED TOOLS APPL, V78, P2837, DOI 10.1007/s11042-018-5982-9
   Ahmad K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.060502
   Ahmad K, 2018, SIGNAL PROCESS-IMAGE, V60, P42, DOI 10.1016/j.image.2017.09.009
   Ahmad K, 2016, IEEE GLOB CONF SIG, P1223, DOI 10.1109/GlobalSIP.2016.7906036
   Ahmad K, 2018, INT ARAB CONF INF TE, P273
   Ahmad S, 2016, 2016 INTERNATIONAL CONFERENCE ON SYSTEMS IN MEDICINE AND BIOLOGY (ICSMB), P53, DOI 10.1109/ICSMB.2016.7915086
   Amit SNKB, 2016, INT GEOSCI REMOTE SE, P5189, DOI 10.1109/IGARSS.2016.7730352
   [Anonymous], ARXIV180109522
   [Anonymous], 2015, P IEEE INT JOINT C N, DOI DOI 10.1109/IJCNN.2015.7280624
   [Anonymous], IEEE AASP CHALL DET
   [Anonymous], MEDIAEVAL
   [Anonymous], P MEDIAEVAL 2017 WOR
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2016, P DETECTION CLASSIFI
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P 7 INT C MULT SYST
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], 2017, P MEDIAEVAL 2017 WOR
   [Anonymous], 2016, P KOREA JAPAN JOINT
   [Anonymous], P 6 IASTED INT C
   [Anonymous], 2016, ARXIV160407160
   [Anonymous], P INT C MULT RETR WO
   [Anonymous], 2015, BMVC
   [Anonymous], 2011, P MEDIAEVAL
   [Anonymous], P 20 ACM INT C MULT
   [Anonymous], ARXIV171103564
   [Anonymous], APPL ARTIFICIAL INTE
   [Anonymous], TRECVID WORKSH
   [Anonymous], SOLVING MULTIPLE INS
   [Anonymous], P ACM C MULT
   [Anonymous], 2017, ARXIV170205538
   [Anonymous], P 2005 IEEE INT C MU
   [Anonymous], 2001, DETECTING SOUND EVEN
   [Anonymous], 2016, DETECTION CLASSIFICA
   [Anonymous], P MEDIAEVAL WORKSH S
   [Anonymous], NIST TRECVID WORKSH
   [Anonymous], ARXIV160908764
   [Anonymous], IEEE AASP CHALL DET
   [Anonymous], 2018, ELECT IMAGING
   [Anonymous], ARXIV14108586
   [Anonymous], 2018, AUTOAUGMENT LEARNING
   [Anonymous], 2014, P TRECVID
   [Anonymous], 2017, IEEE IMAGE PROC
   [Anonymous], 2009, MOSIFT RECOGNIZING H
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, P MEDIAEVAL 2017 WOR
   [Anonymous], IEEE AASP CHALLENGE
   [Anonymous], TRECVID 2013 WORKSH
   [Anonymous], P WORK NOT P MEDIAEV
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2013, P MEDIAEVAL MULT BEN
   [Anonymous], 2016, DETECTION CLASSIFICA
   [Anonymous], 2017, ARXIV170602293
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], TECHNICAL REPORT
   [Anonymous], SPAC LIF EARTH
   [Anonymous], P WORKSH DET CLASS A
   [Anonymous], 2017, P MEDIAEVAL 2017 DUB
   [Anonymous], 2013, ARXIV13124400
   [Anonymous], 2018, ARXIV180711805
   [Anonymous], 2015, P BRIT MACH VIS C BM
   [Anonymous], P DCASE 2017 WORKSH
   [Anonymous], 2018, P IEEE C COMP VIS PA
   [Anonymous], 2018, ARXIV180601810
   [Anonymous], 2016, ARXIV160406338
   [Anonymous], TRECVID MULTIMEDIA E
   [Anonymous], 2017, P MEDIAEVAL 2017 WOR
   [Anonymous], 2016, P ADV NEUR INF PROC
   [Anonymous], 2017, COMPLEXITY
   [Anonymous], 2009, P NAGDAGA INT C ACOU
   [Anonymous], MEDIAEVAL
   [Anonymous], ARXIV161106474
   [Anonymous], GLOBAL BIOGEOCHEMICA
   Bacha S, 2016, J VIS COMMUN IMAGE R, V40, P546, DOI 10.1016/j.jvcir.2016.07.021
   Ballan L, 2009, IEEE INT CON MULTI, P474, DOI 10.1109/ICME.2009.5202537
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bischke B., 2017, P MEDIAEVAL 2017 WOR
   Bischke B, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1077, DOI 10.1145/2964284.2984063
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bossard L, 2013, IEEE I CONF COMP VIS, P1193, DOI 10.1109/ICCV.2013.151
   Cakir E, 2016, IEEE IJCNN, P3399, DOI 10.1109/IJCNN.2016.7727634
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Cheng D, 2015, IEEE INT C SEMANT CO, P32, DOI 10.1109/ICOSC.2015.7050775
   Chu S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P885, DOI 10.1109/ICME.2006.262661
   Cong HZ, 2015, 3RD INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS 2015), P1, DOI 10.1109/ICTIS.2015.7232054
   Cotton CV, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P69, DOI 10.1109/ASPAA.2011.6082331
   Dao MS, 2014, MULTIMED TOOLS APPL, V70, P25, DOI 10.1007/s11042-012-1153-6
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Escalera Sergio, 2015, P IEEE INT C COMPUTE, P1
   Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630
   Feng YC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2964284.2967290
   Foggia P, 2016, IEEE T INTELL TRANSP, V17, P279, DOI 10.1109/TITS.2015.2470216
   Foggia P, 2015, PATTERN RECOGN LETT, V65, P22, DOI 10.1016/j.patrec.2015.06.026
   Font F., 2013, P 2013 ACM MULTIMEDI, P411, DOI 10.1145/2502081.2502245
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Fu JL, 2015, IEEE I CONF COMP VIS, P1985, DOI 10.1109/ICCV.2015.230
   Gan C, 2016, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2016.106
   Gan C, 2016, LECT NOTES COMPUT SC, V9907, P849, DOI 10.1007/978-3-319-46487-9_52
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Gencoglu O, 2014, EUR SIGNAL PR CONF, P506
   Goodfellow I, 2016, Deep learning. vol
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hayashi T, 2017, INT CONF ACOUST SPEE, P766, DOI 10.1109/ICASSP.2017.7952259
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heittola T, 2013, INT CONF ACOUST SPEE, P8677, DOI 10.1109/ICASSP.2013.6639360
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jhuo IH, 2014, INT C PATT RECOG, P666, DOI 10.1109/ICPR.2014.125
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang L, 2014, ADV NEUR IN, V27
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kons Z, 2013, INTERSPEECH, P1481
   Lee JC, 2017, ELEC COMP C, P2015, DOI 10.1109/ECTC.2017.66
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Liu M, 2015, P IEEE INT C COMP VI, P32, DOI 10.1016/j.ijsolstr.2015.02.031
   Liu XC, 2013, PROCEEDINGS OF THE 1ST INTERNATIONAL JOINT SYMPOSIUM ON JOINING AND WELDING, P151
   Liu Y, 2016, PROCEDIA COMPUT SCI, V91, P566, DOI 10.1016/j.procs.2016.07.144
   Long X, 2018, AAAI CONF ARTIF INTE, P7202
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Lopez-Fuentes L, 2017, P MEDIAEVAL WORKSH
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mattivi R, 2011, INFOCOMMUNICATIONS J, V3, P9
   Mesaros A, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060162
   Mesaros A, 2010, EUR SIGNAL PR CONF, P1267
   Mettes P, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P175, DOI 10.1145/2911996.2912036
   Meyer M., 2017, ARXIV170909888
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Parascandolo G, 2016, INT CONF ACOUST SPEE, P6440, DOI 10.1109/ICASSP.2016.7472917
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   Plinge Axel, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3704, DOI 10.1109/ICASSP.2014.6854293
   Pouyanfar S, 2017, INT J SEMANT COMPUT, V11, P85, DOI 10.1142/S1793351X17400050
   Pouyanfar S, 2016, IEEE INT SYM MULTIM, P203, DOI [10.1109/ISM.2016.121, 10.1109/ISM.2016.0048]
   Rhee J, 2010, REMOTE SENS ENVIRON, V114, P2875, DOI 10.1016/j.rse.2010.07.005
   Safdarnejad Seyed Morteza, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163105
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Salvador A, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301334
   Shi Y., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1945, DOI 10.1109/CEC.1999.785511
   Simonyan K., 2014, 14091556 ARXIV
   Singh B, 2015, IEEE I CONF COMP VIS, P4561, DOI 10.1109/ICCV.2015.518
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Sungheon Park, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P45, DOI 10.1109/CVPRW.2015.7301335
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Takahashi N, 2018, IEEE T MULTIMEDIA, V20, P513, DOI 10.1109/TMM.2017.2751969
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Tsai SW., 2011, Proceedings of ICCM-18, P1
   Tzelepis Christos, 2016, Image and Vision Computing, V53, P3, DOI 10.1016/j.imavis.2016.05.005
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L., 2015, Proceedings of the IEEE International Conference on Computer Vision Workshops (ICCVW), P45
   Wang XY, 2015, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2015.7299071
   Wang Y, 2017, INT CONF ACOUST SPEE, P2986, DOI 10.1109/ICASSP.2017.7952704
   Wang Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P265, DOI 10.1145/2911996.2912048
   Wang Y, 2016, INT CONF ACOUST SPEE, P2742, DOI 10.1109/ICASSP.2016.7472176
   Wong WK, 2017, ADV CIV IND ENG BOOK, P1, DOI 10.4018/978-1-5225-2423-6.ch001
   Wu ZF, 2015, IEEE T MULTIMEDIA, V17, P1960, DOI 10.1109/TMM.2015.2477681
   Xiong YJ, 2015, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2015.7298768
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yager RR, 1999, IEEE T SYST MAN CY B, V29, P141, DOI 10.1109/3477.752789
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221
   Yeung S, 2018, INT J COMPUT VISION, V126, P375, DOI 10.1007/s11263-017-1013-y
   Yu LT, 2016, NEUROCOMPUTING, V213, P48, DOI 10.1016/j.neucom.2016.03.102
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1033, DOI 10.1109/TIP.2015.2511585
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhu LC, 2017, INT J COMPUT VISION, V124, P409, DOI 10.1007/s11263-017-1033-7
NR 170
TC 35
Z9 35
U1 2
U2 21
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2019
VL 15
IS 2
AR 39
DI 10.1145/3306240
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IM3ZV
UT WOS:000477935400010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Roberto, P
   Emanuele, F
   Primo, Z
   Adriano, M
   Jelena, L
   Marina, P
AF Roberto, Pierdicca
   Emanuele, Fronton
   Primo, Zingaretti
   Adriano, Mancini
   Jelena, Loncarski
   Marina, Paolanti
TI Design, Large-Scale Usage Testing, and Important Metrics for Augmented
   Reality Gaming Applications
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; mobile gaming; large scale testing; puzzle; gaming
   framework
AB Augmented Reality (AR) offers the possibility to enrich the real world with digital mediated content, increasing in this way the quality of many everyday experiences. While in some research areas such as cultural heritage, tourism, or medicine there is a strong technological investment, AR for game purposes struggles to become a widespread commercial application. In this article, a novel framework for AR kid games is proposed, already developed by the authors for other AR applications such as Cultural Heritage and Arts. In particular, the framework includes different layers such as the development of a series of AR kid puzzle games in an intermediate structure which can be used as a standard for different applications development, the development of a smart configuration tool, together with general guidelines and long-life usage tests and metrics. The proposed application is designed for augmenting the puzzle experience, but can be easily extended to other AR gaming applications. Once the user has assembled the real puzzle, AR functionality within the mobile application can be unlocked, bringing to life puzzle characters, creating a seamless game that merges AR interactions with the puzzle reality. The main goals and benefits of this framework can be seen in the development of a novel set of AR tests and metrics in the pre-release phase (in order to help the commercial launch and developers), and in the release phase by introducing the measures for long-life app optimization, usage tests and hint on final users together with a measure to design policy, providing a method for automatic testing of quality and popularity improvements. Moreover, smart configuration tools, as part of the general framework, enabling multi-app and eventually also multi-user development, have been proposed, facilitating the serialization of the applications. Results were obtained from a large-scale user test with about 4 million users on a set of eight gaming applications, providing the scientific community a workflow for implicit quantitative analysis in AR gaming. Different data analytics developed on the data collected by the framework prove that the proposed approach is affordable and reliable for long-life testing and optimization.
C1 [Roberto, Pierdicca] Univ Politecn Marche DICEA, Via Brecce Bianche, I-60131 Ancona, IT, Italy.
   [Emanuele, Fronton; Primo, Zingaretti; Adriano, Mancini; Marina, Paolanti] Univ Politecn Marche DII, Via Brecce Bianche, I-60131 Ancona, IT, Italy.
   [Jelena, Loncarski] Uppsala Univ, Dept Engn Sci, Div Elect Res, Lagerhyddsvagen 1, S-75121 Uppsala, SE, Sweden.
C3 Uppsala University
RP Roberto, P (corresponding author), Univ Politecn Marche DICEA, Via Brecce Bianche, I-60131 Ancona, IT, Italy.
EM r.pierdicca@staff.univpm.it; e.frontoni@staff.univpm.it;
   p.zingaretti@staff.univpm.it; a.mancini@staff.univpm.it;
   jelena.loncarski@angstrom.uu.se; m.paolanti@staff.univpm.it
RI Frontoni, Emanuele/D-9838-2013; Pierdicca, Roberto/B-3193-2016
OI Frontoni, Emanuele/0000-0002-8893-9244; Loncarski,
   Jelena/0000-0001-6127-7888; Pierdicca, Roberto/0000-0002-9160-834X
CR Ahn J, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808207
   Arteaga SM, 2012, PERVASIVE MOB COMPUT, V8, P900, DOI 10.1016/j.pmcj.2012.08.002
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3145534
   Billinghurst M., 2002, NEW HORIZONS LEARNIN, V12
   Clini P, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/597476
   De Leon NI, 2014, INT J SMART SENS INT, V7, P1044, DOI 10.21307/ijssis-2017-693
   Frontoni E, 2016, LECT NOTES COMPUT SC, V9768, P435, DOI 10.1007/978-3-319-40621-3_31
   Gordon I, 2006, LECT NOTES COMPUT SC, V4170, P67
   Guan W, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348826
   Ha T, 2011, VIRTUAL REAL-LONDON, V15, P295, DOI 10.1007/s10055-010-0164-8
   Haugstvedt AC, 2012, INT SYM MIX AUGMENT, P247, DOI 10.1109/ISMAR.2012.6402563
   Henrysson Anders, 2006, ACM SIGGRAPH 2006 SK, V13, DOI [10.1145/1179133.1179135, DOI 10.1145/1179133.1179135]
   Jee HK, 2014, MULTIMED TOOLS APPL, V68, P225, DOI 10.1007/s11042-011-0880-4
   Kerawalla L., 2006, Virtual Real, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   Kojima M, 2006, FIRST IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, P3, DOI 10.1109/TABLETOP.2006.3
   Kourouthanassis P, 2015, PERVASIVE MOB COMPUT, V18, P71, DOI 10.1016/j.pmcj.2014.08.009
   Lee Y, 2015, LECT NOTES COMPUT SC, V9189, P182, DOI 10.1007/978-3-319-20804-6_17
   Liu KK, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808208
   Lu SJ, 2015, ENVIRON EDUC RES, V21, P525, DOI 10.1080/13504622.2014.911247
   Mulloni A., 2008, Proceedings of the 3rd international conference on Digital Interactive Media in Entertainment and Arts, P472
   Naspetti S, 2016, LECT NOTES COMPUT SC, V9769, P217, DOI 10.1007/978-3-319-40651-0_17
   Nilsen T., 2004, P NZGDC FUSE, V4, P86
   Park JS, 2011, MULTIMED TOOLS APPL, V55, P725, DOI 10.1007/s11042-010-0592-1
   Piekarski Wayne, 2001, ISAR, V177, DOI [10.1109/ISAR.2001.970530, DOI 10.1109/ISAR.2001.970530]
   Pierdicca R, 2016, COMPUT GEOSCI-UK, V95, P67, DOI 10.1016/j.cageo.2016.06.018
   Pierdicca R, 2015, LECT NOTES COMPUT SC, V9254, P38, DOI 10.1007/978-3-319-22888-4_4
   Pucihar KC, 2013, COMPUT ENTERTAIN, V11, DOI 10.1145/2582179.2633427
   Ryu HS, 2016, MULTIMED TOOLS APPL, V75, P3375, DOI 10.1007/s11042-014-2439-7
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Silva VE, 2015, SYMP VIRTUAL AUGMENT, P147, DOI 10.1109/SVR.2015.29
   Taejin Ha, 2010, Proceedings of the 2010 International Symposium on Ubiquitous Virtual Reality (ISUVR 2010), P40, DOI 10.1109/ISUVR.2010.20
   Taketa N, 2007, LECT NOTES COMPUT SC, V4558, P475
   Tatzgern M, 2015, PERVASIVE MOB COMPUT, V18, P55, DOI 10.1016/j.pmcj.2014.08.010
   Thomas BH, 2012, COMPUT ENTERTAIN, V10, DOI 10.1145/2381876.2381879
   Trimailovas Igoris, 2013, MAGMAR COLLABORATIVE
   Wagner D., 2004, ACM SIGGRAPH 2004 Emerging technologies, P12
   Yamabe T, 2013, MULTIMED TOOLS APPL, V62, P259, DOI 10.1007/s11042-011-0979-7
   Yuen S.C.Y., 2011, J. Educ. Technol. Dev. Exch. (JETDE), V4, P11, DOI [10.18785/jetde.0401.10, DOI 10.18785/JETDE.0401.10]
NR 38
TC 8
Z9 10
U1 6
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2019
VL 15
IS 2
AR 41
DI 10.1145/3311748
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IM3ZV
UT WOS:000477935400012
DA 2024-07-18
ER

PT J
AU Chen, ZN
   Al, SS
   Jia, CY
AF Chen, Zhineng
   Al, Shanshan
   Jia, Caiyan
TI Structure-Aware Deep Learning for Product Image Classification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image classification; category hierarchy; convolutional neural network;
   multi-class regression; multi-task learning
ID ASSOCIATION
AB Automatic product image classification is a task of crucial importance with respect to the management of online retailers. Motivated by recent advancements of deep Convolutional Neural Networks (CNN) on image classification, in this work we revisit the problem in the context of product images with the existence of a predefined categorical hierarchy and attributes, aiming to leverage the hierarchy and attributes to improve classification accuracy. With these structure-aware clues, we argue that more advanced deep models could be developed beyond the flat one-versus-all classification performed by conventional CNNs. To this end, novel efforts of this work include a salient-sensitive CNN that gazes into the product foreground by inserting a dedicated spatial attention module; a multiclass regression-based refinement that is expected to predict more accurately by merging prediction scores from multiple preceding CNNs, each corresponding to a distinct classifier in the hierarchy; and a multitask deep learning architecture that effectively explores correlations among categories and attributes for categorical label prediction. Experimental results on nearly 1 million real-world product images basically validate the effectiveness of the proposed efforts individually and jointly, from which performance gains are observed.
C1 [Chen, Zhineng] Chinese Acad Sci, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   [Al, Shanshan; Jia, Caiyan] Beijing Jiaotong Univ, 3 Shangyuancun Rd, Beijing 100044, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Beijing
   Jiaotong University
RP Jia, CY (corresponding author), Beijing Jiaotong Univ, 3 Shangyuancun Rd, Beijing 100044, Peoples R China.
EM zhineng.chen@ia.ac.cn; 15120384@bjtu.edu.cn; cyjia@bjtu.edu.cn
RI chen, zhineng/AAD-6723-2020
FU National Natural Science Foundation of China [61772526, 61473030];
   National Key RD Plan of China [2017YFB1002804]
FX This work is supported by the National Natural Science Foundation of
   China under Grant Nos. 61772526 and 61473030, and the National Key R&D
   Plan of China under Grant No. 2017YFB1002804.
CR Ai SS, 2017, LECT NOTES COMPUT SC, V10132, P176, DOI 10.1007/978-3-319-51811-4_15
   [Anonymous], DEEP INSIDE CONVOLUT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], MULTIMEDIA SYSTEMS
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, IJCAI
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P 18 ACM INT C MULT
   [Anonymous], 2010, CALTECH UCSD BIRDS 2
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, PROC 28 INT C NEURAL
   Bai JF, 2014, IEEE IMAGE PROC, P2560, DOI 10.1109/ICIP.2014.7025518
   Chai LS, 2012, IEEE IMAGE PROC, P1941, DOI 10.1109/ICIP.2012.6467266
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Chen ZN, 2014, J COMPUT SCI TECH-CH, V29, P785, DOI 10.1007/s11390-014-1468-z
   Chen ZJ, 2011, NAT GENET, V43, P55, DOI 10.1038/ng.732
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   George M, 2014, LECT NOTES COMPUT SC, V8690, P440, DOI 10.1007/978-3-319-10605-2_29
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Jiang Yanfang, 2010, Mediators Inflamm, V2010, P143026, DOI 10.1155/2010/143026
   Khosla A., 2011, P CVPR WORKSHOP FINE, V2, P1
   Lei H, 2016, NEUROCOMPUTING, V208, P46, DOI 10.1016/j.neucom.2016.01.100
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Li ZT, 2018, IEEE T IMAGE PROCESS, V27, P4478, DOI 10.1109/TIP.2018.2839916
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lu SY, 2015, IEEE T CIRC SYST VID, V25, P1190, DOI 10.1109/TCSVT.2014.2372272
   Luo CZ, 2018, IEEE T IMAGE PROCESS, V27, P637, DOI 10.1109/TIP.2017.2745109
   Pan YW, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P53, DOI 10.1145/2766462.2767725
   Perronnin F, 2015, PROC CVPR IEEE, P3743, DOI 10.1109/CVPR.2015.7298998
   Qiu ZF, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P225, DOI 10.1145/3077136.3080842
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Simonyan K., 2015, P INT C LEARN REPR 2
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Mai TD, 2017, COMPUT VIS IMAGE UND, V156, P151, DOI 10.1016/j.cviu.2016.10.008
   Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276
   Wu Q, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2890104
   Xie HT, 2014, IEEE T MULTIMEDIA, V16, P1104, DOI 10.1109/TMM.2014.2305909
   Xie HT, 2011, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2011.6115596
   Xu K., 2015, COMPUTER SCI, P2048
   Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zhang CJ, 2018, INFORM SCIENCES, V422, P271, DOI 10.1016/j.ins.2017.09.024
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhu SA, 2014, COMPUT VIS IMAGE UND, V124, P79, DOI 10.1016/j.cviu.2014.03.010
NR 49
TC 27
Z9 28
U1 0
U2 31
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2019
VL 15
IS 1
SU S
AR 4
DI 10.1145/3231742
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HM9IU
UT WOS:000459798100004
DA 2024-07-18
ER

PT J
AU Lokoc, J
   Kovalcík, G
   Münzer, B
   Schöffmann, K
   Bailer, W
   Gasser, R
   Vrochidis, S
   Nguyen, PA
   Rujikietgumjorn, S
   Barthel, KU
AF Lokoc, Jakub
   Kovalcik, Gregor
   Muenzer, Bernd
   Schoeffmann, Klaus
   Bailer, Werner
   Gasser, Ralph
   Vrochidis, Stefanos
   Phuong Anh Nguyen
   Rujikietgumjorn, Sitapa
   Barthel, Kai Uwe
TI Interactive Search or Sequential Browsing? A Detailed Analysis of the
   Video Browser Showdown 2018
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Interactive video retrieval; video browsing; content-based methods;
   evaluation campaigns
ID OF-THE-ART; RETRIEVAL; USER
AB This work summarizes the findings of the 7th iteration of the Video Browser Showdown (VBS) competition organized as a workshop at the 24th International Conference on Multimedia Modeling in Bangkok. The competition focuses on video retrieval scenarios in which the searched scenes were either previously observed or described by another person (i.e., an example shot is not available). During the event, nine teams competed with their video retrieval tools in providing access to a shared video collection with 600 hours of video content. Evaluation objectives, rules, scoring, tasks, and all participating tools are described in the article. In addition, we provide some insights into how the different teams interacted with their video browsers, which was made possible by a novel interaction logging mechanism introduced for this iteration of the VBS. The results collected at the VBS evaluation server confirm that searching for one particular scene in the collection when given a limited time is still a challenging task for many of the approaches that were showcased during the event. Given only a short textual description, finding the correct scene is even harder. In ad hoc search with multiple relevant scenes, the tools were mostly able to find at least one scene, whereas recall was the issue for many teams. The logs also reveal that even though recent exciting advances in machine learning narrow the classical semantic gap problem, user-centric interfaces are still required to mediate access to specific content. Finally, open challenges and lessons learned are presented for future VBS events.
C1 [Lokoc, Jakub; Kovalcik, Gregor] Charles Univ Prague, Fac Math & Phys, Malostranske Nam 25, CR-11800 Prague, Czech Republic.
   [Muenzer, Bernd; Schoeffmann, Klaus] Klagenfurt Univ, Inst Informat Technol, Klagenfurt, Austria.
   [Bailer, Werner] JOANNEUM RES, Inst Informat & Commun Technol, Steyrergasse 17, A-8010 Graz, Austria.
   [Gasser, Ralph] Univ Basel, Dept Math & Comp Sci, CH-4051 Basel, Switzerland.
   [Vrochidis, Stefanos] Ctr Res & Technol Hellas, Informat Technol Inst, 6th Klm Charilaou Thermi Rd, Thessaloniki 57001, Greece.
   [Phuong Anh Nguyen] City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Tatchee Ave, Hong Kong, Peoples R China.
   [Rujikietgumjorn, Sitapa] Natl Elect & Comp Technol Ctr, Khlong Nueng, Thailand.
   [Barthel, Kai Uwe] HTW Berlin, Visual Comp Grp, Wilhelminenhofstr 75a, D-12459 Berlin, Germany.
C3 Charles University Prague; University of Klagenfurt; University of
   Basel; Centre for Research & Technology Hellas; City University of Hong
   Kong; National Science & Technology Development Agency - Thailand;
   National Electronics & Computer Technology Center (NECTEC)
RP Lokoc, J (corresponding author), Charles Univ Prague, Fac Math & Phys, Malostranske Nam 25, CR-11800 Prague, Czech Republic.
EM lokoc@ksi.mff.cuni.cz; gregor.kovalcik@gmail.com; bernd@itec.aau.at;
   ks@itec.aau.at; werner.bailer@joanneum.at; ralph.gasser@unibas.ch;
   stefanos@iti.gr; panguyen2-c@my.city.edu.hk; sitapa.ruj@nectec.or.th;
   Kai-Uwe.Barthel@HTW-Berlin.de
RI Nguyen, Phuong Anh/AAQ-4427-2021; Lokoč, Jakub/P-1216-2017
OI Nguyen, Phuong Anh/0000-0003-1289-3785; Watcharapinchai
   (Rujikietgumjorn), Sitapa/0000-0001-6691-1243; Gasser, Ralph Marc
   Philipp/0000-0002-3016-1396; Vrochidis, Stefanos/0000-0002-2505-9178
FU Czech Science Foundation (GACR) [17-22224S]; Universitat Klagenfurt;
   European Regional Development Fund; Carinthian Economic Promotion Fund
   (KWF) [KWF 20214 u. 3520/26336/38165]; Horizon 2020 Research and
   Innovation Programme V4Design [779962]; Research Grants Council of the
   Hong Kong Special Administrative Region, China [CityU 11250716];
   CHIST-ERA project IMOTION; Swiss National Science Foundation (SNSF)
   [20CH21_151571]; Lakeside Labs GmbH, Klagenfurt, Austria; Swiss National
   Science Foundation (SNF) [20CH21_151571] Funding Source: Swiss National
   Science Foundation (SNF); H2020 - Industrial Leadership [779962] Funding
   Source: H2020 - Industrial Leadership
FX This work was supported by Czech Science Foundation (GACR) project no.
   17-22224S. Parts of this work were supported by Universitat Klagenfurt
   and Lakeside Labs GmbH, Klagenfurt, Austria, and funding from the
   European Regional Development Fund and the Carinthian Economic Promotion
   Fund (KWF) under grant KWF 20214 u. 3520/26336/38165. Part of this
   research received funding from the Horizon 2020 Research and Innovation
   Programme V4Design, under grant agreement no. 779962. Parts of this work
   were supported by a grant from the Research Grants Council of the Hong
   Kong Special Administrative Region, China (CityU 11250716). Work on
   VITRIVR was partly supported by the CHIST-ERA project IMOTION, with
   contributions from the Swiss National Science Foundation (SNSF, contract
   no. 20CH21_151571).
CR [Anonymous], 2015, ARXIV151107571
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, ARXIV160305027
   [Anonymous], P 2018 ACM WORKSH LI
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], MASTERING ELASTICSEA
   [Anonymous], COLLABORATIVE FEATUR
   [Anonymous], 2016, MULTIMEDIA MODELING
   [Anonymous], BIG DATA ANAL LARGE
   [Anonymous], P 15 INT WORKSH CONT
   [Anonymous], P 17 ANNUALTREC VID
   [Anonymous], 2015, NEURAL INFORM PROCES
   [Anonymous], 2010, LUCENE ACTION 2 EDIT
   Barthel Kai Uwe, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P237, DOI 10.1007/978-3-319-14442-9_21
   Cobârzan C, 2017, MULTIMED TOOLS APPL, V76, P5539, DOI 10.1007/s11042-016-3661-2
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Giangreco Ivan, 2016, Datenbank-Spektrum, V16, P17, DOI 10.1007/s13222-015-0209-y
   Ivory MY, 2001, ACM COMPUT SURV, V33, P470, DOI 10.1145/503112.503114
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kohonen T, 1998, NEUROCOMPUTING, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Larson M, 2017, IEEE MULTIMEDIA, V24, P93, DOI 10.1109/MMUL.2017.9
   Leibetseder A, 2018, LECT NOTES COMPUT SC, V10705, P425, DOI 10.1007/978-3-319-73600-6_45
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Lokoc J, 2018, IEEE T MULTIMEDIA, V20, P3361, DOI 10.1109/TMM.2018.2830110
   Lokoc J, 2018, LECT NOTES COMPUT SC, V10705, P419, DOI 10.1007/978-3-319-73600-6_44
   Lu YJ, 2017, LECT NOTES COMPUT SC, V10133, P463, DOI 10.1007/978-3-319-51814-5_42
   Nguyen PA, 2018, LECT NOTES COMPUT SC, V10705, P407, DOI 10.1007/978-3-319-73600-6_42
   Primus MJ, 2018, LECT NOTES COMPUT SC, V10705, P438, DOI 10.1007/978-3-319-73600-6_47
   Rossetto L, 2018, LECT NOTES COMPUT SC, V10705, P403, DOI 10.1007/978-3-319-73600-6_41
   Rossetto L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1183, DOI 10.1145/2964284.2973797
   Rossetto L, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P18, DOI 10.1109/ISM.2014.38
   Rujikietgumjorn S, 2018, LECT NOTES COMPUT SC, V10705, P431, DOI 10.1007/978-3-319-73600-6_46
   Schoeffmann K., 2010, SPIE Reviews, V1, P018004, DOI DOI 10.1117/6.0000005
   Schoeffmann K, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2808796
   Schoeffmann K, 2014, IEEE MULTIMEDIA, V21, P8, DOI 10.1109/MMUL.2014.56
   Shyu ML, 2008, IEEE T MULTIMEDIA, V10, P252, DOI 10.1109/TMM.2007.911830
   Simonyan K., 2014, 14091556 ARXIV
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Truong TD, 2018, LECT NOTES COMPUT SC, V10705, P451, DOI 10.1007/978-3-319-73600-6_49
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Worring M, 2012, IEEE MULTIMEDIA, V19, P6, DOI 10.1109/MMUL.2012.53
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 47
TC 37
Z9 37
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2019
VL 15
IS 1
AR 29
DI 10.1145/3295663
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HM9JB
UT WOS:000459798800013
DA 2024-07-18
ER

PT J
AU Li, L
   Zhu, XG
   Hao, YM
   Wang, SH
   Gao, XY
   Huang, QM
AF Li, Liang
   Zhu, Xinge
   Hao, Yiming
   Wang, Shuhui
   Gao, Xingyu
   Huang, Qingming
TI A Hierarchical CNN-RNN Approach for Visual Emotion Classification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Visual emotion recognition; multi-task learning; feature fusing;
   hierarchical CNN-RNN; stacked bi-directional RNN
ID IMAGE RETRIEVAL
AB Visual emotion classification is predicting emotional reactions of people for the given visual content. Psychological studies show that human emotions are affected by various visual stimuli from low level to high level, including contrast, color, texture, scene, object, and association, among others. Traditional approaches regarded different levels of stimuli as independent components and ignored to effectively fuse different stimuli. This article proposes a hierarchical convolutional neural network (CNN)-recurrent neural network (RNN) approach to predict the emotion based on the fused stimuli by exploiting the dependency among different-level features. First, we introduce a dual CNN to extract different levels of visual stimulus, where two related loss functions are designed to learn the stimuli representation under a multi-task learning structure. Further, to model the dependency between the low- and high-level stimulus, a stacked bi-directional RNN is proposed to fuse the preceding learned features from the dual CNN. Comparison experiments on one large-scale and three small scale datasets show that the proposed approach brings significant improvement. Ablation experiments demonstrate the effectiveness of different modules from our model.
C1 [Li, Liang; Wang, Shuhui] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, CAS, 6 Kexueyuan South Rd, Beijing 100190, Peoples R China.
   [Zhu, Xinge; Huang, Qingming] Univ Chinese Acad Sci, Sch Comp Sci & Technol, 19 A Yuquan Rd, Beijing 100049, Peoples R China.
   [Hao, Yiming] Shandong Univ, Shanda South Rd 27, Jinan 250100, Peoples R China.
   [Gao, Xingyu; Huang, Qingming] Chinese Acad Sci, Beijing, Peoples R China.
   [Huang, Qingming] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Gao, Xingyu] Chinese Acad Sci, Inst Microelect, Beijing 100029, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Shandong University; Chinese Academy of Sciences; Peng Cheng
   Laboratory; Chinese Academy of Sciences; Institute of Microelectronics,
   CAS
RP Wang, SH (corresponding author), Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, CAS, 6 Kexueyuan South Rd, Beijing 100190, Peoples R China.
EM liang.li@vipl.ict.ac.cn; zhuxinge15@mails.ucas.ac.cn;
   yiminghao@vipl.ict.ac.cn; wangshuhui@ict.ac.cn; gxy9910@gmail.com;
   qmhuang@ucas.ac.cn
RI Gao, Xingyu/AAL-3288-2021
OI Gao, Xingyu/0000-0002-4660-8092; Li, Liang/0000-0002-1943-8219
FU National MCF Energy RD Program [2018YFE0303100]; National Natural
   Science Foundation of China [61771457, 61732007, 61772494, 61672497,
   61836002, 61472389, 61702491, 61620106009, U1636214]; Key Research
   Program of Frontier Sciences, Chinese Academy of Sciences
   [QYZDJ-SSWSYS013]
FX This work was supported in part by the National MCF Energy R&D Program:
   2018YFE0303100; in part by National Natural Science Foundation of China:
   61771457, 61732007, 61772494, 61672497, 61836002, 61472389, 61702491,
   61620106009, and U1636214; and in part by the Key Research Program of
   Frontier Sciences, Chinese Academy of Sciences: QYZDJ-SSWSYS013.
CR [Anonymous], 2015, P ICLR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P ACM INT C MULT MM
   [Anonymous], P 2015 IEEE C COMP V
   [Anonymous], 2016, LEARNING MULTILEVEL
   [Anonymous], P ACM INT C MULT MM
   [Anonymous], 2015, P 32 INT C MACH LEAR
   [Anonymous], P 30 AAAI C ART INT
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], P INT C MULT MM 08
   [Anonymous], P INT C NEUR INF PRO
   Benini S, 2011, IEEE T MULTIMEDIA, V13, P1356, DOI 10.1109/TMM.2011.2163058
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Caruana R, 1998, LEARNING TO LEARN, P95, DOI 10.1007/978-1-4615-5529-2_5
   Chung J., 2015, P 28 INT C NEURAL IN, P2980
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Irie G, 2010, IEEE T MULTIMEDIA, V12, P523, DOI 10.1109/TMM.2010.2051871
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Kang H.-B., 2003, Proceedings of the 11th ACM International Conference on Multimedia, P259
   Lang P.J., 2008, A8 NIMH CTR STUD EM
   LANG PJ, 1979, PSYCHOPHYSIOLOGY, V16, P495, DOI 10.1111/j.1469-8986.1979.tb01511.x
   Li L, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1092, DOI 10.1145/3240508.3240649
   Li L, 2016, NEUROCOMPUTING, V174, P384, DOI 10.1016/j.neucom.2015.04.108
   Li L, 2015, J VIS COMMUN IMAGE R, V31, P231, DOI 10.1016/j.jvcir.2015.06.008
   Li L, 2013, IEEE MULTIMEDIA, V20, P13, DOI 10.1109/MMUL.2013.15
   Li L, 2012, IEEE T MULTIMEDIA, V14, P1401, DOI 10.1109/TMM.2012.2194993
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Rao TR, 2016, IEEE IMAGE PROC, P634, DOI 10.1109/ICIP.2016.7532434
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Sartori A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P311, DOI 10.1145/2733373.2806250
   Siersdorfer S., 2010, ACM MM, P715
   Solli M, 2009, LECT NOTES COMPUT SC, V5702, P573, DOI 10.1007/978-3-642-03767-2_70
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Tu YB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1014, DOI 10.1145/3123266.3123354
   Wang WN, 2008, IEEE IMAGE PROC, P117, DOI 10.1109/ICIP.2008.4711705
   Wei-Ning W, 2006, IEEE SYS MAN CYBERN, P3534, DOI 10.1109/ICSMC.2006.384667
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   Yuan ZS, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617500177
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao SC, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3233184
   Zhao SC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4669
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhou B., 2014, CORR, V1412, P6856
NR 52
TC 19
Z9 20
U1 1
U2 33
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2019
VL 15
IS 3
SU S
SI SI
AR 97
DI 10.1145/3359753
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LR5EU
UT WOS:000535718800013
DA 2024-07-18
ER

PT J
AU Koch, C
   Lode, M
   Stohr, D
   Rizk, A
   Steinmetz, R
AF Koch, Christian
   Lode, Moritz
   Stohr, Denny
   Rizk, Amr
   Steinmetz, Ralf
TI Collaborations on YouTube: From Unsupervised Detection to the Impact on
   Video and Channel Popularity
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE YouTube; collaborations; multichannel networks; face detection; face
   recognition; face clustering; unsupervised learning
AB YouTube is the most popular platform for streaming of user-generated videos. Nowadays, professional YouTubers are organized in so-called multichannel networks (MCNs). These networks offer services such as brand deals, equipment, and strategic advice in exchange for a share of the YouTubers' revenues. A dominant strategy to gain more subscribers and, hence, revenue is collaborating with other YouTubers. Yet, collaborations on YouTube have not been studied in a detailed quantitative manner. To close this gap, first, we collect a YouTube dataset covering video statistics over 3 months for 7,942 channels. Second, we design a framework for collaboration detection given a previously unknown number of persons featured in YouTube videos. We denote this framework, for the detection and analysis of collaborations in YouTube videos using a Deep Neural Network (DNN)-based approach, as CATANA. Third, we analyze about 2.4 years of video content and use CATANA to answer research questions guiding YouTubers and MCNs for efficient collaboration strategies. Thereby, we focus on (1) collaboration frequency and partner selectivity, (2) the influence of MCNs on channel collaborations, (3) collaborating channel types, and (4) the impact of collaborations on video and channel popularity. Our results show that collaborations are in many cases significantly beneficial regarding viewers and newly attracted subscribers for both collaborating channels, often showing more than 100% popularity growth compared with noncollaboration videos.
C1 [Koch, Christian; Lode, Moritz; Stohr, Denny; Rizk, Amr; Steinmetz, Ralf] Tech Univ Darmstadt, Multimedia Commun Lab, Rundeturmstr 10, D-64293 Darmstadt, Germany.
C3 Technical University of Darmstadt
RP Koch, C (corresponding author), Tech Univ Darmstadt, Multimedia Commun Lab, Rundeturmstr 10, D-64293 Darmstadt, Germany.
EM Christian.Koch@kom.tu-darmstadt.de; moritzlode@gmail.com;
   Denny.Stohr@kom.tu-darmstadt.de; Amr.Rizk@kom.tu-darmstadt.de;
   Ralf.Steinmetz@kom.tu-darmstadt.de
RI Littlejohn, Allison/AEA-0156-2022; Steinmetz, Patrick R.
   H./AAD-4093-2022
OI Koch, Christian/0000-0002-4994-7567; Steinmetz, Ralf/0000-0002-6839-9359
FU DFG as part of the Collaborative Research Centre 1053 MAKI
FX This work has been funded in part by the DFG as part of the
   Collaborative Research Centre 1053 MAKI (C3, B4).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2016, CMU-CS-16-118
   [Anonymous], 2011, IEEE C COMP VIS PATT
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2015, BRIT MACHINE VISION
   [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   [Anonymous], 2017, ARXIV170608612
   [Anonymous], 2016, EUR C COMP VIS ECCV
   Bhat D, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P62, DOI 10.1145/3083187.3083196
   Brodersen Anders, 2012, P 21 INT C WORLD WID, P241, DOI DOI 10.1145/2187836.2187870
   Cheng X., 2014, P 24 ACM WORKSHOP NE, P73, DOI [10.1145/2578260.2578274, DOI 10.1145/2578260.2578274]
   Figueiredo F., 2011, ACM INT C WEB SEARCH
   Gahan Brendan, 2015, BE SUCCESSFUL YOUTUB
   Gardner J, 2016, BUS HORIZONS, V59, P293, DOI 10.1016/j.bushor.2016.01.009
   Gielen Matt, 2015, BEST PRACTICES YOUTU
   Gugel Bertram, 2015, YOUTUBE UNIVERSUM VE
   Hayes Nick, 2008, INFLUENCER MARKETING
   Holmbom M., 2015, THESIS
   Huang G.B., 2008, PROC WORKSHOP FACES
   Koch Christian, 2017, IEEE INT C NETW SERV, P1
   Lode Moritz, 2018, ARXIV180702020
   Nwana AO, 2013, IEEE GLOB COMM CONF, P3138, DOI 10.1109/GLOCOM.2013.6831554
   Sandberg David, FACENET PROJECT REPO
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wilson C., 2009, ACM EUR C COMP SYST
   YouTube LLC, YOUTUBE STAT
   Zhang Kaipeng, MTCNN FACE DETECTION
   Zhou RJ, 2016, MULTIMED TOOLS APPL, V75, P6035, DOI 10.1007/s11042-015-3206-0
NR 28
TC 5
Z9 7
U1 1
U2 21
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2018
VL 14
IS 4
AR 89
DI 10.1145/3241054
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ4JB
UT WOS:000457139200011
DA 2024-07-18
ER

PT J
AU Wu, HY
   Palù, F
   Ranon, R
   Christie, M
AF Wu, Hui-Yin
   Palu, Francesca
   Ranon, Roberto
   Christie, Marc
TI Thinking Like a Director: Film Editing Patterns for Virtual
   Cinematographic Storytelling
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Film storytelling; editing; virtual cinematography; assisted creativity;
   3D animation
ID REPRESENTATION
AB This article introduces Film Editing Patterns (FEP), a language to formalize film editing practices and stylistic choices found in movies. FEP constructs are constraints, expressed over one or more shots from a movie sequence, that characterize changes in cinematographic visual properties, such as shot sizes, camera angles, or layout of actors on the screen. We present the vocabulary of the FEP language, introduce its usage in analyzing styles from annotated film data, and describe how it can support users in the creative design of film sequences in 3D. More specifically, (i) we define the FEP language, (ii) we present an application to craft filmic sequences from 3D animated scenes that uses FEPs as a high level mean to select cameras and perform cuts between cameras that follow best practices in cinema, and (iii) we evaluate the benefits of FEPs by performing user experiments in which professional filmmakers and amateurs had to create cinematographic sequences. The evaluation suggests that users generally appreciate the idea of FEPs, and that it can effectively help novice and medium experienced users in crafting film sequences with little training.
C1 [Wu, Hui-Yin] N Carolina State Univ, Raleigh, NC 27695 USA.
   [Palu, Francesca; Ranon, Roberto] Univ Udine, Dept Math Comp Sci & Phys, Via Belle Sci 206, I-33100 Udine, Italy.
   [Christie, Marc] Univ Rennes 1, IRISA, INRIA, Rennes, France.
   [Christie, Marc] INRIA Rennes Bretagne Atlanlique, IRISA, Campus Beaulieau, F-35042 Rennes, France.
C3 North Carolina State University; University of Udine; Universite de
   Rennes; Inria; Universite de Rennes
RP Wu, HY (corresponding author), N Carolina State Univ, Raleigh, NC 27695 USA.
EM huiyin_wu@ncsu.edu; roberto.ranon@uniud.it; marc.christie@irisa.fr
OI Wu, Hui-Yin/0000-0001-7315-210X
CR Amerson Dan., 2005, ADV COMPUTER ENTERTA, P369
   Bares WH, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P1101
   Bares William H., 2000, P AAAI SPRING S
   Christianson David B., 1996, P AAAI C ART INT
   Corridoni JM, 1998, PATTERN RECOGN, V31, P2027, DOI 10.1016/S0031-3203(98)00061-2
   Davis Nicholas., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems-CHI '13, P651, DOI DOI 10.1145/2470654.2470747
   DRUCKER SM, 1994, GRAPH INTER, P190
   Elson David K., 2007, P 3 C ART INT INT DI
   Galvane Q., 2013, P MOTION GAMES, P93
   Galvane Quentin, 2015, P AAAI C ART INT
   Jhala A, 2010, IEEE T COMP INTEL AI, V2, P69, DOI 10.1109/TCIAIG.2010.2046486
   Knuth D. E., 1977, SIAM Journal on Computing, V6, P323, DOI 10.1137/0206024
   Leake M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073653
   Li-Wei He, 1996, Computer Graphics Proceedings. SIGGRAPH '96, P217
   LINO C, 2011, P 19 ACM INT C MULT, P323, DOI DOI 10.1145/2072298.2072341
   Lino Christophe, 2015, T GRAPH, V34, P4
   Lino Christophe, 2010, P 2010 ACM SIGGRAPH, P139
   Rasheed Z, 2005, IEEE T CIRC SYST VID, V15, P52, DOI 10.1109/TCSVT.2004.839993
   Ronfard Remi, 2013, P AAAI WORKSH INT CI
   Svanera M., 2015, P INT WORKSH CONT BA
   Tavanapong W, 2004, IEEE T MULTIMEDIA, V6, P517, DOI 10.1109/tmm.2004.830810
   Thompson R., 2009, GRAMMAR OF THE SHOT
   Wang JH, 2003, VISUAL COMPUT, V19, P329, DOI 10.1007/s00371-002-0184-9
   Wu H.Y., 2017, P 2017 EUR WORKSH IN, DOI DOI 10.2312/WICED.20171068
   Wu Hui-Yin, 2016, P 2016 EUR WORKSH IN
   Zettl Herbert, 2007, SIGHT SOUND MOTION A
NR 26
TC 14
Z9 15
U1 4
U2 32
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2018
VL 14
IS 4
AR 81
DI 10.1145/3241057
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ4JB
UT WOS:000457139200003
OA Green Published
DA 2024-07-18
ER

PT J
AU Abdallah, M
   Griwodz, C
   Chen, KT
   Simon, G
   Wang, PC
   Hsu, CH
AF Abdallah, Maha
   Griwodz, Carsten
   Chen, Kuan-Ta
   Simon, Gwendal
   Wang, Pin-Chun
   Hsu, Cheng-Hsin
TI Delay-Sensitive Video Computing in the Cloud: A Survey
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multimedia; cloud computing; virtualization; optimization; networking;
   latency; quality of experience (QoE); quality of service (QoS);
   applications; architecture
ID SERVICE; ALGORITHMS; LATENCY; SYSTEM; CACHE; ART
AB While cloud servers provide a tremendous amount of resources for networked video applications, most successful stories of cloud-assisted video applications are presentational video services, such as YouTube and NetFlix. This article surveys the recent advances on delay-sensitive video computations in the cloud, which are crucial to cloud-assisted conversational video services, such as cloud gaming, Virtual Reality (VR), Augmented Reality (AR), and telepresence. Supporting conversational video services with cloud resources is challenging because most cloud servers are far away from the end users while these services incur the following stringent requirements: high bandwidth, short delay, and high heterogeneity. In this article, we cover the literature with a top-down approach: from applications and experience, to architecture and management, and to optimization in and outside of the cloud. We also point out major open challenges, hoping to stimulate more research activities in this emerging and exciting direction.
C1 [Abdallah, Maha] Sorbonne Univ, CNRS, Lab Informat Paris 6, 4 Pl Jussieu, F-75005 Paris, France.
   [Griwodz, Carsten] Univ Oslo, Gaustadalleen 23, N-0371 Oslo, Norway.
   [Griwodz, Carsten] Simula Res Lab, Martin Linges Vei 25, N-1325 Lysaker, Norway.
   [Chen, Kuan-Ta] Acad Sinica, 128,Sect 2,Acad Rd, Taipei 11529, Taiwan.
   [Simon, Gwendal] IMT Atlantique, 2 Rue Chataigneraie, F-35510 Cesson Sevigne, France.
   [Wang, Pin-Chun; Hsu, Cheng-Hsin] Natl Tsing Hua Univ, 101 Sect 2 Kuang Fu Rd, Hsinchu 300, Taiwan.
C3 Centre National de la Recherche Scientifique (CNRS); Sorbonne
   Universite; University of Oslo; Academia Sinica - Taiwan; IMT - Institut
   Mines-Telecom; IMT Atlantique; National Tsing Hua University
RP Abdallah, M (corresponding author), Sorbonne Univ, CNRS, Lab Informat Paris 6, 4 Pl Jussieu, F-75005 Paris, France.
EM Maha.Abdallah@lip6.fr; griff@ifi.uio.no; swc@iis.sinica.edu.tw;
   gwendal.simon@imt-atlantique.fr; synesthesian23@gmail.com;
   chsu@cs.nthu.edu.tw
RI Simon, Gwendal/Y-6950-2019
OI Simon, Gwendal/0000-0002-7282-918X
CR Adhikari VK, 2015, IEEE ACM T NETWORK, V23, P1984, DOI 10.1109/TNET.2014.2354262
   Adhikari VK, 2012, IEEE INFOCOM SER, P2521, DOI 10.1109/INFCOM.2012.6195644
   Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   Ahmad S, 2018, PEER PEER NETW APPL, V11, P44, DOI 10.1007/s12083-016-0495-7
   Alben L., 1996, INTERACTIONS, V3, P11, DOI [DOI 10.1145/235008.235010, 10.1145/235008.235010]
   Amento B, 2016, 2016 FIRST IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC 2016), P179, DOI 10.1109/SEC.2016.22
   [Anonymous], ROUND CLOUD COMP FOR
   [Anonymous], 2012, P ACM SIGMETRICS
   [Anonymous], 2013, P C INT MEAS C, DOI DOI 10.1145/2504730.2504752
   [Anonymous], 2017, ADV INTEL SYS RES
   [Anonymous], 2017, P 27 NOSSDAV, DOI DOI 10.1145/3083165.3083180
   [Anonymous], 2010, 2010 IEEE 3 INT C CL
   [Anonymous], P C CTR ADV STUD COL
   [Anonymous], P USENIX S NETW SYST
   [Anonymous], EURASIP J ADV SIGNAL
   [Anonymous], P INT C MULT SYST MM
   [Anonymous], 2014, P WORKSHOP MOBILE VI, DOI DOI 10.1145/2579465.2579468
   [Anonymous], 2011, ACM MULTIMEDIA
   [Anonymous], P WORKSH NETW OP SYS
   [Anonymous], P ACM SIGCOMM WORKSH
   [Anonymous], GONE FISHIN JUSTIN T
   [Anonymous], FRONTIERS MULTIMEDIA
   [Anonymous], 2015, P INT WORKSH NETW SY, DOI DOI 10.1109/NETGAMES.2015.7383002
   [Anonymous], 2015, ITU T REC G 107 E MO
   [Anonymous], CISC VIS NETW IND FO
   [Anonymous], THESIS
   [Anonymous], 2009, CIKM 09
   [Anonymous], P IEEE INT C COMM IC
   [Anonymous], P ACM C MULT SYST MM
   [Anonymous], THESIS
   [Anonymous], INT J COMPUTER GAMES
   [Anonymous], 2010, P 2010 ACM MULT WORK
   [Anonymous], 2014, P 13 ANN WORKSH NETW
   [Anonymous], EUROPEAN NETWORK QUA
   [Anonymous], IEEE COMMUNICATIONS
   [Anonymous], P ACM INT WORKSH NET
   [Anonymous], 2010, AKAMAI NETWORK PLATF
   [Anonymous], FRONTIERS MULTIMEDIA
   [Anonymous], 2017, 2017 9 INT C QUAL MU
   [Anonymous], P INT C MEAS MOD EV
   [Anonymous], J MEDIA MASS COMMUNI
   [Anonymous], P IEEE INT C MULT EX
   Barimani M, 2012, INT J QUAL STUD HEAL, V7, DOI 10.3402/qhw.v7i0.18183
   Barlas G, 2012, PARALLEL COMPUT, V38, P226, DOI 10.1016/j.parco.2012.02.001
   Barroso LuizAndre., 2009, DATACENTER COMPUTER, P1
   Beck MT, 2015, INT CONF INTELL NEXT, P38, DOI 10.1109/ICIN.2015.7073804
   Berger DS, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P483
   Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691
   Braud T, 2017, INT CON DISTR COMP S, P1796, DOI 10.1109/ICDCS.2017.48
   Briscoe B, 2016, IEEE COMMUN SURV TUT, V18, P2149, DOI 10.1109/COMST.2014.2375213
   Buyukkaya E, 2015, PEER PEER NETW APPL, V8, P276, DOI 10.1007/s12083-013-0231-5
   Cai W, 2016, IEEE ACCESS, V4, P7605, DOI 10.1109/ACCESS.2016.2590500
   Casas P, 2014, COMPUT NETW, V68, P149, DOI 10.1016/j.comnet.2014.01.008
   Casas P, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1352
   Chang Yu-Chun., 2011, IEEE INT WORKSHOP TE, P1, DOI [10.1109/CQR.2011.5996092, DOI 10.1109/ICME.2011.6012177]
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Choy S, 2014, MULTIMEDIA SYST, V20, P503, DOI 10.1007/s00530-014-0367-z
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Claypool M, 2016, CHI PLAY 2016: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION, P117, DOI 10.1145/2968120.2987743
   Claypool Mark, 2010, Proceedings of the 1st Annual ACM SIGMM Conference on Multimedia Systems, P215, DOI [10.1145/1730836.1730863, DOI 10.1145/1730836.1730863]
   Clincy V, 2013, PROCEEDINGS OF THE 2013 10TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P473, DOI 10.1109/ITNG.2013.79
   Corbillon X, 2017, IEEE ICC, DOI 10.1109/ICC.2017.7996611
   Cui Y, 2017, C LOCAL COMPUT NETW, P640, DOI 10.1109/LCN.2017.112
   Deber J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1827, DOI 10.1145/2702123.2702300
   Dehghan M, 2017, IEEE ACM T NETWORK, V25, P1635, DOI 10.1109/TNET.2016.2636843
   DiCioccio Lucas., 2010, Proceedings of the 2010 ACM SIGCOMM Workshop on Home Networks, P7, DOI DOI 10.1145/1851307.1851310
   DINH T, 2017, P IEEE INT C COMM IC, P1, DOI DOI 10.1109/WCNC.2017.7925612
   Dischinger M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P43
   Ebert JP, 2010, CONSCIOUS COGN, V19, P481, DOI 10.1016/j.concog.2009.10.002
   Feng Lao, 2012, 2012 IEEE International Symposium on Circuits and Systems - ISCAS 2012, P2905, DOI 10.1109/ISCAS.2012.6271923
   Feng Wu-Chang., 2003, Proceedings of the 2nd Workshop on Network and System Support for Games, Netgames '03, P173
   Fu Q, 2014, INT CONF SERVICE SCI, P169, DOI 10.1109/ICSS.2014.34
   Gaddam VR, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P204, DOI 10.1109/PCS.2015.7170076
   Gaddam VR, 2016, IEEE T MULTIMEDIA, V18, P1819, DOI 10.1109/TMM.2016.2586304
   Gammeter S., 2010, CVPR Workshops, P1
   Gao GY, 2015, IEEE T MULTIMEDIA, V17, P1286, DOI 10.1109/TMM.2015.2438713
   Gao YY, 2017, IEEE INT CONF CLOUD, P616, DOI 10.1109/CLOUD.2017.125
   García-Valls M, 2014, J SYST ARCHITECT, V60, P726, DOI 10.1016/j.sysarc.2014.07.004
   Giotsas V, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P446, DOI 10.1145/3098822.3098855
   Goel U, 2016, MOBICOM'16: PROCEEDINGS OF THE 22ND ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P176, DOI 10.1145/2973750.2973771
   Goel U, 2017, LECT NOTES COMPUT SC, V10176, P142, DOI 10.1007/978-3-319-54328-4_11
   Gourdin E, 2017, IEEE T NETW SERV MAN, V14, P22, DOI 10.1109/TNSM.2017.2649045
   GRUBER JG, 1981, IEEE T COMMUN, V29, P786, DOI 10.1109/TCOM.1981.1095070
   Guan HB, 2015, IEEE T PARALL DISTR, V26, P2434, DOI 10.1109/TPDS.2014.2350499
   Hameed A, 2016, COMPUTING, V98, P751, DOI 10.1007/s00607-014-0407-8
   Hang Yuan, 2010, 2010 International Conference on Green Computing (Green Comp), P375, DOI 10.1109/GREENCOMP.2010.5598292
   Harman G., 1990, Philosophical Perspectives, V4, P31, DOI [10.2307/2214186, DOI 10.2307/2214186]
   Hong HJ, 2015, IEEE T CLOUD COMPUT, V3, P42, DOI 10.1109/TCC.2014.2338295
   Houzé P, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511550
   Huang B.B., 2012, PROC ANTICOUNTERFEIT, P1
   Humphreys G, 2002, ACM T GRAPHIC, V21, P693, DOI 10.1145/566570.566639
   IJsselsteijn Wijnand., 2007, International Conference on Advances in Computer Entertainment Technology, V2, P27, DOI DOI 10.1007/978-1-60761-580-4
   Jarschel M., 2011, Proceedings of the 2011 Fifth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS), P330, DOI 10.1109/IMIS.2011.92
   Jarschel M, 2013, MATH COMPUT MODEL, V57, P2883, DOI 10.1016/j.mcm.2011.12.014
   Jeon M, 2016, IEEE ACCESS, V4, P6802, DOI 10.1109/ACCESS.2016.2616540
   Kämäräinen T, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P88, DOI 10.1145/3083187.3083191
   Kao CF, 2007, IEEE T MULTIMEDIA, V9, P221, DOI 10.1109/TMM.2006.886259
   Khan AUR, 2014, IEEE COMMUN SURV TUT, V16, P393, DOI 10.1109/SURV.2013.062613.00160
   Khan KA, 2013, IEEE I C ELECT CIRC, P317, DOI 10.1109/ICECS.2013.6815418
   Khan KA, 2012, 2012 20TH TELECOMMUNICATIONS FORUM (TELFOR), P190, DOI 10.1109/TELFOR.2012.6419180
   Laoutaris N, 2011, ACM SIGCOMM COMP COM, V41, P74, DOI 10.1145/2043164.2018446
   Leblet J, 2011, COMPUT COMMUN, V34, P1968, DOI 10.1016/j.comcom.2011.06.002
   Lee Y.-T., 2012, Network and Systems Support for Games (NetGames), 2012 11th Annual Workshop on, P1
   [李保松 Li Baosong], 2011, [高分子通报, Polymer Bulletin], P1
   Li Z, 2012, INT CONF NETW FUT, P6, DOI 10.1109/nof.2012.6463984
   Li ZY, 2017, IEEE T APPL SUPERCON, V27, DOI [10.1109/TASC.2016.2634326, 10.1142/S0218127417501553]
   Lin CF, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P655, DOI 10.1109/UIC-ATC.2012.72
   Lin CH, 2014, IEEE T COMPUT, V63, P335, DOI 10.1109/TC.2012.210
   Lin TY, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE WORKSHOPS (WCNCW), P111, DOI 10.1109/WCNCW.2013.6533324
   Liu JY, 2017, C LOCAL COMPUT NETW, P498, DOI 10.1109/LCN.2017.28
   Liu JX, 2016, ACSR ADV COMPUT, V68, P1, DOI 10.1145/3185504
   Liu Y, 2015, IEEE T CIRC SYST VID, V25, P1960, DOI 10.1109/TCSVT.2015.2450175
   Liu YN, 2016, IEEE T MULTIMEDIA, V18, P865, DOI 10.1109/TMM.2016.2538718
   Mauve M, 2000, LECT NOTES COMPUT SC, V1905, P199
   Messaoudi F, 2017, IEEE GLOB COMM CONF
   Messaoudi F, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3115934
   Messaoudi Farouk., 2015, 2015 international workshop on network and systems support for games (NetGames), P1
   Michiardi P, 2012, COMPUT NETW, V56, P2038, DOI 10.1016/j.comnet.2012.02.011
   Miettinen A. P., 2010, P 2 USENIX C HOT TOP, V10, P4
   Minh Khiem Ngo Quang., 2010, Proceedings of the first annual ACM SIGMM conference on Multimedia systems, P259, DOI DOI 10.1145/1730836.1730868
   Mouradian C, 2018, IEEE COMMUN SURV TUT, V20, P416, DOI 10.1109/COMST.2017.2771153
   Naveen K., 2015, 5th Workshop on All Things Cellular: Operations, P37
   Ng B., 2002, VRST 02, P163
   Pantel Lothar., 2002, NOSSDAV 02 P 12 INT, P23
   Passarella A, 2012, COMPUT COMMUN, V35, P1, DOI 10.1016/j.comcom.2011.10.005
   Pereira R., 2010, 2010 IEEE 3rd International Conference on Cloud Computing (CLOUD 2010), P482, DOI 10.1109/CLOUD.2010.73
   Politis I., 2017, IEEE INT C COMMUNICA, DOI [10.1109/ICC.2017.7996601, DOI 10.1109/ICC.2017.7996601]
   Quax Peter., 2004, NETGAMES 04, P152
   Raaen K., 2015, Proceedings of the 6th ACM Multimedia Systems Conference, MMSys 2015, P89
   Raaen K., 2014, 2014 13th Annual Workshop on Network and Systems Support for Games, P1
   Rahimi MR, 2014, MOBILE NETW APPL, V19, P133, DOI 10.1007/s11036-013-0477-4
   Rumble Stephen M., 2011, HOTOS, P11
   Sackl A, 2016, IEEE INT CONF COMM, P492, DOI 10.1109/ICCW.2016.7503835
   Samet N, 2017, INT WIREL COMMUN, P1350, DOI 10.1109/IWCMC.2017.7986481
   Sanchez Y, 2016, IEEE INT SYM MULTIM, P87, DOI [10.1109/ISM.2016.124, 10.1109/ISM.2016.0025]
   Satyanarayanan M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P1, DOI 10.4108/icst.mobicase.2014.257757
   Seedorf J, 2009, IEEE INT CONF PEER, P171, DOI 10.1109/P2P.2009.5284511
   Shea R, 2015, IEEE T CIRC SYST VID, V25, P2026, DOI 10.1109/TCSVT.2015.2450172
   Shi Shu., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P103, DOI [10.1145/2072298.2072313, DOI 10.1145/2072298.2072313]
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Smed J, 2002, ELECTRON LIBR, V20, P87, DOI 10.1108/02640470210424392
   Soyata T, 2012, 2012 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS (ISCC), P59, DOI 10.1109/ISCC.2012.6249269
   Suh K, 2007, IEEE J SEL AREA COMM, V25, P1706, DOI 10.1109/JSAC.2007.071209
   Sundaresan S, 2011, ACM SIGCOMM COMP COM, V41, P134, DOI 10.1145/2043164.2018452
   Taleb T, 2017, IEEE COMMUN MAG, V55, P38, DOI 10.1109/MCOM.2017.1600249CM
   Tan B, 2013, IEEE ACM T NETWORK, V21, P566, DOI 10.1109/TNET.2012.2208199
   Tang XY, 2002, PROC INT CONF PARAL, P287, DOI 10.1109/ICPP.2002.1040884
   Tomanek O, 2016, COMPUT NETW, V107, P104, DOI 10.1016/j.comnet.2016.06.011
   Tran TX, 2017, 2017 13TH ANNUAL CONFERENCE ON WIRELESS ON-DEMAND NETWORK SYSTEMS AND SERVICES (WONS), P165, DOI 10.1109/WONS.2017.7888772
   Valancius V., 2009, PROC CONEXT 09, P37, DOI DOI 10.1145/1658939.1658944
   Wang XF, 2014, IEEE COMMUN MAG, V52, P131, DOI 10.1109/MCOM.2014.6736753
   Wang YT, 2015, WIRELESS PERS COMMUN, V80, P1607, DOI 10.1007/s11277-014-2102-7
   Wu HM, 2013, IEEE INT CONF COMM, P728, DOI 10.1109/ICCW.2013.6649329
   Yi S., 2015, P 2015 WORKSH MOB BI, P37
   Yin H., 2009, Proceedings of ACM International Conference on Multimedia, P25
   Zhang HT, 2016, LECT NOTES COMPUT SC, V9784, P309, DOI 10.1007/978-3-319-42553-5_26
   Zhang WW, 2014, IEEE NETWORK, V28, P67, DOI 10.1109/MNET.2014.6963807
   Zhang WW, 2013, IEEE T WIREL COMMUN, V12, P4569, DOI 10.1109/TWC.2013.072513.121842
   Zhang WX, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P194, DOI 10.1145/3126686.3126739
   Zhang YH, 2016, IEEE T PARALL DISTR, V27, P1239, DOI 10.1109/TPDS.2015.2433916
   Zhang ZH, 2016, I C COMM SOFTW NET, P407, DOI 10.1109/ICCSN.2016.7586692
NR 161
TC 23
Z9 24
U1 1
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2018
VL 14
IS 3
SU S
AR 54
DI 10.1145/3212804
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HG9GD
UT WOS:000455314500002
DA 2024-07-18
ER

PT J
AU Kiess, J
   Kopf, S
   Guthier, B
   Effelsberg, W
AF Kiess, Johannes
   Kopf, Stephan
   Guthier, Benjamin
   Effelsberg, Wolfgang
TI A Survey on Content-Aware Image and Video Retargeting
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Image retargeting; image resizing; video retargeting; video resizing;
   seam carving; warping
ID SALIENCY DETECTION; VISUAL-ATTENTION; DEPTH; INFORMATION
AB This survey introduces the current state of the art in image and video retargeting and describes important ideas and technologies that have influenced the recent work. Retargeting is the process of adapting an image or video from one screen resolution to another to fit different displays, for example, when watching a wide screen movie on a normal television screen or a mobile device. As there has been considerable work done in this field already, this survey provides an overview of the techniques. It is meant to be a starting point for new research in the field. We include explanations of basic terms and operators, as well as the basic workflow of the different methods.
C1 [Kiess, Johannes; Guthier, Benjamin; Effelsberg, Wolfgang] Univ Mannheim, Dept Comp Sci 4, A5,6, D-68159 Mannheim, Germany.
   [Kopf, Stephan] Univ Appl Sci Dresden, Friedrich List Pl 1, D-01069 Dresden, Germany.
C3 University of Mannheim
RP Kiess, J (corresponding author), Univ Mannheim, Dept Comp Sci 4, A5,6, D-68159 Mannheim, Germany.
EM j.kiess@gmx.de; stephan.kopf@htw-dresden.de;
   guthier@informatik.uni-mannheim.de;
   effelsberg@informatik.uni-mannheim.de
OI Kopf, Stephan/0000-0002-1140-6685
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2014, P 5 ACM MULT SYST C
   [Anonymous], P 4 ACM C MULT SYST
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Bhatt Jwalant, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P55, DOI 10.1109/ICCE.2016.7430520
   Carlier Axel, 2010, P 18 ACM INT C MULT, P201
   Chen YX, 2015, NEUROCOMPUTING, V151, P645, DOI 10.1016/j.neucom.2014.05.089
   Cheng WH, 2007, IEEE T CIRC SYST VID, V17, P43, DOI 10.1109/TCSVT.2006.885717
   Chiang CK, 2009, IEEE T CIRC SYST VID, V19, P1588, DOI 10.1109/TCSVT.2009.2031462
   Choi Jiwon, 2015, J SIGNAL PROCESS SYS, P1
   Dahan MJ, 2012, VISUAL COMPUT, V28, P1181, DOI 10.1007/s00371-011-0667-7
   Dekel T, 2013, IEEE T PATTERN ANAL, V35, P2513, DOI 10.1109/TPAMI.2013.46
   Dong WM, 2012, J COMPUT SCI TECH-CH, V27, P121, DOI 10.1007/s11390-012-1211-6
   Dong WM, 2016, IEEE T VIS COMPUT GR, V22, P1088, DOI 10.1109/TVCG.2015.2440255
   Dong WM, 2014, IEEE T VIS COMPUT GR, V20, P111, DOI 10.1109/TVCG.2013.103
   Du Huan, 2014, VIDEO RETARGETING BA, P397
   Engelke U, 2015, IEEE SIGNAL PROC LET, V22, P705, DOI 10.1109/LSP.2014.2368136
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Furuta R., 2017, IEEE T CIRC SYST VID
   Gal R., 2006, P 17 EUROGRAPHICS C, P297, DOI DOI 10.2312/EGWR/EGSR06/297-303
   Gallea R, 2014, IEEE T MULTIMEDIA, V16, P971, DOI 10.1109/TMM.2014.2305917
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Grundmann M, 2010, PROC CVPR IEEE, P569, DOI 10.1109/CVPR.2010.5540165
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Guthier B, 2013, 2013 IEEE 11TH IVMSP WORKSHOP: 3D IMAGE/VIDEO TECHNOLOGIES AND APPLICATIONS (IVMSP 2013)
   Han DF, 2009, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2009.5459380
   Han JW, 2009, I SYMP CONSUM ELECTR, P518
   Han JW, 2013, IEEE T CIRC SYST VID, V23, P2009, DOI 10.1109/TCSVT.2013.2242594
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Hu WY, 2014, IEEE J EM SEL TOP C, V4, P70, DOI 10.1109/JETCAS.2014.2298259
   Hwang DS, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1029, DOI 10.1109/ICME.2008.4607613
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jhou WC, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P82, DOI 10.1109/ISM.2014.41
   Junle Wang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P669, DOI 10.1109/ICASSP.2014.6853680
   Kiess J., 2012, P 4 WORKSHOP MOBILE, P13, DOI DOI 10.1145/2151677.2151681
   Kiess J, 2012, IEEE INT CONF MULTI, P145, DOI 10.1109/ICMEW.2012.32
   Kiess J, 2012, PROC SPIE, V8304, DOI 10.1117/12.906386
   Kiess J, 2010, PROC SPIE, V7542, DOI 10.1117/12.840263
   Kim W, 2014, IEEE T CIRC SYST VID, V24, P646, DOI 10.1109/TCSVT.2013.2290579
   Kong Y, 2016, IEEE T VIS COMPUT GR, V22, P2564, DOI 10.1109/TVCG.2016.2515614
   KOPF S, 2006, P 14 ACM INT C MULT, P957
   Kopf S, 2014, IEEE IMAGE PROC, P2898, DOI 10.1109/ICIP.2014.7025586
   Kopf S, 2011, MULTIMED TOOLS APPL, V51, P819, DOI 10.1007/s11042-010-0717-6
   Kopf Stephan., 2009, MM 09, P321
   Kopf Stephan, 2009, P SOC PHOTO-OPT INS, V7256
   KRAHENBUHL P, 2009, ACM SIGGRAPH ASIA, P1
   Lee JS, 2012, IEEE J-STSP, V6, P684, DOI 10.1109/JSTSP.2012.2215006
   Lei JJ, 2017, IEEE T MULTIMEDIA, V19, P1442, DOI 10.1109/TMM.2017.2660440
   Li B, 2015, IEEE T IMAGE PROCESS, V24, P2811, DOI 10.1109/TIP.2015.2431441
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P1615, DOI 10.1109/TIP.2014.2305843
   Li S, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440755
   Li Yun, 2010, Proceedings of the 2010 Second World Congress on Software Engineering (WCSE 2010), P45, DOI 10.1109/WCSE.2010.42
   Liang Y, 2017, IEEE T VIS COMPUT GR, V23, P1099, DOI 10.1109/TVCG.2016.2517641
   Liang Y, 2013, IEEE COMPUT GRAPH, V33, P68, DOI 10.1109/MCG.2012.123
   Lien KC, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P571, DOI 10.1109/3DV.2015.70
   Lin SS, 2013, IEEE T VIS COMPUT GR, V19, P1677, DOI 10.1109/TVCG.2013.75
   Lin X, 2014, J ZHEJIANG U-SCI C, V15, P697, DOI 10.1631/jzus.C1400102
   Liu D, 2016, MULTIMED TOOLS APPL, V75, P12465, DOI 10.1007/s11042-014-2304-8
   Liu Feng, 2006, P ACM INT C MULT, P241, DOI DOI 10.1145/1180639.1180702
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Liu Y., 2015, COMPUT VIS MEDIA, V1, P119
   Ma L, 2012, IEEE J-STSP, V6, P626, DOI 10.1109/JSTSP.2012.2211996
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Mateescu VA, 2016, IEEE MULTIMEDIA, V23, P82, DOI 10.1109/MMUL.2015.59
   Nie YW, 2013, VISUAL COMPUT, V29, P785, DOI 10.1007/s00371-013-0830-4
   Niu YZ, 2012, IEEE T MULTIMEDIA, V14, P783, DOI 10.1109/TMM.2012.2186122
   Noh H., 2012, P 20 ACM INT C MULTI, P709, DOI DOI 10.1145/2393347.2396293
   Panozzo D, 2012, COMPUT GRAPH FORUM, V31, P229, DOI 10.1111/j.1467-8659.2012.03001.x
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Qi SY, 2016, IEEE T IMAGE PROCESS, V25, P2222, DOI 10.1109/TIP.2016.2528040
   Qiu Zhongyan, 2013, IMAGE RETARGETING CO, P200
   Qu Z, 2013, IEEE T MULTIMEDIA, V15, P1677, DOI 10.1109/TMM.2013.2267727
   Ran Gao, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457881
   Razzaghi P, 2015, MULTIMED TOOLS APPL, V74, P11517, DOI 10.1007/s11042-014-2249-y
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Ren TW, 2009, IEEE INT CON MULTI, P406, DOI 10.1109/ICME.2009.5202520
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Scharfenberger C, 2015, IEEE T IMAGE PROCESS, V24, P457, DOI 10.1109/TIP.2014.2380351
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Shao F, 2016, J DISP TECHNOL, V12, P22, DOI 10.1109/JDT.2015.2446973
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Takahashi K., 2010, P 3DTV C TRUE VIS CA, P1
   Vaquero D, 2010, PROC SPIE, V7798, DOI 10.1117/12.862419
   Wang BT, 2014, IEEE J EM SEL TOP C, V4, P82, DOI 10.1109/JETCAS.2014.2298313
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wang JQ, 2016, IEEE T CIRC SYST VID, V26, P2079, DOI 10.1109/TCSVT.2015.2493500
   Wang S., 2017, IEEE T CIRC SYST VID
   Wang SF, 2011, IEEE T IMAGE PROCESS, V20, P855, DOI 10.1109/TIP.2010.2076293
   Wang WW, 2014, SIGNAL PROCESS-IMAGE, V29, P1223, DOI 10.1016/j.image.2014.08.001
   Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594
   Wang YS, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778827
   Wang YS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964983
   Wang YS, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618473
   Wen-Jiin Tsai, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457847
   Wolf L, 2007, IEEE I CONF COMP VIS, P1418
   Wu Lifang, 2014, J MULTIMEDIA, V9, P4
   Yan B, 2017, IEEE T IMAGE PROCESS, V26, P2454, DOI 10.1109/TIP.2017.2681840
   Yan B, 2015, IEEE T CIRC SYST VID, V25, P15, DOI 10.1109/TCSVT.2014.2329374
   Yan B, 2014, IEEE T MULTIMEDIA, V16, P272, DOI 10.1109/TMM.2013.2286112
   Yan Z, 2014, INT CONF MEAS, P60, DOI 10.1109/ICMTMA.2014.21
   Zhang JY, 2014, IEEE T IMAGE PROCESS, V23, P797, DOI 10.1109/TIP.2013.2294541
   Zhang JY, 2012, INT CONF ACOUST SPEE, P837, DOI 10.1109/ICASSP.2012.6288014
   Zhang Lixia, 2015, SOFT COMPUT, P1
   Zhang LM, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886775
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P1538, DOI 10.1109/TMM.2015.2451954
   Zhang YB, 2016, INT CONF ACOUST SPEE, P1080, DOI 10.1109/ICASSP.2016.7471842
   Zhang Y, 2013, INT C DIGIT MANUF, P675, DOI 10.1109/ICDMA.2013.160
   Zhang YF, 2008, COMPUT GRAPH FORUM, V27, P1797, DOI 10.1111/j.1467-8659.2008.01325.x
NR 115
TC 12
Z9 12
U1 1
U2 32
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2018
VL 14
IS 3
AR 76
DI 10.1145/3231598
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GT7CI
UT WOS:000444677600009
DA 2024-07-18
ER

PT J
AU Huang, M
   Su, SZ
   Zhang, HB
   Cai, GR
   Gong, DY
   Cao, DL
   Li, SZ
AF Huang, Min
   Su, Song-Zhi
   Zhang, Hong-Bo
   Cai, Guo-Rong
   Gong, Dongying
   Cao, Donglin
   Li, Shao-Zi
TI Multifeature Selection for 3D Human Action Recognition
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Feature selection; action recognition
AB In mainstream approaches for 3D human action recognition, depth and skeleton features are combined to improve recognition accuracy. However, this strategy results in high feature dimensions and low discrimination due to redundant feature vectors. To solve this drawback, a multi-feature selection approach for 3D human action recognition is proposed in this paper. First, three novel single-modal features are proposed to describe depth appearance, depth motion, and skeleton motion. Second, a classification entropy of random forest is used to evaluate the discrimination of the depth appearance based features. Finally, one of the three features is selected to recognize the sample according to the discrimination evaluation. Experimental results show that the proposed multi-feature selection approach significantly outperforms other approaches based on single-modal feature and feature fusion.
C1 [Huang, Min; Su, Song-Zhi; Gong, Dongying; Cao, Donglin; Li, Shao-Zi] Xiamen Univ, Dept Cognit Sci, Fujian 361005, Peoples R China.
   [Huang, Min; Su, Song-Zhi; Gong, Dongying; Cao, Donglin; Li, Shao-Zi] Xiamen Univ, Fujian Key Lab Brain Inspired Comp Tech & Applica, Fujian 361005, Peoples R China.
   [Zhang, Hong-Bo] Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Cai, Guo-Rong] Jimei Univ, Comp Engn Coll, Xiamen 361021, Fujian, Peoples R China.
C3 Xiamen University; Xiamen University; Huaqiao University; Jimei
   University
RP Su, SZ (corresponding author), Xiamen Univ, Dept Cognit Sci, Fujian 361005, Peoples R China.; Su, SZ (corresponding author), Xiamen Univ, Fujian Key Lab Brain Inspired Comp Tech & Applica, Fujian 361005, Peoples R China.
EM huangmin@stu.xinu.edu.cn; ssz@xmu.edu.cn; hong8757@163.com;
   guorongcai.jmu@gmail.com; 31520141153290@stu.xinu.edu.cn;
   another@xmu.edu.cn; szlig@xmu.edu.cn
RI Li, SZ/G-3959-2010
FU Nature Science Foundation of China [61572409, U1705286, 61402386,
   81230087, 61571188, 61502182]; Natural Science Foundation of Fujian
   Province [2015J01253, 2016J01310, 2016J01309]; Fujian Province 2011
   Collaborative Innovation Center of TCM Health Management; Collaborative
   Innovation Center of Chinese Oolong Tea Industry-Collaborative
   Innovation Center (2011) of Fujian Province; Fujian Provincial Key
   Projects of Technology [2017H6015]
FX This work is supported by the Nature Science Foundation of China (No.
   61572409, No. U1705286, No. 61402386, No. 81230087, No. 61571188, and
   No. 61502182), the Natural Science Foundation of Fujian Province (No.
   2015J01253, No. 2016J01310, and No. 2016J01309), the Fujian Province
   2011 Collaborative Innovation Center of TCM Health Management, the
   Collaborative Innovation Center of Chinese Oolong Tea
   Industry-Collaborative Innovation Center (2011) of Fujian Province, and
   the Fujian Provincial Key Projects of Technology under grant 2017H6015.
CR Chaaraoui AA, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P91, DOI 10.1109/ICCVW.2013.19
   [Anonymous], P 2014 IEEE C COMP V
   [Anonymous], COMPUTER VISION IMAG
   [Anonymous], P 2014 IEEE C COMP V
   [Anonymous], P 2014 IEEE C COMP V
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Bracewell R. N, 1986, FOURIER TRANSFORM IT, V3rd
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen WB, 2015, J VIS COMMUN IMAGE R, V26, P182, DOI 10.1016/j.jvcir.2014.11.008
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Huang M, 2018, NEUROCOMPUTING, V291, P84, DOI 10.1016/j.neucom.2018.02.056
   Huang M, 2017, IET COMPUT VIS, V11, P301, DOI 10.1049/iet-cvi.2016.0252
   Jalal A, 2012, INDOOR BUILT ENVIRON, V21, P184, DOI 10.1177/1420326X11423163
   Jia XF, 2012, INT C PATT RECOG, P3001
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Meng., 2016, Proceedings 9th International Conference on Motion in Games, pp, P123
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu L., 2013, 23 INT JOINT C ART I
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Liu Y, 2014, IEEE IMAGE PROC, P833, DOI 10.1109/ICIP.2014.7025167
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Weston J., 2003, Journal of Machine Learning Research, V3, P1439, DOI 10.1162/153244303322753751
   Wu D, 2014, PROC INT CONF RECON
   Wu JX, 2016, IEEE T CYBERNETICS, V46, P2978, DOI 10.1109/TCYB.2015.2493538
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Yang R, 2015, LECT NOTES COMPUT SC, V9007, P37, DOI 10.1007/978-3-319-16814-2_3
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
NR 42
TC 7
Z9 7
U1 0
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2018
VL 14
IS 2
AR 45
DI 10.1145/3177757
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HQ1BK
UT WOS:000462131600001
DA 2024-07-18
ER

PT J
AU Tulilaulu, A
   Nelimarkka, M
   Paalasmaa, J
   Johnson, D
   Ventura, D
   Myllys, P
   Toivonen, H
AF Tulilaulu, Aurora
   Nelimarkka, Matti
   Paalasmaa, Joonas
   Johnson, Daniel
   Ventura, Dan
   Myllys, Petri
   Toivonen, Hannu
TI Data Musicalization
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Data musicalization; sonification; automated composition; music; data
   analysis; computational creativity
ID SONIFICATION
AB Data musicalization is the process of automatically composing music based on given data as an approach to perceptualizing information artistically. The aim of data musicalization is to evoke subjective experiences in relation to the information rather than merely to convey unemotional information objectively. This article is written as a tutorial for readers interested in data musicalization. We start by providing a systematic characterization of musicalization approaches, based on their inputs, methods, and outputs. We then illustrate data musicalization techniques with examples from several applications: one that perceptualizes physical sleep data as music, several that artistically compose music inspired by the sleep data, one that musicalizes on-line chat conversations to provide a perceptualization of liveliness of a discussion, and one that uses musicalization in a gamelike mobile application that allows its users to produce music. We additionally provide a number of electronic samples of music produced by the different musicalization applications.
C1 [Tulilaulu, Aurora; Paalasmaa, Joonas; Myllys, Petri; Toivonen, Hannu] Univ Helsinki, Dept Comp Sci, POB 68, FI-00014 Helsinki, Finland.
   [Tulilaulu, Aurora; Paalasmaa, Joonas; Myllys, Petri; Toivonen, Hannu] Univ Helsinki, Helsinki Inst Informat Technol, POB 68, FI-00014 Helsinki, Finland.
   [Nelimarkka, Matti] Aalto Univ, Dept Comp Sci, POB 15400, FI-00076 Aalto, Finland.
   [Nelimarkka, Matti] Univ Helsinki, Helsinki Inst Informat Technol, POB 15400, FI-00076 Aalto, Finland.
   [Johnson, Daniel; Ventura, Dan] Brigham Young Univ, Comp Sci Dept, Provo, UT 84602 USA.
C3 University of Helsinki; University of Helsinki; Aalto University;
   University of Helsinki; Brigham Young University
RP Tulilaulu, A (corresponding author), Univ Helsinki, Dept Comp Sci, POB 68, FI-00014 Helsinki, Finland.; Tulilaulu, A (corresponding author), Univ Helsinki, Helsinki Inst Informat Technol, POB 68, FI-00014 Helsinki, Finland.
EM tulilaulu@gmail.com; matti.nelimarkka@aalto.fi;
   joonas.paalasmaa@gmail.com; danj256@gmail.com; ventura@cs.byu.edu;
   petri.myllys@gmail.com; hannu.toivonen@helsinki.fi
RI Toivonen, Hannu TT/A-3657-2012; Paalasmaa, Joonas/E-5824-2010
OI Toivonen, Hannu TT/0000-0003-1339-8022; Nelimarkka,
   Matti/0000-0001-9867-692X; Tulilaulu, Aurora
   Elizabeth/0000-0002-9068-4172
FU Algorithmic Data Analysis (Algodan) Centre of Excellence of the Academy
   of Finland [118653]; European Commission [611733]; Finnish Funding
   Agency for Innovation, through LEAD-project
FX This work has been supported by the Algorithmic Data Analysis (Algodan)
   Centre of Excellence of the Academy of Finland (Grant 118653) and by the
   European Commission (FET grant 611733, ConCreTe). This work has also
   been supported by the Finnish Funding Agency for Innovation, through
   LEAD-project.
CR [Anonymous], P 2001 INT C AUD DIS
   [Anonymous], P 2 INT C COMP CREAT
   [Anonymous], P SIGCHI C HUM FACT
   [Anonymous], 2011, SONIFICATION HDB
   [Anonymous], P INT COMP MUS C ICM
   [Anonymous], MUSICAE SCI S, DOI DOI 10.1177/10298649020050S104
   [Anonymous], ATLOREACHPROC2016005
   [Anonymous], P 34 ANN INT C IEEE
   [Anonymous], P 32 ANN C COGN SCI
   [Anonymous], P INT C AUD DISPL
   [Anonymous], 2001, EMOTIONS SOCIAL PSYC
   [Anonymous], 1999, AISB S MUSICAL CREAT
   [Anonymous], P INT C AUD DISPL IC
   [Anonymous], MEDIA INT AUSTR INC
   [Anonymous], P 2002 INT C AUD DIS
   [Anonymous], P 7 C VIS 96 VIS 96
   [Anonymous], P INT C NEW INT MUS
   [Anonymous], P 21 INT C AUD DISPL
   [Anonymous], 1968, REIHE
   Barrass S, 2006, LEONARDO MUSIC J, V16, P13, DOI 10.1162/lmj.2006.16.13
   Bonebright T.L., 2011, SONIFICATION HDB, P111
   Bradner E., 1999, ECSCW'99. Proceedings of the Sixth European Conference on Computer Supported Cooperative Work, P139
   Bresin R, 2011, CORTEX, V47, P1068, DOI 10.1016/j.cortex.2011.05.009
   Cardoso A, 2009, AI MAG, V30, P15, DOI 10.1609/aimag.v30i3.2252
   Colton S, 2012, FRONT ARTIF INTEL AP, V242, P21, DOI 10.3233/978-1-61499-098-7-21
   Curtis R., 2004, COLL TEACH, V52, P143
   Fernández JD, 2013, J ARTIF INTELL RES, V48, P513, DOI 10.1613/jair.3908
   Essl G, 2009, ORGAN SOUND, V14, P197, DOI 10.1017/S1355771809000302
   Flowers J.H., 2005, ACM Transactions on Applied Perception, V2, P467472, DOI [DOI 10.1145/1101530.1101544, 10.1145/1101530.1101544]
   Grimmer J, 2013, POLIT ANAL, V21, P267, DOI 10.1093/pan/mps028
   Iber C., 2007, AASM MANUAL SCORING
   Jacucci G, 2014, LECT NOTES COMPUT SC, V8820, P3, DOI 10.1007/978-3-319-13500-7_1
   Johnson D., 2014, Proceedings of the 5th International Conference on Computational Creativity, P91
   Juslin P. N., 2001, Music and emotion: Theory and research, P309, DOI DOI 10.1093/OSO/9780192631886.003.0014
   Kantosalo A., 2016, P 7 INT C COMP CREAT, P77
   Levitin DJ, 2000, AIP CONF PROC, V517, P323, DOI 10.1063/1.1291270
   Lin YT, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2710015
   MADHYASTHA TM, 1995, IEEE SOFTWARE, V12, P45, DOI 10.1109/52.368264
   Monteith K., 2010, Proceedings of the First International Conference on Computational Creativity, P140
   Muscutt K, 2007, COMPUT MUSIC J, V31, P10, DOI 10.1162/comj.2007.31.3.10
   Oh Jieun., 2010, Proceedings of the International Conference on New Interfaces for Musical Expression, P82, DOI DOI 10.5281/ZENODO.1177871
   Paalasmaa J, 2015, IEEE J BIOMED HEALTH, V19, P1945, DOI 10.1109/JBHI.2014.2314144
   Paalasmaa J, 2011, IEEE ENG MED BIO, P3812, DOI 10.1109/IEMBS.2011.6090773
   Pennebaker J. W., 2007, Linguistic inquiry and word count (LIWC2007)
   Pousman Z., 2006, P WORK C ADV VIS INT, DOI [https://doi.org/10.1145/1133265.1133277, DOI 10.1145/1133265.1133277]
   Quinn M., 2001, Research set to music: The climate symphony and other sonifications of ice core, radar, DNA, seismic and solar wind data
   Roads Curtis., 1996, The Computer Music Tutorial
   Smith Robert., 2012, P INT C COMPUTATIONA, P160
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Toussaint Godfried, 2005, Proceedings of BRIDGES: Mathematical Connections in Art, Music, and Science, P47
   Tulilaulu Aurora, 2012, Advances in Intelligent Data Analysis XI. Proceedings 11th International Symposium, IDA 2012, P392, DOI 10.1007/978-3-642-34156-4_36
   Turchet L, 2017, IEEE T AFFECT COMPUT, V8, P241, DOI 10.1109/TAFFC.2016.2520924
   Turchet L, 2015, IEEE T AFFECT COMPUT, V6, P152, DOI 10.1109/TAFFC.2015.2416724
   Vickers P., 2006, P 12 INT C AUD DISPL
   Vickers P., 2005, ACM Transactions on Applied Perception (TAP), V2, P477, DOI DOI 10.1145/1101530.1101546
   Wang G., 2009, ICMC 2009, P283
NR 56
TC 2
Z9 2
U1 1
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2018
VL 14
IS 2
AR 47
DI 10.1145/3184742
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GG9BS
UT WOS:000432996000004
DA 2024-07-18
ER

PT J
AU Thirunarayanan, I
   Khetarpal, K
   Koppal, S
   Le Meur, O
   Shea, J
   Jain, E
AF Thirunarayanan, Ishwarya
   Khetarpal, Khimya
   Koppal, Sanjeev
   Le Meur, Olivier
   Shea, John
   Jain, Eakta
TI Creating Segments and Effects on Comics by Clustering Gaze Data
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Comics; effects
ID MODEL; ATTENTION
AB Traditional comics are increasingly being augmented with digital effects, such as recoloring, stereoscopy, and animation. An open question in this endeavor is identifying where in a comic panel the effects should be placed. We propose a fast, semi-automatic technique to identify effects-worthy segments in a comic panel by utilizing gaze locations as a proxy for the importance of a region. We take advantage of the fact that comic artists influence viewer gaze towards narrative important regions. By capturing gaze locations from multiple viewers, we can identify important regions and direct a computer vision segmentation algorithm to extract these segments. The challenge is that these gaze data are noisy and difficult to process. Our key contribution is to leverage a theoretical breakthrough in the computer networks community towards robust and meaningful clustering of gaze locations into semantic regions, without needing the user to specify the number of clusters. We present a method based on the concept of relative eigen quality that takes a scanned comic image and a set of gaze points and produces an image segmentation. We demonstrate a variety of effects such as defocus, recoloring, stereoscopy, and animations. We also investigate the use of artificially generated gaze locations from saliency models in place of actual gaze locations.
C1 [Thirunarayanan, Ishwarya; Khetarpal, Khimya] Univ Florida, Dept Elect & Comp Engn, 216 Larsen Hall, Gainesville, FL 32611 USA.
   [Koppal, Sanjeev] Univ Florida, 437 New Engn Bldg, Gainesville, FL 32611 USA.
   [Le Meur, Olivier] Univ Rennes 1, IRISA, Campus Univ Beaulieu, F-35042 Rennes, France.
   [Shea, John] Univ Florida, 439 New Engn Bldg,POB 116130, Gainesville, FL 32611 USA.
   [Jain, Eakta] Univ Florida, E540 CSE Bldg,POB 116120, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida; State
   University System of Florida; University of Florida; Universite de
   Rennes; State University System of Florida; University of Florida; State
   University System of Florida; University of Florida
RP Thirunarayanan, I (corresponding author), Univ Florida, Dept Elect & Comp Engn, 216 Larsen Hall, Gainesville, FL 32611 USA.
EM iiyengarthir@ufl.edu; kkhetarpal@ufl.edu; sjkoppal@ece.ufl.edu;
   olivier.le_meur@irisa.fr; jshea@ece.ufl.edu; ejain@cise.ufl.edu
OI Shea, John/0000-0003-3323-3575
CR Al-Showarah Suleyman, 2013, P 6 YORK DOCT S COMP, V1, P7
   Anjyo Ken, 2011, COMPUTER GRAPHICS FO, V30
   [Anonymous], 2009, P IEEE INT C COMP VI
   [Anonymous], 2006, ACM T GRAPH
   [Anonymous], 2016, MIT SALIENCY BENCHMA
   [Anonymous], 2016, ARXIV161001563
   [Anonymous], 2010, Technical Report
   [Anonymous], ACM T GRAPHICS
   [Anonymous], 2015, P IEEE C COMP VIS PA
   Aramaki Yuji, 2014, ACM SIGGRAPH 2014, P66
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   Blignaut P, 2009, ATTEN PERCEPT PSYCHO, V71, P881, DOI 10.3758/APP.71.4.881
   Borji A., 2015, P COMP VIS PATT REC
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Choi J., 2016, ARXIV160102852
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   ComicBookPlus, 2015, COM PUBL DOM
   Comichron, 2015, COM SAL DAT
   Cornia M., 2016, ARXIV160901064
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Goldberg JH., 2010, P ACMETRA 2010 S EYE, P227, DOI DOI 10.1145/1743666.1743721
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jain E., 2012, THESIS
   Jain Eakta., 2012, Proceedings of the ACM Symposium on Applied Perception, SAP '12, P55, DOI [DOI 10.1145/2338676.2338688, 10.1145/2338676.2338688]
   Judd T, 2011, J VISION, V11, DOI 10.1167/11.4.14
   Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56
   Karthikeyan S, 2015, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2015.7298944
   Katti H., 2010, P 18 ACM INT C MULT, P667
   Katti Harish, 2011, THESIS
   Kazi RH, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P351, DOI 10.1145/2556288.2556987
   Khetarpal Khimya, 2016, 2016 IEEE International Conference on Multimedia & Expo: Workshops (ICMEW), DOI 10.1109/ICMEW.2016.7574728
   Kholgade Natasha, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601209
   Kopf J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366159
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Le Meur O, 2016, VISION RES, V121, P72, DOI 10.1016/j.visres.2016.01.005
   Le Meur O, 2015, VISION RES, V116, P152, DOI 10.1016/j.visres.2014.12.026
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Merk I, 2002, BIOL CYBERN, V86, P111, DOI 10.1007/s004220100274
   Miniotas Darius, 2015, INFORM TECHNOLOGY CO, V36
   Mishra A, 2009, IEEE I CONF COMP VIS, P468, DOI 10.1109/ICCV.2009.5459254
   Mortensen E. N., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P191, DOI 10.1145/218380.218442
   Papadopoulos DP, 2014, LECT NOTES COMPUT SC, V8693, P361, DOI 10.1007/978-3-319-10602-1_24
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Salvucci DD, 2000, 2000 S EYE TRACKING, P71, DOI [10.1145/355017.355028, DOI 10.1145/355017.355028]
   Santella A., 2004, P S EYE TRACKING RES, P27, DOI DOI 10.1145/968363.968368
   Santella Anthony, 2006, P ACM C HUM FACT COM
   Shea JM, 2013, 2013 IEEE MILITARY COMMUNICATIONS CONFERENCE (MILCOM 2013), P131, DOI 10.1109/MILCOM.2013.32
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Srinivas S. S, 2015, ARXIV151002927
   Sugano Y, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2465780.2465784
   Sun M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P96
   SYKORA D., 2009, COMPUTER GRAPHICS FO, V28, P2
   Sykora D., 2003, C COMP GRAPH, P223, DOI [10.1145/984952.984989, DOI 10.1145/984952.984989]
   Tafaj E., 2012, P S EYE TRACK RES AP, P285, DOI DOI 10.1145/2168556.2168617
   Urruty Thierry, 2007, ACM T MULTIM COMPUT, V3, P5
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Xu XM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409070
   Zhang SH, 2009, IEEE T VIS COMPUT GR, V15, P618, DOI 10.1109/TVCG.2009.9
NR 62
TC 5
Z9 5
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2017
VL 13
IS 3
AR 24
DI 10.1145/3078836
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FD5TE
UT WOS:000407591900002
DA 2024-07-18
ER

PT J
AU Wang, S
   Cong, Y
   Fan, HJ
   Fan, BJ
   Liu, LQ
   Yang, YS
   Tang, YD
   Zhao, H
   Yu, H
AF Wang, Shuai
   Cong, Yang
   Fan, Huijie
   Fan, Baojie
   Liu, Lianqing
   Yang, Yunsheng
   Tang, Yandong
   Zhao, Huaici
   Yu, Haibin
TI Multi-Class Latent Concept Pooling for Computer-Aided Endoscopy
   Diagnosis
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Computer-aided diagnosis; multi-class; sparse dictionary learning;
   latent concept pooling; endoscopy
ID IMAGE CLASSIFICATION; DESCRIPTORS; FEATURES; RECOGNITION
AB Successful computer-aided diagnosis systems typically rely on training datasets containing sufficient and richly annotated images. However, detailed image annotation is often time consuming and subjective, especially for medical images, which becomes the bottleneck for the collection of large datasets and then building computer-aided diagnosis systems. In this article, we design a novel computer-aided endoscopy diagnosis system to deal with the multi-classification problem of electronic endoscopy medical records (EEMRs) containing sets of frames, while labels of EEMRs can be mined from the corresponding text records using an automatic text-matching strategy without human special labeling. With unambiguous EEMR labels and ambiguous frame labels, we propose a simple but effective pooling scheme called Multi-class Latent Concept Pooling, which learns a codebook from EEMRs with different classes step by step and encodes EEMRs based on a soft weighting strategy. In our method, a computer-aided diagnosis system can be extended to new unseen classes with ease and applied to the standard single-instance classification problem even though detailed annotated images are unavailable. In order to validate our system, we collect 1,889 EEMRs with more than 59K frames and successfully mine labels for 348 of them. The experimental results show that our proposed system significantly outperforms the state-of-the-art methods. Moreover, we apply the learned latent concept codebook to detect the abnormalities in endoscopy images and compare it with a supervised learning classifier, and the evaluation shows that our codebook learning method can effectively extract the true prototypes related to different classes from the ambiguous data.
C1 [Wang, Shuai; Cong, Yang; Fan, Huijie; Liu, Lianqing; Tang, Yandong; Zhao, Huaici; Yu, Haibin] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang, Peoples R China.
   [Wang, Shuai] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Fan, Baojie] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210003, Jiangsu, Peoples R China.
   [Yang, Yunsheng] Chinese Peoples Liberat Army Gen Hosp, Beijing 100853, Peoples R China.
   [Wang, Shuai; Cong, Yang; Fan, Huijie; Liu, Lianqing; Tang, Yandong; Zhao, Huaici; Yu, Haibin] Chinese Acad Sci, Shenyang Inst Automat, Shenyang 110016, Peoples R China.
C3 Chinese Academy of Sciences; Shenyang Institute of Automation, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Nanjing University of Posts & Telecommunications; Chinese People's
   Liberation Army General Hospital; Chinese Academy of Sciences; Shenyang
   Institute of Automation, CAS
RP Cong, Y (corresponding author), Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang, Peoples R China.; Cong, Y (corresponding author), Chinese Acad Sci, Shenyang Inst Automat, Shenyang 110016, Peoples R China.
EM shuaiwang@sia.cn; congyang81@gmail.com; fanhuijie@sia.cn;
   jobfbj@gmail.com; lianqingliu@sia.cn; sunny301ddc@126.com; ytang@sia.cn;
   hczhao@sia.cn; yhb@sia.cn
OI Wang, Shuai/0000-0003-3730-6401
FU NSFC [61375014, 61533015, U1613214, 61333019, 61401455]
FX This work was supported by NSFC (61375014, 61533015, U1613214, 61333019,
   and 61401455).
CR Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146
   [Anonymous], J MED SYST
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2020, MILITARY MED RES, DOI DOI 10.1186/s40779-020-0233-6
   [Anonymous], IEEE TPAMI
   [Anonymous], IEEE T INTELL TRANSP
   [Anonymous], LEUKEMIA
   [Anonymous], EUR C COMP VIS ECCV
   Baker ZK, 2005, IEEE T VLSI SYST, V13, P1179, DOI 10.1109/TVLSI.2005.859472
   Bashar MK, 2008, LECT NOTES COMPUT SC, V5242, P603, DOI 10.1007/978-3-540-85990-1_72
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Buchner AM, 2010, GASTROENTEROLOGY, V138, P834, DOI 10.1053/j.gastro.2009.10.053
   Chu XQ, 2010, LECT NOTES COMPUT SC, V6362, P522
   Codella N, 2014, LECT NOTES COMPUT SC, V8674, P487, DOI 10.1007/978-3-319-10470-6_61
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   He HS, 2016, IEEE J BIOMED HEALTH, V20, P848, DOI 10.1109/JBHI.2015.2419251
   Huang CR, 2008, IEEE T INF TECHNOL B, V12, P523, DOI 10.1109/TITB.2007.913128
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Li BP, 2015, MED PHYS, V42, P645, DOI 10.1118/1.4905164
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mozafari AS, 2016, PATTERN RECOGN, V56, P142, DOI 10.1016/j.patcog.2016.03.009
   Muto M, 2011, J GASTROENTEROL, V46, P998, DOI 10.1007/s00535-011-0419-5
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Pasolli E, 2014, IEEE T GEOSCI REMOTE, V52, P2217, DOI 10.1109/TGRS.2013.2258676
   Riaz F, 2012, IEEE T BIO-MED ENG, V59, P2893, DOI 10.1109/TBME.2012.2212440
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shahidi R, 2002, IEEE T MED IMAGING, V21, P1524, DOI 10.1109/TMI.2002.806597
   Shao ZZ, 2014, IEEE INT CONF ROBOT, P1290, DOI 10.1109/ICRA.2014.6907019
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Shenghua Gao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2809, DOI 10.1109/CVPR.2011.5995454
   Wang S, 2016, IEEE T BIO-MED ENG, V63, P2347, DOI 10.1109/TBME.2016.2530141
   Wu CH, 2007, IEEE T BIO-MED ENG, V54, P1199, DOI 10.1109/TBME.2006.889767
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yang JC, 2010, LECT NOTES COMPUT SC, V6315, P113, DOI 10.1007/978-3-642-15555-0_9
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yu XY, 2015, IEEE T CYBERNETICS, V45, P444, DOI 10.1109/TCYB.2014.2327246
   Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484
NR 52
TC 1
Z9 1
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2017
VL 13
IS 2
AR 15
DI 10.1145/3051481
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EV1VK
UT WOS:000401537300003
DA 2024-07-18
ER

PT J
AU Liu, JJ
   Kato, N
   Ujikawa, H
   Suzuki, K
AF Liu, Jiajia
   Kato, Nei
   Ujikawa, Hirotaka
   Suzuki, Kenichi
TI Device-to-Device Communication for Mobile Multimedia in Emerging 5G
   Networks
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE 5G; device-to-device communication; downlink; multichannel cellular
   network; overlay; stochastic geometry
ID BROADCAST MULTICAST SERVICE; VIDEO DELIVERY; ALLOCATION; LTE; CHALLENGES
AB Device-to-device (D2D) communication, which utilizes mobile devices located within close proximity for direct connection and data exchange, holds great promise for improving energy and spectrum efficiency of mobile multimedia in 5G networks. It has been observed that most available D2D-based works-considered only the single-cell scenario with a single BS. Such scenario-based schemes, although tractable and able to illustrate the relationship between D2D links and cellular links, failed to take into account the distribution of surrounding base stations and user equipments (UEs), as well as the accumulated interference from ongoing transmissions in other cells. Furthermore, the single-tier network with one BS considered in available works is far from the real 5G scenario in which multi-tier BSs are heterogeneously distributed among the whole network area. In light of such observations, we present in this article a model for network coverage probability and average rate analysis in a D2D communication overlaying a two-tier downlink cellular network, where nineteen macro base stations (MBSs) with pico base stations (PBSs) placed at the end point of macro cell (hexagons) borders are employed according to the 3GPP specifications, and mobile users are spatially distributed according to the homogeneous Poisson Point Process model. Each mobile UE is able to establish a D2D link with adjacent UEs or connect to a nearby macro or pico base station. Stochastic geometric analysis is adopted to characterize the intratier interference distribution within the MBS-tier, PBS-tier, and D2D-tier based on which network coverage probability and per-user average rate are derived with a careful consideration of important issues such as threshold value, SINR value, user density, content hit rate, spectrum allocation, and cell coverage range. Our results show that, even for the overlaying case, D2D communication can significantly improve network coverage probability and per-user average downlink rate. Another finding is that the frequency allocation for D2D communications should be carefully tuned according to network settings, which may result in totally different varying behaviors for the per-user average rate.
C1 [Liu, Jiajia] Xidian Univ, Sch Cyber Engn, State Key Lab Integrated Serv Networks, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.
   [Kato, Nei] Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi 9808579, Japan.
   [Ujikawa, Hirotaka; Suzuki, Kenichi] NTT Corp, Tokyo, Japan.
C3 Xidian University; Tohoku University; Nippon Telegraph & Telephone
   Corporation
RP Liu, JJ (corresponding author), Xidian Univ, Sch Cyber Engn, State Key Lab Integrated Serv Networks, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.
EM liujiajia@xidian.edu.cn; kato@it.is.tohoku.ac.jp;
   ujikawa.hirotaka@lab.ntt.co.jp; suzuki.kenichi@lab.ntt.co.jp
RI liu, jia/JAC-7852-2023; liu, jia/HKE-9796-2023; Liu,
   Jiayu/JCO-5073-2023; liu, jiajia/ISS-0316-2023; Yu, Kun/IAP-9807-2023;
   KATO, NEI/T-5892-2019; liu, jiajia/IUN-0901-2023; Liu,
   Jiajia/HJY-9021-2023; liu, jiayu/JCP-0511-2023; LIU,
   JIAJIA/HMD-9871-2023; Li, JW/HNC-1743-2023; li, jiawei/HOA-5023-2023
OI KATO, NEI/0000-0001-8769-302X; LIU, JIAJIA/0000-0003-4273-8866; 
FU A3 Foresight Program by the Japan Society for the Promotion of Science
   (JSPS); National Natural Science Foundation of China (NSFC); National
   Research Foundation of Korea (NRF); National Natural Science Foundation
   of China [61372073, 61373043, 61571370, 61472367, 61432015]; Fundamental
   Research Funds for the Central Universities [JB150314]; Key Program of
   NSFC-Guangdong Union Foundation [U1135002]
FX Part of this work was supported by the A3 Foresight Program by the Japan
   Society for the Promotion of Science (JSPS), the National Natural
   Science Foundation of China (NSFC), and the National Research Foundation
   of Korea (NRF). It was also supported by the National Natural Science
   Foundation of China under Grants 61372073, 61373043, 61571370, 61472367,
   and 61432015; the Fundamental Research Funds for the Central
   Universities under Grant JB150314; and by the Key Program of
   NSFC-Guangdong Union Foundation U1135002.
CR 3GPP, 2013, 36839 3GPP TS
   3GPP, 2011, 36913 3GPP TR
   Almowuena S, 2016, IEEE T MULTIMEDIA, V18, P102, DOI 10.1109/TMM.2015.2502067
   Andrews JG, 2011, IEEE T COMMUN, V59, P3122, DOI 10.1109/TCOMM.2011.100411.100541
   [Anonymous], IEEE WIR COMM NETW C
   Argyriou A, 2015, IEEE T MULTIMEDIA, V17, P736, DOI 10.1109/TMM.2015.2408254
   Avocanh Jean Thierry Stephen, 2014, IEEE ICC
   Awobuluyi Olatunde, 2015, IEEE INT C COMP INF
   Bangerter B, 2014, IEEE COMMUN MAG, V52, P90, DOI 10.1109/MCOM.2014.6736748
   Bao Xuan, 2013, INFOCOM 13
   Cao Y, 2017, IEEE SYST J, V11, P1822, DOI 10.1109/JSYST.2015.2449893
   Cha M, 2009, IEEE ACM T NETWORK, V17, P1357, DOI 10.1109/TNET.2008.2011358
   Chen X, 2015, IEEE ACM T NETWORK, V23, P1471, DOI 10.1109/TNET.2014.2329956
   Cisco, 2016, CISC VIS NETW IND GL
   Dong MX, 2015, IEEE WIREL COMMUN, V22, P50, DOI 10.1109/MWC.2015.7224727
   Dong MX, 2015, IEEE NETWORK, V29, P40, DOI 10.1109/MNET.2015.7166189
   Dong MX, 2014, IEEE CLOUD COMPUT, V1, P50, DOI 10.1109/MCC.2014.85
   Ghosh A, 2010, IEEE WIREL COMMUN, V17, P10, DOI 10.1109/MWC.2010.5490974
   Golrezaei N, 2014, IEEE T WIREL COMMUN, V13, P3665, DOI 10.1109/TWC.2014.2316817
   Gruber M, 2011, IEEE COMMUN MAG, V49, P176, DOI 10.1109/MCOM.2011.6094023
   Haenggi M, 2005, IEEE T INFORM THEORY, V51, P3584, DOI 10.1109/TIT.2005.855610
   Lau Chun Pong, 2016, IEEE SYSTEMS J PP, V99, P1
   Liu Jiajia, 2014, IEEE COMMUNICATI DEC
   Liu JK, 2015, IEEE NETWORK, V29, P46, DOI 10.1109/MNET.2015.7064902
   Liu Q, 2013, IEEE INT CON MULTI
   Liu Q, 2015, IEEE T CIRC SYST VID, V25, P1815, DOI 10.1109/TCSVT.2015.2400751
   Militano L, 2015, IEEE T BROADCAST, V61, P263, DOI 10.1109/TBC.2015.2400824
   Moubayed A, 2015, IEEE T BROADCAST, V61, P734, DOI 10.1109/TBC.2015.2492458
   Mushtaq MS, 2016, IEEE SYST J, V10, P749, DOI 10.1109/JSYST.2015.2435994
   Nardelli PHJ, 2012, IEEE T WIREL COMMUN, V11, P15, DOI 10.1109/TWC.2011.111211.101963
   Nasralla Moustafa M., 2013, IEEE ICC 13
   Pande A, 2013, IEEE MULTIMEDIA, V20, P88, DOI 10.1109/MMUL.2013.44
   Pantisano Francesco, 2014, 1 INT C 5G UB CONN 5
   Peng B, 2013, IEEE VTS VEH TECHNOL
   Piro G, 2011, IEEE T MULTIMEDIA, V13, P1052, DOI 10.1109/TMM.2011.2152381
   Ryu Seungwan, 2013, 2013 IEEE INT C MULT
   Scott-Hayward S, 2015, IEEE COMMUN MAG, V53, P240, DOI 10.1109/MCOM.2015.7010540
   Shi L, 2015, IEEE T WIREL COMMUN, V14, P6177, DOI 10.1109/TWC.2015.2449841
   Siris VA, 2015, 2015 IEEE 16TH INTERNATIONAL SYMPOSIUM ON A WORLD OF WIRELESS, MOBILE AND MULTIMEDIA NETWORKS (WOWMOM)
   Tassi A, 2015, IEEE J SEL AREA COMM, V33, P141, DOI 10.1109/JSAC.2014.2384231
   Trestian Ramona, 2015, IEEE ICC 15
   Urie A, 2013, BELL LABS TECH J, V18, P57, DOI 10.1002/bltj.21605
   Vukobratovic D, 2014, IEEE T MULTIMEDIA, V16, P277, DOI 10.1109/TMM.2013.2282129
   Wang Haichao, 2015, INT WIR COMM MOB COM
   Wang Q, 2015, IEEE T VEH TECHNOL, V64, P3755, DOI 10.1109/TVT.2014.2355594
   Wang SY, 2014, IEEE T VEH TECHNOL, V63, P2059, DOI 10.1109/TVT.2014.2312373
   Wang XF, 2014, IEEE COMMUN MAG, V52, P131, DOI 10.1109/MCOM.2014.6736753
   Wang Xiaofei, 2015, 48 HAW INT C SYST SC
   Wu D, 2015, IEEE COMMUN MAG, V53, P232, DOI 10.1109/MCOM.2015.7010539
   Wu D, 2014, IEEE T VEH TECHNOL, V63, P2093, DOI 10.1109/TVT.2014.2311580
   Zhang A, 2014, SCI WORLD J, V2014, P14
   Zhang X, 2014, IEEE NETWORK, V28, P46, DOI 10.1109/MNET.2014.6963804
   Zhao Quanxin, 2015, IEEE ICC 15
   Zheng QH, 2014, IEEE INT CON MULTI
   Zhuang Yanyan, 2011, GLOBECOM 11
   Zorba N, 2016, IEEE SYST J, V10, P797, DOI 10.1109/JSYST.2015.2456072
   Zou LH, 2013, IEEE INT SYM BROADB
NR 57
TC 17
Z9 18
U1 0
U2 24
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2016
VL 12
IS 5
SU S
AR 75
DI 10.1145/2983641
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ0VT
UT WOS:000392929700006
DA 2024-07-18
ER

PT J
AU Lin, YT
   Liu, IT
   Jang, JSR
   Wu, JL
AF Lin, Yin-Tzu
   Liu, I-Ting
   Jang, Jyh-Shing Roger
   Wu, Ja-Ling
TI Audio Musical Dice Game: A User-Preference-Aware Medley Generating
   System
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Design; Experimentation; Music editing; concatenating music;
   musical medley
ID SINGING VOICE
AB This article proposes a framework for creating user-preference-aware music medleys from users' music collections. We treat the medley generation process as an audio version of a musical dice game. Once the user's collection has been analyzed, the system is able to generate various pleasing medleys. This flexibility allows users to create medleys according to the specified conditions, such as the medley structure or the must-use clips. Even users without musical knowledge can compose medley songs from their favorite tracks. The effectiveness of the system has been evaluated through both objective and subjective experiments on individual components in the system.
C1 [Lin, Yin-Tzu; Liu, I-Ting; Wu, Ja-Ling] Natl Taiwan Univ, GINM, CML, Taipei 106, Taiwan.
   [Jang, Jyh-Shing Roger] Natl Taiwan Univ, GINM, Multimedia Informat Retrieval Lab MIR, Taipei 106, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Lin, YT (corresponding author), Natl Taiwan Univ, GINM, CML, CSIE Bldg 1,Sec 4,Roosevelt Rd, Taipei 106, Taiwan.
EM known@cmlab.csie.ntu.edu.tw; tinaliu@cmlab.csie.ntu.edu.tw;
   jang@mirlab.org; wjl@cmlab.csie.ntu.edu.tw
OI WU, JA-LING/0000-0002-3631-1551; JANG, JYH-SHING/0000-0002-7319-9095
CR [Anonymous], 2012, P S COMP MUS MULT RE
   [Anonymous], 2004, P INT COMP MUS C
   [Anonymous], P INT COMP MUS C
   [Anonymous], 2005, THESIS MIT
   [Anonymous], 2009, IEEE T AUDIO SPEECH
   [Anonymous], 1986, COMPUT MUSIC J
   [Anonymous], 2007, J NEW MUSIC RES
   Baccigalupo C, 2006, LECT NOTES ARTIF INT, V4106, P286
   Barrington L, 2010, IEEE T AUDIO SPEECH, V18, P602, DOI 10.1109/TASL.2009.2036306
   Burkhart Charles., 2005, ENGAGING MUSIC, P3
   Chiarandini Luca, 2011, P INT WORKSH MULT SI
   Cliff D., 2000, HP Lab. Tech. Rep.
   Cole R., 2012, Virginia Tech multimedia music dictionary
   Cope D., 1996, EXPT MUSICAL INTELLI
   Dannenberg R.B., 2006, INT COMPUTER MUSIC C, P352
   Davies M. E. P., 2013, P INT SOC MUS INF RE
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Flexer Arthur., 2008, ISMIR, P173, DOI DOI 10.5281/ZENODO.1418272
   Foote J, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P77, DOI 10.1145/319463.319472
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Griffin Garth, 2010, P INT C AC SPEECH SI
   Hanna P, 2007, J NEW MUSIC RES, V36, P267, DOI 10.1080/09298210801927861
   Hanna P, 2009, ACM-IEEE J CONF DIG, P101
   I-Ting Liu, 2013, P INT SOC MUS INF RE
   Ishizaki H., 2009, P INT SOC MUS INF RE, P135
   Kamalzadeh M., 2012, Proceedings of the 13th International Society for Music Information Retrieval Conference (ISMIR'12), P373
   Kobayashi Ryoho, 2003, P INT COMP MUS C
   Latham Alison., 2011, The Oxford Companion to Music
   Leonidas I., 2012, 2012 IEEE Sixth International Conference on Semantic Computing (ICSC 2012), P134, DOI 10.1109/ICSC.2012.18
   Li YP, 2007, IEEE T AUDIO SPEECH, V15, P1475, DOI 10.1109/TASL.2006.889789
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Lin Heng-Yi, 2009, P INT SOC MUS INF RE
   Lin QA, 2010, INT CONF ACOUST SPEE, P69, DOI 10.1109/ICASSP.2010.5496203
   Logan B, 2000, INT CONF ACOUST SPEE, P749
   Loy Gareth, 2006, MUSIMATHICS, V1, p[295, 347]
   MADDAGE NC, 2004, P 12 ANN ACM INT C M, P112, DOI DOI 10.1145/1027527.1027549
   Ni YZ, 2012, IEEE T AUDIO SPEECH, V20, P1771, DOI 10.1109/TASL.2012.2188516
   Nieto O., 2014, Proc. of the 15th International Society for Music Information Retrieval Conference, P265
   Nwe T.L., 2004, 12 ANN ACM INT C MUL, P324
   Paulus J., 2010, Ismir, P625
   Pauwels Johan, 2013, P INT SOC MUS INF RE
   Randel MichaelDon., 2003, The Harvard Dictionary of Music, Vfourth
   Regnier L, 2009, INT CONF ACOUST SPEE, P1685, DOI 10.1109/ICASSP.2009.4959926
   Schwarz D., 2005, P INT COMP MUS C ICM
   Schwarz D., 2008, JOURN INF MUS
   Schwarz D, 2007, IEEE SIGNAL PROC MAG, V24, P92, DOI 10.1109/MSP.2007.323274
   Shan MK, 2010, MULTIMED TOOLS APPL, V46, P1, DOI 10.1007/s11042-009-0303-y
   Soleymani M., 2013, P 2 ACM INT WORKSH C, P1, DOI DOI 10.1145/2506364.2506365
   Su M.-Y., 2009, P 10 INT SOC MUS INF, P705
   Turnbull D., 2007, Proc. of the 5th International Society of Music Information Retrieval, P42
   Webber Stephen, 2007, DJ SKILLS ESSENTIAL, P212
   Weiss Ron J., 2010, P INT SOC MUS INF RE
   Wenger Stephan, 2011, P INT C MULT EXP
   ZAJONC RB, 1968, J PERS SOC PSYCHOL, V9, P1, DOI 10.1037/h0025848
   Zhang Liu, 2012, MULTIMEDIA SYST, V19, P359
NR 55
TC 6
Z9 6
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2015
VL 11
IS 4
AR 52
DI 10.1145/2710015
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CK0ZF
UT WOS:000355933700005
DA 2024-07-18
ER

PT J
AU Ye, J
   Hua, KA
AF Ye, Jun
   Hua, Kien A.
TI Octree-Based 3D Logic and Computation of Spatial Relationships in Live
   Video Query Processing
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Live video computing; live video database; spatial
   relationships; 3D reconstruction
AB Live video computing (LVC) on distributed smart cameras has many important applications; and a database approach based on a Live Video DataBase Management System (LVDBMS) has shown to be effective for general LVC application development. The performance of such a database system relies on accurate interpretation of spatial relationships among objects in the live video. With the popularity of affordable depth cameras, 3D spatial computation techniques have been applied. However, the 3D object models currently used are expensive to compute, and offer limited scalability. We address this drawback in this article by proposing an octree-based 3D spatial logic and presenting algorithms for computing 3D spatial relationships using depth cameras. To support continuous query processing on live video streams, we also develop a GPU-based implementation of the proposed technique to further enhance scalability for real-time applications. Extensive performance studies based on a public RGB-D dataset as well as the LVDBMS prototype demonstrates the correctness and efficiency of our techniques.
C1 [Ye, Jun; Hua, Kien A.] Univ Florida, Dept Comp Sci, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Ye, J (corresponding author), Univ Florida, Dept Comp Sci, Gainesville, FL 32611 USA.
EM kienhua@eecs.ucf.edu
FU National Science Foundation [CNS 0917082]
FX This material is based on work supported by the National Science
   Foundation under Grant Number CNS 0917082. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the authors and do not necessarily reflect the views of the National
   Science Foundation.
CR [Anonymous], P IEEE INT C ROB AUT
   Atrey P. K., 2009, P 1 ACM INT WORKSH E, P57
   Atrey PK, 2006, MULTIMEDIA SYST, V12, P239, DOI 10.1007/s00530-006-0063-8
   Aved AJ, 2012, MULTIMEDIA SYST, V18, P123, DOI 10.1007/s00530-011-0245-x
   Bloch I, 1999, IEEE T PATTERN ANAL, V21, P657, DOI 10.1109/34.777378
   Bloch I, 2006, IEEE T SYST MAN CY B, V36, P312, DOI 10.1109/TSMCB.2005.857095
   Borrmann Andre, 2007, P 24 CIB W78 C IT CO
   Coughlan J. M., 1999, P IEEE INT C COMPUTE, DOI DOI 10.1109/ICCV.1999.790349
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gapp Klaus-Peter, 1994, P 17 ANN C COGN SCI
   Jia ZY, 2013, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2013.8
   Kasper A., 2011, 2011 15th International Conference on Advanced Robotics, P421, DOI 10.1109/ICAR.2011.6088634
   Keller J. M., 1995, Proceedings of ISUMA - NAFIPS '95 The Third International Symposium on Uncertainty Modeling and Analysis and Annual Conference of the North American Fuzzy Information Processing Society (Cat. No.95TB8082), P679, DOI 10.1109/ISUMA.1995.527776
   Keller JM, 1996, FUZZ-IEEE '96 - PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P118, DOI 10.1109/FUZZY.1996.551729
   KUIPERS BJ, 1988, AI MAG, V9, P25
   MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6
   MIYAJIMA K, 1994, FUZZY SET SYST, V65, P225, DOI 10.1016/0165-0114(94)90021-3
   Peng R, 2010, INT J INTERDISCIP TE, V2, P27, DOI 10.4018/jitn.2010010103
   Rahman AMM, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1865106.1865112
   Rosman B, 2011, INT J ROBOT RES, V30, P1328, DOI 10.1177/0278364911408155
   Salamat N, 2012, PATTERN RECOGN, V45, P1559, DOI 10.1016/j.patcog.2011.09.005
   Takemura CM, 2012, PATTERN RECOGN, V45, P757, DOI 10.1016/j.patcog.2011.06.016
   TASHIRO Y, 1977, ANN I STAT MATH, V29, P295, DOI 10.1007/BF02532791
   Ye Jun., 2013, Proceedings of the 4th ACM Multimedia Systems Conference, MMSys 2013, P151, DOI DOI 10.1145/2483977.2483998
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
NR 25
TC 1
Z9 1
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2014
VL 11
IS 2
AR 28
DI 10.1145/2645864
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ6DM
UT WOS:000348308800005
DA 2024-07-18
ER

PT J
AU Deng, YH
   Lau, RWH
AF Deng, Yunhua
   Lau, Rynson W. H.
TI Dynamic Load Balancing in Distributed Virtual Environments using Heat
   Diffusion
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Performance; Multi-server architecture; DVE load balancing;
   heat diffusion; network latency
ID ALGORITHM
AB Distributed virtual environments (DVEs) are attracting a lot of attention in recent years, due to the increasing popularity of online gaming and social networks. As the number of concurrent users of a DVE increases, a critical problem is on how the workload among multiple servers can be balanced in order to maintain real-time performance. Although a number of load balancing methods have been proposed, they either try to produce high quality load balancing results and become too slow or emphasize on efficiency and the load balancing results become less effective. In this article, we propose a new approach to address this problem based on heat diffusion. Our work has two main contributions. First, we propose a local and a global load balancing methods for DVEs based on heat diffusion. Second, we investigate two performance factors of the proposed methods, the convergence threshold and the load balancing interval. We have conducted a number of experiments to extensively evaluate the performance of the proposed methods. Our experimental results show that the proposed methods outperform existing methods in that our methods are effective in reducing server overloading while at the same time being efficient.
C1 [Deng, Yunhua; Lau, Rynson W. H.] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Deng, YH (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
EM yunhua.deng@my.cityu.edu.hk; rynson.lau@cityu.edu.hk
OI LAU, Rynson W H/0000-0002-8957-8129
FU Research Grants Council of Hong Kong [CityU 116010, CityU 115112]
FX The work presented in this article was partially supported by two GRF
   grants from the Research Grants Council of Hong Kong (RGC Reference
   Numbers: CityU 116010 and CityU 115112).
CR Boillat J. E., 1990, Concurrency: Practice and Experience, V2, P289, DOI 10.1002/cpe.4330020403
   Chen Jin., 2005, PPOPP 05, P289
   CYBENKO G, 1989, J PARALLEL DISTR COM, V7, P279, DOI 10.1016/0743-7315(89)90021-X
   Deng YH, 2012, IEEE T VIS COMPUT GR, V18, P529, DOI 10.1109/TVCG.2012.52
   HORTON G, 1993, PARALLEL COMPUT, V19, P209, DOI 10.1016/0167-8191(93)90050-U
   Hu YF, 1998, CONCURRENCY-PRACT EX, V10, P467, DOI 10.1002/(SICI)1096-9128(199805)10:6<467::AID-CPE325>3.0.CO;2-A
   Hu YF, 1999, PARALLEL COMPUT, V25, P417, DOI 10.1016/S0167-8191(99)00002-2
   HU YF, 1998, COMPUTATIONAL DYNAMI, P177
   Johnson D.B., 1996, Mobile Computing, DOI DOI 10.1007/978-0-585-29603-65
   Lau R.W. H., 2010, Proc. Intl. Conf. Multimedia (MM '10), P1231
   Lee K., 2003, P ACM S VIRTUAL REAL, P160
   Liang HG, 2009, MULTIMED TOOLS APPL, V45, P163, DOI 10.1007/s11042-009-0304-x
   LIN FCH, 1987, IEEE T SOFTWARE ENG, V13, P32, DOI 10.1109/TSE.1987.232563
   Lui JCS, 2002, IEEE T PARALL DISTR, V13, P193, DOI 10.1109/71.993202
   Machado F, 2010, L N INST COMP SCI SO, V33, P44
   Muthukrishnan S, 1998, THEOR COMPUT SYST, V31, P331, DOI 10.1007/s002240000092
   Ng B., 2002, VRST 02, P163
   Ou CW, 1997, IEEE T PARALL DISTR, V8, P884, DOI 10.1109/71.605773
   Pittman D, 2010, LECT NOTES COMPUT SC, V5916, P87, DOI 10.1007/978-3-642-11301-7_12
   Prasetya K., 2008, Proc. 7th ACM SIGCOMM Workshop on Network and System Support for Games (NetGames '08), P72
   Steed A., 2003, VRST '03: Proceedings of the ACM symposium on Virtual reality software and technology, P7
   Ta D., 2011, J NETW COMPUTER APPL, V34, P551
   Ta DNB, 2009, W PRIN ADV DISTR SIM, P137, DOI 10.1109/PADS.2009.10
   Van Den Bossche B, 2009, J NETW COMPUT APPL, V32, P1242, DOI 10.1016/j.jnca.2009.04.001
   Watts J, 1998, IEEE T PARALL DISTR, V9, P235, DOI 10.1109/71.674316
   WILLEBEEKLEMAIR MH, 1993, IEEE T PARALL DISTR, V4, P979, DOI 10.1109/71.243526
NR 26
TC 10
Z9 10
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2014
VL 10
IS 2
AR 16
DI 10.1145/2499906
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB6DY
UT WOS:000331879000001
DA 2024-07-18
ER

PT J
AU Ghinea, G
   Ademoye, O
AF Ghinea, Gheorghita
   Ademoye, Oluwakemi
TI User Perception of Media Content Association in Olfaction-Enhanced
   Multimedia
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Experimentation; Human Factors; Olfaction; human-computer
   interaction; multimedia quality; quality of perception
ID ODOR; IMAGERY; NOSE
AB Olfaction is an exciting challenge facing multimedia applications. In this article we have investigated user perception of the association between olfactory media content and video media content in olfactory-enhanced multimedia. Results show that the association between scent and content has a significant impact on the user-perceived experience of olfactory-enhanced multimedia.
C1 [Ghinea, Gheorghita] Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England.
   [Ademoye, Oluwakemi] Swansea Metropolitan Univ, Sch Appl Comp, Swansea SA1 6ED, W Glam, Wales.
C3 Brunel University; Swansea Metropolitan University
RP Ghinea, G (corresponding author), Brunel Univ, Dept Informat Syst & Comp, Kingston Lane, Uxbridge UB8 3PH, Middx, England.
EM george.ghinea@brunel.ac.uk; kemi.ademoye@smu.ac.uk
RI Ghinea, Gheorghita/AAG-6770-2020
OI Ghinea, Gheorghita/0000-0003-2578-5580; Ademoye,
   Kemi/0000-0001-9597-4497
CR [Anonymous], 1995, NUTR FOOD SCI, V5, P24, DOI DOI 10.1108/00346659510094008
   Bodnar A, 2004, P 6 INT C MULTIMODAL, P183, DOI [10.1145/1027933.1027965, DOI 10.1145/1027933.1027965]
   Boyd-Davis S., 2006, P HUM FACT ERG SOC 2, P25
   Brewster S. A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P653
   Chastrette M, 2002, OLFACTION, TASTE, AND COGNITION, P100, DOI 10.1017/CBO9780511546389.012
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Djordjevic J, 2004, PSYCHOL SCI, V15, P143, DOI 10.1111/j.0956-7976.2004.01503001.x
   Dubois D, 2002, OLFACTION, TASTE, AND COGNITION, P47, DOI 10.1017/CBO9780511546389.009
   FOX K., 2007, THE SMELL REPORT THE
   FRAGRA, 2003, FRAGRA AN INTERACTIV
   Ghinea G., 1998, Proceedings ACM Multimedia 98, P49, DOI 10.1145/290747.290754
   GHINEA G., 2012, ACM TRANS MULTIMEDIA
   Ghinea G, 2010, IEEE T SYST MAN CY A, V40, P657, DOI 10.1109/TSMCA.2010.2041224
   Gottfried JA, 2003, NEURON, V39, P375, DOI 10.1016/S0896-6273(03)00392-1
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   Issanchou S, 2002, OLFACTION, TASTE, AND COGNITION, P211, DOI 10.1017/CBO9780511546389.020
   Jones L, 2004, HUMAN PERFORMANCE, SITUATION AWARENESS AND AUTOMATION: CURRENT RESEARCH AND TRENDS, VOL 2, P282
   Jumisko-Pyykko S., 2007, P SPIE, V6507
   Kaye J."J."., 2004, INTERACTIONS, V11, P48, DOI DOI 10.1145/962342.964333
   Kaye J. N., 2001, THESIS
   Keller A, 2004, CURR BIOL, V14, pR875, DOI 10.1016/j.cub.2004.09.066
   Köster EP, 2002, OLFACTION, TASTE, AND COGNITION, P27, DOI 10.1017/CBO9780511546389.007
   Mochizuki A., 2004, ACM SIGGRAPH 2004 Sketches, P123
   Morrot G, 2001, BRAIN LANG, V79, P309, DOI 10.1006/brln.2001.2493
   Nakamoto T, 2005, SENSOR LETT, V3, P136, DOI 10.1166/sl.2005.018
   Nakamoto T, 2005, SENSOR MATER, V17, P365
   Nakamoto T, 2008, IEEE COMPUT GRAPH, V28, P75, DOI 10.1109/MCG.2008.3
   RICHARD E., 2006, VIRT REAL, V10, P207
   Rowe LA, 2005, ACM T MULTIM COMPUT, V1, P3, DOI 10.1145/1047936.1047938
   SAKAI N., 2005, CHEM SENSES SUPP 1, V30, P1
   Stevenson RJ, 2005, PSYCHON B REV, V12, P244, DOI 10.3758/BF03196369
   Tijou A, 2006, LECT NOTES COMPUT SC, V3942, P1223, DOI 10.1007/11736639_152
   Washburn D., 2003, Modelling and Simulation Magazine, V2, P3
NR 33
TC 26
Z9 26
U1 2
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2012
VL 8
IS 4
AR 52
DI 10.1145/2379790.2379794
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 052QA
UT WOS:000312211900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, X
   Ward, T
   McLoone, S
AF Zhang, Xin
   Ward, Tomas
   McLoone, Seamus
TI Comparison of Predictive Contract Mechanisms from an Information Theory
   Perspective
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Measurements; Performance; Theory; Consistency; collaborative virtual
   environments; dead reckoning; distributed interactive applications;
   distributed interactive simulation; distributed virtual environments;
   networked multi-player computer games; networked virtual environments;
   predictive contract mechanisms
ID MUTUAL INFORMATION; CONSISTENCY; UPDATE
AB Inconsistency arises across a Distributed Virtual Environment due to network latency induced by state changes communications. Predictive Contract Mechanisms (PCMs) combat this problem through reducing the amount of messages transmitted in return for perceptually tolerable inconsistency. To date there are no methods to quantify the efficiency of PCMs in communicating this reduced state information. This article presents an approach derived from concepts in information theory for a deeper understanding of PCMs. Through a comparison of representative PCMs, the worked analysis illustrates interesting aspects of PCMs operation and demonstrates how they can be interpreted as a form of lossy information compression.
C1 [Zhang, Xin; Ward, Tomas; McLoone, Seamus] Natl Univ Ireland Maynooth, Dept Elect Engn, Maynooth, Kildare, Ireland.
C3 Maynooth University
RP Zhang, X (corresponding author), Natl Univ Ireland Maynooth, Dept Elect Engn, Maynooth, Kildare, Ireland.
EM xzhang@eeng.nuim.ie; tomas.ward@eeng.nuim.ie;
   seamus.mcloone@eeng.nuim.ie
RI Ward, Tomas/AEN-2410-2022
OI Ward, Tomas/0000-0002-6173-6607
FU Irish Research Council for Science, Engineering, and Technology
   (IRCSET); National Development Plan
FX This work is supported by the Irish Research Council for Science,
   Engineering, and Technology (IRCSET): funded by the National Development
   Plan.
CR [Anonymous], 2006, Elements of Information Theory
   [Anonymous], 15162000 IEEE
   [Anonymous], 1998, 12781A1998 IEEE
   CALVIN J, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P450, DOI 10.1109/VRAIS.1993.380745
   Capps M, 2000, IEEE COMPUT GRAPH, V20, P12, DOI 10.1109/38.865873
   Capps M, 1997, SIXTH IEEE WORKSHOPS ON ENABLING TECHNOLOGIES: INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES, PROCEEDINGS, P205, DOI 10.1109/ENABL.1997.630815
   Chen L, 2005, LECT NOTES ARTIF INT, V3614, P961
   DELANEY D, 2003, P 21 IASTED INT MULT
   Delaney D, 2006, PRESENCE-TELEOP VIRT, V15, P465, DOI 10.1162/pres.15.4.465
   El Saddik A, 2008, MULTIMED TOOLS APPL, V39, P353, DOI 10.1007/s11042-007-0165-0
   Frecon E., 1998, Distributed Systems Engineering, V5, P91, DOI 10.1088/0967-1846/5/3/002
   Hanawa D, 2005, 2005 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P279
   Hanawa D, 2006, 2006 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P107, DOI 10.1109/CW.2006.10
   Jeong J, 2001, CLIN NEUROPHYSIOL, V112, P827, DOI 10.1016/S1388-2457(01)00513-2
   Kenny A, 2009, ACM T INTERNET TECHN, V9, DOI 10.1145/1592446.1592449
   Kushner D, 2002, IEEE SPECTRUM, V39, P42, DOI 10.1109/MSPEC.2002.1021943
   LEE BS, 2000, INT J SIMULATION SYS, V1, P21
   Lloyd J., 2004, Game Devel. Mag, V11, P8
   McCoy A, 2005, SIMULATION IN WIDER EUROPE, P727
   McCoy A, 2007, ACM T MODEL COMPUT S, V17, DOI 10.1145/1276927.1276929
   Mellon L, 1995, 1995 WINTER SIMULATION CONFERENCE PROCEEDINGS, P634
   MILLER DC, 1995, P IEEE, V83, P1114, DOI 10.1109/5.400452
   MOON YI, 1995, PHYS REV E, V52, P2318, DOI 10.1103/PhysRevE.52.2318
   Pantel Lothar., 2002, NETGAMES 02 P 1 WORK, P79
   Roberts D, 2008, SIMUL-T SOC MOD SIM, V84, P239, DOI 10.1177/0037549708092221
   Singhal S., 1999, Networked Virtual Environments
   Steuer R, 2002, BIOINFORMATICS, V18, pS231, DOI 10.1093/bioinformatics/18.suppl_2.S231
   Yu SJ, 2001, COMPUT COMMUN, V24, P1745, DOI 10.1016/S0140-3664(01)00321-8
   Yu Y, 2007, IEEE IC COMP COM NET, P563
   Zhang X., 2008, INT J COMPUT GAMES T, V4, P1
   Zhang X, 2009, IEEE ACM DIS SIM, P121, DOI 10.1109/DS-RT.2009.23
   Zimmermann R, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352018
   Zukerman I, 2001, USER MODEL USER-ADAP, V11, P5, DOI 10.1023/A:1011175525451
NR 33
TC 6
Z9 6
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2012
VL 8
IS 2
AR 18
DI 10.1145/2168996.2168998
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 945BX
UT WOS:000304248900002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Cheng, X
   Liu, JC
AF Cheng, Xu
   Liu, Jiangchuan
TI Exploring Interest Correlation for Peer-to-Peer Socialized Video Sharing
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Measurement; Performance; YouTube; video on demand;
   peer-to-peer; social network
ID INTERNET
AB The last five years have witnessed an explosion of networked video sharing, represented by YouTube, as a new killer Internet application. Their sustainable development however is severely hindered by the intrinsic limit of their client/server architecture. A shift to the peer-to-peer paradigm has been widely suggested with success already shown in live video streaming and movie-on-demand. Unfortunately, our latest measurement demonstrates that short video clips exhibit drastically different statistics, which would simply render these existing solutions suboptimal, if not entirely inapplicable.
   Our long-term measurement over five million YouTube videos, on the other hand, reveals interesting social networks with strong correlation among the videos, thus opening new opportunities to explore. In this article, we present NetTube, a novel peer-to-peer assisted delivering framework that explores the user interest correlation for short video sharing. We address a series of key design issues to realize the system, including a bi-layer overlay, an efficient indexing scheme, a delay-aware scheduling mechanism, and a prefetching strategy leveraging interest correlation. We evaluate NetTube through both simulations and prototype experiments, which show that it greatly reduces the server workload, improves the playback quality and scales well.
C1 [Cheng, Xu; Liu, Jiangchuan] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Cheng, X (corresponding author), Simon Fraser Univ, Sch Comp Sci, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
EM jeliu@cs.sfu.ca
FU Canada NSERC; NSERC; NSERC DAS; MITACS
FX This research was supported by a Canada NSERC Strategic Project Grant,
   an NSERC Discovery Grant, an NSERC DAS Grant, and an MITACS Project
   Grant.
CR Aggarwal V., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P421, DOI DOI 10.1145/1631272.1631330
   Albert R, 1999, NATURE, V401, P130, DOI 10.1038/43601
   ALEXA, 2010, YOUT COM SIT INF
   [Anonymous], 2007, IMC 07 P 2007 ACM SI, DOI DOI 10.1145/1298306.1298310
   Benevenuto F, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P49
   BLOG O. Y, 2009, ZOINKS 20 HOURS VIDE
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Carter L., 2008, Web Could Collapse as Video Demand Soars
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Cha M, 2008, IMC'08: PROCEEDINGS OF THE 2008 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P71
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Cheng X, 2009, IEEE INFOCOM SER, P1152, DOI 10.1109/INFCOM.2009.5062028
   Cheng Xu., 2010, IEEE Transactions on Multimedia
   Corbett Colin., 2006, PEERING VIDEO
   Gopalakrishnan V, 2009, IEEE INFOCOM SER, P91, DOI 10.1109/INFCOM.2009.5061910
   Huang C, 2007, ACM SIGCOMM COMP COM, V37, P133, DOI 10.1145/1282427.1282396
   Huang Y, 2008, ACM SIGCOMM COMP COM, V38, P375, DOI 10.1145/1402946.1403001
   La Monica P. R., 2006, GOOGLE BUY YOUTUBE 1
   LAI K, 2010, P 20 INT WORKSH NETW
   Liang C, 2009, IEEE T MULTIMEDIA, V11, P348, DOI 10.1109/TMM.2009.2012909
   Liu JC, 2008, P IEEE, V96, P11, DOI 10.1109/JPROC.2007.909921
   Liu ZM, 2009, IEEE INFOCOM SER, P82, DOI 10.1109/INFCOM.2009.5061909
   Magharei N, 2009, NOSSDAV 09: 18TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P25
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   O'Reilly T., 2006, What Is Web 2.0: Design patterns and business models for the next generation of software
   Qiu XJ, 2009, NOSSDAV 09: 18TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P19
   RAO L, 2010, COMSCORE YOUTUBE REA
   Saxena Mohit., 2008, NOSSDAV '08: Proceedings of the 18th International Workshop on Network and Operating Systems Support for Digital Audio and Video, P39
   Schneider F, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P35
   Song HH, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P322
   Venkataraman V, 2006, PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P2, DOI 10.1109/ICNP.2006.320193
   Wang F, 2008, IEEE INFOCOM SER, P36
   Watts Duncan J., 2000, Small worlds: The dynamics of networks between order and randomness
   Wu C, 2008, IEEE INFOCOM SER, P2029
   Wu D, 2009, IEEE INFOCOM SER, P2726, DOI 10.1109/INFCOM.2009.5062220
   Yen Y-W., 2008, YouTube looks for the money clip
   YIN H, 2009, P 9 ACM SIGCOMM C IN, P442
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
NR 39
TC 4
Z9 5
U1 0
U2 20
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2012
VL 8
IS 1
AR 5
DI 10.1145/2071396.2071401
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 894AV
UT WOS:000300400200005
DA 2024-07-18
ER

PT J
AU Bhattacharya, S
   Sukthankar, R
   Shah, M
AF Bhattacharya, Subhabrata
   Sukthankar, Rahul
   Shah, Mubarak
TI A Holistic Approach to Aesthetic Enhancement of Photographs
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Human Factors; Interactive photo tools; spatial
   recomposition; quality enhancement
AB This article presents an interactive application that enables users to improve the visual aesthetics of their digital photographs using several novel spatial recompositing techniques. This work differs from earlier efforts in two important aspects: (1) it focuses on both photo quality assessment and improvement in an integrated fashion, (2) it enables the user to make informed decisions about improving the composition of a photograph. The tool facilitates interactive selection of one or more than one foreground objects present in a given composition, and the system presents recommendations for where it can be relocated in a manner that optimizes a learned aesthetic metric while obeying semantic constraints. For photographic compositions that lack a distinct foreground object, the tool provides the user with crop or expansion recommendations that improve the aesthetic appeal by equalizing the distribution of visual weights between semantically different regions. The recomposition techniques presented in the article emphasize learning support vector regression models that capture visual aesthetics from user data and seek to optimize this metric iteratively to increase the image appeal. The tool demonstrates promising aesthetic assessment and enhancement results on variety of images and provides insightful directions towards future research.
C1 [Bhattacharya, Subhabrata; Shah, Mubarak] Univ Cent Florida, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Bhattacharya, S (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.
EM subh@cs.ucf.edu
RI Sahoo, Sarat Kumar/J-8765-2014
OI Sahoo, Sarat Kumar/0000-0001-5734-6844; Shah,
   Mubarak/0000-0001-6172-5572
CR [Anonymous], 1999, Advances in kernel methods: Support vector learning
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   AVIDAN S, 2007, P ACM SIGGRAPH INT C
   BOUTELL M, 2004, P IEEE C COMP VIS PA
   DATTA R, 2007, P ACM MULT C
   Datta R., 2006, P EUR C COMP VIS
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   JONAS P, 1976, PHOTOGRAPHIC COMPOSI, P2
   Ke Y., 2006, P IEEE C COMP VIS PA
   LEYVAND T, 2008, P ACM SIGGRAPH INT C
   Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI 10.1109/TPAMI.20071176
   LIVIO M, 2002, PLUS MAG LIVING MATH
   Luo Y, 2008, P EUR C COMP VIS
   MANSOOR A, 2009, P SCAND C IM AN
   Nishiyama M., 2009, P 17 ACM INT C MULTI, P669
   VENKATA ND, 2000, IEEE T IMAGE PROCESS, V9, P2
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   YOU J, 2009, P ACM MULT C
   ZHANG Y, 2004, P EUROGRAPHICS
NR 21
TC 24
Z9 29
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2011
VL 7
IS 1
SI SI
AR 21
DI 10.1145/2037676.2037678
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science
GA 857NR
UT WOS:000297725800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Meyer, M
   Rensing, C
   Steinmetz, R
AF Meyer, Marek
   Rensing, Christoph
   Steinmetz, Ralf
TI Multigranularity Reuse of Learning Resources
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Theory; Standardization; Reuse; reusability; e-learning; learning
   resources; granularity
AB This article investigates a scenario of reuse in which existing learning resources serve as preliminary products for the creation of new learning resources. Authors should be able to reuse learning resources and also parts of them at different levels of granularity in a modular way. The requirements of multigranularity reuse are analyzed and compared to existing solutions. A concept for modular, multigranularity reuse is presented in this article. It is also shown how this kind of reuse can be achieved in practise.
C1 [Meyer, Marek; Rensing, Christoph; Steinmetz, Ralf] Tech Univ Darmstadt, Multimedia Commun Lab KOM, D-64283 Darmstadt, Germany.
C3 Technical University of Darmstadt
RP Meyer, M (corresponding author), Tech Univ Darmstadt, Multimedia Commun Lab KOM, Rundeturmstr 10, D-64283 Darmstadt, Germany.
EM Marek.Meyer@KOM.tu-darmstadt.de; Christoph.Rensing@KOM.tu-darmstadt.de;
   Ralf.Steinmetz@KOM.tu-darmstadt.de
RI Steinmetz, Patrick R. H./AAD-4093-2022; Rensing, Christopher/D-3947-2011
OI Rensing, Christopher/0000-0002-5012-7953; Rensing,
   Christoph/0000-0002-1287-216X; Steinmetz, Ralf/0000-0002-6839-9359
CR Advanced Distributed Learning, 2004, SHAR CONT OBJ REF MO
   Alonso G., 2004, DAT SYS APP, DOI 10.1007/978-3-662-10876-5_5
   Baldwin CarlissY., 1999, DESIGN RULES, V1
   Barrit C., 1999, CISCO SYSTEMS REUSAB
   Brase J, 2003, 3RD IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P493, DOI 10.1109/ICALT.2003.1215216
   CURTIS B, 1992, COMMUN ACM, V35, P75, DOI 10.1145/130994.130998
   Doorten M., 2004, Online Education Using Learning Objects, P116
   Duval E, 2001, COMMUN ACM, V44, P72, DOI 10.1145/374308.374346
   DUVAL E, 2003, P 12 INT WORLD WID W, P20
   FEILER PH, 1992, ADA258465 DTIC RES R
   Fernandes E, 2005, 5th IEEE International Conference on Advanced Learning Technologies, Proceedings, P948, DOI 10.1109/ICALT.2005.220
   Hodgins H.W., 2002, Evaluation of learning objects and instruction using learning objects, P281
   Hodgins W., 2002, 14841212002 IEEE
   HOERMANN S, 2005, P WORLD C ED MULT HY, P3453
   HOERMANN S, 2005, THESIS TU DARMSTADT
   IP A, 2003, P 20 ANN C AUSTR SOC, V1, P256
   KABEL S, 2004, J ED MULTIMEDIA HYPE, V13, P405
   Koper R., 2003, REUSING ONLINE RESOU, P46
   Marsh J., 2006, XML INCLUSIONS XINCL
   Meyer M., 2008, International Journal of Advanced Media and Communication, V2, P59, DOI 10.1504/IJAMC.2008.016758
   MEYER M, 2006, P PREC WORKSH 4 E LE, P19
   MEYER M, 2008, THESIS TU DARMSTADT
   MEYER M, 2007, P WORLD C ED MULT HY, P3164
   Meyer M, 2007, LECT NOTES COMPUT SC, V4351, P34
   Molenda M., 2003, PERFORMANCE IMPROVEM, V42, P34, DOI DOI 10.1002/PFI.4930420508
   Neven F., 2002, Proceedings of the tenth ACM international conference on Multimedia, P291, DOI [10.1145/641007.641067, DOI 10.1145/641007.641067]
   Niegemann H M., 2004, Kompendium E-Learning
   OCHOA X, 2008, P WORLD C ED MULT HY, P6031
   Polsani P., 2003, J DIGITAL INFORM, V3
   Rensing C., 2005, KOMTR200502 TU DARMS
   ROSTANIN O, 2007, P EC TEL POST SESS
   Sanchez S., 2004, P 4 IEEE INT C ADV L
   STEINACKER A, 2001, THESIS TU DARMSTADT
   SUSS C, 2002, P INT WORKSH INT COM
   Verbert K, 2004, ED-MEDIA 2004: World Conference on Educational Multimedia, Hypermedia & Telecommunications, Vols. 1-7, P202
   Verbert K., 2006, International Journal on E-Learning, V5, P67
   Wiley D.A., 2000, Connecting learning objects to instructional design theory: A definition, a metaphor, and a taxonomy
   ZIMMERMANN B, 2006, P WORLD C ED MULT HY
NR 38
TC 6
Z9 6
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2011
VL 7
IS 1
AR 1
DI 10.1145/1870121.1870122
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 712GI
UT WOS:000286653800001
DA 2024-07-18
ER

PT J
AU Jin, X
   Chan, SHG
AF Jin, Xing
   Chan, S. -H. Gary
TI Detecting Malicious Nodes in Peer-to-Peer Streaming by Peer-Based
   Monitoring
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Performance; Design; Malicious nodes; peer monitoring; peer-to-peer
   streaming
ID TRUST
AB Current peer-to-peer (P2P) streaming systems often assume that nodes cooperate to upload and download data. However, in the open environment of the Internet, this is not necessarily true and there exist malicious nodes in the system. In this article, we study malicious actions of nodes that can be detected through peer-based monitoring. We require each node to monitor the data received and to periodically send monitoring messages about its neighbors to some trustworthy nodes. To efficiently store and search messages among multiple trustworthy nodes, we organize trustworthy nodes into a threaded binary tree. Trustworthy nodes also dynamically redistribute monitoring messages among themselves to achieve load balancing. Our simulation results show that this scheme can efficiently detect malicious nodes with high accuracy, and that the dynamic redistribution method can achieve good load balancing among trustworthy nodes.
C1 [Jin, Xing] Oracle USA Inc, Redwood Shores, CA 94065 USA.
   [Chan, S. -H. Gary] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.
C3 Oracle; Hong Kong University of Science & Technology
RP Jin, X (corresponding author), Oracle USA Inc, 400 Oracle Pkwy, Redwood Shores, CA 94065 USA.
EM jin@oracle.com; gchan@cse.ust.hk
OI Chan, Gary Shueng Han/0000-0003-4207-764X
FU Research Grant Council of the Hong Kong Special Administrative Region,
   China [611107]; Cisco University Research Program Fund; Silicon Valley
   Community Foundation [SVCF08/09.EG01]; Hong Kong Innovation Technology
   Fund [ITS/013/08]
FX This work was supported in part by the General Research Fund from the
   Research Grant Council of the Hong Kong Special Administrative Region,
   China (611107), the Cisco University Research Program Fund, a
   corporate-advised fund of Silicon Valley Community Foundation
   (SVCF08/09.EG01) and the Hong Kong Innovation Technology Fund
   (ITS/013/08).
CR Aberer K., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P310, DOI 10.1145/502585.502638
   Adar E., 2000, First Monday, V5, DOI 10.5210/fm.v5i10.792
   [Anonymous], P SIGCOMM 01, DOI DOI 10.1145/383059.383071
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   Chen R., 2001, Poblano A Distributed Trust Model for Peer-to-Peer Networks
   Chu YH, 2002, IEEE J SEL AREA COMM, V20, P1456, DOI 10.1109/JSAC.2002.803066
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Cornelli F., 2002, P 11 INT WORLD WIDE, P376
   Damiani E., 2002, P 9 ACM C COMP COMM, P207
   DEERING S, 1988, MULTICAST ROUTING IN, P55
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   DRAGOVIC B, 2003, P INT C DAT EXP SYST
   Guo Y., 2003, Proceedings of the 12th International Conference on World Wide Web, P301, DOI DOI 10.1145/775152.775195
   Habib A, 2006, IEEE T MULTIMEDIA, V8, P610, DOI 10.1109/TMM.2006.870724
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   HERNANDEZ EA, 2001, J NETW SYST MANAGE, V9
   Jannotti J, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE FOURTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P197
   JIN X, 2006, P IEEE GLOB TEL C GL
   Jin X, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1537, DOI 10.1109/ICME.2006.262836
   Jun S, 2005, INT CON DISTR COMP S, P293, DOI 10.1109/ICDCS.2005.70
   Kamvar M. T., 2003, P 12 INT C WORLD WID, P640
   KNUTH DE, 1998, ART PROGRAMMING, V3
   Lai K., 2003, P WORKSH EC PEER TO
   Liu JC, 2006, MULTIMED TOOLS APPL, V29, P211, DOI 10.1007/s11042-006-0013-7
   Marti S, 2006, COMPUT NETW, V50, P472, DOI 10.1016/j.comnet.2005.07.011
   Mekouar L, 2006, COMPUT NETW, V50, P545, DOI 10.1016/j.comnet.2005.07.025
   NIELSON S, 2005, P INT WORKSH PEER PE
   RODRIGUES R, 2005, P INT WORKSH PEER PE
   ROWSTRON A, 2001, P 18 ACM S OP SYST P, P188
   Sherwood R, 2006, COMPUT NETW, V50, P523, DOI 10.1016/j.comnet.2005.07.012
   Singh A, 2003, THIRD INTERNATIONAL CONFERENCE ON PEER-TO-PEER COMPUTING (P2P2003), PROCEEDINGS, P142, DOI 10.1109/PTP.2003.1231514
   SINGH A, 2004, P ACM SPEC INT GROUP
   *SSL, INTR SSL
   Tan G, 2006, INT WORKSH QUAL SERV, P41, DOI 10.1109/IWQOS.2006.250450
   Tang Y, 2007, IEEE COMMUN MAG, V45, P100, DOI 10.1109/MCOM.2007.374426
   Tran DA, 2004, IEEE J SEL AREA COMM, V22, P121, DOI 10.1109/JSAC.2003.818803
   Xiong L, 2004, IEEE T KNOWL DATA EN, V16, P843, DOI 10.1109/TKDE.2004.1318566
   Zhang BC, 2002, IEEE INFOCOM SER, P1366, DOI 10.1109/INFCOM.2002.1019387
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
NR 39
TC 16
Z9 19
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR 10
PY 2010
VL 6
IS 2
AR 9
DI 10.1145/1671962.1671965
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 579PA
UT WOS:000276382700003
DA 2024-07-18
ER

PT J
AU Nguyen, GP
   Worring, M
AF Nguyen, Giang Phuong
   Worring, Marcel
TI Optimization of interactive visual-similarity-based search
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE experimentation; human factors; algorithms; interactive search;
   similarity based visualization; active learning
ID RELEVANCE FEEDBACK; IMAGE RETRIEVAL
AB At one end of the spectrum, research in interactive content-based retrieval concentrates on machine learning methods for effective use of relevance feedback. On the other end, the information visualization community focuses on effective methods for conveying information to the user. What is lacking is research considering the information visualization and interactive retrieval as truly integrated parts of one content-based search system. In such an integrated system, there are many degrees of freedom like the similarity function, the number of images to display, the image size, different visualization modes, and possible feedback modes. To base the optimal values for all of those on user studies is unfeasible. We therefore develop search scenarios in which tasks and user actions are simulated. From there, the proposed scheme is optimized based on objective constraints and evaluation criteria. In such a manner, the degrees of freedom are reduced and the remaining degrees can be evaluated in user studies. In this article, we present a system that integrates advanced similarity based visualization with active learning. We have performed extensive experimentation on interactive category search with different image collections. The results using the proposed simulation scheme show that indeed the use of advanced visualization and active learning pays off in all of these datasets.
C1 [Nguyen, Giang Phuong; Worring, Marcel] Univ Amsterdam, Intelligent Syst Lab Amsterdam, NL-1098 SJ Amsterdam, Netherlands.
C3 University of Amsterdam
RP Nguyen, GP (corresponding author), Univ Amsterdam, Intelligent Syst Lab Amsterdam, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.
EM giangnp@uva.nl; M.Worring@uva.nl
RI Nguyen, Giang/HZI-3726-2023; Worring, Marcel/JRW-7059-2023
OI Worring, Marcel/0000-0003-4097-4136
CR BASSEVILLE M, 1989, SIGNAL PROCESS, V18, P349, DOI 10.1016/0165-1684(89)90079-0
   BEDERSON BB, 2001, P 2001 ACM S US INT, V3, P71
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CHEN B, 2001, INT ARCH PHOTOGRAMME, V34, P37
   CHEN M, 2005, MULTIMEDIA 05, P902
   DUBES RC, 1987, PATTERN RECOGN, V20, P645, DOI 10.1016/0031-3203(87)90034-3
   Geusebroek JM, 2005, INT J COMPUT VISION, V62, P7, DOI 10.1007/s11263-005-4632-7
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   GOSSELIN P, 2004, P INT C IM PROC
   GUO G, 2001, P INT C COMP VIS PAT
   HEESCH D, 2004, P INT C IM VID RETR, P491
   Ivory MY, 2001, ACM COMPUT SURV, V33, P470, DOI 10.1145/503112.503114
   KEIM D, 2002, IEEE T VIS COMPUT GR, V7, P10
   Lei Z, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P721, DOI 10.1109/ICIP.2001.958595
   Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574
   Moghaddam B, 2004, INT J COMPUT VISION, V56, P109, DOI 10.1023/B:VISI.0000004834.62090.74
   NAPHADE M, 2002, P IEEE INT C IM PROC
   NGUYEN G, 2005, P 7 INT WORKSH AUD V
   RODDEN K, 2001, P SIGCHI C HUM FACT, P190, DOI DOI 10.1145/365024.365097
   Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934
   Rubner Y., 1999, THESIS STANFORD U ST
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek CG, 2005, P ACM MULT
   SWALN M, 1991, INT J COMPUT VISION, V7, P11
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   VOORHEES E, 2001, TREE 10 P APP COMM E
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
   Zhu M, 2004, Recall, precision and average precision
NR 32
TC 15
Z9 17
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2008
VL 4
IS 1
AR 7
DI 10.1145/1324287.1324294
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 264UK
UT WOS:000253315700007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Poellabauer, C
   Schwan, K
AF Poellabauer, Christian
   Schwan, Karsten
TI Flexible Cross-Domain Event Delivery for Quality-Managed Multimedia
   Applications
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Performance; Event delivery; operating system;
   quality-of-service; real-time events; quality management; dynamic code
   generation
AB To meet end users' quality-of-service (QoS) requirements, online quality management for multimedia applications must include appropriate allocation of the underlying computing platform's resources. Previous work has developed novel operating system (OS) functionality for dynamic QoS management, including multimedia or real-time CPU schedulers and OS extensions for online performance monitoring and for adaptations, as well as QoS-aware applications that adapt their behavior to gain additional benefits from such functionality. This article describes a general OS mechanism that may be used to implement a wide variety of online quality management functions. ECalls is a communication mechanism that implements multiple cross-domain calling conventions that can be customized to the quality management needs of applications. The ECalls mechanism is based on the notions of events, event channels, and event handlers. Using events, applications can share relevant QoS attributes with OS services, and OS-level resource management services can efficiently provide monitoring data to target applications or application managers. Dynamically generated event handlers can be used to customize event delivery to meet diverse application needs, for example, to achieve high scalability for Web servers or small jitter for real-time data delivery.
C1 [Poellabauer, Christian] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
   [Schwan, Karsten] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.
C3 University of Notre Dame; University System of Georgia; Georgia
   Institute of Technology
RP Poellabauer, C (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
EM cpoellab@cse.nd.edu; schwan@cc.gatech.edu
RI Poellabauer, Christian/JVO-2076-2024
CR ANDERSON TE, 1991, P 13 ACM S OP SYST P, P95
   Banga G, 1999, PROCEEDINGS OF THE 1999 USENIX ANNUAL TECHNICAL CONFERENCE, P253
   Bershad B.N., 1995, P 15 ACM S OP SYST P, P267
   BIHARI TE, 1991, ACM T COMPUT SYST, V9, P143, DOI 10.1145/103720.103723
   Birman KP, 2003, PROCEEDINGS OF THE AUTONOMIC COMPUTING WORKSHOP/FIFTH ANNUAL INTERNATIONAL WORKSHOP ON ACTIVE MIDDLEWARE SERVICES, P4
   Chandra A, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 2001 USENIX ANNUAL TECHNICAL CONFERENCE, P231
   Clark D. D., 1985, Operating Systems Review, V19, P171, DOI 10.1145/323627.323645
   Druschel P., 1993, Operating Systems Review, V27, P189, DOI 10.1145/173668.168634
   EISENHAUER G, 2001, ACM SIGOPS, V35, P7
   Engler D.R., 1995, S OPERATING SYSTEMS, P251
   GANEV I, 2004, P 3 VIRT MACH RES TE, P83
   Gopalakrishnan R, 1998, IEEE ACM T NETWORK, V6, P374, DOI 10.1109/90.720871
   LEE C, 1996, P IEEE REAL TIM TECH, P220
   Lemon J, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE FREENIX TRACK, P141
   MANIMARAN G, 1998, J PARALLEL DISTRIBUT, V1, P75
   Mogul JC, 1997, ACM T COMPUT SYST, V15, P217, DOI 10.1145/263326.263335
   Nieh J, 2003, ACM T COMPUT SYST, V21, P117, DOI 10.1145/762483.762484
   NIEH J, 1993, P 4 INT WORKSH NETW, P41
   PAI V, 1999, P 2 S OP SYST DES IM, P37
   Pai VS, 1999, PROCEEDINGS OF THE 1999 USENIX ANNUAL TECHNICAL CONFERENCE, P199
   Pietzuch PR, 2002, 22ND INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOP, PROCEEDINGS, P611, DOI 10.1109/ICDCSW.2002.1030837
   POELLABAUER C, 2002, P 10 ACM MULT C JUAN, P402
   POLETTO M, 1996, P 1 WORKSH COMP SUPP, P1
   Provos N, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE 4TH ANNUAL LINUX SHOWCASE AND CONFERENCE, ATLANTA, P1
   Provos N, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE FREENIX TRACK, P109
   Rosu D, 1997, REAL TIM SYST SYMP P, P320, DOI 10.1109/REAL.1997.641293
   Rosu MC, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE GENERAL TRACK, P225
   Steere DC, 1999, USENIX ASSOCIATION PROCEEDINGS OF THE THIRD SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '99), P145
   Wallach D.A., 1995, P 5 ACM SIGPLAN S PR, P217
   West R, 2000, REAL TIM SYST SYMP P, P239, DOI 10.1109/REAL.2000.896013
   YAU DKY, 1996, P IS T SPIE MULT COM
NR 31
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2005
VL 1
IS 3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA V74DW
UT WOS:000205012400002
DA 2024-07-18
ER

PT J
AU Buchanan, MC
   Zellweger, PT
AF Buchanan, M. Cecelia
   Zellweger, Polle T.
TI Automatic Temporal Layout Mechanisms Revisited
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Languages; Multimedia documents; multimedia authoring;
   temporal formatting; temporal specification
AB A traditional static document has a spatial layout that specifies where objects in the document appear. Because multimedia documents incorporate time, they also require a temporal layout, or schedule, that specifies when events in the document occur. This article argues that multimedia document systems should provide mechanisms for automatically producing temporal layouts for documents. The major advantage of this approach is that it makes it easier for authors to create and modify multimedia documents.
   This article revisits our 1993 framework for understanding automatic temporal formatters and explores the basic issues surrounding them. It also describes the Firefly multimedia document system, which was developed in 1992 to test the potential of automatic temporal formatting. Using our original framework, the paper reviews a representative sample of recent automatic document formatters. This analysis validates the basic framework and demonstrates the progress of the field in the intervening decade. A discussion of potential extensions to the framework is included.
C1 [Buchanan, M. Cecelia] Tuatara Consulting, Merion, PA 19066 USA.
   [Zellweger, Polle T.] MacZell Consulting, Bellevue, WA 98004 USA.
RP Buchanan, MC (corresponding author), Tuatara Consulting, 217 Stoneway Lane, Merion, PA 19066 USA.
EM mc_buchanan@yahoo.com; pzellweger@acm.org
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Bailey B., 1998, Proceedings ACM Multimedia 98, P257, DOI 10.1145/290747.290779
   Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691
   BLAKOWSKI G, 1992, COMPUT COMMUN, V15, P611, DOI 10.1016/0140-3664(92)90113-S
   BLAKOWSKI G, 1992, AUSTR COMPUTER SCI C, V14, P93
   BLAKOWSKI G, 1992, P ACSSC15 15 AUSTR C
   Boll S, 2001, IEEE T KNOWL DATA EN, V13, P361, DOI 10.1109/69.929895
   Boll S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P37, DOI 10.1145/319463.319468
   Buchanan M. C., 1993, Proceedings ACM Multimedia 93, P341, DOI 10.1145/166266.168415
   Buchanan M. C., 1992, Proceeding of the ACM Conference on Hypertext, P262, DOI 10.1145/168466.171513
   Bulterman D. C. A., 1998, Proceedings ACM Multimedia 98, P247, DOI 10.1145/290747.290778
   BULTERMAN DCA, 1991, PROCEEDINGS OF THE SUMMER 1991 USENIX CONFERENCE, P137
   Bulterman DCA, 1998, COMPUT NETWORKS ISDN, V30, P519, DOI 10.1016/S0169-7552(98)00128-7
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Candan KS, 1998, INT J INTELL SYST, V13, P1059, DOI 10.1002/(SICI)1098-111X(199812)13:12<1059::AID-INT2>3.0.CO;2-K
   CANDAN KS, 1997, P 4 ACM INT C MULT B, P329
   COURTIAT JP, 1997, P 4 ACM INT C MULT B, P141
   DECHTER R, 1991, ARTIF INTELL, V49, P61, DOI 10.1016/0004-3702(91)90006-6
   DRAPEAU GD, 1991, PROCEEDINGS OF THE SUMMER 1991 USENIX CONFERENCE, P315
   FIUME E, 1987, P EUR 1987 N HOLL
   Hamakawa R., 1993, Proceedings ACM Multimedia 93, P273, DOI 10.1145/166266.168399
   HAMAKAWA R, 1994, MULTIMEDIA SYSTEMS, V2, P26
   Hillier F.S., 1974, Operations Research, V2nd
   JOURDAN M, 1997, P INT C MULT COMP NE, P68
   JOURDAN M, 1998, SPIE P, V3020, P267
   KIM MY, 1995, P ACM MULT 95, P143
   KIM MY, 1992, 9242 U MINN COMP SCI
   KNUTH DE, 1981, SOFTWARE PRACT EXPER, V11, P1119, DOI 10.1002/spe.4380111102
   KOEGEL J, 1992, P XHIB 1992 SAN JOS, P275
   Layaida N, 1996, P SOC PHOTO-OPT INS, V2667, P124, DOI 10.1117/12.235866
   Layaïda N, 2002, MULTIMED TOOLS APPL, V18, P213, DOI 10.1023/A:1019944800320
   LITTLE TDC, 1990, IEEE J SEL AREA COMM, V8, P413, DOI 10.1109/49.53017
   *MACR INC, 1989, MACROMIND DIR OV MAN
   Mirbel I, 2000, VLDB J, V9, P111, DOI 10.1007/PL00010674
   Ogawa R., 1990, Hypertext: Concepts, Systems and Applications. Proceedings of the First European Conference on Hypertext, P38
   PerezLuque MJ, 1996, IEEE J SEL AREA COMM, V14, P36, DOI 10.1109/49.481692
   POOLE L, 1991, MACWORLD, V8, P154
   *REAL NETW, 2004, REALPLAYER
   Rodrigues R. F., 2003, P 2003 ACM S DOC ENG, P78
   ROISIN C, 2003, P SYNCHR MULT INT LA
   Sampaio P. N. M., 2001, Proceedings of the ACM Symposium on Document Engineering (DocEng '01), P115, DOI 10.1145/502187.502205
   Santos C. A. S., 1998, Proceedings ACM Multimedia 98, P39, DOI 10.1145/290747.290753
   Schnepf J, 1996, IEEE J SEL AREA COMM, V14, P114, DOI 10.1109/49.481698
   Schnepf JA., 1996, P PAC WORKSH DISTR M
   Soares LFG, 2000, MULTIMEDIA SYST, V8, P118, DOI 10.1007/s005300050155
   Song JH, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P276, DOI 10.1109/VL.1996.545298
   Song JW, 1999, MULTIMEDIA SYST, V7, P424, DOI 10.1007/s005300050143
   STEINMETZ R, 1990, IEEE J SEL AREA COMM, V8, P401, DOI 10.1109/49.53016
   Stotts P. D., 1990, Journal of Visual Languages and Computing, V1, P237, DOI 10.1016/S1045-926X(05)80008-4
   SWINEHART DC, 1986, ACM T PROGR LANG SYS, V8, P419, DOI 10.1145/6465.6466
   van Rossum G., 1993, Proceedings ACM Multimedia 93, P183, DOI 10.1145/166266.166287
   Vazirgiannis M, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P244, DOI 10.1109/MMCS.1997.609599
   Wahl T., 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P274, DOI 10.1109/MMCS.1995.484933
   Wahl T., 1994, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.94TH0631-2), P538, DOI 10.1109/MMCS.1994.292502
   [No title captured]
   P 7 INT C WORLD WID
NR 56
TC 9
Z9 10
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2005
VL 1
IS 1
BP 60
EP 88
DI 10.1145/1047936.1047942
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA V74DU
UT WOS:000205012200006
DA 2024-07-18
ER

PT J
AU Hsu, WY
   Jian, PW
AF Hsu, Wei-Yen
   Jian, Pei-Wen
TI Recurrent Multi-scale Approximation-Guided Network for Single Image
   Super-Resolution
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; multi-scale wavelet; recurrent structure
   reservation; approximation-guided network
ID YOLO
AB Single-image super-resolution (SISR) is an essential topic in computer vision applications. However, most CNN-based SISR approaches directly learn the relationship between low- and high-resolution images while ignoring the contextual texture and detail fidelity to explore super-resolution; thus, they hinder the representational power of CNNs and lead to the unrealistic, distorted reconstruction of edges and textures in the images. In this study, we propose a novel recurrent structure preservation mechanism with the integration and innovative use of multi-scale wavelet transform, Recurrent Multiscale Approximation-guided Network (RMANet), to recursively process the low-frequency and high-frequency sub-networks at each level separately. Unlike traditional wavelet transform, we propose a novel Approximation Level Preservation (ALP) architecture to import and learn the low-frequency sub-networks at each level. Through proposed Approximation level fusion (ALF) and inverse wavelet transform, rich image structures of low frequency at each level can be recursively restored and greatly preserved with the combination of ALP at each level. In addition, a novel low-frequency to high-frequency detail enhancement (DE) mechanism is also proposed to solve the problem of detail distortion in high-frequency networks by transmitting low-frequency information to the high-frequency network. Finally, a joint loss function is used to balance low-frequency and high-frequency information with different degrees of fusion. In addition to correct restoration, image details are further enhanced by tuning different hyperparameters during training. Compared with the stateof-the-art approaches, the experimental results on synthetic and real datasets demonstrate that the proposed RMANet achieves better performance in visual presentation, especially in image edges and texture details.
C1 [Hsu, Wei-Yen; Jian, Pei-Wen] Natl Chung Cheng Univ, Dept Informat Management, 168 Univ Rd, Chiayi 62102, Taiwan.
   [Hsu, Wei-Yen; Jian, Pei-Wen] Natl Chung Cheng Univ, Adv Inst Mfg High Tech Innovat, 168 Univ Rd, Chiayi 62102, Taiwan.
   [Hsu, Wei-Yen; Jian, Pei-Wen] Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, 168 Univ Rd, Chiayi 62102, Taiwan.
C3 National Chung Cheng University; National Chung Cheng University;
   National Chung Cheng University
RP Hsu, WY (corresponding author), Natl Chung Cheng Univ, Dept Informat Management, 168 Univ Rd, Chiayi 62102, Taiwan.; Hsu, WY (corresponding author), Natl Chung Cheng Univ, Adv Inst Mfg High Tech Innovat, 168 Univ Rd, Chiayi 62102, Taiwan.; Hsu, WY (corresponding author), Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, 168 Univ Rd, Chiayi 62102, Taiwan.
EM shenswy@gmail.com; hi456456789@gmail.com
OI Jian, Pei-Wen/0009-0005-8858-2934
FU Ministry of Science and Technology, Taiwan [MOST110-2221-E-194-027-MY3,
   MOST111-2410-H-194-038-MY3]
FX We gratefully acknowledge the funding agency, Ministry of Science and
   Technology, Taiwan, under grant No. MOST110-2221-E-194-027-MY3 and
   MOST111-2410-H-194-038-MY3.
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arif F, 2014, IEEE INT CONF INF VI, P357, DOI 10.1109/IV.2014.46
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Choi JH, 2021, IEEE ACCESS, V9, P37487, DOI 10.1109/ACCESS.2021.3063760
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fang FM, 2020, IEEE T IMAGE PROCESS, V29, P4656, DOI 10.1109/TIP.2020.2973769
   Feichtenhofer C, 2013, IEEE SIGNAL PROC LET, V20, P379, DOI 10.1109/LSP.2013.2248711
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Guo TT, 2017, IEEE COMPUT SOC CONF, P1100, DOI 10.1109/CVPRW.2017.148
   Hsu WY, 2023, OPT EXPRESS, V31, P3606, DOI 10.1364/OE.479370
   Hsu WY, 2023, PATTERN RECOGN, V137, DOI 10.1016/j.patcog.2022.109294
   Hsu WY, 2022, OPT EXPRESS, V30, P41279, DOI 10.1364/OE.473400
   Hsu WY, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3142061
   Hsu WY, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108078
   Hsu WY, 2021, IEEE ACCESS, V9, P110063, DOI 10.1109/ACCESS.2021.3102600
   Hsu WY, 2021, IEEE T IMAGE PROCESS, V30, P1369, DOI 10.1109/TIP.2020.3044209
   Hsu WY, 2021, IEEE T IMAGE PROCESS, V30, P934, DOI 10.1109/TIP.2020.3039574
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang YF, 2021, IEEE T IMAGE PROCESS, V30, P2325, DOI 10.1109/TIP.2021.3050856
   Jiang K, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107475
   Jin X, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3417333
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Q, 2021, IEEE T GEOSCI REMOTE, V59, P8693, DOI 10.1109/TGRS.2020.3047363
   Li YC, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3414838
   Liang YD, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107931
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Ma H., 2022, ACM T MULTIM COMPUT, V18, P1
   Ooi YK, 2021, IEEE ACCESS, V9, P126837, DOI 10.1109/ACCESS.2021.3111983
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang L, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3546076
   Wang LF, 2017, PATTERN RECOGN, V68, P191, DOI 10.1016/j.patcog.2017.02.027
   Wang Q, 2021, IEEE T IND ELECTRON, V68, P11276, DOI 10.1109/TIE.2020.3038096
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wang ZR, 2022, IEEE ACCESS, V10, P30974, DOI 10.1109/ACCESS.2022.3158936
   Wei-Yen Hsu, 2022, IEEE T INSTRUM MEAS, V71
   Yamanaka J, 2017, LECT NOTES COMPUT SC, V10635, P217, DOI 10.1007/978-3-319-70096-0_23
   Yan Q, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2414877
   Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403
   Yang X, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3578934
   Yuqing Liu, 2023, ACM T MULTIM COMPUT, V19, P1
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang DY, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3398685
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao MD, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P531, DOI 10.1109/ICIVC.2017.7984612
NR 54
TC 2
Z9 2
U1 5
U2 18
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2023
VL 19
IS 6
AR 194
DI 10.1145/3592613
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N3AP4
UT WOS:001035785200017
DA 2024-07-18
ER

PT J
AU Li, R
   Zhang, BP
   Liu, W
   Teng, Z
   Fan, JP
AF Li, Rui
   Zhang, Baopeng
   Liu, Wei
   Teng, Zhu
   Fan, Jianping
TI PANet: An End-to-end Network Based on Relative Motion for Online
   Multi-object Tracking
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multi-object tracking; tracking-by-detection; pivot; association
AB The popular tracking-by-detection paradigm of multi-object tracking (MOT) takes detections of each frame as the input and associates detections from one frame to another. Existing association methods based on the relative motion have attracted attention, because they restrain the effect of noisy detections and improve the performance of MOT. However, these methods depend only on the immediately previous frame, which may easily lead to inaccurate matches and even large accumulated errors. Furthermore, multiple objects involved in occlusions are not fully exploited in these existing methods, which leads to the aggravation of inaccurate matches. Motivated by these issues, we design the pivot to represent each object and propose a novel pivot association network (PANet) for the MOT task. Specifically, pivots are learned from spatial semantic and historical contextual clues, which alleviates the dependency on the immediately previous frame. Our online tracker PANet employs pivots and a lightweight associator to localize tracklets of objects, which can inhibit noise detections and improve the accuracy of tracklet prediction by learning the correlation responses between pivots and spatial search areas. Extensive experiments conducted on two-dimensionalMOT15, MOT16, MOT17, and MOT20 demonstrate the effectiveness of the proposed method against numerous state-of-the-art MOT trackers.
C1 [Li, Rui; Zhang, Baopeng; Liu, Wei; Teng, Zhu] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
   [Fan, Jianping] Lenovo Res, AI Lab, Beijing 100085, Peoples R China.
C3 Beijing Jiaotong University; Legend Holdings; Lenovo
RP Teng, Z (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
EM rui.li@bjtu.edu.cn; bpzhang@bjtu.edu.cn; 18281132@bjtu.edu.cn;
   zteng@bjtu.edu.cn; jfan1@Lenovo.com
OI Li, Rui/0000-0003-1679-5904; Teng, Zhu/0000-0002-1754-4878; Fan,
   Jianping/0000-0003-2290-1785
FU Fundamental Research Funds for the Central Universities of China
   [2022JBMC009]; Natural Science Foundation of China [61972027]; Beijing
   Municipal Natural Science Foundation [4212041]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities of China (2022JBMC009), the Natural Science
   Foundation of China (61972027), and the Beijing Municipal Natural
   Science Foundation (Grant No. 4212041).
CR Baisa NL, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103279
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Brasó G, 2020, PROC CVPR IEEE, P6246, DOI 10.1109/CVPR42600.2020.00628
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chu P, 2019, IEEE I CONF COMP VIS, P6171, DOI 10.1109/ICCV.2019.00627
   Chu Q, 2020, AAAI CONF ARTIF INTE, V34, P10672
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Coble NJ, 2021, Arxiv, DOI arXiv:2012.05460
   Dai P, 2021, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR46437.2021.00247
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2022, IEEE T IMAGE PROCESS, V31, P2201, DOI 10.1109/TIP.2022.3154286
   Hornakova A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6310, DOI 10.1109/ICCV48922.2021.00627
   Hornakova A, 2020, PR MACH LEARN RES, V119
   Kim C, 2021, PROC CVPR IEEE, P9548, DOI 10.1109/CVPR46437.2021.00943
   Leal-Taix‚ L, 2015, Arxiv, DOI arXiv:1504.01942
   Lei Ba J., 2016, arXiv
   Li R, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108738
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu QK, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P530
   Liu Q, 2023, IEEE T MULTIMEDIA, V25, P1269, DOI 10.1109/TMM.2022.3140929
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YT, 2021, NEUROCOMPUTING, V447, P80, DOI 10.1016/j.neucom.2021.02.084
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Milan A, 2016, Arxiv, DOI arXiv:1603.00831
   Peng JL, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107480
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WH, 2021, IEEE T IMAGE PROCESS, V30, P1439, DOI 10.1109/TIP.2020.3044219
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen JB, 2022, IEEE T PATTERN ANAL, V44, P8896, DOI 10.1109/TPAMI.2021.3127492
   Shen JB, 2019, IEEE T CYBERNETICS, V49, P1990, DOI 10.1109/TCYB.2018.2803217
   Shen JB, 2018, IEEE T INTELL TRANSP, V19, P162, DOI 10.1109/TITS.2017.2750082
   Sheng H, 2020, IEEE T CIRC SYST VID, V30, P2971, DOI 10.1109/TCSVT.2020.2988649
   Tang SY, 2014, INT J COMPUT VISION, V110, P58, DOI 10.1007/s11263-013-0664-6
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GA, 2023, IEEE T MULTIMEDIA, V25, P1256, DOI 10.1109/TMM.2022.3140919
   Wang GA, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P482, DOI 10.1145/3343031.3350853
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xiang J, 2021, IEEE T CIRC SYST VID, V31, P275, DOI 10.1109/TCSVT.2020.2975842
   Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yang JM, 2022, APPL INTELL, V52, P1268, DOI 10.1007/s10489-021-02457-5
   Yang K, 2022, IEEE T MULTIMEDIA, V24, P1956, DOI 10.1109/TMM.2021.3074239
   Yin JB, 2020, PROC CVPR IEEE, P6767, DOI 10.1109/CVPR42600.2020.00680
   Yoon YC, 2021, INFORM SCIENCES, V561, P326, DOI 10.1016/j.ins.2020.10.002
   Yuan D, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3486678
   Yuan D, 2021, IEEE T IMAGE PROCESS, V30, P976, DOI 10.1109/TIP.2020.3037518
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang MD, 2015, IEEE IMAGE PROC, P1468, DOI 10.1109/ICIP.2015.7351044
   Zhang Y, 2020, IEEE T IMAGE PROCESS, V29, P6694, DOI 10.1109/TIP.2020.2993073
NR 59
TC 2
Z9 2
U1 4
U2 19
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2023
VL 19
IS 6
AR 197
DI 10.1145/3595379
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N3AP4
UT WOS:001035785200020
OA Bronze
DA 2024-07-18
ER

PT J
AU Zhu, HG
   Wei, YC
   Zhao, Y
   Zhang, CJ
   Huang, SJ
AF Zhu, Hongguang
   Wei, Yunchao
   Zhao, Yao
   Zhang, Chunjie
   Huang, Shujuan
TI AMC: Adaptive Multi-expert Collaborative Network for Text-guided Image
   Retrieval
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE guided image retrieval; multimodal fusion; mixture-of-experts
AB Text-guided image retrieval integrates reference image and text feedback as a multimodal query to search the image corresponding to user intention. Recent approaches employ multi-level matching, multiple accesses, or multiple subnetworks for better performance regardless of the heavy burden of storage and computation in the deployment. Additionally, these models not only rely on expert knowledge to handcraft image-text composing modules but also do inference by the static computational graph. It limits the representation capability and generalization ability of networks in the face of challenges from complex and varied combinations of reference image and text feedback. To break the shackles of the static network concept, we introduce the dynamic router mechanism to achieve data-dependent expert activation and flexible collaboration of multiple experts to explore more implicit multimodal fusion patterns. Specifically, we construct AMC, our Adaptive Multi-expert Collaborative network, by using the proposed router to activate the different experts with different levels of image-text interaction. Since routers can dynamically adjust the activation of experts for the current samples, AMC can achieve the adaptive fusion mode for the different reference image and text combinations and generate dynamic computational graphs according to varied multimodal queries. Extensive experiments on two benchmark datasets demonstrate that due to benefits from the image-text composing representation produced by an adaptive multi-expert collaboration mechanism, AMC has better retrieval performance and zero-shot generalization ability than the state-of-the-art method while keeping the lightweight model and fast retrieval speed. Moreover, we analyze the visualization of path activation, attention map, and retrieval results to further understand the routing decisions and semantic localization ability of AMC. The codes and pretrained models are available at https://github.com/KevinLight831/AMC.
C1 [Zhu, Hongguang; Wei, Yunchao; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
   [Zhang, Chunjie; Huang, Shujuan] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Zhang, Chunjie; Huang, Shujuan] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Beijing
   Jiaotong University
RP Zhao, Y (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
EM hongguang@bjtu.edu.cn; wychao1987@gmail.com; yzhao@bjtu.edu.cn;
   cjzhang@bjtu.edu.cn; shujuanhuang@bjtu.edu.cn
OI Zhu, Hongguang/0000-0002-1356-5153; Zhao, Yao/0000-0002-8581-9554;
   zhang, chunjie/0000-0002-1161-8995
FU National Key Research and Development of China [2018AAA0102100];
   National Natural Science Foundation of China [62120106009, 62072026];
   Beijing Natural Science Foundation [JQ20022]
FX This work was supported in part by the National Key Research and
   Development of China (grant 2018AAA0102100), the National Natural
   Science Foundation of China (62120106009 and 62072026), and the Beijing
   Natural Science Foundation (JQ20022).
CR Ak KE, 2018, PROC CVPR IEEE, P7708, DOI 10.1109/CVPR.2018.00804
   [Anonymous], 2014, P 2014 C EMP METH NA
   Berg TL, 2010, LECT NOTES COMPUT SC, V6311, P663, DOI 10.1007/978-3-642-15549-9_48
   Cai SF, 2021, IEEE WINT CONF APPL, P3587, DOI 10.1109/WACV48630.2021.00363
   Chen YB, 2020, PROC CVPR IEEE, P2998, DOI 10.1109/CVPR42600.2020.00307
   Cheng YH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3499027
   Delmas Ginger, 2021, P INT C LEARNING REP
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dodds E, 2020, Arxiv, DOI arXiv:2007.00145
   Faghri Fartash, 2017, P BRIT MACHINE VISIO
   Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z
   Geng QC, 2021, IEEE T IMAGE PROCESS, V30, P2436, DOI 10.1109/TIP.2020.3046921
   Ghosh A, 2019, IEEE I CONF COMP VIS, P1171, DOI 10.1109/ICCV.2019.00126
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Gu CB, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4600, DOI 10.1145/3474085.3475619
   Guo XX, 2018, ADV NEUR IN, V31
   Han XT, 2017, IEEE I CONF COMP VIS, P1472, DOI 10.1109/ICCV.2017.163
   Han YZ, 2022, IEEE T PATTERN ANAL, V44, P7436, DOI 10.1109/TPAMI.2021.3117837
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herrmann Charles, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P241, DOI 10.1007/978-3-030-58583-9_15
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jandial S, 2022, IEEE WINT CONF APPL, P597, DOI 10.1109/WACV51458.2022.00067
   Jang E, 2017, Arxiv, DOI arXiv:1611.01144
   Kim J, 2021, AAAI CONF ARTIF INTE, V35, P1771
   Kingma D. P., 2014, arXiv
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Lee S, 2021, PROC CVPR IEEE, P802, DOI 10.1109/CVPR46437.2021.00086
   Lei Ba J., 2016, arXiv
   Li X J., 2020, P EUR C COMP VIS, P121, DOI DOI 10.1007/978-3-030-58577-8_8
   Li Zheng, 2022, ARXIV
   Liu RY, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3300939
   Liu Zheyuan, 2021, P IEEECVF INT C COMP, P2125, DOI DOI 10.1109/1CCV48922.2021.00213
   Ma JQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1930, DOI 10.1145/3219819.3220007
   Ma J, 2020, IEEE WINT CONF APPL, P2492, DOI [10.1109/wacv45572.2020.9093427, 10.1109/WACV45572.2020.9093427]
   Ma Z, 2020, AAAI CONF ARTIF INTE, V34, P11741
   Mai L, 2017, PROC CVPR IEEE, P1121, DOI 10.1109/CVPR.2017.125
   Messina N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3451390
   Mullapudi RT, 2018, PROC CVPR IEEE, P8080, DOI 10.1109/CVPR.2018.00843
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Perez E, 2018, AAAI CONF ARTIF INTE, P3942
   Qu LG, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1104, DOI 10.1145/3404835.3462829
   Radford A, 2021, PR MACH LEARN RES, V139
   Rostamzadeh N, 2018, Arxiv, DOI arXiv:1806.08317
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Santoro A, 2017, ADV NEUR IN, V30
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shin M, 2020, Arxiv, DOI arXiv:2007.06404
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Vaswani A, 2017, ADV NEUR IN, V30
   Vo N, 2019, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2019.00660
   Wen HK, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1369, DOI 10.1145/3404835.3462967
   Wu H, 2020, Arxiv, DOI [arXiv:1905.12794, DOI 10.48550/ARXIV.1905.12794]
   Wu ZX, 2018, PROC CVPR IEEE, P8817, DOI 10.1109/CVPR.2018.00919
   Xiong R., 2020, INT C MACHINE LEARNI, P10524
   Yanagi R, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3485042
   Yang YC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3303, DOI 10.1145/3474085.3475483
   Yao Lewei, 2021, P INT C LEARNING REP
   Yelamarthi SK, 2018, LECT NOTES COMPUT SC, V11208, P316, DOI 10.1007/978-3-030-01225-0_19
   Yu E, 2019, IEEE T MULTIMEDIA, V21, P1276, DOI 10.1109/TMM.2018.2877127
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Yu YJ, 2020, Arxiv, DOI arXiv:2003.12299
   Zhang FF, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3478642
   Zhang FF, 2022, IEEE T IMAGE PROCESS, V31, P1000, DOI 10.1109/TIP.2021.3138302
   Zhang GJ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5353, DOI 10.1145/3474085.3475659
   Zhang HW, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2637291
   Zhao B, 2017, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2017.652
   Zhu JG, 2022, Arxiv, DOI arXiv:2206.04674
NR 72
TC 2
Z9 2
U1 8
U2 17
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2023
VL 19
IS 6
AR 188
DI 10.1145/3584703
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N3AP4
UT WOS:001035785200011
DA 2024-07-18
ER

PT J
AU Li, Y
AF Li, Yang
TI Detection of Moving Object Using Superpixel Fusion Network
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Moving object detection; superpixel; fusion; histogram; convolutional
   neural network
ID NEURAL-NETWORK; SEGMENTATION
AB Moving object detection is still a challenging task in complex scenes. The existing methods based on deep learning mainly use U-Nets and have achieved amazing results. However, they ignore the local continuity between pixels. In order to solve this problem, a method based on a superpixel fusion network (SF-Net) is proposed in this article. First, the median filter is used to extract the candidate foreground (called pixel features) and the image sequence is segmented by superpixel. Then, the histogram features (called superpixel features) of the candidate foreground superpixels are extracted. Next, the pixel features and the superpixel features are the inputs of SF-Net, respectively. Experiments show the effectiveness of SF-Net on 34 image sequences and the average F-measure reaches 0.84. SF-Net can remove more background noise and has stronger expression ability than a network with the same depth.
C1 [Li, Yang] Jiangsu Vocat Coll Informat Technol, Sch Informat Secur, Sch IoT Engn, 1 Qianou Rd, Wuxi, Peoples R China.
C3 Jiangsu Vocational College of Information Technology
RP Li, Y (corresponding author), Jiangsu Vocat Coll Informat Technol, Sch Informat Secur, Sch IoT Engn, 1 Qianou Rd, Wuxi, Peoples R China.
EM liyang19901222@163.com
OI Yang, Li/0000-0002-0087-3472
FU Jiangsu Provincial Colleges and Universities Natural Science Research
   General Project [21KJB520006, 22KJB520017]; Research Project of Jiangsu
   Vocational College of Information Technology [10072020028(001)];
   excellent teaching team of the "Qinglan Project" in Jiangsu Universities
   in 2022 (SuJiaoShi [2022]) [29]; 2021 Jiangsu University Philosophy and
   Social Science Research Project [2021SJA0928]; 2021 Jiangsu Higher
   Education Teaching Reform Research Project (Innovation and Practice of
   the Ideological by Political Reform of the "4+N" Mixed Curriculum of the
   Program Design Foundation) [2021JSJG504]; Water Conservancy Science and
   Technology Project of Jiangsu Province [2022058]
FX This work was supported in part by the Jiangsu Provincial Colleges and
   Universities Natural Science Research General Project under grant nos.
   21KJB520006 and 22KJB520017, in part by the Research Project of Jiangsu
   Vocational College of Information Technology under grant no.
   10072020028(001), in part by the excellent teaching team of the "Qinglan
   Project" in Jiangsu Universities in 2022 (SuJiaoShi [2022] No. 29), in
   part by the 2021 Jiangsu University Philosophy and Social Science
   Research Project (grant no. 2021SJA0928), in part by the 2021 Jiangsu
   Higher Education Teaching Reform Research Project (Innovation and
   Practice of the Ideological, in part by Political Reform of the "4+N"
   Mixed Curriculum of the Program Design Foundation 2021JSJG504), and in
   part by the Water Conservancy Science and Technology Project of Jiangsu
   Province under grant no. 2022058.
CR [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   Bakkay MC, 2018, IEEE IMAGE PROC, P4018, DOI 10.1109/ICIP.2018.8451603
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Boukhriss RR, 2020, PATTERN RECOGN LETT, V129, P205, DOI 10.1016/j.patrec.2019.11.004
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chandrakar R, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116306
   Chen ML, 2018, IEEE T PATTERN ANAL, V40, P1518, DOI 10.1109/TPAMI.2017.2717828
   Fang WT, 2018, IEEE ACCESS, V6, P33376, DOI 10.1109/ACCESS.2018.2846678
   Fu YH, 2020, NEUROCOMPUTING, V387, P1, DOI 10.1016/j.neucom.2019.12.104
   Gadde R, 2016, LECT NOTES COMPUT SC, V9905, P597, DOI 10.1007/978-3-319-46448-0_36
   Giordano D, 2015, PROC CVPR IEEE, P4814, DOI 10.1109/CVPR.2015.7299114
   Giraldo JH, 2021, IEEE INT CONF COMP V, P225, DOI 10.1109/ICCVW54120.2021.00030
   Giraldozuluaga JH, 2022, IEEE T PATTERN ANAL, V44, P2485, DOI 10.1109/TPAMI.2020.3042093
   Guo JT, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3131342
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Hou B., 2020, IEEE INT SYMP CIRC S, P1, DOI DOI 10.1109/iscas45731.2020.9181053
   Hou BX, 2021, IEEE ACCESS, V9, P148433, DOI 10.1109/ACCESS.2021.3123975
   Isik S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023002
   Jampani V, 2018, LECT NOTES COMPUT SC, V11211, P363, DOI 10.1007/978-3-030-01234-2_22
   Javed S, 2019, IEEE T IMAGE PROCESS, V28, P1007, DOI 10.1109/TIP.2018.2874289
   Javed S, 2018, 2018 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P836, DOI 10.1109/SSP.2018.8450718
   Javed S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P930, DOI 10.1109/ICCVW.2015.123
   Javed Sajid, 2017, INT WORKSHOP ACTIVIT, P1
   Jayed S, 2020, IEEE IMAGE PROC, P3209, DOI 10.1109/ICIP40778.2020.9190734
   Jiaxing Zhao, 2018, Computational Visual Media, V4, P333, DOI 10.1007/s41095-018-0123-y
   Ju JG, 2019, MULTIMED TOOLS APPL, V78, P29937, DOI 10.1007/s11042-018-6710-1
   Kalsotra R, 2022, VISUAL COMPUT, V38, P4151, DOI 10.1007/s00371-021-02286-0
   Li CJ, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1236471.1236475
   Li Y, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/1680489
   Li Y, 2019, NEUROCOMPUTING, V323, P352, DOI 10.1016/j.neucom.2018.10.012
   Li YF, 2018, INFRARED PHYS TECHN, V92, P44, DOI 10.1016/j.infrared.2018.05.009
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Lin F, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3440694
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Mandal M, 2022, IEEE T INTELL TRANSP, V23, P6101, DOI [10.1109/TITS.2021.3077883, 10.3233/IP-200233]
   Mandal M, 2021, IEEE T IMAGE PROCESS, V30, P546, DOI 10.1109/TIP.2020.3037472
   Minematsu T, 2020, IEEE IMAGE PROC, P3229, DOI 10.1109/ICIP40778.2020.9191151
   Minematsu T, 2018, J IMAGING, V4, DOI 10.3390/jimaging4060078
   Montero VJ, 2021, J REAL-TIME IMAGE PR, V18, P967, DOI 10.1007/s11554-020-01058-8
   Patil PW, 2019, IEEE T INTELL TRANSP, V20, P4066, DOI 10.1109/TITS.2018.2880096
   Patil PW, 2018, IEEE SYS MAN CYBERN, P1670, DOI 10.1109/SMC.2018.00289
   Peng Suo, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1436, DOI 10.1109/ICOSP.2008.4697402
   Rai M, 2022, MULTIMED TOOLS APPL, V81, P9289, DOI 10.1007/s11042-021-11548-x
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sultana M, 2021, IEEE T MULTIMEDIA, V23, P2005, DOI 10.1109/TMM.2020.3006419
   Tezcan MO, 2020, IEEE WINT CONF APPL, P2763, DOI [10.1109/WACV45572.2020.9093464, 10.1109/wacv45572.2020.9093464]
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Xiang P, 2021, IEEE J-STARS, V14, P2270, DOI 10.1109/JSTARS.2021.3052968
   Yang YC, 2019, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2019.00097
   Zhang J, 2021, IEEE T IMAGE PROCESS, V30, P9058, DOI 10.1109/TIP.2021.3122102
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zhao CQ, 2016, COMM COM INF SC, V662, P392, DOI 10.1007/978-981-10-3002-4_33
   Zhu Lin, 2020, ACM T MULTIM COMPUT, V16, P1
NR 55
TC 0
Z9 0
U1 2
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD SEP
PY 2023
VL 19
IS 5
AR 160
DI 10.1145/3579998
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K7WP6
UT WOS:001018509300009
DA 2024-07-18
ER

PT J
AU Wu, SX
   Sang, JT
   Xu, KY
   Zhang, JM
   Yu, J
AF Wu, Shangxi
   Sang, Jitao
   Xu, Kaiyuan
   Zhang, Jiaming
   Yu, Jian
TI Attention, Please! Adversarial Defense via Activation Rectification and
   Preservation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Adversarial defense; activation map; rectification; preservation
ID PRESENTATION ATTACK DETECTION; DEEP NEURAL-NETWORKS; ROBUSTNESS
AB This study provides a new understanding of the adversarial attack problem by examining the correlation between adversarial attack and visual attention change. In particular, we observed that: (1) images with incomplete attention regions are more vulnerable to adversarial attacks; and (2) successful adversarial attacks lead to deviated and scattered activation map. Therefore, we use the mask method to design an attention-preserving loss and a contrast method to design a loss that makes the model's attention rectification. Accordingly, an attention-based adversarial defense framework is designed, under which better adversarial training or stronger adversarial attacks can be performed through the above constraints. We hope the attention-related data analysis and defense solution in this study will shed some light on the mechanism behind the adversarial attack and also facilitate future adversarial defense/attack model design.
C1 [Wu, Shangxi; Sang, Jitao; Xu, Kaiyuan; Zhang, Jiaming; Yu, Jian] Beijing Jiaotong Univ, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Wu, SX (corresponding author), Beijing Jiaotong Univ, Beijing, Peoples R China.
EM wushangxi@bjtu.edu.cn; jtsang@bjtu.edu.cn; 15281106@bjtu.edu.cn;
   20112023@bjtu.edu.cn; jianyu@bjtu.edu.cn
RI Zhang, Jiaming/AAA-2289-2022
OI Zhang, Jiaming/0000-0003-0991-7109
FU Fundamental Research Funds for the Central Universities [2021JBM011];
   Beijing Natural Science Foundation [JQ20023]; Tianjin Natural Science
   Foundation [20JCZDJC00400]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (No. 2021JBM011), Beijing Natural Science Foundation (No.
   JQ20023) and Tianjin Natural Science Foundation (No. 20JCZDJC00400).
CR Amini S, 2020, IEEE T MULTIMEDIA, V22, P1889, DOI 10.1109/TMM.2020.2969784
   Andriushchenko M., 2020, EUROPEAN C COMPUTER
   [Anonymous], 2018, INT C LEARN REPR
   Athalye A, 2018, PR MACH LEARN RES, V80
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Croce F., 2020, INT C MACHINE LEARNI
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong YP, 2020, PROC CVPR IEEE, P318, DOI 10.1109/CVPR42600.2020.00040
   Du YL, 2019, IEEE T MULTIMEDIA, V21, P555, DOI 10.1109/TMM.2018.2887018
   Duan MX, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3506852
   Duan MX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P264, DOI 10.1145/3474085.3475542
   Duan MX, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3379449
   Ferrari Claudio, 2022, ACM T MULTIM COMPUT, V2022
   Goodfellow I.J., 2015, PROC 3 INT C LEARN R
   Guo Chuan, 2018, PROCEEDING INT C LEA
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, COMPUT SCI, V2
   Kannan H., 2018, Adversarial logit pairing
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kurakin A., 2016, Adversarial machine learning at scale
   Kurakin A., 2016, WORKSHOP TRACK P
   Li HF, 2020, IEEE T IMAGE PROCESS, V29, P9305, DOI 10.1109/TIP.2020.3025404
   Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191
   Liu F, 2021, IEEE T IMAGE PROCESS, V30, P2394, DOI 10.1109/TIP.2021.3052341
   Liu XM, 2021, IEEE ACCESS, V9, P4566, DOI 10.1109/ACCESS.2020.3045078
   Madry A., 2018, ARXIV
   Mohajerani S, 2019, IEEE T IMAGE PROCESS, V28, P4117, DOI 10.1109/TIP.2019.2904267
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Mustafa A, 2020, IEEE T IMAGE PROCESS, V29, P1711, DOI 10.1109/TIP.2019.2940533
   Noack A., 2019, Does interpretability of neural networks imply adversarial robustness?
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Raghavendra R, 2015, IEEE T IMAGE PROCESS, V24, P1060, DOI 10.1109/TIP.2015.2395951
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Selvaraju R. R., 2017, IEEE INT C COMPUTER
   Shen Shiwei., 2017, Ape-gan: Adversarial perturbation elimination with gan
   Song Yang, 2018, PROCEEDING INT C LEA
   Su Z, 2019, IEEE T MULTIMEDIA, V21, P537, DOI 10.1109/TMM.2019.2899279
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tramer F., 2017, INT C LEARNING REPRE
   Tsipras D., 2018, There is no free lunch in adversarial robustness (but there are unexpected benefits), V2
   Wang YL, 2020, IEEE T MULTIMEDIA, V22, P1796, DOI 10.1109/TMM.2019.2949872
   Xiao C, 2020, PROC CVPR IEEE, P409, DOI 10.1109/CVPR42600.2020.00049
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang CZ, 2021, IEEE T IMAGE PROCESS, V30, P1291, DOI 10.1109/TIP.2020.3042083
   Zhang HY, 2019, PR MACH LEARN RES, V97
   Zhang T., 2019, INT C MACHINE LEARNI, P7502
NR 47
TC 0
Z9 0
U1 1
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUL
PY 2023
VL 19
IS 4
AR 142
DI 10.1145/3572843
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FX8
UT WOS:001011937600004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, SG
   Wang, HX
AF Liu, Shiguang
   Wang, Huixin
TI Talking Face Generation via Facial Anatomy
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Cross-modality generation; talking face generation; facial anatomy;
   action units
AB To generate the corresponding talking face from a speech audio and a face image, it is essential to match the variations in the facial appearance with the speech audio in subtle movements of different face regions. Nevertheless, the facial movements generated by the existing methods lack detail and vividness, or the methods are only oriented toward a specific person. In this article, we propose a novel two-stage network to generate talking faces for any target identity through annotations of the action units (AUs). In the first stage, the relationship between the audio and the AUs in the audio-to-AU network is learned. The audio-to-AU network needs to produce the consistent AU group for the input audio. In the second stage, the AU group in the first stage and a face image are fed into the generation network to output the resulting talking face image. Various results confirm that, compared to state-of-the-art methods, our approach is able to produce more realistic and vivid talking faces for arbitrary targets with richer details of facial movements, such as the cheek motion and eyebrow motion.
C1 [Liu, Shiguang; Wang, Huixin] Tianjin Univ, Sch Comp Sci & Technol, Coll Intelligence & Comp, Tianjin, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Coll Intelligence & Comp, Tianjin, Peoples R China.
EM lsg@tju.edu.cn; wanghuixin_hx@foxmail.com
CR Baltrusaitis T, 2015, IEEE INT CONF AUTOMA
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Chen LL, 2019, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2019.00802
   Chen LL, 2018, LECT NOTES COMPUT SC, V11211, P538, DOI 10.1007/978-3-030-01234-2_32
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen WC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1985, DOI 10.1145/3394171.3413623
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chung J., 2017, 5 INT C LEARNING REP
   Chung JS, 2017, LECT NOTES COMPUT SC, V10117, P251, DOI 10.1007/978-3-319-54427-4_19
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Ekman P., 1978, Facial action coding system
   Eskimez SE, 2020, INT CONF ACOUST SPEE, P1948, DOI [10.1109/ICASSP40776.2020.9054103, 10.1109/icassp40776.2020.9054103]
   Eskimez SE, 2021, IEEE T MULTIMEDIA, V24, P3480, DOI 10.1109/TMM.2021.3099900
   Fan B, 2015, INT CONF ACOUST SPEE, P4884, DOI 10.1109/ICASSP.2015.7178899
   Huang FR, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3388861
   Izadinia H, 2013, IEEE T MULTIMEDIA, V15, P378, DOI 10.1109/TMM.2012.2228476
   Jiaqi Hao, 2021, SA '21 Technical Communications: SIGGRAPH Asia 2021 Technical Communications, DOI 10.1145/3478512.3488610
   Jin XT, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1171, DOI 10.1145/3394171.3413572
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Lele Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P35, DOI 10.1007/978-3-030-58545-7_3
   Liu RY, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3300939
   Liu S., 2022, IEEE Trans. Vis. Comput. Graphics, P1
   Liu SG, 2022, IEEE T CIRC SYST VID, V32, P1299, DOI 10.1109/TCSVT.2021.3079897
   Liu XL, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231740
   Liu ZL, 2019, NEUROCOMPUTING, V355, P200, DOI 10.1016/j.neucom.2019.05.003
   Oord A., 2016, ARXIV160903499
   Owens A, 2016, PROC CVPR IEEE, P2405, DOI 10.1109/CVPR.2016.264
   Park J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P649, DOI 10.1109/VR.2018.8446445
   Pham HX, 2017, IEEE COMPUT SOC CONF, P2328, DOI 10.1109/CVPRW.2017.287
   Prajwal KR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P484, DOI 10.1145/3394171.3413532
   Prajwal KR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1428, DOI 10.1145/3343031.3351066
   Pumarola A, 2020, INT J COMPUT VISION, V128, P698, DOI 10.1007/s11263-019-01210-3
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Reed S, 2016, PR MACH LEARN RES, V48
   Shlizerman E, 2018, PROC CVPR IEEE, P7574, DOI 10.1109/CVPR.2018.00790
   Siarohin A, 2019, ADV NEUR IN, V32
   Song Y, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P919
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Tang TR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1598, DOI 10.1145/3240508.3240526
   Tianrui Niu, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P145, DOI 10.1145/3372278.3390684
   Tu XG, 2022, IEEE T CIRC SYST VID, V32, P1805, DOI 10.1109/TCSVT.2021.3083257
   Wang S, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3314577
   Pham HX, 2018, Arxiv, DOI arXiv:1803.07716
   Yi R, 2020, Arxiv, DOI arXiv:2002.10137
   Yuan MK, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1407, DOI 10.1145/3240508.3240559
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhou H, 2019, AAAI CONF ARTIF INTE, P9299
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhu H, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2362
NR 50
TC 4
Z9 4
U1 2
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2023
VL 19
IS 3
AR 125
DI 10.1145/3571746
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FQ5
UT WOS:001011930300025
DA 2024-07-18
ER

PT J
AU Xue, H
   Ling, J
   Tang, AN
   Song, L
   Xie, R
   Zhang, WJ
AF Xue, Han
   Ling, Jun
   Tang, Anni
   Song, Li
   Xie, Rong
   Zhang, Wenjun
TI High-Fidelity Face Reenactment via Identity-Matched Correspondence
   Learning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Face reenactment; 3D face reconstruction; feature transformation;
   generative adversarial networks
AB Face reenactment aims to generate an animation of a source face using the poses and expressions from a target face. Although recent methods have made remarkable progress by exploiting generative adversarial networks, they are limited in generating high-fidelity and identity-preserving results due to the inappropriate driving information and insufficiently effective animating strategies. In this work, we propose a novel face reenactment framework that achieves both high-fidelity generation and identity preservation. Instead of sparse face representations (e.g., facial landmarks and keypoints), we utilize the Projected Normalized Coordinate Code (PNCC) to better preserve facial details. We propose to reconstruct the PNCC with the source identity parameters and the target pose and expression parameters estimated by 3D face reconstruction to factor out the target identity. By adopting the reconstructed representation as the driving information, we address the problem of identity mismatch. To effectively utilize the driving information, we establish the correspondence between the reconstructed representation and the source representation based on the features extracted by an encoder network. This identity-matched correspondence is then utilized to animate the source face using a novel feature transformation strategy. The generator network is further enhanced by the proposed geometry-aware skip connection. Once trained, our model can be applied to previously unseen faces without further training or fine-tuning. Through extensive experiments, we demonstrate the effectiveness of our method in face reenactment and show that our model outperforms state-of-the-art approaches both qualitatively and quantitatively. Additionally, the proposed PNCC reconstruction module can be easily inserted into other methods and improve their performance in cross-identity face reenactment.
C1 [Xue, Han; Ling, Jun; Tang, Anni; Song, Li; Xie, Rong; Zhang, Wenjun] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai, Peoples R China.
   [Xue, Han; Ling, Jun; Tang, Anni; Song, Li; Xie, Rong; Zhang, Wenjun] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr CMIC, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Song, L (corresponding author), Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai, Peoples R China.; Song, L (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr CMIC, Shanghai, Peoples R China.
EM xue_han@sjtu.edu.cn; lingjun@sjtu.edu.cn; memory97@sjtu.edu.cn;
   song_li@sjtu.edu.cn; xierong@sjtu.edu.cn; zhangwenjun@sjtu.edu.cn
OI Song, Li/0000-0002-7124-5182
FU MoE-China Mobile Research Fund Project [MCM20180702]; National Key R&D
   Project of China [2019YFB1802701]; Shanghai Key Laboratory of Digital
   Media Processing and Transmissions
FX This work was supported in part by MoE-China Mobile Research Fund
   Project under Grant MCM20180702, National Key R&D Project of China under
   Grant 2019YFB1802701, and Shanghai Key Laboratory of Digital Media
   Processing and Transmissions.
CR Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648
   [Anonymous], 2017, ARXIV170400028CSLG
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Bansal A, 2018, LECT NOTES COMPUT SC, V11209, P122, DOI 10.1007/978-3-030-01228-1_8
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Bounareli S, 2022, Arxiv, DOI arXiv:2202.00046
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Burkov E., 2020, P IEEE CVF C COMP VI, P13783, DOI DOI 10.1109/CVPR42600.2020.01380
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen Zhuo, 2020, P IEEE CVF C COMP VI, P13518
   Chung JS, 2018, INTERSPEECH, P1086
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng Y, 2020, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR42600.2020.00520
   Doukas Michail Christos, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P31, DOI 10.1109/TBIOM.2021.3049576
   Fincato M, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3491226
   Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874
   Ghosh P, 2020, INT CONF 3D VISION, P868, DOI 10.1109/3DV50981.2020.00097
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Ha S, 2020, AAAI CONF ARTIF INTE, V34, P10893
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hsu GS, 2022, PROC CVPR IEEE, P632, DOI 10.1109/CVPR52688.2022.00072
   Huang PH, 2020, PROC CVPR IEEE, P7082, DOI 10.1109/CVPR42600.2020.00711
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jianzhu Guo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P152, DOI 10.1007/978-3-030-58529-7_10
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang Wonjun, 2022, ARXIV
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Kingma D. P., 2014, arXiv
   Koujan MR, 2020, IEEE INT CONF AUTOMA, P16, DOI 10.1109/FG47880.2020.00048
   Kowalski Marek, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P299, DOI 10.1007/978-3-030-58621-8_18
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Nagrani A, 2018, PROC CVPR IEEE, P8427, DOI 10.1109/CVPR.2018.00879
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Nirkin Y, 2022, Arxiv, DOI arXiv:2202.12972
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455
   Shamai G, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3337067
   Siarohin A, 2021, PROC CVPR IEEE, P13648, DOI 10.1109/CVPR46437.2021.01344
   Siarohin A, 2019, PROC CVPR IEEE, P2372, DOI 10.1109/CVPR.2019.00248
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Siarohin Aliaksandr, 2019, Adv.Neural Inf. Process. Syst.
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P899
   Song LS, 2021, PROC CVPR IEEE, P2236, DOI 10.1109/CVPR46437.2021.00227
   Tewari A, 2020, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR42600.2020.00618
   Tewari A, 2017, IEEE INT CONF COMP V, P1274, DOI 10.1109/ICCVW.2017.153
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Tripathy S, 2020, IEEE WINT CONF APPL, P3374, DOI [10.1109/wacv45572.2020.9093474, 10.1109/WACV45572.2020.9093474]
   Unterthiner T, 2019, Arxiv, DOI arXiv:1812.01717
   Wang T.-C., 2019, ARXIV191012713
   Wang TC, 2021, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR46437.2021.00991
   Wang XP, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3355397
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiles O, 2018, LECT NOTES COMPUT SC, V11217, P690, DOI 10.1007/978-3-030-01261-8_41
   Wu WN, 2018, LECT NOTES COMPUT SC, V11205, P622, DOI 10.1007/978-3-030-01246-5_37
   Xiang ST, 2020, Arxiv, DOI arXiv:2004.12452
   Xu RZ, 2017, Arxiv, DOI arXiv:1710.06090
   Yao GM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1773, DOI 10.1145/3394171.3413865
   Yao GM, 2021, AAAI CONF ARTIF INTE, V35, P3172
   Zakharov Egor, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P524, DOI 10.1007/978-3-030-58610-2_31
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang H., 2021, arXiv
   Zhang J, 2022, IEEE T CIRC SYST VID, V32, P5916, DOI 10.1109/TCSVT.2022.3164190
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhang Yunxuan, 2019, P BRIT MACHINE VISIO
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
NR 75
TC 4
Z9 4
U1 3
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2023
VL 19
IS 3
AR 122
DI 10.1145/3571857
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FQ5
UT WOS:001011930300022
DA 2024-07-18
ER

PT J
AU Zhou, W
   Hou, YK
   Chen, DH
   Hu, HF
   Su, T
AF Zhou, Wei
   Hou, Yanke
   Chen, Dihu
   Hu, Haifeng
   Su, Tao
TI Attention-Augmented Memory Network for Image Multi-Label Classification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multi-label classification; categorical memory module; channel-relation;
   spatial-relation; visual analysis
AB The purpose of image multi-label classification is to predict all the object categories presented in an image. Some recent works exploit graph convolution network to capture the correlation between labels. Although promising results have been reported, these methods cannot learn salient object features in the images and ignore the correlation between channel feature maps. In addition, the current researches only learn the feature information within individual input image, but fail to mine the contextual information of various categories from the dataset to enhance the input feature representation. To address these issues, we propose an Attention-Augmented Memory Network (AAMN) model for the image multi-label classification task. Specifically, we first propose a novel categorical memory module to excavate the contextual information of various categories from the dataset to augment the current input feature. Secondly, we design a new channel-relation exploration module to capture the inter-channel relationship of features, so as to enhance the correlation between objects in the images. Thirdly, we develop a spatial-relation enhancement module to model second-order statistics of features and capture long-range dependencies between pixels in feature maps, so as to learn salient object features. Experimental results on standard benchmarks, including MS-COCO 2014, PASCAL VOC 2007, and VG-500, demonstrate the effectiveness and superiority of AAMN model, which outperforms current state-of-the-art methods.
C1 [Zhou, Wei; Hou, Yanke; Chen, Dihu; Hu, Haifeng; Su, Tao] Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Hu, HF (corresponding author), Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM zhouw75@mail2.sysu.edu.cn; houyk@mail2.sysu.edu.cn;
   stscdh@mail.sysu.edu.cn; huhaif@mail.sysu.edu.cn; sutao@mail.sysu.edu.cn
OI Zhou, Wei/0000-0002-9237-7205; Hou, Yanke/0000-0002-9421-5306; Hu,
   Haifeng/0000-0002-4884-323X; chen, dihu/0000-0001-5432-8149
FU National Natural Science Foundation of China [62076262, 61673402,
   61273270, 60802069]; Science and Technology Program of Guangdong
   Province [2021B1101270007, 2019B010140002]
FX This work was supported in part by the National Natural Science
   Foundation of China (62076262, 61673402, 61273270, 60802069), and in
   part by the Science and Technology Program of Guangdong Province
   (2021B1101270007, 2019B010140002).
CR Alonso I, 2021, Arxiv, DOI arXiv:2104.13415
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32
   Chen TS, 2022, IEEE T PATTERN ANAL, V44, P1371, DOI 10.1109/TPAMI.2020.3025814
   Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Cheng X, 2021, Arxiv, DOI arXiv:2106.06195
   Deng HM, 2019, IEEE I CONF COMP VIS, P6677, DOI 10.1109/ICCV.2019.00678
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng Weijian, 2020, ARXIV
   Durand T, 2019, IEEE T PATTERN ANAL, V41, P337, DOI 10.1109/TPAMI.2017.2788435
   Durand T, 2017, PROC CVPR IEEE, P5957, DOI 10.1109/CVPR.2017.631
   Dutta Ayushi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P191, DOI 10.1007/978-3-030-58526-6_12
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao BB, 2021, IEEE T IMAGE PROCESS, V30, P5920, DOI 10.1109/TIP.2021.3088605
   Gao ZL, 2019, PROC CVPR IEEE, P3019, DOI 10.1109/CVPR.2019.00314
   Gong YC, 2014, Arxiv, DOI arXiv:1312.4894
   Guo H, 2019, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2019.00082
   Gupta S, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3436494
   Hassanin M, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2022.103448
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jeong S, 2021, PROC CVPR IEEE, P6554, DOI 10.1109/CVPR46437.2021.00649
   Ji WT, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3446792
   Jin JR, 2016, INT C PATT RECOG, P2452, DOI 10.1109/ICPR.2016.7900004
   Krishna R, 2016, Arxiv, DOI arXiv:1602.07332
   Lanchantin J, 2021, PROC CVPR IEEE, P16473, DOI 10.1109/CVPR46437.2021.01621
   Levi H, 2019, Arxiv, DOI arXiv:1811.12152
   Li JB, 2020, LECT NOTES COMPUT SC, V12396, P736, DOI 10.1007/978-3-030-61609-0_58
   Li Q, 2019, Arxiv, DOI arXiv:1909.13005
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Liu SL, 2021, Arxiv, DOI arXiv:2107.10834
   Lyu F, 2019, IEEE T MULTIMEDIA, V21, P1971, DOI 10.1109/TMM.2019.2894964
   Meng Q., 2019, PROC ACM MULTIMEDIA, P1
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Ridnik T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P82, DOI 10.1109/ICCV48922.2021.00015
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Inder Pal, 2022, AAAI22 WORKSHOP PROG
   Sun Dengdi, 2022, COGN COMPUT, V9, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Xiaomei, 2021, 2021 IEEE INT C MULT, P1
   Wang Y, 2020, AAAI CONF ARTIF INTE, V34, P12265
   Wang YT, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1575, DOI 10.1145/3340531.3411880
   Wang Z, 2022, IEEE T CIRC SYST VID, V32, P1848, DOI 10.1109/TCSVT.2021.3083978
   Weston J, 2015, Arxiv, DOI arXiv:1410.3916
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu XP, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P284, DOI 10.1145/3394171.3414046
   Yan Z, 2019, IEEE ACCESS, V7, P98005, DOI 10.1109/ACCESS.2019.2929512
   Yazici Vacit Oguz, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13437, DOI 10.1109/CVPR42600.2020.01345
   Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35
   Yu WJ, 2019, PATTERN RECOGN, V91, P322, DOI 10.1016/j.patcog.2019.03.006
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Yue KY, 2018, Arxiv, DOI arXiv:1810.13125
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JJ, 2018, IEEE T MULTIMEDIA, V20, P2801, DOI 10.1109/TMM.2018.2812605
   Zhang K., 2020, P IEEE CVF C COMP VI, P9050
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
   Zhang ZZ, 2020, Arxiv, DOI arXiv:1904.02998
   Zhao HY, 2020, IEEE ACCESS, V8, P225539, DOI 10.1109/ACCESS.2020.3044446
   Zhao Rui, 2021, ARXIV
   Zhou FT, 2021, Arxiv, DOI arXiv:2012.12509
   Zhou Fengtao, 2021, IEEE T CIRC SYST VID
   Zhou Wei, 2022, ACM T MULTIM COMPUT
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
   Zhu K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P184, DOI 10.1109/ICCV48922.2021.00025
   Zhu L., 2021, P IEEECVF INT C COMP, P12292
   Zhu XZ, 2019, IEEE I CONF COMP VIS, P6687, DOI 10.1109/ICCV.2019.00679
NR 74
TC 2
Z9 2
U1 5
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2023
VL 19
IS 3
AR 116
DI 10.1145/3570166
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FQ5
UT WOS:001011930300016
DA 2024-07-18
ER

PT J
AU Mei, HY
   Yu, LT
   Xu, K
   Wang, Y
   Yang, X
   Wei, XP
   Lau, RWH
AF Mei, Haiyang
   Yu, Letian
   Xu, Ke
   Wang, Yang
   Yang, Xin
   Wei, Xiaopeng
   Lau, Rynson W. H.
TI Mirror Segmentation via Semantic-aware Contextual Contrasted Feature
   Learning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Mirror segmentation; contextual contrast; semantic association; dataset;
   reflection; deep neural network
ID SALIENT; NETWORK
AB Mirrors are everywhere in our daily lives. Existing computer vision systems do not consider mirrors, and hence may get confused by the reflected content inside a mirror, resulting in a severe performance degradation. However, separating the real content outside a mirror from the reflected content inside it is non-trivial. The key challenge is that mirrors typically reflect contents similar to their surroundings, making it very difficult to differentiate the two. In this article, we present a novel method to segment mirrors from a single RGB image. To the best of our knowledge, this is the first work to address the mirror segmentation problem with a computational approach. We make the following contributions: First, we propose a novel network, called MirrorNet+, for mirror segmentation, by modeling both contextual contrasts and semantic associations. Second, we construct the first large-scale mirror segmentation dataset, which consists of 4,018 pairs of images containing mirrors and their corresponding manually annotated mirror masks, covering a variety of daily-life scenes. Third, we conduct extensive experiments to evaluate the proposed method and show that it outperforms the related state-of-the-art detection and segmentation methods. Fourth, we further validate the effectiveness and generalization capability of the proposed semantic awareness contextual contrasted feature learning by applying MirrorNet+ to other vision tasks, i.e., salient object detection and shadow detection. Finally, we provide some applications of mirror segmentation and analyze possible future research directions. Project homepage: https://mhaiyang.github.io/TOMM2022-MirrorNet+/index.html.
C1 [Mei, Haiyang; Yu, Letian; Wang, Yang; Yang, Xin; Wei, Xiaopeng] Dalian Univ Technol, 2 Linggong Rd, Dalian 116024, Liaoning, Peoples R China.
   [Xu, Ke; Lau, Rynson W. H.] City Univ Hong Kong, Kowloon, 83 Tat Chee Ave, Hong Kong 518057, Peoples R China.
C3 Dalian University of Technology; City University of Hong Kong
RP Wei, XP (corresponding author), Dalian Univ Technol, 2 Linggong Rd, Dalian 116024, Liaoning, Peoples R China.; Xu, K; Lau, RWH (corresponding author), City Univ Hong Kong, Kowloon, 83 Tat Chee Ave, Hong Kong 518057, Peoples R China.
EM mhy666@mail.dlut.edu.cn; letianyu@mail.dlut.edu.cn; kkangwing@gmail.com;
   yangwang06@mail.dlut.edu.cn; xinyang@dlut.edu.cn; xpwei@dlut.edu.cn;
   Rynson.Lau@cityu.edu.hk
RI Mei, Haiyang/AAA-1479-2020
OI Mei, Haiyang/0000-0003-3549-9684; Wang, Yang/0000-0003-3369-6772; LAU,
   Rynson W H/0000-0002-8957-8129; XU, Ke/0000-0001-5855-3810
FU National Key Research and Development Program of China
   [2022ZD0210500/2021ZD0112400]; National Natural Science Foundation of
   China [61972067/U21A20491/U1908214]; Innovation Technology Funding of
   Dalian [2020JJ26GX036]; Research Grants Council of Hong Kong [11205620];
   Strategic Research Grant from City University of Hong Kong [7005674]
FX This work was supported in part by the National Key Research and
   Development Program of China (No. 2022ZD0210500/2021ZD0112400) and the
   National Natural Science Foundation of China underGrant
   61972067/U21A20491/U1908214, the Innovation Technology Funding of Dalian
   (2020JJ26GX036), the Research Grants Council of Hong Kong (Grant No.:
   11205620), and a Strategic Research Grant from City University of Hong
   Kong (Ref.: 7005674).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen YZ, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3460940
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Gao LL, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P719
   Guo S., 2022, CVPR, P4361
   He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778
   Krahenbuhl Philipp, 2011, Advances in neural information processing systems, V24
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin F, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3440694
   Lin F, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3387926
   Lin Jiaying, 2022, ACM T MULTIM COMPUT, V2022
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Man X, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3503927
   Mei H., 2022, P IEEECVF C COMPUTER, P12622
   Mei HY, 2022, IEEE T CIRC SYST VID, V32, P1378, DOI 10.1109/TCSVT.2021.3069848
   Mei HY, 2021, PROC CVPR IEEE, P8768, DOI 10.1109/CVPR46437.2021.00866
   Mei HY, 2020, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR42600.2020.00374
   Mei Haiyang, 2022, IEEE T PATTERN ANAL, V2022
   Messina N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3451390
   Olson E, 2011, IEEE INT CONF ROBOT
   Pang YW, 2022, PROC CVPR IEEE, P2150, DOI 10.1109/CVPR52688.2022.00220
   Punn NS, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3376922
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qu LQ, 2017, PROC CVPR IEEE, P2308, DOI 10.1109/CVPR.2017.248
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song Yue, 2022, ACM T MULTIM COMPUT, V2022
   Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390
   Tan X, 2023, IEEE T PATTERN ANAL, V45, P3492, DOI 10.1109/TPAMI.2022.3181030
   Tan X, 2021, IEEE T IMAGE PROCESS, V30, P9085, DOI 10.1109/TIP.2021.3122004
   Tian X, 2022, INT J COMPUT VISION, V130, P729, DOI 10.1007/s11263-021-01553-w
   Tian Xin, 2022, P IEEECVF C COMPUTER, P5882
   Vaswani A, 2017, ADV NEUR IN, V30
   Vincente TFY, 2016, LECT NOTES COMPUT SC, V9910, P816, DOI 10.1007/978-3-319-46466-4_49
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Whelan T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201319
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xu K, 2021, IEEE T IMAGE PROCESS, V30, P8497, DOI 10.1109/TIP.2021.3116794
   Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235
   Xu X, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3414839
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang X, 2019, IEEE I CONF COMP VIS, P8808, DOI 10.1109/ICCV.2019.00890
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P328, DOI 10.1109/TMM.2018.2863602
   Yang ZZ, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3446618
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Yu LT, 2022, IEEE T IMAGE PROCESS, V31, P2920, DOI 10.1109/TIP.2022.3162709
   Zhang J., 2020, ICME
   Zhang J, 2022, IEEE T CIRC SYST VID, V32, P5916, DOI 10.1109/TCSVT.2022.3164190
   Zhang JQ, 2022, IEEE T CIRC SYST VID, V32, P1020, DOI 10.1109/TCSVT.2021.3071191
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhu L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4682, DOI 10.1109/ICCV48922.2021.00466
   Zhu L, 2018, LECT NOTES COMPUT SC, V11210, P122, DOI 10.1007/978-3-030-01231-1_8
NR 78
TC 3
Z9 3
U1 5
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2023
VL 19
IS 2
SU S
AR 100
DI 10.1145/3566127
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J8FS5
UT WOS:001011932300025
DA 2024-07-18
ER

PT J
AU Liu, Y
   Yin, XH
   Wan, ZL
   Yue, GH
   Zheng, Z
AF Liu, Yun
   Yin, Xiaohua
   Wan, Zuliang
   Yue, Guanghui
   Zheng, Zhi
TI Toward A No-reference Omnidirectional Image Quality Evaluation by Using
   Multi-perceptual Features
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Omnidirectional images; blind quality assessment; multi-scale visual
   perception
AB Compared to ordinary images, omnidirectional image (OI) usually has a broader view and a higher resolution, and image quality assessment (IQA) can help people to understand and improve their visual experience. However, the current IQA works cannot achieve good performance. To address this, we proposed a novel visual perception-based no-reference/blind omnidirectional image quality assessment (NR/B-OIQA) model. The gradient-based global structural features and gray-level co-occurrence matrix-based local structural features are combined together to highlight the rich quality-aware structural information. And a novel steganalysis real model-based color descriptor is extracted to reflect the color information that ignored in most IQA models. With a multi-scale visual perception, we take image entropy and the natural scene statistics features to convey the high-level semantics and quantify the unnaturalness of omnidirectional images. Finally, we apply support vector regression to predict the objective quality value based on the subjective scores and extracted all features. Experiments are conducted on OIQA and CVIQD2018 Databases, and the results illustrate that our model has more reliable performance and stronger competitiveness and receives better conformity with the subjective values.
C1 [Liu, Yun; Yin, Xiaohua; Wan, Zuliang] Liaoning Univ, Shenyang, Peoples R China.
   [Yue, Guanghui] Shenzhen Univ, Shenzhen, Peoples R China.
   [Zheng, Zhi] Beijing Jiaotong Univ, Beijing, Peoples R China.
C3 Liaoning University; Shenzhen University; Beijing Jiaotong University
RP Liu, Y; Yin, XH (corresponding author), Liaoning Univ, Shenyang, Peoples R China.; Yue, GH (corresponding author), Shenzhen Univ, Shenzhen, Peoples R China.
EM yunliu@tju.edu.cn; yinxhhhh@163.com; zuliangwan@gmail.com;
   yueguanghui@szu.edu.cn
OI Liu, Yun/0000-0003-4115-1617
FU National Natural Science Foundation of China [61901205, 62001302];
   Guangdong Basic and Applied Basic Research Foundation [2019A1515111205];
   Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University [VR-LAB2021C05]
FX This work was supported by the National Natural Science Foundation of
   China under Grants No. 61901205 and No. 62001302, Guangdong Basic and
   Applied Basic Research Foundation under Grant No. 2019A1515111205, and
   Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University (Grant No. VR-LAB2021C05).
CR Chen CLZ, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3447393
   Chen ZB, 2018, IEEE T IMAGE PROCESS, V27, P721, DOI 10.1109/TIP.2017.2766780
   Duan HY, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351786
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He LH, 2011, SIGNAL IMAGE VIDEO P, V5, P283, DOI 10.1007/s11760-010-0200-x
   Huawei iLab, 2019, VR DAT REP
   Jiang H, 2021, IEEE T IMAGE PROCESS, V30, P2364, DOI 10.1109/TIP.2021.3052073
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Kim HG, 2020, IEEE T CIRC SYST VID, V30, P917, DOI 10.1109/TCSVT.2019.2898732
   Kiran I, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010014
   Kusuno Y, 2019, IEEE/SICE I S SYS IN, P325, DOI [10.1109/SII.2019.8700393, 10.1109/sii.2019.8700393]
   Larsson J, 2006, J NEUROPHYSIOL, V95, P862, DOI 10.1152/jn.00668.2005
   Lasmar NE, 2009, IEEE IMAGE PROC, P2281, DOI 10.1109/ICIP.2009.5414404
   Li HD, 2020, SIGNAL PROCESS, V174, DOI 10.1016/j.sigpro.2020.107616
   Li J, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P113, DOI 10.1145/3177404.3177425
   Li QH, 2017, NEUROCOMPUTING, V236, P93, DOI 10.1016/j.neucom.2016.09.105
   Li YF, 2019, IEEE ACCESS, V7, P46706, DOI 10.1109/ACCESS.2019.2909073
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu YT, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3414837
   Ma KD, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5664, DOI 10.1145/3474085.3478870
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shim I, 2019, IEEE T CIRC SYST VID, V29, P1569, DOI 10.1109/TCSVT.2018.2846292
   Sporring J., 1996, PROC INT CONF PATT R
   Sui XJ, 2022, IEEE T VIS COMPUT GR, V28, P3022, DOI 10.1109/TVCG.2021.3050888
   Sun W., 2019, IEEE INT SYMP CIRC S
   Sun W, 2018, IEEE INT WORKSH MULT
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303
   Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   wikipedia, 2020, VR PHOT
   Xia Y, 2019, PROCEEDINGS OF THE TENTH INTERNATIONAL WORKSHOP ON PROGRAMMING MODELS AND APPLICATIONS FOR MULTICORES AND MANYCORES (PMAM 2019), P1, DOI 10.1145/3303084.3309487
   Xu JH, 2021, IEEE T CIRC SYST VID, V31, P1724, DOI 10.1109/TCSVT.2020.3015186
   Xu JZ, 2021, IMPACT ASSESS PROJ A, V39, P429, DOI [10.1109/TR.2020.3040191, 10.1080/14615517.2020.1848242]
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yeung YL, 2020, IEEE T CIRC SYST VID, V30, P1423, DOI 10.1109/TCSVT.2019.2903432
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zakharchenko V, 2016, PROC SPIE, V9970, DOI 10.1117/12.2235885
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zheng X., 2020, IEEE ACCESS, V8, P1
   Zhou W, 2021, Arxiv, DOI arXiv:2102.11393
   Zhou W, 2020, INFORM SCIENCES, V528, P205, DOI 10.1016/j.ins.2020.04.030
   Zhou W, 2020, IEEE T IMAGE PROCESS, V29, P4070, DOI 10.1109/TIP.2020.2969777
   Zhou YF, 2018, INT CONF SIGN PROCES, P54, DOI 10.1109/ICSP.2018.8652269
   Zhu SP, 2020, IEEE T CIRC SYST VID, V30, P1946, DOI 10.1109/TCSVT.2019.2911396
NR 52
TC 2
Z9 2
U1 2
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2023
VL 19
IS 2
AR 72
DI 10.1145/3549544
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J7DP3
UT WOS:001011190000022
DA 2024-07-18
ER

PT J
AU Hu, YZ
   Yang, WH
   Liu, JY
   Guo, ZM
AF Hu, Yuzhang
   Yang, Wenhan
   Liu, Jiaying
   Guo, Zongming
TI Deep Inter Prediction with Error-Corrected Auto-Regressive Network for
   Video Coding
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE High Efficient Video Coding (HEVC); inter prediction; deep learning;
   virtual reference frame; Error-Corrected Auto-Regressive Network;
   Versatile Video Coding (VVC)
AB Modern codecs remove temporal redundancy of a video via inter prediction, i.e., searching previously coded frames for similar blocks and storing motion vectors to save bit-rates. However, existing codecs adopt blocklevel motion estimation, where a block is regressed by reference blocks linearly and is doomed to fail to deal with non-linear motions. In this article, we generate virtual reference frames (VRFs) with previously reconstructed frames via deep networks to offer an additional candidate, which is not constrained to linear motion structure and further significantly improves coding efficiency. More specifically, we propose a novel deep Auto-Regressive Moving-Average (ARMA) model, Error-Corrected Auto-Regressive Network (ECARNet), equipped with the powers of the conventional statistic ARMA models and deep networks jointly for reference frame prediction. Similar to conventionalARMAmodels, the ECAR-Net consists of two stages: AutoRegression (AR) stage and Error-Correction (EC) stage, where the first part predicts the signal at the current time-step based on previously reconstructed frames, while the second one compensates for the output of the AR stage to obtain finer details. Different from the statistic AR models only focusing on short-term temporal dependency, the AR model of our ECAR-Net is further injected with the long-term dynamics mechanism, where long temporal information is utilized to help predict motions more accurately. Furthermore, ECAR-Net works in a configuration-adaptive way, i.e., using different dynamics and error definitions for the Low Delay B and Random Access configurations, which helps improve the adaptivity and generality in diverse coding scenarios. With the well-designed network, our method surpasses HEVC on average 5.0% and 6.6% BD-rate saving for the luma component under the Low Delay B and Random Access configurations and also obtains on average 1.54% BD-rate saving over VVC. Furthermore, ECAR-Net works in a configuration-adaptive way, i.e., using different dynamics and error definitions for the Low Delay B and Random Access configurations, which helps improve the adaptivity and generality in diverse coding scenarios.
C1 [Hu, Yuzhang; Yang, Wenhan; Liu, Jiaying; Guo, Zongming] Peking Univ, Wangxuan Inst Comp Technol, Zhongguancun North St 128, Beijing, Peoples R China.
C3 Peking University
RP Liu, JY (corresponding author), Peking Univ, Wangxuan Inst Comp Technol, Zhongguancun North St 128, Beijing, Peoples R China.
EM yuzhanghu@pku.edu.cn; yangwenhan@pku.edu.cn; liujiaying@pku.edu.cn;
   guozongming@pku.edu.cn
OI Liu, Jiaying/0000-0002-0468-9576
FU National Key Research and Development Program of China [2018AAA0102702];
   National Natural Science Foundation of China [62172020]; research
   achievement of Key Laboratory of Science, Techonology and Standard in
   Press Industry (Key Laboratory of Intelligent Press Media Technology);
   State Key Laboratory of Media Convergence Production Technology and
   Systems
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant No. 2018AAA0102702, the
   National Natural Science Foundation of China under Contract No.
   62172020, and a research achievement of Key Laboratory of Science,
   Techonology and Standard in Press Industry (Key Laboratory of
   Intelligent Press Media Technology) and State Key Laboratory of Media
   Convergence Production Technology and Systems.
CR Bjontegaard G., 2001, CALCULATION AVERAGE
   Bossen F., 2013, JCTVCL1100
   Bross B., 2020, JVET-S2001
   Choi H, 2020, IEEE T CIRC SYST VID, V30, P1843, DOI 10.1109/TCSVT.2019.2924657
   Cox D., 2017, INT C LEARNING REPRE
   Denton E, 2015, ADV NEUR IN, V28
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu P, 2018, IEEE T MULTIMEDIA, V20, P2814, DOI 10.1109/TMM.2018.2815784
   Hu Y., 2020, P IEEE INT S CIRCUIT, P1
   Hu YY, 2019, IEEE T MULTIMEDIA, V21, P3024, DOI 10.1109/TMM.2019.2920603
   Hu YY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP)
   Hu YY, 2018, IEEE DATA COMPR CONF, P413, DOI 10.1109/DCC.2018.00066
   Huo S, 2021, IEEE T CIRC SYST VID, V31, P1178, DOI 10.1109/TCSVT.2020.2995243
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jia CM, 2019, IEEE T IMAGE PROCESS, V28, P3343, DOI 10.1109/TIP.2019.2896489
   Jin X, 2018, LECT NOTES COMPUT SC, V11256, P439, DOI 10.1007/978-3-030-03398-9_38
   Kang J, 2017, IEEE IMAGE PROC, P26, DOI 10.1109/ICIP.2017.8296236
   Kingma D. P., 2014, arXiv
   LAUDE T, 2019, PICT COD SYMP, pNIL23
   Li JH, 2018, IEEE T IMAGE PROCESS, V27, P3236, DOI 10.1109/TIP.2018.2817044
   Li MD, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3341728
   Li MD, 2016, LECT NOTES COMPUT SC, V9911, P819, DOI 10.1007/978-3-319-46478-7_50
   Li MD, 2015, IEEE T CIRC SYST VID, V25, P200, DOI 10.1109/TCSVT.2014.2347531
   Lin JP, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP)
   Liu JY, 2020, IEEE T MULTIMEDIA, V22, P2497, DOI 10.1109/TMM.2019.2961504
   Liu JY, 2019, IEEE T IMAGE PROCESS, V28, P2140, DOI 10.1109/TIP.2018.2882923
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126
   Meyer S, 2015, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2015.7298747
   Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37
   Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Reda FA, 2018, LECT NOTES COMPUT SC, V11211, P747, DOI 10.1007/978-3-030-01234-2_44
   Ren J, 2011, IEEE IMAGE PROC, P1177, DOI 10.1109/ICIP.2011.6115639
   Shi XJ, 2015, ADV NEUR IN, V28
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Wang DZ, 2019, IEEE IMAGE PROC, P2671, DOI [10.1109/ICIP.2019.8803253, 10.1109/icip.2019.8803253]
   Wang Y., 2018, P IEEE INT C MULTIME, P1
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xia SF, 2018, IEEE DATA COMPR CONF, P127, DOI 10.1109/DCC.2018.00021
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yang WH, 2019, IEEE T CIRC SYST VID, V29, P1270, DOI 10.1109/TCSVT.2018.2838453
   Yang WH, 2018, IEEE T CIRC SYST VID, V28, P1071, DOI 10.1109/TCSVT.2016.2638864
   Zamir Syed Waqas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P492, DOI 10.1007/978-3-030-58595-2_30
   Zhang XS, 2018, IEEE IMAGE PROC, P390, DOI 10.1109/ICIP.2018.8451694
   Zhao L, 2019, IEEE T IMAGE PROCESS, V28, P4832, DOI 10.1109/TIP.2019.2913545
   Zhao L, 2018, IEEE IMAGE PROC, P206, DOI 10.1109/ICIP.2018.8451465
NR 48
TC 2
Z9 2
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2023
VL 19
IS 1
SU S
DI 10.1145/3528173
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Q4HK
UT WOS:000927169800008
DA 2024-07-18
ER

PT J
AU Huang, XW
   Sang, JT
   Xu, CS
AF Huang, Xiaowen
   Sang, Jitao
   Xu, Changsheng
TI Image-Based Personality Questionnaire Design
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Personality questionnaire design; personality estimation; image favorite
   behavior analysis
ID MODEL; IMPRESSIONS
AB This article explores the problem of image-based personality questionnaire design. Compared with the traditional text-based personality questionnaire, the image-based personality questionnaire is more natural, truthful, and language insensitive. Instead of responding to textual questions, the subjects are provided a set of "choose-your-favorite-image" visual questions. With each question, consisting of image options describing the same semantic concept, the subjects are requested to choose their favorite image. Based on responses to typically 15 to 25 questions, we can accurately estimate the subjects' personality traits in five dimensions. The solution to design such an image-based personality questionnaire consists of concept-question identification and image-option selection. We have presented a preliminary framework to regularize these two steps in this exploratory study. A demo automatically adapting between desktop and mobile devices is available at http://120.27.209.14/vbfi. Subjective and objective evaluations have demonstrated the feasibility of accurately estimating a subject's personality in a limited round of questions.
C1 [Huang, Xiaowen; Sang, Jitao] Beijing Jiaotong Univ, Sch Comp & Informat Technol, 3 Shangyuancun, Beijing 100044, Peoples R China.
   [Huang, Xiaowen; Sang, Jitao] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, 3 Shangyuancun, Beijing 100044, Peoples R China.
   [Sang, Jitao] Peng Cheng Lab, Shenzhen 518055, Peoples R China.
   [Xu, Changsheng] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, 95 Zhongguancun Rd, Beijing 100190, Peoples R China.
   [Xu, Changsheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, 80 Zhongguanctm Rd, Beijing 100048, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Peng Cheng
   Laboratory; Chinese Academy of Sciences; Institute of Automation, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Sang, JT (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, 3 Shangyuancun, Beijing 100044, Peoples R China.; Sang, JT (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, 3 Shangyuancun, Beijing 100044, Peoples R China.; Sang, JT (corresponding author), Peng Cheng Lab, Shenzhen 518055, Peoples R China.
EM xwhuang@bjtu.edu.cn; jtsang@bjtu.edu.cn; csxu@nlpr.ia.ac.cn
RI xu, cj/HJZ-3488-2023
FU National Key R&D Program of China [2018AAA0100604]; Fundamental Research
   Funds for the Central Universities [2021RC217]; Beijing Natural Science
   Foundation [JQ20023]; National Natural Science Foundation of China
   [61632002, 61832004, 62036012, 61720106006]
FX This work is supported by the National Key R&D Program of China (grant
   no. 2018AAA0100604), the Fundamental Research Funds for the Central
   Universities (grant no. 2021RC217), the Beijing Natural Science
   Foundation (grant no. JQ20023), and the National Natural Science
   Foundation of China (grant nos. 61632002, 61832004, 62036012,
   61720106006).
CR Aran O, 2014, IEEE T MULTIMEDIA, V16, P201, DOI 10.1109/TMM.2013.2284893
   Back MD, 2010, PSYCHOL SCI, V21, P372, DOI 10.1177/0956797609360756
   Batrinca L, 2016, IEEE T MULTIMEDIA, V18, P659, DOI 10.1109/TMM.2016.2522763
   Biederman I, 2006, AM SCI, V94, P247, DOI 10.1511/2006.3.247
   Biel JI, 2013, IEEE T MULTIMEDIA, V15, P41, DOI 10.1109/TMM.2012.2225032
   Birlutiu A, 2013, MACH LEARN, V90, P1, DOI 10.1007/s10994-012-5297-4
   Cantador I., 2013, CEUR WORKSHOP PROC
   Chittaranjan G, 2011, IEEE INT SYM WRBL CO, P29, DOI 10.1109/ISWC.2011.29
   Cristani M., 2013, P 21 ACM INT C MULT, P213
   De Raad B, 1998, J CROSS CULT PSYCHOL, V29, P212
   Ferwerda Bruce, 2018, 23 INT C INT US INT
   Fiske S. T, 1991, SOCIAL COGNITION M
   Funder D.C., 1997, PERSONALITY PUZZLE
   Guntuku Sharath Chandra, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P171, DOI 10.1007/978-3-319-14442-9_15
   Guntuku SC, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P223, DOI 10.1145/3091478.3091522
   HARRIS CW, 1964, PSYCHOMETRIKA, V29, P347, DOI 10.1007/BF02289601
   Ivcevic Z, 2012, PSYCHOL POP MEDIA CU, V1, P38, DOI 10.1037/a0027329
   Jitao Sang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P95, DOI 10.1007/978-3-319-48890-5_10
   Kramer RSS, 2010, Q J EXP PSYCHOL, V63, P2273, DOI 10.1080/17470211003770912
   Lay Alixe, 2018, 23 INT C INT US INT
   Little AC, 2007, BRIT J PSYCHOL, V98, P111, DOI 10.1348/000712606X109648
   Lovato P, 2014, IEEE T INF FOREN SEC, V9, P364, DOI 10.1109/TIFS.2014.2298370
   Malerba D, 2004, IEEE T PATTERN ANAL, V26, P612, DOI 10.1109/TPAMI.2004.1273937
   Matthews G., 2003, PERSONALITY TRAITS
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   McDonald J.D., 2008, ENQUIRE, V1, P75
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Nie J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P905, DOI 10.1145/2647868.2655062
   Oosterhof NN, 2008, P NATL ACAD SCI USA, V105, P11087, DOI 10.1073/pnas.0805664105
   Paulhus DL, 2007, HDB RES METHODS PERS, V1, P224, DOI DOI 10.1111/J.1744-6570.2008.01133_6.X
   Penton-Voak IS, 2006, SOC COGNITION, V24, P607, DOI 10.1521/soco.2006.24.5.607
   Rattray J, 2007, J CLIN NURS, V16, P234, DOI 10.1111/j.1365-2702.2006.01573.x
   Segalin C, 2017, IEEE T AFFECT COMPUT, V8, P268, DOI 10.1109/TAFFC.2016.2516994
   Segalin C, 2017, COMPUT VIS IMAGE UND, V156, P34, DOI 10.1016/j.cviu.2016.10.013
   Sutherland CAM, 2013, COGNITION, V127, P105, DOI 10.1016/j.cognition.2012.12.001
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Tkalcic Marko, 2009, AFFECTIVE COMPUTING, P33
   Vinciarelli A, 2014, IEEE T AFFECT COMPUT, V5, P273, DOI 10.1109/TAFFC.2014.2330816
   Yao T, 2015, IEEE I CONF COMP VIS, P28, DOI 10.1109/ICCV.2015.12
   Zhang LJ, 2016, PR INT CONGR SOUND V
   Zhuang JF, 2011, UBICOMP'11: PROCEEDINGS OF THE 2011 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P153
NR 42
TC 5
Z9 6
U1 0
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2022
VL 18
IS 4
AR 91
DI 10.1145/3503489
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0E1KA
UT WOS:000776441600002
DA 2024-07-18
ER

PT J
AU Liu, CX
   Kong, DH
   Wang, SF
   Li, JH
   Yin, BC
AF Liu, Caixia
   Kong, Dehui
   Wang, Shaofan
   Li, Jinghua
   Yin, Baocai
TI A Spatial Relationship Preserving Adversarial Network for 3D
   Reconstruction from a Single Depth View
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; latent capsule; self-attention; a single depth view
ID OBJECT DETECTION; POINT CLOUD; SHAPE
AB Recovering the geometry of an object from a single depth image is an interesting yet challenging problem. While previous learning based approaches have demonstrated promising performance, they don't fully explore spatial relationships of objects, which leads to unfaithful and incomplete 3D reconstruction. To address these issues, we propose a Spatial Relationship Preserving Adversarial Network (SRPAN) consisting of 3D Capsule Attention Generative Adversarial Network (3DCAGAN) and 2D Generative Adversarial Network (2DGAN) for coarse-to-fine 3D reconstruction from a single depth view of an object. Firstly, 3DCAGAN predicts the coarse geometry using an encoder-decoder based generator and a discriminator. The generator encodes the input as latent capsules represented as stacked activity vectors with local-to-global relationships (i.e., the contribution of components to the whole shape), and then decodes the capsules by modeling local-to-local relationships (i.e., the relationships among components) in an attention mechanism. Afterwards, 2DGAN refines the local geometry slice-by-slice, by using a generator learning a global structure prior as guidance, and stacked discriminators enforcing local geometric constraints. Experimental results show that SRPAN not only outperforms several state-of-the-art methods by a large margin on both synthetic datasets and real-world datasets, but also reconstructs unseen object categories with a higher accuracy.
C1 [Liu, Caixia; Kong, Dehui; Wang, Shaofan; Li, Jinghua; Yin, Baocai] Beijing Univ Technol, Fac Informat Technol, Beijing Inst Artificial Intelligence, Beijing Key Lab Multimedia & Intelligent Software, 100 Pingleyuan, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Kong, DH (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Inst Artificial Intelligence, Beijing Key Lab Multimedia & Intelligent Software, 100 Pingleyuan, Beijing 100124, Peoples R China.
EM lcxxib@emails.bjut.edu.cn; kdh@bjut.edu.cn; wangshaofan@bjut.edu.cn;
   lijinghua@bjut.edu.cn; ybc@bjut.edu.cn
FU National Natural Science Foundation of China [61772049, 61632006,
   61876012, U19B2039]; Beijing Natural Science Foundation [4202003]
FX The work is supported by the National Natural Science Foundation of
   China (No. 61772049, 61632006, 61876012, U19B2039), Beijing Natural
   Science Foundation (4202003).
CR Afzal H, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177756
   Bechtold Jan., CVPR, P15880
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dong WS, 2017, IEEE T MULTIMEDIA, V19, P293, DOI 10.1109/TMM.2016.2613824
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Firman M, 2016, PROC CVPR IEEE, P5431, DOI 10.1109/CVPR.2016.586
   Gao JK, 2019, IEEE T INSTRUM MEAS, V68, P4765, DOI 10.1109/TIM.2019.2900962
   Gao X, 2020, IEEE T CIRC SYST VID, V30, P3688, DOI 10.1109/TCSVT.2019.2943892
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Guo JW, 2020, IEEE T VIS COMPUT GR, V26, P1372, DOI 10.1109/TVCG.2018.2869784
   Guo YL, 2015, IEEE T INSTRUM MEAS, V64, P683, DOI 10.1109/TIM.2014.2358131
   Gwak J, 2017, INT CONF 3D VISION, P263, DOI 10.1109/3DV.2017.00038
   Han XG, 2017, IEEE I CONF COMP VIS, P85, DOI 10.1109/ICCV.2017.19
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kanazawa A, 2018, LECT NOTES COMPUT SC, V11219, P386, DOI 10.1007/978-3-030-01267-0_23
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kingma D. P., 2014, arXiv
   Kong C, 2017, PROC CVPR IEEE, P5603, DOI 10.1109/CVPR.2017.594
   Li DP, 2017, IEEE T VIS COMPUT GR, V23, P1809, DOI 10.1109/TVCG.2016.2553102
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Li YY, 2015, COMPUT GRAPH FORUM, V34, P435, DOI 10.1111/cgf.12573
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Liu ZN, 2021, IEEE T VIS COMPUT GR, V27, P83, DOI 10.1109/TVCG.2019.2937300
   Lv CL, 2022, IEEE T MULTIMEDIA, V24, P1815, DOI 10.1109/TMM.2021.3073265
   Mattausch O, 2014, COMPUT GRAPH FORUM, V33, P11, DOI 10.1111/cgf.12286
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Michalkiewicz Mateusz, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P614, DOI 10.1007/978-3-030-58595-2_37
   Monszpart A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766995
   Nan LL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366156
   Nash C, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13240
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Pinheiro PO, 2019, IEEE I CONF COMP VIS, P7637, DOI 10.1109/ICCV.2019.00773
   Pontes JK, 2019, LECT NOTES COMPUT SC, V11361, P365, DOI 10.1007/978-3-030-20887-5_23
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Rezende D.J., 2016, ADV NEURAL INFORM PR, P4996
   Riegler G, 2017, INT CONF 3D VISION, P57, DOI 10.1109/3DV.2017.00017
   Sabour S, 2017, ADV NEUR IN, V30
   Sharma A, 2016, LECT NOTES COMPUT SC, V9915, P236, DOI 10.1007/978-3-319-49409-8_20
   Shi YF, 2016, COMPUT GRAPH-UK, V55, P55, DOI 10.1016/j.cag.2015.11.003
   Sipiran I, 2014, COMPUT GRAPH FORUM, V33, P131, DOI 10.1111/cgf.12481
   Smith Edward J., 2017, P MACH LEARN RES, V78, P87
   Soltani AA, 2017, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2017.269
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Speciale P, 2016, LECT NOTES COMPUT SC, V9912, P313, DOI 10.1007/978-3-319-46484-8_19
   Tang JP, 2019, PROC CVPR IEEE, P4536, DOI 10.1109/CVPR.2019.00467
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30
   Varley J, 2017, IEEE INT C INT ROBOT, P2442, DOI 10.1109/IROS.2017.8206060
   Wang Lingjing, 2017, arXiv: 1711.09312., DOI [10.1080/10426910802679196, DOI 10.1080/10426910802679196]
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang WY, 2017, IEEE I CONF COMP VIS, P2317, DOI 10.1109/ICCV.2017.252
   Wang XG, 2020, PROC CVPR IEEE, P787, DOI 10.1109/CVPR42600.2020.00087
   Wen X, 2020, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR42600.2020.00201
   Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Wickramasinghe Udaranga, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P299, DOI 10.1007/978-3-030-59719-1_30
   Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu JJ, 2016, LECT NOTES COMPUT SC, V9910, P365, DOI 10.1007/978-3-319-46466-4_22
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie Haozhe, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P365, DOI 10.1007/978-3-030-58545-7_21
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Xie HZ, 2020, INT J COMPUT VISION, V128, P2919, DOI 10.1007/s11263-020-01347-6
   Xu Q., 2019, Advances in Neural Information Processing Systems (NeurIPS)
   Yang B, 2020, INT J COMPUT VISION, V128, P53, DOI 10.1007/s11263-019-01217-w
   Yang B, 2017, IEEE INT CONF COMP V, P679, DOI 10.1109/ICCVW.2017.86
   Yang B, 2019, IEEE T PATTERN ANAL, V41, P2820, DOI 10.1109/TPAMI.2018.2868195
   Yang GD, 2018, LECT NOTES COMPUT SC, V11219, P90, DOI 10.1007/978-3-030-01267-0_6
   Yang S, 2021, PROC CVPR IEEE, P3151, DOI 10.1109/CVPR46437.2021.00317
   Yao Y, 2020, PROC CVPR IEEE, P528, DOI 10.1109/CVPR42600.2020.00061
   Yongheng Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P1, DOI 10.1007/978-3-030-58452-8_1
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang Y, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105574
   Zhao F., 2021, P IEEECVF INT C COMP, P12674
   Zhao MH, 2021, NEUROCOMPUTING, V430, P94, DOI 10.1016/j.neucom.2020.10.097
   Zhao TH, 2019, IEEE T MULTIMEDIA, V21, P114, DOI 10.1109/TMM.2018.2844087
   Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110
   Zhu H, 2017, IEEE T CIRC SYST VID, V27, P760, DOI 10.1109/TCSVT.2016.2596118
   Zou CH, 2017, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2017.103
   Zubic Nikola, 2021, IFIP ADV INFORM COMM, P309
NR 84
TC 0
Z9 0
U1 1
U2 27
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2022
VL 18
IS 4
AR 110
DI 10.1145/3506733
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0E1KA
UT WOS:000776441600021
DA 2024-07-18
ER

PT J
AU Wu, JJ
   Jiang, JG
   Qi, MB
   Chen, CQ
   Liu, YM
AF Wu, Jingjing
   Jiang, Jianguo
   Qi, Meibin
   Chen, Cuiqun
   Liu, Yimin
TI Improving Feature Discrimination for Object Tracking by
   Structural-similarity-based Metric Learning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Visual object tracking; appearance matching; feature discrimination;
   triplet structural loss; adaptive matching module; reduction of spatial
   suppression
ID IMAGE-RECONSTRUCTION; NETWORKS
AB Existing approaches usually form the tracking task as an appearance matching procedure. However, the discrimination ability of appearance features is insufficient in these trackers, which is caused by their weak feature supervision constraints and inadequate exploitation of spatial contexts. To tackle this issue, this article proposes a novel appearance matching tracking (AMT) method to strengthen the feature restraints and capture discriminative spatial representations. Specifically, we first utilize a triplet structural loss function, which improves the learning capability of features by applying a structural similarity constraint with a triplet metric format on the features. It leverages feature statistics to capture the complex interactions of visual parts. Second, we put forward an adaptive matching module that exploits the dual spatial enhancement module to reinforce target feature discrimination. This not only boosts the representation ability of spatial context but also realizes spatially dynamic feature selection by attending to target deformation information. Moreover, this model introduces a simple but effective matching unit to intuitively evaluate the relative appearance differences between the target and the proposals. In addition, with the obtained discriminative features, AMT is capable of providing precise localization for the target. Therefore, the impact of spatial suppression imposed by window functions can be alleviated, allowing for effective tracking of high-speed moving objects. Extensive experiments prove that AMT outperforms state-of-the-art methods on six public datasets and demonstrate the effectiveness of each component in AMT.
C1 [Wu, Jingjing; Jiang, Jianguo; Qi, Meibin; Chen, Cuiqun; Liu, Yimin] Hefei Univ Technol, 193 Tun Xi Lu Rd, Hefei 230002, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Wu, JJ (corresponding author), Hefei Univ Technol, 193 Tun Xi Lu Rd, Hefei 230002, Anhui, Peoples R China.
EM hfutwujingjing@mail.hfut.edu.cn; jgjiang@hfut.edu.cn; qimeibin@163.com;
   chencuiqun_hfut@163.com; liuyimin2018@gmail.com
RI Liu, Yiming/ISU-3780-2023; Liu, Yi/HTN-4916-2023; Liu,
   Kun/JAX-5396-2023; Li, Kun/JLL-6505-2023; liu, bing/JJD-5566-2023; Liu,
   Kai/IST-6808-2023; Yan, Jun/IXD-7801-2023
OI Li, Kun/0000-0002-3638-2974; Liu, Yimin/0000-0002-5543-4602
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Du F, 2020, PROC CVPR IEEE, P6835, DOI 10.1109/CVPR42600.2020.00687
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Guo C., 2020, PLOS ONE, V16, P1
   He A., 2018, P EUR C COMP VIS ECC
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   King DB, 2015, ACS SYM SER, V1214, P1
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Q, 2021, IEEE T MULTIMEDIA, V23, P2114, DOI 10.1109/TMM.2020.3008028
   Liu Q, 2020, AAAI CONF ARTIF INTE, V34, P11604
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yang TY, 2020, PROC CVPR IEEE, P6717, DOI 10.1109/CVPR42600.2020.00675
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 45
TC 2
Z9 2
U1 0
U2 23
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2022
VL 18
IS 4
AR 90
DI 10.1145/3497746
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0E1KA
UT WOS:000776441600001
DA 2024-07-18
ER

PT J
AU Yu, Y
   Ni, RR
   Li, WJ
   Zhao, Y
AF Yu, Yang
   Ni, Rongrong
   Li, Wenjie
   Zhao, Yao
TI Detection of AI-Manipulated Fake Faces via Mining Generalized Features
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE AI-manipulated face detection; intrinsic features mining; attention
   fusion; generalization ability
ID NETWORKS
AB Recently, AI-manipulated face techniques have developed rapidly and constantly, which has raised new security issues in society. Although existing detection methods consider different categories of fake faces, the performance on detecting the fake faces with "unseen" manipulation techniques is still poor due to the distribution bias among cross-manipulation techniques. To solve this problem, we propose a novel framework that focuses on mining intrinsic features and further eliminating the distribution bias to improve the generalization ability. First, we focus on mining the intrinsic clues in the channel difference image (CDI) and spectrum image (SI) view of two different aspects, including the camera imaging process and the indispensable step in AI manipulation process. Then, we introduce the Octave Convolution and an attention-based fusion module to effectively and adaptively mine intrinsic features from CDI and SI view of these two different but intrinsic aspects. Finally, we design an alignment module to eliminate the bias of manipulation techniques to obtain a more generalized detection framework. We evaluate the proposed framework on four categories of fake faces datasets with the most popular and state-of-the-art manipulation techniques and achieve very competitive performances. We further conduct experiments on cross-manipulation techniques, and the results of our method show the superior advantages on improving generalization ability.
C1 [Yu, Yang; Ni, Rongrong; Li, Wenjie; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network Techno, 3 Shangyuancun Rd, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Ni, RR (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network Techno, 3 Shangyuancun Rd, Beijing, Peoples R China.
EM 18112012@bjtu.edu.cn; rrni@bjtu.edu.cn; 16112058@bjtu.edu.cn;
   yzhao@bjtu.edu.cn
RI 于, 洋/IUN-7956-2023
FU National Key Research and Development Program of China [2018YFC0807306];
   National Science Foundation of China [U1936212]
FX This work was supported in part by the National Key Research and
   Development Program of China (2018YFC0807306), and the National Science
   Foundation of China (U1936212).
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Chai Lucy, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P103, DOI 10.1007/978-3-030-58574-7_7
   Chen YC, 2019, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2019.00251
   Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chugh K, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P439, DOI 10.1145/3394171.3413700
   Ciftci Umur Aybars, 2020, IEEE T PATTERN ANAL, V2020
   Cozzolino D, 2018, ARXIV PREPRINT ARXIV
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Ding H, 2018, AAAI CONF ARTIF INTE, P6781
   Fernandes S, 2019, IEEE INT CONF COMP V, P1721, DOI 10.1109/ICCVW.2019.00213
   Frank Joel, 2020, INT C MACH LEARN, P3247
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He PS, 2019, IEEE IMAGE PROC, P2299, DOI [10.1109/icip.2019.8803740, 10.1109/ICIP.2019.8803740]
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Jeon H., 2020, ICML, P4746
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T., 2018, INT CONFLEARN REPRES
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   King DB, 2015, ACS SYM SER, V1214, P1
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Li HD, 2020, SIGNAL PROCESS, V174, DOI 10.1016/j.sigpro.2020.107616
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Li YZ, 2018, IEEE INT WORKS INFOR
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu SG, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3355394
   Liu X., 2020, P IEEE CVF C COMP VI, P8057
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Marra F, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035099
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey S, 2019, IEEE IMAGE PROC, P4584, DOI [10.1109/icip.2019.8803661, 10.1109/ICIP.2019.8803661]
   Mi ZJ, 2020, IEEE J-STSP, V14, P969, DOI 10.1109/JSTSP.2020.2994523
   Mittal T, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2823, DOI 10.1145/3394171.3413570
   Mou LT, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542208
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sheng-YuWang OliverWang, 2020, P IEEE C COMP VIS PA, V8695
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang R, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3444
   Wei Y, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3408299
   Yang X, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P113, DOI 10.1145/3335203.3335724
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Yuyang Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P86, DOI 10.1007/978-3-030-58610-2_6
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang X, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035107
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
NR 62
TC 10
Z9 10
U1 4
U2 28
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2022
VL 18
IS 4
AR 94
DI 10.1145/3499026
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0E1KA
UT WOS:000776441600005
DA 2024-07-18
ER

PT J
AU Bi, AQ
   Tian, XY
   Wang, SH
   Zhang, YD
AF Bi, An-Qi
   Tian, Xiao-Yang
   Wang, Shui-Hua
   Zhang, Yu-Dong
TI Dynamic Transfer Exemplar based Facial Emotion Recognition Model Toward
   Online Video
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; exemplar-based learning model; GoogLeNet; dynamic
   facial emotion recognition
ID WAVELET ENTROPY; CLASSIFICATION; MACHINE; MOTION
AB In this article, we focus on the dynamic facial emotion recognition from online video. We combine deep neural networks with transfer learning theory and propose a novel model named DT-EFER. In detail, DT-EFER uses GoogLeNet to extract the deep features of key images from video clips. Then to solve the dynamic facial emotion recognition scenario, the framework introduces transfer learning theory. Thus, to improve the recognition performance, model DT-EFER focuses on the differences between key images instead of those images themselves. Moreover, the time complexity of this model is not high, even if previous exemplars are introduced here. In contrast to other exemplar-based models, experiments based on two datasets, namely, BAUM-1s and Extended Cohn-Kanade, have shown the efficiency of the proposed DT-EFER model.
C1 [Bi, An-Qi; Tian, Xiao-Yang] Changshu Inst Technol, 99 South Third Ring Rd, Changshu 215500, Jiangsu, Peoples R China.
   [Wang, Shui-Hua; Zhang, Yu-Dong] Univ Leicester, Univ Rd, Leicester LE1 7RH, Leics, England.
C3 Changshu Institute of Technology; University of Leicester
RP Bi, AQ (corresponding author), Changshu Inst Technol, 99 South Third Ring Rd, Changshu 215500, Jiangsu, Peoples R China.
EM anqi_b@cslg.edu.cn; 2238838262@qq.com; shuihuawang@ieee.org;
   yudongzhang@ieee.org
RI Zhang, Yudong/I-7633-2013; Wang, shuihua/G-7326-2016
OI Zhang, Yudong/0000-0002-4870-1493; Wang, shuihua/0000-0003-4713-2791
CR Asghar MA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235218
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Bi AQ, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/4147807
   Bi AQ, 2016, NEUROCOMPUTING, V194, P288, DOI 10.1016/j.neucom.2016.02.054
   Deng DD, 2020, AAAI CONF ARTIF INTE, V34, P2621
   Du GL, 2021, IEEE T INTELL TRANSP, V22, P4570, DOI 10.1109/TITS.2020.3007357
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Fang LM, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3408322
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Nguyen HL, 2015, KNOWL INF SYST, V45, P535, DOI 10.1007/s10115-014-0808-1
   Hickson S, 2019, IEEE WINT CONF APPL, P1626, DOI 10.1109/WACV.2019.00178
   Houshmand B, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P70, DOI 10.1109/BigMM50055.2020.00020
   Hu M, 2019, J VIS COMMUN IMAGE R, V59, P176, DOI 10.1016/j.jvcir.2018.12.039
   Jiang YZ, 2020, J SUPERCOMPUT, V76, P2929, DOI 10.1007/s11227-019-03080-5
   Jiang YZ, 2017, IEEE T NEUR SYS REH, V25, P2270, DOI 10.1109/TNSRE.2017.2748388
   Kahou SE, 2016, J MULTIMODAL USER IN, V10, P99, DOI 10.1007/s12193-015-0195-2
   Kim DH, 2019, IEEE T AFFECT COMPUT, V10, P223, DOI 10.1109/TAFFC.2017.2695999
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Lin YP, 2020, IEEE J BIOMED HEALTH, V24, P1255, DOI 10.1109/JBHI.2019.2934172
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mehta D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020416
   Noroozi Fatemeh, 2021, IEEE Transactions on Affective Computing, V12, P505, DOI 10.1109/TAFFC.2018.2874986
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   ShitongWang Anqi, 2016, INT J MACH LEARN CYB, V8, P1
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tanveer M, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3409264
   Tanveer M, 2022, IEEE J BIOMED HEALTH, V26, P1453, DOI 10.1109/JBHI.2021.3083274
   Virtusio JJ, 2021, IEEE T MULTIMEDIA, V23, P2245, DOI 10.1109/TMM.2021.3087026
   Wang SH, 2018, NEUROCOMPUTING, V272, P668, DOI 10.1016/j.neucom.2017.08.015
   Wenhao Jiang, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P789, DOI 10.1007/978-3-642-33486-3_50
   Wu M, 2022, IEEE T AFFECT COMPUT, V13, P805, DOI 10.1109/TAFFC.2020.2966440
   XueLiang Quan, 2021, ACTA AUTOMATICA SINI, V47, px, DOI [10.16383/j.aas.c200783, DOI 10.16383/J.AAS.C200783]
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zepf S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3388790
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
   Zheng Y, 2013, IEEE T KNOWL DATA EN, V25, P2206, DOI 10.1109/TKDE.2012.202
   Zhu JQ, 2019, IEEE ACCESS, V7, P103823, DOI 10.1109/ACCESS.2019.2931695
NR 40
TC 1
Z9 1
U1 4
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2022
VL 18
IS 2
SU S
AR 121
DI 10.1145/3538385
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7R6FY
UT WOS:000910168000008
DA 2024-07-18
ER

PT J
AU Sun, T
   Wang, C
   Song, XM
   Feng, FL
   Nie, LQ
AF Sun, Teng
   Wang, Chun
   Song, Xuemeng
   Feng, Fuli
   Nie, Liqiang
TI Response Generation by Jointly Modeling Personalized Linguistic Styles
   and Emotions
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Social media dataset construction; response generation; personalized and
   emotionalized response
AB Natural language generation (NLG) has been an essential technique for various applications, like Xiaolce and Ski, and engaged increasing attention recently. To improve the user experience, several emotion-aware NLG methods have been developed to generate responses coherent with a pre-designated emotion (e.g., the positive or negative). Nevertheless, existing methods cannot generate personalized responses as they frequently overlook the personalized linguistic style. Apparently, different human responsers tend to have different linguistic styles. Inspired by this, in this work, we focus on a novel research theme of personalized emotion-aware NLG (PENLG), whereby the generated responses should be coherent with the linguistic style of a pre-designated responser and emotion. In particular, we study PENLG under a scenario of generating personalized emotion-aware response for social media post. Yet it faces certain research challenges: (1) the user linguistic styles are implicit and complex by nature, and hence it is hard to learn their representations; and (2) linguistic styles and emotions are usually expressed in different manners in a response, and thus how to convey them properly in the generated responses is not easy. Toward this end, we present a novel scheme of PENLG, named CRobot, which consists of a personalized emotion-aware response generator and two discriminators, i.e., general discriminator and personalized emotion-aware discriminator. To be more specific, the post-based and avatar-based user linguistic style modeling methods are incorporated into the encoder-decoder-based generator, while the discriminators are devised to ensure that the generated response is fluent and consistent with both the emotion and the linguistic style of the user. Different from the traditional adversarial networks, we embed adversarial learning under the umbrella of reinforcement learning. In this way, the response generation problem can be tackled by the generator taking a sequence of actions on selecting the proper word of each timestep for output. To justify our model, we construct a large-scale response generation dataset based on Twitter, consisting of 6,763 tweets with a corresponding 1,461,713 response created by 153,664 users. Extensive experiments demonstrate that CRobot surpasses the state-of-the-art baselines regarding both subjective and objective evaluation.
C1 [Sun, Teng; Wang, Chun; Song, Xuemeng; Nie, Liqiang] Shandong Univ, Tsingtao Campus,72 Binhai Rd, Qingdao 266237, Shandong, Peoples R China.
   [Feng, Fuli] Natl Univ Singapore, Sch Comp, 13 Comp Dr, Singapore 117417, Singapore.
C3 Shandong University; National University of Singapore
RP Sun, T (corresponding author), Shandong Univ, Tsingtao Campus,72 Binhai Rd, Qingdao 266237, Shandong, Peoples R China.
EM stbestforever@gmail.com; wclegends1998@gmail.com; sxmustc@gmail.com;
   fulifeng93@gmail.com; nieliqiang@gmail.com
FU National Key Research and Development Project of New Generation
   Artificial Intelligence [2018AAA0102502]
FX This work is supported by the National Key Research and Development
   Project of New Generation Artificial Intelligence, No. 2018AAA0102502.
CR Alloatti F, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P250
   Azzopardi L., 2003, P 26 ANN INT ACM SIG, P369
   Baziotis C., 2017, P 11 INT WORKSHOP SE, P747, DOI [DOI 10.18653/V1/S17-2126, 10.18653/v1/S17-2126]
   Brader Ted, 2011, OXFORD HDB AM PUBLIC
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Dai QY, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P329, DOI 10.1145/3308558.3313445
   Feng ZH, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3338841
   Fong K, 2015, PERS SOC PSYCHOL B, V41, P237, DOI 10.1177/0146167214562761
   Fu CP, 2020, LECT NOTES COMPUT SC, V11961, P111, DOI 10.1007/978-3-030-37731-1_10
   Goodfellow I. J., 2014, CoRR abs/1406.2661
   Guo JX, 2018, AAAI CONF ARTIF INTE, P5141
   Hajung Sohn, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P551, DOI 10.1109/ICDMW.2019.00084
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   He SZ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P199, DOI 10.18653/v1/P17-1019
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Jitao Sang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P95, DOI 10.1007/978-3-319-48890-5_10
   Kingma D.P., 2014, ARXIV14126980
   Koleejan C, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P353, DOI 10.1145/3350546.3352546
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee H, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P957, DOI 10.1145/2911451.2914734
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Li Jiwei, 2017, P 2017 C EMP METH NA, P2157, DOI DOI 10.18653/V1/D17-1230
   Li P, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3237
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin H, 2014, COMPUT HUM BEHAV, V34, P213, DOI 10.1016/j.chb.2013.10.005
   Lin K, 2017, ADV NEUR IN, V30
   Liu CX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P3, DOI 10.1145/3343031.3350869
   Liu JH, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3508
   Liu Zhiwei, 2019, ACM T MULTIM COMPUT, V15, P16
   Nie LQ, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3380954
   Oraby S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5938
   Ozsoy MakbuleGulcin., 2010, Proceedings of the 23rd international conference on computational linguistics, P869
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Qu C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1133, DOI 10.1145/3331184.3331341
   Truong QT, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1864, DOI 10.1145/3308558.3313463
   Sarkar A, 2019, NLPIR 2019: 2019 3RD INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, P49, DOI 10.1145/3342827.3342850
   Shandilya A, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P97, DOI 10.1145/3184558.3186947
   Song XH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1286, DOI 10.1145/3343031.3351051
   Tan CH, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P526, DOI 10.1145/3340555.3356099
   Tang Jian, 2016, ARXIV161109900
   Tripathi S, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3345318
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang BN, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1453, DOI 10.1145/3269206.3271735
   Wang SH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3341095
   Wei YW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1437, DOI 10.1145/3343031.3351034
   Wei YW, 2020, IEEE T IMAGE PROCESS, V29, P1, DOI 10.1109/TIP.2019.2923608
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu CF, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P519, DOI 10.1145/3240508.3240513
   Yang Z, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5077
   Yao YS, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1143, DOI 10.1145/3133956.3133990
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zeng WH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P229
   Zhang JM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1423, DOI 10.1145/3394171.3413906
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhao LJ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2425, DOI 10.1145/3308558.3313581
   Zhou H, 2018, AAAI CONF ARTIF INTE, P730
   Zhu H, 2017, ABS170805509 CORR
   Zhuang YT, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3366710
NR 61
TC 5
Z9 5
U1 3
U2 17
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2022
VL 18
IS 2
AR 52
DI 10.1145/3475872
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0A0YT
UT WOS:000773689400009
DA 2024-07-18
ER

PT J
AU Zhai, DM
   Shi, RF
   Jiang, JJ
   Liu, XM
AF Zhai, Deming
   Shi, Ruifeng
   Jiang, Junjun
   Liu, Xianming
TI Rectified Meta-learning from Noisy Labels for Robust Image-based Plant
   Disease Classification
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Meta learning; noisy labels; plant disease classification
AB Plant diseases serve as one of main threats to food security and crop production. It is thus valuable to exploit recent advances of artificial intelligence to assist plant disease diagnosis. One popular approach is to transform this problem as a leaf image classification task, which can be then addressed by the powerful convolutional neural networks (CNNs). However, the performance of CNN-based classification approach depends on a large amount of high-quality manually labeled training data, which inevitably introduce noise on labels in practice, leading to model overfitting and performance degradation. To overcome this problem, we propose a novel framework that incorporates rectified meta-learning module into common CNN paradigm to train a noise-robust deep network without using extra supervision information. The proposed method enjoys the following merits: (i) A rectified meta-learning is designed to pay more attention to unbiased samples, leading to accelerated convergence and improved classification accuracy. (ii) Our method is free on assumption of label noise distribution, which works well on various kinds of noise. (iii) Our method serves as a plug-and-play module, which can be embedded into any deep models optimized by gradient descent-based method. Extensive experiments are conducted to demonstrate the superior performance of our algorithm over the state-of-the-arts.
C1 [Zhai, Deming; Shi, Ruifeng; Jiang, Junjun; Liu, Xianming] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Liu, XM (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM zhaideming@hit.edu.cn; rfengshi@hit.edu.cn; jiangjunjun@hit.edu.cn;
   csxm@hit.edu.cn
RI Jiang, Junjun/L-7087-2019
OI Jiang, Junjun/0000-0002-5694-505X
FU Natural Science Foundation of China [62071155, 61922027, 61971165];
   China Postdoctoral Science Foundation [2018M630360]
FX This work was supported by Natural Science Foundation of China under
   Grant Nos. 62071155, 61922027, 61971165, and China Postdoctoral Science
   Foundation funded project 2018M630360.
CR Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Chen YT, 2017, PR MACH LEARN RES, V70
   Denil Misha, 2016, ADV NEUR IN
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Finn C, 2017, PR MACH LEARN RES, V70
   Gold JR, 2017, PLAN HIST ENVIRON SE, P1
   Han JF, 2019, IEEE I CONF COMP VIS, P5137, DOI 10.1109/ICCV.2019.00524
   Harvey CA, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0089
   Hendrycks Dan, 2018, C WORKSH NEUR INF PR
   Hughes A, 2015, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.17
   Kaur R, 2015, 2015 IEEE 3RD INTERNATIONAL CONFERENCE ON MOOCS, INNOVATION AND TECHNOLOGY IN EDUCATION (MITE), P135, DOI 10.1109/MITE.2015.7375303
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Kim Y, 2019, IEEE I CONF COMP VIS, P101, DOI 10.1109/ICCV.2019.00019
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kumar M. Pawan, 2010, NEURIPS
   Lee KH, 2018, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2018.00571
   Lemke C, 2015, ARTIF INTELL REV, V44, P117, DOI 10.1007/s10462-013-9406-y
   Li JN, 2019, PROC CVPR IEEE, P5046, DOI 10.1109/CVPR.2019.00519
   Li YC, 2017, IEEE I CONF COMP VIS, P1928, DOI 10.1109/ICCV.2017.211
   Li Zhenguo, 2017, ARXIV170709835
   Lillicrap Timothy, 2016, C WORKSH NEUR INF PR
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu X, 2017, IEEE INT CONF AUTOMA, P111, DOI 10.1109/FG.2017.22
   Maclaurin D, 2015, PR MACH LEARN RES, V37, P2113
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Niu L, 2018, PROC CVPR IEEE, P7689, DOI 10.1109/CVPR.2018.00802
   Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240
   Santoro A, 2016, PR MACH LEARN RES, V48
   Sheng Guo, 2018, EUR C COMP VIS
   Snell J, 2017, ADV NEUR IN, V30
   Soyer Dhruva, 2016, ANN M COGN SCI SOC
   Strange RN, 2005, ANNU REV PHYTOPATHOL, V43, P83, DOI 10.1146/annurev.phyto.43.113004.133839
   Sukhbaatar S., 2014, ARXIV PREPRINT ARXIV
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tanaka D, 2018, PROC CVPR IEEE, P5552, DOI 10.1109/CVPR.2018.00582
   Veit A, 2017, PROC CVPR IEEE, P6575, DOI 10.1109/CVPR.2017.696
   Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069
   Waghmare Harshal, 2016, INT C SIGN PROC INT
   Wang G, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/2917536
   Wang XB, 2019, IEEE I CONF COMP VIS, P9357, DOI 10.1109/ICCV.2019.00945
   Wang YS, 2018, PROC CVPR IEEE, P8688, DOI 10.1109/CVPR.2018.00906
   Wang YS, 2019, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2019.00041
   Yi Kun, 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00718
   Younger AS, 2001, IEEE IJCNN, P2001, DOI 10.1109/IJCNN.2001.938471
   Zhang Z, 2018, ADV NEUR IN, V31
NR 46
TC 9
Z9 9
U1 0
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2022
VL 18
IS 1
SU S
SI SI
AR 30
DI 10.1145/3472809
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5PV
UT WOS:000772639300007
DA 2024-07-18
ER

PT J
AU Wang, J
   Min, WQ
   Hou, SJ
   Ma, SN
   Zheng, YJ
   Jiang, SQ
AF Wang, Jing
   Min, Weiqing
   Hou, Sujuan
   Ma, Shengnan
   Zheng, Yuanjie
   Jiang, Shuqiang
TI LogoDet-3K. A Large-scale Image Dataset for Logo Detection
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Datasets; logo detection; multi-scale; deep learning
AB Logo detection has been gaining considerable attention because of its wide range of applications in the multimedia field, such as copyright infringement detection, brand visibility monitoring, and product brand management on social media. In this article, we introduce LogoDet-3K, the largest logo detection dataset with full annotation, which has 3,000 logo categories, about 200,000 manually annotated logo objects, and 158,652 images. LogoDet-3K creates a more challenging benchmark for logo detection, for its higher comprehensive coverage and wider variety in both logo categories and annotated objects compared with existing datasets. We describe the collection and annotation process of our dataset and analyze its scale and diversity in comparison to other datasets for logo detection. We further propose a strong baseline method Logo-Yolo, which incorporates Focal loss and Clot) loss into the basic YOLOv3 framework for large-scale logo detection. It obtains about 4% improvement on the average performance compared with YOLOv3, and greater improvements compared with reported several deep detection models on LogoDet-3K. We perform extensive evaluation on three other existing datasets to further verify on both logo detection and retrieval tasks, and we demonstrate better generalization ability of LogoDet-3K on logo detection and retrieval tasks. The LogoDet3K dataset is used to promote large-scale logo-related research. The code and LogoDet-3K can be found at https://github.com/Wangjing1551 /LogoDet-3K-Dataset.
C1 [Wang, Jing; Hou, Sujuan; Ma, Shengnan; Zheng, Yuanjie] Shandong Normal Univ, Sch Informat Sci & Engn, 1 Daxue Rd, Jinan, Shandong, Peoples R China.
   [Min, Weiqing; Jiang, Shuqiang] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, 6 Kexueyuan South Rd, Beijing, Peoples R China.
C3 Shandong Normal University; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS
RP Hou, SJ (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, 1 Daxue Rd, Jinan, Shandong, Peoples R China.
EM 2018020875@stu.sdnu.edu.cn; weiqingmin@ict.ac.cn; sujuanhou@sdnu.edu.cn;
   201711030133@stu.sdnu.edu.cn; zhengyuanjie@gmail.com; sqjiang@ict.ac.cn
OI hou, sujuan/0000-0002-6547-6048
FU National Natural Science Foundation of China [62072289, 62073201];
   Postdoctoral Science Foundation of China [2017M612338]; Shandong science
   and technology plan project [J17KB177]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 62072289, No. 62073201), in part by
   Postdoctoral Science Foundation of China (Grant No. 2017M612338), and in
   part by Shandong science and technology plan project (Grant No.
   J17KB177).
CR [Anonymous], 2014, P INT C MULT RETR
   [Anonymous], 2015, 3 INT C LEARN REPR
   [Anonymous], 2012, P 20 ACM INT C MULTI
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Bao Y, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P319, DOI 10.1145/3007669.3007728
   Bianco S, 2017, NEUROCOMPUTING, V245, P23, DOI 10.1016/j.neucom.2017.03.051
   Bianco S, 2015, LECT NOTES COMPUT SC, V9280, P438, DOI 10.1007/978-3-319-23234-8_41
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Cheng ZQ, 2017, IEEE T MULTIMEDIA, V19, P1170, DOI 10.1109/TMM.2016.2647386
   Cheng ZQ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1365, DOI 10.1145/2964284.2964326
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eggert C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P172, DOI 10.1145/3078971.3078990
   Fehérvári I, 2019, IEEE WINT CONF APPL, P715, DOI 10.1109/WACV.2019.00081
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Gao Y, 2016, IEEE T MULTIMEDIA, V18, P2115, DOI 10.1109/TMM.2016.2581483
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoi S.C.H., 2015, LOGO NET LARGE SCALE
   Iandola F. N., 2015, DeepLogo: Hitting logo recognition with the deep neural network hammer
   Kalantidis Y., 2011, Proceedings of the 1st ACM International Conference on Multimedia Retrieval, ICMR'11, Association for Computing Machinery, DOI DOI 10.1145/1991996.1992016
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Kuznetsov Andrey, 2020, Computer Vision and Graphics. International Conference, ICCVG 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12334), P87, DOI 10.1007/978-3-030-59006-2_8
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Liao Y, 2017, IEEE I CONF COMP VIS, P4856, DOI 10.1109/ICCV.2017.519
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JY, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3365212
   Liu Liu, 2018, AAAI C ART INT, P71
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mei Tao., 2007, Proceedings of the 15th International Conference on Multimedia, P1075
   Neumann J, 2002, PATTERN RECOGN LETT, V23, P1449, DOI 10.1016/S0167-8655(02)00105-8
   Oliveira G, 2016, IEEE IJCNN, P985, DOI 10.1109/IJCNN.2016.7727305
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romberg S., 2011, P 1 ACM INT C MULT R, P1
   Romberg S., 2013, Proceedings of the 3rd ACM conference on International conference on multimedia retrieval, P113
   Singh B, 2018, 32 C NEURAL INFORM P
   Su H, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107003
   Su H, 2017, IEEE INT CONF COMP V, P270, DOI 10.1109/ICCVW.2017.41
   Su H, 2017, IEEE WINT CONF APPL, P530, DOI 10.1109/WACV.2017.65
   Su Hang, 2021, COMPUT VIS IMAGE UND, V2021, P103
   Sun P., 2020, SPARSE R CNN END TO
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tüzkö A, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P284, DOI 10.5220/0006614602840292
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Wang J, 2020, AAAI CONF ARTIF INTE, V34, P6194
   Xie LX, 2014, COMPUT VIS IMAGE UND, V124, P31, DOI 10.1016/j.cviu.2013.12.011
   Xue Jian, 2020, IEEE T MULTIMEDIA, V2020, P1
   Yan WQ, 2005, MULTIMEDIA SYST, V10, P379, DOI 10.1007/s00530-005-0167-6
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yang Wei, 2020, ACM T MULTIM COMPUT, V16, P1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang QN, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457454
   Zhang SJ, 2020, I S MOD ANAL SIM COM, P1, DOI 10.1109/mascots50786.2020.9285955
   Zhang X, 2017, NAT COMMUN, V8, DOI [10.1038/ncomms15280, 10.1038/ncomms14542]
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhong Sheng-Hua, 2019, ACM T MULTIM COMPUT, V2019, P1
NR 66
TC 25
Z9 25
U1 0
U2 19
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2022
VL 18
IS 1
AR 21
DI 10.1145/3466780
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZY5OX
UT WOS:000772636900021
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xia, BH
   Wang, XT
   Yamasaki, T
AF Xia, Bohui
   Wang, Xueting
   Yamasaki, Toshihiko
TI Semantic Explanation for Deep Neural Networks Using Feature Interactions
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Explainability; multimedia analysis; semantics
AB Given the promising results obtained by deep-learning techniques in multimedia analysis, the explainability of predictions made by networks has become important in practical applications. We present a method to generate semantic and quantitative explanations that are easily interpretable by humans. The previous work to obtain such explanations has focused on the contributions of each feature, taking their sum to be the prediction result for a target variable; the lack of discriminative power due to this simple additive formulation led to low explanatory performance. Our method considers not only individual features but also their interactions, for a more detailed interpretation of the decisions made by networks. The algorithm is based on the factorization machine, a prediction method that calculates factor vectors for each feature. We conducted experiments on multiple datasets with different models to validate our method, achieving higher performance than the previous work. We show that including interactions not only generates explanations but also makes them richer and is able to convey more information. We show examples of produced explanations in a simple visual format and verify that they are easily interpretable and plausible.
C1 [Xia, Bohui; Wang, Xueting; Yamasaki, Toshihiko] Univ Tokyo, Tokyo, Japan.
C3 University of Tokyo
RP Xia, BH (corresponding author), Univ Tokyo, Tokyo, Japan.
EM xia@hal.t.u-tokyo.ac.jp; xt_wang@hal.t.u-tokyo.ac.jp;
   yamasaki@hal.t.u-tokyo.ac.jp
RI wang, xueting/JPY-2782-2023; zhou, you/KBC-3567-2024
FU JSPS [JP18H03339, JP19K20289]
FX This research is partially supported by the Grants-in-Aid for Scientific
   Research Numbers JP18H03339 and JP19K20289 from JSPS.
CR [Anonymous], 2015, 3 INT C LEARN REPR
   [Anonymous], 2017, ARXIV161208220
   Arik SO, 2020, J MACH LEARN RES, V21
   Chen CF, 2019, ADV NEUR IN, V32
   Chen RJ, 2019, IEEE I CONF COMP VIS, P9186, DOI 10.1109/ICCV.2019.00928
   Chen X, 2016, ADV NEUR IN, V29
   Cheng H., 2016, P 1 WORKSH DEEP LEAR, P7, DOI [DOI 10.1145/2988450.2988454, 10.1145/2988450.2988454]
   Choi E, 2016, ADV NEUR IN, V29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Erhan D, 2009, Univ Montr, V1341, P1
   Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148
   Frosst N., 2017, P 1 INT WORKSH COMPR, V2071
   Guo HF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1725
   Gupta Rajiv, 2015, P 19 INT C EV ASS SO, P1
   Harradon M., 2018, ARXIV180200541
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendricks LA, 2018, LECT NOTES COMPUT SC, V11206, P269, DOI 10.1007/978-3-030-01216-8_17
   Higgins I., 2017, 5 INT C LEARN REPR T
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kanehira A, 2019, PROC CVPR IEEE, P8586, DOI [10.1109/CVPR.2019.00880, 10.1109/CVPR.2019.00879]
   Kim J, 2018, LECT NOTES COMPUT SC, V11206, P577, DOI 10.1007/978-3-030-01216-8_35
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Li O, 2018, AAAI CONF ARTIF INTE, P3530
   Lian JX, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1754, DOI 10.1145/3219819.3220023
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lou Y, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P623, DOI 10.1145/2487575.2487579
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Ming Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P903, DOI 10.1145/3292500.3330908
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Park DH, 2018, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2018.00915
   Qu YR, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3233770
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Singh C., 2019, INT C LEARN REPR
   Song WP, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1161, DOI 10.1145/3357384.3357925
   Srebro N., 2004, P ADV NEUR INF PROC, V17, P1329
   Stone A, 2017, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2017.85
   Tao Li, 2020, P ANN C JSAI
   Tsang Michael, 2020, P INT C LEARN REPR
   Wang RX, 2017, ADKDD'17: 23RD ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD 2017), DOI 10.1145/3124749.3124754
   Wen BR, 2018, P ASME INT C OCEAN
   Xie N., 2020, EXPLANABLE DEEP LEAR
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688
   Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920
   Zhang Weinan, 2016, ADV INFORM RETRIEVAL, P45
   ZhihaoWang Jian Chen, 2020, IEEE T PATTERN ANAL, V43, P3365
   Zintgraf L. M., 2017, ARXIV170204595, P1
NR 54
TC 2
Z9 2
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2021
VL 17
IS 3
SU S
SI SI
AR 115
DI 10.1145/3474557
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YA4BM
UT WOS:000738280600017
OA Bronze
DA 2024-07-18
ER

PT J
AU Zheng, HD
   Wang, JF
   Zhang, JP
   Li, RR
AF Zheng, Hongdi
   Wang, Junfeng
   Zhang, Jianping
   Li, Ruirui
TI IRTS: An Intelligent and Reliable Transmission Scheme for Screen Updates
   Delivery in DaaS
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Desktop-as-a-service; reinforcement learning; fountain code; end-to-end
   transmission scheme
ID ADAPTIVE CONGESTION CONTROL; TRANSPORT PROTOCOL; HIGH-SPEED; DESK-TOP;
   EXPERIENCE; QUALITY
AB Desktop-as-a-service (DaaS) has been recognized as an elastic and economical solution that enables users to access personal desktops from anywhere at any time. During the interaction process of DaaS, users rely on screen updates to perceive execution results remotely, and thus the reliability and timeliness of screen updates transmission have a great influence on users' quality of experience (QoE). However, the efficient transmission of screen updates in DaaS is facing severe challenges: most transmission schemes applied in DaaS determine sending strategies in terms of pre-set rules, lacking the intelligence to utilize bandwidth rationally and fit new network scenarios. Meanwhile, they tend to focus on reliability or timeliness and perform unsatisfactorily in ensuring reliability and timeliness simultaneously, leading to lower transmission efficiency of screen updates and users' QoE when network conditions turn unfavorable. In this article, an intelligent and reliable end-to-end transmission scheme (IRTS) is proposed to cope with the preceding issues. IRTS draws support from reinforcement learning by adopting SARSA, an online learning method based on the temporal difference update rule, to grasp the optimal mapping between network states and sending actions, which extricates IRTS from the reliance on pre-set rules and augments its adaptability to different network conditions. Moreover, IRTS guarantees reliability and timeliness via an adaptive loss recovery method, which intends to recover lost screen updates data automatically with fountain code while controlling the number of redundant packets generated. Extensive performance evaluations are conducted, and numerical results show that IRTS outperforms the reference schemes in display quality, end-to-end delay/delay jitter, and fairness when transferring screen updates under various network conditions, proving that IRTS can enhance the transmission efficiency of screen updates and users' QoE in DaaS.
C1 [Zheng, Hongdi; Wang, Junfeng] Sichuan Univ, Coll Comp Sci, 24 Southern Sect 1,1st Ring Rd, Chengdu 610065, Sichuan, Peoples R China.
   [Zhang, Jianping] Civil Aviat Adm China, Res Inst 2, 17 Southern Sect 2,2nd Ring Rd, Chengdu 610041, Peoples R China.
   [Li, Ruirui] Beijing Futong Dongfang Technol Co Ltd, 26 Chaowai St, Beijing 100020, Peoples R China.
C3 Sichuan University
RP Wang, JF (corresponding author), Sichuan Univ, Coll Comp Sci, 24 Southern Sect 1,1st Ring Rd, Chengdu 610065, Sichuan, Peoples R China.
EM zhdscu@126.com; wangjf@scu.edu.cn; zhangjp@caacsri.com;
   lirr@futong.com.cn
RI Li, Ruirui/AAL-4473-2020; Zhang, Jianping/A-8167-2014
FU National Key Research and Development Program [2018YFB0804503,
   2019QY1400]; National Natural Science Foundation of China [U20A20161,
   U1836103]; Basic Research Program of China [2019-JCJQZD-113]; Technology
   Research and Development Program of Sichuan, China [2019YFG0390]
FX This work was supported by the National Key Research and Development
   Program (2018YFB0804503, 2019QY1400), the National Natural Science
   Foundation of China (U20A20161, U1836103), the Basic Research Program of
   China (2019-JCJQZD-113), and the Technology Research and Development
   Program of Sichuan, China (2019YFG0390).
CR Abu Layek M, 2016, COMPUT J, V59, P260, DOI 10.1093/comjnl/bxv116
   Alizadeh M, 2010, ACM SIGCOMM COMP COM, V40, P63, DOI 10.1145/1851275.1851192
   Almström P, 2009, IEEE DECIS CONTR P, P2711, DOI 10.1109/CDC.2009.5400803
   [Anonymous], 2004, P PFLDNET
   [Anonymous], 2002, P 3 WORKSH PASS ACT
   Arun V, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P329
   Baratto RicardoA., 2005, Proceedings of the 20th ACM Symposium on Operating Systems Principles, SOSP '05, P277, DOI DOI 10.1145/1095810.1095837
   Cardwell N, 2017, COMMUN ACM, V60, P58, DOI 10.1145/3009824
   Citrix, 2020, WHAT IS HDX
   Dhall M, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P55, DOI [10.1109/ICCCBDA.2019.8725659, 10.1109/icccbda.2019.8725659]
   Dong M, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P343
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Floyd S., 1999, 2582 RFC
   Fortin-Parisi S, 2004, PERFORM EVALUATION, V58, P89, DOI 10.1016/j.peva.2004.07.016
   Kong Y., 2018, P WORKSH NETW MEETS, P60
   Li W, 2019, IEEE T NETW SCI ENG, V6, P445, DOI 10.1109/TNSE.2018.2835758
   Li XH, 2018, IEEE J SEL AREA COMM, V36, P1097, DOI 10.1109/JSAC.2018.2832858
   Li XH, 2017, IET COMMUN, V11, P2336, DOI 10.1049/iet-com.2017.0008
   Liu S, 2008, PERFORM EVALUATION, V65, P417, DOI 10.1016/j.peva.2007.12.007
   Lundqvist H, 2004, 2004 INTERNATIONAL ZURICH SEMINAR ON COMMUNICATIONS: ACCESS-TRANSMISSION-NETWORKING, PROCEEDINGS, P152
   Luo Q, 2018, IEEE J SEL AREA COMM, V36, P257, DOI 10.1109/JSAC.2018.2804099
   Marcotte Ryan J., 2017, P RSS 2017 RCW WORKS
   Microsoft, 2020, MICR REMOTEFX
   Mtibaa A., 2018, PROC 4 INT C ADV TEC, P1
   Mukherjee B, 2000, 2000 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P165, DOI 10.1109/ICNP.2000.896301
   NS-3, 2020, NS 3 NETWORK SIMULAT
   Ngo QT, 2017, MULTIMED TOOLS APPL, V76, P22217, DOI 10.1007/s11042-017-4692-z
   Richardson T, 1998, IEEE INTERNET COMPUT, V2, P33, DOI 10.1109/4236.656066
   Sangtae Ha, 2008, Operating Systems Review, V42, P64, DOI 10.1145/1400097.1400105
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Spice, 2020, SPIC NEWB
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tan K, 2006, IEEE INFOCOM SER, P1217
   Teradici, 2020, PC OV IP
   Tuexen Michael, 2015, 7496 RFC
   Value Market Research, 2020, GLOB DESKT SERV MARK
   Vankeirsbilck B, 2008, ATNAC: 2008 AUSTRALASIAN TELECOMMUNICATION NETWOKS AND APPLICATIONS CONFERENCE, P385, DOI 10.1109/ATNAC.2008.4783355
   Vankeirsbilck B, 2012, J NETW COMPUT APPL, V35, P1620, DOI 10.1016/j.jnca.2012.03.007
   VMware, 2020, VMWARE BLAST EXTR
   Wang M, 2014, COMPUT NETW, V64, P308, DOI 10.1016/j.comnet.2014.02.021
   Wikipedia, 2020, SUN RAY
   Wikipedia, 2020, FRAM RAT
   Wikipedia, 2020, IND COMP ARCH
   Wikipedia, 2020, REM DESKT PROT
   Wikipedia, 2020, PERS VIS VIS STAYING
   Winstein K, 2013, ACM SIGCOMM COMP COM, V43, P123, DOI 10.1145/2534169.2486020
   Wu JY, 2016, IEEE T CIRC SYST VID, V26, P711, DOI 10.1109/TCSVT.2015.2412774
   Xiao KF, 2019, IEEE ACCESS, V7, P11892, DOI 10.1109/ACCESS.2019.2892046
   Zheng HD, 2019, MULTIMED TOOLS APPL, V78, P16755, DOI 10.1007/s11042-018-7058-2
   Zhu XQ, 2009, IEEE T MULTIMEDIA, V11, P752, DOI 10.1109/TMM.2009.2017641
NR 50
TC 2
Z9 2
U1 0
U2 13
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2021
VL 17
IS 3
AR 82
DI 10.1145/3440035
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UC5SO
UT WOS:000686585400006
DA 2024-07-18
ER

PT J
AU Ji, RY
   Liu, ZY
   Zhang, LB
   Liu, JW
   Zuo, X
   Wu, YJ
   Zhao, C
   Wang, HF
   Yang, L
AF Ji, Ruyi
   Liu, Zeyu
   Zhang, Libo
   Liu, Jianwei
   Zuo, Xin
   Wu, Yanjun
   Zhao, Chen
   Wang, Haofeng
   Yang, Lin
TI Multi-peak Graph-based Multi-instance Learning for Weakly Supervised
   Object Detection
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Weakly supervised object detection; multi-instance learning; context
   information; graph neural network
ID LOCALIZATION; CONTEXT
AB Weakly supervised object detection (WSOD), aiming to detect objects with only image-level annotations, has become one of the research hotspots over the past few years. Recently, much effort has been devoted to WSOD for the simple yet effective architecture and remarkable improvements have been achieved. Existing approaches using multiple-instance learning usually pay more attention to the proposals individually, ignoring relation information between proposals. Besides, to obtain pseudo-ground-truth boxes for WSOD, MIL-based methods tend to select the region with the highest confidence score and regard those with small overlap as background category, which leads to mislabeled instances. As a result, these methods suffer from mislabeling instances and lacking relations between proposals, degrading the performance of WSOD. To tackle these issues, this article introduces a multi-peak graph-based model for WSOD. Specifically, we use the instance graph to model the relations between proposals, which reinforces multiple-instance learning process. In addition, a multi-peak discovery strategy is designed to avert mislabeling instances. The proposed model is trained by stochastic gradients decent optimizer using back-propagation in an end-to-end manner. Extensive quantitative and qualitative evaluations on two publicly challenging benchmarks, PASCAL VOC 2007 and PASCAL VOC 2012, demonstrate the superiority and effectiveness of the proposed approach.
C1 [Ji, Ruyi; Zhang, Libo; Wu, Yanjun; Zhao, Chen] Chinese Acad Sci, Inst Software, South Fourth St, Beijing 100190, Peoples R China.
   [Ji, Ruyi] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Liu, Zeyu; Liu, Jianwei; Zuo, Xin] China Univ Petr, Dept Automat, Beijing 102249, Peoples R China.
   [Wang, Haofeng; Yang, Lin] Beijing Inst Comp Technol & Applicat, Yongding Rd, Beijing 100854, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; China
   University of Petroleum
RP Zhang, LB (corresponding author), Chinese Acad Sci, Inst Software, South Fourth St, Beijing 100190, Peoples R China.
EM ruyi2017@iscas.ac.cn; logonod@gmail.com; libo@iscas.ac.cn;
   liujw@cup.edu.cn; zuox@cup.edu.cn; yanjun@iscas.ac.cn;
   zhaochen@iscas.ac.cn; wanghaofeng@sina.com; hsjyl@126.com
RI yuan, lin/JDW-7387-2023; Liu, Jian-Wei/C-5013-2008; Li,
   Kun/JLL-6505-2023
OI Li, Kun/0000-0002-3638-2974; Liu, Ze-yu/0000-0002-3229-2824
CR Angelidis S., 2018, Transactions of the Association for Computational Linguistics, V6, P17, DOI DOI 10.1162/TACLA00002
   [Anonymous], Graph Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Arun Aditya, 2018, DISSIMILARITY COEFFI
   Bergeron C, 2012, IEEE T PATTERN ANAL, V34, P1068, DOI 10.1109/TPAMI.2011.194
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Bojchevski A, 2018, PR MACH LEARN RES, V80
   Chavali Neelima, 2015, OBJECT PROPOSAL EVAL
   Chen XL, 2017, IEEE I CONF COMP VIS, P4106, DOI 10.1109/ICCV.2017.440
   Chum O., 2007, 2007 IEEE C COMPUTER, P1
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   De Cao N., 2018, ICML 2018 WORKSH THE
   Defferrard M, 2016, ADV NEUR IN, V29
   Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3
   Diba Ali, 2016, WEAKLY SUPERVISED CA
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Galleguillos C, 2008, PROC CVPR IEEE, P3552
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Gao Mingfei, 2017, C WSL COUNT GUIDED W
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goossens Michel, 1999, The Latex Web Companion: Integrating TEX, HTML, and XML, V1st
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Hosang Jan, 2014, P BRIT MACH VIS C BM, DOI [10.5244/C.28.24, DOI 10.5244/C.28.24]
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Ilse M, 2018, PR MACH LEARN RES, V80
   JAIN A, 2016, PROC CVPR IEEE, P5308, DOI DOI 10.1109/CVPR.2016.573
   Ji Ruyi, 2019, LEARNING SEMANTIC NE
   Jie ZQ, 2017, PROC CVPR IEEE, P4294, DOI 10.1109/CVPR.2017.457
   Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22
   Kipf T. N., 2016, ARXIV161107308, V1050, P21
   Kipf TN, 2016, ARXIV
   Kong Qiuqiang, 2019, WEAKLY LABELLED AUDI
   Kotzias D, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P597, DOI 10.1145/2783258.2783380
   Li Xiaoyan, 2019, WEAKLY SUPERVISED OB
   Lin CH, 2020, AAAI CONF ARTIF INTE, V34, P11482
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XH, 2019, AAAI CONF ARTIF INTE, P8778
   Maron O, 1998, ADV NEUR IN, V10, P570
   Oquab M., 2015, PROC CVPR IEEE, P685
   Pan SR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2609
   Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383
   Pappas N., 2014, EMNLP, P455
   Paszke A, 2019, ADV NEUR IN, V32
   Peng Minlong, 2019, ADDRESS INSTANCE LEV
   Pinheiro P.O., 2014, Weakly supervised semantic segmentation with convolutional networks. arXiv
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ruyi Ji, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10465, DOI 10.1109/CVPR42600.2020.01048
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shen YH, 2018, PROC CVPR IEEE, P5764, DOI 10.1109/CVPR.2018.00604
   Shen YH, 2019, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2019.00079
   Shi MJ, 2017, IEEE I CONF COMP VIS, P3401, DOI 10.1109/ICCV.2017.366
   Shi ZY, 2015, IEEE T PATTERN ANAL, V37, P1959, DOI 10.1109/TPAMI.2015.2392769
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh KK, 2019, PROC CVPR IEEE, P9406, DOI 10.1109/CVPR.2019.00964
   Song Hyun Oh, 2014, WEAKLY SUPERVISED DI
   Tang P, 2018, LECT NOTES COMPUT SC, V11215, P370, DOI 10.1007/978-3-030-01252-6_22
   Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304
   Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326
   Tang P, 2017, PATTERN RECOGN, V71, P446, DOI 10.1016/j.patcog.2017.05.001
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   van der Merwe R, 2019, ARCH REC, V40, P239, DOI 10.1080/23257962.2017.1388224
   Velickovic Petar, 2018, INT C LEARN REPR
   Wan F, 2019, PROC CVPR IEEE, P2194, DOI 10.1109/CVPR.2019.00230
   Wan F, 2018, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2018.00141
   Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wei Y., 2018, TS2C TIGHT BOX MININ
   Williams C.K.I., PASCAL VISUAL OBJECT
   Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968
   You JX, 2018, PR MACH LEARN RES, V80
   Zeni L. F., 2020, PROC IEEECVF C COMPU, P768
   Zhang JN, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P339
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XP, 2018, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR.2018.00448
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou Z.-H., 2002, P INT C INT INF TECH, P455
   Zhou Zhi-Hua, 2008, MULTIINSTANCE LEARNI
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 93
TC 7
Z9 9
U1 1
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2021
VL 17
IS 2
SU S
SI SI
AR 70
DI 10.1145/3432861
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TA7ZH
UT WOS:000667464100012
DA 2024-07-18
ER

PT J
AU Mohammed, MA
   Elhoseny, M
   Abdulkareem, KH
   Mostafa, SA
   Maashi, MS
AF Mohammed, Mazin Abed
   Elhoseny, Mohamed
   Abdulkareem, Karrar Hameed
   Mostafa, Salama A.
   Maashi, Mashael S.
TI A Multi-agent Feature Selection and Hybrid Classification Model for
   Parkinson's Disease Diagnosis
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease; machine learning; feature evaluation; voice
   feature; multi-agent system; multi-agent feature filter; Hybrid
   Classification Model; Convolutional Neural Network
ID NEURAL-NETWORK; PERFORMANCE; ALGORITHM
AB Parkinson's disease (PD) diagnostics includes numerous analyses related to the neurological, physical, and psychical status of the patient. Medical teams analyze multiple symptoms and patient history considering verified genetic influences. The proposed method investigates the voice symptoms of this disease. The voice files are processed, and the feature extraction is conducted. Several machine learning techniques are used to recognize Parkinson's and healthy patients. This study focuses on examining PD diagnosis through voice data features. A new multi-agent feature filter (MAFT) algorithm is proposed to select the best features from the voice dataset. The MAFT algorithm is designed to select a set of features to improve the overall performance of prediction models and prevent over-fitting possibly due to extreme reduction to the features. Moreover, this algorithm aims to reduce the complexity of the prediction, accelerate the training phase, and build a robust training model. Ten different machine learning methods are then integrated with the MAFT algorithm to form a powerful voice-based PD diagnosis model. Recorded test results of the PD prediction model using the actual and filtered features yielded 86.38% and 86.67% accuracies on average, respectively. With the aid of the MAFT feature selection, the test results are improved by 3.2% considering the hybrid model (HM) and 3.1% considering the Naive Bayesian and random forest. Subsequently, an HM, which comprises a binary convolutional neural network and three feature selection algorithms (namely, genetic algorithm, Adam optimizer, and mini-batch gradient descent), is proposed to improve the classification accuracy of the PD. The results reveal that PD achieves an overall accuracy of 93.7%. The HM is integrated with the MAFT, and the combination realizes an overall accuracy of 96.9%. These results demonstrate that the combination of the MAFT algorithm and the HM model significantly enhances the PD diagnosis outcomes.
C1 [Mohammed, Mazin Abed] Univ Anbar, Coll Comp Sci & Informat Technol, Ramadi 11, Anbar, Iraq.
   [Elhoseny, Mohamed] Amer Univ Emirates, Coll Comp Informat Technol, Dept Comp Sci, Dubai 503000, U Arab Emirates.
   [Elhoseny, Mohamed] Mansoura Univ, Fac Comp & Informat, Mansoura, Egypt.
   [Abdulkareem, Karrar Hameed] Al Muthanna Univ, Coll Agr, Samawah 66001, Iraq.
   [Mostafa, Salama A.] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Batu Pahat 86400, Johor, Malaysia.
   [Maashi, Mashael S.] King Saud Univ, Software Engn Dept, Riyadh 11451, Saudi Arabia.
   [Elhoseny, Mohamed] Amer Univ 7 Emirates, Dept Comp Sci, Coll Comp Informat Technol, Dubai 503000, U Arab Emirates.
C3 University of Anbar; Egyptian Knowledge Bank (EKB); Mansoura University;
   Al-Muthanna University; University of Tun Hussein Onn Malaysia; King
   Saud University
RP Mohammed, MA (corresponding author), Univ Anbar, Coll Comp Sci & Informat Technol, Ramadi 11, Anbar, Iraq.
EM mazinalshujeary@uoanbar.edu.iq; melhoseny@ieee.org; khak9784@mu.edu.iq;
   salama@uthm.edu.my; mmaashi@ksu.edu.sa
RI Mohammed, Mazin Abed/E-3910-2018; Mostafa, Salama A./N-2437-2017;
   Abdulkareem, Karrar Hameed/V-1741-2017; Elhoseny, Mohamed/Q-5591-2017;
   Maashi, Mashael S./AAJ-3501-2020
OI Mohammed, Mazin Abed/0000-0001-9030-8102; Mostafa, Salama
   A./0000-0001-5348-502X; Abdulkareem, Karrar Hameed/0000-0001-7302-2049;
   Elhoseny, Mohamed/0000-0001-6347-8368; Maashi, Mashael
   S./0000-0003-0446-5430
CR Abd Ghani MK, 2020, NEURAL COMPUT APPL, V32, P625, DOI 10.1007/s00521-018-3882-6
   Abdulkareem KH, 2019, IEEE ACCESS, V7, P153123, DOI 10.1109/ACCESS.2019.2947542
   [Anonymous], 2010, P INT C ADV NEUR INF
   [Anonymous], 2018, PARKINSONS DIS SYMPT
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Avci D, 2016, PARKINSONS DIS-US, V2016, DOI 10.1155/2016/5264743
   Can M., 2013, SE EUR J SOFT COMPUT, V2, P1
   [曹莹 Cao Ying], 2013, [自动化学报, Acta Automatica Sinica], V39, P745
   Chen HL, 2016, NEUROCOMPUTING, V184, P131, DOI 10.1016/j.neucom.2015.07.138
   Doan S., 2004, P 2 INT C AUTONOMOUS, P362
   Farahnakian F, 2009, INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL : ICACC 2009 - PROCEEDINGS, P107, DOI 10.1109/ICACC.2009.96
   Georgiev D., 2019, Sex differences, quality of life and non-motor symptoms in Parkinson's disease
   Gupta D, 2018, COGN SYST RES, V52, P36, DOI 10.1016/j.cogsys.2018.06.006
   Gupta D, 2018, COMPUT ELECTR ENG, V68, P412, DOI 10.1016/j.compeleceng.2018.04.014
   Gürüler H, 2017, NEURAL COMPUT APPL, V28, P1657, DOI 10.1007/s00521-015-2142-2
   Haq A. Ul, J INTELL FUZZY SYST, P1
   Hariharan M, 2014, COMPUT METH PROG BIO, V113, P904, DOI 10.1016/j.cmpb.2014.01.004
   Kaya E, 2011, INT J INNOV COMPUT I, V7, P4669
   Kubota KJ, 2016, MOVEMENT DISORD, V31, P1314, DOI 10.1002/mds.26693
   Little MA, 2009, IEEE T BIO-MED ENG, V56, P1015, DOI 10.1109/TBME.2008.2005954
   Mekyska J, 2015, 2015 4TH INTERNATIONAL WORK CONFERENCE ON BIOINSPIRED INTELLIGENCE (IWOBI), P111, DOI 10.1109/IWOBI.2015.7160153
   Mohammed MA, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113723
   Mohammed MA, 2020, IEEE ACCESS, V8, P99115, DOI 10.1109/ACCESS.2020.2995597
   Mohammed MA, 2018, COMPUT ELECTR ENG, V70, P871, DOI 10.1016/j.compeleceng.2018.01.033
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P232, DOI 10.1016/j.jocs.2017.04.012
   Mostafa SA, 2019, COGN SYST RES, V54, P90, DOI 10.1016/j.cogsys.2018.12.004
   Mostafa SA, 2018, ADV INTELL SYST, V700, P43, DOI 10.1007/978-3-319-72550-5_5
   Mueller K, 2013, NEW ENGL J MED, V368, P482, DOI 10.1056/NEJMc1214078
   Pereira CR, 2016, LECT NOTES COMPUT SC, V9605, P377, DOI 10.1007/978-3-319-50478-0_19
   Prasanna J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174952
   Ramayya AG, 2014, J NEUROSCI, V34, P6887, DOI 10.1523/JNEUROSCI.5445-13.2014
   Rueda A., 2019, P INTERSPEECH, P1
   Sanchez CI, 2009, PROC SPIE, V7260, DOI 10.1117/12.812088
   Tsanas A, 2010, IEEE T BIO-MED ENG, V57, P884, DOI 10.1109/TBME.2009.2036000
   Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009
   Wrobel Krzysztof, 2019, Computer Information Systems and Industrial Management. 18th International Conference, CISIM 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11703), P84, DOI 10.1007/978-3-030-28957-7_8
   ZYL J, 2004, P ECML PKDD04 WORKSH, P194
NR 38
TC 13
Z9 13
U1 1
U2 19
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2021
VL 17
IS 2
SU S
SI SI
AR 74
DI 10.1145/3433180
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TA7ZH
UT WOS:000667464100016
DA 2024-07-18
ER

PT J
AU Xu, X
   Tian, JL
   Lin, KY
   Lu, HM
   Shao, J
   Shen, HT
AF Xu, Xing
   Tian, Jialin
   Lin, Kaiyi
   Lu, Huimin
   Shao, Jie
   Shen, Heng Tao
TI Zero-shot Cross-modal Retrieval by Assembling AutoEncoder and Generative
   Adversarial Network
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; zero-shot learning; feature synthesis
AB Conventional cross-modal retrieval models mainly assume the same scope of the classes for both the training set and the testing set. This assumption limits their extensibility on zero-shot cross-modal retrieval (ZS-CMR), where the testing set consists of unseen classes that are disjoint with seen classes in the training set. The ZS-CMR task is more challenging due to the heterogeneous distributions of different modalities and the semantic inconsistency between seen and unseen classes. A few of recently proposed approaches are inspired by zero-shot learning to estimate the distribution underlying multimodal data by generative models and make the knowledge transfer from seen classes to unseen classes by leveraging class embeddings. However, directly borrowing the idea from zero-shot learning (ZSL) is not fully adaptive to the retrieval task, since the core of the retrieval task is learning the common space. To address the above issues, we propose a novel approach named Assembling AutoEncoder and Generative Adversarial Network (AAEGAN), which combines the strength of AutoEncoder (AE) and Generative Adversarial Network (GAN), to jointly incorporate common latent space learning, knowledge transfer, and feature synthesis for ZS-CMR. Besides, instead of utilizing class embeddings as common space, the AAEGAN approach maps all multimodal data into a learned latent space with the distribution alignment via three coupled AEs. We empirically show the remarkable improvement for ZS-CMR task and establish the state-of-the-art or competitive performance on four image-text retrieval datasets.
C1 [Xu, Xing; Tian, Jialin; Lin, Kaiyi; Shao, Jie; Shen, Heng Tao] Univ Elect Sci & Technol China, 2006 Xiyuan Ave, Chengdu 611731, Peoples R China.
   [Lu, Huimin] Kyushu Inst Technol, 1-1 Sensui, Kitakyushu, Fukuoka 8048550, Japan.
   [Shao, Jie; Shen, Heng Tao] Sichuan Artificial Intelligence Res Inst, 430,2nd Subsubsect,Changjiang North Rd, Yibin 611731, Peoples R China.
C3 University of Electronic Science & Technology of China; Kyushu Institute
   of Technology
RP Lu, HM (corresponding author), Kyushu Inst Technol, 1-1 Sensui, Kitakyushu, Fukuoka 8048550, Japan.
EM xing.xu@uestc.edu.cn; tian.garin@gmail.com; lky.linkaiyi@gmail.com;
   dr.huimin.lu@ieee.org; shaojie@uestc.edu.cn; shenhengtao@hotmail.com
RI TIAN, Jialin/E-4988-2015; Shen, Heng Tao/ABD-5331-2021
OI TIAN, Jialin/0000-0002-9991-9839; 
FU National Natural Science Foundation of China [61976049, 61632007];
   Fundamental Research Funds for the Central Universities [ZYGX2019Z015];
   Sichuan Science and Technology Program, China [2019ZDZX0008,
   2019YFG0003, 2019YFG0533, 2019YFG0535, 2020YFS0057, 2020YJ0038]
FX This work is partially supported by the National Natural Science
   Foundation of China (No. 61976049 and 61632007); the Fundamental
   Research Funds for the Central Universities (No. ZYGX2019Z015); and the
   Sichuan Science and Technology Program, China (No. 2019ZDZX0008,
   2019YFG0003, 2019YFG0533, 2019YFG0535, 2020YFS0057, and 2020YJ0038).
CR Akata Z, 2016, PROC CVPR IEEE, P59, DOI 10.1109/CVPR.2016.14
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Arjovsky, 2017, ARXIV170104862
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Ballan L., 2014, P INT C MULTIMEDIA R, P73
   Chen L, 2018, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2018.00115
   Chi JZ, 2020, IEEE T CIRC SYST VID, V30, P1173, DOI 10.1109/TCSVT.2019.2900171
   Chi JZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P663
   Chua Tat-Seng, 2009, P ACM INT C CONT BAS
   Coates A., 2011, P 14 INT C ART INT S, V15, P215
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang X., 2018, IEEE T CYBERNETICS, V14, P143
   Gulrajani I, 2017, ADV NEUR IN, V30
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Kingma D. P., 2013, ARXIV13126114
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Lin KY, 2020, AAAI CONF ARTIF INTE, V34, P11515
   Liu R., 2017, ARXIV170303567
   Mikolov Tomas, 2013, Preprints
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Sariyildiz MB, 2019, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2019.00227
   Shen HT, 2021, IEEE T KNOWL DATA EN, V33, P3351, DOI [10.1109/TKDE.2020.2970050, 10.1109/TNNLS.2020.2995708]
   Shen Heng Tao, 2020, IEEE T CYBERNET, P1
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Simonyan K., 2014, 14091556 ARXIV
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Srivastava N., 2012, P INT C MACH LEARN W
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408317
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xu X, 2020, IEEE T CYBERNETICS, V50, P2400, DOI 10.1109/TCYB.2019.2928180
   Xu X, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P46, DOI 10.1145/3206025.3206033
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhu YZ, 2018, PROC CVPR IEEE, P1004, DOI 10.1109/CVPR.2018.00111
   Zhuang Y., 2013, P 27 AAAI C ART INT, P1070
NR 61
TC 0
Z9 0
U1 1
U2 19
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD APR
PY 2021
VL 17
IS 1
SU S
SI SI
AR 3
DI 10.1145/3424341
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RW2ZT
UT WOS:000646396900003
DA 2024-07-18
ER

PT J
AU Zhao, ZY
   Yang, YH
   Li, C
   Nie, LQ
AF Zhao, Zhongying
   Yang, Yonghao
   Li, Chao
   Nie, Liqiang
TI GuessUNeed: Recommending Courses via Neural Attention Network and Course
   Prerequisite Relation Embeddings
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Recommendation; MOOCs; prerequisite relation; relation embeddings
AB Massive Open Online Courses, offering millions of high-quality courses from prestigious universities and prominent experts, are picking up momentum in popularity. Although users enrolling on MOOCs have free access to abundant knowledge, they may easily get overwhelmed by information overload. Therefore, there is a need of recommending technology as a fundamental and well-accepted effective solution. However, differing from many other online recommendations, recommending courses to users on MOOCs faces two challenges. First, users' knowledge background differs, so does their purpose of learning. Second, online courses are not independent but intertwined with prerequisite relations. Therefore, it is necessary to take these two challenges into account when designing a recommending method. To tackle this issue, in this article, we first propose two algorithms for extracting concept-level and course-level prerequisite relations. We then present the recommending method GuessUNeed based on neural attention network and course prerequisite relation embeddings. The experimental results on real-world datasets demonstrate the superiority of the proposed GuessUNeed method.
C1 [Zhao, Zhongying; Yang, Yonghao; Li, Chao] Shandong Univ Sci & Technol, 579 Qianwangang Rd, Qingdao 266590, Peoples R China.
   [Nie, Liqiang] Shandong Univ, Sch Comp Sci & Technol, Qingdao 266237, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University
RP Zhao, ZY (corresponding author), Shandong Univ Sci & Technol, 579 Qianwangang Rd, Qingdao 266590, Peoples R China.
EM zzysuin@163.com; yyh7089@foxmail.com; lichao@sdust.edu.cn;
   nieliqiang@gmail.com
RI Wang, Xingyi/KHT-7171-2024; Han, Liang/KFR-6745-2024; LI,
   Xiang-Yang/JZE-0275-2024; zhao, zhongying/V-6991-2019
FU National Natural Science Foundation of China [62072288, 61702306];
   National Key RD Plan [2018YFC0831002]; Ministry of Education in China
   Foundation for Humanities and Social Sciences [17YJCZH262, 18YJAZH136];
   Taishan Scholar Program of Shandong Province; Natural Science Foundation
   of Shandong Province [ZR2018BF013]; Open Project of Guangxi Key
   Laboratory of Trusted Software [KX201535]; Open Project Foundation of
   Intelligent Information Processing Key Laboratory of Shanxi Province
   [CICIP2020001]; SDUST Research Found for Innovative Team [2015TDJH102]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 62072288, 61702306), the National Key R&D Plan (Grant
   No. 2018YFC0831002), the Ministry of Education in China Foundation for
   Humanities and Social Sciences (Grant Nos. 17YJCZH262, 18YJAZH136), the
   Taishan Scholar Program of Shandong Province (Grant No. ts20190936), the
   Natural Science Foundation of Shandong Province (Grant No. ZR2018BF013),
   Open Project of Guangxi Key Laboratory of Trusted Software (Grant No.
   KX201535), Open Project Foundation of Intelligent Information Processing
   Key Laboratory of Shanxi Province (Grant No. CICIP2020001), and the
   SDUST Research Found for Innovative Team (Grant No. 2015TDJH102).
CR Abdi M.H., 2018, Comput. Inf. Sci., V11, P1, DOI [DOI 10.5539/CIS.V11N2P1, 10.5539/cis.v11n2p1]
   [Anonymous], 2015, P 2015 C EMP METH NA
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen JY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/3077136.3080797
   Christakopoulou E, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P67, DOI 10.1145/2959100.2959185
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Guo HF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1725
   Guo YB, 2019, EVID-BASED COMPL ALT, V2019, DOI 10.1155/2019/7517431
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   He Xiangnan, 2018, IEEE T KNOWL DATA EN, V30, P2354
   Hidasi Balazs, 2016, P 4 INT C LEARN REPR, P25
   Kabbur S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P659
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Pan LM, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1447, DOI 10.18653/v1/P17-1133
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Smith B, 2017, IEEE INTERNET COMPUT, V21, P12, DOI 10.1109/MIC.2017.72
   Tan Y. K., 2016, Proceedings of the 1st workshop on deep learning for recommender systems, P17
   Wei YW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1437, DOI 10.1145/3343031.3351034
   Xia Ning, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P497, DOI 10.1109/ICDM.2011.134
   Xiao J., 2017, ATTENTIONAL FACTORIZ, P3119, DOI 10.5555/3172077.3172324
   Xue F, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3314578
   Zhang Jing, 2019, P 33 AAAI C ART INT, P8023
   Zhao J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173903
   Zhao JL, 2019, KNOWL-BASED SYST, V166, P132, DOI 10.1016/j.knosys.2018.12.022
   Zhao ZY, 2021, INFORM SCIENCES, V543, P382, DOI 10.1016/j.ins.2020.07.001
   Zhao ZY, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106218
NR 27
TC 10
Z9 12
U1 2
U2 24
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2021
VL 16
IS 4
AR 132
DI 10.1145/3410441
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QB4CR
UT WOS:000614088800016
DA 2024-07-18
ER

PT J
AU Bentaleb, A
   Timmerer, C
   Begen, AC
   Zimmermann, R
AF Bentaleb, Abdelhak
   Timmerer, Christian
   Begen, Ali C.
   Zimmermann, Roger
TI Performance Analysis of ACTE: A Bandwidth Prediction Method for
   Low-latency Chunked Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE HAS; ABR; DASH; CMAF; low-latency; HTTP chunked transfer encoding;
   bandwidth measurement and prediction; RLS; encoding parameters; FFmpeg
AB HTTP adaptive streaming with chunked transfer encoding can offer low-latency streaming without sacrificing the coding efficiency. This allows media segments to be delivered while still being packaged. However, conventional schemes often make widely inaccurate bandwidth measurements due to the presence of idle periods between the chunks and hence this is causing sub-optimal adaptation decisions. To address this issue, we earlier proposed ACTE (ABR for Chunked Transfer Encoding) [6], a bandwidth prediction scheme for low-latency chunked streaming. While ACTE was a significant step forward, in this study we focus on two still remaining open areas, namely, (i) quantifying the impact of encoding parameters, including chunk and segment durations, bitrate levels, minimum interval between IDR-frames and frame rate on ACTE, and (ii) exploring the impact of video content complexity on ACTE. We thoroughly investigate these questions and report on our findings. We also discuss some additional issues that arise in the context of pursuing very low latency HTTP video streaming.
C1 [Bentaleb, Abdelhak; Zimmermann, Roger] Natl Univ Singapore, Sch Comp, 21 Lower Kent Ridge Rd, Singapore 119077, Singapore.
   [Timmerer, Christian] Alpen Adria Univ, Univ Str 65-67, A-9020 Klagenfurt, Austria.
   [Timmerer, Christian] Bitmovin, Univ Str 65-67, A-9020 Klagenfurt, Austria.
   [Begen, Ali C.] Ozyegin Univ, Orman Sk 13, TR-34794 Cekmekoy Istanbul, Turkey.
   [Begen, Ali C.] Networked Media, Orman Sk 13, TR-34794 Cekmekoy Istanbul, Turkey.
C3 National University of Singapore; University of Klagenfurt; Ozyegin
   University
RP Bentaleb, A (corresponding author), Natl Univ Singapore, Sch Comp, 21 Lower Kent Ridge Rd, Singapore 119077, Singapore.
EM bentaleb@comp.nus.edu.com; christian.timmerer@itec.uni-klu.ac.at;
   ali.begen@ozyegin.edu.tr; rogerz@comp.nus.edu.com
RI Zimmermann, Roger/D-7944-2015; Begen, Ali C./R-5897-2016; Bentaleb,
   Abdelhak/ABI-3704-2020
OI Zimmermann, Roger/0000-0002-7410-2590; Begen, Ali
   C./0000-0002-0835-3017; Bentaleb, Abdelhak/0000-0002-5382-6530
FU Singapore Ministry of Education Academic Research Fund Tier 2 under
   MOE's official Grant [MOE2018-T2-1-103]; Austrian Research Promotion
   Agency (FFG) under the Next Generation Video Streaming project
   "PROMETHEUS"; Christian Doppler Laboratory ATHENA
FX This research is supported by Singapore Ministry of Education Academic
   Research Fund Tier 2 under MOE's official Grant No. MOE2018-T2-1-103,
   the Austrian Research Promotion Agency (FFG) under the Next Generation
   Video Streaming project "PROMETHEUS," and the Christian Doppler
   Laboratory ATHENA.
CR [Anonymous], 2018, 23000192018 ISOIEC
   Begen A. C., 2018, IEEE ICMEW, P1, DOI DOI 10.1109/ICMEW.2018.8551563
   Ben Yahia M, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3280854
   Bentaleb A, 2019, PROCEEDINGS OF THE 29TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'19), P7, DOI 10.1145/3304112.3325611
   Bentaleb A, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P13, DOI 10.1145/3204949.3204961
   Bentaleb A, 2019, IEEE COMMUN SURV TUT, V21, P562, DOI 10.1109/COMST.2018.2862938
   Bouzakaria N, 2014, 5TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS, IISA 2014, P92, DOI 10.1109/IISA.2014.6878732
   El Essaili A, 2018, IEEE INT SYM BROADB
   Haddad RJ, 2013, IEEE COMMUN SURV TUT, V15, P1803, DOI 10.1109/SURV.2013.032213.00091
   Haykin S. S., 2008, ADAPTIVE FILTER THEO
   Houzé P, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511550
   Hu Xinjue, 2019, MOBILE INFO SYST, V2019
   Huang TY, 2014, SIGCOMM'14: PROCEEDINGS OF THE 2014 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P187, DOI 10.1145/2619239.2626296
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Mao HZ, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P197, DOI 10.1145/3098822.3098843
   Musumeci F, 2019, IEEE COMMUN SURV TUT, V21, P1383, DOI 10.1109/COMST.2018.2880039
   Naha RK, 2018, IEEE ACCESS, V6, P47980, DOI 10.1109/ACCESS.2018.2866491
   Neely Michael J., 2010, ARXIV10083519
   Pang HT, 2019, IEEE INFOCOM SER, P991, DOI 10.1109/INFOCOM.2019.8737395
   Pantos R., 2019, HTTP LIVE STREAMING
   Raca D, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P201, DOI 10.1145/3304109.3306233
   Robitza W, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P466, DOI 10.1145/3204949.3208124
   Shuai Y, 2018, 2018 15 IEEE ANN CON, P1, DOI [10.1109/CCNC.2018.8319262, DOI 10.1109/CCNC.2018.8319262]
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   Sun Y, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P272, DOI 10.1145/2934872.2934898
   Twitter Periscope, 2018, INTRO LHLS MEDIA STR
   van der Hooft J, 2018, J NETW SYST MANAG, V26, P51, DOI 10.1007/s10922-017-9407-2
   Veillon V, 2019, 2019 IEEE 3RD INTERNATIONAL CONFERENCE ON FOG AND EDGE COMPUTING (ICFEC), DOI 10.1109/cfec.2019.8733154
   Will L., ULTRALOW LATENCY STR
   Xie BC, 2011, IEEE INT SYMP ELEC, P16, DOI 10.1109/ISEMC.2011.6038277
   Xie XF, 2016, GETMOBILE-MOB COMPU, V20, P31
   Yin XQ, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P325, DOI 10.1145/2785956.2787486
NR 33
TC 13
Z9 13
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUL
PY 2020
VL 16
IS 2
SU S
SI SI
AR 69
DI 10.1145/3387921
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1FH
UT WOS:000583712600012
DA 2024-07-18
ER

PT J
AU Mettes, P
   Koelma, DC
   Snoek, CGM
AF Mettes, Pascal
   Koelma, Dennis C.
   Snoek, Cees G. M.
TI Shuffled ImageNet Banks for Video Event Detection and Search
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Event detection; event search; concepts; shuffle
AB This article aims for the detection and search of events in videos, where video examples are either scarce or even absent during training. To enable such event detection and search, ImageNet concept banks have shown to be effective. Rather than employing the standard concept bank of 1,000 ImageNet classes, we leverage the full 21,841-class dataset. We identify two problems with using the full dataset: (i) there is an imbalance between the number of examples per concept, and (ii) not all concepts are equally relevant for events. In this article, we propose to balance large-scale image hierarchies for pre-training. We shuffle concepts based on bottom-up and top-down operations to overcome the problems of example imbalance and concept relevance. Using this strategy, we arrive at the shuffled ImageNet bank, a concept bank with an order of magnitude more concepts compared to standard ImageNet banks. Compared to standard ImageNet pre-training, our shuffles result in more discriminative representations to train event models from the limited video event examples. For event search, the broad range of concepts enable a closer match between textual queries of events and concept detections in videos. Experimentally, we show the benefit of the proposed bank for event detection and event search, with state-of-the-art performance for both tasks on the challenging TRECVID Multimedia Event Detection and Ad-Hoc Video Search benchmarks.
C1 [Mettes, Pascal; Koelma, Dennis C.; Snoek, Cees G. M.] Univ Amsterdam, Sci Pk 904, Amsterdam, Netherlands.
C3 University of Amsterdam
RP Mettes, P (corresponding author), Univ Amsterdam, Sci Pk 904, Amsterdam, Netherlands.
EM P.S.M.Mettes@uva.nl; koelma@uva.nl; cgmsnoek@uva.nl
OI Mettes, Pascal/0000-0001-9275-5942
CR [Anonymous], 2017, P TRECVID
   [Anonymous], 2015, P CVPR
   Bhattacharya Subhabrata, 2014, P ICMR
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang XJ, 2016, AAAI CONF ARTIF INTE, P3464
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2016, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2016.208
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   CHANG XJ, 2017, TPAMI, V39, P1617, DOI DOI 10.1109/TPAMI.2016.2608901
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen Tianqi, 2015, P CORR
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dong Jianfeng, 2016, P MM
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan Hehe, 2017, P ICCV
   Foote JT, 1997, P SOC PHOTO-OPT INS, V3229, P138, DOI 10.1117/12.290336
   Gan C, 2016, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2016.106
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Girard Julien, 2018, PROCEEDINGS OF THE B
   Habibian A, 2017, IEEE T PATTERN ANAL, V39, P2089, DOI 10.1109/TPAMI.2016.2627563
   Habibian A, 2014, COMPUT VIS IMAGE UND, V124, P110, DOI 10.1016/j.cviu.2014.02.003
   Habibian Amirhossein, 2014, P MM
   Habibian Amirhossein, 2014, P ICMR
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Inoue Nakamasa, 2016, P MM
   Jaimes Alejandro, 2003, P CIVR
   Jain Mihir, 2015, P ICCV
   Jiang L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P49, DOI 10.1145/2733373.2806237
   Jiang Yu-Gang, 2007, VIREO 374 LSCOM SEMA
   Jiang Yu-Gang, 2008, CU VIREO374 FUSING C, P223
   Karpathy Andrej, 2014, PROCEEDINGS OF THE C
   Li Chao, 2017, P ICCV
   Li Xirong, 2016, P MM
   Liu Jingen, 2013, P WACV
   MA ZG, 2017, TMM, V19, P1558, DOI DOI 10.1109/TMM.2017.2659221
   Ma Zhigang, 2018, TNNLS, V10
   Markatopoulou Foteini, 2017, P ICMR
   MAZLOOM M, 2016, TMM, V18, P1378, DOI DOI 10.1109/TMM.2016.2559947
   Mazloom M, 2014, IEEE T MULTIMEDIA, V16, P2214, DOI 10.1109/TMM.2014.2359771
   Merler M., 2012, T MM, V14, P1
   Mettes Pascal, 2016, P ICMR
   Mettes Pascal, 2015, P ICMR
   Mettes Pascal, 2017, P ICCV
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nagel Markus, 2015, P BMVC
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Neo Shi-Yong, 2006, P CIVR
   Oneata D., 2013, P ICCV
   Ordonez Vicente., 2013, P ICCV
   Ronneberger Olaf, 2015, P MICCAI SOC
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Singh Bharat, 2015, P ICCV
   Snoek Cees G. M., 2006, P ACM MM
   SNOEK CGM, 2007, TMM, V9, P975, DOI DOI 10.1109/TMM.2007.900156
   Sun Chen, 2013, P WACV
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tamrakar Amir, 2012, P CVPR
   van der Corput P, 2017, COMPUT GRAPH FORUM, V36, P295, DOI 10.1111/cgf.13188
   Vreeswijk Daan T. J., 2012, P ICMR
   Wang Dong, 2007, P ACM MM
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   WEI XY, 2008, TMM, V10, P1085, DOI DOI 10.1109/TMM.2008.2001382
   Wong Sebastien C., 2016, P DICTA
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yanagawa Akira, 2007, COLUMBIA UNIVERSITY
   Yang Yang, 2012, P ECCV
   Ye Guangnan, 2015, P MM
   Yu LT, 2016, IEEE T IMAGE PROCESS, V26, P5689, DOI 10.1109/TIP.2016.2614136
   Yu LT, 2016, NEUROCOMPUTING, V213, P48, DOI 10.1016/j.neucom.2016.03.102
   Yu SI, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P419, DOI 10.1145/2671188.2749398
   Zha Shengxin, 2015, PROCEEDINGS OF THE B
   Zhang X., 2015, NANOMATERIALS, V2015, P9
   Zhu LG, 2019, IRONMAK STEELMAK, V46, P499, DOI 10.1080/03019233.2017.1405153
   Zhu LC, 2018, LECT NOTES COMPUT SC, V11211, P782, DOI 10.1007/978-3-030-01234-2_46
   Zhu LC, 2017, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2017.147
NR 80
TC 11
Z9 11
U1 7
U2 16
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2020
VL 16
IS 2
AR 44
DI 10.1145/3377875
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1EO
UT WOS:000583710600005
OA Green Published
DA 2024-07-18
ER

PT J
AU Hou, YX
   Yao, HX
   Sun, XS
   Li, HR
AF Hou, Yuxin
   Yao, Hongxun
   Sun, Xiaoshuai
   Li, Haoran
TI Soul Dancer: Emotion-Based Human Action Generation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Human emotion; body language; pose sequence; action generation
ID EXPRESSION ANALYSIS; SENTIMENT ANALYSIS; RECOGNITION
AB Body language is one of the most common ways of expressing human emotion. In this article, we make the first attempt to generate an action video with a specific emotion from a single person image. The goal of the emotion-based action generation task (EBAG) is to generate action videos expressing a specific type of emotion given a single reference image with a full human body. We divide the task into two parts and propose a two-stage framework to generate action videos with specified emotions. At the first stage, we propose an emotion-based pose sequence generation approach (EPOSE-GAN) for translating the emotion to a pose sequence. At the second stage, we generate the target video frames according to the three inputs including the source pose and the target pose as the motion information and the source image as the appearance reference by using conditional GAN model with an online training strategy. Our framework produces the pose sequence and transforms the action independently, which highlights the fundamental role that the high-level pose feature plays in generating action video with a specific emotion. The proposed method has been evaluated on the "Soul Dancer" dataset which is built for action emotion analysis and generation. The experimental results demonstrate that our framework can effectively solve the emotion-based action generation task. However, the gap in the details of the appearance between the generated action video and the real-world video still exists, which indicates that the emotion-based action generation task has great research potential.
C1 [Hou, Yuxin; Yao, Hongxun; Sun, Xiaoshuai; Li, Haoran] Harbin Inst Technol, Dazhi St West 92, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Hou, YX (corresponding author), Harbin Inst Technol, Dazhi St West 92, Harbin, Heilongjiang, Peoples R China.
EM YuxinHou_054@outlook.com; h.yao@hit.edu.cn; xiaoshuaisun@hit.edu.cn;
   haoran_li@hit.edu.cn
RI Li, Hao/GPS-9834-2022; Hou, Yuxin/J-3660-2019
FU National Natural Science Foundation of China [61772158, 61702136,
   U1711265]
FX This work was supported in part by the National Natural Science
   Foundation of China under project No. 61772158, 61702136, and U1711265.
CR Aman S, 2007, LECT NOTES ARTIF INT, V4629, P196
   [Anonymous], ARXIV181011794CS
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2019, P 33 AAAI C ART INT
   [Anonymous], ARXIV171201955CS
   [Anonymous], 2016, PROC 4 INT C LEARN R
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.632
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46484-8_29
   [Anonymous], 2018, CORR
   [Anonymous], ARXIV180803344CS
   [Anonymous], 2012, Mining Text Data, DOI [10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-413]
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P EUROPEAN C COMPUTE
   [Anonymous], 2017, P 31 INT C NEUR INF
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bulut M., 2004, P 6 INT C MULT INT, P205
   Cao Z., 2017, P IEEE C COMP VIS PA, P7291
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chaffar S, 2011, LECT NOTES ARTIF INT, V6657, P62, DOI 10.1007/978-3-642-21043-3_8
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kouloumpis E., 2011, TWITTER SENTIMENT AN
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li WY, 2014, EXPERT SYST APPL, V41, P1742, DOI 10.1016/j.eswa.2013.08.073
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Lu C., 2018, P BRIT MACH VIS C
   Lu Xin, 2012, Proc ACM Int Conf Multimed, V2012, P229, DOI 10.1145/2393347.2393384
   Ma LQ, 2018, PROC CVPR IEEE, P99, DOI 10.1109/CVPR.2018.00018
   Majumder N, 2018, KNOWL-BASED SYST, V161, P124, DOI 10.1016/j.knosys.2018.07.041
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Oh J., 2015, P NEURIPS, P2863
   Quan CQ, 2010, COMPUT SPEECH LANG, V24, P726, DOI 10.1016/j.csl.2010.02.002
   Salimans T., 2016, P 30 C NEUR INF PROC, P2234
   Simonyan K., 2014, 14091556 ARXIV
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Song XH, 2017, IEEE T IMAGE PROCESS, V26, P2721, DOI 10.1109/TIP.2017.2686017
   Strapparava C, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1556
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Villegas R., 2017, P ICLR
   Villegas R., 2017, International Conference on Machine Learning, P3560
   Vondrick C, 2017, PROC CVPR IEEE, P2992, DOI 10.1109/CVPR.2017.319
   Wang T., 2018, ARXIV
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Yan YC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P199, DOI 10.1145/3123266.3123277
   Yang P, 2010, PROC CVPR IEEE, P2638, DOI 10.1109/CVPR.2010.5539978
   Yang YH, 2017, IEEE T MULTIMEDIA, V19, P519, DOI 10.1109/TMM.2016.2626959
   Yang YH, 2017, IEEE T CYBERNETICS, V47, P439, DOI 10.1109/TCYB.2016.2519448
   Yang YH, 2016, SIGNAL PROCESS, V124, P36, DOI 10.1016/j.sigpro.2015.10.035
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang SX, 2018, FUTURE GENER COMP SY, V81, P395, DOI 10.1016/j.future.2017.09.048
   Zhao SC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1319, DOI 10.1145/3240508.3240591
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P3218, DOI 10.1109/TCYB.2017.2762344
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao Yan-Yan, 2010, Journal of Software, V21, P1834, DOI 10.3724/SP.J.1001.2010.03832
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 72
TC 3
Z9 4
U1 1
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PY 2019
VL 15
IS 3
SU S
SI SI
AR 99
DI 10.1145/3340463
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LR5EU
UT WOS:000535718800015
DA 2024-07-18
ER

PT J
AU Gudmundsson, GT
   Jónsson, BT
   Amsaleg, L
   Franklin, MJ
AF Gudmundsson, Gylfi Thor
   Jonsson, Bjorn Thor
   Amsaleg, Laurent
   Franklin, Michael J.
TI Prototyping a Web-Scale Multimedia Retrieval Service Using Spark
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; scalability; distributed computing; cloud
   computing; Spark
AB The world has experienced phenomenal growth in data production and storage in recent years, much of which has taken the form of media files. At the same time, computing power has become abundant with multi-core machines, grids, and clouds. Yet it remains a challenge to harness the available power and move toward gracefully searching and retrieving from web-scale media collections. Several researchers have experimented with using automatically distributed computing frameworks, notably Hadoop and Spark, for processing multimedia material, but mostly using small collections on small computing clusters. In this article, we describe a prototype of a (near) web-scale throughput-oriented MM retrieval service using the Spark framework running on the AWS cloud service. We present retrieval results using up to 43 billion SIFT feature vectors from the public YFCC 100M collection, making this the largest high-dimensional feature vector collection reported in the literature. We also present a publicly available demonstration retrieval system, running on our own servers, where the implementation of the Spark pipelines can be observed in practice using standard image benchmarks, and downloaded for research purposes. Finally, we describe a method to evaluate retrieval quality of the ever-growing high-dimensional index of the prototype, without actually indexing a web-scale media collection.
C1 [Gudmundsson, Gylfi Thor] Reykjavik Univ, Sch Comp Sci, Menntavegi 1, IS-101 Reykjavik, Iceland.
   [Jonsson, Bjorn Thor] IT Univ Copenhagen, Dept Comp Sci, Rued Langgaards Vej 7, DK-2300 Copenhagen S, Denmark.
   [Amsaleg, Laurent] IRISA, CNRS, Campus Beaulieu, F-35042 Rennes, France.
   [Franklin, Michael J.] Univ Chicago, Dept Comp Sci, Ryerson Lab 152, 1100 E 58th St, Chicago, IL 60637 USA.
   [Jonsson, Bjorn Thor] Reykjavik Univ, Reykjavik, Iceland.
   [Gudmundsson, Gylfi Thor; Franklin, Michael J.] Univ Calif Berkeley, AMPLab, 465 Soda Hall,MC 1776, Berkeley, CA 94720 USA.
C3 Reykjavik University; IT University Copenhagen; Centre National de la
   Recherche Scientifique (CNRS); Universite de Rennes; University of
   Chicago; Reykjavik University; University of California System;
   University of California Berkeley
RP Gudmundsson, GT (corresponding author), Reykjavik Univ, Sch Comp Sci, Menntavegi 1, IS-101 Reykjavik, Iceland.
EM gylfig@ru.is; bjorn@itu.dk; laurent.amsaleg@irisa.fr;
   mjfranklin@uchicago.edu
OI Franklin, Michael/0009-0005-0310-4803; Jonsson, Bjorn
   THor/0000-0003-0889-3491
FU Inria@SiliconValleyprogram; DHS [HSHQDC-16-3-00083]; NSF CISE
   Expeditions Award [CCF-1139158]; DOE Award [SN10040 DE-SC0012463]; DARPA
   XData Award [FA8750-12-2-0331]
FX Part of the work of G. P. Guomundsson and M. J. Franklin was performed
   while they were at the AMPLab, University of California, Berkeley. The
   work of Gylfi Por Guomundsson was supported in part by the
   Inria@SiliconValleyprogram. The research was also supported in part by
   DHS Award HSHQDC-16-3-00083, NSF CISE Expeditions Award CCF-1139158, DOE
   Award SN10040 DE-SC0012463, and DARPA XData Award FA8750-12-2-0331, and
   gifts from Amazon Web Services, Google, IBM, SAP, The Thomas and Stacey
   Siebel Foundation, Apple Inc., Arimo, Blue Goji, Bosch, Cisco, Cray,
   Cloudera, Ericsson, Facebook, Fujitsu, HP, Huawei, Intel, Microsoft,
   Mitre, Pivotal, Samsung, Schlumberger, Splunk, State Farm, and VMware.
CR Amsaleg L., 2014, HABILITATION DIRIGER
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2011, FDN LARGE SCALE MULT
   [Anonymous], 2011, INT WORKSH CONT BAS
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P EUR C COMP VIS
   [Anonymous], P INT C TEL
   [Anonymous], 2003, P IEEE INT C COMP VI
   [Anonymous], 2015, ARXIV151106051
   [Anonymous], P ACM INT C MULT RET
   Arandjelovic R., 2013, P IEEE INT C COMP VI
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319
   Batko M, 2010, MULTIMED TOOLS APPL, V47, P599, DOI 10.1007/s11042-009-0339-z
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Grace R. K., 2014, P INT C COMP SCI COM
   Gu C., 2012, P INT C CLOUD GREEN
   Guomundsson G. P., 2017, P ACM MULT SYST C
   Hare J. S., 2012, P ACM INT C MULT RET
   Jegou H., 2008, COPYDAYS IMAGE DATAS
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Lejsek H., 2011, P ACM INT C MULT RET
   Liu T., 2007, P IEEE WORKSH APPL C
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marz N., 2015, Big Data: Principles and Best Practices of Scalable Realtime Data Systems
   Moise D, 2013, IEEE INT CONF BIG DA
   Ooi B. C., 2015, P ACM INT C MULT
   Owen Sean., 2011, Mahout in Action
   Philbin J., 2008, P IEEE INT C COMP VI
   Premchaiswadi W., 2013, P INT C HIGH PERF CO
   Shvachko K, 2010, IEEE S MASS STOR SYS
   Sun X., 2013, P ACM INT C MULT
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Wang H., 2015, P ACM INT C MULT
   White B., 2010, P INT WORKSH MULT DA
   Yao Qing-An, 2014, J MULTIMEDIA, V9, P2
   Zaharia M., 2010, P USENIX WORKSH HOT
   Zaharia M., 2012, P S NETW SYST DES IM
   Zhang J., 2010, P INT C PERV COMP AP
NR 40
TC 4
Z9 4
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2018
VL 14
IS 3
SU S
AR 65
DI 10.1145/3209662
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HG9GD
UT WOS:000455314500013
OA Bronze
DA 2024-07-18
ER

PT J
AU Kirchhoffer, H
   Marpe, D
   Schwarz, H
   Wiegand, T
AF Kirchhoffer, Heiner
   Marpe, Detlev
   Schwarz, Heiko
   Wiegand, Thomas
TI Properties and Design of Variable-to-Variable Length Codes
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Entropy coding; Huffman coding; package merge algorithm; variable length
   coding; V2V coding
ID ALGORITHM
AB For the entropy coding of independent and identically distributed (i.i.d.) binary sources, variable-to-variable length (V2V) codes are an interesting alternative to arithmetic coding. Such a V2V code translates variable length words of the source into variable length code words by employing two prefix-free codes. In this article, several properties of V2V codes are studied, and new concepts are developed. In particular, it is shown that the redundancy of a V2V code cannot be zero for a binary i.i.d. source {X) with 0 < p(X)(1) < 0.5. Furthermore, the concept of prime and composite V2V codes is proposed, and it is shown why composite V2V codes can be disregarded in the search for particular classes of minimum redundancy codes. Moreover, a canonical representation for V2V codes is proposed, which identifies V2V codes that have the same average code length function. It is shown how these concepts can be employed to greatly reduce the complexity of a search for minimum redundancy (size-limited) V2V codes.
C1 [Kirchhoffer, Heiner; Marpe, Detlev; Schwarz, Heiko; Wiegand, Thomas] Heinrich Hertz Inst Nachrichtentech Berlin GmbH, Fraunhofer Inst Telecommun, Einsteinufer 37, D-10587 Berlin, Germany.
   [Wiegand, Thomas] Tech Univ Berlin, Fac Elect Engn & Comp Sci, Einsteinufer 17D, D-10587 Berlin, Germany.
C3 Fraunhofer Gesellschaft; Technical University of Berlin
RP Kirchhoffer, H (corresponding author), Heinrich Hertz Inst Nachrichtentech Berlin GmbH, Fraunhofer Inst Telecommun, Einsteinufer 37, D-10587 Berlin, Germany.
EM Heiner.Kirchhoffer@hhi.fraunhofer.de; Detlev.Marpe@hhi.fraunhofer.de;
   Heiko.Schwarz@hhi.fraunhofer.de; Thomas.Wiegand@hhi.fraunhofer.de
OI Marpe, Detlev/0000-0002-5391-3247
CR Abrahams J., 1997, COMPRESSION COMPLEXI, P145, DOI DOI 10.1109/SEQUEN.1997.666911
   Boreico I., 2008, Harv. Coll. Math. Rev., V2, P87
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   CONNELL JB, 1973, P IEEE, V61, P1046, DOI 10.1109/PROC.1973.9200
   FABRIS F, 1992, IEEE T INFORM THEORY, V38, P1609, DOI 10.1109/18.149517
   Freeman G. H., 1993, DCC '93. Data Compression Conference (Cat. No.93TH0536-3), P79, DOI 10.1109/DCC.1993.253142
   Freeman G. H., 1991, DCC '91. Data Compression Conference (Cat. No.91TH0373-1), P208, DOI 10.1109/DCC.1991.213360
   GUTHERY SB, 2010, MOTIF MATH HIST APPL
   HIRSCHBERG DS, 1990, COMMUN ACM, V33, P449, DOI 10.1145/77556.77566
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   JELINEK F, 1972, IEEE T INFORM THEORY, V18, P765, DOI 10.1109/TIT.1972.1054899
   Kirchhoffer H., 2016, THESIS
   Kraft Leon Gordon, 1949, THESIS
   LARMORE LL, 1990, J ACM, V37, P464, DOI 10.1145/79147.79150
   Marpe Detlev, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P66, DOI 10.1109/PCS.2010.5702580
   Marpe D., 2014, US Patent, Patent No. [8,907,823, 8907823]
   Michaels J.G., 1991, APPL DISCRETE MATH
   RISSANEN JJ, 1976, IBM J RES DEV, V20, P198, DOI 10.1147/rd.203.0198
   SCHWARTZ ES, 1964, COMMUN ACM, V7, P166, DOI 10.1145/363958.363991
   Stubley P. R., 1994, Proceedings DCC '94. Data Compression Conference (Cat. No.94TH0626-2), P98, DOI 10.1109/DCC.1994.305917
   Stubley P. R., 1994, Proceedings DCC '94. Data Compression Conference (Cat. No.94TH0626-2), P90, DOI 10.1109/DCC.1994.305916
   Stubley P. R., 1992, THESIS
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Tunstall B. P., 1967, THESIS
   Wiegand T., 2011, SOURCE CODING 1, DOI [10.1561/2000000010, DOI 10.1561/2000000010]
NR 25
TC 2
Z9 2
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2018
VL 14
IS 3
AR 75
DI 10.1145/3230653
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GT7CI
UT WOS:000444677600008
OA Bronze
DA 2024-07-18
ER

PT J
AU Liu, C
   Ooi, WT
   Jia, JY
   Zhao, L
AF Liu, Chang
   Ooi, Wei Tsang
   Jia, Jinyuan
   Zhao, Lei
TI Cloud Baking: Collaborative Scene Illumination for Dynamic Web3D Scenes
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Remote rendering; global illumination; light baking; WebGL; interactive
   3D applications
ID EDUCATION; DEPTH
AB We propose Cloud Baking, a collaborative rendering architecture for dynamic Web3D scenes. In our architecture, the cloud renderer renders the scene with the global illumination (GI) information in a GI map; the web-based client renderer renders the scene with ambient lighting only and blends it with the GI map received from the cloud for the final scene. This approach allows the users to interact with the web scene and change the scene dynamically through the web interface end, yet move the computationally heavy tasks of global illumination computation to the cloud. A challenge we face is the interaction delay that causes the frames rendered on the cloud and the client to go out of sync. We propose to use 3D warping and a hole-filling algorithm designed for GI map to predict the late GI map. We show both quantitatively and visually the quality of the GI map produced using our method. Our prediction algorithm allows us to further reduce the frequency at which the GI map is computed and sent from the server, reducing both computational needs and bandwidth usage.
C1 [Liu, Chang; Jia, Jinyuan] Tongji Univ, Caoan Highway 4800, Shanghai 201804, Peoples R China.
   [Ooi, Wei Tsang] Natl Univ Singapore, Dept Comp Sci, AS6,05-14, Singapore 117417, Singapore.
   [Zhao, Lei] Nanchang Hangkong Univ, Fenghe South Rd 696, Nanchang 330063, Jiangxi, Peoples R China.
C3 Tongji University; National University of Singapore; Nanchang Hangkong
   University
RP Liu, C (corresponding author), Tongji Univ, Caoan Highway 4800, Shanghai 201804, Peoples R China.
EM 70202@nchu.edu.cn; ooiwt@comp.nus.edu.sg; jyjia@tongji.edu.cn;
   zhaolei.U@gmail.com
RI Ooi, Wei Tsang/AAE-7810-2019; Ooi, Wei Tsang/HLW-5142-2023
OI Ooi, Wei Tsang/0000-0001-8994-1736; Ooi, Wei Tsang/0000-0001-8994-1736
FU Fundamental Research Funds for Chinese Central Universities [2100219066,
   0200219153]
FX This work was supported by The Fundamental Research Funds for Chinese
   Central Universities (Project 2100219066 and 0200219153)
CR [Anonymous], P 1997 S INT 3D GRAP
   [Anonymous], P 11 ANN WORKSH NETW
   Bao P, 2004, IEE P-VIS IMAGE SIGN, V151, P329, DOI 10.1049/ip-vis:20040749
   Brodlie KW, 2004, COMPUT GRAPH FORUM, V23, P223, DOI 10.1111/j.1467-8659.2004.00754.x
   Chen K.-T., 2011, P 19 ACM INT C MULT, P1269
   Chittaro L, 2007, COMPUT EDUC, V49, P3, DOI 10.1016/j.compedu.2005.06.002
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Crassin C, 2011, COMPUT GRAPH FORUM, V30, P1921, DOI 10.1111/j.1467-8659.2011.02063.x
   Crassin Cyril., 2015, Journal of Computer Graphics Techniques Vol, V4, P1
   Dachsbacher C., 2005, Proc. Symp. Interactive Graph. and Games, P203, DOI DOI 10.1145/1053427.1053460
   Dirksen J, 2013, Learning three. js: the JavaScript 3D library for WebGL
   Duguet F, 2004, IEEE COMPUT GRAPH, V24, P57, DOI 10.1109/MCG.2004.5
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Gladstien K., 2013, FLASH GAME DEV SOCIA
   Hsu LW, 2012, J HOSP LEIS SPORT TO, V11, P113, DOI 10.1016/j.jhlste.2012.02.013
   Kaplanyan A., 2010, Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'10, P99, DOI [10.1145/1730804.1730821, 10.1145/1730804.1730821.24, DOI 10.1145/1730804.1730821.24]
   Koller D, 2004, ACM T GRAPHIC, V23, P695, DOI 10.1145/1015706.1015782
   Lee K., 2015, ANAL CLOUD GAMING PL, P151
   Lluch J., 2005, Proceedings of the 2005 ACM SIGCHI international Conference on Advances in Computer Entertainment Technology (Valencia, Spain, June 15 - 17, 2005), P254
   McMillan Leonard, 1997, THESIS
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Nah FFH, 2004, BEHAV INFORM TECHNOL, V23, P153, DOI 10.1080/01449290410001669914
   Paul B, 2008, IEEE T VIS COMPUT GR, V14, P627, DOI 10.1109/TVCG.2007.70631
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shi S, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348825
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen L., 2014, P 13 ACM SIGGRAPH IN, P95
   Wen Laixiang, 2016, LNCS, V9517, P93, DOI [10.1007/978-3-319-27674-89, DOI 10.1007/978-3-319-27674-89]
   Zhu Minhui, 2011, P 19 ACM INT C MULT, P183, DOI DOI 10.1145/2072298.2072324
   Zinner Thomas, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P29, DOI 10.1109/QOMEX.2010.5518277
NR 31
TC 10
Z9 15
U1 3
U2 20
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2018
VL 14
IS 3
SU S
AR 59
DI 10.1145/3206431
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HG9GD
UT WOS:000455314500007
DA 2024-07-18
ER

PT J
AU Ahmad, K
   Mekhalfi, ML
   Conci, N
   Melgani, F
   De Natale, F
AF Ahmad, Kashif
   Mekhalfi, Mohamed Lamine
   Conci, Nicola
   Melgani, Farid
   De Natale, Francesco
TI Ensemble of Deep Models for Event Recognition
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Event recognition; deep neural networks; multiple classifiers; fusion;
   multimedia indexing and retrieval; IOWA; genetic algorithms; PSO; CNN
ID FUSION
AB In this article, we address the problem of recognizing an event from a single related picture. Given the large number of event classes and the limited information contained in a single shot, the problem is known to be particularly hard, To achieve a reliable detection, we propose a combination of multiple classifiers, and we compare three alternative strategies to fuse the results of each classifier, namely: (i) induced order weighted averaging operators, (ii) genetic algorithms, and (iii) particle swarm optimization. Each method is aimed at determining the optimal weights to be assigned to the decision scores yielded by different deep models, according to the relevant optimization strategy. Experimental tests have been performed on three event recognition datasets, evaluating the performance of various deep models, both alone and selectively combined. Experimental results demonstrate that the proposed approach outperforms traditional multiple classifier solutions based on uniform weighting, and outperforms recent state-of-the-art approaches.
C1 [Ahmad, Kashif; Mekhalfi, Mohamed Lamine; Conci, Nicola; Melgani, Farid; De Natale, Francesco] Univ Trento, DISI, Via Sommarive 5, I-38123 Trento, Italy.
C3 University of Trento
RP Ahmad, K (corresponding author), Univ Trento, DISI, Via Sommarive 5, I-38123 Trento, Italy.
EM kashif.ahmad@unitn.it; mmedlamine@gmail.com; nicola.conci@unitn.it;
   farid.melgani@unitn.it; francesco.denatale@unitn.it
RI Conci, Nicola/AAH-4671-2020; ahmad, kashif/AAV-8323-2021; Mekhalfi,
   Mohamed Lamine/AAA-4596-2019; Ahmad, Kashif/JJE-8424-2023
OI Conci, Nicola/0000-0002-7858-0928; Ahmad, Kashif/0000-0002-0931-9275
CR Ahmad K, 2018, SIGNAL PROCESS-IMAGE, V60, P42, DOI 10.1016/j.image.2017.09.009
   Ahmad K, 2016, IEEE GLOB CONF SIG, P1223, DOI 10.1109/GlobalSIP.2016.7906036
   [Anonymous], 2016, P KOREA JAPAN JOINT
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, P 7 INT C MULTIMEDIA
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], P CVPR
   [Anonymous], PATTERN RECOGNIT SUP
   [Anonymous], MEDIAEVAL
   [Anonymous], P MEDIAEVAL 2013 MUL
   [Anonymous], BCS IRSG ANN C IR RE
   [Anonymous], P ACM ICMR 2014 WORK
   [Anonymous], ARXIV161204062
   [Anonymous], 2017, P MEDIAEVAL 2017 DUB
   [Anonymous], ACM T MULTIMEDIA COM
   [Anonymous], 2017, COMPLEXITY
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Banks Alec, 2008, Natural Computing, V7, P109, DOI 10.1007/s11047-007-9050-z
   Bazi Y, 2006, IEEE T GEOSCI REMOTE, V44, P3374, DOI 10.1109/TGRS.2006.880628
   Bossard L, 2013, IEEE I CONF COMP VIS, P1193, DOI 10.1109/ICCV.2013.151
   Brenner Markus., 2012, Proceedings of the 2nd ACM International Conference on Multimedia Retrieval, page, P21
   Caruana R, 2006, IEEE DATA MINING, P828
   Chang SF, 2005, INT CONF ACOUST SPEE, P1005
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen L., 2009, Proceedings of the 18th ACM conference on Information and knowledge management, P523
   Dao MS, 2014, MULTIMED TOOLS APPL, V70, P25, DOI 10.1007/s11042-012-1153-6
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Escalera Sergio, 2015, P IEEE INT C COMPUTE, P1
   Firan C.S., 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, P189
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Gong Y., 2012, 2012 20th International Conference on Geoinformatics, P1, DOI DOI 10.1109/GEOINFORMATICS.2012.6270316
   Guo Cheng, 2015, 2015 IEEE 34th International Performance Computing and Communications Conference (IPCCC), P1, DOI 10.1109/PCCC.2015.7410341
   Hall DL, 1997, P IEEE, V85, P6, DOI [10.1109/5.554205, 10.1109/ISCAS.1998.705329]
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Iyengar G, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P772
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Lan ZZ, 2012, LECT NOTES COMPUT SC, V7131, P173
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Liu M, 2015, P IEEE INT C COMP VI, P32, DOI 10.1016/j.ijsolstr.2015.02.031
   Liu XC, 2013, PROCEEDINGS OF THE 1ST INTERNATIONAL JOINT SYMPOSIUM ON JOINING AND WELDING, P151
   McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61
   Mezaris V, 2014, MULTIMED TOOLS APPL, V70, P1, DOI 10.1007/s11042-013-1426-8
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Natarajan P, 2012, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2012.6247814
   Papadopoulos S, 2011, IEEE MULTIMEDIA, V18, P52, DOI 10.1109/MMUL.2010.68
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Rosani A, 2015, IEEE T MULTIMEDIA, V17, P1359, DOI 10.1109/TMM.2015.2441003
   Salvador A, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301334
   Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392
   Scrucca L., 2016, Unsupervised Learning Algorithms, P55
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Simonyan K., 2014, 14091556 ARXIV
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Sungheon Park, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P45, DOI 10.1109/CVPRW.2015.7301335
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Troncy R., 2010, Proceedings of the 6th International Conference on Semantic Systems, P42
   Tzelepis Christos, 2016, Image and Vision Computing, V53, P3, DOI 10.1016/j.imavis.2016.05.005
   Voorhees E. M., 1995, SIGIR Forum, P172
   Wang L., 2015, Proceedings of the IEEE International Conference on Computer Vision Workshops (ICCVW), P45
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   Wang Y., 2012, Proceedings of the 20th ACM International Conference on Multimedia, P865, DOI [DOI 10.1145/2393347.239633216, 10.1145/2393347.239633216]
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
   Xiong YJ, 2015, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2015.7298768
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   Yager RR, 1999, IEEE T SYST MAN CY B, V29, P141, DOI 10.1109/3477.752789
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 72
TC 27
Z9 27
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2018
VL 14
IS 2
AR 51
DI 10.1145/3199668
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GG9BS
UT WOS:000432996000008
DA 2024-07-18
ER

PT J
AU Wen, JQ
   She, J
   Li, XP
   Mao, H
AF Wen, Jiqing
   She, James
   Li, Xiaopeng
   Mao, Hui
TI Visual Background Recommendation for Dance Performances Using Deep
   Matrix Factorization
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Interactive dance; dance background; image recommendation; content-based
   social computing
AB The stage background is one of the most important features for a dance performance, as it helps to create the scene and atmosphere. In conventional dance performances, the background images are usually selected or designed by professional stage designers according to the theme and the style of the dance. In new media dance performances, the stage effects are usually generated by media editing software. Selecting or producing a dance background is quite challenging and is generally carried out by skilled technicians. The goal of the research reported in this article is to ease this process. Instead of searching for background images from the sea of available resources, dancers are recommended images that they are more likely to use. This work proposes the idea of a novel system to recommend images based on content-based social computing. The core part of the system is a probabilistic prediction model to predict a dancer's interests in candidate images through social platforms. Different from traditional collaborative filtering or content-based models, the model proposed here effectively combines a dancer's social behaviors (rating action, click action, etc.) with the visual content of images shared by the dancer using deep matrix factorization (DMF). With the help of such a system, dancers can select from the recommended images and set them as the backgrounds of their dance performances through a media editor. According to the experiment results, the proposed DMF model outperforms the previous methods, and when the dataset is very sparse, the proposed DMF model shows more significant results.
C1 [Wen, Jiqing; She, James; Li, Xiaopeng; Mao, Hui] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Wen, JQ (corresponding author), Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China.
EM jwenab@connect.ust.hk; eejames@ust.hk; xlibo@connect.ust.hk;
   hmaoaa@connect.ust.hk
OI Li, Xiaopeng/0000-0003-4916-1131
FU HKUST-NIE Social Media Lab
FX This work was supported by HKUST-NIE Social Media Lab.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 1999, P ACM SIGIR WORKSH R
   [Anonymous], 2015, P 9 ACM C RECOMMENDE, DOI [10.1145/2792838.2800193, DOI 10.1145/2792838.2800193]
   Aylward R., 2006, P 2006 C NEW INTERFA, P134
   Clay A, 2014, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR-AMH.2014.6935434
   Clay A, 2012, INT SYM MIX AUGMENT, DOI 10.1109/ISMAR-AMH.2012.6483986
   DAS Abhinandan, 2007, P 16 INT C WORLD WID, V16, P271
   Fang C, 2015, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2015.7298656
   Gatys L., 2015, NIPS
   Geng X, 2015, IEEE I CONF COMP VIS, P4274, DOI 10.1109/ICCV.2015.486
   Heryadi Y, 2012, 2012 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER SCIENCE AND INFORMATION SYSTEMS, P261
   James J., 2006, P ACM INT C MULTIMED, P470
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Latulipe C., 2010, CHI EA '10: Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems, P2995, DOI [10.1145/1753846.1753904, DOI 10.1145/1753846.1753904]
   Latulipe Celine., 2011, Proceedings of the ACM Conference on Creativity Cognition, P107
   Li XP, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P931, DOI 10.1109/BigData.2016.7840689
   Ma H, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P203, DOI 10.1145/1571941.1571978
   Massa P, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P17
   Melville P, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P187
   Park Chulsung., 2006, P 4 ANN IEEE INT C P
   Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, P1257, DOI DOI 10.5555/2981562.2981720
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soboroff Ian., 1999, Proceedings of the IJCAI99 Workshop on Machine Learning for Information Filtering, P86
   Van den Oord A., 2013, ADV NEURAL INFORM PR, P2643, DOI [DOI 10.1109/MMUL.2011.34.VAN, 10.5555/2999792.2999907]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang J., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P501, DOI 10.1145/1148170.1148257
   Wang XX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P627, DOI 10.1145/2647868.2654940
   Wen JQ, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P521, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2016.120
   Yang LQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1410, DOI 10.1109/ICDMW.2015.160
NR 30
TC 10
Z9 11
U1 2
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2018
VL 14
IS 1
AR 11
DI 10.1145/3152463
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FW9HO
UT WOS:000425646500011
DA 2024-07-18
ER

PT J
AU Karafotias, G
   Teranishi, A
   Korres, G
   Eyssel, F
   Copti, S
   Eid, M
AF Karafotias, Georgios
   Teranishi, Akiko
   Korres, Georgios
   Eyssel, Friederike
   Copti, Scandar
   Eid, Mohamad
TI Intensifying Emotional Reactions via Tactile Gestures in Immersive Films
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Immersive virtual reality; affective haptics; multimodal interaction;
   tactile gestures
ID DATABASE; HAPTICS
AB The film industry continuously strives to make visitors' movie experience more immersive and thus, more captivating. This is realized through larger screens, sophisticated speaker systems, and high quality 2D and 3D content. Moreover, a recent trend in the film industry is to incorporate multiple interaction modalities, such as 4D film, to simulate rain, wind, vibration, and heat, in order to intensify viewers' emotional reactions. In this context, humans' sense of touch possesses significant potential for intensifying emotional reactions for the film experience beyond audio-visual sensory modalities. This article presents a framework for authoring tactile cues (tactile gestures as used in this article) and enabling automatic rendering of said gestures to intensify emotional reactions in an immersive film experience. To validate the proposed framework, we conducted an experimental study where tactile gestures are designed and evaluated for the ability to intensify four emotional reactions: high valence-high arousal, high valence-low arousal, low valence-high arousal, and low valence-low arousal. Using a haptic jacket, participants felt tactile gestures that are synchronized with the audio-visual contents of a film. Results demonstrated that (1) any tactile feedback generated a positive user experience; (2) the tactile feedback intensifies emotional reactions when the audio-visual stimuli elicit clear emotional responses, except for low arousal emotional response since tactile gestures seem to always generate excitement; (3) purposed tactile gestures do not seem to significantly outperform randomized tactile gesture for intensifying specific emotional reactions; and (4) using a haptic jacket is not distracting for the users.
C1 [Karafotias, Georgios; Teranishi, Akiko; Korres, Georgios; Copti, Scandar; Eid, Mohamad] New York Univ Abu Dhabi, POB 129188, Abu Dhabi, U Arab Emirates.
   [Eyssel, Friederike] Bielefeld Univ, Bielefeld, Germany.
   [Eyssel, Friederike] Univ Bielefeld, Exzellenzcluster Cognit Interact Technol CITEC, Forsch Bau, Inspirat 1 Zehlendorfer Damm 199, D-33619 Bielefeld, Germany.
C3 New York University Abu Dhabi; University of Bielefeld; University of
   Bielefeld
RP Karafotias, G (corresponding author), New York Univ Abu Dhabi, POB 129188, Abu Dhabi, U Arab Emirates.
EM georgios.karafotias@nyu.edu; at132@nyu.edu; george.korres@nyu.edu;
   feyssel@cit-ec.uni-bielefeld.de; scandar.copti@nyu.edu;
   mohamad.eid@nyu.edu
OI Eyssel, Friederike/0000-0002-4978-8922
CR Albert W., 2013, Measuring the User Experience
   Arafsha F, 2015, MULTIMED TOOLS APPL, V74, P3035, DOI 10.1007/s11042-013-1767-3
   Baveye Y, 2015, IEEE T AFFECT COMPUT, V6, P43, DOI 10.1109/TAFFC.2015.2396531
   Bonanni L., 2006, TAPTAP HAPTIC WEARAB, P580, DOI DOI 10.1145/1125451.1125573
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Cha J., 2009, MM '09: Proceedings of the seventeen ACM international conference on Multimedia, P1135, DOI [10.1145/1631272.1631535, DOI 10.1145/1631272.1631535]
   Danieau F, 2013, IEEE T HAPTICS, V6, P193, DOI [10.1109/TOH.2012.70, 10.1109/ToH.2012.70]
   Eid MA, 2016, IEEE ACCESS, V4, P26, DOI 10.1109/ACCESS.2015.2497316
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Hamam A, 2013, MULTIMED TOOLS APPL, V67, P455, DOI 10.1007/s11042-012-0990-7
   Israr A., 2011, 2011 IEEE World Haptics Conference (WHC 2011), P457, DOI 10.1109/WHC.2011.5945529
   Israr A, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2641570
   Krishna Sreekar, 2010, CHI 10 EXTENDED ABST, P3637
   Kryssanov V.V., 2009, P IEEE 2009 3 INT C, P1
   Lemmens P, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P7, DOI 10.1109/WHC.2009.4810832
   Lentini Rodrigo, 2016, WORLD ACAD SCI ENG T, V10, P1862
   Mazzoni A, 2015, PROCEEDINGS OF THE 2015 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNOLOGIES FOR INTERACTIVE ENTERTAINMENT, P64, DOI 10.4108/icst.intetain.2015.259625
   Nummenmaa L, 2014, P NATL ACAD SCI USA, V111, P646, DOI 10.1073/pnas.1321664111
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Rashid M, 2013, VISUAL COMPUT, V29, P1269, DOI 10.1007/s00371-012-0768-y
   Reiner M, 2004, IEEE T CIRC SYST VID, V14, P392, DOI 10.1109/TCSVT.2004.823399
   Salminen K, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1555
   Schaefer A, 2010, COGNITION EMOTION, V24, P1153, DOI 10.1080/02699930903274322
   Sun K, 2009, IEEE INT CON MULTI, P566, DOI 10.1109/ICME.2009.5202559
   Weddle AB, 2013, INT WORK QUAL MULTIM, P158, DOI 10.1109/QoMEX.2013.6603230
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 26
TC 14
Z9 13
U1 3
U2 33
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2017
VL 13
IS 3
AR 29
DI 10.1145/3092840
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA FD5TE
UT WOS:000407591900007
DA 2024-07-18
ER

PT J
AU Pouladzadeh, P
   Shirmohammadi, S
AF Pouladzadeh, Parisa
   Shirmohammadi, Shervin
TI Mobile Multi-Food Recognition Using Deep Learning
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Mobile food recognition; deep learning; cloud computing
AB In this article, we propose a mobile food recognition system that uses the picture of the food, taken by the user's mobile device, to recognize multiple food items in the same meal, such as steak and potatoes on the same plate, to estimate the calorie and nutrition of the meal. To speed up and make the process more accurate, the user is asked to quickly identify the general area of the food by drawing a bounding circle on the food picture by touching the screen. The system then uses image processing and computational intelligence for food item recognition. The advantage of recognizing items, instead of the whole meal, is that the system can be trained with only single item food images. At the training stage, we first use region proposal algorithms to generate candidate regions and extract the convolutional neural network (CNN) features of all regions. Second, we perform region mining to select positive regions for each food category using maximum cover by our proposed submodular optimization method. At the testing stage, we first generate a set of candidate regions. For each region, a classification score is computed based on its extracted CNN features and predicted food names of the selected regions. Since fast response is one of the important parameters for the user who wants to eat the meal, certain heavy computational parts of the application are offloaded to the cloud. Hence, the processes of food recognition and calorie estimation are performed in cloud server. Our experiments, conducted with the FooDD dataset, show an average recall rate of 90.98%, precision rate of 93.05%, and accuracy of 94.11% compared to 50.8% to 88% accuracy of other existing food recognition systems.
C1 [Pouladzadeh, Parisa; Shirmohammadi, Shervin] Univ Ottawa, Sch Elect Engn & Comp Sci, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
   [Shirmohammadi, Shervin] Istanbul Sehir Univ, Multimedia Syst Lab, Istanbul, Turkey.
C3 University of Ottawa; Istanbul Sehir University
RP Pouladzadeh, P (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
EM ppoul081@uottawa.ca; shervin@discover.uottawa.ca
RI Shirmohammadi, Shervin/E-6945-2012; Pouladzadeh, Parisa/JAX-7657-2023
OI Shirmohammadi, Shervin/0000-0002-3973-4445; 
CR Aizawa K, 2015, IEEE MULTIMEDIA, V22, P4, DOI 10.1109/MMUL.2015.39
   Amano S, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P48, DOI 10.1109/BigMM.2015.54
   [Anonymous], ACM INT C MULT
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Dehais J, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P23, DOI 10.1145/2986035.2986047
   Fard MA, 2016, DH'16: PROCEEDINGS OF THE 2016 DIGITAL HEALTH CONFERENCE, P121, DOI 10.1145/2896338.2896355
   Fujishige S, 2005, ANN DISCR MATH, V58, P1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kawano Y, 2013, IEEE COMPUT SOC CONF, P1, DOI 10.1109/CVPRW.2013.5
   Khudanpur V, 2015, P 16 ANN C INT SPEEC, P1
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, P1097
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Matsuda Y., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P25, DOI 10.1109/ICME.2012.157
   Pouladzadeh P, 2016, IEEE INSTRU MEAS MAG, V19, P9, DOI 10.1109/MIM.2016.7384954
   Pouladzadeh P, 2015, LECT NOTES COMPUT SC, V9281, P441, DOI 10.1007/978-3-319-23222-5_54
   Pouladzadeh P, 2014, IEEE T INSTRUM MEAS, V63, P1947, DOI 10.1109/TIM.2014.2303533
   Pouladzadeh Parisa, 2016, P IEEE INT C INSTR M
   Shimoda W, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P13, DOI 10.1145/2986035.2986043
   Singla A, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P3, DOI 10.1145/2986035.2986039
   Su Z, 2016, IEEE T MULTIMEDIA, V18, P1650, DOI 10.1109/TMM.2016.2566584
   Ware C, 2008, IEEE COMPUT GRAPH, V28, P6, DOI 10.1109/MCG.2008.39
   WOLSEY LA, 1982, COMBINATORICA, V2, P385, DOI 10.1007/BF02579435
   Zeiler M. D., 2013, P INT C AC SPEECH SI
   Zhang Weiyu, 2015, J Diabetes Sci Technol, V9, P525, DOI 10.1177/1932296815582222
   Zhang XJ, 2016, J COMPUT SCI TECH-CH, V31, P489, DOI 10.1007/s11390-016-1642-6
   Zhu FQ, 2015, IEEE J BIOMED HEALTH, V19, P377, DOI 10.1109/JBHI.2014.2304925
NR 26
TC 41
Z9 44
U1 2
U2 29
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2017
VL 13
IS 3
SU S
AR 36
DI 10.1145/3063592
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FP1UO
UT WOS:000417400400004
DA 2024-07-18
ER

PT J
AU Zhang, J
   Wang, M
   Lin, L
   Yang, X
   Gao, J
   Rui, Y
AF Zhang, Jun
   Wang, Meng
   Lin, Liang
   Yang, Xun
   Gao, Jun
   Rui, Yong
TI Saliency Detection on Light Field: A Multi-Cue Approach
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Light field; multi-cue; saliency detection
ID INFORMATION; PREDICT
AB Saliency detection has recently received increasing research interest on using high-dimensional datasets beyond two-dimensional images. Despite the many available capturing devices and algorithms, there still exists a wide spectrum of challenges that need to be addressed to achieve accurate saliency detection. Inspired by the success of the light-field technique, in this article, we propose a new computational scheme to detect salient regions by integrating multiple visual cues from light-field images. First, saliency prior maps are generated from several light-field features based on superpixel-level intra-cue distinctiveness, such as color, depth, and flow inherited from different focal planes and multiple viewpoints. Then, we introduce the location prior to enhance the saliency maps. These maps will finally be merged into a single map using a random-search-based weighting strategy. Besides, we refine the object details by employing a two-stage saliency refinement to obtain the final saliency map.
   In addition, we present a more challenging benchmark dataset for light-field saliency analysis, named HFUT-Lytro, which consists of 255 light fields with a range from 53 to 64 images generated from each light-field image, therein spanning multiple occurrences of saliency detection challenges such as occlusions, cluttered background, and appearance changes. Experimental results show that our approach can achieve 0.6-6.7% relative improvements over state-of-the-art methods in terms of the F-measure and Precision metrics, which demonstrates the effectiveness of the proposed approach.
C1 [Zhang, Jun; Wang, Meng; Yang, Xun; Gao, Jun] Hefei Univ Technol, Sch Comp Sci & Informat Engn, 485 Danxia Rd, Hefei 230601, Anhui, Peoples R China.
   [Lin, Liang] Sun Yat Sen Univ, Sch Data & Comp Sci, Higher Educ Mega Ctr, East Campus, Guangzhou, Guangdong, Peoples R China.
   [Rui, Yong] Lenovo Grp Ltd, 6 Shang Di West Rd, Beijing 100085, Peoples R China.
C3 Hefei University of Technology; Sun Yat Sen University; Legend Holdings;
   Lenovo
RP Wang, M (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, 485 Danxia Rd, Hefei 230601, Anhui, Peoples R China.
EM zhangjun1126@gmail.com; eric.mengwang@gmail.com; linliang@ieee.org;
   hfutyangxun@gmail.com; gaojun@hfut.edu.cn; yongrui@lenovo.com
RI Lin, L/HKO-8213-2023; LU, LU/JEZ-4760-2023; Gao, Jun/KLC-1824-2024;
   zhang, cl/JDW-6549-2023; l, j/JVZ-8480-2024; L, J/JEF-9564-2023; l,
   j/HNC-5728-2023; Wang, Meng/ITR-8699-2023
OI M.Khalaf, Nourhan/0009-0006-9717-9239
FU Natural Science Foundation of China [61403116, 61432019]; China
   Postdoctoral Science Foundation [2014M560507]; Fundamental Research
   Funds for the Central Universities
FX This work is supported by the Natural Science Foundation of China
   (61403116 and 61432019), the China Postdoctoral Science Foundation
   (2014M560507), and the Fundamental Research Funds for the Central
   Universities.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   [Anonymous], 1991, COMPUTATIONAL MODELS
   [Anonymous], 2 STANF U COMP SCI
   [Anonymous], P INT SOC OPT PHOT C
   [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], IPSJ T COMPUT VISION
   [Anonymous], 2006, DIGITAL LIGHT FIELD
   [Anonymous], J VIS
   [Anonymous], IEEE TPAMI
   [Anonymous], 2009, INT C COMP PHOT
   [Anonymous], 2011, PASCAL VISUAL OBJECT
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2016, P 8 INT C QUALITY MU
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Bruce NDB, 2015, VISION RES, V116, P95, DOI 10.1016/j.visres.2015.01.010
   Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137
   Foulsham T, 2008, J VISION, V8, DOI 10.1167/8.2.6
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liang CK, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360654
   Liu Ce, 2009, THESIS
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu TY, 2011, LEARNING TO RANK FOR INFORMATION RETRIEVAL, P33, DOI 10.1007/978-3-642-14267-3_2
   Lu Y, 2012, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2012.6247785
   Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120
   Ma CY, 2015, J VISION, V15, DOI 10.1167/15.6.19
   Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914
   Mihara Hajime, 2016, P INT C COMPUTATIONA, P1
   Mousnier A., 2015, ARXIV150301903
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Raghavendra R, 2015, IEEE T IMAGE PROCESS, V24, P1060, DOI 10.1109/TIP.2015.2395951
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Ren JK, 2015, EUROMICRO, P25, DOI 10.1109/ECRTS.2015.10
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Schauerte B, 2013, IEEE IMAGE PROC, P74, DOI 10.1109/ICIP.2013.6738016
   Tao MW, 2015, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2015.7298804
   Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4
   Vaish V., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.244
   Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang JL, 2013, IEEE T IMAGE PROCESS, V22, P2151, DOI 10.1109/TIP.2013.2246176
   Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398
   Wanner S., 2013, INT S VIS MOD VIS, P225
   Wetzstein G, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185576
   Wetzstein G, 2011, COMPUT GRAPH FORUM, V30, P2397, DOI 10.1111/j.1467-8659.2011.02073.x
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Xu YC, 2015, IEEE I CONF COMP VIS, P3442, DOI 10.1109/ICCV.2015.393
   Xu YC, 2015, COMPUT VIS IMAGE UND, V139, P122, DOI 10.1016/j.cviu.2015.02.009
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2212
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhu GK, 2014, COMPUT VIS IMAGE UND, V118, P40, DOI 10.1016/j.cviu.2013.07.011
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 78
TC 61
Z9 67
U1 0
U2 25
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2017
VL 13
IS 3
AR 32
DI 10.1145/3107956
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FD5TE
UT WOS:000407591900010
DA 2024-07-18
ER

PT J
AU Sobhani, A
   Yassine, A
   Shirmohammadi, S
AF Sobhani, Ashkan
   Yassine, Abdulsalam
   Shirmohammadi, Shervin
TI A Video Bitrate Adaptation and Prediction Mechanism for HTTP Adaptive
   Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE HAS; Fuzzy-based controller; adaptation; video bitrate; ON-OFF traffic;
   prediction; grey model; adaptive moving average
AB The Hypertext Transfer Protocol (HTTP) Adaptive Streaming (HAS) has now become ubiquitous and accounts for a large amount of video delivery over the Internet. But since the Internet is prone to bandwidth variations, HAS's up and down switching between different video bitratesto keep up with bandwidth variations leads to a reduction in Quality of Experience (QoE). In this article, we propose a video bitrate adaptation and prediction mechanism based on Fuzzy logic for HAS players, which takes into consideration the estimate of available network bandwidth as well as the predicted buffer occupancy level in order to proactively and intelligently respond to current conditions. This leads to two contributions: First, it allows HAS players to take appropriate actions, sooner than existing methods, to prevent playback interruptions caused by buffer underrun, reducing the ON-OFF traffic phenomena associated with current approaches and increasing the QoE. Second, it facilitates fair sharing of bandwidth among competing players at the bottleneck link. We present the implementation of our proposed mechanism and provide both empirical/QoE analysis and performance comparison with existing work. Our results show that, compared to existing systems, our system has (1) better fairness among multiple competing players by almost 50% on average and as much as 80% as indicated by Jain's fairness index and (2) better perceived quality of video by almost 8% on average and as much as 17%, according to the estimate the Mean Opinion Score (eMOS) model.
C1 [Sobhani, Ashkan; Yassine, Abdulsalam; Shirmohammadi, Shervin] Univ Ottawa, Comp & Elect Engn Dept, Ottawa, ON, Canada.
C3 University of Ottawa
RP Sobhani, A (corresponding author), Univ Ottawa, Comp & Elect Engn Dept, Ottawa, ON, Canada.
EM asobh034@uottawa.ca; ayasine@uottawa.ca; shervin@discover.uottawa.ca
RI Shirmohammadi, Shervin/E-6945-2012; Abdulsalam, Yassine/ABA-9425-2020
OI Shirmohammadi, Shervin/0000-0002-3973-4445; Yassine,
   Abdulsalam/0000-0003-3539-0945
CR Akhshabi S, 2012, SIGNAL PROCESS-IMAGE, V27, P271, DOI 10.1016/j.image.2011.10.003
   Alberti C, 2013, INT WORK QUAL MULTIM, P58, DOI 10.1109/QoMEX.2013.6603211
   [Anonymous], 2014, P 5 ACM INT C MULT S
   [Anonymous], P WORKSH ADV CONC IN
   [Anonymous], 1984, Congestion control in IP/TCP internetworks
   [Anonymous], W11578 MPEG IJSW ISO
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], P 7 ACM INT C MULT S
   [Anonymous], P 2 ANN ACM C MULT S
   [Anonymous], 1995, Smarter Trading
   [Anonymous], P 35 ANN IEEE INT C
   [Anonymous], ARXIV150502056
   [Anonymous], ACM T MULTIM COMPUT
   [Anonymous], 2013, P AS PAC SIGN INF PR
   Begen AC, 2011, IEEE INTERNET COMPUT, V15, P54, DOI 10.1109/MIC.2010.155
   Bouten N, 2015, COMPUT NETW, V81, P96, DOI 10.1016/j.comnet.2015.02.007
   BROWN RG, 1957, OPER RES, V5, P145
   Chatfield C., 1978, Journal of the Royal Statistical Society: Series C (Applied Statistics), V27, P264, DOI 10.2307/2347162
   Chen C, 2014, IEEE T IMAGE PROCESS, V23, P2206, DOI 10.1109/TIP.2014.2312613
   Claeys M, 2014, IEEE COMMUN LETT, V18, P716, DOI 10.1109/LCOMM.2014.020414.132649
   Conover W, 1980, PRACTICAL NONPARAMET, P99
   Curcio I.D., 2010, Proc. ACM Workshop on Mobile Video (MoVid), P3
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   De Vriendt J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1288
   Houdaille R., 2012, P 3 MULTIMEDIA SYSTE, P1
   Huang TY, 2014, SIGCOMM'14: PROCEEDINGS OF THE 2014 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P187, DOI 10.1145/2619239.2626296
   Jain R., 1984, DEC TECHNICAL REPORT
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Joseph V, 2014, IEEE INFOCOM SER, P82, DOI 10.1109/INFOCOM.2014.6847927
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Juluri P, 2015, I C DES RELIABL COMM, P89, DOI 10.1109/DRCN.2015.7148992
   Kuschnig R., 2011, MMSYS, P245
   Le HT, 2013, PROC INT CONF ADV, P33, DOI 10.1109/ATC.2013.6698072
   Li BC, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2505805
   Li Z., 2014, Proceedings of the 5th ACM Multimedia Systems Conference, MMSys '14, P248
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Lir Y., 2013, P 20 INT PACKET VIDE, P1
   Liu SF, 2010, UNDERST COMPLEX SYST, P1
   Liu XW, 2007, MATH COMPUT MODEL, V45, P177, DOI 10.1016/j.mcm.2006.04.014
   MAMDANI EH, 1974, P I ELECTR ENG, V121, P1585, DOI 10.1049/piee.1974.0328
   Martin Virginia, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P293, DOI 10.1109/ICCE.2016.7430618
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Park J, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P222, DOI 10.1109/ICOIN.2015.7057886
   Pengcheng Xiong, 2012, 2012 IEEE International Conference on Mobile Services (MS 2012), P48, DOI 10.1109/MobServ.2012.10
   Petrangeli S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818361
   Rizzo L., 1997, Computer Communication Review, V27, P31, DOI 10.1145/251007.251012
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Sobhani A., 2015, P 25 ACM WORKSHOP NE, P31
   Tian G., 2012, P 8 INT C EM NETW EX, P109
   Toni Laura., 2014, Proceedings of_the_5th_ACM_Multimedia_Systems_Conference, P271
   Thang TC, 2014, IEEE J SEL AREA COMM, V32, P693, DOI 10.1109/JSAC.2014.140403
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Yao J, 2012, IEEE T MOBILE COMPUT, V11, P603, DOI 10.1109/TMC.2011.97
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   YOUNG IT, 1977, J HISTOCHEM CYTOCHEM, V25, P935, DOI 10.1177/25.7.894009
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
   Zambelli A., 2009, MICROSOFT CORPORATIO, V3, P40
   Zhou CF, 2015, ADV INTELL SYST, V355, P1, DOI [10.1109/VCIP.2015.7457843, 10.1007/978-3-319-17398-6_1]
NR 59
TC 17
Z9 18
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2017
VL 13
IS 2
AR 18
DI 10.1145/3052822
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EV1VK
UT WOS:000401537300006
DA 2024-07-18
ER

PT J
AU Gaj, S
   Kanetkar, A
   Sur, A
   Bora, PK
AF Gaj, Sibaji
   Kanetkar, Aditya
   Sur, Arijit
   Bora, Prabin Kumar
TI Drift-Compensated Robust Watermarking Algorithm for H.265/HEVC Video
   Stream
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Robustwatermarking; compressed domain watermarking; high efficiency
   video coding; H.265/HEVC; drift compensation
ID DATA HIDING ALGORITHM; HEVC
AB It has been observed in the recent literature that the drift error due to watermarking degrades the visual quality of the embedded video. The existing drift error handling strategies for recent video standards such as H.264 may not be directly applicable for upcoming high-definition video standards (such as High Efficiency Video Coding (HEVC)) due to different compression architecture. In this article, a compressed domain watermarking scheme is proposed for H.265/HEVC bit stream that can handle drift error propagation both for intra-and interprediction process. Additionally, the proposed scheme shows adequate robustness against recompression attack as well as common image processing attacks while maintaining decent visual quality. A comprehensive set of experiments has been carried out to justify the efficacy of the proposed scheme over the existing literature.
C1 [Gaj, Sibaji; Kanetkar, Aditya; Sur, Arijit] Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Multimedia Lab, Gauhati 781039, Assam, India.
   [Bora, Prabin Kumar] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Guwahati
RP Gaj, S (corresponding author), Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Multimedia Lab, Gauhati 781039, Assam, India.
EM sibaji@iitg.ernet.in; a.kanetkar@iitg.ernet.in; arijit@iitg.ernet.in;
   prabin@iitg.ernet.in
RI Sur, Arijit/AAB-4216-2020; Gaj, Sibaji/AAE-8920-2022
OI Gaj, Sibaji/0000-0002-6997-5717
CR Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Chen W, 2014, MULTIMEDIA SYST, V20, P179, DOI 10.1007/s00530-013-0329-x
   Gong XY, 2008, PROCEEDINGS OF THE ASME POWER CONFERENCE 2008, P649, DOI 10.1115/POWER2008-60085
   Huo WJ, 2011, IEEE SIGNAL PROC LET, V18, P535, DOI 10.1109/LSP.2011.2162061
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li L, 2015, J VIS COMMUN IMAGE R, V26, P1, DOI 10.1016/j.jvcir.2014.08.009
   Liu YX, 2012, PROCEEDINGS OF 2012 IEEE 14TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, P824, DOI 10.1109/ICCT.2012.6511318
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Saxena A, 2013, IEEE T IMAGE PROCESS, V22, P3974, DOI 10.1109/TIP.2013.2265882
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang LW, 2010, INT CONF ACOUST SPEE, P1758, DOI 10.1109/ICASSP.2010.5495443
NR 19
TC 21
Z9 23
U1 0
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2017
VL 13
IS 1
AR 11
DI 10.1145/3009910
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM7WJ
UT WOS:000395522700011
DA 2024-07-18
ER

PT J
AU Zhang, QC
   Zhong, H
   Yang, LT
   Chen, ZK
   Bu, FY
AF Zhang, Qingchen
   Zhong, Hua
   Yang, Laurence T.
   Chen, Zhikui
   Bu, Fanyu
TI PPHOCFS: Privacy Preserving High-Order CFS Algorithm on the Cloud for
   Clustering Multimedia Data
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Multimedia data; privacy preserving; CFS clustering algorithm; cloud
   computing; BGV encryption
ID HOMOMORPHIC ENCRYPTION; BIG
AB Clustering is a commonly used technique for multimedia data analysis and management. In this article, we propose a high-order clustering algorithm by fast search and find of density peaks (HOCFS) by extending the traditional clustering scheme by fast search and find of density peaks (CFS) algorithm from the vector space to the tensor space for multimedia data clustering. Furthermore, we propose a privacy preserving HOCFS algorithm (PPHOCFS) which improves the efficiency of the HOCFS algorithm by using the cloud computing to perform most of the clustering operations. To protect the private data in the multimedia data sets during the clustering process on the cloud, the raw data is encrypted by the Brakerski-Gentry-Vaikuntanathan (BGV) strategy before being uploaded to the cloud for performing the HOCFS clustering algorithm efficiently. In the proposed method, the client is required to only execute the encryption/decryption operations and the cloud servers are employed to perform all the computing operations. Finally, the performance of our scheme is evaluated on two representative multimedia data sets, namely NUS-WIDE and SNAE2, in terms of clustering accuracy, execution time, and speedup in the experiments. The results demonstrate that the proposed PPHOCFS scheme can save at least 40% running time compared with HOCFS, without disclosing the private data on the cloud, making our scheme securely suitable for multimedia big data clustering.
C1 [Zhang, Qingchen; Zhong, Hua; Chen, Zhikui; Bu, Fanyu] Dalian Univ Technol, Sch Software Technol, Dalian 116620, Liaoning, Peoples R China.
   [Yang, Laurence T.] St Francis Xavier Univ, Dept Comp Sci, Antigonish, NS B2G 2W5, Canada.
C3 Dalian University of Technology; Saint Francis Xavier University -
   Canada
RP Zhang, QC (corresponding author), Dalian Univ Technol, Sch Software Technol, Dalian 116620, Liaoning, Peoples R China.
EM 623759909@qq.com; cszhonghua@yeah.net; ltyang@gmail.com;
   zkchen@dlut.edu.cn; 737897793@qq.com
RI Laurence T. Yang, FCAE/AAA-1898-2019; zhong, hua/JRW-4786-2023
OI Laurence T. Yang, FCAE/0000-0002-7986-4244; 
FU National Science Foundation of China [U1301253]
FX This work is supported by the National Science Foundation of China,
   under grant U1301253.
CR Ahmed N, 2015, IET IMAGE PROCESS, V9, P1020, DOI 10.1049/iet-ipr.2014.0885
   [Anonymous], 2006, Proceedings of the 23rd international conference on Machine learning, DOI DOI 10.1145/1143844.1143918
   Bekkerman R, 2006, LECT NOTES COMPUT SC, V4212, P30
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Brakerski Z, 2012, LECT NOTES COMPUT SC, V7417, P868, DOI 10.1007/978-3-642-32009-5_50
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P4381, DOI 10.1109/TIP.2015.2463223
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Gao Bin, 2005, P 11 ACM SIGKDD INT
   Gentry C, 2013, LECT NOTES COMPUT SC, V8042, P75, DOI 10.1007/978-3-642-40041-4_5
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Gu QQ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P359
   Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483
   Han Xudong, 2011, Computer Engineering and Applications, V47, P176, DOI 10.3778/j.issn.1002-8331.2011.06.048
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Jiang T, 2009, IEEE T KNOWL DATA EN, V21, P161, DOI 10.1109/TKDE.2008.150
   Kuang LW, 2014, IEEE T EMERG TOP COM, V2, P280, DOI 10.1109/TETC.2014.2330516
   Liu Y, 2010, IEEE T NEURAL NETWOR, V21, P1848, DOI 10.1109/TNN.2010.2066574
   Meng L, 2014, IEEE T KNOWL DATA EN, V26, P2293, DOI 10.1109/TKDE.2013.47
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Smith J.R., 2013, P 36 INT ACM SIGIR C
   Song W, 2015, EXPERT SYST APPL, V42, P2517, DOI 10.1016/j.eswa.2014.11.003
   Sun K, 2015, IEEE GEOSCI REMOTE S, V12, P998, DOI 10.1109/LGRS.2014.2372071
   Wu XD, 2014, IEEE T KNOWL DATA EN, V26, P97, DOI 10.1109/TKDE.2013.109
   Xi W., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P130, DOI 10.1145/1076034.1076059
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Zfle Andreas, 2014, P 20 ACM SIGKDD INT
   Zhang QC, 2017, IEEE SYST J, V11, P2160, DOI 10.1109/JSYST.2015.2423499
   Zhang QC, 2016, IEEE T COMPUT, V65, P1351, DOI 10.1109/TC.2015.2470255
   Zhang QC, 2014, INT J COMMUN SYST, V27, P1378, DOI 10.1002/dac.2844
   Zhang Y, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700293
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
NR 34
TC 28
Z9 28
U1 0
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2016
VL 12
IS 4
SU S
AR 66
DI 10.1145/2886779
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI8DS
UT WOS:000392736100010
DA 2024-07-18
ER

PT J
AU Nilsson, T
   Hogsden, C
   Perera, C
   Aghaee, S
   Scruton, DJ
   Lund, A
   Blackwell, AF
AF Nilsson, Tommy
   Hogsden, Carl
   Perera, Charith
   Aghaee, Saeed
   Scruton, David J.
   Lund, Andreas
   Blackwell, Alan F.
TI Applying Seamful Design in Location-Based Mobile Museum Applications
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Human Factors; Experimentation; Human-computer interaction;
   museum studies; game design; smart-phone games; mobile games; location
   based gaming; seamful design; multimodal interaction; mobile
ID TECHNOLOGY
AB The application of mobile computing is currently altering patterns of our behavior to a greater degree than perhaps any other invention. In combination with the introduction of power-efficient wireless communication technologies, such as Bluetooth Low Energy (BLE), designers are today increasingly empowered to shape the way we interact with our physical surroundings and thus build entirely new experiences. However, our evaluations of BLE and its abilities to facilitate mobile location-based experiences in public environments revealed a number of potential problems. Most notably, the position and orientation of the user in combination with various environmental factors, such as crowds of people traversing the space, were found to cause major fluctuations of the received BLE signal strength. These issues are rendering a seamless functioning of any location-based application practically impossible. Instead of achieving seamlessness by eliminating these technical issues, we thus choose to advocate the use of a seamful approach, that is, to reveal and exploit these problems and turn them into a part of the actual experience. In order to demonstrate the viability of this approach, we designed, implemented, and evaluated the Ghost Detector-an educational location-based museum game for children. By presenting a qualitative evaluation of this game and by motivating our design decisions, this article provides insight into some of the challenges and possible solutions connected to the process of developing location-based BLE-enabled experiences for public cultural spaces.
C1 [Nilsson, Tommy] Univ Nottingham, Mixed Real Lab, Nottingham NG7 2RD, England.
   [Hogsden, Carl; Scruton, David J.] Univ Cambridge, Fitzwilliam Museum, Trumpington St, Cambridge CB2 1RB, England.
   [Perera, Charith] Open Univ, Dept Comp, Walton Hall, Milton Keynes MK7 6AA, Bucks, England.
   [Lund, Andreas] Umea Univ, Dept Informat, SE-90187 Umea, Sweden.
   [Aghaee, Saeed; Blackwell, Alan F.] William Gates Bldg,15 JJ Thomson Ave, Cambridge CB3 0F, England.
   [Nilsson, Tommy] Natl Inst Mental Health, Topolova 748, Klecany 25067, Czech Republic.
C3 University of Nottingham; University of Cambridge; Open University - UK;
   Umea University; National Institute of Mental Health - Czech Republic
RP Nilsson, T (corresponding author), Univ Nottingham, Mixed Real Lab, Nottingham NG7 2RD, England.; Nilsson, T (corresponding author), Natl Inst Mental Health, Topolova 748, Klecany 25067, Czech Republic.
EM psxtn2@nottingham.ac.uk; carl@hogsden.org; charith.perera@ieee.org;
   saeed.aghaee@cl.cam.ac.uk; djs94@cam.ac.uk; alund@informatik.umu.se;
   afb21@cam.ac.uk
OI Nilsson, Tommy/0000-0002-8568-0062
FU Arts Council England; Engineering and Physical Sciences Research Council
   [EP/N014243/1]; Swiss National Science Foundation [P2TIP2 152264]; CECS
   Deans Travel Grant; International Alliance of Research Universities
   (IARU) Travel Grant; ANU VC Travel Grant; Swiss National Science
   Foundation (SNF) [P2TIP2_152264] Funding Source: Swiss National Science
   Foundation (SNF); EPSRC [EP/N014243/1] Funding Source: UKRI
FX This project was supported using public funding by Arts Council England.
   Tommy Nilsson's work was supported by the Engineering and Physical
   Sciences Research Council (project EP/N014243/1). Dr. Saeed Aghaee's
   work was supported by a Swiss National Science Foundation Early Postdoc
   Mobility fellowship (P2TIP2 152264). Dr. Charith Perera's work was
   supported by a CECS Deans Travel Grant, International Alliance of
   Research Universities (IARU) Travel Grant, and ANU VC Travel Grant.
CR AlexWest, 2013, SMARTPH KEY BLUET LO
   [Anonymous], P 8 ANN C INN TECHN
   [Anonymous], 2008, Measuring the User Experience Collecting, Analyzing, and Presenting Usability Metrics
   [Anonymous], P 4 INT C COLL VIRT
   [Anonymous], INTERACTIVE LEARNING
   Apple-Insider, 2013, APPLE INSIDER    DEC
   Arnaudov Stanimir, 2008, AUGMENTED REALITY MU
   Benford S., 2006, ACM Transactions on Computer-Human Interaction, V13, P100, DOI 10.1145/1143518.1143522
   Broll Gregor, 2005, P 4 INT C ENT COMP
   Busching Felix, 2012, 32 INT C DISTR COMP
   Chalmers Matthew, 2003, P EL I ENG EUR
   Creswell J. W., 2016, Qualitative Inquiry & Research Design Choosing Among Five Aproaches, DOI DOI 10.1089/TMJ.2009.0067
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Faragher R., 2014, P 27 INT TECHN M SAT
   Faragher RM, 2015, NAVIGATION-US, V62, P55, DOI 10.1002/navi.76
   Gaver William, 1992, P C HUM FACT COMP SY
   Golding Paul, 2011, CONNECTED SERVICES G
   Gomez C, 2012, SENSORS-BASEL, V12, P11734, DOI 10.3390/s120911734
   Gonzalez Gustavo Ramirez, 2008, ADV LEARNING TECHNOL
   Jacobs Rachel, 2015, P 33 ANN ACM C HUM F
   Jones V., 2004, COMFORT ZONE
   Kamath S., 2012, ARCH TOXICOL, P1
   Liu H, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2491735
   McLuhan Marshall, 1994, Laws of Media: The New Science
   Oulasvirta Antii, 2004, TELIASONERA HAN SEAM
   Riha Daniel, 2012, DEV VISUAL LITERACY
   Rosati Eleonora, 2013, MOBILE COLLECTIONS, V2013
   She J, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2557450
   Sterling G., 2014, MAGNETIC POSITIONING
   Styles Kirsty, 2013, 7 10 PEOPL UK NOW OW
   Vazquez M., 2014, P 2014 ACM IEEE INT
   Wein Leonard, 2014, P SIGCHI C HUM FACT
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Weiser Mark., 1993, ACM Interactions Magazine, V1, P7
   Yamazaki Keiichi, 2009, P SIGCHI C HUM FACT
   Yin YF, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700287
NR 36
TC 13
Z9 17
U1 3
U2 31
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2016
VL 12
IS 4
AR 56
DI 10.1145/2962720
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DV4EH
UT WOS:000382877500010
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Thomee, B
   Arapakis, I
   Shamma, DA
AF Thomee, Bart
   Arapakis, Ioannis
   Shamma, David A.
TI Finding Social Points of Interest from Georeferenced and Oriented Online
   Photographs
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Algorithms; Performance; Measurement; Points of interest;
   location estimation; georeferenced photos; oriented photos; line of
   sight; field of view; GPS; compass; sensor accuracy; photo composition
ID WORLD; COLLECTIONS; RECOGNITION; PLACE
AB Points of interest are an important requirement for location-based services, yet they are editorially curated and maintained, either professionally or through community. Beyond the laborious manual annotation task, further complications arise as points of interest may appear, relocate, or disappear over time, and may be relevant only to specific communities. To assist, complement, or even replace manual annotation, we propose a novel method for the automatic localization of points of interest depicted in photos taken by people across the world. Our technique exploits the geographic coordinates and the compass direction supplied by modern cameras, while accounting for possible measurement errors due to the variability in accuracy of the sensors that produced them. We statistically demonstrate that our method significantly outperforms techniques from the research literature on the task of estimating the geographic coordinates and geographic footprints of points of interest in various cities, even when photos are involved in the estimation process that do not show the point of interest at all.
C1 [Thomee, Bart; Shamma, David A.] Yahoo Labs, 110 5th St, San Francisco, CA 94103 USA.
   [Arapakis, Ioannis] Yahoo Labs, Avinguda Diagonal 177, Barcelona 08018, Spain.
C3 Yahoo! Inc; Yahoo! Inc United States; Yahoo! Inc; Yahoo! Inc Spain
RP Thomee, B (corresponding author), Yahoo Labs, 110 5th St, San Francisco, CA 94103 USA.
OI Shamma, David/0000-0003-2399-9374
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Ahern S, 2007, ACM-IEEE J CONF DIG, P1, DOI 10.1145/1255175.1255177
   [Anonymous], P ACM INT C GEOGR IN
   [Anonymous], P IEEE INT C 3D VIS
   [Anonymous], 2005, CROSS ENTROPY METHOD
   [Anonymous], P ACM INT C ADV GEOG
   [Anonymous], P ACM WORKSH GEOGR I
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], 2000, Icml, DOI DOI 10.1007/3-540-44491-2_3
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI DOI 10.1145/2502081.2502151
   [Anonymous], P INT C 3D VIS
   [Anonymous], P ACM INT C MULT
   [Anonymous], REMARKS RURAL SCENAR
   [Anonymous], TECHNICAL REPORT
   [Anonymous], WORKING NOTES MEDIAE
   [Anonymous], 2000, P IASTED INT C ROB A
   [Anonymous], 2012, ACM T GRAPHIC, DOI DOI 10.1145/2185520.2185597
   [Anonymous], P ACM INT WORKSH GEO
   [Anonymous], 2010, P INT C EXH COMP GEO
   Cham TJ, 2010, PROC CVPR IEEE, P366, DOI 10.1109/CVPR.2010.5540191
   Chang F, 2004, COMPUT VIS IMAGE UND, V93, P206, DOI 10.1016/j.cviu.2003.09.002
   Chen L., 2009, Proceedings of the 18th ACM conference on Information and knowledge management, P523
   Crandall DJ, 2013, IEEE T PATTERN ANAL, V35, P2841, DOI 10.1109/TPAMI.2012.218
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   De Choudhury M., 2010, Proceedings of the 21st ACM Conference on Hypertext and Hypermedia-HT'10, P35, DOI DOI 10.1145/1810617.1810626
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dwork C., 2001, P 10 INT C WORLD WID, P613, DOI [10.1145/371920.372165, DOI 10.1145/371920.372165]
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Field George., 1845, CHROMATICS ANALOGY H
   Hao J, 2014, IEEE T MULTIMEDIA, V16, P1929, DOI 10.1109/TMM.2014.2330802
   Hays J, 2008, PROC CVPR IEEE, P3436
   Heinly J, 2015, PROC CVPR IEEE, P3287, DOI 10.1109/CVPR.2015.7298949
   Hölzl M, 2013, LECT NOTES COMPUT SC, V8112, P381, DOI 10.1007/978-3-642-53862-9_49
   Hollenstein L, 2010, J SPAT INT SCI, P21, DOI 10.5311/JOSIS.2010.1.3
   Jaffe A., 2006, MULTIMEDIA INFORM RE, P89
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaminsky Ryan S., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P63, DOI 10.1109/CVPR.2009.5204180
   Karney CFF, 2013, J GEODESY, V87, P43, DOI 10.1007/s00190-012-0578-z
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kosecká J, 2002, LECT NOTES COMPUT SC, V2353, P476
   Lacerda Y.A., 2012, Proceedings_of_the_18th_Brazilian_Symposium on_Multimedia_and_the_Web, WebMedia'12, P281
   Li YP, 2009, IEEE I CONF COMP VIS, P1957, DOI 10.1109/ICCV.2009.5459432
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Luo ZP, 2010, LECT NOTES COMPUT SC, V5916, P695
   Mummidi LN, 2008, GEOJOURNAL, V72, P215, DOI 10.1007/s10708-008-9181-5
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   Paek J., 2010, Proceedings of the 8th international conference on Mobile systems, applications, and services, P299
   Papadopoulos S, 2011, IEEE MULTIMEDIA, V18, P52, DOI 10.1109/MMUL.2010.68
   Pihur V, 2007, BIOINFORMATICS, V23, P1607, DOI 10.1093/bioinformatics/btm158
   Popescu A., 2009, ACM International Conference on Information and Knowledge Management, P1713, DOI DOI 10.1145/1645953.1646211
   Quack Till., 2008, P 2008 INT C CONTENT, P47
   Rae A, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P711, DOI 10.1145/2348283.2348379
   Raguram R, 2011, INT J COMPUT VISION, V95, P213, DOI 10.1007/s11263-011-0445-z
   Rattenbury Tye, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P103, DOI 10.1145/1277741.1277762
   Rattenbury T, 2009, ACM T WEB, V3, DOI 10.1145/1462148.1462149
   Serdyukov P, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P484, DOI 10.1145/1571941.1572025
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   STEPHENS MA, 1974, J AM STAT ASSOC, V69, P730, DOI 10.2307/2286009
   Thode H. C., 2002, Testing for Normality, DOI 10.1201/9780203910894
   Yang YY, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P883
   Zandbergen P. A., 2008, Transactions in GIS, V12, P103, DOI 10.1111/j.1467-9671.2008.01088.x
   Zandbergen PA, 2011, J NAVIGATION, V64, P381, DOI 10.1017/S0373463311000051
   Zheng YT, 2011, MULTIMED TOOLS APPL, V51, P77, DOI 10.1007/s11042-010-0630-z
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 66
TC 8
Z9 8
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAR
PY 2016
VL 12
IS 2
AR 36
DI 10.1145/2854004
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ0PK
UT WOS:000373906200010
DA 2024-07-18
ER

PT J
AU Calagari, K
   Pakravan, MR
   Shirmohammadi, S
   Hefeeda, M
AF Calagari, Kiana
   Pakravan, Mohammad Reza
   Shirmohammadi, Shervin
   Hefeeda, Mohamed
TI ALP: Adaptive Loss Protection Scheme with Constant Overhead for
   Interactive Video Applications
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Performance; Measurement; Adaptive video protection; interactive video;
   ROI; HD video; H.264/AVC; data partitioning; error propagation; slicing;
   FMO; FEC; ULP
ID FACE DETECTION; REGION; TRANSMISSION; H.264/AVC; INTERNET
AB There has been an increasing demand for interactive video transmission over the Internet for applications such as video conferencing, video calls, and telepresence applications. These applications are increasingly moving towards providing High Definition (HD) video quality to users. A key challenge in these applications is to preserve the quality of video when it is transported over best-effort networks that do not guarantee lossless transport of video packets. In such conditions, it is important to protect the transmitted video by using intelligent and adaptive protection schemes. Applications such as HD video conferencing require live interaction among participants, which limits the overall delay the system can tolerate. Therefore, the protection scheme should add little or no extra delay to video transport. We propose a novel Adaptive Loss Protection (ALP) scheme for interactive HD video applications such as video conferencing and video chats. This scheme adds negligible delay to the transmission process and is shown to achieve better quality than other schemes in lossy networks. The proposed ALP scheme adaptively applies four different protection modes to cope with the dynamic network conditions, which results in high video quality in all network conditions. Our ALP scheme consists of four protection modes; each of these modes utilizes a protection method. Two of the modes rely on the state-of-the-art protection methods, and we propose a new Integrated Loss Protection (ILP) method for the other two modes. In the ILP method we integrate three factors for distributing the protection among packets. These three factors are error propagation, region of interest and header information. In order to decide when to switch between the protection modes, a new metric is proposed based on the effectiveness of each mode in performing protection, rather than just considering network statistics such as packet loss rate. Results show that by using this metric not only the overall quality will be improved but also the variance of quality will decrease. One of the main advantages of the proposed ALP scheme is that it does not increase the bit rate overhead in poor network conditions. Our results show a significant gain in video quality, up to 3dB PSNR improvement is achieved using our scheme, compared to protecting all packets equally with the same amount of overhead.
C1 [Calagari, Kiana] Sharif Univ Technol, Tehran, Iran.
   [Pakravan, Mohammad Reza] Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Shirmohammadi, Shervin] Univ Tehran, Sch Elect & Comp Engn, Coll Engn, Multimedia Proc Lab, Tehran 14174, Iran.
   [Hefeeda, Mohamed] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
C3 Sharif University of Technology; Sharif University of Technology;
   University of Tehran; Simon Fraser University
RP Calagari, K (corresponding author), Sharif Univ Technol, Tehran, Iran.
EM kcalagar@sfu.ca; pakravan@sharif.edu; sshirmohammadi@ut.ac.ir;
   mhefeeda@cs.sfu.ca
RI Pakravan, Mohammadreza/E-4489-2010; Shirmohammadi, Shervin/E-6945-2012
OI Pakravan, Mohammadreza/0000-0002-3899-8211; Shirmohammadi,
   Shervin/0000-0002-3973-4445
CR Albanese A, 1996, IEEE T INFORM THEORY, V42, P1737, DOI 10.1109/18.556670
   [Anonymous], 2011, IEEE INT C MULT EXP
   [Anonymous], P PACK VID 2007
   [Anonymous], 2010, SURVEY RECENT ADV FA
   Arachchi H. K., 2006, P IEEE CAN C EL COMP, P2033
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Calagari Kiana, 2012, P 20 ACM INT C MULT, P1033
   CAO DT, 2013, P 5 INT C UB FUT NET, P570
   Chen Q, 2007, IEEE WRK SIG PRO SYS, P357, DOI 10.1109/SIPS.2007.4387572
   Ciubotaru B, 2009, IEEE T BROADCAST, V55, P202, DOI 10.1109/TBC.2009.2020448
   Dhondt Y, 2006, IEEE IMAGE PROC, P829, DOI 10.1109/ICIP.2006.312530
   ELLIOTT EO, 1963, AT&T TECH J, V42, P1977, DOI 10.1002/j.1538-7305.1963.tb00955.x
   Fernandez Ivan Alen, 2012, Journal of Communications, V7, P265, DOI 10.4304/jcm.7.4.265-280
   GILBERT EN, 1960, BELL SYST TECH J, V39, P1253, DOI 10.1002/j.1538-7305.1960.tb03959.x
   Girod B, 1998, P SOC PHOTO-OPT INS, V3653, P833, DOI 10.1117/12.334735
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Huang TH, 2009, PROC CVPR IEEE, P296, DOI 10.1109/CVPRW.2009.5206765
   Kazemi M, 2014, MULTIMEDIA SYST, V20, P283, DOI 10.1007/s00530-013-0319-z
   Lee PJ, 2009, IEEE T CONSUM ELECTR, V55, P158, DOI 10.1109/TCE.2009.4814429
   Lou Y H, 2013, P 5 WORKSH MOB VID M, P31
   Muntean GM, 2008, IEEE T BROADCAST, V54, P296, DOI 10.1109/TBC.2008.919012
   Nafaa A, 2008, IEEE COMMUN MAG, V46, P72, DOI 10.1109/MCOM.2008.4427233
   Osberger W, 1998, INT C PATT RECOG, P701, DOI 10.1109/ICPR.1998.711240
   Porter T.H., 2011, The power of transformational leadership: The effect on selfefficacy, spirituality, P1
   Sanson Horacio, 2010, 2010 12th International Conference on Advanced Communication Technology (ICACT 2010), P59
   Song W., 2010, P INT C MULTIMEDIA M, P321, DOI DOI 10.1145/1873951.1873996
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Su H, 2009, INT J DIGIT MULTIMED, V2009, DOI 10.1155/2009/141986
   Thomos N, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P593, DOI 10.1109/ICME.2006.262478
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2011, IEEE INT CONF NETWOR, P41, DOI 10.1109/ICON.2011.6168504
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu DP, 2000, P IEEE, V88, P1855, DOI 10.1109/5.899055
   Xiaolong Wang, 2010, 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P175, DOI 10.1109/ICCMS.2010.408
   Xingjun Zhang, 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P2471, DOI 10.1109/CIT.2010.423
   Yanchun Zhong, 2010, 2010 Fifth International Conference on Digital Information Management (ICDIM 2010), P145, DOI 10.1109/ICDIM.2010.5664732
   Yi-Fei Xu, 2013, International Journal of Future Computer and Communication, V2, P292, DOI 10.7763/IJFCC.2013.V2.170
   Zhang PY, 2009, IEEE WCNC, P1, DOI 10.1109/PLASMA.2009.5227420
   ZHANG XJ, 2009, P 23 INT C INF NETW, P195
NR 42
TC 1
Z9 1
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2014
VL 11
IS 2
AR 25
DI 10.1145/2656203
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ6DM
UT WOS:000348308800002
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Cui, P
   Xie, LX
   Zhu, WW
   Rui, Y
   Yang, SQ
AF Wang, Zhiyu
   Cui, Peng
   Xie, Lexing
   Zhu, Wenwu
   Rui, Yong
   Yang, Shiqiang
TI Bilateral Correspondence Model for Words-and-Pictures Association in
   Multimedia-Rich Microblogs
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Experimentation; Social media; topic models; image analysis
AB Nowadays, the amount of multimedia contents in microblogs is growing significantly. More than 20% of microblogs link to a picture or video in certain large systems. The rich semantics in microblogs provides an opportunity to endow images with higher-level semantics beyond object labels. However, this raises new challenges for understanding the association between multimodal multimedia contents in multimedia-rich microblogs. Disobeying the fundamental assumptions of traditional annotation, tagging, and retrieval systems, pictures and words in multimedia-rich microblogs are loosely associated and a correspondence between pictures and words cannot be established. To address the aforementioned challenges, we present the first study analyzing and modeling the associations between multimodal contents in microblog streams, aiming to discover multimodal topics from microblogs by establishing correspondences between pictures and words in microblogs. We first use a data-driven approach to analyze the new characteristics of the words, pictures, and their association types in microblogs. We then propose a novel generative model called the Bilateral Correspondence Latent Dirichlet Allocation (BC-LDA) model. Our BC-LDA model can assign flexible associations between pictures and words and is able to not only allow picture-word co-occurrence with bilateral directions, but also single modal association. This flexible association can best fit the data distribution, so that the model can discover various types of joint topics and generate pictures and words with the topics accordingly. We evaluate this model extensively on a large-scale real multimedia-rich microblogs dataset. We demonstrate the advantages of the proposed model in several application scenarios, including image tagging, text illustration, and topic discovery. The experimental results demonstrate that our proposed model can significantly and consistently outperform traditional approaches.
C1 [Wang, Zhiyu; Cui, Peng; Zhu, Wenwu; Yang, Shiqiang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Xie, Lexing] Australian Natl Univ, Canberra, ACT 0200, Australia.
   [Rui, Yong] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Tsinghua University; Australian National University; Microsoft;
   Microsoft Research Asia
RP Wang, ZY (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, FIT 1-304, Beijing 100084, Peoples R China.
EM zy.wang08@gmail.com
RI yang, shiqiang/AAH-5484-2019
OI Xie, Lexing/0000-0001-8319-0118
FU National Natural Science Foundation of China [61370022, 61003097,
   60933013, 61210008]; International Science and Technology Cooperation
   Program of China [2013DFG12870]; National Program on Key Basic Research
   Project [2011CB302206]; National "1000 People Plan" starting grant; MDA,
   Singapore [WBS:R-252-300-001-490]
FX This work is supported by National Natural Science Foundation of China,
   no. 61370022, no. 61003097, no. 60933013, and no. 61210008, the
   International Science and Technology Cooperation Program of China, no.
   2013DFG12870, the National Program on Key Basic Research Project, no.
   2011CB302206, and National "1000 People Plan" starting grant. The
   authors also thank NExT Research Center funded by MDA, Singapore, under
   Research Grant WBS:R-252-300-001-490.
CR [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], 2011, P ACM 2011 C COMP SU, DOI DOI 10.1145/1958824.1958830
   [Anonymous], 2011, PASCAL VISUAL OBJECT
   [Anonymous], P NIPS
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   CASELLA G, 1992, AM STAT, V46, P167, DOI 10.2307/2685208
   Chen T., 2013, P 21 ACM INT C MULT, P781, DOI [DOI 10.1145/2502081.2502203, 10.1145/2502081, DOI 10.1145/2502081]
   Chen X., 2010, CIKM, P899
   Chen X., 2011, P 20 ACM INT C INF K, P1341
   Chua Tat-Seng, 2009, CIVR
   Cui B, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P619
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fagin R, 2003, SIAM PROC S, P28
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jiang Meng, 2012, P 21 ACM INT C INFOR, P45
   Joshi D, 2006, ACM T MULTIM COMPUT, V2, P68, DOI 10.1145/1126004.1126008
   Li LJ, 2010, PROC CVPR IEEE, P3336, DOI 10.1109/CVPR.2010.5540027
   Liu SW, 2014, COMPUT VIS IMAGE UND, V118, P30, DOI 10.1016/j.cviu.2013.06.011
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Miller R., 2010, TWITTER UNVEILS NEW
   Moosmann F, 2007, Adv Neural Inf Process Syst, P985
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Noh TG, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P492, DOI 10.1145/1571941.1572026
   Ou MD, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P230
   Qi G., 2011, Proc. ACM International Conference on World Wide Web, P297
   Qi Z., 2012, P 20 ACM INT C MULT, P479
   Ramage D., 2010, P AAAI INT C WEBL SO
   San Pedro Jose., 2012, WWW, P439
   Shi M., 2012, P 20 ACM INT C MULT, P69
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sproat Richard, 2003, P 2 SIGHAN WORKSH CH, P133
   Van Zwol R., 2012, P 5 ACM INT C WEB SE, P3
   Wang Z., 2012, Proceedings of the 20th ACM International Conference on Multimedia, MM '12, P1359
   Wu Pengcheng., 2011, Proceedings of the Fourth 140 ACM International Conference on Web Search and Data Mining, WSDM, P197, DOI DOI 10.1145/1935826.1935865
   Yang Y., 2013, P 21 ACM INT C MULT, P785, DOI DOI 10.1145/2502081.2502204
NR 39
TC 7
Z9 8
U1 0
U2 22
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2014
VL 10
IS 4
AR 34
DI 10.1145/2611388
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AO4FY
UT WOS:000341292900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chandra, S
   Boreczky, J
   Rowe, LA
AF Chandra, Surendar
   Boreczky, John
   Rowe, Lawrence A.
TI High Performance Many-to-Many Intranet Screen Sharing with DisplayCast
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Experimentation; Measurement; Performance; Screencast; screen capture;
   screen sharing
AB DisplayCast is a many to many Intranet screen sharing system. Its screen capture mechanism creates a sequence of pixmap images of the screen updates. Prior systems that used a similar approach were designed to operate over constrained wide-area networks and did not exploit the Intranet network conditions to achieve high capture rates. First we empirically analyzed the screen contents for a variety of scenarios. We showed that screen updates were sporadic with long periods of inactivity. When active, screens were updated at far higher rates than was supported by earlier systems. The mismatch was pronounced for interactive scenarios. Even during active screen updates, the number of updated pixels were frequently small. We showed that crucial information can be lost if individual updates were merged. When the available system resources could not support high capture rates, we showed ways in which updates can be effectively collapsed. Next, we investigate compression mechanisms for streaming these updates. Even while using a hardware encoder, lossy compressors such as H. 264 were unable to sustain high frame rates. Though Zlib lossless compression operated within the latency and compression rate requirements, the compression efficiency was poor. By analyzing the screen pixels, we developed a practical transformation that significantly improved compression rates. DisplayCast incorporates these observations. It shares the processor and network resources required for screen capture, compression and transmission with host applications whose output needs to be shared. DisplayCast is agile and uses faster processing capability to achieve even higher performance. Our system components operate natively in Windows 7, Mac OS X and iOS and is deployed in a production setting. DisplayCast is released under a New BSD License.
C1 [Chandra, Surendar; Boreczky, John; Rowe, Lawrence A.] FX Palo Alto Lab Inc, Palo Alto, CA 94304 USA.
RP Chandra, S (corresponding author), 3174 Porter Dr, Palo Alto, CA 94304 USA.
EM surendar@acm.org; johnb@fxpal.com; rowe@fxpal.com
CR [Anonymous], 1951 RFC
   Apple, OS X MOUNT LION
   Boyaci O, 2008, IEEE INT SYM MULTIM, P432, DOI 10.1109/ISM.2008.97
   Chandra Surendar, 2012, P ACM IFIP USENIX 12, DOI DOI 10.1145/2405146.2405150
   Connected Intelligence, 2013, ACM T MULTIMEDIA COM, V10
   DemoForge, DEMOFORGE MIR DRIV D
   Estes Charles D., 2012, P MULT SYST C MMSYS, P119, DOI DOI 10.1145/2155555.2155577
   FIELDING R, 2000, THESIS UC IRVINE
   Hilbert David M., 2008, PLENUM PRAVLENIYA RO
   Humphreys G, 2001, COMP GRAPH, P129, DOI 10.1145/383259.383272
   Intel, INT QUICK SYNC VID
   Intel laptop, LAPT TV INT R WIR DI
   ITU, 2013, H 264 ADV VID COD GE
   *ITU, 1992, DIG COMPR COD CONT T
   Kim Hwanju, 2012, P MULT SYST C MMSYS, P5, DOI DOI 10.1145/2155555.2155566
   loup Gailly J., zlib: A Massively Spiffy Yet Delicately Unobtrusive Compression Library
   Microsoft Remote, REM DESKT CONN
   Richardson T, 1998, IEEE INTERNET COMPUT, V2, P33, DOI 10.1109/4236.656066
   Richardson T., 2011, 6143 RFC
   Samsung, 2012, ALLSH INSTANTPLAY
   Schmidt BK, 1999, OPERATING SYSTEMS REVIEW, VOL 33, NO 5, DECEMBER 1999, P32, DOI 10.1145/319344.319154
   Sun Y, 2008, J PARALLEL DISTR COM, V68, P1463, DOI 10.1016/j.jpdc.2008.05.007
   Uchino Satoshi, METAVNC WINDOW AWARE
   von Hoffman Jennifer Teig, 2001, GUIDE DISTRIBUTED PO
   Wallace G, 2007, USENIX ASSOCIATION PROCEEDINGS OF THE 2007 USENIX ANNUAL TECHNICAL CONFERENCE, P375
   WHDI, WIR HOM DIG INT
   Windows Mirror, WIND MIRR DRIV
   Yun HC, 1997, ACM T GRAPHIC, V16, P359, DOI 10.1145/263834.263835
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 29
TC 7
Z9 7
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD FEB
PY 2014
VL 10
IS 2
AR 19
DI 10.1145/2534328
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB6DY
UT WOS:000331879000004
DA 2024-07-18
ER

PT J
AU Huang, CY
   Chen, KT
   Chen, DY
   Hsu, HJ
   Hsu, CH
AF Huang, Chun-Ying
   Chen, Kuan-Ta
   Chen, De-Yu
   Hsu, Hwai-Jung
   Hsu, Cheng-Hsin
TI GamingAnywhere: The First Open Source Cloud Gaming System
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Measurement; Cloud games; remote rendering; live video
   streaming; real-time encoding; performance evaluation; performance
   optimization
ID PERFORMANCE
AB We present the first open source cloud gaming system, called GamingAnywhere. In addition to its openness, we have designed, GamingAnywhere for high extensibility, portability, and reconfigurability. We implemented it on Windows, Linux, OS X, and Android. We conducted extensive experiments to evaluate its performance. Our experimental results indicate that GamingAnywhere is efficient, scalable, adaptable to network conditions, and achieves high responsiveness and streaming quality. GamingAnywhere can be employed by researchers, game developers, service providers, and end users for setting up cloud gaming testbeds, which we believe, will stimulate more research into innovations for cloud gaming systems and applications.
C1 [Huang, Chun-Ying] Natl Taiwan Ocean Univ, Chilung, Taiwan.
   [Chen, Kuan-Ta; Chen, De-Yu; Hsu, Hwai-Jung] Acad Sinica, Taipei, Taiwan.
   [Hsu, Cheng-Hsin] Natl Tsing Hua Univ, Hsinchu, Taiwan.
C3 National Taiwan Ocean University; Academia Sinica - Taiwan; National
   Tsing Hua University
RP Huang, CY (corresponding author), 2 Pei Ning Rd, Chilung 20224, Taiwan.
EM chuang@ntou.edu.tw; swc@iis.sinica.edu.tw; r96922083@ntu.edu.tw;
   hjhsu@iis.sinica.edu.tw; chsu@cs.nthu.edu.tw
OI Huang, Chun-Ying/0000-0001-5503-9541
FU National Science Council of Taiwan [NSC100-2628-E-001-002-MY3,
   NSC102-2219-E-019-001, NSC102-2221-E-007-062-MY3]
FX This work was supported in part by the National Science Council of
   Taiwan under grants NSC100-2628-E-001-002-MY3, NSC102-2219-E-019-001,
   and NSC102-2221-E-007-062-MY3.
CR [Anonymous], P IEEE ACM NETGAMES
   [Anonymous], 2000, Dissertation
   Chang Yu-Chun, 2011, P IEEE CQR
   Chen KT, 2009, IEEE T PARALL DISTR, V20, P593, DOI 10.1109/TPDS.2008.148
   Chen Kuan-Ta, 2011, P ACM MULT
   Chen Y., 2010, P ACM SIGGRAPH S INT
   Choy Sharon, 2012, P IEEE ACM NETGAMES
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Costello Roger L., 2007, BUILDING WEB SERVICE
   Desnoyers Mathieu, 2013, LINUX TRACE TOOLKIT
   EA, 2012, EL ARTS BUYS ONL GAM
   Eisert P, 2008, IEEE IMAGE PROC, P2704, DOI 10.1109/ICIP.2008.4712352
   Giesen F., 2008, P INT FALL WORKSH VI
   Henderson T., 2003, THESIS U LONDON
   Holthe O., 2009, P IEEE CONS COMM NET
   Huang Chun-Ying, 2013, P ACM MMSYS
   Jurgelionis A, 2009, INT J COMPUT GAMES T, V2009, DOI 10.1155/2009/231863
   Lai AM, 2006, ACM T COMPUT SYST, V24, P175, DOI 10.1145/1132026.1132029
   Levon John, 2013, OPROFILE SYSTEM PROF
   Live Networks, 2013, LIVE555 STREAM MED
   Microsoft, 2012, FLIPP SURF DIRECT3D
   Nieh J, 2003, ACM T COMPUT SYST, V21, P87, DOI 10.1145/592637.592640
   Packard K., 2003, P USENIX ANN TECHN C, P206
   Sam Lantinga, 2013, SIMPLE DIRECTMEDIA L
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Schulzrinne H., 1998, 2326 RFC
   Shi Shu., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P103, DOI [10.1145/2072298.2072313, DOI 10.1145/2072298.2072313]
   Sony, 2012, CLOUD GAM AD IS ACC
   Tanenbaum A.S., 2002, COMPUT NETW, VFourth
   Tolia N, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.101
   van Oortmerssen Wouter, 2013, CUB 2 SAUERBR
   Wang Y., 2001, VIDEO PROCESSING COM
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Winter D., 2006, P ACM NOSSDAV
   Wong AYI, 1999, PROCEEDINGS OF THE 3RD USENIX WINDOWS NT SYMPOSIUM, P145
   Zander S., 2005, P 2005 ACM SIGCHI IN, P117, DOI DOI 10.1145/1178477.1178493
NR 36
TC 87
Z9 95
U1 0
U2 24
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JAN
PY 2014
VL 10
IS 1
SU S
SI SI
AR 10
DI 10.1145/2537855
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AA2EF
UT WOS:000330907200002
DA 2024-07-18
ER

PT J
AU Hua, KA
AF Hua, Kien A.
TI Online Video Delivery: Past, Present, and Future
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Video streaming; video on demand; caching
AB Video streaming is the core technology for online video delivery systems. Initial research on this technology faced many challenges. In this article, lessons learned from beginning trials are discussed; some pioneering works that provided early solutions and inspired subsequent research are presented; and new techniques required for emerging applications are examined.
C1 Univ Cent Florida, Div Comp Sci, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Hua, KA (corresponding author), Univ Cent Florida, Div Comp Sci, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.
EM kienhua@eecs.ucf.edu
CR BLANK C., 1995, IEEE COMPUT, V28, P9
   Ho AH, 2011, C LOCAL COMPUT NETW, P537, DOI 10.1109/LCN.2011.6115505
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   HUA K. A., 2010, PROCEEDINGS OF THE C, P1
   Hua KA, 1997, IEEE INFOCOM SER, P990, DOI 10.1109/INFCOM.1997.631037
   HUA KA, 1997, P SIGCOMM 1997, V27, P89
   Sheu S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P110, DOI 10.1109/MMCS.1997.609583
   Tran DA, 2003, IEEE INFOCOM SER, P1283
NR 8
TC 1
Z9 1
U1 0
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2013
VL 9
IS 1
SU S
AR 39
DI 10.1145/2502435
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 241SJ
UT WOS:000326187700009
DA 2024-07-18
ER

PT J
AU Liu, H
   Mei, T
   Li, HQ
   Luo, JB
   Li, SP
AF Liu, Heng
   Mei, Tao
   Li, Houqiang
   Luo, Jiebo
   Li, Shipeng
TI Robust and Accurate Mobile Visual Localization and Its Applications
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Performance; Design; Experimentation; Mobile visual
   localization; geo-tagging; scene reconstruction; location-based services
ID RECOGNITION; COLLECTIONS
AB Mobile applications are becoming increasingly popular. More and more people are using their phones to enjoy ubiquitous location-based services (LBS). The increasing popularity of LBS creates a fundamental problem: mobile localization. Besides traditional localization methods that use GPS or wireless signals, using phone-captured images for localization has drawn significant interest from researchers. Photos contain more scene context information than the embedded sensors, leading to a more precise location description. With the goal being to accurately sense real geographic scene contexts, this article presents a novel approach to mobile visual localization according to a given image (typically associated with a rough GPS position). The proposed approach is capable of providing a complete set of more accurate parameters about the scene geo-context including the real locations of both the mobile user and perhaps more importantly the captured scene, as well as the viewing direction. To figure out how to make image localization quick and accurate, we investigate various techniques for large-scale image retrieval and 2D-to-3D matching. Specifically, we first generate scene clusters using joint geo-visual clustering, with each scene being represented by a reconstructed 3D model from a set of images. The 3D models are then indexed using a visual vocabulary tree structure. Taking geo-tags of the database image as prior knowledge, a novel location-based codebook weighting scheme proposed to embed this additional information into the codebook. The discriminative power of the codebook is enhanced, thus leading to better image retrieval performance. The query image is aligned with the models obtained from the image retrieval results, and eventually registered to a real-world map. We evaluate the effectiveness of our approach using several large-scale datasets and achieving estimation accuracy of a user's location within 13 meters, viewing direction within 12 degrees, and viewing distance within 26 meters. Of particular note is our showcase of three novel applications based on localization results: (1) an on-the-spot tour guide, (2) collaborative routing, and (3) a sight-seeing guide. The evaluations through user studies demonstrate that these applications are effective in facilitating the ideal rendezvous for mobile users.
C1 [Liu, Heng; Li, Houqiang] Univ Sci & Technol China, CAS Key Lab Spatial Informat Proc & Appl Syst, Hefei 230027, Peoples R China.
   [Mei, Tao; Li, Shipeng] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Luo, Jiebo] Univ Rochester, Rochester, NY 14627 USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Microsoft; Microsoft Research Asia; University of Rochester
RP Mei, T (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.
EM sorcerer@mail.ustc.edu.cn; tmei@microsoft.com; ligq@mail.ustc.edu.cn;
   jluo@cs.rochester.edu; spli@microsoft.com
RI Mei, Tao/GQZ-0596-2022; Li, Houqiang Li/B-6259-2013; Luo,
   Jiebo/AAI-7549-2020; Li, Shipeng/AAA-3374-2020
OI Mei, Tao/0000-0002-5990-7307; Luo, Jiebo/0000-0002-4516-9729; Li,
   Shipeng/0000-0001-5368-4256
FU NSFC
FX This work is partly supported by NSFC general project fund "Intelligent
   Video Processing and Coding Based on Cloud Computing."
CR [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], P 17 ACM INT C MULT
   Avrithis Yannis, 2010, P 18 ACM INT C MULTI, P153, DOI 10.1145/1873951.1873973Place
   Bourke S., 2011, Proceedings of the International Conference of Intelligent User Interfaces (IUI), P13, DOI DOI 10.1145/1943403.1943408
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Girod B, 2011, IEEE SIGNAL PROC MAG, V28, P61, DOI 10.1109/MSP.2011.940881
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/CVPRW.2009.5206587
   Ji R., 2011, Proceedings of the 19th ACM International Conference on Multimedia, MM'11, P573
   Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9
   Josephson Klas, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2419, DOI 10.1109/CVPRW.2009.5206756
   Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9_54
   Kroep M., 2010, Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS '10, P119
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791
   Liu H., 2012, Proceedings_of_the_20th_ACM_ International_Conference_on_Multimedia, MM'12, P9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Park M., 2010, Proceedings of the International Conference on Multimedia, Firenze, Italy, P631
   Philbin J, 2010, LECT NOTES COMPUT SC, V6313, P677
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302
   Schindler G., 2007, P IEEE C COMP VIS PA, V2007, P1
   Schroth G, 2011, IEEE SIGNAL PROC MAG, V28, P77, DOI 10.1109/MSP.2011.940882
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Yu F.X., 2011, Proceedings_of_the_19th_ACM_International_Conference_on_Multimedia, MM'11, P3
   Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80
   Zhou W., 2010, P 18 ACM INT C MULTI, P511
   Zhuang JF, 2011, UBICOMP'11: PROCEEDINGS OF THE 2011 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P153
NR 38
TC 3
Z9 3
U1 0
U2 20
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD OCT
PY 2013
VL 9
IS 1
SU S
AR 51
DI 10.1145/2491735
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 241SJ
UT WOS:000326187700021
DA 2024-07-18
ER

PT J
AU Naskar, R
   Chakraborty, RS
AF Naskar, Ruchira
   Chakraborty, Rajat Subhra
TI A Generalized Tamper Localization Approach for Reversible Watermarking
   Algorithms
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Security; Performance; Authentication; digital image forensics;
   reversible watermarking; tamper localization
AB In general reversible watermarking algorithms, the convention is to reject the entire cover image at the receiver end if it fails authentication, since there is no way to detect the exact locations of tampering. This feature may be exploited by an adversary to bring about a form of DoS attack. Here we provide a solution to this problem in form of a tamper localization mechanism for reversible watermarking algorithms, which allows selective rejection of distorted cover image regions in case of authentication failure, thus avoiding rejection of the complete image. Additionally it minimizes the bandwidth requirement of the communication channel.
C1 [Naskar, Ruchira; Chakraborty, Rajat Subhra] Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Naskar, R (corresponding author), Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur, W Bengal, India.
EM ruchira@cse.iitkgp.ernet.in
RI Chakraborty, Rajat Subhra/AAN-3806-2020
OI Chakraborty, Rajat Subhra/0000-0003-3588-163X
CR [Anonymous], 1992, RFC1321
   [Anonymous], 1972, PLAYBOY MAGAZINE
   Bausys R, 2006, PROCEEDINGS ELMAR-2006, P53, DOI 10.1109/ELMAR.2006.329513
   Bhaskaran V., 1995, IMAGE VIDEO COMPRESS
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Crystal T., 2002, Proceedings of the second international conference on Human Language Technology Research, P212
   ELIAS P., 1995, IRE CONVENTION REC, V3, P37
   Feng J.B., 2006, IJ Network Security, V2, P161
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Lin S., 2004, Error Control Coding, Vsecond
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   REED A., 1990, U.S. Patent, Patent No. 4939731
   Shaowei Weng, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P241
   Singh R, 2001, INT CONF ACOUST SPEE, P273, DOI 10.1109/ICASSP.2001.940820
   Sobolewski J., 2003, ENCY COMPUTER SCI
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Wang N, 2012, COMPUT AIDED DESIGN, V44, P320, DOI 10.1016/j.cad.2011.11.001
   Xiaoyun Wu, 2007, 2007 Inaugural IEEE International Conference on Digital Ecosystems and Technologies, P501
   Yan YX, 2009, I W IMAG SYST TECHNI, P179, DOI 10.1109/IST.2009.5071628
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
NR 24
TC 14
Z9 14
U1 0
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUN
PY 2013
VL 9
IS 3
AR 19
DI 10.1145/2487268.2487272
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 175GL
UT WOS:000321218800004
DA 2024-07-18
ER

PT J
AU Zhao, ZW
   Samarth, S
   Ooi, WT
AF Zhao, Zhen Wei
   Samarth, Sameer
   Ooi, Wei Tsang
TI Modeling the Effect of User Interactions on Mesh-Based P2P VoD Streaming
   Systems
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Performance; Human Factors; User interaction; peer-to-peer; analytical
   modeling; video-on-demand; streaming; seek; pause; random departure
ID PERFORMANCE; SUPPORT; DESIGN
AB User interactions such as seeks and pauses are widely supported by existing Peer-to-Peer Video-on-Demand (P2P VoD) streaming systems. Their effect on the streaming system, however, has not been well studied. Seeks cause peers to skip part of the video, making them stay in the system for shorter time, and thus contribute less. On the other hand, only part of the video is downloaded due to seeks, reducing peers' demand from the system. It is unclear which factor dominates the effect of seeks on the streaming system. Pauses during playback, on one hand, allow peers to stay longer in the system and upload more content. When interleaved with seeks, however, long pauses may increase peers' demand unnecessarily as peers may download content that will eventually be skipped by subsequent forward seeks. The collective effect of seeks and pauses, together with the known random peer departure, is unintuitive and needs to be addressed properly so as to understand the effect of human factors on the streaming system performance.
   In this article, we develop an analytical model to both qualitatively and quantitatively study the effect of seeks and pauses on mesh-based P2P VoD streaming systems, in particular, the effect on the server cost. Our model can help in understanding how human factors such as seeks and pauses affect the streaming system performance, tuning a P2P VoD system towards better system performance and stability, and providing a framework for capacity planning.
C1 [Zhao, Zhen Wei] Natl Univ Singapore, Ctr Life Sci CeLS, NUS Grad Sch Intergrat Sci & Engn, Singapore 117456, Singapore.
   [Samarth, Sameer; Ooi, Wei Tsang] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
C3 National University of Singapore; National University of Singapore
RP Zhao, ZW (corresponding author), Natl Univ Singapore, Ctr Life Sci CeLS, NUS Grad Sch Intergrat Sci & Engn, 05-01,28 Med Dr, Singapore 117456, Singapore.
EM zhaozhenwei@nus.edu.sg
RI Ooi, Wei Tsang/AAE-7810-2019; Ooi, Wei Tsang/HLW-5142-2023
OI Ooi, Wei Tsang/0000-0001-8994-1736; Ooi, Wei Tsang/0000-0001-8994-1736
FU Singapore National Research Foundation; Interactive Digital Media R&D
   Program Office of Media Development Authority [WBS:R-252-300-001-490]
FX This research is conducted under the NExT Search Center, supported by
   the Singapore National Research Foundation and the Interactive Digital
   Media R&D Program Office of Media Development Authority under research
   grant WBS:R-252-300-001-490.
CR Aalto S., 2010, 201022ND INT TELETRA, P1
   Almeida J.M., 2001, Proceedings of the 11th international workshop on Network and operating systems support for digital audio and video, P21, DOI 10.1145/378344.378348
   Annapureddy S., 2007, Proc. Int'l WWW Conference, P903
   [Anonymous], 2006, P IEEE INFOCOM 2006
   [Anonymous], P INT C PEER TO PEER
   Bharambe A. R., 2005, Performance Evaluation Review, V33, P398, DOI 10.1145/1071690.1064273
   Brampton A., 2007, P INT WORKSH OP SYST, P99
   Cheng B, 2007, IEEE ICC, P1698, DOI 10.1109/ICC.2007.284
   Cheng Bin., 2008, ACM Trans. Multimedia Comput. Commun. Appl, V4, P1, DOI DOI 10.1145/1412196.1412199
   Chesire M., 2001, P 3 USENIX S INT TEC, V3
   Chi HC, 2007, IEEE J SEL AREA COMM, V25, P119, DOI 10.1109/JSAC.2007.070112
   Costa C., 2004, P 13 INT C WORLD WID, P534
   Crockford C, 2006, INT J HUM-COMPUT ST, V64, P340, DOI 10.1016/j.ijhcs.2005.08.012
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   Guo L, 2007, IEEE J SEL AREA COMM, V25, P155, DOI 10.1109/JSAC.2007.070116
   Guo Y., 2003, Proceedings of the 12th International Conference on World Wide Web, P301, DOI DOI 10.1145/775152.775195
   Guo Y, 2007, GLOB TELECOMM CONF, P225
   He Y, 2009, IEEE T PARALL DISTR, V20, P528, DOI 10.1109/TPDS.2008.102
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Huang C, 2007, ACM SIGCOMM COMP COM, V37, P133, DOI 10.1145/1282427.1282396
   Huang Y, 2008, ACM SIGCOMM COMP COM, V38, P375, DOI 10.1145/1402946.1403001
   Kostic D., 2003, Operating Systems Review, V37, P282, DOI 10.1145/1165389.945473
   Kumar R, 2007, IEEE INFOCOM SER, P919, DOI 10.1109/INFCOM.2007.112
   Lu Y, 2008, IEEE INT SYM MULTIM, P364, DOI 10.1109/ISM.2008.30
   Parvez KN, 2008, PERF E R SI, V36, P301, DOI 10.1145/1384529.1375492
   Qiu DY, 2004, ACM SIGCOMM COMP COM, V34, P367, DOI 10.1145/1030194.1015508
   Qiu XJ, 2009, NOSSDAV 09: 18TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P19
   Shah P, 2007, IEEE IPCCC, P340
   Vilas M, 2005, EUROMICRO-SEAA 2005: 31st EUROMICRO Conference on Software Engineering and Advanced Applications, Proceedings, P330
   Wang X, 2008, IEEE T CONSUM ELECTR, V54, P531, DOI 10.1109/TCE.2008.4560126
   Zhou YP, 2011, IEEE INFOCOM SER, P945, DOI 10.1109/INFCOM.2011.5935322
NR 31
TC 1
Z9 1
U1 0
U2 11
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2013
VL 9
IS 2
AR 13
DI 10.1145/2457450.2457455
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 144MS
UT WOS:000318944400005
DA 2024-07-18
ER

PT J
AU Spicer, R
   Lin, YR
   Kelliher, A
   Sundaram, H
AF Spicer, Ryan
   Lin, Yu-Ru
   Kelliher, Aisling
   Sundaram, Hari
TI NextSlidePlease: Authoring and Delivering Agile Multimedia Presentations
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Experimentation; Presentations; authoring; slideware
AB Presentation support tools, such as Microsoft PowerPoint, pose challenges both in terms of creating linear presentations from complex data and fluidly navigating such linear structures when presenting to diverse audiences. NextSlidePlease is a slideware application that addresses these challenges using a directed graph structure approach for authoring and delivering multimedia presentations. The application combines novel approaches for searching and analyzing presentation datasets, composing meaningfully structured presentations, and efficiently delivering material under a variety of time constraints. We introduce and evaluate a presentation analysis algorithm intended to simplify the process of authoring dynamic presentations, and a time management and path selection algorithm that assists users in prioritizing content during the presentation process. Results from two comparative user studies indicate that the directed graph approach promotes the creation of hyperlinks, the consideration of connections between content items, and a richer understanding of the time management consequences of including and selecting presentation material.
C1 [Spicer, Ryan; Kelliher, Aisling; Sundaram, Hari] Arizona State Univ, Sch Arts Media & Engn, Tempe, AZ USA.
   [Lin, Yu-Ru] Northeastern Univ, Harvard Univ, Inst Quantitat Social Sci, Boston, MA USA.
   [Lin, Yu-Ru] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA USA.
C3 Arizona State University; Arizona State University-Tempe; Northeastern
   University; Harvard University; Northeastern University
RP Kelliher, A (corresponding author), Carnegie Mellon Univ, Sch Design, MM 202C, Pittsburgh, PA 15213 USA.
EM aislingk@andrew.cmu.edu
OI Sundaram, Hari/0000-0003-3315-6055; Kelliher,
   Aisling/0000-0001-9175-2176
FU National Science Foundation through IGERT [0504647]; Direct For
   Education and Human Resources; Division Of Graduate Education [0504647]
   Funding Source: National Science Foundation
FX This work was supported by the National Science Foundation through IGERT
   no. 0504647.
CR [Anonymous], 2006, The cognitive style of PowerPoint: Pitching Out Corrupts within
   [Anonymous], 1951, COWLES COMMISSION MO
   [Anonymous], 1983, INTRO MODERN INFORM
   Bergman L, 2010, IUI 2010, P209
   Burkhard R, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P76, DOI 10.1109/IV.2005.27
   Drucker Steven M, 2006, P 19 ANN ACM S USER, P47
   Farkas D. K., 2006, Information Design Journal, V14, P162, DOI 10.1075/idj.14.2.08far
   Foote JT, 2003, PROC SPIE, V5021, P167, DOI 10.1117/12.476302
   Gaskins R., 1984, SAMPLE PRODUCT PROPO
   Good L., 2002, Information Visualization, V1, P35, DOI 10.1057/palgrave/ivs/9500004
   Gross AG, 2009, IEEE T PROF COMMUN, V52, P121, DOI 10.1109/TPC.2009.2020889
   Hammes T, 2009, ARMED FORCES J
   KHACHIYAN L., 1979, MATH DOKLADY, V20, P191
   LANIR J., 2008, P 16 INT C MULT MULT
   Lanir J, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P695
   Lichtschlag L, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P547
   Mahin L., 2004, Business Communication Quarterly, V67, P219, DOI 10.1177/1080569904672010
   Marnykina L., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P144, DOI 10.1145/365024.365077
   McCloud Scott., 2000, Reinventing Comics: How Imagination and Technology Are Revolutionizing an Art Form
   Mignot J, 2005, AEROSP CONF PROC, P4508
   MOSCOVICH T., 2004, CS0416 BROWN U
   Nelson Les., 1999, Proceedings of the SIGCHI conference on Human Factors in Computing Systems, P354, DOI DOI 10.1145/302979.303109
   Novak J.D., 2008, Florida Institute for Human and Machine Cognition, P1
   Parker I., 2001, The New Yorker, V77, P76
   SPICER R., 2011, 20112 AME TR AR STAT
   SPICER R. P., 2009, CHI 09 HUM FACT COMP
   YATES JOANN, 2008, COMMUNICATIVE PRACTI
NR 27
TC 15
Z9 19
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2012
VL 8
IS 4
AR 53
DI 10.1145/2379790.2379795
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 052QA
UT WOS:000312211900005
DA 2024-07-18
ER

PT J
AU Zhu, XL
   Chen, CW
AF Zhu, Xinglei
   Chen, Chang Wen
TI A Joint Layered Scheme for Reliable and Secure Mobile JPEG-2000
   Streaming
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Performance; Security; Multimedia authentication;
   authentication schemes; mobile media communication; communication system
   security; error correction coding; streaming authentication
ID IMAGE AUTHENTICATION; ASSIGNMENT; PROTECTION
AB This article presents a novel joint layered approach to simultaneously achieve both reliable and secure mobile JPEG-2000 image streaming. With a priori knowledge of JPEG-2000 source coding and channel coding, the proposed joint system integrates authentication into the media error protection components to ensure that every source-decodable media unit is authenticated. By such a dedicated design, the proposed scheme protects both compressed JPEG-2000 codestream and the authentication data from wireless channel impairments. It is fundamentally different from many existing systems that consider the problem of media authentication separately from the other operations in the media transmission system. By utilizing the contextual relationship, such as coding dependency and content importance between media slices for authentication hash appending, the proposed scheme generates an extremely low authentication overhead. Under this joint layered coding framework, an optimal rate allocation algorithm for source coding, channel coding, and media authentication is developed to guarantee end-to-end media quality. Experiment results on JPEG-2000 images validate the proposed scheme and demonstrate that the performance of the proposed scheme is approaching its upper bound, in which case no authentication is applied to the media stream.
C1 [Zhu, Xinglei; Chen, Chang Wen] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo
RP Zhu, XL (corresponding author), SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
EM xzhu4@buffalo.edu; chencw@buffalo.edu
FU US NSF [0915842]; Directorate For Engineering; Div Of Electrical, Commun
   & Cyber Sys [0915842] Funding Source: National Science Foundation
FX This work was supported in part by US NSF under Grant 0915842.
CR Albanese A, 1996, IEEE T INFORM THEORY, V42, P1737, DOI 10.1109/18.556670
   [Anonymous], P INT C IM PROC ROCH
   [Anonymous], 154441 ITU ISOIEC
   [Anonymous], 2003, NDSS
   [Anonymous], P WORKSH MULT SEC
   [Anonymous], J DATA INF QUAL
   Cai H, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/45412
   Deng RH, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1596990.1596992
   Gennaro R, 1997, LECT NOTES COMPUT SC, V1294, P180
   Hefeeda M, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671954.1671960
   Huang YZ, 2006, IEEE IMAGE PROC, P1685, DOI 10.1109/ICIP.2006.312683
   Jung Min Park, 2003, ACM Transactions on Information and Systems Security, V6, P258, DOI 10.1145/762476.762480
   Li Z, 2007, IEEE T MULTIMEDIA, V9, P837, DOI 10.1109/TMM.2007.893338
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Merkle R. C., 1980, Proceedings of the 1980 Symposium on Security and Privacy, P122
   MERKLE RC, 1990, LECT NOTES COMPUT SC, V435, P218, DOI 10.1007/0-387-34805-0_21
   Mohanty SP, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1413862.1413865
   Mohr AE, 2000, IEEE IMAGE PROC, P367, DOI 10.1109/ICIP.2000.900971
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Park Y, 2004, LECT NOTES COMPUT SC, V3046, P799
   Peng C., 2003, P ACM INT C MULTIMED, P433
   Perrig A, 2000, P IEEE S SECUR PRIV, P56, DOI 10.1109/SECPRI.2000.848446
   Sachs D. G., 2000, Proceedings DCC 2000. Data Compression Conference, DOI 10.1109/DCC.2000.838216
   Sun Q., 2005, INT J IMAGE GRAPH, V5
   Sun QB, 2008, P IEEE, V96, P97, DOI 10.1109/JPROC.2007.909926
   Thie J, 2004, EURASIP J APPL SIG P, V2004, P207, DOI 10.1155/S1110865704308024
   Zhang ZS, 2007, IEEE T MULTIMEDIA, V9, P320, DOI 10.1109/TMM.2006.886281
   Zhang ZS, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P784
   Zhang ZS, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P915
   Zhu X, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P349, DOI 10.1109/MMSP.2007.4412888
   Zhu XL, 2009, IEEE INT CON MULTI, P710, DOI 10.1109/ICME.2009.5202595
   Zhu XL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P13, DOI 10.1109/ICME.2008.4607359
NR 33
TC 3
Z9 3
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD JUL
PY 2012
VL 8
IS 3
AR 30
DI 10.1145/2240136.2240143
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 986AM
UT WOS:000307311700007
DA 2024-07-18
ER

PT J
AU Vu, L
   Gupta, I
   Nahrstedt, K
   Liang, J
AF Vu, Long
   Gupta, Indranil
   Nahrstedt, Klara
   Liang, Jin
TI Understanding Overlay Characteristics of a Large-Scale Peer-to-Peer IPTV
   System
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Measurement; Performance; Peer-to-peer; IPTV; streaming; multimedia;
   overlay; PPLive
AB This article presents results from our measurement and modeling efforts on the large-scale peer-to-peer (p2p) overlay graphs spanned by the PPLive system, the most popular and largest p2p IPTV (Internet Protocol Television) system today. Unlike other previous studies on PPLive, which focused on either network-centric or user-centric measurements of the system, our study is unique in (a) focusing on PPLive overlay-specific characteristics, and (b) being the first to derive mathematical models for its distributions of node degree, session length, and peer participation in simultaneous overlays.
   Our studies reveal characteristics of multimedia streaming p2p overlays that are markedly different from existing file-sharing p2p overlays. Specifically, we find that: (1) PPLive overlays are similar to random graphs in structure and thus more robust and resilient to the massive failure of nodes, (2) Average degree of a peer in the overlay is independent of the channel population size and the node degree distribution can be fitted by a piecewise function, (3) The availability correlation between PPLive peer pairs is bimodal, that is, some pairs have highly correlated availability, while others have no correlation, (4) Unlike p2p file-sharing peers, PPLive peers are impatient and session lengths (discretized, per channel) are typically geometrically distributed, (5) Channel population size is time-sensitive, self-repeated, event-dependent, and varies more than in p2p file-sharing networks, (6) Peering relationships are slightly locality-aware, and (7) Peer participation in simultaneous overlays follows a Zipf distribution. We believe that our findings can be used to understand current large-scale p2p streaming systems for future planning of resource usage, and to provide useful and practical hints for future design of large-scale p2p streaming systems.
C1 [Vu, Long; Gupta, Indranil; Nahrstedt, Klara] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
   [Liang, Jin] Google Inc, Mountain View, CA 94043 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign;
   Google Incorporated
RP Vu, L (corresponding author), Univ Illinois, Dept Comp Sci, 201 N Goodwin Ave, Urbana, IL 61801 USA.
EM longvu2@illinois.edu; indy@illinois.edu; klara@illinois.edu;
   jinliang@gmail.com
CR Andersen D., 2001, Proc. of SOSP, P131, DOI DOI 10.1145/502059.502048
   [Anonymous], P 14 INT WORKSH NETW
   [Anonymous], P WORKSH REC ADV PEE
   Banerjee S., 2002, P ACM SIGCOMM
   BHAGWAN R, 2003, P INT WORKSH PEERT
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Huang Y, 2008, ACM SIGCOMM COMP COM, V38, P375, DOI 10.1145/1402946.1403001
   Li B, 2008, IEEE INFOCOM SER, P1705
   Li B, 2007, IEEE J SEL AREA COMM, V25, P1627, DOI 10.1109/JSAC.2007.071203
   LIANG J, 2006, P ACM MULT COMP NETW
   Liao X., 2006, P IEEE INFOCOM, P1
   Ripeanu M, 2002, IEEE INTERNET COMPUT, V6, P50, DOI 10.1109/4236.978369
   Saroiu S, 2003, MULTIMEDIA SYST, V9, P170, DOI 10.1007/s00530-003-0088-1
   SILVERSTON T, 2006, P INT C EM NETW EXPE
   SILVERSTON T, 2007, P ACM NOSSDAV
   Stutzbach D, 2008, IEEE ACM T NETWORK, V16, P267, DOI 10.1109/TNET.2007.900406
   SUH K, 2006, P IEEE INFOCOM
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   VU L, 2006, UIUCDSR2006275
   VU L, 2007, P IEEE QSHINE
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wu C., 2007, PROC IEEE INT C DIST, P62
   Wu C, 2007, IEEE J SEL AREA COMM, V25, P1612, DOI 10.1109/JSAC.2007.071202
   Wu C, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1386109.1386112
   XIE S, 2007, P INT C PAR PROC WOR
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
NR 26
TC 28
Z9 35
U1 0
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD NOV
PY 2010
VL 6
IS 4
AR 31
DI 10.1145/1865106.1865115
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 688VA
UT WOS:000284880900009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Qudah, B
   Sarhan, NJ
AF Qudah, Bashar
   Sarhan, Nabil J.
TI Efficient Delivery of On-Demand Video Streams to Heterogeneous Receivers
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Design; Performance; Adaptive stream merging; client heterogeneity;
   multimedia servers; Video-on-Demand (VOD); video streaming
AB The number of video streams that can be serviced concurrently is highly constrained by the required real-time and high-rate transfers of multimedia data. Resource sharing techniques, such as Batching, Patching, and Earliest Reachable Merge Target (ERMT), can be used to address this problem by utilizing the multicast facility, which allows multiple requests to share the same set of server and network resources. They assume, however, that all clients have the same available download bandwidth and buffer space. We study how to efficiently support clients with varying available download bandwidth and buffer space, while delivering data in a client-pull fashion using enhanced resource sharing. In particular, we propose three hybrid solutions to address the variability in the download bandwidth among clients: Simple Hybrid Solution (SHS), Adaptive Hybrid Solution (AHS), and Enhanced Hybrid Solution (EHS). SHS simply combines Batching with either Patching or ERMT, leading to two alternatives: SHS-P and SHS-E, respectively. Batching is used for clients with bandwidth lower than double the video playback rate, and Patching/ERMT is used for the rest. In contrast, AHS and EHS classify clients into multiple bandwidth classes and service them accordingly. AHS employs a new stream type, called adaptive stream, and EHS employs an enhanced adaptive stream type to serve clients with bandwidth capacities ranging between the video playback rate and double that rate. AHS and EHS employ adaptive streams or enhanced adaptive streams in conjunction with Batching and Patching or ERMT, leading to four possible schemes: AHS-P, AHS-E, EHS-P, and EHS-E. Moreover, we consider the variability of the available buffer space among clients. Furthermore, we study how the waiting playback requests for different videos can be scheduled for service in the heterogeneous environment, capturing the variations in both the client bandwidth and buffer space. We evaluate the effectiveness of the proposed solutions and analyze various scheduling policies through extensive simulation.
C1 [Qudah, Bashar; Sarhan, Nabil J.] Wayne State Univ, Dept Elect & Comp Engn, Detroit, MI 48202 USA.
C3 Wayne State University
RP Qudah, B (corresponding author), Wayne State Univ, Dept Elect & Comp Engn, Detroit, MI 48202 USA.
EM bqudah@wayne.edu; nabil@wayne.edu
OI Sarhan, Nabil/0000-0002-0527-5666
FU NSF [CNS-0626861]
FX This work is supported in part by NSF grant CNS-0626861.
CR Aggarwal CC, 2001, IEEE T COMPUT, V50, P97, DOI 10.1109/12.908987
   ALSMIRAT M, 2007, P ACM MULT SEP, P791
   BAGOUET O, 2003, P MULT COMP NETW C M
   Cai Y, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P211
   Dan Asit, 1994, P ACM MULT, P391
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   Eager D, 2000, PROC SPIE, V3969, P206
   Eager D, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P199, DOI 10.1145/319463.319601
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   Pâris JF, 2001, IEEE IC COMP COM NET, P418, DOI 10.1109/ICCCN.2001.956299
   QUDAH B, 2006, P ACM MULT OCT, P347
   QUDAH B, 2006, P 14 IEEE INT S MOD, P327
   Sarhan NJ, 2007, PROC SPIE, V6504, DOI 10.1117/12.706022
   SARHAN NJ, 2004, P 7 IFIP IEEE INT C, P127
   SESSINI P, 2006, P ACM MULT OCT, P337
   Tantaoui MA, 2004, IEEE T BROADCAST, V50, P289, DOI 10.1109/TBC.2004.834202
   TSIOLIS AK, 1997, P ACM SIGMETRICS C M, P285
NR 18
TC 1
Z9 2
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2010
VL 6
IS 3
SI SI
AR 20
DI 10.1145/1823746.1823754
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 649UL
UT WOS:000281799300009
DA 2024-07-18
ER

PT J
AU Knoche, H
   Sasse, MA
AF Knoche, H.
   Sasse, M. A.
TI The Big Picture on Small Screens Delivering Acceptable Video Quality in
   Mobile TV
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Human Factors; Experimentation; Measurement; Design; Mobile multimedia
   consumption; resolution; size; trade-off
ID SUBJECTIVE IMAGE QUALITY; VIEWING-DISTANCE; RESOLUTION; WORK
AB Mobile TV viewers can change the viewing distance and (on some devices) scale the picture to their preferred viewing ratio, trading off size for angular resolution. We investigated optimal trade-offs between size and resolution through a series of studies. Participants selected their preferred size and rated the acceptability of the visual experience on a 200ppi device at a 4: 3 aspect ratio. They preferred viewing ratios similar to living room TV setups regardless of the much lower resolution: at a minimum 14 pixels per degree. While traveling on trains people required videos with a height larger than 35mm.
C1 [Knoche, H.; Sasse, M. A.] UCL, Dept Comp Sci, London WC1E 6BT, England.
C3 University of London; University College London
RP Knoche, H (corresponding author), UCL, Dept Comp Sci, Gower St, London WC1E 6BT, England.
EM h.knoche@cs.ucl.ac.uk
RI Sasse, Angela M/G-8628-2013; Knoche, Hendrik/AAD-4754-2019
OI Knoche, Hendrik/0000-0003-3950-8453
FU UNIversal satellite home Connection (UNIC) project [IST-2005-27034]
FX This work was supported by the IST-2005-27034 UNIversal satellite home
   Connection (UNIC) project.
CR [Anonymous], P 14 ANN ACM INT C M
   [Anonymous], 2004, P 2004 C HUM FACT CO
   [Anonymous], 2005, The Guardian
   [Anonymous], 2003, Digital Video and HDTV Algorithms and Interfaces
   [Anonymous], WORKPLACE ERGONOMICS
   [Anonymous], GRAMMAR SHOT
   [Anonymous], 1999, P911 ITUT
   APTEKER RT, 1994, P SOC PHOTO-OPT INS, P226
   Ardito M, 1996, IEEE T CONSUM ELECTR, V42, P145, DOI 10.1109/30.485473
   ARDITO M, 1994, SMPTE, V103, P8
   ASSFALG J, 2003, P C IM PROC
   BARTEN PGJ, 1990, J OPT SOC AM A, V7, P2024, DOI 10.1364/JOSAA.7.002024
   BIRKMAIER C, 2000, GUIDE DIGITAL TELEVI
   Boff KR, 1988, ENG DATA COMPENDIUM
   CHUANG SL, 1993, INT S SOC INF DISPL
   COREY GP, 1983, SOC PHOTOGRAPHIC SCI, V27, P9
   DIAMANT L, 1989, BROADCAST COMMUNICAT
   FRIESER H, 1963, PHOTOGR SCI ENG, V7, P28
   GHINEA G, 1998, P ACM MULT C 98
   GWINN E, 2005, CHICAGO TRIBUNE
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   HARPER R, 2008, P 18 AUSTR C COMP HU, P79
   HATADA T, 1980, SMPTE J, V89, P560, DOI 10.5594/J01582
   *ITU R, 2004, BT50011 ITUR
   JESTY LC, 1958, P I ELECTR ENG, P425
   JUMISKOPYYKKO S, 2008, P MOB HCI
   Kato S, 2005, SEVENTH IASTED INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING, P442
   Kingslake R., 1963, LENSES PHOTOGRAPHY
   KNOCHE H, 2004, P WIR WORLD RES FOR
   KNOCHE H, 2007, P ACM MULT 2007, P87
   Knoche H., 2005, P 7 INT C HUMAN COMP, P69
   Knoche H., 2006, P EUROITV US BROADC, P359
   Knoche Hendrick., 2005, Proceedings of the 13th Annual Association for Computing Machinery Conference on Multimedia, P829
   KOPF S, 2006, P 14 ACM INT C MULT, P957
   LLOYD E, 2006, MOBILE TV RESULTS BT
   LUND AM, 1993, SMPTE J, V102, P406, DOI 10.5594/J15915
   LUTHER AC, 1996, PRINCIPLES DIGITAL A
   MASON S, 2006, MOBILE TV RESULTS BT
   MASOODIAN M, 1995, INTERACT COMPUT, V7, P237, DOI 10.1016/0953-5438(95)93603-3
   NATHAN JG, 1985, HUM FACTORS, V27, P467, DOI 10.1177/001872088502700410
   NEUMAN WR, 1988, RES PAN NAT ASS BROA
   *OD SOFTW INC, 2003, CFCOM 2003
   OWENS DA, 1987, INVEST OPHTH VIS SCI, V28, P743
   Reeves B., 1993, NEW TELEVISIONS EFFE
   RIBCHESTER E, 1958, P I EL ENG B, V105, P437
   Richardson IEG, 2004, ELECTRON LETT, V40, P799, DOI 10.1049/el:20040553
   SASSE MA, 2006, P 2 ISCA DEGA TUT RE
   Sco K, 2007, IEEE T CIRC SYST VID, V17, P1395, DOI 10.1109/TCSVT.2007.903775
   SINHA A, 2005, GPSX 2005
   SODERGARD C, 2003, P506 VTT INF TECHN
   *STRAT AN, 2006, TV PHON INT POW IMPR
   SUGAMA Y, 2005, P ICME, P1262
   Tamminen S, 2004, PERS UBIQUIT COMPUT, V8, P135, DOI 10.1007/s00779-004-0263-1
   Tang J. C., 1993, Computer Supported Cooperative Work (CSCW), V1, P163, DOI 10.1007/BF00752437
   TANTON NE, 2004, 090 WHP BRIT BORADC
   THOMPSON FT, 1957, SMPTE, V66, P603
   WESTERINK JHDM, 1989, SMPTE J, V98, P113, DOI 10.5594/J02825
   WINKLER S, 2005, P WORKSH VID PROC QU
   YANQING C, 2007, P EUROITV 2007, P195
   Yu ZH, 2002, IEEE T BROADCAST, V48, P331, DOI 10.1109/TBC.2002.805637
NR 60
TC 20
Z9 23
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2009
VL 5
IS 3
AR 20
DI 10.1145/1556134.1556137
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 504DV
UT WOS:000270595600003
OA Green Published
DA 2024-07-18
ER

PT J
AU Wei, Y
   Bhandarkar, SM
   Li, K
AF Wei, Yong
   Bhandarkar, Suchendra M.
   Li, Kang
TI Client-Centered Multimedia Content Adaptation
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Video personalization; video indexing; hidden Markov models;
   multiple choice multidimensional knapsack problem
AB The design and implementation of a client-centered multimedia content adaptation system suitable for a mobile environment comprising of resource-constrained handheld devices or clients is described. The primary contributions of this work are: (1) the overall architecture of the client-centered content adaptation system, (2) a data-driven multi-level Hidden Markov model (HMM)-based approach to perform both video segmentation and video indexing in a single pass, and (3) the formulation and implementation of a Multiple-choice Multidimensional Knapsack Problem (MMKP)-based video personalization strategy. In order to segment and index video data, a video stream is modeled at both the semantic unit level and video program level. These models are learned entirely from training data and no domain-dependent knowledge about the structure of video programs is used. This makes the system capable of handling various kinds of videos without having to manually redefine the program model. The proposed MMKP-based personalization strategy is shown to include more relevant video content in response to the client's request than the existing 0/1 knapsack problem and fractional knapsack problem-based strategies, and is capable of satisfying multiple client-side constraints simultaneously. Experimental results on CNN news videos and Major League Soccer (MLS) videos are presented and analyzed.
C1 [Wei, Yong] N Georgia Coll & State Univ, Dept Math & Comp Sci, Dahlonega, GA 30597 USA.
   [Bhandarkar, Suchendra M.; Li, Kang] Univ Georgia, Dept Comp Sci, Athens, GA 30602 USA.
C3 University System of Georgia; North Georgia College & State University;
   University System of Georgia; University of Georgia
RP Wei, Y (corresponding author), N Georgia Coll & State Univ, Dept Math & Comp Sci, Dahlonega, GA 30597 USA.
EM ywei@ngcsu.edu
RI chen, yian/IWM-4310-2023
CR Akbar MM, 2001, LECT NOTES COMPUT SC, V2074, P659
   [Anonymous], 1997, LINEAR PROGRAMMING F
   Bartoli A, 2004, COMPUT ANIMAT VIRT W, V15, P501, DOI 10.1002/cav.13
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   Bhandarkar S. M., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P269
   BORECZKY JS, 1998, P IEEE INT C AC SPEE
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Chen MJ, 2002, IEEE T CIRC SYST VID, V12, P269, DOI 10.1109/76.999204
   Eickeler S, 1999, INT CONF ACOUST SPEE, P2997, DOI 10.1109/ICASSP.1999.757471
   EICKELER S, 2000, P IEEE INT C AC SPEE, V4, P1991
   Eleftheriadis A, 2006, IEEE T MULTIMEDIA, V8, P297, DOI 10.1109/TMM.2005.864346
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   FORNEY GD, 1973, IEEE P, V3, P268, DOI DOI 10.1109/PR0C.1973.9030
   Huang JC, 2005, IEEE T MULTIMEDIA, V7, P538, DOI 10.1109/TMM.2005.843346
   IRANI M, 1995, P SOC PHOTO-OPT INS, V2419, P242, DOI 10.1117/12.206363
   Irani M, 1996, SIGNAL PROCESS-IMAGE, V8, P327, DOI 10.1016/0923-5965(95)00055-0
   KHAN S, 1998, THESIS U VICTORIA
   Leacock C, 1998, LANG SPEECH & COMMUN, P265
   LI B, 2001, P IEEE WORKSH CONT B, V8, P132
   Li CS, 1998, INT CONF ACOUST SPEE, P3789, DOI 10.1109/ICASSP.1998.679709
   Merialdo B, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P323, DOI 10.1145/319463.319637
   Nakajima Y, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC408
   Ney H, 1999, IEEE SIGNAL PROC MAG, V16, P64, DOI 10.1109/79.790984
   Papoulis A, 1984, PROBABILITY RANDOM V, p[104, 148]
   Parra-Hernández R, 2005, IEEE T SYST MAN CY A, V35, P708, DOI 10.1109/TSMCA.2005.851140
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   SHINODA K, 2005, P S LARG SCAL KNOWL, P107
   Snoek CGM, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P481
   Sun HF, 1996, IEEE T CIRC SYST VID, V6, P191, DOI 10.1109/76.488826
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tseng BL, 2003, P SOC PHOTO-OPT INS, V5242, P14, DOI 10.1117/12.512987
   Tseng BL, 2004, IEEE MULTIMEDIA, V11, P42, DOI 10.1109/MMUL.2004.1261105
   Tseng BL, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P424
   Uykan Z, 2000, INT CONF ACOUST SPEE, P3486, DOI 10.1109/ICASSP.2000.860152
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wei Y, 2006, INT CONF PARA PROC, P82
   Wheeler E.S., 2002, GLOTTOMETRICS, V4, P45
   Zhu WW, 1998, BELL LABS TECH J, V3, P21, DOI 10.1002/bltj.2113
NR 39
TC 5
Z9 5
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2009
VL 5
IS 3
AR 22
DI 10.1145/1556134.1556139
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 504DV
UT WOS:000270595600005
DA 2024-07-18
ER

PT J
AU Cooper, M
   Foote, J
   Girgensohn, A
   Wilcox, L
AF Cooper, Matthew
   Foote, Jonathan
   Girgensohn, Andreas
   Wilcox, Lynn
TI Temporal Event Clustering for Digital Photo Collections
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Algorithms; Management; Digital photo organization; temporal media
   indexing; digital libraries
AB Organizing digital photograph collections according to events such as holiday gatherings or vacations is a common practice among photographers. To support photographers in this task, we present similarity-based methods to cluster digital photos by time and image content. The approach is general and unsupervised, and makes minimal assumptions regarding the structure or statistics of the photo collection. We present several variants of an automatic unsupervised algorithm to partition a collection of digital photographs based either on temporal similarity alone, or on temporal and content-based similarity. First, interphoto similarity is quantified at multiple temporal scales to identify likely event clusters. Second, the final clusters are determined according to one of three clustering goodness criteria. The clustering criteria trade off computational complexity and performance. We also describe a supervised clustering method based on learning vector quantization. Finally, we review the results of an experimental evaluation of the proposed algorithms and existing approaches on two test collections.
C1 [Cooper, Matthew; Foote, Jonathan; Girgensohn, Andreas; Wilcox, Lynn] FX Palo Alto Lab, Palo Alto, CA 94304 USA.
RP Cooper, M (corresponding author), FX Palo Alto Lab, 3400 Hillview Ave, Palo Alto, CA 94304 USA.
EM cooper@fxpal.com; foote@fxpal.com; andreas@fxpal.com; wilcox@fxpal.com
CR [Anonymous], 2002, CSCW '02, DOI DOI 10.1145/587078.587102
   Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794
   COOPER M, 2003, P 11 ACM INT C MULT, P364
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Foote J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P452, DOI 10.1109/ICME.2000.869637
   GIRGENSOHN A, 2003, P HUM COMP INT INTER, P196
   Graham A., 2002, Proceedings of the second ACM/IEEE-CS joint conference on Digital libraries, P326
   Harada S, 2004, ACM-IEEE J CONF DIG, P325
   Hartigan J. A., 1975, CLUSTERING ALGORITHM, V458, P468
   JAIMES A, 2000, IEEE INT C IM PROC, V2, P528
   *JEIDA, 1998, DIG STILL CAM IM FIL
   Kohonen, 1989, SELF ORG ASS MEMORY
   KOHONEN T., 1992, P INT JOINT C NEURAL, VI, P725
   Leung Y, 2000, IEEE T PATTERN ANAL, V22, P1396, DOI 10.1109/34.895974
   Lim JH, 2003, IEEE MULTIMEDIA, V10, P28, DOI 10.1109/MMUL.2003.1237548
   Loui AC, 2003, IEEE T MULTIMEDIA, V5, P390, DOI 10.1109/TMM.2003.814723
   MILLS T, 2000, 200010 AT T LAB CAMB
   MOJSILOVIC A, 2002, SPIE HUMAN VISION EL, P266
   PLATT J, 2003, 4 IEEE PAC RIM C MUL, P6
   RODDEN K, 2002, THESIS U CAMBRIDGE C
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   SLANEY M, 2001, ACM INT C MULT, P29
   Ullas G, 2003, P 5 ACM SIGMM INT WO, P47
   Witkin A., 1984, Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP '84, VVolume 9, P150, DOI DOI 10.1109/ICASSP.1984.1172729
NR 25
TC 27
Z9 29
U1 1
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2005
VL 1
IS 3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA V74DW
UT WOS:000205012400003
DA 2024-07-18
ER

EF