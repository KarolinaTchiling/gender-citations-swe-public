FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Zana, Y
   Cesar, RM
   Feris, R
   Turk, M
AF Zana, Y.
   Cesar, R. M., Jr.
   Feris, R.
   Turk, M.
TI Local approach for face verification in polar frequency domain
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; human visual perception
ID RECOGNITION; PATTERNS; FEATURES
AB We present a face verification system inspired by known properties of the human visual system. In the proposed algorithm the face is normalized for geometry and luminance, and Fourier-Bessel (FB) descriptors are extracted from three locations in the eyes region (local analysis). The resulting representations are embedded in a dissimilarity space, where each image is represented by its distance to all the other images, and a Pseudo-Fisher discriminator is built. Using the FERET database, we submitted the system to a battery of tests under a wide variation of imaging conditions, including expression, age, and illumination variations. Results showed that the system outperformed previous state-of-the-art methods in most testing conditions. To deal with partial occlusions, we implemented an occluded region detector that resulted in low performance loss under up to 50% occlusion level. Finally, we automated the registration step by implementing face and eye detection algorithms. We also showed that the local-FB analysis outperforms the global-FB version of the system and an alternative polar frequency representation. In conclusion, the intermediate-scale local analysis approach used in the proposed system resulted in state-of-the-art face verification performance and high robustness to common problems such as expression, age, and illumination variations and to strong occlusions. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Sao Paulo, Sao Paulo, Brazil.
   Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
C3 Universidade de Sao Paulo; University of California System; University
   of California Santa Barbara
RP Zana, Y (corresponding author), Univ Sao Paulo, R Matao,1010, Sao Paulo, Brazil.
EM zana@vision.ime.usp.br; cesar@vision.ime.usp.br; feris@cs.ucsb.edu;
   mturk@cs.ucsb.edu
RI Zana, Yossi/F-5999-2015; Cesar-Jr, Roberto/C-4120-2012
OI Turk, Matthew/0000-0002-4198-8401; Cesar-Jr, Roberto/0000-0003-2701-4288
CR [Anonymous], P 2004 ACM S APPL CO
   Bowman F., 1958, Introduction to Bessel Function
   CABRERA J, 1992, CYBERNET SYST, V23, P241, DOI 10.1080/01969729208927460
   CAMPOS TE, 2000, P 13 SIBGRAPI, P28
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   DeValois R. L, 1990, Spatial Vision, V2
   DUIN R, 2000, PRTOOLS3 MATLAB TOOL
   Duin RPW, 1997, PATTERN RECOGN LETT, V18, P1159, DOI 10.1016/S0167-8655(97)00138-4
   Edelman Shimon., 1999, REPRESENTATION RECOG
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fox PD, 2003, J ACOUST SOC AM, V113, P2412, DOI 10.1121/1.1560211
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   GALLANT JL, 1993, SCIENCE, V259, P100, DOI 10.1126/science.8418487
   GROVE TD, 1996, P BRIT MACH VIS C ED, V1, P293
   Guan SG, 2001, PHYSICA D, V151, P83, DOI 10.1016/S0167-2789(01)00223-8
   HALLINAN PW, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P995, DOI 10.1109/CVPR.1994.323941
   Heisele B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P153, DOI 10.1109/AFGR.2004.1301523
   HOTTA T, 1998, P 3 IEEE INT C AUT F, P70
   Kothari R, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P519, DOI 10.1109/ICIP.1996.560546
   Lemieux A, 2002, INT C PATT RECOG, P421, DOI 10.1109/ICPR.2002.1044743
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X
   PERRETT DI, 1982, EXP BRAIN RES, V47, P329
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   RHODES G, 1988, PERCEPTION, V17, P43, DOI 10.1068/p170043
   RIZVI S, 1998, 6281 NIST NISTIR
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   SCHWARTZ EL, 1977, BIOL CYBERN, V25, P181, DOI 10.1007/BF01885636
   SCURICHINA M, 1996, P 13 INT C PATT REC, V2, P891
   Sim T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P214, DOI 10.1109/AFGR.2000.840637
   Smeraldi F, 2002, PATTERN RECOGN LETT, V23, P463, DOI 10.1016/S0167-8655(01)00178-7
   Tax DMJ, 2002, INT C PATT RECOG, P124, DOI 10.1109/ICPR.2002.1048253
   TISTARELLI M, 1998, FACE RECOGNITION THE, P262
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wilson HR, 1998, VISION RES, V38, P2933, DOI 10.1016/S0042-6989(98)00109-6
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   YOUNG MP, 1992, SCIENCE, V256, P1327, DOI 10.1126/science.1598577
   Zana Y, 2005, LECT NOTES COMPUT SC, V3804, P183
   ZANA Y, 2005, 18 BRAZ S COMP GRAPH, P233
   ZANA Y, 2006, ACT T APPL PERCEPTIO, V3, P1
   Zana Y, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P299
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 44
TC 4
Z9 5
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 904
EP 913
DI 10.1016/j.imavis.2006.02.014
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100011
DA 2024-07-18
ER

PT J
AU Chung, D
   MacLean, WJ
   Dickinson, S
AF Chung, Desmond
   MacLean, W. James
   Dickinson, Sven
TI Integrating region and boundary information for spatially coherent
   object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE segmentation; motion estimation; boundary recovery; parametric models;
   motion layers
AB The problem of segmenting image sequences based on 2D motion has been under study for many years now. Most early approaches were either region-based, doing some sort of robust motion estimation, or boundary-based, preferring instead to track the bounding contours of the moving image region. In this paper, we explore an approach based on a synergy between these two previous approaches. For example, while motion constraints are often in violation of their underlying assumptions at region boundaries, image edges are a rich source of information. The approach we propose uses feed-forward to use region-based information to propagate boundary estimates, feedback to use boundaries to improve motion estimation, and finally uses motion-based warping to compare image appearance between frames in order to provide additional information for the boundary estimation process.
   We show results from an implementation in which a hierarchical, layered-motion estimation using parametric models is coupled with a distance-transform based active contour. The system is shown to provide stable and accurate segmentation in sequences with background motion, and multiple moving objects. Quantitative measures are proposed and reported for these sequences. Finally, a modification is detailed which allows the system to incorporate a Condensation algorithm tracker, but without requiring off-line learning in advance. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Toronto, Edward S Rogers Sr Dept Elect & Comp Engn, Toronto, ON M5S 3G4, Canada.
   Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.
C3 University of Toronto; University of Toronto
RP MacLean, WJ (corresponding author), Univ Toronto, Edward S Rogers Sr Dept Elect & Comp Engn, 100 Coll St, Toronto, ON M5S 3G4, Canada.
EM desmond.chunglincheung@utoronto.ca; maclean@eecg.toronto.edu;
   sven@cs.toronto.edu
CR [Anonymous], P 2 INT C COMP VIS
   AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859
   BASCLE B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P302, DOI 10.1109/ICCV.1995.466925
   BERGEN JR, 1992, P 2 EUR C COMP VIS, P237
   Black M.J., 1993, ROBUST ESTIMATION MU
   Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   DARELL T, 1991, P IEEE WORKSH VIS MO, P173
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gelgon M, 2000, PATTERN RECOGN, V33, P725, DOI 10.1016/S0031-3203(99)00083-7
   Grzywacz N. M., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P148, DOI 10.1109/WVM.1989.47104
   IRANI M, 1992, DETECTING TRACKING M, P282
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   ISARD M, ECCV96, V2, P343
   Jain A., 1988, Fundamentals of Digital Image Processing
   Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161
   Jepson AD, 2001, PROC CVPR IEEE, P415
   JEPSON AD, EUR C COMP VIS ECCV, P692
   Jojic N, 2001, PROC CVPR IEEE, P199
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   MACLEAN WJ, 1994, BMVC94 - PROCEEDINGS OF THE 5TH BRITISH MACHINE VISION CONFERENCE, VOLS 1 AND 2, P175
   Paragios N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P688, DOI 10.1109/ICCV.1999.791292
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   PARAGIOS N, 1999, UNIFYING BOUNDARY RE, V2, P300
   Sawhney HS, 2000, IEEE T PATTERN ANAL, V22, P1191, DOI 10.1109/34.879803
   Stockman George, 2001, Computer Vision
   TORR PHS, 1994, THESIS U OXFORD
   TORR PHS, 1994, LNCS, V801, P328
   WANG JYA, 1993, P 1993 IEEE COMP SOC, P363
   Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375
   Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   YILMAZ A, 2004, P AS C COMP VIS KOR
   YUILLE AL, 1989, INT J COMPUT VISION, V3, P155, DOI 10.1007/BF00126430
   ZHANG R, 2003, IEEE WORKSH GEOM VAR
NR 38
TC 5
Z9 9
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 680
EP 692
DI 10.1016/j.imavis.2005.09.020
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400004
DA 2024-07-18
ER

PT J
AU Bonaiuto, J
   Itti, L
AF Bonaiuto, J.
   Itti, L.
TI The use of attention and spatial information for rapid facial
   recognition in video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE visual attention; bottom-up; face recognition; video processing
AB Bottom-up visual attention allows primates to quickly select regions of an image that contain salient objects. In artificial systems. restricting the task of object recognition to these regions allows faster recognition and Unsupervised learning of multiple objects in cluttered scenes. A problem with this approach is that objects superficially dissimilar to the target are given the same consideration in recognition as similar objects. In video, objects recognized in previous frames at locations distant to the current fixation point are given the same consideration in recognition as objects previously recognized in locations closer to the Current target of attention. Due to the continuity of smooth motion, objects recently recognized in previous frames at locations close to the current focus of attention have a high probability of matching the current target. Here we investigate rapid pruning of the facial recognition search space using the already-computed low-level features that guide attention and spatial information derived from previous video frames. For each video frame, Itti & Koch's bottom-up visual attention algorithm is used to select salient locations based on low-level features such as contrast, orientation, color, intensity, flicker and motion. This algorithm has shown to be highly effective in selecting faces as salient objects. Lowe's SIFT object recognition algorithm then extracts a signature of the attended object. for comparison with the facial database. The database search is prioritized for faces which better match the low-level features used to guide attention to the current candidate for recognition or those that were previously recognized near the current candidate's location. The SIFT signatures of the prioritized faces are then checked against the attended candidate for a match. By comparing performance of Lowe's recognition algorithm and Itti & Koch's bottom-up attention model with or without search space pruning we demonstrate that Our pruning approach improves the speed of facial recognition in video footage. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ So Calif, Dept Neurosci, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Itti, L (corresponding author), Univ So Calif, Dept Neurosci, Los Angeles, CA 90089 USA.
EM itti@usc.edu
RI Bonaiuto, James/H-3457-2019
OI Bonaiuto, James/0000-0001-9165-4082
CR Herpers R, 1997, INT J NEURAL SYST, V8, P27, DOI 10.1142/S0129065797000057
   HERPERS R, 1996, P 13 INT C PATT REC, V2, P23
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2003, PROC SPIE, V5200, P64, DOI 10.1117/12.512618
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowe DG, 2000, LECT NOTES COMPUT SC, V1811, P20
   NAVALPAKKAM V, MODELING INFLUENCE T
   Rutishauser U., 2004, INT C COMP VIS PATT
   STAROVOITOV V, 1999, P IEEE EURASIP WORKS, V2, P210
   Walther D, 2002, LECT NOTES COMPUT SC, V2525, P472
   Walther D., 2004, WORKSHOP ATTENTION P, P96
   WENDT S, 2002, INT C SPOK LANG PROC, V1, P377
   Wolfe J., 1998, VISUAL SEARCH
NR 15
TC 10
Z9 12
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2006
VL 24
IS 6
BP 557
EP 563
DI 10.1016/j.imavis.2005.09.008
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 061NB
UT WOS:000238878200002
DA 2024-07-18
ER

PT J
AU Amornraksa, T
   Janthawongwilail, K
AF Amornraksa, T
   Janthawongwilail, K
TI Enhanced images watermarking based on amplitude modulation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE digital image processing; copyright protection; digital watermarking;
   amplitude modulation
ID DIGITAL WATERMARKING
AB This paper presents an image watermarking method with blind detection based on amplitude modulation. Basically, the watermark embedding is performed by modifying the pixel values in the blue channel of an image, while the watermark retrieval is achieved by using a prediction technique based on a linear combination of nearby pixel values around the embedded pixels. Based on the analysis results, three different methods are proposed to enhance the watermark retrieval performance, i.e. by balancing watermark bits around the embedding pixels, by properly tuning the strength of embedding watermark, by modifying the method of pixel prediction. Experimental result, show that the watermarking scheme implementing our methods achieves significant improvements over the existing schemes. Remarkable improvemems are still obtained even if various types of attacks are applied.
C1 King Mongkuts Univ Technol, Dept Comp Engn, Bangkok 10140, Thailand.
C3 King Mongkuts University of Technology North Bangkok; King Mongkuts
   University of Technology Thonburi
RP King Mongkuts Univ Technol, Dept Comp Engn, Thonburi 91, Bangkok 10140, Thailand.
EM thumrongrat.amo@kmutt.ac.th
CR Cox I. J., 2002, Digital Watermarking
   Delaigle JF, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA489
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Kutter M, 1998, J ELECTRON IMAGING, V7, P326, DOI 10.1117/1.482648
   PUERTPAN R, 2001, P IEEE ISSPA KUAL LA
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Suhail MA, 2003, IEEE T INSTRUM MEAS, V52, P1640, DOI 10.1109/TIM.2003.817155
   Sweeney P., 1991, ERROR CONTROL CODING
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
NR 9
TC 36
Z9 39
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 111
EP 119
DI 10.1016/j.imavis.2005.09.018
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900001
DA 2024-07-18
ER

PT J
AU Mallon, J
   Whelan, PF
AF Mallon, J
   Whelan, PF
TI Projective rectification from the fundamental matrix
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE projective rectification; homography; fundamental matrix; distortion
   minimisation; stereo vision
ID STEREO; VIEW
AB This paper describes a direct. self-contained method for planar image rectification of stereo pairs. The method is based solely on an examination of the Fundamental matrix, where an improved method is given for the derivation of two projective transformations that horizontally align all the epipolar projections. A novel approach is proposed to uniquely optimise each transform in order to minimise perspective distortions. This ensures the rectified images resemble the original images as closely as possible. Detailed results show that the rectification precision exactly matches the estimation error of the Fundamental matrix. In tests the remaining perspective distortion offers on average less than one percent viewpoint distortion. Both these factors offer superior robustness and performance compared with existing techniques. (c) 2005 Elsevier B.V. All rights reserved.
C1 Dublin City Univ, Vis Syst Grp, Dublin 9, Ireland.
C3 Dublin City University
RP Dublin City Univ, Vis Syst Grp, Dublin 9, Ireland.
EM john.mallon@eeng.dcu.ie
RI Whelan, Paul/C-7962-2011
OI Whelan, Paul/0000-0001-9230-7656
CR Al-Shalfan KA, 2000, ELECTRON LETT, V36, P419, DOI 10.1049/el:20000362
   [Anonymous], 1996, MATRIX COMPUTATION
   Armangué X, 2003, IMAGE VISION COMPUT, V21, P205, DOI 10.1016/S0262-8856(02)00154-3
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Isgrò F, 1999, IEE CONF PUBL, P42, DOI 10.1049/cp:19990278
   Loop C., 1999, Comput. Vision Pattern Recognit, V1, P1125, DOI [10.1109/CVPR.1999.786928, DOI 10.1109/CVPR.1999.786928]
   Ng KC, 2002, INT J COMPUT VISION, V47, P131, DOI 10.1023/A:1014589723611
   Papadimitriou DV, 1996, IEEE T IMAGE PROCESS, V5, P672, DOI 10.1109/83.491345
   Pollefeys M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P496, DOI 10.1109/ICCV.1999.791262
   WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074
NR 13
TC 69
Z9 82
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2005
VL 23
IS 7
BP 643
EP 650
DI 10.1016/j.imavis.2005.03.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 940LX
UT WOS:000230147100003
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Shih, MY
   Tseng, DC
AF Shih, MY
   Tseng, DC
TI A wavelet-based multiresolution edge detection and tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE edge extraction; edge detection; edge tracking; wavelet transform
ID TEXTURE SEGMENTATION; TRANSFORM; IMAGES; CLASSIFICATION; MODEL
AB A gradient image describes the differences of neighboring pixels in the image. Extracting edges only depending on a gradient image will results in noised and broken edges. Here, we propose a two-stage edge extraction approach with contextual-filter edge detector and multiscale edge tracker to solve the problems. The edge detector detects most edges and the tracker refines the results as well as reduces the noised or blurred influence; moreover, the extracted results are nearly thinned edges which are suitable for most applications. Based on six wavelet basis functions, qualitative and quantitative comparisons with other methods show that the proposed approach extracts better edges than the other wavelet-based edge detectors and Canny detector extract. (C) 2004 Elsevier B.V. All rights reserved.
C1 Natl Cent Univ, Inst Comp Sci & Informat Engn, Chungli 320, Taiwan.
C3 National Central University
RP Natl Cent Univ, Inst Comp Sci & Informat Engn, Chungli 320, Taiwan.
EM tsengdc@ip.csie.ncu.edu.tw
CR Aydin T, 1996, IEEE T IMAGE PROCESS, V5, P1370, DOI 10.1109/83.535850
   BELTRAN JR, 1994, IEEE IMAGE PROC, P293, DOI 10.1109/ICIP.1994.413322
   Busch C, 1997, COMPUT GRAPH-UK, V21, P347, DOI 10.1016/S0097-8493(97)00012-5
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   Chickanosky V, 1998, INT CONF ACOUST SPEE, P2953, DOI 10.1109/ICASSP.1998.678145
   Coifman R., 1995, TRANSLATION INVARIAN, P125, DOI [10.1007/978-1-4612-2544-7_9, DOI 10.1007/978-1-4612-2544-7_9]
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Falcao AX, 2000, IEEE T MED IMAGING, V19, P55, DOI 10.1109/42.832960
   Feng L, 2000, INT J PATTERN RECOGN, V14, P779, DOI 10.1142/S0218001400000519
   Fukuda S, 1999, IEEE T GEOSCI REMOTE, V37, P2282, DOI 10.1109/36.789624
   HEIJDEN F, 1995, IEEE T PATTERN ANAL, V17, P16
   Hohne KH, 1996, COMPUTER, V29, P25, DOI 10.1109/2.481433
   Hsieh JW, 1997, IMAGE VISION COMPUT, V15, P511, DOI 10.1016/S0262-8856(96)00003-0
   Lu CS, 1997, PATTERN RECOGN, V30, P729, DOI 10.1016/S0031-3203(96)00116-1
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MOON P, 1992, IEEE P COMM SIGN PRO, P233
   Morsy KA, 1997, 1997 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION - CIRA '97, PROCEEDINGS, P398, DOI 10.1109/CIRA.1997.613887
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   VANDERZWET PMJ, 1992, IEEE P COMP CARD LOS, P107
   Xu XG, 2000, HEALTH PHYS, V78, P476, DOI 10.1097/00004032-200005000-00003
NR 21
TC 51
Z9 71
U1 0
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2005
VL 23
IS 4
BP 441
EP 451
DI 10.1016/j.imavis.2004.11.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NR
UT WOS:000227222100007
DA 2024-07-18
ER

PT J
AU Stern, H
   Efros, B
AF Stern, H
   Efros, B
TI Adaptive color space switching for tracking under varying illumination
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE color segmentation; face tracking; color space model selection; adaptive
   color segmentation; tracking performance measures
AB Many studies use color space models (CSM) and color distribution models (CDM) for detection of faces in an image. We develop a procedure that adaptively switches CSMs throughout the processing of a video. We show that this works in environments with varying types of illumination. In addition, a new performance measure for evaluating tracking algorithms is proffered. Extensive testing of the procedure found that switching between the color spaces resulted in increased tracking performance when compared to using single CSMs throughout. The methodology developed can be used to find the optimal CSM-CDM combination in the design of adaptive color tracking systems. The adaptive color space switching algorithm has linear computational time complexity O(S), at each iteration, where S is the picture size in pixels. (C) 2004 Elsevier B.V. All rights reserved.
C1 Ben Gurion Univ Negev, Dept Ind Engn & Management, IL-84105 Beer Sheva, Israel.
C3 Ben Gurion University
RP Ben Gurion Univ Negev, Dept Ind Engn & Management, POB 563, IL-84105 Beer Sheva, Israel.
EM helman@bgumail.bgu.ac.il; bgumail@bgu.ac.il
CR AKAHO S, 1995, TR9513 ETL
   [Anonymous], 1998, 4 IEEE WORKSH APPL C
   Bradski G., 1999, SPIE, V3656, P230
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   FANG Y, 2000, P 11 BRIT MACH VIS C, V1, P23
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Gong S., 2000, Dynamic vision from images to face recognition
   GONG S, 2000, P EUR C COMP VIS DUB, V2, P150
   Greenspan H, 2001, PATTERN RECOGN LETT, V22, P1525, DOI 10.1016/S0167-8655(01)00086-1
   Kjeldsen R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P312, DOI 10.1109/AFGR.1996.557283
   Lee CH, 1996, PATTERN RECOGN, V29, P1877, DOI 10.1016/0031-3203(96)00036-2
   MCKENNA S, 1998, EUR C COMP VIS JUL
   MCKENNA S, 1998, IMAGE VISION COMPUT, V3, P225
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   STYRRING M, 1999, 7 S INT ROB SYST COI, P187
   WREN C, 1995, SPIE PHOTONICS E, V2615, P89
   Yang J, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P142, DOI 10.1109/ACV.1996.572043
   Yang MH, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P127, DOI 10.1109/ICIP.1998.723442
   Yin XM, 2001, ROBOT AUTON SYST, V34, P235, DOI 10.1016/S0921-8890(00)00125-1
NR 19
TC 38
Z9 45
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2005
VL 23
IS 3
BP 353
EP 364
DI 10.1016/j.imavis.2004.09.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NO
UT WOS:000227221800007
DA 2024-07-18
ER

PT J
AU Huang, KQ
   Wu, ZY
   Wang, Q
AF Huang, KQ
   Wu, ZY
   Wang, Q
TI Image enhancement based on the statistics of visual representation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image enhancement; visual representation; brightness; contrast
ID ADAPTIVE HISTOGRAM EQUALIZATION; CONTRAST ENHANCEMENT
AB This paper introduces a novel algorithm to image enhancement that exploits the multi-scale wavelet and statistical characters of visual representation. Processing includes the global dynamic range (brightness) correction and local contrast adjustment, whose parameters are picked automatically by the information contained in the image itself. Experimental results show that the new algorithm outperforms other many existing image enhancement methods and is highly resilient to the effects of both the image-source variations. (C) 2004 Elsevier B.V. All rights reserved.
C1 Chinese Acad Sci, Inst Automat, NLPR, Beijing 100080, Peoples R China.
   SE Univ, Dept Radio Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Southeast
   University - China
RP Chinese Acad Sci, Inst Automat, NLPR, S Rd 95,POB 2728, Beijing 100080, Peoples R China.
EM kqhuang@nlpr.ia.ac.cn
RI 黄, 凯琦/JJC-9384-2023; Wang, Qiao/AAU-2338-2020
OI 黄, 凯琦/0000-0001-6834-6604; Wang, Qiao/0000-0002-5271-0472
CR [Anonymous], 2008, DIGITAL IMAGE PROCES
   [Anonymous], 1987, Nonlinear Parameter Estimation: An Integrated System in BASIC
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   Huang KQ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P721
   Huang KQ, 2003, PROC SPIE, V5150, P1667, DOI 10.1117/12.507817
   JI TL, 1994, IEEE T MED IMAGING, V13, P573, DOI 10.1109/42.363111
   JOBSON D, 2002, P SOC PHOTO-OPT INS, P4736
   Kim HS, 2003, INT J MECH SCI, V45, P1999, DOI 10.1016/j.ijmecsci.2004.02.002
   KIM YT, 1997, IEEE T, V43
   LAINE A, 1995, IEEE ENG MED BIOL, V14, P536, DOI 10.1109/51.464770
   LIM JS, 1999, TWO DIMENSIONAL SIGN
   LU JA, 1994, OPT ENG, V33, P2151, DOI 10.1117/12.172254
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MARR D, 1982, FREEMAN COMPANT
   PEIL T, 1981, P ICASSP81 ATL, P1117
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rosebfield A., 1976, DIGITAL PICTURE PROC
   SHERRIER RH, 1987, IEEE T MED IMAGING, V6, P1, DOI 10.1109/TMI.1987.4307791
   ZONG T, 2000, MED ENG PHYS, V22, P79
NR 20
TC 28
Z9 36
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2005
VL 23
IS 1
BP 51
EP 57
DI 10.1016/j.imavis.2004.07.005
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 882BO
UT WOS:000225913700005
DA 2024-07-18
ER

PT J
AU Zheng, L
   Qin, BJ
   Zhuang, TG
   Tiede, U
   Höhne, KH
AF Zheng, L
   Qin, BJ
   Zhuang, TG
   Tiede, U
   Höhne, KH
TI Localization of acupoints on a head based on a 3D virtual body
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Traditional Chinese Medicine; acupuncture and moxibustion; localization
   of acupoints; three-dimensional body model; visible human project;
   VOXEL-MAN
AB Modem computer science allows powerful and versatile computer-based knowledge representations of acupuncture, one part of Traditional Chinese Medicine. For further research and development of acupuncture therapy, it is critical to define where to accurately localize acupoints onto such a computer based pictorial representation of the human body. Using the segmentation and 3D visualization of the VOXEL-MAN software system, original work for localizing the acupoints on a head based of a virtual body is reported in this paper. The proposed 2D acupoint description links the description taken from literature for locating acupoints in Traditional Chinese Medicine to the data in the absolute reference frame of a 3D virtual body. It offers a simple and useful way for the localization of acupoints on a 3D model, especially one derived from the data from Visible Human Project. (C) 2004 Elsevier B.V. All rights reserved.
C1 Shanghai Jiao Tong Univ, Dept Biomed Engn, Shanghai 200030, Peoples R China.
   Univ Hamburg Hosp, IMI, D-2000 Hamburg, Germany.
C3 Shanghai Jiao Tong University; University of Hamburg; University Medical
   Center Hamburg-Eppendorf
RP Shanghai Jiao Tong Univ, Dept Biomed Engn, Shanghai 200030, Peoples R China.
EM tgzhuang@sjtu.edu.cn
RI Qin, Binjie/B-5472-2008; Qin, Binjie/L-7882-2019
OI Qin, Binjie/0000-0001-7445-1582
CR Hearn D., 1994, Computer Graphics
   HOHNE KH, 1995, NAT MED, V1, P506, DOI 10.1038/nm0695-506
   HOHNE KH, 1995, VOXEL MAN 1
   LOHMANN G, 1999, VOLUMETRIC IMAGE ANA, P53
   Pommert A, 2001, MED IMAGE ANAL, V5, P221, DOI 10.1016/S1361-8415(01)00044-5
   YAN ZG, 1993, ENBLISH CHINESE PRAC
   YAN ZG, 1995, NORMAL HUMAN ANATOMY
NR 7
TC 17
Z9 18
U1 0
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2005
VL 23
IS 1
BP 1
EP 9
DI 10.1016/j.imavis.2004.03.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 882BO
UT WOS:000225913700001
DA 2024-07-18
ER

PT J
AU Alterson, R
   Spetsakis, M
AF Alterson, R
   Spetsakis, M
TI Object recognition with adaptive Gabor features
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE adaptive sampling; Gabor wavelets; object recognition
ID FILTER
AB We present a novel adaptive-sampling algorithm for spectral signature generation. Our algorithm is designed to increase inter-object discrimination and reduce feature-vector dimensionality. This algorithm is applied to a nonorthogonal-wavelet based multi-resolution object detection and recognition scheme. In this context we study and analyze the detection and identification of unknown objects in a complex background. Iterative optimization methods are employed to reduce computational demands during the learning phase. Our representation scheme takes into account all items in a given object library. It selects sample-point sets that maximize inter-object distance. Thus, the presented method increases identification robustness and can reduce the size of signature vectors. (C) 2004 Elsevier B.V. All rights reserved.
C1 York Univ, Dept Comp Sci, N York, ON M3J 1P3, Canada.
C3 York University - Canada
RP Spetsakis, M (corresponding author), York Univ, Dept Comp Sci, 4700 Keele St, N York, ON M3J 1P3, Canada.
EM rsa@sten.sunnybrook.utoronto.ca; minas@cs.yorku.ca
CR Alexandrov A. D., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P12, DOI 10.1117/12.205292
   Ben-Arie J, 2000, ELECTRON LETT, V36, P1764, DOI 10.1049/el:20001223
   BenArie J, 1997, PROC CVPR IEEE, P34, DOI 10.1109/CVPR.1997.609294
   BETKE M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P523, DOI 10.1109/ICCV.1995.466895
   Chen CC, 1996, PATTERN RECOGN LETT, V17, P1069, DOI 10.1016/0167-8655(96)00065-7
   CHUNG KC, 1999, P INT WORKSH REC AN, P53
   DAILEY MN, 1999, CS629 UCSD
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5
   Herpers R, 1998, INT J PATTERN RECOGN, V12, P381, DOI 10.1142/S0218001498000257
   Herpers R, 2001, IMAGE VISION COMPUT, V19, P793, DOI 10.1016/S0262-8856(00)00107-4
   Jain AK, 1997, PATTERN RECOGN, V30, P295, DOI 10.1016/S0031-3203(96)00068-4
   JAIN AK, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P264, DOI 10.1109/ICPR.1992.201769
   SCHIELE B, 1999, P INT C COMP VIS, V1, P177
   WELDON TP, 1998, IEEE INT C IM PROC C
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   WU V, 1997, P 2 INT C DIG LIB PH
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
NR 18
TC 10
Z9 10
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 1007
EP 1014
DI 10.1016/j.imavis.2004.03.010
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800007
DA 2024-07-18
ER

PT J
AU Rigoll, G
   Breit, H
   Wallhoff, F
AF Rigoll, G
   Breit, H
   Wallhoff, F
TI Robust tracking of persons in real-world scenarios using a statistical
   computer vision approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE person tracking; hidden Markov models; Kalman-filter; statistical object
   modeling; background adaptation
ID MODELS
AB In the following work we present a novel approach to robust and flexible person tracking using an algorithm that combines two powerful stochastic modeling techniques: the first one is the technique of so-called Pseudo-2D Hidden Markov Models (P2DHMMs) used for capturing the shape of a person within an image frame, and the second technique is the well-known Kalman-filtering algorithm, that uses the output of the P2DHMM for tracking the person by estimation of a bounding box trajectory indicating the location of the person within the entire video sequence. Both algorithms are cooperating together in an optimal way, and with this cooperative feedback, the proposed approach even makes the tracking of persons possible in the presence of background motions, for instance caused by moving objects such as cars, or by camera operations as e.g. panning or zooming. We consider this as a major advantage compared to most other tracking algorithms that are mostly not capable of dealing with background motion. Furthermore, the person to be tracked is not required to wear special equipment (e.g. sensors) or special clothing. Additionally, we show how our approach can be effectively extended in order to include on-line background adaptation. Our results are confirmed by several tracking examples in real scenarios, shown at the end of the article and provided on the web server of our institute. (C) 2003 Elsevier B.V. All rights reserved.
C1 Tech Univ Munich, Inst Human Machine Commun, D-80290 Munich, Germany.
C3 Technical University of Munich
RP Tech Univ Munich, Inst Human Machine Commun, Arcisstr 16, D-80290 Munich, Germany.
EM rigoll@ei.tum.de
OI Wallhoff, Frank/0000-0002-7791-3225
CR BAUMBERG AM, 1994, 9411 U LEEDS
   Black M. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P551, DOI 10.1109/ICCV.1999.791271
   BOBICK AF, 1996, P WORKSH APPL COMP V, V5
   BREIT H, 2001, P IEEE INT C IM PROC
   Cai Q., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P68, DOI 10.1109/ICPR.1996.546796
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Eickeler S, 2000, IMAGE VISION COMPUT, V18, P279, DOI 10.1016/S0262-8856(99)00055-4
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Grewal Mohinder S., 1993, Kalman filtering: Theory and Practice with MATLAB
   HARITAOGLU I, 1998, P IEEE INT C FAC GES
   Heisele B, 1998, INT C PATT RECOG, P1325, DOI 10.1109/ICPR.1998.711946
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Iketani A, 1998, INT C PATT RECOG, P74, DOI 10.1109/ICPR.1998.711083
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482
   MARCHANDMAILLET S, 1999, MMWP99XX EUR ECOM I
   Müller S, 1999, INT CONF ACOUST SPEE, P3489
   Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Segen J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P63, DOI 10.1109/ICPR.1996.546795
   SHAH M, 1997, MOTION RECOGNITION C
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xu LQ, 1996, INTERNATIONAL WORKSHOP ON NEURAL NETWORKS FOR IDENTIFICATION, CONTROL, ROBOTICS, AND SIGNAL/IMAGE PROCESSING - PROCEEDINGS, P145, DOI 10.1109/NICRSP.1996.542755
   YAMANE T, 1998, P IEEE INT C ROB AUT
NR 24
TC 4
Z9 5
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2004
VL 22
IS 7
BP 571
EP 582
DI 10.1016/j.imavis.2003.09.014
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RT
UT WOS:000221481000006
DA 2024-07-18
ER

PT J
AU Quan, L
   Wei, YC
   Lu, L
   Shum, HY
AF Quan, L
   Wei, YC
   Lu, L
   Shum, HY
TI Constrained planar motion analysis by decomposition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE SFM; planar motion; 1D camera; vision geometry; image-based rendering
AB General SFM methods give poor results for images captured by constrained motions such as planar motion. In this paper, we propose new SFM algorithms for images captured under a common but constrained planar motion: the image plane is perpendicular to the motion plane. We show that a 2D image captured under such constrained planar motion can be decoupled into two 1D images: one 1D projective and one 1D affine. We then introduce the 1D affine camera model for completing 1D camera models. Next, we describe new subspace reconstruction methods, and apply these methods to the images captured by concentric mosaics, which undergo a special case of constrained planar motion. Finally, we demonstrate both in theory and experiments the advantage of the decomposition method over the general SFM methods by incorporating the constrained motion into the earliest stage of motion analysis. (C) 2003 Elsevier B.V. All rights reserved.
C1 HKUST, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   Microsoft Res China, Beijing 100080, Peoples R China.
   Chinese Acad Sci, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China.
C3 Hong Kong University of Science & Technology; Microsoft; Chinese Academy
   of Sciences; Institute of Automation, CAS
RP HKUST, Dept Comp Sci, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.
EM quan@cs.ust.hk
RI Lu, Le/AAD-7619-2020
OI Lu, Le/0000-0002-6799-9416
CR ARMSTRONG M, 1996, THESIS U OXFORD UK
   ARMSTRONG M, 1996, LNCS, V1064, P3
   ASTOM K, 1996, THESIS LUND U
   Åström K, 2000, J MATH IMAGING VIS, V12, P121, DOI 10.1023/A:1008362322190
   BEARDSLEY P, 1995, EUR CHIN WORKSH GEOM, P214
   CHEN SE, 1995, QUICKTIME VR IMAGE B, P29
   FAUGERAS O, 1995, WORKSH REPR VIS SCEN, P37
   FAUGERAS O, 1998, P 5 EUR C COMP VIS F, P36
   FITZGIBBON AW, 1998, 3D STRUCTURE MULTIPL, P154
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   HARTLEY RI, 1995, P 5 INT C COMP VIS C, P887
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   MUNDY JL, 1992, ARTIF INT, P463
   Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346
   Quan L, 1997, IEEE T PATTERN ANAL, V19, P834, DOI 10.1109/34.608285
   QUAN L, 2001, P 8 INT C COMP VIS V, V2, P193
   SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567
   Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573
   Spetsakis M.E., 1990, PROC DARPA IU WORKSH, P271
   Szeliski Richard., 1997, P SIGGRAPH 97 COMPUT, P251, DOI DOI 10.1145/258734.258861
   Tomasi C., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P21, DOI 10.1109/WVM.1991.212792
   TRIGGS B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P338, DOI 10.1109/ICCV.1995.466920
   TRIGGS B, 2000, P EUR C COMP VIS, P522
   WILES C, 1996, P 4 EUR C COMP VIS C, V1065, P238
   ZHANG Z, 1994, 2273 INRIA
   [No title captured]
NR 26
TC 2
Z9 4
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2004
VL 22
IS 5
BP 379
EP 389
DI 10.1016/j.imavis.2003.11.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 806GN
UT WOS:000220422500003
DA 2024-07-18
ER

PT J
AU Gutiérrez, S
   Marroquín, JL
AF Gutiérrez, S
   Marroquín, JL
TI Robust approach for disparity estimation in stereo vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereo; disparity; occlusion; left-right disparity consistency;
   homogeneous regions; bayesian estimation; regularization; diffusion
ID ALGORITHM; DEPTH
AB In this paper, we present a robust probabilistic method for the estimation of stereo disparity. It is based in Bayesian estimation theory, with a prior Markov random field model for the assigned disparities. The optimal estimator is computed using a Gauss-Markov random field model for the corresponding posterior marginals, which results in a diffusion process in probability space. This process, with the appropriate boundary conditions, is also used to estimate disparity in problematic regions of stereo pairs, such as occluded areas and non-textured (homogeneous) regions. Experimental comparisons of the proposed approach with other state-of-the-art methods are presented as well. (C) 2003 Elsevier B.V. All rights reserved.
C1 Brigham Young Univ, Provo, UT 84602 USA.
   Ctr Invest Matemat, Guanajuato, Gto, Mexico.
C3 Brigham Young University; CIMAT - Centro de Investigacion en Matematicas
EM salvador@et.byu.edu; jlm@cimat.mx
RI Gutierrez, Susana/K-3835-2014
CR [Anonymous], 2 EUR C COMP VIS ECC
   [Anonymous], ACM COMPUTING SURVEY
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 1977, TECHNIQUES AUTOMATIC
   ARNOLD RD, 1983, AUTOMATED STEREO PRE
   BAKER HH, 1980, EDGE BASED STEREO CO, P168
   BELJUMEUR PN, 1992, P IEEE C COMP VIS PA, P506
   BHAT D, 1996, IEEE C COMP VIS PATT, P351
   Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296
   Blonde L, 1996, IEEE MULTIMEDIA, V3, P18, DOI 10.1109/93.502291
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097
   Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040
   CRUZ JM, 1995, NEURAL NETWORKS, V8, P805, DOI 10.1016/0893-6080(95)00017-T
   DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067
   FAUGERAS O, 1993, 2 DIMENSIONAL COMPUT
   FAUGERAS O, 1996, 3021 I NAT RECJ INF
   FIGUEROA HVR, 1993, THESIS U SUSSEX
   FLEET DJ, 1991, CVGIP-IMAG UNDERSTAN, V53, P198, DOI 10.1016/1049-9660(91)90027-M
   GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683
   GUTIERREZ S, 2001, THESIS CENTRO INVEST
   HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709
   Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   KANG SB, 1995, P 5 INT C COMP VIS, P88
   MAAS MAV, 1999, P IEEE COMP SOC C CO, P106
   MAEDA E, 1992, NEURAL NETWORKS, V2, P141
   MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029
   MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482
   MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449
   PRAZDNY K, 1985, BIOL CYBERN, V52, P93, DOI 10.1007/BF00363999
   Roy S, 1999, INT J COMPUT VISION, V34, P147, DOI 10.1023/A:1008192004934
   RYAN TW, 1980, OPT ENG, V19, P312, DOI 10.1117/12.7972515
   SCHARSTEIN D, 1996, IEEE COMP SOC C COMP, P353
   Szeliski R, 1999, INT J COMPUT VISION, V32, P45, DOI 10.1023/A:1008192912624
   SZELISKI R, 1985, SOLVING RANDOM DOT S, P284
   ter Haar Romeny B., 1994, GEOMETRY DRIVEN DIFF
   Tomasi C, 1998, IEEE T PATTERN ANAL, V20, P333, DOI 10.1109/34.667890
   Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184
NR 42
TC 18
Z9 20
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2004
VL 22
IS 3
BP 183
EP 195
DI 10.1016/j.imavis.2003.08.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 776RH
UT WOS:000189130100002
DA 2024-07-18
ER

PT J
AU Pan, X
   Zhai, H
   Yang, Y
   Chen, LH
   Li, AY
AF Pan, Xin
   Zhai, Hao
   Yang, You
   Chen, Lianhua
   Li, Anyu
TI Improving multi-focus image fusion through Noisy image and feature
   difference network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-focus image fusion; Deep learning; Diffusion process; Denoising
   diffusion probabilistic models
ID NEURAL-NETWORK
AB Limited by optical constraints, the acquisition of a comprehensive set of multi-focus images remains a challenge. Leveraging the intrinsic accuracy of focused images, the concept of multi-focus image fusion emerges. However, distinguishing between focused and defocused regions, despite their visual similarities, is complex due to the absence of direct numerical indicators. This study unveils a novel insight: noisy source images lead to more substantial information loss in focus areas than in defocused regions. This observation prompts us to exploit this discrepancy by introducing noise to the source images. Motivated by this discovery, we introduce the Feature Difference Network (DDMF) for Multi-Focus Image Fusion (MFIF), aiming to leverage the differences present within feature dimensions. The pioneering DDMF approach incorporates the diffusion process from the Denoising Diffusion Probabilistic Models, employing it as a mechanism to introduce Gaussian noise to source images. Furthermore, the denoising process enhances feature representation. This equips DDMF to effectively capture hidden differences within features, allowing precise categorization of each pixel. Our extensive experimental evaluation underscores the prowess of DDMF. Through both subjective visual assessment and objective evaluation metrics, DDMF emerges as a frontrunner, surpassing established state-of-the-art MFIF methods.
C1 [Pan, Xin; Zhai, Hao; Chen, Lianhua; Li, Anyu] Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.
   [Yang, You] Natl Ctr Appl Math Chongqing, Chongqing 401331, Peoples R China.
C3 Chongqing Normal University
RP Zhai, H (corresponding author), Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.
EM zhaihao@cqnu.edu.cn
FU National Natural Science Foundation of China [62003065]; Natural Science
   Foundation of Chongqing (General Program) [CSTB2022NSCQ-MSX1231];
   Science and Technology Research Program of Chongqing Municipal Education
   Commission [KJQN202200564, KJZD- K202200504]; Fund project of Chongqing
   Normal University [21XLB032]
FX This study was supported by Supported by the National Natural Science
   Foundation of China (Grant No. 62003065) ; the Natural Science
   Foundation of Chongqing (General Program) (Grant No.
   CSTB2022NSCQ-MSX1231) ; the Science and Technology Research Program of
   Chongqing Municipal Education Commission (Grant No. KJQN202200564) ; the
   Science and Technology Research Program of Chongqing Municipal Education
   Commission (Grant No. KJZD- K202200504) ; the Fund project of Chongqing
   Normal University (Grant No. 21XLB032) .
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Ayyoubzadeh SM, 2021, IEEE COMPUT SOC CONF, P388, DOI 10.1109/CVPRW53098.2021.00049
   Baranchuk D., 2021, arXiv
   Brempong EA, 2022, IEEE COMPUT SOC CONF, P4174, DOI 10.1109/CVPRW56347.2022.00462
   Chen J, 2022, IEEE T MULTIMEDIA, V24, P655, DOI 10.1109/TMM.2021.3057493
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Dong ZK, 2018, NEUROCOMPUTING, V308, P172, DOI 10.1016/j.neucom.2018.04.066
   Haghighat M, 2014, I C APPL INF COMM TE, P424
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Ho J, 2022, J MACH LEARN RES, V23, P1
   Hu XY, 2023, INFORM FUSION, V92, P127, DOI 10.1016/j.inffus.2022.11.014
   Jin X, 2018, SOFT COMPUT, V22, P6395, DOI 10.1007/s00500-017-2694-4
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li SS, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P167, DOI 10.1109/ICALIP.2008.4589989
   Li XS, 2021, SIGNAL PROCESS, V184, DOI 10.1016/j.sigpro.2021.108062
   Liu Y, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3124058
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Lugmayr A, 2022, PROC CVPR IEEE, P11451, DOI 10.1109/CVPR52688.2022.01117
   Ma BY, 2022, NEUROCOMPUTING, V470, P204, DOI 10.1016/j.neucom.2021.10.115
   Ma BY, 2021, NEURAL COMPUT APPL, V33, P5793, DOI 10.1007/s00521-020-05358-9
   Ma HY, 2020, IEEE T IMAGE PROCESS, V29, P8668, DOI 10.1109/TIP.2020.3018261
   Ma JY, 2022, IEEE-CAA J AUTOMATIC, V9, P1200, DOI 10.1109/JAS.2022.105686
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saharia C, 2023, IEEE T PATTERN ANAL, V45, P4713, DOI 10.1109/TPAMI.2022.3204461
   Vaswani A, 2017, ADV NEUR IN, V30
   Vishwakarma A, 2019, IEEE T INSTRUM MEAS, V68, P3367, DOI 10.1109/TIM.2018.2877285
   Wang C, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106253
   Wang YC, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116295
   Wang ZY, 2023, INT J COMPUT VISION, V131, P2529, DOI 10.1007/s11263-023-01806-w
   Xiao B, 2020, IEEE T MULTIMEDIA, V22, P285, DOI 10.1109/TMM.2019.2928516
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xu S, 2020, Arxiv, DOI arXiv:2002.04780
   Xydeas C, 2000, P SOC PHOTO-OPT INS, V4051, P89, DOI 10.1117/12.381668
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang L, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3626235
   You CS, 2022, DISPLAYS, V72, DOI 10.1016/j.displa.2021.102146
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zhang H, 2021, INFORM FUSION, V76, P323, DOI 10.1016/j.inffus.2021.06.008
   Zhang H, 2021, INT J COMPUT VISION, V129, P2761, DOI 10.1007/s11263-021-01501-8
   Zhang H, 2021, INFORM FUSION, V66, P40, DOI 10.1016/j.inffus.2020.08.022
   Zhang XC, 2022, IEEE T PATTERN ANAL, V44, P4819, DOI 10.1109/TPAMI.2021.3078906
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang YX, 2021, PROC CVPR IEEE, P10140, DOI 10.1109/CVPR46437.2021.01001
   Zhao J., 2006, International journal of innovative computing, information & control: IJICIC, V3
NR 49
TC 0
Z9 0
U1 9
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2024
VL 142
AR 104891
DI 10.1016/j.imavis.2023.104891
EA DEC 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IJ3R6
UT WOS:001165923700001
DA 2024-07-18
ER

PT J
AU Deng, FQ
   Zhong, JM
   Li, NN
   Fu, LH
   Wang, D
   Lam, TL
AF Deng, Fuqin
   Zhong, Jiaming
   Li, Nannan
   Fu, Lanhui
   Wang, Dong
   Lam, Tin Lun
TI Exploring cross-video matching for few-shot video classification via
   dual-hierarchy graph neural network learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video classification; Few-shot learning; Hierarchy graph neural network
AB Few-shot video classification methods aim to recognize a new class with only a few training examples. Distinct from previous few-shot methods, we explicitly consider the relations in cross-video domains and take full advantage of the cross-video frame matching in a hierarchy learning fashion. In this paper, we propose a DualHierarchy Graph Neural Network to realize comprehensive cross-video frame matching and video relation modeling. In the first hierarchy of the graph neural network, we build a Cross-video Frame Matching Graph to extract robust frame-level features via accumulating information across frames sampled from both query and support videos. Then, frame representations are accumulated to obtain the video-level features. In the second hierarchy of the graph neural network, we construct a Video Relation Graph by taking the video-level features as nodes, which can adaptively learn positive relations between query and support videos. We get the predicted label of the query video through the matching learning of edges connecting video nodes. We evaluate the model on three benchmarks: HMDB51, Kinetics, and UCF101. Extensive experiments on benchmark datasets demonstrate that our model significantly improves few-shot video classification across a wide range of competitive baselines and showcases the strong generalization of our framework. The source code and models will be publicly available at https://github.com/JiaMingZhong2621/DHGNN.
C1 [Deng, Fuqin; Zhong, Jiaming; Fu, Lanhui; Wang, Dong] Wuyi Univ, Sch Intelligent Mfg, Jiangmen, Peoples R China.
   [Li, Nannan] Macau Univ Sci & Technol, Fac Innovat Engn, Sch Comp Sci & Engn, Macau, Peoples R China.
   [Deng, Fuqin; Lam, Tin Lun] Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen, Peoples R China.
   [Deng, Fuqin; Lam, Tin Lun] 3irobotix Co Ltd, Shenzhen, Peoples R China.
   [Lam, Tin Lun] Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen, Peoples R China.
C3 Wuyi University; Macau University of Science & Technology; Shenzhen
   Institute of Artificial Intelligence & Robotics for Society; The Chinese
   University of Hong Kong, Shenzhen
RP Li, NN (corresponding author), Macau Univ Sci & Technol, Fac Innovat Engn, Sch Comp Sci & Engn, Macau, Peoples R China.
EM nnli@must.edu.mo
RI wei, wang/KHY-7669-2024
FU National Key R&D Program of China [2020YFB1313300]; Wuyi University-Hong
   Kong-Macau Joint-Funding-Scheme [2022WGALH17, 2021WGALH18]; Macau
   University of Science and Technology [FRG-22-102-FIE]; Shenzhen
   Institute of Artificial Intelligence and Robotics for Society
   [AC01202101103]; Shenzhen Peacock Plan of Shenzhen Science and
   Technology Program [KQTD2016113010470345]; National Natural Science
   Foundation of China [62073274]; Wuyi University [BSQD2222]
FX This work was supported in part by the National Key R&D Program of China
   (2020YFB1313300) , Wuyi University-Hong Kong-Macau Joint-Funding-Scheme
   (2022WGALH17,2021WGALH18) , the funding for General Scientific Research
   of Macau University of Science and Technology (Grant No. FRG-22-102-FIE)
   , the funding from the Shenzhen Institute of Artificial Intelligence and
   Robotics for Society (AC01202101103) , Shenzhen Peacock Plan of Shenzhen
   Science and Technology Program (KQTD2016113010470345) , National Natural
   Science Foundation of China (62073274) , and PhD Research start-up Fund
   of Wuyi University (No. BSQD2222) .
CR Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Bishay M., 2019, ARXIV190709021
   Cao JZ, 2023, IMAGE VISION COMPUT, V137, DOI 10.1016/j.imavis.2023.104757
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen SX, 2017, Arxiv, DOI arXiv:1707.00803
   Defferrard M, 2016, ADV NEUR IN, V29
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gordon J, 2019, Arxiv, DOI arXiv:1805.09921
   Gori M, 2005, IEEE IJCNN, P729
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Henaff M., 2015, arXiv
   Hu YF, 2021, IEEE T MULTIMEDIA, V23, P4285, DOI 10.1109/TMM.2020.3039329
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Kaidi Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10615, DOI 10.1109/CVPR42600.2020.01063
   Kim J, 2019, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2019.00010
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li SY, 2022, AAAI CONF ARTIF INTE, P1404
   Ling Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13387, DOI 10.1109/CVPR42600.2020.01340
   Miller A, 2016, Arxiv, DOI arXiv:1606.03126
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Perrett T, 2021, PROC CVPR IEEE, P475, DOI 10.1109/CVPR46437.2021.00054
   Ravi S, 2016, PROC INT C LEARN REP
   Santoro A, 2016, PR MACH LEARN RES, V48
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang SM, 2023, IMAGE VISION COMPUT, V136, DOI 10.1016/j.imavis.2023.104736
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Zhang H., 2020, P EUR C COMP VIS, P525
   Zheng SP, 2022, LECT NOTES COMPUT SC, V13664, P297, DOI 10.1007/978-3-031-19772-7_18
   Zhu LC, 2018, LECT NOTES COMPUT SC, V11211, P782, DOI 10.1007/978-3-030-01234-2_46
   Zhu XT, 2021, Arxiv, DOI arXiv:2101.08085
NR 41
TC 1
Z9 1
U1 3
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104822
DI 10.1016/j.imavis.2023.104822
EA SEP 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA U6VF3
UT WOS:001086155300001
DA 2024-07-18
ER

PT J
AU Liu, YB
   Chen, CY
AF Liu, Yunbiao
   Chen, Chunyi
TI MODE: Monocular omnidirectional depth estimation via consistent depth
   fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Omnidirectional depth estimation; Depth initialization; Long-range
   dependency
AB Monocular depth estimation has seen significant progress in recent years, especially in outdoor scenes. However, depth estimation results are not satisfying in omnidirectional images. As compared to perspective images, esti-mating the depth map from an omnidirectional image captured in the outdoor scene, using neural networks, has two additional challenges: (i) the depth range of outdoor images varies a lot across different scenes, making it difficult for the depth network to predict accurate depth results for training with an indoor dataset, besides the maximum distance in outdoor scenes mostly stays the same as the camera sees the sky, but depth labels in this region are entirely missing in existing datasets; (ii) a standard representation of omnidirectional images intro-duces spherical distortion, which causes difficulties for the vanilla network to predict accurate relative structural depth details. In this paper, we propose a novel network-MODE by giving special considerations to those challenges and designing a set of flexible modules for improving the performance of omnidirectional depth esti-mation. First, a consistent depth structure module is proposed to estimate a consistent depth structure map, and the predicted structural map can improve depth details. Second, to suit the characteristics of spherical sampling, we propose a strip convolution fusion module to enhance long-range dependencies. Third, rather than using a single depth decoder branch as in previous methods, we propose a semantics decoder branch to estimate sky re-gions in the omnidirectional image. The proposed method is validated on three widely used datasets, demon-strating the state-of-the-art performance. Moreover, the effectiveness of each module is shown through an ablation study on real-world datasets. Our code is available at https://github.com/lkku1/MODE.& COPY; 2017 Elsevier Inc. All rights reserved. & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Liu, Yunbiao; Chen, Chunyi] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130022, Peoples R China.
C3 Changchun University of Science & Technology
RP Chen, CY (corresponding author), Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130022, Peoples R China.
EM chenchunyi@hotmail.com
FU National Natural Science Foundation of China [U19A2063]; Jilin
   Provincial Science amp; Technology Development Program of China
   [20230201080GX]
FX Acknowledgements This work was supported partially by the National
   Natural Science Foundation of China under Grant U19A2063 and partially
   by the Jilin Provincial Science & Technology Development Program of
   China under Grant 20230201080GX.
CR Armeni I., 2017, arXiv
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Chen HX, 2021, IEEE SIGNAL PROC LET, V28, P334, DOI 10.1109/LSP.2021.3050712
   Chen LC, 2018, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2018.00422
   Cui Y., 2022, WACV, P3411, DOI 10.1109/WACV51458
   Eigen D, 2014, ADV NEUR IN, V27
   Fang YM, 2022, AAAI CONF ARTIF INTE, P580
   Feng Q, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P664, DOI 10.1109/VR51125.2022.00087
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Handa A, 2016, IEEE INT CONF ROBOT, P5737, DOI 10.1109/ICRA.2016.7487797
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu JJ, 2019, IEEE I CONF COMP VIS, P3868, DOI 10.1109/ICCV.2019.00397
   Jiang HL, 2021, IEEE ROBOT AUTOM LET, V6, P1519, DOI 10.1109/LRA.2021.3058957
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee Y, 2019, PROC CVPR IEEE, P9173, DOI 10.1109/CVPR.2019.00940
   Li RZ, 2023, IEEE T CIRC SYST VID, V33, P830, DOI 10.1109/TCSVT.2022.3207105
   Li YY, 2022, PROC CVPR IEEE, P2791, DOI 10.1109/CVPR52688.2022.00282
   Lin DY, 2020, IEEE IMAGE PROC, P2131, DOI 10.1109/ICIP40778.2020.9190900
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Miangoleh S. Mahdi H., 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P9680, DOI 10.1109/CVPR46437.2021.00956
   Peng CH, 2023, IEEE WINT CONF APPL, P3115, DOI 10.1109/WACV56688.2023.00313
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pintore G, 2021, PROC CVPR IEEE, P11531, DOI 10.1109/CVPR46437.2021.01137
   Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Rao S, 2021, IEEE COMPUT SOC CONF, P3701, DOI 10.1109/CVPRW53098.2021.00411
   Rey-Area M, 2022, PROC CVPR IEEE, P3752, DOI 10.1109/CVPR52688.2022.00374
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Serrano A, 2019, IEEE T VIS COMPUT GR, V25, P1817, DOI 10.1109/TVCG.2019.2898757
   Shen Z., 2022, COMPUTER VISION ECCV, V13661
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Su YC, 2017, ADV NEUR IN, V30
   Su YC, 2019, PROC CVPR IEEE, P9434, DOI 10.1109/CVPR.2019.00967
   Sun C, 2021, PROC CVPR IEEE, P2573, DOI 10.1109/CVPR46437.2021.00260
   Sun C, 2021, PROC CVPR IEEE, P11333, DOI 10.1109/CVPR46437.2021.01118
   Tateno K, 2018, LECT NOTES COMPUT SC, V11220, P732, DOI 10.1007/978-3-030-01270-0_43
   Wang FE, 2020, PROC CVPR IEEE, P459, DOI 10.1109/CVPR42600.2020.00054
   Yuan WH, 2022, PROC CVPR IEEE, P3906, DOI 10.1109/CVPR52688.2022.00389
   Zhuang CQ, 2022, AAAI CONF ARTIF INTE, P3653
   Zioulis N, 2018, LECT NOTES COMPUT SC, V11210, P453, DOI 10.1007/978-3-030-01231-1_28
NR 41
TC 0
Z9 0
U1 10
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104723
DI 10.1016/j.imavis.2023.104723
EA JUN 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA L9UK1
UT WOS:001026648400001
DA 2024-07-18
ER

PT J
AU Lin, XY
   Zhou, YJ
   Liu, YP
   Zhu, C
AF Lin, Xinyu
   Zhou, Yingjie
   Liu, Yipeng
   Zhu, Ce
TI A dedicated benchmark for contour-based corner detection evaluation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Contour; curve analysis; Corner detection; Dominant point detection;
   Low-level computer vision; Performance evaluation
ID DOMINANT POINT DETECTION; CURVATURE SCALE-SPACE; MULTISCALE; DIFFERENCE;
   BOUNDARY
AB Numerous contour-based corner detection (CBCD) algorithms have been proposed recently, necessitating effective and practical evaluation. Most existing methods evaluate corner detection accuracy through metrics between the testing image and its attacked versions or rely on image-specific ground truth for corner evaluation. These methods use images as input, failing to solely evaluate the corner detection performance but combining it with contour extraction evaluation. Since contour extraction is another important research topic and existing CBCD algorithms almost have no contribution to contour extraction, this intertwining may negatively impact the evaluation results, hindering corner detection development. Furthermore, most evaluation methods directly provide simple statistical scores of evaluation metrics, such as the mean value, which are inadequate to reflect the overall performance distribution. This study presents a novel benchmark that is specifically designed for assessing CBCD methods, which includes two major contributions. Firstly, we design two dedicated datasets, one with the ground-truth corner and the other without them. The dedicated contours instead of images are employed as input to evaluate numerous CBCD methods, eliminating the impact of the extracted contour quality. When the ground-truth corners are unavailable, we employ additional contour attacks, including Gaussian noise, projective, and combined geometry on contours, to simulate real-world complex image processes compared with the attacks in existing evaluation methods. Secondly, we evaluate the performance of twelve CBCD methods using six distinct metrics based on the constructed contour datasets. To gain a deep insight into the overall performance distribution, the sign test method for hypothesis testing is utilized alongside some simple statistical measures for evaluation metric analysis. Experimental results demonstrated that no individual method performs the best across all six evaluation metrics, while different CBCD algorithms have their positive scenarios. The evaluation code will be publicly available at https://github.com/roylin1229/CBCD_eva.& COPY; 2023 Published by Elsevier B.V.
C1 [Lin, Xinyu; Liu, Yipeng; Zhu, Ce] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, 2006, Xiyuan Ave, West Hitech Zone, Chengdu 611731, Sichuan, Peoples R China.
   [Zhou, Yingjie] Sichuan Univ, Coll Comp Sci, 24 South Sect 1,Yihuan Rd, Chengdu 610065, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; Sichuan
   University
RP Zhu, C (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Commun Engn, 2006, Xiyuan Ave, West Hitech Zone, Chengdu 611731, Sichuan, Peoples R China.
EM eczhu@uestc.edu.cn
RI ZHOU, YINGJIE/KLE-8614-2024; Lin, Xinyu/HIZ-6071-2022
FU National Natural Science Foundation of China (NSFC) [U19A2052, 62171088,
   62171302]; Sichuan Youth Science and Technology Innovation Team
   [2022-JDTD0014]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant U19A2052, Grant 62171088, and
   Grant 62171302, and by the Sichuan Youth Science and Technology
   Innovation Team under Grant 2022-JDTD0014.
CR Afrin N., 2017, INT C CENTR EUR COMP
   Aldana-Iuit J, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2019.08.011
   ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472
   [Anonymous], 2011, INT ENCY STAT SCI, DOI [DOI 10.1007/978-3-642-04898-2_420, 10.1007/978-3-642-04898-2_420]
   Awrangjeb M, 2008, IEEE T IMAGE PROCESS, V17, P2425, DOI 10.1109/TIP.2008.2006441
   Awrangjeb M, 2008, IEEE T MULTIMEDIA, V10, P1059, DOI 10.1109/TMM.2008.2001384
   Awrangjeb M, 2012, IEEE T IMAGE PROCESS, V21, P4167, DOI 10.1109/TIP.2012.2200493
   Awrangjeb M, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P519, DOI 10.1109/DICTA.2009.91
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carmona-Poyato A, 2005, IMAGE VISION COMPUT, V23, P1226, DOI 10.1016/j.imavis.2005.07.025
   Dede MA, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104495
   Fan B, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104492
   Fanani N, 2017, IMAGE VISION COMPUT, V68, P3, DOI 10.1016/j.imavis.2017.08.002
   Gao XT, 2007, IMAGE VISION COMPUT, V25, P890, DOI 10.1016/j.imavis.2006.07.002
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He XC, 2008, OPT ENG, V47, DOI 10.1117/1.2931681
   Hollander M., 2015, Nonparametric statistical methods, DOI [DOI 10.1002/9781119196037, 10.1002/9781119196037, DOI 10.1002/9781119196037.CH12]
   Jing JF, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118673
   Jing JF, 2023, IEEE T PATTERN ANAL, V45, P4694, DOI 10.1109/TPAMI.2022.3201185
   Lin XY, 2019, MULTIMED TOOLS APPL, V78, P177, DOI 10.1007/s11042-017-5606-9
   Lin XY, 2017, IEEE SIGNAL PROC LET, V24, P1393, DOI 10.1109/LSP.2017.2724851
   Masood A, 2008, IMAGE VISION COMPUT, V26, P702, DOI 10.1016/j.imavis.2007.08.006
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Mokhtarian F, 2006, COMPUT VIS IMAGE UND, V102, P81, DOI 10.1016/j.cviu.2005.11.001
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   Nachar R, 2023, MULTIMED TOOLS APPL, V82, P39459, DOI 10.1007/s11042-023-15053-1
   Pandey A, 2019, IMAGE VISION COMPUT, V89, P236, DOI 10.1016/j.imavis.2019.07.002
   Pedrosa GV, 2010, PATTERN RECOGN LETT, V31, P1658, DOI 10.1016/j.patrec.2010.05.013
   Prasad DK, 2012, IMAGE VISION COMPUT, V30, P843, DOI 10.1016/j.imavis.2012.06.010
   RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805
   ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Sezer A, 2021, SOLDER SURF MT TECH, V33, P291, DOI 10.1108/SSMT-04-2021-0013
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Sun X, 2023, IEEE SIGNAL PROC LET, V30, P50, DOI 10.1109/LSP.2023.3240371
   Teng SW, 2015, PATTERN RECOGN, V48, P2185, DOI 10.1016/j.patcog.2015.01.016
   Topal C, 2013, INT CONF ACOUST SPEE, P1444, DOI 10.1109/ICASSP.2013.6637890
   Tsai DM, 1999, PATTERN RECOGN LETT, V20, P31, DOI 10.1016/S0167-8655(98)00130-5
   TSANG WM, 1994, IMAGE VISION COMPUT, V12, P547, DOI 10.1016/0262-8856(94)90009-4
   Wan CL, 2023, VISUAL COMPUT, V39, P2499, DOI 10.1007/s00371-022-02474-6
   Wong D, 2017, IMAGE VISION COMPUT, V68, P53, DOI 10.1016/j.imavis.2017.07.004
   Wu WY, 2003, IMAGE VISION COMPUT, V21, P517, DOI 10.1016/S0262-8856(03)00031-3
   Yag I, 2022, BIOLOGY-BASEL, V11, DOI 10.3390/biology11121732
   Yang DP, 2022, NEUROCOMPUTING, V488, P470, DOI 10.1016/j.neucom.2022.02.079
   Zha Xinjing, 2023, Proceedings of SPIE, DOI 10.1117/12.2669973
   Zhang SZ, 2022, ALEX ENG J, V61, P8585, DOI 10.1016/j.aej.2022.01.068
   Zhang SZ, 2021, J ENG-JOE, V2021, P762, DOI 10.1049/tje2.12071
   Zhang SZ, 2020, IEEE ACCESS, V8, P66741, DOI 10.1109/ACCESS.2020.2984566
   Zhang SX, 2019, MULTIMED TOOLS APPL, V78, P25685, DOI 10.1007/s11042-019-07792-x
   Zhang WC, 2023, IEEE T PATTERN ANAL, V45, P9883, DOI 10.1109/TPAMI.2023.3240129
   Zhang WC, 2019, IEEE T IMAGE PROCESS, V28, P4444, DOI 10.1109/TIP.2019.2910655
   Zhang XH, 2007, PATTERN RECOGN LETT, V28, P545, DOI 10.1016/j.patrec.2006.10.006
   Zhang XH, 2010, PATTERN RECOGN, V43, P1207, DOI 10.1016/j.patcog.2009.10.017
   Zhang XH, 2009, PATTERN RECOGN LETT, V30, P449, DOI 10.1016/j.patrec.2008.11.002
   Zhong BJ, 2007, IEEE T PATTERN ANAL, V29, P508, DOI 10.1109/TPAMI.2007.50
NR 56
TC 1
Z9 1
U1 4
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104716
DI 10.1016/j.imavis.2023.104716
EA JUN 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA K6BM1
UT WOS:001017272800001
DA 2024-07-18
ER

PT J
AU Zhe, X
   Du, ZK
   Lou, CW
   Li, JJ
AF Zhe, Xiao
   Du, Zhekai
   Lou, Chunwei
   Li, Jingjing
TI Alleviating the generalization issue in adversarial domain adaptation
   networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Domain adaptation; Transfer learning; Adversarial learning
ID KERNEL
AB Recently, adversarial learning has dominated domain adaptation, which is a popular branch of transfer learning. The basic idea of adversarial domain adaptation networks (ADAN) is to learn domain-invariant features which is able to confuse the domain discriminator. By sharing the spirit of generative adversarial networks (GANs), ADAN achieved state-of-the-art performance. However, ADAN also inherits the drawbacks of GANs. One of the most critical issues of GANs is that the learned distribution may be far from the expected one even if the training is suc-cessful, which is known as the generalization issue in GANs. As a result, it is no guarantee that the learned repre-sentations are domain-invariant even if the domain discriminator is successfully confused. To address this, we propose a new domain adaptation approach under the framework of ADAN. Specifically, we reformulate the con-ventional ADAN and propose ADAN plus metric protocol under the new ADAN formulation, ADANM for short, which leverages both adversarial learning and metric learning. The proposed method, on one hand, challenges the generalization issue in previous ADAN approaches. On the other hand, it guarantees that domain divergence is minimized during the adversarial training. Extensive experiments on three public benchmarks verify that the proposed protocol is favorable for unsupervised domain adaptation tasks.& COPY; 2023 Published by Elsevier B.V.
C1 [Du, Zhekai; Lou, Chunwei; Li, Jingjing] Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China.
   [Zhe, Xiao] China Elect Technol Grp Corp, Sci & Technol Commun Networks Lab, Res Inst 54, Shijiazhuang, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; China
   Electronics Technology Group
RP Lou, CW; Li, JJ (corresponding author), Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China.
EM lijin117@yeah.net
RI Li, Jingjing/T-6522-2019
FU CETC Innovation Foundation of Science and Technology [SCX21641X002]
FX This work was supported by CETC Innovation Foundation of Science and
   Technology under grant No. SCX21641X002.
CR Arora S., 2017, Generalization and equilibrium in generative adversarial nets (GANs) [Conference proceedings]. In International Conference on Machine Learning, 70, P224
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Chen C, 2019, AAAI CONF ARTIF INTE, P3296
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004
   Ganin Y, 2015, Arxiv, DOI arXiv:1409.7495
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Huang J., CVPR 2022, P1203
   Li JJ, 2022, IEEE T KNOWL DATA EN, V34, P5770, DOI 10.1109/TKDE.2021.3060473
   Li JJ, 2022, IEEE T PATTERN ANAL, V44, P8196, DOI 10.1109/TPAMI.2021.3109287
   Li JJ, 2021, IEEE T PATTERN ANAL, V43, P3918, DOI 10.1109/TPAMI.2020.2991050
   Li YC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4091, DOI 10.1145/3474085.3475540
   Liu JY, 2023, IEEE T MULTIMEDIA, V25, P9356, DOI 10.1109/TMM.2023.3251094
   Liu M.-Y., 2016, P ADV NEUR INF PROC, P469
   Liu MY, 2017, ADV NEUR IN, V30
   Long M., 2017, PMLR, P2208
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peng X., 2017, ARXIV
   Russakovsky O., 2015, INT J COMPUT VISION, V115, P211
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Sugiyama M, 2007, J MACH LEARN RES, V8, P985
   Tzeng E, 2014, Arxiv, DOI [arXiv:1412.3474, 10.48550/arXiv.1412.3474, DOI 10.48550/ARXIV.1412.3474]
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Yang X, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1, DOI 10.1145/3404835.3462823
   Yu ZQ, 2023, IEEE T CIRC SYST VID, V33, P3398, DOI 10.1109/TCSVT.2022.3230963
NR 38
TC 1
Z9 1
U1 6
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104695
DI 10.1016/j.imavis.2023.104695
EA JUN 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA K5JQ2
UT WOS:001016804100001
DA 2024-07-18
ER

PT J
AU Zhu, WJ
   Feng, HD
   Yi, Y
   Zhang, MY
AF Zhu, Wenjun
   Feng, Haida
   Yi, Yang
   Zhang, Mengyi
TI FCR-TrackNet: Towards high-performance 6D pose tracking with multi-level
   features fusion and joint classification-regression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object pose tracking; Deep learning; Feature fusion; Multi -task
   learning; Classification smoothing label
AB Tracking an object's 6D pose is significant in various real-world applications, such as robotic grasping, virtual reality, and self-driving. Still the existing methods suffer from following challenges: i) geometric shapes, such as rotational symmetry shapes, and ii) complex scenes, for instance, cluttered backgrounds and occluded scenes. To tackle these problems, we propose FCR-TrackNet, a novel tracking network that utilizes a residual iterative framework with low-and high-level feature fusion and joint classification-regression. FCR-TrackNet inputs the rendered RGB-D image from the previous frame pose and the current RGB-D image to extract low-level features. Then, high-level features are also obtained by the convolutional network and fused with low-level one to capture subtle variations in target object features across adjacent frames. To reduce computational complexity and ensure high tracking speed, we adopt decoupled branches to estimate the translation and rotation of the pose independently. At last, a joint classification-regression is designed to address the boundary problem of the rotation angle. We introduce a smooth classification label that effectively enhances the accuracy of rotation vector classification. We evaluate the performance of FCR-TrackNet on two well-known datasets, YCB-Video and YCBInEOAT. FCR-TrackNet achieves state-of-the-art ADD values of 94.5% and 93.2%, and ADD-S values of 96.7% and 96.0%, respectively, with a tracking speed of 89.6 Hz. It also outperforms competing algorithms in target pose tracking in occlusion and rotational symmetry shapes. The quantitative and qualitative results validate the high performance of FCR-TrackNet on 6D pose tracking.
C1 [Zhu, Wenjun; Feng, Haida; Yi, Yang; Zhang, Mengyi] Nanjing Tech Univ, Coll Elect Engn & Control Sci, Nanjing 211816, Peoples R China.
C3 Nanjing Tech University
RP Yi, Y (corresponding author), Nanjing Tech Univ, Coll Elect Engn & Control Sci, Nanjing 211816, Peoples R China.
EM yiyang@njtech.edu.cn
FU National Key Research and Development Program of China [2021YFB3301300];
   Natural Science Foundation of the Higher Education Institutions of
   Jiangsu Province of China [21KJB520007]
FX Funding This article was partially supported by the National Key
   Research and Development Program of China (No.2021YFB3301300) , Natural
   Science Foundation of the Higher Education Institutions of Jiangsu
   Province of China (No.21KJB520007) .
CR Adimoolam M, 2022, INT J INTERACT MULTI, V7, P112, DOI 10.9781/ijimai.2022.01.002
   Azad Pedram, 2011, IEEE International Conference on Robotics and Automation, P5204
   Barfoot T.D., 2017, State Estimation for Robotics, DOI [10.1017/9781316671528, DOI 10.1017/9781316671528]
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng XK, 2021, IEEE T ROBOT, V37, P1328, DOI 10.1109/TRO.2021.3056043
   Do TT, 2018, Arxiv, DOI [arXiv:1802.10367, 10.48550/ARXIV.1802.10367, DOI 10.48550/ARXIV.1802.10367]
   Garon M, 2017, IEEE T VIS COMPUT GR, V23, P2410, DOI 10.1109/TVCG.2017.2734599
   Han W, 2022, INT J INTERACT MULTI, V7, P23, DOI 10.9781/ijimai.2022.07.003
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YS, 2021, PROC CVPR IEEE, P3002, DOI 10.1109/CVPR46437.2021.00302
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Issac J, 2016, IEEE INT CONF ROBOT, P608, DOI 10.1109/ICRA.2016.7487184
   Kanezaki A, 2018, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR.2018.00526
   Karasu S., 2022, INT MED C
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Labbe Yann, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P574, DOI 10.1007/978-3-030-58520-4_34
   Li Y, 2018, LECT NOTES COMPUT SC, V11210, P695, DOI [10.1007/s11263-019-01250-9, 10.1007/978-3-030-01231-1_42]
   Liang GY, 2021, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.616775
   Majcher M, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 5: VISAPP, P690, DOI 10.5220/0009365706900697
   Manhardt F, 2018, LECT NOTES COMPUT SC, V11218, P833, DOI 10.1007/978-3-030-01264-9_49
   Marougkas Isidoros, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P682, DOI 10.1007/978-3-030-66096-3_45
   Pan HR, 2022, COMPUT GRAPH FORUM, V41, P371, DOI 10.1111/cgf.14684
   Paszke A, 2019, ADV NEUR IN, V32
   Poirson P, 2016, INT CONF 3D VISION, P676, DOI 10.1109/3DV.2016.78
   Sezer Ali, 2021, 2021 3rd International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA), DOI 10.1109/HORA52670.2021.9461342
   Sezer A, 2021, SOLDER SURF MT TECH, V33, P291, DOI 10.1108/SSMT-04-2021-0013
   Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wang G, 2021, PROC CVPR IEEE, P16606, DOI 10.1109/CVPR46437.2021.01634
   Wang Y., 2019, 2019 IEEE INT C ROB, P284
   Wen BW, 2020, IEEE INT C INT ROBOT, P10367, DOI 10.1109/IROS45743.2020.9341314
   Wüthrich M, 2013, IEEE INT C INT ROBOT, P3195, DOI 10.1109/IROS.2013.6696810
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yag I, 2022, BIOLOGY-BASEL, V11, DOI 10.3390/biology11121732
   Yang X, 2022, INT J COMPUT VISION, V130, P1340, DOI 10.1007/s11263-022-01593-w
   Yang X, 2018, IEEE ACCESS, V6, P50839, DOI 10.1109/ACCESS.2018.2869884
NR 38
TC 1
Z9 1
U1 4
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104698
DI 10.1016/j.imavis.2023.104698
EA MAY 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA J5OM8
UT WOS:001010110100001
DA 2024-07-18
ER

PT J
AU Ibrahim, Y
   Benedek, C
AF Ibrahim, Yahya
   Benedek, Csaba
TI MVPCC-Net: Multi-View Based Point Cloud Completion Network for MLS data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-view; 3D point cloud completion; Deep learning; Mobile laser
   scanning
AB In this paper, we introduce a novel multi view-based method for completing high-resolution 3D point clouds of partial object shapes obtained by mobile laser scanning (MLS) platforms. Our approach estimates both the geom-etry and color cues of the missing or incomplete object segments, by projecting the 3D input point cloud by mul-tiple virtual cameras, and performing 2D inpainting in the image domains of the different views. In contrast to existing state-of-the-art methods, our method can generate point clouds consisting of a variable number of points, depending on the detailedness of the input measurement, which property highly facilitates the efficient processing of MLS data with inhomogeneous point density. For training and quantitative evaluation of the pro-posed method, we provide a new point cloud dataset that consists of both synthetic point clouds of four different street objects with accurate ground truth, and real MLS measurements of partially or fully scanned vehicles. The quantitative and qualitative experiments on the provided dataset demonstrate that our method surpasses state-of-the-art approaches in reconstructing the local fine geometric structures as well as in estimating the overall shape and color pattern of the objects.(c) 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Ibrahim, Yahya; Benedek, Csaba] Inst Comp Sci & Control SZTAK, Kende u 13-17, H-1111 Budapest, Hungary.
   [Ibrahim, Yahya; Benedek, Csaba] Peter Pazmany Catholic Univ, Fac Informat Technol & Bion, Prater u 50-A, H-1083 Budapest, Hungary.
C3 Pazmany Peter Catholic University
RP Ibrahim, Y (corresponding author), Inst Comp Sci & Control SZTAK, Kende u 13-17, H-1111 Budapest, Hungary.
EM ibrahim.yahya@sztaki.hu
OI Ibrahim, Yahya/0000-0003-0131-985X
FU European Union [RRF- 2.3.1-21-2022-00002]; Artificial Intelligence
   National Laboratory (MILAB) programs;  [TKP2021-NVA-01];  [OTKA K-
   143274]
FX The research work was supported by the European Union within the
   framework of the National Laboratory for Autonomous Systems (RRF-
   2.3.1-21-2022-00002) and the Artificial Intelligence National Laboratory
   (MILAB) programs, and by the TKP2021-NVA-01, and OTKA K- 143274 projects
   of the Hungarian NRDI Office.
CR Bolkas D, 2020, INT J IMAGE DATA FUS, V11, P136, DOI 10.1080/19479832.2020.1716861
   Boulch A., 2017, EUROGRAPHICS WORKSHO, V2
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gong Z., 2022, P IEEECVF C COMPUTER, P1726
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hadi Normi Abdul, 2021, Journal of Physics: Conference Series, V1770, DOI 10.1088/1742-6596/1770/1/012006
   Hariz F., 2021, IEEE INT S ROB SENS, P1, DOI [10.1109/ROSE52750.2021.9611774, DOI 10.1109/ROSE52750.2021.9611774]
   Ibrahim Y, 2022, INT C PATT RECOG, P2121, DOI 10.1109/ICPR56361.2022.9956459
   Ibrahim Y, 2021, INT C PATT RECOG, P3178, DOI 10.1109/ICPR48806.2021.9413009
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jaritz M, 2019, IEEE INT CONF COMP V, P3995, DOI 10.1109/ICCVW.2019.00494
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D, 2014, ICLR P, V2014, P1
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu ZB, 2022, ADV INF TECHNOL ELEC, P452, DOI 10.1109/IAEAC54830.2022.9929938
   Moenning C., 2003, EUROGRAPHICS POSTERS, DOI DOI 10.2312/EGP.20031024
   Nagy B, 2019, IEEE SENS J, V19, P10034, DOI 10.1109/JSEN.2019.2927269
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Nie Y., 2020, Advances in Neural Information Processing Systems, V33, P16119
   Qi CR, 2017, ADV NEUR IN, V30
   Rock J, 2015, PROC CVPR IEEE, P2484, DOI 10.1109/CVPR.2015.7298863
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tagliasacchi A, 2011, COMPUT GRAPH FORUM, V30, P1563, DOI 10.1111/j.1467-8659.2011.02030.x
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   Vanjigounder K., 2016, INT J ADV SCI ENG IN, V6, P419, DOI [10.18517/ijaseit.6.4.850, DOI 10.18517/IJASEIT.6.4.850]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xia Y, 2021, ISPRS J PHOTOGRAMM, V174, P166, DOI 10.1016/j.isprsjprs.2021.01.027
   Xiang P, 2023, IEEE T PATTERN ANAL, V45, P6320, DOI 10.1109/TPAMI.2022.3217161
   Xie Haozhe, 2020, P EUR C COMP VIS
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yida Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P70, DOI 10.1007/978-3-030-58580-8_5
   Yu X., 2023, arXiv
   Yu XM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12478, DOI 10.1109/ICCV48922.2021.01227
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhang J, 2021, VIS INFORM, V5, P114, DOI 10.1016/j.visinf.2021.09.003
   Zhang XC, 2021, PROC CVPR IEEE, P15885, DOI 10.1109/CVPR46437.2021.01563
   Zhou HR, 2022, LECT NOTES COMPUT SC, V13663, P416, DOI 10.1007/978-3-031-20062-5_24
   Zhou QY, 2018, Arxiv, DOI arXiv:1801.09847
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Z, 2022, Arxiv, DOI arXiv:2208.00751
NR 47
TC 2
Z9 2
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2023
VL 134
AR 104675
DI 10.1016/j.imavis.2023.104675
EA APR 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA G7MH3
UT WOS:000990950500001
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Shu, QY
   Shi, X
AF Zhao, Yu
   Shu, Qiaoyuan
   Shi, Xi
TI Dual-level contrastive learning for unsupervised person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised person re-ID; Instance discrimination; Unsupervised feature
   learning; Contrastive learning
ID DOMAIN ADAPTATION
AB Unsupervised person re-identification (re-ID) has drawn increasing attention in the community because it is more data-friendly when applied in the real world. Most existing works leverage instance discrimination learn-ing to guide the model to learn image features for person matching. However, the instance discrimination may cause unexpected repulsion among similar samples, which makes the unsupervised feature learning unstable. To address this problem, we propose a dual-level contrastive learning (DLCL) framework to mine both the intra-instance and inter-instance similarities. The DLCL framework consists of two tasks: instance-instance contrastive learning (IICL) and instance-community contrastive learning (ICCL). The IICL aims to mine the intra-instance similarity via pulling an original sample and its augmented versions closer and pushing different instances away. The ICCL is proposed to capture the inter-instance similarity by attracting similar instances to the same sample community, which can reduce the unexpected repulsion brought by instance discrimination. The combination of IICL and ICCL can enable the model to learn more robust and discriminative image features. Extensive experimental results on Market-1501 and DukeMTMC-reID indicate the effectiveness of our method for unsupervised person re-ID.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhao, Yu; Shi, Xi] Chongqing Univ Educ, Sch Artificial Intelligence, Chongqing 400065, Peoples R China.
   [Shu, Qiaoyuan] Chongqing Univ Educ, Sch Math & Big Data, Chongqing 400065, Peoples R China.
C3 Chongqing University of Education; Chongqing University of Education
RP Zhao, Y (corresponding author), Chongqing Univ Educ, Sch Artificial Intelligence, Chongqing 400065, Peoples R China.
EM zhaoyu@cque.edu.cn
FU Natural Science Foundation Project of Chongqing, Chongqing Science and
   Technology Commission; Science and Technology Research Program of
   Chongqing Municipal Education Commission; Scientific Research Project of
   Chongqing Uni-versity of Education;  [cstc2020jcyj-msxmX0023]; 
   [KJQN202101612];  [KY202115C]
FX Acknowledgments This work was supported by the Natural Science
   Foundation Project of Chongqing, Chongqing Science and Technology
   Commission (Grant No. cstc2020jcyj-msxmX0023) , the Science and
   Technology Research Program of Chongqing Municipal Education Commission
   (Grant No. KJQN202101612) , and the Scientific Research Project of
   Chongqing Uni-versity of Education (Grant No. KY202115C) .
CR Bai Y, 2021, IEEE T IMAGE PROCESS, V30, P6715, DOI 10.1109/TIP.2021.3094140
   Chen H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14940, DOI 10.1109/ICCV48922.2021.01469
   Chen T, 2020, PR MACH LEARN RES, V119
   Chong YW, 2021, NEUROCOMPUTING, V422, P314, DOI 10.1016/j.neucom.2020.10.005
   Deng J., 2009, IEEE C COMP VIS PATT
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Du B., 2022, INT J COMPUT VISION, P1
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Kaiwei Zeng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13654, DOI 10.1109/CVPR42600.2020.01367
   Li M., 2018, PROC EUR C COMPUT, P737
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Lin S, 2018, Arxiv, DOI arXiv:1807.01440
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Liu XB, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P246, DOI 10.1109/MIPR.2019.00051
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Mekhazni D., 2020, EUR C COMP VIS SPRIN, P159
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Raj SS, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114502
   Raj S, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108287
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu AC, 2019, IEEE I CONF COMP VIS, P6921, DOI 10.1109/ICCV.2019.00702
   Wu GL, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108239
   Wu GL, 2020, AAAI CONF ARTIF INTE, V34, P12362
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Yang Qize, 2019, CVPR
   Yang Zou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P87, DOI 10.1007/978-3-030-58536-5_6
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2019, PROC CVPR IEEE, P6203, DOI 10.1109/CVPR.2019.00637
   Yin QZ, 2021, IEEE SIGNAL PROC LET, V28, P1390, DOI 10.1109/LSP.2021.3090258
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Zeng KW, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103913
   Zhao Y, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104000
   Zheng KC, 2021, PROC CVPR IEEE, P5306, DOI 10.1109/CVPR46437.2021.00527
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Y., 2021, IEEECVF INT C COMPUT, P8371
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313
NR 50
TC 3
Z9 3
U1 2
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104607
DI 10.1016/j.imavis.2022.104607
EA DEC 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7S6FQ
UT WOS:000910848000003
DA 2024-07-18
ER

PT J
AU Koo, B
   Choi, HS
   Kang, M
AF Koo, Bongyeong
   Choi, Han-Soo
   Kang, Myungjoo
TI Aggregation of attention and erasing for weakly supervised object
   localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional neural network; Weakly supervised learning; Object
   localization
ID DROPOUT
AB In weakly supervised object localization (WSOL), objects are localized using image-level labels only. Most previ-ous WSOL methods erase the most discriminative region using a fixed threshold to cover the entire region of the object, or they use random selection between attention and erasing. However, these methods have several lim-itations. First, the previous erasing method does not guarantee the erasing of adjacent pixels in the most discrim-inative region. Because adjacent pixels have similar information, this property may decrease the effect of the erasing. Next, random selection does not ensure the consistent use of attention and erasing, and it can be less ef-fective to utilize both of them. To overcome these limitations, we propose a new sequential block, namely, a spa-tial attention branch followed by a refinement branch. Initially, the spatial attention branch generates a feature map with enhanced spatial information. Subsequently, the refinement branch helps the network capture the en-tire area of the object using attention and erasing modules. The attention module enhances the positional infor-mation by considering the spatial relationships. The erasing module erases all values within the specified region using various erasing sizes to increase the erasing effect. Finally, to make full use of the advantages of attention and erasing, these modules are combined through element-wise addition. Using such approaches, the proposed method achieves a state-of-the-art localization performance on the CUB-200-2011 and ILSVRC 2012 datasets. Furthermore, the proposed block requires only lightweight trainable parameters, demonstrating the efficiency of the proposed approach.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Koo, Bongyeong; Kang, Myungjoo] Seoul Natl Univ, Dept Math Sci, Seoul, South Korea.
   [Choi, Han-Soo] Seoul Natl Univ, Res Inst Math, Seoul, South Korea.
   [Choi, Han-Soo] LG CNS, AI Res, Seoul, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU)
RP Kang, M (corresponding author), Seoul Natl Univ, Dept Math Sci, Seoul, South Korea.
EM gbk2004@snu.ac.kr; hschoi86@snu.ac.kr; mkang@snu.ac.kr
FU National Research Foundation grant of Korea [2021R1A2C3010887]; ICT R\&D
   program of MSIT/IITP [1711117093]
FX Myungjoo Kang was supported by a National Research Foundation grant of
   Korea (2021R1A2C3010887) and the ICT R\&D program of MSIT/IITP (No.
   1711117093) .
CR Benassou S.N, 2022, IMAGE COMMUN, V100
   Benassou SN, 2021, NEUROCOMPUTING, V429, P60, DOI 10.1016/j.neucom.2020.11.006
   Bowen Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12472, DOI 10.1109/CVPR42600.2020.01249
   Choe J, 2019, PROC CVPR IEEE, P2214, DOI 10.1109/CVPR.2019.00232
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Ghiasi G, 2018, ADV NEUR IN, V31
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2017, P ICCV, DOI DOI 10.1109/ICCV.2017.322
   He K., 2016, INDIAN J CHEM B
   Pham H, 2021, AAAI CONF ARTIF INTE, V35, P9351
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jinjie Mai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8763, DOI 10.1109/CVPR42600.2020.00879
   Ki Minsong, 2020, P ASIAN C COMPUTER V
   Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963
   Koo B, 2021, MULTIDIM SYST SIGN P, V32, P1185, DOI 10.1007/s11045-021-00778-9
   Kou Z., 2021, P IEEECVF WINTER C A
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Mei YQ, 2021, PROC CVPR IEEE, P3516, DOI 10.1109/CVPR46437.2021.00352
   Qin Z., 2021, P IEEECVF INT C COMP
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O., 2015, Int. J. Comput. Vis., V115, P211, DOI DOI 10.1007/S11263-015-0816-Y
   Shaw P, 2018, Arxiv, DOI arXiv:1803.02155
   Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiong YW, 2019, PROC CVPR IEEE, P8810, DOI 10.1109/CVPR.2019.00902
   Xue HL, 2019, IEEE I CONF COMP VIS, P6588, DOI 10.1109/ICCV.2019.00669
   Yang L. X., 2021, INT C MACHINE LEARNI
   Yin JH, 2021, INT C PATT RECOG, P4229, DOI 10.1109/ICPR48806.2021.9412181
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang XL, 2018, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2018.00144
   Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37
   Zhang YL, 2019, Arxiv, DOI arXiv:1903.10082
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 44
TC 2
Z9 2
U1 3
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104598
DI 10.1016/j.imavis.2022.104598
EA DEC 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7S6FQ
UT WOS:000910848000001
DA 2024-07-18
ER

PT J
AU Zhang, SH
   Wang, W
   Zhao, WB
   Wang, L
   Li, QP
AF Zhang, Shihui
   Wang, Wei
   Zhao, Weibo
   Wang, Lei
   Li, Qunpeng
TI A cross-modal crowd counting method combining CNN and cross-modal
   transformer
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross -modal crowd counting; CNN; Transformer; Cross layer connection
   structure; Cross -modal attention module
AB Cross-modal crowd counting aims to use the information between different modalities to generate crowd density images, so as to estimate the number of pedestrians more accurately in unconstrained scenes. Due to the huge differences between different modal images, how to effectively fuse the information between different modali-ties is still a challenging problem. To address this problem, we propose a cross-modal crowd counting method based on CNN and novel cross-modal transformer, which effectively fuses the information between different mo-dalities and boosts the accuracy of crowd counting in unconstrained scenes. Concretely, we first design double CNN branches to capture the modality-specific features of images. After that, we design a novel cross-modal transformer to extract cross-modal global features from the modality-specific features. Furthermore, we a pro-pose cross layer connection structure to connect the front-end information and back-end information of the net-work by adding different layer features. At the end of the network, we develop a cross-modal attention module to strengthen the cross-modal feature representation by extracting the complementarities between different modal features. The experimental results show that the method combining CNN and novel cross-modal trans-former proposed in this paper achieves state-of-the-art performance, which not only effectively improves the accuracy and robustness of cross-modal crowd counting, but also has good generalization under multimodal crowd counting.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhang, Shihui; Wang, Wei; Zhao, Weibo; Wang, Lei; Li, Qunpeng] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Peoples R China.
   [Zhang, Shihui] Key Lab Comp Virtual Technol & Syst Integrat Hebei, Qinhuangdao 066004, Peoples R China.
C3 Yanshan University
RP Wang, W (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Peoples R China.
EM 202022040173@stumail.ysu.edu.cn
RI Zhang, Shihui/KFB-3255-2024; zhang, shihui/ABD-6039-2021
OI zhang, shihui/0000-0001-7601-3631
FU Central Government Guided Local Funds for Science and Technology
   Development, China; Natural Science Foundation of Hebei province in
   China; Innovation Capability Improvement Plan Project of Hebei Province;
    [216Z0301G];  [F2019203285];  [22567626H]
FX This work was supported partly by the Central Government Guided Local
   Funds for Science and Technology Development, China (No. 216Z0301G) ,
   the Natural Science Foundation of Hebei province in China (No.
   F2019203285) , Innovation Capability Improvement Plan Project of Hebei
   Province (No. 22567626H) . The authors would sincerely thank the editors
   and anonymous reviewers for their helpful suggestions.
CR Bai S, 2020, PROC CVPR IEEE, P4593, DOI 10.1109/CVPR42600.2020.00465
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Cao ZJ, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104026
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Fan ZZ, 2022, NEUROCOMPUTING, V472, P224, DOI 10.1016/j.neucom.2021.02.103
   Fu HY, 2012, IEEE IMAGE PROC, P2685, DOI 10.1109/ICIP.2012.6467452
   Ghodgaonkar I, 2020, Arxiv, DOI arXiv:2008.12363
   Kang D, 2019, IEEE T CIRC SYST VID, V29, P1408, DOI 10.1109/TCSVT.2018.2837153
   Li H, 2023, IEEE T IND INFORM, V19, P306, DOI 10.1109/TII.2022.3171352
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lian DZ, 2019, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2019.00192
   Liang DK, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3445-y
   Lin H., 2022, P IEEECVF C COMPUTER, P19628
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu LB, 2021, PROC CVPR IEEE, P4821, DOI 10.1109/CVPR46437.2021.00479
   Liu LB, 2019, IEEE I CONF COMP VIS, P1774, DOI 10.1109/ICCV.2019.00186
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Marsden M., 2016, arXiv
   Peng T., 2020, P AS C COMP VIS ACCV, DOI DOI 10.1007/978-3-030-69544-6_30
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Sun GL, 2023, Arxiv, DOI [arXiv:2105.10926, DOI 10.48550/ARXIV.2105.10926]
   Tian Y, 2021, Arxiv, DOI [arXiv:2109.14483, DOI 10.48550/ARXIV.2109.14483]
   Wang Fusen, 2022, arXiv
   Xia YF, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104242
   Xiong F, 2017, IEEE I CONF COMP VIS, P5161, DOI 10.1109/ICCV.2017.551
   Yang SD, 2019, IEEE INT CONF COMP V, P4521, DOI 10.1109/ICCVW.2019.00553
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang Q, 2019, PROC CVPR IEEE, P8289, DOI 10.1109/CVPR.2019.00849
   Zhang XC, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P215, DOI 10.1109/AVSS.2012.82
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhou DS, 2020, IEEE ACCESS, V8, P101616, DOI 10.1109/ACCESS.2020.2998678
NR 33
TC 4
Z9 4
U1 2
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104592
DI 10.1016/j.imavis.2022.104592
EA NOV 2022
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q3GL
UT WOS:000891502900001
DA 2024-07-18
ER

PT J
AU Ji, Z
   Hu, ZF
   Wang, YD
   Shao, Z
   Pang, YW
AF Ji, Zhong
   Hu, Zhenfei
   Wang, Yaodong
   Shao, Zhuang
   Pang, Yanwei
TI Reinforced pedestrian attribute recognition with group optimization
   reward
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pedestrian attribute recognition; Intelligent video surveillance;
   Reinforcement learning; Deep Q-learning
ID NETWORK
AB Pedestrian Attribute Recognition (PAR) is a challenging task in intelligent video surveillance. Two key challenges in PAR include complex alignment relations between images and attributes, and imbalanced data distribution. Existing approaches usually formulate PAR as a recognition task. Different from them, this paper addresses it as a decision-making task via a reinforcement learning framework, which is dubbed as Rein-PAR. Specifically, PAR is formulated as a Markov decision process (MDP) to efficiently explore semantic alignments between im-ages and attributes. To alleviate the inter-attribute imbalance problem, we apply an Attribute Grouping Strategy (AGS) by dividing all attributes into subgroups according to their region and category information. Then we em-ploy an agent to recognize each group of attributes, which is trained with Deep Q-learning algorithm. We also propose a Group Optimization Reward (GOR) function to alleviate the intra-attribute imbalance problem. Exper-imental results on the three benchmark datasets of PETA, RAP and PA100K illustrate the effectiveness and com-petitiveness of the proposed approach and demonstrate that the application of reinforcement learning to PAR is a valuable research direction. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Ji, Zhong; Hu, Zhenfei; Wang, Yaodong; Pang, Yanwei] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Shao, Zhuang] Univ Warwick, Warwick Mfg Grp, Coventry CV4 7AL, England.
C3 Tianjin University; University of Warwick
RP Wang, YD (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM jizhong@tju.edu.cn; hzf0226@tju.edu.cn; wangyaodong@tju.edu.cn;
   Zhuang.Shao@warwick.ac.uk; pyw@tju.edu.cn
RI Shao, Zhuang/GYU-2414-2022
FU National Natural Science Founda-tion of China (NSFC); Natural Science
   Foundation of Tianjin;  [62176178];  [19JCYBJC16000]
FX Acknowledgement This work was supported by the National Natural Science
   Founda-tion of China (NSFC) under Grant 62176178, and the Natural
   Science Foundation of Tianjin under Grant 19JCYBJC16000.
CR An HR, 2021, IEEE T MULTIMEDIA, V23, P268, DOI 10.1109/TMM.2020.2975417
   [Anonymous], 2011, BMVC 2011BRITISH MAC, DOI DOI 10.1109/NCC.2011.5734769
   [Anonymous], 2017, Deep. Learn. Image Process. Appl, DOI DOI 10.48550/ARXIV.1611.03718
   Chen WC, 2022, MACH INTELL RES, V19, P153, DOI 10.1007/s11633-022-1321-8
   Chen YY, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104462
   Cheng DQ, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104493
   Chiang SH, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104069
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Dong WK, 2019, AAAI CONF ARTIF INTE, P8247
   Guo MH, 2018, LECT NOTES COMPUT SC, V11214, P783, DOI 10.1007/978-3-030-01249-6_47
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He SY, 2018, AAAI CONF ARTIF INTE, P3183
   Huang EB, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103928
   Islam K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103970
   Ji Z, 2020, PATTERN RECOGN LETT, V138, P170, DOI 10.1016/j.patrec.2020.07.018
   Ji Z, 2019, PATTERN RECOGN LETT, V120, P89, DOI 10.1016/j.patrec.2019.01.010
   Joulin A, 2016, Arxiv, DOI [arXiv:1607.01759, DOI 10.48550/ARXIV.1607.01759]
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Layne R, 2012, LECT NOTES COMPUT SC, V7583, P402, DOI 10.1007/978-3-642-33863-2_40
   Le N, 2021, Arxiv, DOI arXiv:2108.11510
   Li DW, 2016, Arxiv, DOI arXiv:1603.07054
   Li DW, 2018, IEEE INT CON MULTI
   Li DW, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P111, DOI 10.1109/ACPR.2015.7486476
   Li Y, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104332
   Li Y, 2017, PROC CVPR IEEE, P5660, DOI 10.1109/CVPR.2017.600
   Lin EL, 2020, APPL INTELL, V50, P2488, DOI 10.1007/s10489-020-01637-z
   Liu F, 2017, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2017.443
   Liu PZ, 2018, Arxiv, DOI arXiv:1808.09102
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Miaomiao Lou, 2019, Artificial Intelligence and Security. 5th International Conference, ICAIS 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11632), P217, DOI 10.1007/978-3-030-24274-9_19
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Russakovsky O., 2015, Int. J. Comput. Vis., V115, P211, DOI DOI 10.1007/S11263-015-0816-Y
   Sarfraz MS, 2017, Arxiv, DOI arXiv:1707.06089
   Shi W, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104335
   Shi YX, 2021, IEEE T MULTIMEDIA, V23, P3264, DOI 10.1109/TMM.2020.3023272
   Siadari T.S., IEEE INT C COMPUTER, P1098
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sudowe P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P329, DOI 10.1109/ICCVW.2015.51
   Tan ZC, 2019, IEEE T IMAGE PROCESS, V28, P6126, DOI 10.1109/TIP.2019.2919199
   Tang ZR, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108254
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Wang, 2020, P IEEE CVF C COMP VI, P9319, DOI DOI 10.1109/CVPR42600.2020.00934
   Wang JY, 2017, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2017.65
   Wang X, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108220
   Wang YJ, 2020, PROC CVPR IEEE, P6957, DOI 10.1109/CVPR42600.2020.00699
   Yaghoubi E, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103981
   Yaghoubi E, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165608
   Yu WY, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104145
   Zhang DW, 2021, AAAI CONF ARTIF INTE, V35, P3315
   Zhang JF, 2021, IEEE T IMAGE PROCESS, V30, P603, DOI 10.1109/TIP.2020.3036762
   Zhao X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3177
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
   Zhou Y., BRIT MACHINE VISION, P1
NR 53
TC 6
Z9 6
U1 2
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104585
DI 10.1016/j.imavis.2022.104585
EA NOV 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, SY
   Liu, DF
   Pu, YM
   Zhong, YF
AF Chen, Siyuan
   Liu, Danfei
   Pu, Yumei
   Zhong, Yunfei
TI Advances in deep learning-based image recognition of product packaging
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Target detection; Deep learning; Data augmentation; Computer vision
ID OBJECT DETECTION
AB The information about the goods on the shelves needed to be obtained by the dealers in real time, so that they could serve the customers better. The visual-based shelf commodity detection methods have attracted extensive attention in recent years. Among them, the target detection method based on deep learning could automatically understand the picture features, which greatly promoted the development of goods shelf identification. This paper made a comparison and analysis between the common target detecting data set and the data set of goods on shelf from their features, advantages and application. It came up with a method to build an excellent data set of goods, and sorted out the data enhancement methods to perfect the data set for defective data sets. Then, from the three angles of large-scale package identification, small target identification and partial occluded recognition, the latest product package identification method was summarized. At last, the limitations of deep learning method in product identification were discussed and the future development direction was looked forward.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Chen, Siyuan; Liu, Danfei; Pu, Yumei; Zhong, Yunfei] Hunan Univ Technol, Sch Packaging & Mat Engn, 88 Taishan Rd, Zhuzhou 412007, Hunan, Peoples R China.
C3 Hunan University of Technology
RP Zhong, YF (corresponding author), Hunan Univ Technol, Sch Packaging & Mat Engn, 88 Taishan Rd, Zhuzhou 412007, Hunan, Peoples R China.
EM m20085600011@stu.hut.edu.cn; m18080502003@stu.hut.edu.cn;
   m21085600005@stu.hut.edu.cn; yfzhong@hut.edu.cn
RI zhong, yunfei/JDV-6536-2023
FU Natural Science Foundation of Hunan Province [2021JJ30218]; Training
   Project of Hunan Industrial Application of Higher Education Institution
   [15CY003]; Hunan Province Higher Education Institutions Demonstration
   Base of Production, Education and Research [2014-117]
FX This work has been funded by the Natural Science Foundation of Hunan
   Province (2021JJ30218), the Training Project of Hunan Industrial
   Application of Higher Education Institution (15CY003) and Hunan Province
   Higher Education Institutions Demonstration Base of Production,
   Education and Research (2014-117).
CR Agrawal Nitin, 2008, 2008 USENIX ANN TECH
   Aly W, 2019, IEEE ACCESS, V7, P123138, DOI 10.1109/ACCESS.2019.2938829
   An J., 2015, Special Lecture on IE, V2, P1
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Bai YL, 2020, Arxiv, DOI arXiv:2008.10545
   Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Chen ZN, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231742
   Christian S., 2022, AAAI C ARTIFICIAL IN
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deutsch T, 2010, J HIST RES MARKETING, V2, P130, DOI 10.1108/17557501011016299
   Follmann P, 2018, LECT NOTES COMPUT SC, V11214, P581, DOI 10.1007/978-3-030-01249-6_35
   Fuchs K., P 9 INT C INTERNET T, P1
   Gao Yuan, 2019, Journal of Computer Applications, V39, P2731, DOI 10.11772/j.issn.1001-9081.2019030413
   George M, 2014, LECT NOTES COMPUT SC, V8690, P440, DOI 10.1007/978-3-319-10605-2_29
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goldman E, 2019, PROC CVPR IEEE, P5222, DOI 10.1109/CVPR.2019.00537
   He FX, 2020, IEEE T NEUR NET LEAR, V31, P5349, DOI 10.1109/TNNLS.2020.2966319
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Isaksson L.J., 2022, MIXUP SAMPLE PAIRING
   Jia Yao, 2021, RES COMPLEX DOCUMENT
   Klasson M, 2019, IEEE WINT CONF APPL, P491, DOI 10.1109/WACV.2019.00058
   Krishna H, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P340, DOI 10.1109/ACPR.2017.149
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li JS, 2016, PROCEEDINGS OF 2016 2ND INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND INTERNET OF THINGS (CCIOT), P115, DOI 10.1109/CCIOT.2016.7868315
   Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loula F, 2005, J EXP PSYCHOL HUMAN, V31, P210, DOI 10.1037/0096-1523.31.1.210
   Pandey P, 2017, IEEE SIGNAL PROC LET, V24, P1758, DOI 10.1109/LSP.2017.2758862
   Park E., 2017, LARGE SCALE VISUAL R, V2017
   Peng J., 2020, arXiv
   Qiao SY, 2017, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2017.199
   Ramponi G, 2019, Arxiv, DOI [arXiv:1811.08295, DOI 10.48550/ARXIV.1811.08295]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schaal S, 2006, ADAPTIVE MOTION OF ANIMALS AND MACHINES, P261, DOI 10.1007/4-431-31381-8_23
   Singh B., 2018, ADV NEURAL INFORM PR, P31
   Sun HT, 2020, IEEJ T ELECTR ELECTR, V15, P242, DOI 10.1002/tee.23051
   Sutskever I., 2008, ADV NEURAL INF PROCE, V21
   Tonioni A, 2017, LECT NOTES COMPUT SC, V10484, P682, DOI 10.1007/978-3-319-68560-1_61
   van Dyk DA, 2001, J COMPUT GRAPH STAT, V10, P1, DOI 10.1198/10618600152418584
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vicente S, 2014, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2014.13
   Wang KL, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419829651
   Wang WY, 2020, NEURAL COMPUT APPL, V32, P14613, DOI 10.1007/s00521-020-05148-3
   Wei X.-S., 2019, arXiv
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xie R, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA 2019), P78, DOI 10.1109/ICCIA.2019.00022
   Yang CF, 2017, Arxiv, DOI arXiv:1703.01340
   Yang X, 2021, PR MACH LEARN RES, V139
   Zhang HY, 2018, Arxiv, DOI [arXiv:1710.09412, DOI 10.48550/ARXIV.1710.09412]
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 59
TC 5
Z9 5
U1 6
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104571
DI 10.1016/j.imavis.2022.104571
EA OCT 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6A7AA
UT WOS:000880802600002
DA 2024-07-18
ER

PT J
AU Wu, Q
   Wang, JZ
   Chai, ZL
   Guo, GD
AF Wu, Qin
   Wang, Jianzhe
   Chai, Zhilei
   Guo, Guodong
TI Multi-scale feature aggregation and boundary awareness network for
   salient object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Salient object detection; Feature aggregation; Complex
   boundary
AB Salient object detection aims to detect the most visually distinctive objects in an image. Although existing FCNbased methods have shown strong advantages in this field, scale variation and complex boundary are still great challenges. In this paper, we propose a multi-scale feature aggregation and boundary awareness network to overcome the problems. Multi-scale feature aggregation module is proposed to integrate adjacent hierarchical features and the multiple aggregation strategy solves the problem of scale variation. To obtain more effective multi-scale features from integrated features, a cross feature refinement module is proposed to compose the decoder. For the issue of complex boundary, we design a boundary pixel awareness loss function to enable the network to acquire boundary information and generate high-quality saliency maps with better boundary. Experiments on five benchmark datasets show that our network outperforms recent state-of-the-art detectors quantitatively and qualitatively.
C1 [Wu, Qin; Wang, Jianzhe; Chai, Zhilei] Jiangnan Univ, Wuxi 214122, Jiangsu, Peoples R China.
   [Guo, Guodong] West Virginia Univ, Morgantown, WV 26505 USA.
C3 Jiangnan University; West Virginia University
RP Wu, Q (corresponding author), Jiangnan Univ, Wuxi 214122, Jiangsu, Peoples R China.
EM qinwu@jiangnan.edu.cn
FU National Natural Science Foundation of China [61972180]
FX This research was funded by the National Natural Science Foundation of
   China (No. 61972180).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen XW, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104166
   Chen ZX, 2021, IEEE T IMAGE PROCESS, V30, P431, DOI 10.1109/TIP.2020.3037536
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Deng J., 2009 IEEE C COMPUTER, P248
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan D.P., 2017 IEEE INT C COMP, P4558
   Fan D.P., 2018, ARXIV PREPRINT
   Federico P., 2012 IEEE C COMPUTER, P733
   Feng M.Y., 2019 IEEE CVF C COMP, P1623
   Flores CF, 2019, PATTERN RECOGN, V94, P62, DOI 10.1016/j.patcog.2019.05.002
   He K.M., 2016 IEEE C COMPUTER, P770
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Li G.B., 2016 IEEE C COMPUTER, P478
   Li H.C., 2019 IEEE CVF C COM, P9514
   Li Y., 2014 IEEE C COMPUTER, P280
   Liang PP, 2016, IEEE SIGNAL PROC LET, V23, P949, DOI 10.1109/LSP.2016.2556706
   Liu J.J., 2019 IEEE CVF C COMP, P3912
   Liu JJ, 2020, IEEE T IMAGE PROCESS, V29, P8652, DOI 10.1109/TIP.2020.3017352
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Luo Z.M., 2017 IEEE C COMPUTER, P6593
   Milletari F., 2016 4 INT C 3D VISI, P565
   Pang Y.W, 2020 IEEECVF C COMPU, P9410
   Qin X.B., 2019 IEEE CVF C COMP, P7471
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Su J.M., 2019 IEEECVF INT C C, P3798
   Wang B, 2020, AAAI CONF ARTIF INTE, V34, P12128
   Wang L.J., 2017 IEEE C COMPUTER, P3796
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wang W.G., 2019 IEEE CVF C COMP, P1448
   Wang ZY, 2021, IMAGE VISION COMPUT, V113, DOI 10.1016/j.imavis.2021.104243
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wei Y.C., 2017 IEEE C COMPUTER, P6488
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Z., 2019 IEEE CVF C COMP, P3902
   Xi XY, 2019, NEUROCOMPUTING, V323, P265, DOI 10.1016/j.neucom.2018.10.002
   Xiao J.X., 2010 IEEE COMPUTER S, P3485
   Yang C., 2013 IEEE C COMPUTER, P3166
   Zhao J.X., 2019 IEEECVF INT C C, P8778
   Zhao T., 2019 IEEE CVF C COMP, P3080
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhou H.J, 2020 IEEECVF C COMPU, P9138
NR 53
TC 4
Z9 5
U1 4
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104442
DI 10.1016/j.imavis.2022.104442
EA APR 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1F1NU
UT WOS:000794942300006
DA 2024-07-18
ER

PT J
AU Chen, Z
   Fu, ZH
   Huang, JQ
   Tao, MY
   Jiang, RX
   Tian, X
   Chen, YW
   Hua, XS
AF Chen, Ze
   Fu, Zhihang
   Huang, Jianqiang
   Tao, Mingyuan
   Jiang, Rongxin
   Tian, Xiang
   Chen, Yaowu
   Hua, Xian-Sheng
TI Spatial likelihood voting with self-knowledge distillation for weakly
   supervised object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Weak supervision; Spatial likelihood voting;
   Self-knowledge distillation
AB Weakly supervised object detection (WSOD), which is an effective way to train an object detection model using only image-lev el annotations, has attracted considerable attention from researchers. However, most of the existing methods, which are based on multiple instance learning (MIL), tend to localize instances to the discriminative parts of salient objects instead of the entire content of all objects. In this paper, we pro -pose a WSOD framework called the Spatial Likelihood Voting with Self-knowledge Distillation Network (SLV-SD Net). In this framework, we introduce a spatial likelihood voting (SLV) module to converge region proposal localization without bounding box annotations. Specifically, in every iteration during training, all the region proposals in a given image act as voters voting for the likelihood of each category in the spatial dimensions. After dilating the alignment on the area with large likelihood values, the voting results are regularized as bounding boxes, which are then used for the final classification and localization. Based on SLV, we further propose a self-knowledge distillation (SD) module to refine the feature repre-sentations of the given image. The likelihood maps generated by the SLV module are used to supervise the feature learning of the backbone network, encouraging the network to attend to wider and more diverse areas of the image. Extensive experiments on the PASCAL VOC 2007/2012 and MS-COCO datasets demonstrate the excellent performance of SLV-SD Net. In addition, SLV-SD Net produces new state-of-the -art results on these benchmarks. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Chen, Ze; Jiang, Rongxin; Tian, Xiang; Chen, Yaowu] Zhejiang Univ, Inst Adv Digital Technol & Instrument, 38 Zheda Rd, Hangzhou 310027, Peoples R China.
   [Jiang, Rongxin] Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou, Peoples R China.
   [Tian, Xiang] Zhejiang Prov Key Lab Network Multimedia Technol, Hangzhou, Peoples R China.
   [Chen, Yaowu] Zhejiang Univ, Minist Educ China, Embedded Syst Engn Res Ctr, Hangzhou, Peoples R China.
   [Fu, Zhihang; Huang, Jianqiang; Tao, Mingyuan; Hua, Xian-Sheng] Alibaba Grp, Hangzhou 311121, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Alibaba
   Group
RP Chen, YW (corresponding author), Zhejiang Univ, Inst Adv Digital Technol & Instrument, 38 Zheda Rd, Hangzhou 310027, Peoples R China.
EM chenze@zju.edu.cn; cyw@mail.bme.zju.edu.cn
OI Fu, Zhihang/0000-0003-0418-2553
FU Alibaba Group through Alibaba Re-search Intern Program; Fundamen-tal
   Research Funds for the Central Universities; National Natural Science
   Foundation of China [31627802]
FX This work was supported by Alibaba Group through Alibaba Re-search
   Intern Program. And this work was supported by the Fundamen-tal Research
   Funds for the Central Universities, and the National Natural Science
   Foundation of China under Grant 31627802.
CR Arun A., P IEEE C COMP VIS PA, P9432
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535
   Chen Z., P IEEE CVF C COMP VI, P12995
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   Dean J., 2015, NIPS DEEP LEARNING R
   Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gao MF, 2018, LECT NOTES COMPUT SC, V11205, P155, DOI 10.1007/978-3-030-01246-5_10
   Gao Yan, 2019, ARXIV190606023
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Kan M., 2019, ARXIV190400551
   Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Peng Xi, 2020, ADV NEUR IN, V33
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908
   Ren Z., P IEEE CVF C COMP VI, P10598
   Romero A., 2014, 3 INT C LEARN REPRES
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shao S., P IEEE CVF INT C COM, P8430
   Shen YH, 2019, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2019.00079
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang P, 2018, LECT NOTES COMPUT SC, V11215, P370, DOI 10.1007/978-3-030-01252-6_22
   Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304
   Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326
   Tang P, 2017, PATTERN RECOGN, V71, P446, DOI 10.1016/j.patcog.2017.05.001
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wan F, 2019, PROC CVPR IEEE, P2194, DOI 10.1109/CVPR.2019.00230
   Wan F, 2018, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2018.00141
   Wei YC, 2018, LECT NOTES COMPUT SC, V11215, P454, DOI 10.1007/978-3-030-01252-6_27
   Yang CL, 2019, PROC CVPR IEEE, P2854, DOI 10.1109/CVPR.2019.00297
   Yang K., P IEEE INT C COMP VI, P8372
   Yin Y., 2021, INSTANCE MININGWITH
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeng ZY, 2019, IEEE I CONF COMP VIS, P8291, DOI 10.1109/ICCV.2019.00838
   Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381
   Zhang XP, 2018, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR.2018.00448
   Zhang YQ, 2018, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.2018.00103
NR 50
TC 3
Z9 3
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104314
DI 10.1016/j.imavis.2021.104314
EA NOV 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA XF7WP
UT WOS:000724279100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Narayanan, A
   Rao, A
   Prasad, A
   Natarajan, S
AF Narayanan, Abhishek
   Rao, Abijna
   Prasad, Abhishek
   Natarajan, S.
TI VQA as a factoid question answering problem: A novel approach for
   knowledge-aware and explainable visual question answering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual question answering; Factoid question answering; Knowledge based
   reasoning; Explainable VQA
AB With recent advancements in machine perception and scene understanding, Visual Question Answering (VQA) has garnered much attraction from researchers in the direction of training neural models for jointly analyzing, grounding and reasoning over the multi-modal space of image visual context and natural language in order to answer natural language questions pertaining to the image contents. However, though recent works have achieved significant improvement over state-of-art models for answering questions that are answerable by solely referring to the visual context of the image, such models are often limited, being incapable of tackling questions involving external world knowledge beyond the visible contents. Though recently, research has been driven towards tackling external knowledge based VQA as well, there is significant room for improvement as limited studies exist in this area. Inspired by the aforementioned challenges involved, this paper is aimed at answering free form and open ended natural language questions, not limited to visual context of an image, but external world knowledge as well. With this motive, inspired by human cognitive abilities of comprehending and reasoning answers when given a set of facts, this paper proposes a novel model architecture to model VQA as a factoid question answering problem, leveraging state-of-the-art deep learning techniques for reasoning and inferring answers to free form questions, in an attempt of improving the state-of-art in open ended visual question answering. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Narayanan, Abhishek; Rao, Abijna; Prasad, Abhishek; Natarajan, S.] PES Univ, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
C3 PES University
RP Narayanan, A (corresponding author), PES Univ, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
EM abhishek.1010n@gmail.com; abijnarao@gmail.com;
   abhishek.pes2016@gmail.com; natarajan@pes.edu
OI Rao, Abijna/0000-0002-9557-962X; Narayanan,
   Abhishek/0000-0002-9462-9779; Prasad, Abhishek/0000-0002-7237-2466;
   Subramanyam, Natarajan/0000-0002-8689-5137
CR Agarwal V., P IEEE CVF C COMP VI, P9690
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], Simple baseline for visual question answering
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2016, ARXIV160603647
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Cho K., 2014, ARXIV14061078
   Chollet F., KERAS
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gao H., 2015, INT C NEURAL INF PRO, P2296
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ilievski Ilija., 2016, A focused dynamic attention model for visual question answering
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kafle K, 2016, PROC CVPR IEEE, P4976, DOI 10.1109/CVPR.2016.538
   Kim J.-H., 2016, arXiv
   Kim JH, 2016, ADV NEUR IN, V29
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lu JS, 2016, ADV NEUR IN, V29
   Malinowski M, 2014, ADV NEUR IN, V27
   Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mollá D, 2007, COMPUT LINGUIST, V33, P41, DOI 10.1162/coli.2007.33.1.41
   Narasimhan M, 2018, LECT NOTES COMPUT SC, V11212, P460, DOI 10.1007/978-3-030-01237-3_28
   Narayanan A., 2021, EMERGING TECHNOLOGIE, P749
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Redmon J., 2018, P IEEE C COMP VIS PA
   Shah S, 2019, AAAI CONF ARTIF INTE, P8876
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Teney D, 2017, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2017.344
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang Peng., 2015, Explicit knowledge-based reasoning for visual question answering
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Xu L., P IEEE CVF C COMP VI, P9878
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu J, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107563
   Zhu Y., P IEEE C COMP VIS PA, P1154
NR 44
TC 6
Z9 6
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104328
DI 10.1016/j.imavis.2021.104328
EA NOV 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WU6KE
UT WOS:000716651500004
DA 2024-07-18
ER

PT J
AU Xu, XQ
   Zhu, MY
   Yu, JH
   Chen, SH
   Hu, XL
   Yang, YQ
AF Xu, Xiuqi
   Zhu, Mingyu
   Yu, Jinhao
   Chen, Shuhan
   Hu, Xuelong
   Yang, Yuequan
TI Boundary guidance network for camouflage object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camouflaged object detection; Boundary guidance; Hierarchical-Split
   Convolution; Residual refinement
AB Camouflage object detection (COD) aims to detect camouflaged objects hidden in the background region in an image. The difficulty of COD lies in the fact that camouflaged objects are often accompanied with weak bound-aries, low contrast, and similar patterns to the background. Although various methods have been proposed to ad -dress these challenges, they still suffer from coarse object boundaries. In this work, we design a novel boundary guidance network for COD, which follows a two-step framework: localization and refinement. Firstly, an Initial Localization Decoder is proposed to capture multi-scale cues by embedding a Hierarchical-Split Convolution block. After obtained the coarse localization of the camouflaged object, we further propose a Residual Refinement Decoder to fix the missing object parts and boundary details progressively. Each of the proposed decoder consists of a region branch and a boundary branch for object detection and boundary detection respectively. To suffi-ciently leverage their complementary features, we design a novel Boundary-Guide-Region module. Benefiting from the guidance of the boundary feature, the region branch can focus on the inside parts of the boundary for residual learning, thus leads to more accurate detection. Extensive experimental results on four benchmark datasets demonstrate that our method outperforms existing state-of-the-art algorithms in both object accuracy and boundary accuracy with real-time speed. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Xu, Xiuqi; Zhu, Mingyu; Yu, Jinhao; Chen, Shuhan; Hu, Xuelong; Yang, Yuequan] Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
C3 Yangzhou University
RP Chen, SH (corresponding author), Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
EM shchen@yzu.edu.cn; xlhu@yzu.edu.cn; yang@yzu.edu.cn
FU Natural Science Foundation of China [61802336, 61806175, 62073322];
   Yangzhou University "Qinglan Project"
FX This work is partially supported by the Natural Science Foundation of
   China (No. 61802336, No. 61806175, No. 62073322), and Yangzhou
   University "Qinglan Project".
CR Bhajantri N., CAMOUFLAGE DEFECT ID, DOI [10.1109/ICIT.2006.34, DOI 10.1109/ICIT.2006.34]
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen ZH, 2020, PROC CVPR IEEE, P5610, DOI 10.1109/CVPR42600.2020.00565
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Chu HK, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778788
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Ding HH, 2019, IEEE I CONF COMP VIS, P6818, DOI 10.1109/ICCV.2019.00692
   Fan D.-P., 2021, ARXIV PREPRINT ARXIV
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Hall JR, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.0064
   He H., 2021, ARXIV PREPRINT ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim Y., 2018, AS C COMP VIS, P555, DOI DOI 10.1007/978-3-030-20876-9
   Lee H.J., 2020, P IEEE C COMP VIS PA
   Lin JK, 2020, PROC CVPR IEEE, P5890, DOI 10.1109/CVPR42600.2020.00593
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Lyu Y., 2021, P IEEE C COMP VIS PA
   Margolin R., 2021, P IEEE C COMP VIS PA
   Mei H., P IEEE C COMP VIS PA, P3687
   Mei HY, 2021, PROC CVPR IEEE, P8768, DOI 10.1109/CVPR46437.2021.00866
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Shang-Hua Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P702, DOI 10.1007/978-3-030-58539-6_42
   Skurowski P., ANIMAL CAMOUFL UNPUB
   Sun Y., 2021, ARXIV PREPRINT ARXIV
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Wei J., 2019, ARXIV191111445
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xue F, 2016, MULTIMED TOOLS APPL, V75, P4065, DOI 10.1007/s11042-015-2946-1
   Xue F, 2015, MULTIMEDIA SYST, V21, P169, DOI 10.1007/s00530-014-0368-y
   Yan JN, 2021, IEEE ACCESS, V9, P43290, DOI 10.1109/ACCESS.2021.3064443
   Yang X., P IEEE INT C COMP VI, P8809
   Yuan P., 2020, ARXIV PREPRINT ARXIV
   Zhai Q, 2021, PROC CVPR IEEE, P12992, DOI 10.1109/CVPR46437.2021.01280
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang J., 2020, PROC IEEECVFCONF COM, DOI DOI 10.1109/CVPR42600.2020.01256
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhu JC, 2021, AAAI CONF ARTIF INTE, V35, P3599
NR 48
TC 16
Z9 16
U1 4
U2 52
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2021
VL 114
AR 104283
DI 10.1016/j.imavis.2021.104283
EA AUG 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UR9HP
UT WOS:000697051200003
DA 2024-07-18
ER

PT J
AU Kiran, M
   Bhuiyan, A
   Nguyen-Meidine, L
   Blais-Morin, LA
   Ben Ayed, I
   Granger, E
AF Kiran, Madhu
   Bhuiyan, Amran
   Nguyen-Meidine, Le Thanh
   Blais-Morin, Louis-Antoine
   Ben Ayed, Ismail
   Granger, Eric
TI Flow guided mutual attention for person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video surveillance; Person re-identification; Optical flow; Metric
   learning; Attention mechanisms
AB Person Re-Identification (ReID) is a challenging problem in many video analytics and surveillance applications, where a person's identity must be associated across a distributed non-overlapping network of cameras. Video based person ReID has recently gained much interest given the potential for capturing discriminant spatiotemporal information from video clips that is unavailable for image-based ReID. Despite recent advances, deep learning (DL) models for video ReID often fail to leverage this information to improve the robustness of feature representations. In this paper, the motion pattern of a person is explored as an additional cue for ReID. In particular, a flow-guided Mutual Attention network is proposed for fusion of bounding box and optical flow sequences over tracklets using any 2D-CNN backbone, allowing to encode temporal information along with spatial appearance information. Our Mutual Attention network relies on the joint spatial attention between image and optical flow feature maps to activate a common set of salient features. In addition to flow-guided attention, we introduce a method to aggregate features from longer input streams for better video sequence-level representation. Our extensive experiments on three challenging video ReID datasets indicate that using the proposed approach allows to improve recognition accuracy considerably with respect to conventional gated-attention networks, and stateof-the-art methods for video-based person ReID. (c) 2021 Published by Elsevier B.V.
C1 [Kiran, Madhu; Bhuiyan, Amran; Nguyen-Meidine, Le Thanh; Ben Ayed, Ismail; Granger, Eric] Ecole Technol Super, Lab Imagerie Vis & Intelligence Artificielle, Dept Syst Engn, Montreal, PQ, Canada.
   [Blais-Morin, Louis-Antoine] Genetec Inc, Montreal, PQ, Canada.
C3 University of Quebec; Ecole de Technologie Superieure - Canada
RP Kiran, M; Nguyen-Meidine, L (corresponding author), Ecole Technol Super, Lab Imagerie Vis & Intelligence Artificielle, Dept Syst Engn, Montreal, PQ, Canada.
EM madhu_sajc@hotmail.com; amran.apece@gmail.com;
   le-thanh.nguyen-meidine.1@ens.etsmtl.ca; lablaismorin@genetec.com;
   Ismail.BenAyed@etsmtl.ca; Eric.Granger@etsmtl.ca
RI Bhuiyan, Md Amran Hossen/ABC-6140-2021
OI Bhuiyan, Md Amran Hossen/0000-0002-2069-0753; Granger,
   Eric/0000-0001-6116-7945
FU Mathematics of Infor-mation Technology and Complex Systems (MITACS);
   Natural Sciences and Engineering Research Council of Canada (NSERC)
   organizations
FX This research was partially supported by the Mathematics of Infor-mation
   Technology and Complex Systems (MITACS) and the Natural Sciences and
   Engineering Research Council of Canada (NSERC) organizations.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Bhuiyan A., 2020, WACV
   Bhuiyan A, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020028
   Bhuiyan Amran., 2014, ECCV
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen GY, 2020, IEEE T IMAGE PROCESS, V29, P6963, DOI 10.1109/TIP.2020.2995272
   Chen GY, 2019, IEEE T IMAGE PROCESS, V28, P4192, DOI 10.1109/TIP.2019.2908062
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cho S., 2018, AS C COMP VIS, P347
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Gao Jinyang., 2018, CoRR
   Gu XQ, 2019, IEEE I CONF COMP VIS, P9646, DOI 10.1109/ICCV.2019.00974
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Hu J., 2018, P IEEECVF C COMPUTER, P7132
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936
   Kiran M., ARXIV PREPRINT ARXIV
   Leibe B., 2017, ARXIV170307737CS
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li JN, 2020, IEEE T IMAGE PROCESS, V29, P4461, DOI 10.1109/TIP.2020.2972108
   Li JN, 2019, AAAI CONF ARTIF INTE, P8618
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu C.T., 2019, BMVC
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Mekhazni Djebril, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P159, DOI 10.1007/978-3-030-58583-9_10
   Panda Rameswar., 2017, CVPR
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Simonyan K, 2014, ADV NEUR IN, V27
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song GL, 2018, AAAI CONF ARTIF INTE, P7347
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Turaga P, 2010, ADV COMPUT, V80, P237, DOI 10.1016/S0065-2458(10)80007-5
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wu G., BMVC, P278
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang RM, 2019, IEEE T IMAGE PROCESS, V28, P4870, DOI 10.1109/TIP.2019.2911488
   Zhang Z., P IEEE CVF C COMP VI, P10407
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L., 2017, IEEE T IMAGE PROCESS
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 62
TC 6
Z9 7
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104246
DI 10.1016/j.imavis.2021.104246
EA JUL 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900002
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Zhang, YZ
   Liu, Y
   Liu, SC
   Coleman, S
   Kerr, D
AF Wang, Zhenyu
   Zhang, Yunzhou
   Liu, Yan
   Liu, Shichang
   Coleman, Sonya
   Kerr, Dermot
TI MFC-Net : Multi-feature fusion cross neural network for salient object
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; Cross network framework; Contextual feature
   transfer; Feature fusion
ID ATTENTION
AB Although methods based on the fully convolutional neural networks (FCNs) have shown strong advantages in the field of salient object detection, the existing methods still have two challenging issues: insufficient multi-level feature fusion ability and boundary blur. To overcome these issues, we propose a novel salient object detection method based on a multi-feature fusion cross network (denoted MFC-Net). Firstly, to overcome the issue of insufficient multi-level feature fusion ability, inspired by the connection mode of human brain neurons, we propose a novel cross network framework, combined with contextual feature transfer modules (CFTMs) to integrate, enhance and transmit multi-level feature information in an iterative manner. Secondly, to address the issue of blurred boundaries, we effectively enhance the edge features of saliency map by a simple edge enhancement strategy. Thirdly, to reduce the loss of information caused by the saliency map generated by multi-level feature fusion, we use feature fusion modules (FFMs) to learn contextual feature information from multiple angles and then output the resulting saliency map. Finally, a hybrid loss function fully supervises the network at the pixel and object level, optimizing the network performance. The proposed MFC-Net has been evaluated using five benchmark datasets. The performance evaluation demonstrates that the proposed method outperforms other state-of-the-art methods, which proves the superiority of MFC-Net approach. (c) 2021 Published by Elsevier B.V.
C1 [Wang, Zhenyu; Liu, Yan] Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110819, Peoples R China.
   [Zhang, Yunzhou] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
   [Liu, Shichang] SIASUN Robot & Automat CO Ltd, Shanghai, Peoples R China.
   [Coleman, Sonya; Kerr, Dermot] Univ Ulster, Intelligent Syst Res Ctr, Derry BT52 1SA, North Ireland.
C3 Northeastern University - China; Northeastern University - China; Ulster
   University
RP Zhang, YZ (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
EM zhangyunzhou@mail.neu.edu.cn
OI Wang, Zhenyu/0000-0001-9941-1480
FU Major Science and technology innovation engineering projects of Shandong
   Province [2019JZZY010128]; National Natural Science Foundation of China
   [61973066]; Open Fundation of Zhijiang Laboratory [2019KD0AD01/006];
   Equipment Pre-research Fundation [61403120111]; Distinguished Creative
   Talent Programof Liaoning Colleges and Universities [LR2019027];
   Fundamental Research Funds for the Central Universities [N182608004,
   N2004022]
FX This work is supported byMajor Science and technology innovation
   engineering projects of Shandong Province (2019JZZY010128), National
   Natural Science Foundation of China (No. 61973066), Open Fundation of
   Zhijiang Laboratory(No.2019KD0AD01/006), Equipment Pre-research
   Fundation (61403120111), Distinguished Creative Talent Programof
   Liaoning Colleges and Universities (LR2019027) and Fundamental Research
   Funds for the Central Universities (N182608004, N2004022).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Beaulieu-Laroche L, 2018, CELL, V175, P643, DOI 10.1016/j.cell.2018.08.045
   Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2017, J COMPUT SCI TECH-CH, V32, P110, DOI 10.1007/s11390-017-1681-7
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Craye C, 2016, IEEE INT CONF ROBOT, P2303, DOI 10.1109/ICRA.2016.7487379
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Han JG, 2013, NEUROCOMPUTING, V111, P70, DOI 10.1016/j.neucom.2012.12.015
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hou QB, 2018, ADV NEUR IN, V31
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu HY, 2016, IEEE T NEUR NET LEAR, V27, P1201, DOI 10.1109/TNNLS.2016.2553579
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu JJ, 2020, IEEE T IMAGE PROCESS, V29, P8652, DOI 10.1109/TIP.2020.3017352
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Y., IMAGE VISION COMPUT, V106, DOI [10.1016/j.imavis.2020, DOI 10.1016/J.IMAVIS.2020]
   Luo RH, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103876
   Mohammadi S, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107303
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Scholkopf B., ADV NEURAL INFORM PR, V19, P545
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390
   Tan F, 2019, IEEE T NEUR NET LEAR, V30, P1565, DOI 10.1109/TNNLS.2018.2870573
   Vecchio G, 2020, IEEE T NEUR NET LEAR, V31, P5103, DOI 10.1109/TNNLS.2019.2963282
   Wang B, 2020, AAAI CONF ARTIF INTE, V34, P12128
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI 10.1109/TNNLS.2015.2477537
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733
   Zhang Y, 2020, IEEE T NEUR NET LEAR, V31, P2716, DOI 10.1109/TNNLS.2018.2890310
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhou ZQ, 2020, AAAI CONF ARTIF INTE, V34, P13082
   Zong M, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104108
NR 65
TC 6
Z9 8
U1 3
U2 40
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104243
DI 10.1016/j.imavis.2021.104243
EA JUL 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900009
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Omelina, L
   Goga, J
   Pavlovicova, J
   Oravec, M
   Jansen, B
AF Omelina, Lubos
   Goga, Jozef
   Pavlovicova, Jarmila
   Oravec, Milos
   Jansen, Bart
TI A survey of iris datasets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Iris recognition; Iris datasets; Human iris
ID TEXTURED CONTACT-LENSES; RECOGNITION; SEGMENTATION; BIOMETRICS;
   AUTHENTICATION; IMAGE
AB Research on human eye image processing and iris recognition has grown steadily over the last few decades. It is important for researchers interested in this discipline to know the relevant datasets in this area to (i) be able to compare their results and (ii) speed up their research using existing datasets rather than creating custom datasets. In this paper, we provide a comprehensive overview of the existing publicly available datasets and their popularity in the research community using a bibliometric approach. We reviewed 158 different iris datasets referenced from the 689 most relevant research articles indexed by the Web of Science online library. We categorized the datasets and described the properties important for performing relevant research. We provide an overview of the databases per category to help investigators conducting research in the domain of iris recognition to identify relevant datasets.
   (c) 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Omelina, Lubos; Jansen, Bart] Vrije Univ Brussel, Dept Elect & Informat, Pleinlaan 2, B-1050 Brussels, Belgium.
   [Omelina, Lubos; Goga, Jozef; Pavlovicova, Jarmila; Oravec, Milos] Slovak Univ Technol Bratislava, Fac Elect Engn & Informat Technol, Ilkovicova 3, Bratislava 81219, Slovakia.
   [Omelina, Lubos; Jansen, Bart] IMEC, Kapeldreef 75, B-3001 Leuven, Belgium.
C3 Vrije Universiteit Brussel; Slovak University of Technology Bratislava;
   IMEC
RP Omelina, L (corresponding author), Vrije Univ Brussel, Dept Elect & Informat, Pleinlaan 2, B-1050 Brussels, Belgium.; Omelina, L (corresponding author), Slovak Univ Technol Bratislava, Fac Elect Engn & Informat Technol, Ilkovicova 3, Bratislava 81219, Slovakia.; Omelina, L (corresponding author), IMEC, Kapeldreef 75, B-3001 Leuven, Belgium.
EM lomelina@etrovub.be; jozef.goga@stuba.sk; jarmila.pavlovicova@stuba.sk;
   milos.oravec@stuba.sk; bjansen@etrovub.be
RI Pavlovičová, Jarmila/AAD-2061-2020; Jansen, Bart/GLR-1063-2022
OI Pavlovičová, Jarmila/0000-0002-8490-5821; Omelina,
   Lubos/0000-0002-2500-5217; Jansen, Bart/0000-0001-8042-6834; Oravec,
   Milos/0000-0001-5106-4803
FU Slovak Grant Agency VEGA [1/0867/17]
FX The research described in the paper was done within the project No.
   1/0867/17 of the Slovak Grant Agency VEGA.
CR Adhau AS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P75, DOI 10.1109/INFOP.2015.7489354
   Aguinis H., 2021, ORGAN RES METHODS, V24, P678, DOI [DOI 10.1177/1094428119836485, 10.1177/1094428119836485]
   Ali Z, 2017, KSII T INTERNET INF, V11, P6133, DOI 10.3837/tiis.2017.12.024
   Alonso-Fernandez F, 2019, IEEE ACCESS, V7, P6519, DOI 10.1109/ACCESS.2018.2889395
   Alonso-Fernandez F, 2016, PATTERN RECOGN LETT, V82, P92, DOI 10.1016/j.patrec.2015.08.026
   Alvarez-Betancourt Y, 2014, SCIENTOMETRICS, V101, P2003, DOI 10.1007/s11192-014-1336-1
   [Anonymous], 2010, P IEEE COMP SOC C CO
   [Anonymous], TWINS DAY DATASET 20
   [Anonymous], 2009, ND IRIS 0405 IRIS IM
   [Anonymous], 2012, P 2012 IEEE COMP VIS
   Arora S. S., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P346, DOI 10.1109/BTAS.2012.6374599
   Arora S. S., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P336, DOI 10.1109/ICB.2012.6199829
   Baker S.E., 2013, TEMPLATE AGING IRIS, V205-218
   Baker SE, 2010, COMPUT VIS IMAGE UND, V114, P1030, DOI 10.1016/j.cviu.2010.06.002
   Barra S, 2015, PATTERN RECOGN LETT, V57, P66, DOI 10.1016/j.patrec.2014.10.011
   Basak P, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P627, DOI 10.1109/BTAS.2017.8272750
   Bielikova M, 2018, J EYE MOVEMENT RES, V11, DOI 10.16910/jemr.11.3.6
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Bowyer KW, 2012, PATTERN RECOGN LETT, V33, P965, DOI 10.1016/j.patrec.2011.11.024
   BROWN B, 1977, AM J OPHTHALMOL, V83, P350, DOI 10.1016/0002-9394(77)90732-2
   Chen Y, 2014, SCI WORLD J, DOI 10.1155/2014/670934
   Chun CN, 2004, LECT NOTES COMPUT SC, V3072, P426
   Crihalmeanu S.S. S., 2007, PROTOCOL MULTIBIOMET
   Crouse D, 2015, INT CONF BIOMETR, P135, DOI 10.1109/ICB.2015.7139043
   Czajka A., 2013, BIOSIGNALS 2013 P IN, V4, P1
   Czajka A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232849
   Das Abhijit, 2014, 2014 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM). Proceedings, P22, DOI 10.1109/CIBIM.2014.7015439
   Das A, 2016, INT CONF BIOMETR
   Das A, 2018, INT CONF BIOMETR, P303, DOI 10.1109/ICB2018.2018.00053
   Das A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P742, DOI 10.1109/BTAS.2017.8272764
   Das A, 2016, PATTERN RECOGN LETT, V82, P232, DOI 10.1016/j.patrec.2015.11.016
   Das S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P11, DOI 10.1109/CGVIS.2015.7449883
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   De Marsico M, 2018, PATTERN RECOGN, V74, P286, DOI 10.1016/j.patcog.2017.08.028
   De Marsico M, 2017, PATTERN RECOGN LETT, V91, P3, DOI 10.1016/j.patrec.2016.12.013
   De Marsico M, 2016, PATTERN RECOGN LETT, V82, P106, DOI 10.1016/j.patrec.2016.02.001
   De Marsico M, 2015, PATTERN RECOGN LETT, V57, P17, DOI 10.1016/j.patrec.2015.02.009
   De Waard A., 2015, Ten aspects of highly effective research data
   Dehnavi M, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-30
   Dobes M, 2004, OPTIK, V115, P399, DOI 10.1078/0030-4026-00388
   Dong H, 2015, J ELECTRON IMAGING, V24, P1
   Dong Wenbo., 2009, CHINESE C PATTERN RE, P1
   Doyle JS, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Doyle JS, 2015, IEEE ACCESS, V3, P1672, DOI 10.1109/ACCESS.2015.2477470
   Dugelay J., 2018, PROC CVPR IEEE
   Edwards M, 2012, AM J PHYS ANTHROPOL, V147, P141, DOI 10.1002/ajpa.21637
   Ewe H.T, 2005, P WSCG 2005
   Fierrez J, 2007, PATTERN RECOGN, V40, P1389, DOI 10.1016/j.patcog.2006.10.014
   Fogelton A, 2018, COMPUT VIS IMAGE UND, V176, P78, DOI 10.1016/j.cviu.2018.09.006
   Gomer R., 2016, ANAL REPORT 3 OPEN D, P6
   Gupta P, 2014, INT C PATT RECOG, P1681, DOI 10.1109/ICPR.2014.296
   Hosseini MS, 2010, IEEE T INSTRUM MEAS, V59, P792, DOI 10.1109/TIM.2009.2037996
   ISO, 2006, 1979512006 ISO IEC
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain P, 2019, INDIAN J OPHTHALMOL, V67, P350, DOI 10.4103/ijo.IJO_1253_18
   Jan F, 2017, SIGNAL PROCESS, V133, P192, DOI 10.1016/j.sigpro.2016.11.007
   Jang G., 2020, IRIS LIVENESS DETECT, Vedition
   Jillela R, 2016, ADV COMPUT VIS PATT, P281, DOI 10.1007/978-1-4471-6784-6_13
   Jillela RR, 2015, PATTERN RECOGN LETT, V57, P4, DOI 10.1016/j.patrec.2014.09.014
   Johnson P.A., 2010, Fourth IEEE International Conference on Biometrics: Theory Applications and Systems (BTAS), P1
   Joshi S, 2016, NEURON, V89, P221, DOI 10.1016/j.neuron.2015.11.028
   Kalka ND, 2006, PROC SPIE, V6202, DOI 10.1117/12.666448
   Karpenko A., 2011, DIGITAL VIDEO STABIL
   Keshari R, 2016, IEEE IMAGE PROC, P3116, DOI 10.1109/ICIP.2016.7532933
   Kihal N, 2017, IET BIOMETRICS, V6, P379, DOI 10.1049/iet-bmt.2016.0067
   Kohli N., 2016, IEEE Int. Conf. on Biometrics: Theory Applications and Systems (BTAS), P1, DOI DOI 10.1109/BTAS.2016.7791168
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Li Ma, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P279
   Luo ZL, 2019, MATEC WEB CONF, V267, DOI 10.1051/matecconf/201926703002
   Matey JR, 2006, P IEEE, V94, P1936, DOI 10.1109/JPROC.2006.884091
   Mehrotra H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078333
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Nalla PR, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2616281
   Neves J, 2016, ARTIF INTELL REV, V46, P515, DOI 10.1007/s10462-016-9474-x
   Nguyen K, 2017, PATTERN RECOGN, V72, P123, DOI 10.1016/j.patcog.2017.05.021
   Oliveira H, 2014, VISAPP 2014 P 9 INT, V3, P1
   Orlans N. M., 2014, BIOMETRIC AGING EFFE
   Padole C. N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P439, DOI 10.1109/ICB.2012.6199790
   Padole CN, 2013, INT J BIOMETRICS, V5, P336, DOI 10.1504/IJBM.2013.055971
   Phillips P. J., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P185, DOI 10.1109/FG.2011.5771395
   Phillips PJ, 2007, IEEE T PATTERN ANAL, V29, P1869, DOI [10.1109/TPAMI.2007.1137, 10.1109/TPAMI.2007.1137.]
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Phillips PJ, 2009, LECT NOTES COMPUT SC, V5558, P705, DOI 10.1007/978-3-642-01793-3_72
   Phillips PJ, 2008, 2 IEEE INT C BIOM TH, P1
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Proenca H., 2007, P 2007 FIRST IEEE IN, P1, DOI [DOI 10.1109/BTAS.2007.4401910, 10.1109/BTAS.2007.4401910]
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Raja KB, 2015, PATTERN RECOGN LETT, V57, P33, DOI 10.1016/j.patrec.2014.09.006
   Rattani A, 2017, IMAGE VISION COMPUT, V59, P1, DOI 10.1016/j.imavis.2016.11.019
   Rattani A, 2016, IEEE IMAGE PROC, P320, DOI 10.1109/ICIP.2016.7532371
   Richman Jack E, 2004, Optometry, V75, P175, DOI 10.1016/S1529-1839(04)70037-8
   Rigas Ioannis., 2014, IEEE International Joint Conference on Biometrics, P1, DOI DOI 10.1109/BTAS.2014.6996282
   Ruiz-Albacete V, 2008, LECT NOTES COMPUT SC, V5372, P181, DOI 10.1007/978-3-540-89991-4_19
   Santos G, 2015, PATTERN RECOGN LETT, V57, P52, DOI 10.1016/j.patrec.2014.09.012
   Sequeira A., 2014, IEEE IJCNN, V9
   Sequeira A, 2016, 2016 INT C BIOM SPEC, V260, P1, DOI DOI 10.1109/BIOSIG.2016.7736915
   Sequeira AF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P725, DOI 10.1109/BTAS.2017.8272762
   Shah S, 2006, IEEE IMAGE PROC, P317, DOI 10.1109/ICIP.2006.313157
   Sharma A, 2014, IEEE IMAGE PROC, P5007, DOI 10.1109/ICIP.2014.7026014
   Singh M, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P666, DOI 10.1109/BTAS.2017.8272755
   sun z., 2019, JCB 2019, V6
   Szwoch M, 2012, LECT NOTES COMPUT SC, V7594, P669, DOI 10.1007/978-3-642-33564-8_80
   Tapia JE, 2016, IEEE T INF FOREN SEC, V11, P1771, DOI 10.1109/TIFS.2016.2550418
   Teo CC, 2010, LECT NOTES COMPUT SC, V6443, P532, DOI 10.1007/978-3-642-17537-4_65
   Tomeo-Reyes I, 2016, PATTERN RECOGN, V60, P306, DOI 10.1016/j.patcog.2016.05.022
   Trokielewicz M., 2016, IEEE International Conference on Identity, Security and Behavior Analysis, P1
   Trokielewicz M, 2015, INT CONF BIOMETR THE
   Trokielewicz M, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P510, DOI 10.1109/BTAS.2017.8272736
   Trokielewicz M, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON CYBERNETICS (CYBCONF), P495, DOI 10.1109/CYBConf.2015.7175984
   Vitek M., 2020, IJCB 2020, P10
   Wei ZS, 2008, INT C PATT RECOG, P1344, DOI 10.1109/ICPR.2008.4761674
   Wild P, 2015, IET BIOMETRICS, V4, P227, DOI 10.1049/iet-bmt.2014.0073
   Wu Su, 2014, IEEE INT JOINT C BIO, P1
   Xiao LH, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), DOI 10.1109/BTAS.2013.6712752
   Yadav D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P574, DOI 10.1109/BTAS.2017.8272744
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
   Yambay D, 2017, 2017 IEEE International Joint Conference on Biometrics, P733
   Yambay D., 2019, REV IRIS PRESENTATIO, P169
   Yambay D, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Yambay D, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Zanlorensi L.A., 2019, OCULAR RECOGNITION D
   Zhang L.Z. Menglu., 2009, P SPIE, V7495
   Zhang MY, 2016, IEEE INT CONF MOB, P1, DOI [10.1109/MASS.2016.012, 10.1109/MASS.2016.53]
   Zhang Q., BIOMETRIC RECOGNITIO, P569
   Zhang Q, 2016, INT CONF BIOMETR
   Zhang Q, 2018, IEEE T INF FOREN SEC, V13, P2897, DOI 10.1109/TIFS.2018.2833033
   Zuo JY, 2007, IEEE T INF FOREN SEC, V2, P77, DOI 10.1109/TIFS.2006.890305
NR 130
TC 18
Z9 18
U1 1
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104109
DI 10.1016/j.imavis.2021.104109
EA FEB 2021
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600011
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Liu, KL
   Qiu, GP
   Tang, WM
   Zhou, F
AF Liu, Kanglin
   Qiu, Guoping
   Tang, Wenming
   Zhou, Fei
TI Spectral regularization for combating mode collapse in GANs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Spectral regularization; Generative adversarial networks (GANs); Mode
   collapse
AB Generative adversarial networks (GANs) have been enjoying considerable success in recent years. However, mode collapse remains a major unsolved problem in training GANs and is one of the main obstacles hindering progress. In this paper, we present spectral regularization for GANs (SR-GANs), a new and robust method for combating the mode collapse problem in GANs. We first perform theoretical analysis to show that the spectral distributions of the weight matrix in the discriminator affect how the equality of Lipschitz constraint can be fulfilled, thus will have an impact on the performance of the discriminator. Prompted by these analysis, we set out to monitor the spectral distributions in the discriminators of spectral normalized GANs (SN-GANs), and discover a phenomenon which we refer to as spectral collapse, where a large number of singular values of the weight matrices drop dramatically when mode collapse occurs. We show that there are strong evidences linking mode collapse to spectral collapse; and based on this link, we set out to tackle spectral collapse as a surrogate of mode collapse. We have developed a spectral regularization method where we introduce two schemes, one static and one dynamic, to compensate the spectral distributions of the weight matrices to prevent them from collapsing, which in turn successfully prevents mode collapse in GANs. Through gradient analysis, we provide theoretical explanations for why SR-GANs are more stable and can provide better performances than SN-GANs. We also present extensive experimental results and analysis to show that SR-GANs not only always outperform SN-GANs but also always succeed in combating mode collapse where SN-GANs fail. The code is available at https:// github.com/max-liu-112/SRGANs-Spectral-Regularization-GANs (c) 2020 Elsevier B.V. All rights reserved.
C1 [Liu, Kanglin; Qiu, Guoping; Tang, Wenming; Zhou, Fei] Shenzhen Univ, Shenzhen, Peoples R China.
   [Liu, Kanglin; Qiu, Guoping; Tang, Wenming; Zhou, Fei] Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.
   [Liu, Kanglin; Qiu, Guoping; Tang, Wenming; Zhou, Fei] Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen, Peoples R China.
   [Qiu, Guoping] Univ Nottingham, Nottingham, England.
C3 Shenzhen University; Shenzhen Institute of Artificial Intelligence &
   Robotics for Society; University of Nottingham
RP Qiu, GP (corresponding author), Shenzhen Univ, Shenzhen, Peoples R China.
EM guoping.qiu@nottingham.ac.uk
OI Zhou, Fei/0000-0003-1216-2181; Qiu, Guoping/0000-0002-5877-5648
FU Education Department of Guangdong Province, P.R. China [2019KZDZX1028]
FX This work is partially supported by the Education Department of
   Guangdong Province, P.R. China, under project No.2019KZDZX1028.
CR Andrew B., ARXIV PREPRINT ARXIV
   [Anonymous], 2018, ICML
   [Anonymous], 2005, Lectures on Lipschitz Analysis, University of Jyva"\skyla
   Arjovsky M., ARXIV PREPRINT ARXIV
   Arpit D., ARXIV PREPRINT ARXIV
   Berthelot D., ARXIV PREPRINT ARXIV
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Deng J., P248
   DOWSON DC, 1982, J MULTIVARIATE ANAL, V12, P450, DOI 10.1016/0047-259X(82)90077-X
   Fedus W., 2017, ARXIV171008446
   Fu JW, 2019, ADV SCI, V6, DOI 10.1002/advs.201900796
   Goodfellow IJ, 2014, ADV NEUR IN, P2672, DOI DOI 10.1145/3422622
   Gulrajani I., 2017, Advances in neural information processing systems, P5769
   Heusel M., 2017, ADV NEURAL INFORM PR, P6626
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isogawa M, 2019, INT J COMPUT VISION, V127, P1751, DOI 10.1007/s11263-018-1132-0
   Jamaludin A, 2019, INT J COMPUT VISION, V127, P1767, DOI 10.1007/s11263-019-01150-y
   Karras T., ARXIV PREPRINT ARXIV
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma P., ARXIV PREPRINT ARXIV
   Kodali N., 2017, ARXIV170507215
   Lim Theodore, 2016, P INT C LEARN REPR
   Mao Xudong, 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.304
   Mescheder L., ARXIV PREPRINT ARXIV
   Miyato T., 2018, 6 INT C LEARNING REP
   Miyato T, 2018, INT C LEARN REPR
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Radford A., 2015, ARXIV
   Salimans T, 2016, ADV NEUR IN, V29
   Salimans T, 2016, ADV NEUR IN, V29
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wu J., ARXIV PREPRINT ARXIV
NR 33
TC 3
Z9 4
U1 6
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104005
DI 10.1016/j.imavis.2020.104005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mazumder, P
   Singh, P
   Namboodiri, VP
AF Mazumder, Pratik
   Singh, Pravendra
   Namboodiri, Vinay P.
TI GIFSL - grafting based improved few-shot learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Few-shot learning; Grafting; Self-supervision; Distillation; Deep
   learning; Object recognition
AB A few-shot learning model generally consists of a feature extraction network and a classification module. In this paper, we propose an approach to improve few-shot image classification performance by increasing the representational capacity of the feature extraction network and improving the quality of the features extracted by it. The ability of the feature extraction network to extract highly discriminative features from images is essential to few-shot learning. Such features are generally class agnostic and contain information about the general content of the image. Our approach improves the training of the feature extraction network in order to enable them to produce such features. We train the network using filter-grafting along with an auxiliary self-supervision task and a knowledge distillation procedure. Particularly, filter-grafting rejuvenates unimportant (invalid) filters in the feature extraction network to make them useful and thereby, increases the number of important filters that can be further improved by using self-supervision and knowledge distillation techniques. This combined approach helps in significantly improving the few-shot learning performance of the model. We perform experiments on several few-shot learning benchmark datasets such as mini-ImageNet, tiered-ImageNet, CIFAR-FS, and FC100 using our approach. We also present various ablation studies to validate the proposed approach. We empirically show that our approach performs better than other state-of-the-art few-shot learning methods. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Mazumder, Pratik; Singh, Pravendra; Namboodiri, Vinay P.] Indian Inst Technol Kanpur, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
   [Namboodiri, Vinay P.] Univ Bath, Bath, Avon, England.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur; University of Bath
RP Mazumder, P (corresponding author), Indian Inst Technol Kanpur, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
EM pratikm@iitk.ac.in; psingh@iitk.ac.in; vinaypn@iitk.ac.in
RI Mazumder, Pratik/AAK-2564-2021; Singh, Pravendra/ABC-9247-2020
OI Mazumder, Pratik/0000-0003-1103-1884; Singh,
   Pravendra/0000-0003-1001-2219; Namboodiri, Vinay/0000-0001-5262-9722
CR Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13
   [Anonymous], 2019, P INT C LEARN REPR
   [Anonymous], CALTECH UCSD BIRDS 2
   [Anonymous], LEARNING MULTIPLE LA
   [Anonymous], 2019, INT C LEARN REPR
   [Anonymous], 2018, INT C LEARN REPR
   [Anonymous], AUTOMATIC DIFFERENTI
   Apostoloff N., 2018, ARXIV180710585, V2
   Bartlett P.L., 2020, ARXIV200205715
   Chen J., 2020, P AAAI C ART INT
   Chen M., 2020, P AAAI C ART INT
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen Y., ARXIV200304390
   Chen ZT, 2019, PROC CVPR IEEE, P8672, DOI 10.1109/CVPR.2019.00888
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Dosovitskiy A, 2014, ADV NEUR IN, V27
   Feng ZY, 2019, PROC CVPR IEEE, P10356, DOI 10.1109/CVPR.2019.01061
   Finn C, 2017, PR MACH LEARN RES, V70
   Fleuret F., 2018, ARXIV180300443
   Gidaris S, 2019, IEEE I CONF COMP VIS, P8058, DOI 10.1109/ICCV.2019.00815
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Hadsell R, INT C LEARN REPR, P2020
   He J., 2020, ARXIV200504414
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   Huang Z., 2017, ARXIV170701219
   Koch G, 2015, P 32 INT C MACHINE L
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li H., 2017, P ICLR
   Li K., 2020, ADVERSARIAL FEATURE
   Lifchitz Y, 2019, PROC CVPR IEEE, P9250, DOI 10.1109/CVPR.2019.00948
   Liu YH, 2019, INT J PSYCHIAT CLIN, V23, P164, DOI 10.1080/13651501.2019.1569238
   Lucic M., 2018, NEURAL ORDINARY DIFF
   Meng FX, 2020, PROC CVPR IEEE, P6598, DOI 10.1109/CVPR42600.2020.00663
   Mishra N., 2018, INT C LEARN REPR
   Munkhdalai Tsendsuren, 2017, Proc Mach Learn Res, V70, P2554
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Owens A, 2016, LECT NOTES COMPUT SC, V9905, P801, DOI 10.1007/978-3-319-46448-0_48
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755
   Ravichandran A, 2019, IEEE I CONF COMP VIS, P331, DOI 10.1109/ICCV.2019.00042
   Ren M, 2018, 6 INT C LEARNING REP
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A. A., 2019, INT C LEARN REPR
   Satorras V. G., 2018, ICLR
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Vinyals O., 2014, NEURIPS
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Yan SP, 2019, AAAI CONF ARTIF INTE, P9079
   Yiluan Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13496, DOI 10.1109/CVPR42600.2020.01351
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhuo H., 2018, ARXIV PREPRINT ARXIV
NR 61
TC 6
Z9 6
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104006
DI 10.1016/j.imavis.2020.104006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cantoni, V
   Cascone, L
   Nappi, M
   Porta, M
AF Cantoni, Virginio
   Cascone, Lucia
   Nappi, Michele
   Porta, Marco
TI Demographic classification through pupil analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Pupil analysis; Gaze analysis
ID EYE-MOVEMENTS; ADABOOST; DIAMETER; SIZE; AGE
AB An area of biometrics that has recently attracted much attention is gender and age classification. Its applications can be found not only in the fields of security and surveillance, but also in the context of marketing and demographic information gathering. In addition, extracting this information from a biometric sample can help to decrease the time to identify the exact individual. In this paper, we exploit pupil size as a discriminating feature for the estimation of gender and age. Data obtained from the free observation of face images have been used to train two classifiers (Adaboost and SVM), considering both the best results produced by each classifier and their fusion through weighted means. With experiments involving more than 100 participants, we have found that pupil size can provide significant results, better than those achievable using data on fixations and gaze paths. Pupil Diameter Mean (PDM) has proved to be the best discriminating feature for both gender and age. To the best of our knowledge, there are no other studies trying to perform such a classification using pupil size only. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Cantoni, Virginio; Porta, Marco] Univ Pavia, Dipartimento Ingn Ind & Informaz, Via A Ferrata S, I-27100 Pavia, Italy.
   [Cascone, Lucia; Nappi, Michele] Univ Salerno, Dipartimento Informat, Via Giovanni Paolo II 32, I-84084 Salerno, Italy.
C3 University of Pavia; University of Salerno
RP Porta, M (corresponding author), Univ Pavia, Dipartimento Ingn Ind & Informaz, Via A Ferrata S, I-27100 Pavia, Italy.
EM marco.porta@unipv.it
RI Porta, Marco/ACW-5714-2022; Cascone, Lucia/ABV-5620-2022
OI Cascone, Lucia/0000-0002-9333-5699
CR [Anonymous], **DATA OBJECT**, DOI DOI 10.17632/3KN4JDD4KF.2
   [Anonymous], 2012, P COMPSYSTECH 12 13, DOI DOI 10.1145/2383276.2383331
   Bednarik R, 2005, LECT NOTES COMPUT SC, V3540, P780
   Cantoni V, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P574, DOI 10.1109/SITIS.2014.40
   Cantoni V, 2015, PATTERN RECOGN, V48, P1027, DOI 10.1016/j.patcog.2014.02.017
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Duchowski AndrewT., 2017, Eye Tracking Methodology: Theory and Practice, P3, DOI DOI 10.1007/978-3-319-57883-5_1
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Galdi C, 2016, PATTERN RECOGN LETT, V82, P226, DOI 10.1016/j.patrec.2015.08.018
   George A, 2016, PATTERN RECOGN LETT, V82, P207, DOI 10.1016/j.patrec.2015.11.020
   Guillon M, 2016, OPTOMETRY VISION SCI, V93, P1093, DOI 10.1097/OPX.0000000000000893
   Hämmerer D, 2017, NEUROBIOL AGING, V58, P129, DOI 10.1016/j.neurobiolaging.2017.06.021
   Holland Corey, 2011, 2011 INT JOINT C BIO, P1, DOI [DOI 10.1109/IJCB.2011.6117536, 10.1109/IJCB.2011.6117536.]
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Juhola M, 2013, COMPUT BIOL MED, V43, P42, DOI 10.1016/j.compbiomed.2012.10.005
   JUST MA, 1976, COGNITIVE PSYCHOL, V8, P441, DOI 10.1016/0010-0285(76)90015-3
   Kasprowski P, 2004, LECT NOTES COMPUT SC, V3087, P248
   Kasthurirangan S, 2006, VISION RES, V46, P1393, DOI 10.1016/j.visres.2005.07.004
   Kinnunen T, 2010, P S EYE TRACK RES AP, P187
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   Komogortsev O. V., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P209, DOI 10.1109/BTAS.2012.6374579
   Komogortsev O. V., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P413, DOI 10.1109/ICB.2012.6199786
   Mathôt S, 2015, J EXP PSYCHOL GEN, V144, P513, DOI 10.1037/a0039168
   Mitra S., 2017, OVERVIEW BIOMETRIC A
   Nugrahaningsih N, 2014, LECT NOTES COMPUT SC, V8897, P222, DOI 10.1007/978-3-319-13386-7_18
   Ortiz Estefan., 2013, IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1, DOI [10.1109/BTAS.2013.6712687, DOI 10.1109/BTAS.2013.6712687]
   Partala T, 2003, INT J HUM-COMPUT ST, V59, P185, DOI 10.1016/S1071-5819(03)00017-X
   Perego E, 2010, MEDIA PSYCHOL, V13, P243, DOI 10.1080/15213269.2010.502873
   Poerio GL, 2013, CONSCIOUS COGN, V22, P1412, DOI 10.1016/j.concog.2013.09.012
   Porta DD, 2012, ROUTL ADV CRIMINOL, P1
   Qu QX, 2019, INT J IND ERGONOM, V72, P281, DOI 10.1016/j.ergon.2019.06.006
   Randhawa K, 2018, IEEE ACCESS, V6, P14277, DOI 10.1109/ACCESS.2018.2806420
   Rigas I., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P217, DOI 10.1109/BTAS.2012.6374580
   Saeed K., 2016, NEW DIRECTIONS BEHAV
   Sai CY, 2018, IEEE J BIOMED HEALTH, V22, P664, DOI 10.1109/JBHI.2017.2723420
   Sanchis-Gimeno JA, 2012, SURG RADIOL ANAT, V34, P167, DOI 10.1007/s00276-011-0889-4
   Srivastava N, 2015, INT CONF CONTEMP, P365, DOI 10.1109/IC3.2015.7346708
   Wang F, 2019, J SUPERCOMPUT, V75, P7460, DOI 10.1007/s11227-019-02954-y
   Wang Y, 2018, EAR HEARING, V39, P573, DOI 10.1097/AUD.0000000000000512
NR 40
TC 9
Z9 9
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103980
DI 10.1016/j.imavis.2020.103980
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700002
DA 2024-07-18
ER

PT J
AU Pan, L
   Zhou, XF
   Shi, R
   Zhang, JY
   Yan, CG
AF Pan, Liang
   Zhou, Xiaofei
   Shi, Ran
   Zhang, Jiyong
   Yan, Chenggang
TI Cross-modal feature extraction and integration based RGBD saliency
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RGBD; Saliency; Cross-modal; Feature extraction; Integration
ID OBJECT DETECTION; NETWORK; FUSION
AB In RGBD saliency detection research field, RGB and depth cues are generally given the same status by RGBD saliency models. However, they ignore that both modalities are significantly different in inherent attribution so that effective features cannot be drawn from depth maps. In order to address this issue, this paper proposes a novel RGBD saliency model including two key components: the contrast-guided depth feature extraction (CDFE) module and the cross-modal feature integration (CFI) module. Specifically, considering the specific properties of depth information, we first design a targeted CDFE module, which learns multi-level deep depth features by strengthening the depth contrast between foreground and background, to provide multi-level deep depth features. Then, to sufficiently and reasonably integrate multi-level cross-modal features, namely the multi-level deep RGB and depth features, we equip the saliency inference branch with the CFI module, which contains two successive steps, i.e. information enrichment and feature enhancement. Extensive experiments are conducted on five challenging RGBD datasets, and the experimental results clearly demonstrate the effectiveness and superiority of the proposed model against the state-of-the-art RGBD saliency models. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Pan, Liang; Zhou, Xiaofei; Zhang, Jiyong; Yan, Chenggang] Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
   [Shi, Ran] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
C3 Hangzhou Dianzi University; Nanjing University of Science & Technology
RP Zhou, XF (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
EM zxforchid@outlook.com
OI Zhang, Jiyong/0000-0001-9600-8477
FU National Natural Science Foundation of China [61901145, 61801219,
   61931008]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61901145, Grant 61801219 and Grant
   61931008.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen H, 2018, IEEE INT C INT ROBOT, P6821, DOI 10.1109/IROS.2018.8594373
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007
   Chen YX, 2014, INTERNATIONAL CONFERENCE ON MECHANICS AND MATERIALS ENGINEERING (ICMME 2014), P23
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   FAN DP, ARXIV190706781
   Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257
   Glorot X., 2010, P INT C ART INT STAT, P249
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Kingma D. P., 2015, INT C LEARNING REPRE
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Liu C, 2010, IMAGE VISION COMPUT, V28, P825, DOI 10.1016/j.imavis.2009.07.009
   Mukherjee P, 2017, IMAGE VISION COMPUT, V61, P82, DOI 10.1016/j.imavis.2017.02.008
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Ren JQ, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301391
   Shigematsu R, 2017, IEEE INT CONF COMP V, P2749, DOI 10.1109/ICCVW.2017.323
   Simonyan K., 2014, 14091556 ARXIV
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhou XF, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103888
   Zhou XF, 2016, IEEE SIGNAL PROC LET, V23, P517, DOI 10.1109/LSP.2016.2536743
   Zhu CB, 2017, IEEE INT CONF COMP V, P1509, DOI 10.1109/ICCVW.2017.178
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 45
TC 6
Z9 6
U1 2
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2020
VL 101
AR 103964
DI 10.1016/j.imavis.2020.103964
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NP4HG
UT WOS:000570137900008
DA 2024-07-18
ER

PT J
AU Raj, R
   Rajiv, P
   Kumar, P
   Khari, M
   Verdú, E
   Crespo, RG
   Manogaran, G
AF Raj, Rohit
   Rajiv, Pooshkar
   Kumar, Prabhat
   Khari, Manju
   Verdu, Elena
   Gonzalez Crespo, Ruben
   Manogaran, Gunasekaran
TI Feature based video stabilization based on boosted HAAR Cascade and
   representative point matching algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Digital image stabilization; Representative point matching; Boosted HAAR
   Cascade; Foreground feature selection; Motion compensation
ID MOTION ESTIMATION; IMAGE; SCHEME
AB The success of handheld video capturing devices has further fueled the need of improved video stabilization. The videos often contain many foreground facial features like eyes, nose etc. These foreground features can be considered as feature points and may be used to stabilize videos. This paper proposes an innovative and effective digital video stabilization technique, which utilizes foreground features present in the video to produce consistent and stabilized output. It uses successive stages of Boosted HAAR cascade and representative point matching digital motion stabilization algorithm to identify and stabilize the video. The feature based tracking of object improves motion estimation accuracy between two frames thereby increasing the correlation calculation and compensation motion vector. This work achieves a significantly smoother sequence after the motion compensation. It also improves the robustness, precision and quality of the video when compared to traditional digital stabilization algorithms. The simulation results compared with pre-existing techniques reflect distinct improvements in Inter-Frame Transformation Fidelity values and Structural Similarity Index along with lesser standard deviation between image frames. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Raj, Rohit; Kumar, Prabhat] Natl Inst Technol Patna, Comp Sci & Engn, Patna, Bihar, India.
   [Rajiv, Pooshkar] Birla Inst Technol Mesra, Dept Elect & Commun Engn, Ranchi, Bihar, India.
   [Khari, Manju] Ambedkar Inst Adv Commun Technol & Res, Dept Comp Sci & Engn, Delhi, India.
   [Verdu, Elena; Gonzalez Crespo, Ruben] Univ Int La Rioja, Logrono, Spain.
   [Manogaran, Gunasekaran] Univ Calif Davis, Davis, CA 95616 USA.
   [Manogaran, Gunasekaran] Asia Univ, Taichung, Taiwan.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna; Birla Institute of Technology Mesra; Netaji Subhas
   University of Technology; Netaji Subhas University of Technology (East
   Campus); Universidad Internacional de La Rioja (UNIR); University of
   California System; University of California Davis; Asia University
   Taiwan
RP Crespo, RG (corresponding author), Univ Int La Rioja, Logrono, Spain.
EM rohit124197@nitp.ac.in; prabhat@nitp.ac.in; manjukhari@aiactr.ac.in;
   elena.verdu@unir.net; ruben.gonzalez@unir.net; gmanogaran@ieee.org
RI Gonzalez Crespo, Ruben/P-8601-2018; Khari, Manju/B-6040-2017; Kumar,
   Prabhat/HGC-8304-2022; Verdu, Elena/A-5021-2019; Kumar,
   Prabhat/AAA-9743-2019
OI Gonzalez Crespo, Ruben/0000-0001-5541-6319; Verdu,
   Elena/0000-0002-3040-7077; Kumar, Prabhat/0000-0001-9945-7702
CR Abdullah L. M., 2012, Proceedings of the 2012 IEEE Control and System Graduate Research Colloquium (ICSGRC 2012), P303, DOI 10.1109/ICSGRC.2012.6287181
   [Anonymous], 2013, VISUAL COMMUNICATION
   Ayad H, 2018, INT J INTERACT MULTI, V5, P81, DOI 10.9781/ijimai.2018.01.001
   Chen BH, 2016, ENG APPL ARTIF INTEL, V54, P39, DOI 10.1016/j.engappai.2016.05.004
   EGUSA Y, 1995, IEEE T FUZZY SYST, V3, P351, DOI 10.1109/91.413239
   Ertürk S, 2001, ELECTRON LETT, V37, P1217, DOI 10.1049/el:20010729
   HOOKE R, 1961, J ACM, V8, P212, DOI 10.1145/321062.321069
   Hsu SC, 2005, IEEE T CONSUM ELECTR, V51, P335, DOI 10.1109/TCE.2005.1467968
   Hsu SC, 2007, IEEE T SYST MAN CY C, V37, P234, DOI 10.1109/TSMCC.2006.887009
   Joshi RC, 2019, INT J INTERACT MULTI, V5, P28, DOI 10.9781/ijimai.2019.01.001
   Kamble SD, 2017, INT J INTERACT MULTI, V4, P27, DOI 10.9781/ijimai.2017.444
   Khari M, 2019, INT J INTERACT MULTI, V5, P22, DOI 10.9781/ijimai.2019.09.002
   Kim SK, 2013, IEEE T CONSUM ELECTR, V59, P267, DOI 10.1109/TCE.2013.6490269
   Ko SJ, 1998, IEEE T CONSUM ELECTR, V44, P617, DOI 10.1109/30.713172
   Koh YJ, 2015, IEEE T IMAGE PROCESS, V24, P5260, DOI 10.1109/TIP.2015.2479918
   Marcenaro L, 2001, IEEE IMAGE PROC, P349, DOI 10.1109/ICIP.2001.959025
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Mizuki MM, 1996, INT CONF ACOUST SPEE, P3248, DOI 10.1109/ICASSP.1996.550569
   Okade M, 2016, IEEE T CIRC SYST VID, V26, P453, DOI 10.1109/TCSVT.2015.2412772
   Pacheco A, 2014, INT J INTERACT MULTI, V2, P7, DOI 10.9781/ijimai.2014.261
   PAIK JK, 1992, IEEE T CONSUM ELECTR, V38, P607, DOI 10.1109/30.156744
   Qiang Y., 2006, 2006 7 INT C COMP AI, P1
   Ryu YG, 2012, IEEE SIGNAL PROC LET, V19, P223, DOI 10.1109/LSP.2012.2188286
   Saxena H, 2019, 2019 NATIONAL POWER ELECTRONICS CONFERENCE (NPEC), DOI 10.1109/npec47332.2019.9034769
   Song JF, 2015, INT CONF AWARE SCI, P91, DOI 10.1109/ICAwST.2015.7314026
   Tang CY, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/614378
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang CT, 2009, IEEE T CONSUM ELECTR, V55, P6, DOI 10.1109/TCE.2009.4814407
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu J, 2013, MEAS SCI REV, V13, P122, DOI 10.2478/msr-2013-0021
   Yoon I, 2015, 2015 IEEE 5TH INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - BERLIN (ICCE-BERLIN), P116, DOI 10.1109/ICCE-Berlin.2015.7391209
   Yu JY, 2019, PROC CVPR IEEE, P3795, DOI 10.1109/CVPR.2019.00392
   Yu JY, 2018, LECT NOTES COMPUT SC, V11209, P569, DOI 10.1007/978-3-030-01228-1_34
NR 33
TC 14
Z9 15
U1 3
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2020
VL 101
AR 103957
DI 10.1016/j.imavis.2020.103957
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NP4HG
UT WOS:000570137900004
DA 2024-07-18
ER

PT J
AU Rana, MS
   Nibali, A
   He, Z
   Morgan, S
AF Rana, Md Sohel
   Nibali, Aiden
   He, Zhen
   Morgan, Stuart
TI Automated repair of fragmented tracks with 1D CNNs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiple object tracking; Fragmented track repair; Occlusion handling
ID SOCCER PLAYER TRACKING; CAMERA
AB Multiple object tracking is an important but challenging computer vision problem. The complex motion of objects makes tracking difficult during long periods of object occlusion, and as a result occlusions frequently cause fragmented tracks with gaps. Previous works use linear interpolation to fill in such gaps, a technique which is only able to model simple motion. As a result, tracked bounding box locations can be quite poor in these situations. In this paper, we propose a 1D CNN based solution to filling gaps which models complex motion in a data-driven way. Our proposed solution uses only bounding box coordinates as input, and as such does not incur the computational cost of processing image features directly. We show that our model significantly outperforms linear interpolation on dynamic sports datasets in terms of mean intersection over union between predicted and ground truth bounding boxes. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Rana, Md Sohel; Nibali, Aiden; He, Zhen] La Trobe Univ, Dept Comp Sci, Melbourne, Vic, Australia.
   [Morgan, Stuart] Australian Inst Sport, Bruce, ACT, Australia.
C3 La Trobe University; Australian Institute of Sport
RP Rana, MS (corresponding author), La Trobe Univ, Dept Comp Sci, Melbourne, Vic, Australia.
EM M.Rana@latrobe.edu.au
RI Rana, Sohel/IXX-0615-2023; Rana, Sohel/AAX-1677-2020; Morgan, Stuart
   W/B-9850-2017
OI Rana, Sohel/0000-0002-0410-9228; Nibali, Aiden/0000-0002-1352-9910;
   Morgan, Stuart/0000-0002-4512-4774
FU Australian Institute of Sport, Australia
FX We are grateful to the Australia Institute of Sport for providing
   annotated netball and hockey videos to us for use in this project. This
   work was partially funded by Australian Institute of Sport, Australia.
CR [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Baysal S, 2016, IEEE T CIRC SYST VID, V26, P1350, DOI 10.1109/TCSVT.2015.2455713
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Choi C, 2019, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2019.00101
   Dearden A., 2006, TRACKING FOOTBALL PL
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   Gedikli S., 2007, INT C COMP VIS SYST
   Hamid R, 2010, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.2010.5540142
   Joo SW, 2007, IEEE T IMAGE PROCESS, V16, P2849, DOI 10.1109/TIP.2007.906254
   Kim C, 2018, LECT NOTES COMPUT SC, V11212, P208, DOI 10.1007/978-3-030-01237-3_13
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JC, 2013, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2013.239
   Manafifard M, 2017, COMPUT VIS IMAGE UND, V159, P19, DOI 10.1016/j.cviu.2017.02.002
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Misu T, 2009, LECT NOTES COMPUT SC, V5371, P39, DOI 10.1007/978-3-540-92892-8_6
   Morais E, 2014, PATTERN RECOGN LETT, V39, P21, DOI 10.1016/j.patrec.2013.09.007
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Nishikawa Y, 2018, IEEE TOPIC CONF WIRE, P8, DOI 10.1109/WISNET.2018.8311550
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Sabirin H, 2015, IEICE T INF SYST, VE98D, P1580, DOI 10.1587/transinf.2014EDP7313
   Sadeghian A, 2019, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2019.00144
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Senocak A, 2018, IEEE COMPUT SOC CONF, P1813, DOI 10.1109/CVPRW.2018.00225
   Shen Han, 2018, ARXIV180801562
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Wang GA, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P482, DOI 10.1145/3343031.3350853
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468
   Zamir AR, 2012, LECT NOTES COMPUT SC, V7573, P343, DOI 10.1007/978-3-642-33709-3_25
NR 35
TC 3
Z9 3
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2020
VL 101
AR 103982
DI 10.1016/j.imavis.2020.103982
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NP4HG
UT WOS:000570137900005
DA 2024-07-18
ER

PT J
AU Nousi, P
   Tefas, A
   Pitas, I
AF Nousi, Paraskevi
   Tefas, Anastasios
   Pitas, Ioannis
TI Dense convolutional feature histograms for robust visual object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object Tracking; Deep Learning; Bag-of-Features; Convolutional Feature
   Histograms
ID NETWORKS
AB Despite recent breakthroughs in the field, Visual Object Tracking remains an open and challenging task in Computer Vision. Modern applications require trackers to not only be accurate but also very last, even on embedded systems. In this work, we use features from Convolutional Neural Networks to build histograms, which are more adept at handling appearance variations, in an end-to-end trainable architecture. To deal with the internal covariate shift that occurs when extracting histograms from convolutional features as well as to incorporate informations from the multiple levels of the neural hierarchy, we propose and use a novel densely connected architecture where histograms from multiple layers are concatenated to produce the final representation. Experimental results validate our hypotheses on the benefits of using histograms as opposed to standard convolutional features, as the proposed histogram-based tracker surpasses recently proposed sophisticated trackers on multiple benchmarks. Long-term tracking results also reaffirm the usefulness of the proposed tracker in more challenging scenarios, where appearance variations are more severe and traditional trackers fail. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Nousi, Paraskevi; Tefas, Anastasios; Pitas, Ioannis] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Nousi, P (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
EM paranous@csd.auth.gr; tefas@aiia.csd.auth.gr; pitas@aiia.csd.auth.gr
RI Tefas, Anastasios/ABA-2328-2020; Tefas, Anastasios/F-1899-2010
OI Tefas, Anastasios/0000-0003-1288-3667
FU European Unions Horizon 2020 research and innovation programme [731667]
FX This project has received funding fromthe European Unions Horizon 2020
   research and innovation programme under grant agreement No 731667
   (MULTIDRONE). This publication reflects the authors views only. The
   European Commission is not responsible for any use that may be made of
   the information it contains.
CR [Anonymous], ARXIV151105879
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Deng J., IMAGENET LARGE SCALE
   Deori B., 2014, Int. J. Inf. Theory, V3, P31, DOI [DOI 10.5121/IJIT.2014.3304, 10.5121/ijit.2014.3304]
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kamate S, 2015, PROCEDIA COMPUT SCI, V61, P436, DOI 10.1016/j.procs.2015.09.183
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li Y., ARXIV190202804
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Passalis N, 2019, IEEE T NEUR NET LEAR, V30, P1705, DOI 10.1109/TNNLS.2018.2872995
   Passalis N, 2017, IEEE I CONF COMP VIS, P5766, DOI 10.1109/ICCV.2017.614
   Passalis N, 2017, PATTERN RECOGN, V64, P277, DOI 10.1016/j.patcog.2016.11.014
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vojir T, 2014, PATTERN RECOGN LETT, V49, P250, DOI 10.1016/j.patrec.2014.03.025
   Wang Q., 2017, ARXIV170404057
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zoidi O, 2013, IEEE T CIRC SYST VID, V23, P870, DOI 10.1109/TCSVT.2012.2226527
NR 40
TC 10
Z9 10
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2020
VL 99
AR 103933
DI 10.1016/j.imavis.2020.103933
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LZ3LW
UT WOS:000541130800006
DA 2024-07-18
ER

PT J
AU Li, J
   Deng, BS
   Zhang, MJ
   Yan, Y
   Wang, ZM
AF Li, Jing
   Deng, Baosong
   Zhang, Maojun
   Yan, Ye
   Wang, Zhengming
TI Local-adaptive and outlier-tolerant image alignment using RBF
   approximation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image alignment; radial basis function; scattered data approximation;
   outlier removal; computer vision
ID POLYHARMONIC SPLINES; REGISTRATION; WARPS
AB Image alignment is a crucial step to generate a high quality panorama. The state-of-the-art approaches use local-adaptive transformations to deal with multi-view parallax, but still suffer from unreliable feature correspondences and high computational cost. In this paper, we propose a local-adaptive and outlier-tolerant image alignment method using RBF (radial basis function) approximation. To eliminate the visible artifacts, the input images are warped according to a constructed projection error function, whose parameters are estimated by solving a linear system. The outliers are efficiently removed by screening out the abnormal weights of RBFs, such that better alignment quality can be achieved compared to the existing approaches. Moreover, a weight assignment strategy is introduced to further address the overfitting issues caused by extrapolation, and hence the global projectivity can be well preserved. The proposed method is computationally efficient, whose performance is verified by comparative experiments on several challenging cases. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Li, Jing; Deng, Baosong; Yan, Ye] Acad Mil Med Sci, NIIDT, Beijing, Peoples R China.
   [Li, Jing; Deng, Baosong] TAIIC, Tianjin, Peoples R China.
   [Zhang, Maojun; Wang, Zhengming] Natl Univ Def Technol, Coll Syst Engn, Changsha, Peoples R China.
C3 Academy of Military Medical Sciences - China; National University of
   Defense Technology - China
RP Li, J (corresponding author), Acad Mil Med Sci, NIIDT, Beijing, Peoples R China.
EM jingli@nudt.edu.cn
RI wang, zhengming/AAL-8263-2020
FU National Natural Science Foundation of China (NSFC) [61801504, 61703415]
FX The following authors report financial support: Jing Li, National
   Natural Science Foundation of China (NSFC), 61703415; Baosong Deng,
   National Natural Science Foundation of China (NSFC), 61801504.
CR [Anonymous], [No title captured]
   [Anonymous], BRIT MACH VIS C
   ARAD N, 1995, COMPUT GRAPH FORUM, V14, P35, DOI 10.1111/1467-8659.1410035
   ARAD N, 1994, CVGIP-GRAPH MODEL IM, V56, P161, DOI 10.1006/cgip.1994.1015
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Beatson RK, 2007, IMA J NUMER ANAL, V27, P427, DOI 10.1093/imanum/drl027
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Bozzini M, 2010, APPL MATH COMPUT, V216, P317, DOI 10.1016/j.amc.2010.01.065
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Carroll R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531349
   Chang CH, 2014, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2014.422
   Chen YS, 2016, LECT NOTES COMPUT SC, V9909, P186, DOI 10.1007/978-3-319-46454-1_12
   de Boer A, 2007, COMPUT STRUCT, V85, P784, DOI 10.1016/j.compstruc.2007.01.013
   Fasshauer G.E., 2007, Meshfree approximation methods with MATLAB
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao JH, 2011, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2011.5995433
   HARDY RL, 1990, COMPUT MATH APPL, V19, P163, DOI 10.1016/0898-1221(90)90272-L
   He KM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462004
   Heckbert P.S., 1989, Fundamentals of texture mapping and image warping
   Herrmann C, 2018, LECT NOTES COMPUT SC, V11206, P53, DOI 10.1007/978-3-030-01216-8_4
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Jia JY, 2008, IEEE T PATTERN ANAL, V30, P617, DOI 10.1109/TPAMI.2007.70729
   Li J, 2018, IEEE T MULTIMEDIA, V20, P1672, DOI 10.1109/TMM.2017.2777461
   Lin CC, 2015, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2015.7298719
   Lin KM, 2017, PROC CVPR IEEE, P2701, DOI 10.1109/CVPR.2017.289
   Lin KM, 2016, LECT NOTES COMPUT SC, V9907, P370, DOI 10.1007/978-3-319-46487-9_23
   Lin WY, 2011, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2011.5995314
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Majdisova Z, 2017, APPL MATH MODEL, V51, P728, DOI 10.1016/j.apm.2017.07.033
   Nie Y, 2017, IEEE T IMAGE PROCESS, Vpp
   Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9
   Rohr K, 1996, LECT NOTES COMPUT SC, V1131, P297, DOI 10.1007/BFb0046967
   Sprengel R, 1997, P IEEE EMBS, V18, P1190, DOI 10.1109/IEMBS.1996.652767
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolf L, 2007, IEEE I CONF COMP VIS, P1418
   Zagorchev L, 2006, IEEE T IMAGE PROCESS, V15, P529, DOI 10.1109/TIP.2005.863114
   Zaragoza J, 2014, IEEE T PATTERN ANAL, V36, P1285, DOI 10.1109/TPAMI.2013.247
   Zhang F, 2014, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2014.423
   Zhang GF, 2016, IEEE T IMAGE PROCESS, V25, P3099, DOI 10.1109/TIP.2016.2535225
   Zhang ZR, 2018, IEEE ACCESS, V6, P42631, DOI 10.1109/ACCESS.2018.2860627
   Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2
NR 45
TC 2
Z9 2
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103890
DI 10.1016/j.imavis.2020.103890
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000010
DA 2024-07-18
ER

PT J
AU Cruz, S
   Chan, A
AF Cruz, Sergio
   Chan, Antoni
TI Is that my hand? An egocentric dataset for hand disambiguation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Egocentric perspective; Hand detection
AB With the recent development of wearable cameras, the interest for research on the egocentric perspective is increasing. This opens the possibility to work on a specific object detection problem of hand detection and hand disambiguation. However, recent progress in egocentric hand disambiguation and even hand detection, especially using deep learning, has been limited by the lack of a large dataset, with suitable variations in subject, activity, and scene. In this paper, we propose a dataset that simulates daily activities, with variable illumination and people from different cultures and ethnicity to address daily life conditions. We increase the dataset size from previous works to allow robust solutions like deep neural networks that need a substantial amount of data for training. Our dataset consists of 50,000 annotated images with 10 different subjects doing 5 different daily activities (biking, eating, kitchen, office and running) in over 40 different scenes with variable illumination and changing backgrounds, and we compare with previous similar datasets.
   Hands in an egocentric view are challenging to detect due to a number of factors, such as shape variations, inconsistent illumination, motion blur, and occlusion. To improve hand detection and disambiguation, context information can be included to aid in the detection. In particular, we propose three neural network architectures that jointly learn the hand and context information, and we provide baseline results with current object/hand detection approaches. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Cruz, Sergio; Chan, Antoni] City Univ Hong Kong, Kowloon, Tat Chee Ave, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Cruz, S; Chan, A (corresponding author), City Univ Hong Kong, Kowloon, Tat Chee Ave, Hong Kong, Peoples R China.
EM scruzgome2-c@my.cityu.edu.hk; abchan@cityu.edu.hk
RI ; CHAN, Antoni B./D-7858-2013
OI Cruz, Sergio/0000-0001-9444-7038; CHAN, Antoni B./0000-0002-2886-2513
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Betancourt A, 2014, IEEE COMPUT SOC CONF, P600, DOI 10.1109/CVPRW.2014.92
   Chandrasekhar V, 2014, IEEE COMPUT SOC CONF, P541, DOI 10.1109/CVPRW.2014.84
   Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44
   Fathi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3281, DOI 10.1109/CVPR.2011.5995444
   Fathi A, 2012, PROC CVPR IEEE, P1226, DOI 10.1109/CVPR.2012.6247805
   Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269
   Finocchiaro J, 2017, IEEE WINT CONF APPL, P1142, DOI 10.1109/WACV.2017.132
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gunther Tobias, 2015, 2015 IEEE Virtual Reality (VR), P327, DOI [10.1109/3DUI.2015.7131748, 10.1109/VR.2015.7223428]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee S, 2014, IEEE COMPUT SOC CONF, P557, DOI 10.1109/CVPRW.2014.86
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li C, 2013, IEEE I CONF COMP VIS, P2624, DOI 10.1109/ICCV.2013.326
   Li C, 2013, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2013.458
   Li Y, 2015, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2015.7298625
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Poleg Y., 2014, TEMPORAL SEGMENTATIO
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren XF, 2010, PROC CVPR IEEE, P3137, DOI 10.1109/CVPR.2010.5540074
   Ryoo MS, 2016, INT J COMPUT VISION, V119, P307, DOI 10.1007/s11263-015-0847-4
   Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352
   Spriggs EH, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2009.5204354
   Spurr A, 2018, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2018.00017
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Urooj Aisha, 2018, IEEE C COMP VIS PATT
NR 33
TC 10
Z9 10
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 131
EP 143
DI 10.1016/j.imavis.2019.06.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900012
DA 2024-07-18
ER

PT J
AU Torres, DM
   Correa, HL
   Bravo, EC
AF Martinez Torres, Duber
   Loaiza Correa, Humberto
   Caicedo Bravo, Eduardo
TI Online learning of contexts for detecting suspicious behaviors in
   surveillance videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Incremental learning; Online learning; Context; Suspicious behavior;
   Surveillance
ID RECOGNITION; INFORMATION
AB One of the main incentives for implementing video-based surveillance systems is the urban security. During the last years, several approaches for automatic detection of suspicious events have been proposed. Those methods usually require a training stage before starting their operation. This means that previous to run time a representative dataset of interest events, that may occur in the future, must be available. Nevertheless, most real surveillance systems lack of that information, so many of those proposals results impractical.
   In this paper, a context online learning scheme for detecting suspicious behaviors on surveillance videos is proposed. Contextual information, which is inferred from videos of people in a scenario, allows detecting suspicious behaviors before an eventual criminal's final attack occur. The main attribute of the proposed approach is the capacity to start up its operation with a reduced training dataset. By an incremental learning process, which uses new data obtained during the online operation, the proposed scheme improves the performance over time achieving a better adaptation to conditions of each scenario.
   The proposed scheme was validated on two datasets. The first of them includes threats against a parked truck and its driver. The second testing dataset is composed of night assault scenes recorded in an urban environment. The experimental results demonstrate that the proposed method is able to learn incrementally from a reduced initial dataset, achieving a performance similar to batch-type systems trained with all data simultaneously and outperforming five state-of-the-art algorithms over violence detection. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Martinez Torres, Duber; Loaiza Correa, Humberto; Caicedo Bravo, Eduardo] Univ Valle, Escuela Ingn Elect & Elect, Cali, Colombia.
C3 Universidad del Valle
RP Torres, DM (corresponding author), Univ Valle, Escuela Ingn Elect & Elect, Cali, Colombia.
EM duber.martinez@correounivalle.edu.co;
   humberto.loaiza@correounivalle.edu.co;
   eduardo.caicedo@correounivalle.edu.co
OI Loaiza-Correa, Humberto/0000-0001-7206-7333
FU PSI research group of Universidad del Valle (Colombia); Departamento
   Administrativo de Ciencia, Tecnologia e Innovacion-Colciencias
   (Colombia) [528-2011]
FX This work was supported by PSI research group of Universidad del Valle
   (Colombia), scholarship 528-2011 from Departamento Administrativo de
   Ciencia, Tecnologia e Innovacion-Colciencias (Colombia). We thank to
   MIVIA research group of the University of Salerno for their support to
   build the UVS-dataset. Also, acknowledgements to University of Reading
   for providing the PETS2014 dataset
CR [Anonymous], 1966, The hidden dimension: Man's use of space in public and private
   [Anonymous], ANN STAT
   [Anonymous], 2000, ADV LARGE MARGIN CLA
   Arroyo R, 2015, EXPERT SYST APPL, V42, P7991, DOI 10.1016/j.eswa.2015.06.016
   Bastani V, 2016, IEEE T IMAGE PROCESS, V25, P2089, DOI 10.1109/TIP.2016.2540813
   Chakroun M, 2015, INT CONF INTELL SYST, P563, DOI 10.1109/ISDA.2015.7489178
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   den Hollander Richard J. M, 2015, P SOC PHOTO-OPT INS, V9652
   Diehl CP, 2003, IEEE IJCNN, P2685
   Gaidon A, 2014, INT J COMPUT VISION, V107, P219, DOI 10.1007/s11263-013-0677-1
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   Hasan M, 2016, COMPUT VIS IMAGE UND, V144, P24, DOI 10.1016/j.cviu.2015.10.018
   Karmaker Amitava., 2007, International Journal of Hybrid Intelligent Systems, V4, P243
   Leyva R, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P621, DOI 10.1109/TSP.2017.8076061
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luis Jose, 2014, PETS 2014 DATASET CH, P355
   Mihajlo Grbovic, 2011, TRACKING CONCEPT CHA, P516
   Minhas R, 2012, IEEE T CIRC SYST VID, V22, P1529, DOI 10.1109/TCSVT.2011.2177182
   Mohammadi S, 2015, 2015 12TH INTERNATIONAL IRANIAN SOCIETY OF CRYPTOLOGY CONFERENCE ON INFORMATION SECURITY AND CRYPTOLOGY (ISCISC), P6, DOI 10.1109/ISCISC.2015.7387890
   Noceti N, 2014, PATTERN RECOGN, V47, P3535, DOI 10.1016/j.patcog.2014.05.008
   Rizwan Muhammad, 2015, DICTA, P1
   Rota P, 2015, IEEE IMAGE PROC, P3456, DOI 10.1109/ICIP.2015.7351446
   Subetha T., 2016, P IEEE 2016 INT C IN, P25, DOI [10.1109/ICICES.2016.7518920, DOI 10.1109/ICICES.2016.7518920]
   Wiliem A, 2012, COMPUT VIS IMAGE UND, V116, P194, DOI 10.1016/j.cviu.2011.10.001
   Wiliem A, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P146, DOI 10.1109/DICTA.2009.31
   Yang Xinzhu., 2009, Proceedings of CSA 2009, P1, DOI DOI 10.1109/APPEEC.2009.4918470
   Yasin Amanullah, 2013, THESIS
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Zhang TZ, 2013, IEEE T IND INFORM, V9, P149, DOI 10.1109/TII.2012.2218251
   Zhao Chaoyang, 2016, MAT RES, P1
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P1360, DOI 10.1109/TPAMI.2014.2369044
   Zhu YY, 2013, IEEE J-STSP, V7, P91, DOI 10.1109/JSTSP.2012.2234722
NR 32
TC 5
Z9 5
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 197
EP 210
DI 10.1016/j.imavis.2019.07.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900017
DA 2024-07-18
ER

PT J
AU Chacon-Murguia, MI
   Guzman-Pando, A
   Ramirez-Alonso, G
   Ramirez-Quintana, JA
AF Chacon-Murguia, Mario I.
   Guzman-Pando, Abimael
   Ramirez-Alonso, Graciela
   Ramirez-Quintana, Juan A.
TI A novel instrument to compare dynamic object detection algorithms
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dynamic object detection; Algorithm methodology comparison; Video
   analysis
ID FOREGROUND SEGMENTATION; HISTOGRAM
AB Nowadays, the amount of dynamic object detection in video sequences algorithms has increased considerably. Notwithstanding the many efforts to provide benchmarking resource, a standard methodology to achieve this evaluation does not exist. Most of the existing benchmarking resources concentrate on the evaluation of the algorithms from a rigid perspective by using just quantitative metric values of the performance. However, these evaluations do not consider important criteria like documentation, auto-adaptability, novelty, speed, which are important factors to consider from a scientific and/or real word application. Therefore, this paper proposes a new methodology to evaluate, compare, and select dynamic object detection algorithms by considering the criteria previously mentioned including performance. The new methodology was developed by analyzing 119 algorithms and the databases CDnet2014, CDnet2012 and BMC The findings indicate that the proposed methodology preserves consistence with some of the rankings in the databases, but it also provides more complete and useful information in the evaluation of the algorithm. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Chacon-Murguia, Mario I.; Guzman-Pando, Abimael; Ramirez-Quintana, Juan A.] Tecnol Nacl Mexico IT Chihuahua, Chih, Mexico.
   [Ramirez-Alonso, Graciela] Univ Autonoma Chihuahua, Chih, Mexico.
RP Chacon-Murguia, MI (corresponding author), Tecnol Nacl Mexico IT Chihuahua, Chih, Mexico.
EM mchacon@ieee.org; aguzman@itchihuahua.edu.mx; galonso@uach.mx;
   jaramirez@itchihuahua.edu.mx
OI Guzman Pando, Abimael/0000-0003-0819-0438; Ramirez-Alonso,
   Graciela/0000-0002-9781-3010
FU Tecnologico Nacional de Mexico/I. T. Chihuahua [5162.19-P]
FX The authors wish to extend their thanks to Tecnologico Nacional de
   Mexico/I. T. Chihuahua for the support provided to carry out this work,
   under grant 5162.19-P.
CR Al-Berr MN, 2016, PROCEEDINGS OF 2016 11TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P172, DOI 10.1109/ICCES.2016.7821995
   Al-Khateeb H., 2010, COMP VIS PATT REC WO, P53
   Ramirez-Quintana JA, 2015, PATTERN RECOGN, V48, P1137, DOI 10.1016/j.patcog.2014.09.009
   [Anonymous], 2016, J MENINGITIS, DOI DOI 10.1016/J.BMC1.2015.12.021
   [Anonymous], 2013, 9 WORKSHOP VISAO COM
   Azzam R, 2016, J VIS COMMUN IMAGE R, V36, P90, DOI 10.1016/j.jvcir.2015.11.009
   Babaee M., 2017, CVMI WORKSH CVPR, P1
   Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a
   Benezeth Y, 2008, INT C PATT RECOG, P237, DOI 10.1109/icpr.2008.4760998
   Benezeth Y., 2012, J ELECTRON IMAGING, V19, P1
   Bianco Simone, 2015, CAN YOU GET COMBININ
   Biao Y, 2015, OPTIK, V126, P4586, DOI 10.1016/j.ijleo.2015.08.064
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Braham M, 2017, IEEE IMAGE PROC, P4552, DOI 10.1109/ICIP.2017.8297144
   Buch N, 2011, IEEE T INTELL TRANSP, V12, P920, DOI 10.1109/TITS.2011.2119372
   Caetano TS, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P275, DOI 10.1109/SIBGRA.2002.1167155
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Chacon-Murguia MI, 2014, STUD COMPUT INTELL, V547, P315, DOI 10.1007/978-3-319-05170-3_22
   Chen ML, 2014, LECT NOTES COMPUT SC, V8695, P521, DOI 10.1007/978-3-319-10584-0_34
   Chen ZZ, 2014, COMPUT VIS IMAGE UND, V122, P35, DOI 10.1016/j.cviu.2014.01.004
   Chiranjeevi P, 2014, IEEE T CYBERNETICS, V44, P870, DOI 10.1109/TCYB.2013.2274330
   David C, 2013, INT SYMP IMAGE SIG, P230
   Deb A, 2016, PR IEEE COMP DESIGN, P17, DOI 10.1109/ICCD.2016.7753256
   Dey B, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2445631
   González FAD, 2015, COMPUT SIST, V19, P283, DOI 10.13053/CyS-19-2-2006
   Dong P, 2016, IEEE T IMAGE PROCESS, V25, P5035, DOI 10.1109/TIP.2016.2598680
   Dou JF, 2014, OPTIK, V125, P435, DOI 10.1016/j.ijleo.2013.06.079
   Dou JF, 2013, OPTIK, V124, P6081, DOI 10.1016/j.ijleo.2013.04.106
   ELHarrouss O, 2015, 2015 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   Evangelio R. H., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P71, DOI 10.1109/AVSS.2011.6027297
   Gervasoni L, 2014, SPAN 15 ARG S TECHN, P25
   Giordano D, 2014, INT C PATT RECOG, P4388, DOI 10.1109/ICPR.2014.751
   Giordano M., 2016, LETT NOTES COMPUT SC, V9281
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guo R, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 1, P209, DOI 10.1109/ICMLA.2013.43
   Hernandez-Lopez FJ, 2014, MACH VISION APPL, V25, P1175, DOI 10.1007/s00138-013-0564-3
   Hossain W, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1476, DOI 10.1109/ICACCCT.2014.7019348
   Hung M.H., 2014, J INFORM HIDING MULT, V5, P33
   Javed S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P930, DOI 10.1109/ICCVW.2015.123
   Jiang S., 2017, IEEE T CIRC SYST VID, V99, P1, DOI DOI 10.1109/TCSVT.2017.2711659.HTTP://IEEEXPL0RE.IEEE.0RG/D0CUMENT/7938679/
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kim W, 2016, IEEE SIGNAL PROC LET, V23, P634, DOI 10.1109/LSP.2016.2544778
   Kulchandani J. S., 2015, PERV COMP ICPC 2015, V1, P1
   Lee S., 2014, WISENETMD MOTION DET
   Lee S, 2015, OPTIK, V126, P2063, DOI 10.1016/j.ijleo.2015.05.074
   Lim L.A, 2018, ARXIV180102225V1, P1
   Lim L. A., 2018, 180801477 ARXIV
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Lu HY, 2015, 2015 INTERNATIONAL CONFERENCE ON SOFTWARE, MULTIMEDIA AND COMMUNICATION ENGINEERING (SMCE 2015), P1
   Martins I, 2017, LECT NOTES COMPUT SC, V10255, P50, DOI 10.1007/978-3-319-58838-4_6
   Nikolov B, 2014, RADIOENGINEERING, V23, P652
   Pan J, 2013, CHIN CONT DECIS CONF, P901
   Panda DK, 2016, IEEE SIGNAL PROC LET, V23, P45, DOI 10.1109/LSP.2015.2498839
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Radolko M, 2015, INT SYMP IMAGE SIG, P31, DOI 10.1109/ISPA.2015.7306028
   Ramírez-Alonso G, 2016, NEUROCOMPUTING, V175, P990, DOI 10.1016/j.neucom.2015.04.118
   Ramirez-Quintana JA, 2015, NEURAL PROCESS LETT, V42, P665, DOI 10.1007/s11063-014-9380-7
   Rao G. Mallikarjuna, 2014, International Journal of Intelligent Systems and Applications, V6, P83, DOI 10.5815/ijisa.2014.05.09
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Sajid H, 2015, IEEE IMAGE PROC, P4530, DOI 10.1109/ICIP.2015.7351664
   Sakkos D, 2018, MULTIMED TOOLS APPL, V77, P23023, DOI 10.1007/s11042-017-5460-9
   Sedky M, 2014, IEEE COMPUT SOC CONF, P405, DOI 10.1109/CVPRW.2014.65
   SHAH M, 2012, COMPUT VIS ACCV, V7728, P308
   Shakeri M, 2016, COMPUT VIS IMAGE UND, V146, P27, DOI 10.1016/j.cviu.2016.02.009
   Sobral A., 2015, LRSLIBRARY LOW RANK
   Spampinato C, 2014, COMPUT VIS IMAGE UND, V122, P74, DOI 10.1016/j.cviu.2013.12.003
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Staglianò A, 2015, IEEE T IMAGE PROCESS, V24, P2415, DOI 10.1109/TIP.2015.2421435
   Subudhi BN, 2015, SOFT COMPUT, V19, P2769, DOI 10.1007/s00500-014-1440-4
   Tiefenbacher P, 2014, IEEE IMAGE PROC, P3282, DOI 10.1109/ICIP.2014.7025664
   Vacavant A., 2015, BACKGROUND MODELING, P1
   Vujovic I, 2013, IET IMAGE PROCESS, V7, P671, DOI 10.1049/iet-ipr.2013.0169
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Zhao Z., 2015, IEEE T IMAGE PROCESS, V7149, P1
   [郑文博 Zheng Wenbo], 2018, [自动化学报, Acta Automatica Sinica], V44, P878
   Zhou G., 2015, IEEE T NEUR NET LEAR, V13, P736, DOI DOI 10.1109/TNNLS.2015.2423694
   Zhou Q., 2001, Proceedings of IEEE Workshop on Performance Evaluation of Tracking and Surveillance, P46
   Zhu G, 2014, IEEE INT VEH SYM, P432, DOI 10.1109/IVS.2014.6856603
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 82
TC 4
Z9 4
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 19
EP 28
DI 10.1016/j.imavis.2019.04.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400003
DA 2024-07-18
ER

PT J
AU Park, JM
   Lee, JW
AF Park, Jeong Min
   Lee, Joon Woong
TI Lane estimation by particle-filtering combined with likelihood
   computation of line boundaries and motion compensation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Probabilistic lane estimation; Likelihood computation; Motion
   compensation; ROI weighting; Two-step particle filtering
ID MACHINE VISION; SYSTEM; TRACKING
AB Roads are exposed to various kinds of noise, lighting conditions and weather; thus, robust lane localization is difficult Our paper presents an algorithm for a probabilistic estimation of lane information and solves the problem by the combining particle-filtering (PF) with likelihood computation of pixels on line boundaries using Gaussian like functions. Additionally, because a pitch or an abrupt yaw motion of the camera makes lane estimation imprecise, motion compensation is added to the estimation. Thus, the algorithm provides precise lane information to a driver assistant or autonomous driving system. The results of experiments show that the algorithm is well adapted to various lane conditions. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Park, Jeong Min; Lee, Joon Woong] Chonnam Natl Univ, Ind Engn Dept, 77 Yongbong Ro, Gwangju 61186, South Korea.
C3 Chonnam National University
RP Lee, JW (corresponding author), Chonnam Natl Univ, Ind Engn Dept, 77 Yongbong Ro, Gwangju 61186, South Korea.
EM joonlee@chonnam.ac.kr
FU Chonnam National University [2016-2688]
FX This study was financially supported by Chonnam National University
   (Grant number: 2016-2688).
CR Apostoloff N, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P558, DOI 10.1109/IVS.2003.1212973
   Bar Hillel A, 2014, MACH VISION APPL, V25, P727, DOI 10.1007/s00138-011-0404-2
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   Borkar A, 2009, IEEE IMAGE PROC, P3261, DOI 10.1109/ICIP.2009.5413980
   Chiu KY, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P706
   Danescu R, 2009, IEEE T INTELL TRANSP, V10, P272, DOI 10.1109/TITS.2009.2018328
   Hsiao PY, 2009, IEEE T VEH TECHNOL, V58, P2089, DOI 10.1109/TVT.2008.2006618
   Huang SS, 2004, IEEE INT CONF ROBOT, P2456
   Huval Brody., 2015, COMPUTER VISION PATT
   Jung CR, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P891
   Kim J, 2017, NEURAL NETWORKS, V87, P109, DOI 10.1016/j.neunet.2016.12.002
   Lee JW, 2005, COMPUT VIS IMAGE UND, V99, P359, DOI 10.1016/j.cviu.2005.03.002
   Lee JW, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P100, DOI 10.1109/IVS.2003.1212891
   Lee M, 2016, J INFRASTRUCT SYST, V22, DOI 10.1061/(ASCE)IS.1943-555X.0000269
   Li QQ, 2014, IEEE T VEH TECHNOL, V63, P540, DOI 10.1109/TVT.2013.2281199
   McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595
   Ozgunalp U, 2017, IEEE T INTELL TRANSP, V18, P621, DOI 10.1109/TITS.2016.2586187
   Park J. W., J IMAGING SCI TECHNO, V45
   Park JW, 2003, PATTERN RECOGN LETT, V24, P2301, DOI 10.1016/S0167-8655(03)00056-4
   Pomerleau D, 1996, IEEE EXPERT, V11, P19, DOI 10.1109/64.491277
   Pomerleau D. A, 1989, P ADV NEURAL INFORM, P305
   Ruyi J, 2011, MACH VISION APPL, V22, P721, DOI 10.1007/s00138-010-0307-7
   Shin DH, 2010, P I MECH ENG D-J AUT, V224, P849, DOI 10.1243/09544070JAUTO1306
   Son J, 2015, EXPERT SYST APPL, V42, P1816, DOI 10.1016/j.eswa.2014.10.024
   Tian M, 2006, PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON VEHICULAR ELECTRONICS AND SAFETY, P413
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Wang Y, 2000, PATTERN RECOGN LETT, V21, P677, DOI 10.1016/S0167-8655(00)00021-0
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
NR 28
TC 5
Z9 5
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 11
EP 24
DI 10.1016/j.imavis.2018.04.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800002
DA 2024-07-18
ER

PT J
AU Karanam, S
   Li, Y
   Radke, RJ
AF Karanam, Srikrishna
   Li, Yang
   Radke, Richard J.
TI Person re-identification with block sparse recovery
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Block sparsity; Video analytics
ID SIGNAL RECOVERY; CLASSIFICATION; ALGORITHMS
AB We consider the problem of automatically re-identifying a person of interest seen in a "probe" camera view among several candidate people in a "gallery" camera view. This problem, called person re-identification, is of fundamental importance in several video analytics applications. While extracting knowledge from high dimensional visual representations based on the notions of sparsity and regularization has been successful for several computer vision problems, such techniques have not been fully exploited in the context of the re-identification problem. Here, we develop a principled algorithm for the re-identification problem in the general framework of learning sparse visual representations. Given a set of feature vectors for a person in one camera view (corresponding to multiple images as they are tracked), we show that a feature vector representing the same person in another view approximately lies in the linear span of this feature set. Furthermore, under certain conditions, the associated coefficient vector can be characterized as being block sparse. This key insight allows us to design an algorithm based on block sparse recovery that achieves stateof-the-art results in multi-shot person re-identification. We also revisit an older feature transformation technique, Fisher discriminant analysis, and show that, when combined with our proposed formulation, it outperforms many sophisticated methods. Additionally, we show that the proposed algorithm is flexible and can be used in conjunction with existing metric learning algorithms, resulting in improved ranking performance. We perform extensive experiments on several publicly available datasets to evaluate the proposed algorithm. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Karanam, Srikrishna; Li, Yang; Radke, Richard J.] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Rensselaer, NY 12180 USA.
C3 Rensselaer Polytechnic Institute
RP Karanam, S (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Rensselaer, NY 12180 USA.
EM srikrishna@ieee.org
RI Radke, Richard J/I-3289-2013
FU U.S. Department of Homeland Security, Science and Technology
   Directorate, Office of University Programs [2013-ST-061-ED0001]
FX This material is based upon work supported by the U.S. Department of
   Homeland Security, Science and Technology Directorate, Office of
   University Programs, under Award 2013-ST-061-ED0001. The views and
   conclusions contained in this document are those of the authors and
   should not be interpreted as necessarily representing the official
   policies, either expressed or implied, of the U.S. Department of
   Homeland Security.
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2010, Human identification based on gait
   [Anonymous], SPIE OPTICAL ENG APP
   [Anonymous], 2014, INT J ANTENNAS PROPA
   Bach F, 2012, FOUND TRENDS MACH LE, V4, P1, DOI 10.1561/2200000015
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Bialkowski A, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA)
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Camps O., 2016, IEEE T CIRCUITS SYST
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chakraborty A., 2015, IEEE T PATTERN ANAL, V6, P591
   Chapelle O, 2010, INFORM RETRIEVAL, V13, P201, DOI 10.1007/s10791-009-9109-9
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Eldar YC, 2009, IEEE T INFORM THEORY, V55, P5302, DOI 10.1109/TIT.2009.2030471
   Elhamifar E., 2012, Advances in Neural Information Processing Systems, P19
   Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   Gong DNT, 2009, LECT NOTES COMPUT SC, V5716, P179, DOI 10.1007/978-3-642-04146-4_21
   Gou M., 2016, P BRIT MACH VIS C YO
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Harandi MT, 2012, LECT NOTES COMPUT SC, V7573, P216, DOI 10.1007/978-3-642-33709-3_16
   He XF, 2004, ADV NEUR IN, V16, P153
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Ibn Khedher M, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P159, DOI 10.1109/AVSS.2013.6636633
   Jaakkola T., 1998, ANN C NEUR INF PROC
   Karanam S., 2015, IEEE ISPRS 2 JOINT W
   Karanam S., 2015, P BRIT MACH VIS C SW
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Y, 2015, IEEE WINT CONF APPL, P373, DOI 10.1109/WACV.2015.56
   Li Yang., 2015, BMVC
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Ma B, 2012, WORK HYPERSP IMAG
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Martinel N., 2014, P INT C DISTR SMART
   Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048
   Martinel N, 2015, IEEE T PATTERN ANAL, V37, P1656, DOI 10.1109/TPAMI.2014.2377748
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Schmid C., 2001, IEEE C COMP VIS PATT
   Simonnet D, 2012, LECT NOTES COMPUT SC, V7583, P423, DOI 10.1007/978-3-642-33863-2_42
   Sugiyama M., 2006, P 23 INT C MACH LEAR, P905, DOI DOI 10.1145/1143844.1143958
   Vedaldi A., 2010, INT C MULT
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhu PF, 2013, IEEE I CONF COMP VIS, P2664, DOI 10.1109/ICCV.2013.331
NR 71
TC 13
Z9 15
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 75
EP 90
DI 10.1016/j.imavis.2016.11.015
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800009
DA 2024-07-18
ER

PT J
AU Pham, TTT
   Le, TL
   Vu, H
   Dao, TK
   Nguyen, VT
AF Thi Thanh Thuy Pham
   Thi-Lan Le
   Hai Vu
   Trung Kien Dao
   Van Toi Nguyen
TI Fully-automated person re-identification in multi-camera surveillance
   system with a robust kernel descriptor and effective shadow removal
   method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person Re-ID; Non-overlapping cameras; Kernel descriptor; Shadow
   removal; Score fusion scheme
ID ALGORITHMS
AB In this paper, a fully-automated person Re-ID (Re-identification) system is proposed for real scenarios of human tracking in non-overlapping camera network. The system includes two phases of human detection and Re-ID. The human ROIs (Regions of Interest) are extracted from human detection phase and then feature extraction is done on these ROIs in order to build human descriptor for Re-ID. Unlike other approaches which deal with manually-cropped human ROls for person Re-ID, in this system, the person identity is determined based on the human ROIs extracted automatically by a combined method of human detection. Two main contributions are proposed on both phases of human detection and Re-ID in order to enhance the performance of person Re-ID system. First, an effective shadow removal method based on score fusion of density matching is proposed to get better human detection results. Second, a robust KDES (Kernel DEScriptor) is extracted from human ROI for person classification. Additionally, a new person Re-ID dataset is built in real surveillance scenarios from multiple cameras. The experiments on benchmark datasets and our own dataset show that the person Re-ID results using the proposed solutions outperform some of the state-of-the-art methods. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Thi Thanh Thuy Pham; Thi-Lan Le; Hai Vu; Trung Kien Dao] Hanoi Univ Sci & Technol, Int Res Inst MICA, HUST CNRS UMI 2954 GRENOBLE INP, Hanoi, Vietnam.
   [Thi-Lan Le] Acad People Secur, Hanoi, Vietnam.
   [Van Toi Nguyen] Thai Nguyen Univ, Univ Informat & Commun Technol, Thai Nguyen, Vietnam.
C3 Hanoi University of Science & Technology (HUST); Thai Nguyen University
RP Le, TL (corresponding author), Hanoi Univ Sci & Technol, Int Res Inst MICA, HUST CNRS UMI 2954 GRENOBLE INP, Hanoi, Vietnam.
EM Thi-Lan.Le@mica.com.vn
RI Kien, Dao Trung/AAT-8068-2021; Le, Thi-Lan/AAA-5855-2020; Vu,
   Hai/AAI-9419-2020
OI Vu, Hai/0000-0003-2880-4417; Dao, Trung-Kien/0000-0002-4726-3858; Le,
   Thi-Lan/0000-0001-9541-3905
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.04-2013.32]
FX This research is funded by the Vietnam National Foundation for Science
   and Technology Development (NAFOSTED) under grant number 102.04-2013.32.
CR Alavi A, 2013, IEEE IMAGE PROC, P3542, DOI 10.1109/ICIP.2013.6738731
   [Anonymous], 2015, UBICOMM 2015
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2003, Journal of machine learning research
   [Anonymous], 2010, ADV NEUR INF PROC SY
   [Anonymous], 2007, PROC IEEE C COMPUT V
   [Anonymous], 2011, BRIT MACH VIS C DUND
   [Anonymous], 2010, P BRIT MACH VIS C
   [Anonymous], 2010, Asian Conference on Computer Vision
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bauml M., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P291, DOI 10.1109/AVSS.2011.6027339
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Cavallaro A, 2005, IEE P-VIS IMAGE SIGN, V152, P398, DOI 10.1049/ip-vis:20045108
   Chapelle O, 2010, INFORM RETRIEVAL, V13, P201, DOI 10.1007/s10791-009-9109-9
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Figueira D., 2014, COMPUTER VISION ECCV, P241
   Figueira D, 2011, LECT NOTES COMPUT SC, V6753, P294, DOI 10.1007/978-3-642-21593-3_30
   Gong DNT, 2009, LECT NOTES COMPUT SC, V5716, P179, DOI 10.1007/978-3-642-04146-4_21
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Huang JB, 2009, PROC CVPR IEEE, P2310, DOI 10.1109/CVPRW.2009.5206629
   Maji S, 2013, IEEE T PATTERN ANAL, V35, P66, DOI 10.1109/TPAMI.2012.62
   Martel-Brisson N., 2008, IEEE C COMPUTER VISI, P1
   Martel-Brisson N, 2007, IEEE T PATTERN ANAL, V29, P1133, DOI 10.1109/TPAMI.2007.1039
   Martin N.J., 2012, Decreases in Psychological Well-Being Among American Adolescents, P1
   Martinel N., 2013, 2013 7 INT C DISTRIB, P1
   Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Sanin Andres, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P141, DOI 10.1109/ICPR.2010.43
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Simonnet D, 2012, LECT NOTES COMPUT SC, V7583, P423, DOI 10.1007/978-3-642-33863-2_42
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Teixeira LF, 2009, PATTERN RECOGN LETT, V30, P157, DOI 10.1016/j.patrec.2008.04.001
   Wang Bing-bing, 2011, Proceedings of the 2011 International Conference on Transportation and Mechanical & Electrical Engineering (TMEE), P527, DOI 10.1109/TMEE.2011.6199257
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Zhang S, 2015, IEEE WINT CONF APPL, P365, DOI 10.1109/WACV.2015.55
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 45
TC 16
Z9 16
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2017
VL 59
BP 44
EP 62
DI 10.1016/j.imavis.2016.10.010
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EP9IS
UT WOS:000397687900004
DA 2024-07-18
ER

PT J
AU Samangouei, P
   Patel, VM
   Chellappa, R
AF Samangouei, Pouya
   Patel, Vishal M.
   Chellappa, Rama
TI Facial attributes for active authentication on mobile devices
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Attributes; Security; Active authentication; Face; Mobile
ID FACE; RETRIEVAL; PATTERNS
AB We present a method using facial attributes for continuous authentication of smartphone users. We train a bunch of binary attribute classifiers which provide compact visual descriptions of faces. The learned classifiers are applied to the image of the current user of a mobile device to extract the attributes and then authentication is done by simply comparing the calculated attributes with the enrolled attributes of the original user. Extensive experiments on two publicly available unconstrained mobile face video datasets show that our method is able to capture meaningful attributes of faces and performs better than the previously proposed LBP-based authentication method. We also provide a practical variant of our method for efficient continuous authentication on an actual mobile device by doing extensive platform evaluations of memory usage, power consumption, and authentication speed. Published by Elsevier B.V.
C1 [Samangouei, Pouya; Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
   [Patel, Vishal M.] Rutgers State Univ, Dept Elect & Comp Engn, 94 Brett Rd, Piscataway, NJ USA.
C3 University System of Maryland; University of Maryland College Park;
   Rutgers University System; Rutgers University New Brunswick
RP Samangouei, P (corresponding author), Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
EM pouya@umiacs.umd.edu; vishal.m.patel@rutgers.edu; rama@umiacs.umd.edu
RI Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAV-8690-2020
FU DARPA [FA8750-13-2-0279]
FX This work was supported by cooperative agreement FA8750-13-2-0279 from
   DARPA.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2015, IEEE INT C AC SPEECH
   [Anonymous], 2003, P 2003 WORKSH MULT U
   [Anonymous], 2013, Biometrics (ICB), 2013 International Conference on
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], SPIE DEFENSE SECURIT
   [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   [Anonymous], 2015, CNBC
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Bradski G, 2000, DR DOBBS J, V25, P120
   Carrillo C. M., 2003, DTIC DOCUMENT
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cox D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P8, DOI 10.1109/FG.2011.5771385
   Crouse D, 2015, INT CONF BIOMETR, P135, DOI 10.1109/ICB.2015.7139043
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   Derawi M. O., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P306, DOI 10.1109/IIHMSP.2010.83
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Feng T, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, P451, DOI 10.1109/THS.2012.6459891
   Ferrari V., 2007, P 20 INT C NEUR INF, P433
   Frank M, 2013, IEEE T INF FOREN SEC, V8, P136, DOI 10.1109/TIFS.2012.2225048
   Fridman L., 2015, IEEE SYSTEMS J
   Hadid A, 2007, 2007 FIRST ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P96
   Jain A, 2000, COMMUN ACM, V43, P90, DOI 10.1145/328236.328110
   Jain AK, 2004, LECT NOTES COMPUT SC, V3087, P259
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Janakiraman R, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P501
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Klare BF, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Klosterman A.J., 2000, Secure continuous biometric-enhanced authentication
   Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Liu MX, 2014, NEUROCOMPUTING, V139, P34, DOI 10.1016/j.neucom.2013.09.056
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   McCool C., 2012, IEEE ICME WORKSH HOT
   Monrose F., 2002, International Journal of Information Security, V1, P69, DOI 10.1007/s102070100006
   Niinuma K, 2010, IEEE T INF FOREN SEC, V5, P771, DOI 10.1109/TIFS.2010.2075927
   Obeid M., 2001, Proceedings of the ninth ACM international conference on Multimedia, P531
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Patel VM, 2016, IEEE SIGNAL PROC MAG, V33, P49, DOI 10.1109/MSP.2016.2555335
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Primo A, 2014, IEEE COMPUT SOC CONF, P98, DOI 10.1109/CVPRW.2014.20
   Sim T, 2007, IEEE T PATTERN ANAL, V29, P687, DOI 10.1109/TPAMI.2007.1010
   Spillane R. J., 1975, IBM Technical Disclosure Bulletin, V17
   Takacs G., 2008, MIR 08, P427, DOI DOI 10.1145/1460096.1460165
   The MathWorks Inc, 2014, MATLAB VERS 8 4 0 15
   Thornton J., 2011, 2011 IEEE International Conference on Technologies for Homeland Security (HST 2011), P55, DOI 10.1109/THS.2011.6107847
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhang H, 2015, IEEE WINT CONF APPL, P207, DOI 10.1109/WACV.2015.35
   Zhang LA, 2010, KEY ENG MATER, V419-420, P105
   Zhang LY, 2014, INT J MULTIMED INF R, V3, P69, DOI 10.1007/s13735-014-0052-1
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao W, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P336, DOI 10.1109/AFGR.1998.670971
NR 64
TC 40
Z9 45
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 181
EP 192
DI 10.1016/j.imavis.2016.05.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700017
DA 2024-07-18
ER

PT J
AU Papazoglou, A
   Del Pero, L
   Ferrari, V
AF Papazoglou, Anestis
   Del Pero, Luca
   Ferrari, Vittorio
TI Discovering object aspects from video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual aspects; Object aspect discovery
AB We investigate the problem of automatically discovering the visual aspects of an object class. Existing methods discover aspects from still images under strong supervision, as they require time-consuming manual annotation of the objects' location (e.g. bounding boxes). Instead, we explore using video, which enables automatic localisation by motion segmentation. We introduce a new video dataset containing over 10,000 frames annotated with aspect labels for two classes: cars and tigers. We evaluate several strategies for aspect discovery using state-of-the-art descriptors (e.g. CNN), and assess, the benefits of using automatic video segmentation. For this, we introduce a new protocol to evaluate aspect discovery directly, in contrast to the general trend of evaluating it indirectly (e.g. its impact on a recognition pipeline). Our results consistently show that leveraging the nature of video to discover visual aspects yields significantly more accuracy. Finally, we discuss two new applications to showcase the potential of aspect discovery: image retrieval of aspects, and learning aspect transitions from video. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Papazoglou, Anestis; Del Pero, Luca; Ferrari, Vittorio] Univ Edinburgh, Edinburgh EH8 9YL, Midlothian, Scotland.
C3 University of Edinburgh
RP Papazoglou, A (corresponding author), Univ Edinburgh, Edinburgh EH8 9YL, Midlothian, Scotland.
EM a.papazoglou@sms.ed.ac.uk; ldelper@staffmail.ed.ac.uk;
   vferrari@staffmail.ed.ac.uk
CR Aghazadeh O., 2012, ECCV
   [Anonymous], ECCV
   [Anonymous], BIOL CYBERN
   [Anonymous], 2009, ICCV
   [Anonymous], 2012, CVPR
   [Anonymous], 2006, IEEECOMPUT SOC C COM
   [Anonymous], IEEE T PAMI
   [Anonymous], ISCE
   [Anonymous], 2013, CVPR
   [Anonymous], CVPR
   [Anonymous], ARXIV13101531
   [Anonymous], 2014, PROC BRIT MACH VIS C
   [Anonymous], DEEPVISION WORKSH CV
   [Anonymous], ECCV
   [Anonymous], P ICPR
   [Anonymous], IEEE T PAMI
   [Anonymous], 2008, CVPR
   [Anonymous], 2011, ICCV
   [Anonymous], 2013, Caffe: An open source convolutional architecture for fast feature embedding
   [Anonymous], FOCS
   [Anonymous], 2010, ECCV
   [Anonymous], 2012, PASCAL VISUAL OBJECT
   [Anonymous], MSRTR2011114
   [Anonymous], ICCV
   [Anonymous], 2013, ICCV
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 2011, Ensemble of Exemplar-SVMs for Object Detection and Beyond
   Azizpour H., 2012, ECCV
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Brox T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2225, DOI 10.1109/CVPR.2011.5995659
   Girshick R., 2013, IEEE Comput. Soc., P580
   Gu C., 2010, ECCV
   Gu Chunhui., 2012, ECCV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lowe DG, 2001, PROC CVPR IEEE, P682
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Mei Liang., 2011, ICCV
   Savarese S., 2008, ECCV
   Su H., 2009, ICCV
   Thomas A., 2006, CVPR
NR 41
TC 1
Z9 1
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 206
EP 217
DI 10.1016/j.imavis.2016.04.014
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400016
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Shin, J
   Kim, D
AF Shin, Jongju
   Kim, Daijin
TI Robust face alignment and tracking by combining local search and global
   fitting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face alignment; Face tracking; Local search method; Global fitting
   method; Combination of local search and global fitting methods
AB When a face in an image is considerably occluded, existing local search and global fitting methods often cannot find the facial features due to failures in the local facial feature detectors or the fitting limitations of appearance modeling. To solve these problems, we propose a new face alignment method that combines the local search and global fitting methods, where local misalignments in the local search method are restricted by holistic appearance fitting in the global fitting method and the divergent or shrinking alignments in the global fitting method are avoided by the restricting local movements in the local search method. The proposed alignment method consists of two stages: the initialization stage detects the face, estimates the facial pose and obtains the initial facial features by locating a pose-specific mean shape on the detected face; the optimization stage then obtains the facial features by updating the parameter set from the combined Hessian matrix and the combined gradient vector. We also extend the proposed face alignment to face tracking by adding a template image that is warped from the facial features obtained in the previous frame. In the experiments, the proposed method yields more accurate and stable face alignment or tracking under heavy occlusion and pose variation than the existing methods. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Shin, Jongju; Kim, Daijin] Pohang Univ Sci & Technol, Dept Comp Sci & Engn, San 31, Pohang 790784, Gyeongbuk, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Kim, D (corresponding author), Pohang Univ Sci & Technol, Dept Comp Sci & Engn, San 31, Pohang 790784, Gyeongbuk, South Korea.
EM jjshin@postech.ac.kr; dkim@postech.ac.kr
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   "ICT Consilience Creative Program" [IITP-2015-R0346-15-1007]; IITP grant
   - Korean government (MSIP) (Development of Predictive Visual
   Intelligence Technology) [B0101-15-0552]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the "ICT Consilience Creative Program"
   (IITP-2015-R0346-15-1007) supervised by the IITP (Institute for
   Information & Communications Technology Promotion), and was also
   supported by IITP grant funded by the Korean government (MSIP)
   (B0101-15-0552, Development of Predictive Visual Intelligence
   Technology).
CR Alabort-i-Medina J, 2015, PROC CVPR IEEE, P3679, DOI 10.1109/CVPR.2015.7298991
   [Anonymous], 300 FACES WILD CHALL
   [Anonymous], CMURITR0335 ROB I
   [Anonymous], 2010, Fddb: A benchmark for face detection in unconstrained settings
   [Anonymous], CVPR 2012 IEEE C
   [Anonymous], 2012 IEEE C COMP VIS
   [Anonymous], 1998, 24 COMP VIS CTR
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Bishop C, 2007, RECOGNITION PATTERN
   Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cootes TF, 2001, PROC CVPR IEEE, P1114
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Fröba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   Huang C, 2005, IEEE I CONF COMP VIS, P446
   Huber P., 1981, Robust Statistics
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Matthews I., 2008, IEEE INT C AUTOMATIC, P1
   Navarathna R, 2011, IEEE I CONF COMP VIS, P1919, DOI 10.1109/ICCV.2011.6126461
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Saragih JM, 2009, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2009.5459461
   Theobald BJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P149
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Wang Y., 2008, IEEE C COMPUTER VISI, P1
   Wang Y., 2007, IEEE INT C COMPUTER, P1, DOI [10.1109/1CCV.2007.4409188, DOI 10.1109/1CCV.2007.4409188]
   Wu Y, 2013, PROC CVPR IEEE, P3452, DOI 10.1109/CVPR.2013.443
   Xiao J, 2004, PROC CVPR IEEE, P535
   Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yoon J, 2013, INT CONF UBIQ ROBOT, P755, DOI 10.1109/URAI.2013.6677446
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
NR 43
TC 3
Z9 3
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2016
VL 51
BP 69
EP 83
DI 10.1016/j.imavis.2016.04.012
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4HB
UT WOS:000378455900007
DA 2024-07-18
ER

PT J
AU Ardiyanto, I
   Miura, J
AF Ardiyanto, I.
   Miura, J.
TI Partial least squares-based human upper body orientation estimation with
   combined detection and tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human upper body orientation; Partial least squares; Multi-level
   HOG-LBP; Random Forest classifier; UKF tracker
AB This paper deals with the problem of estimating the human upper body orientation. We propose a framework which integrates estimation of the human upper body orientation and the human movements. Our human orientation estimator utilizes a novel approach which hierarchically employs partial least squares-based models of the gradient and texture features, coupled with the random forest classifier. The movement predictions are done by projecting detected persons into 3D coordinates and running an Unscented Kalman Filter-based tracker. The body orientation results are then fused with the movement predictions to build a more robust estimation of the human upper body orientation. We carry out comprehensive experiments and provide comparison results to show the advantages of our system over the other existing methods. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Ardiyanto, I.; Miura, J.] Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Aichi 4418580, Japan.
C3 Toyohashi University of Technology
RP Ardiyanto, I (corresponding author), Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Aichi 4418580, Japan.
EM iardiyanto@aisl.cs.tut.ac.jp; jun.miura@tut.jp
RI Ardiyanto, Igi/L-2069-2019
OI Ardiyanto, Igi/0000-0002-0006-1458
FU Grants-in-Aid for Scientific Research [25280093] Funding Source: KAKEN
CR Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156
   [Anonymous], 1975, Perspectives in probability and statistics
   Archer KJ, 2008, COMPUT STAT DATA AN, V52, P2249, DOI 10.1016/j.csda.2007.08.015
   Baltieri D, 2012, LECT NOTES COMPUT SC, V7576, P270, DOI 10.1007/978-3-642-33715-4_20
   Benbouzid D, 2012, J MACH LEARN RES, V13, P549
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cheng Chen, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P5, DOI 10.1109/AVSS.2011.6027284
   Choi W, 2010, LECT NOTES COMPUT SC, V6314, P553, DOI 10.1007/978-3-642-15561-1_40
   Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Genuer R, 2010, PATTERN RECOGN LETT, V31, P2225, DOI 10.1016/j.patrec.2010.03.014
   Hoiem D., 2006, CVPR
   Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Wang LM, 2007, LECT NOTES COMPUT SC, V4843, P189
   Weinrich C, 2012, IEEE INT C INT ROBOT, P2147, DOI 10.1109/IROS.2012.6386122
   Wold S., 1993, 3D QSAR DRUG DESIGN, P523, DOI DOI 10.1007/0-306-46858-1
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 23
TC 15
Z9 15
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 904
EP 915
DI 10.1016/j.imavis.2014.08.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900008
DA 2024-07-18
ER

PT J
AU Benhammadi, F
   Bey, KB
AF Benhammadi, Farid
   Bey, Kadda Beghdad
TI Password hardened fuzzy vault for fingerprint authentication system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Minutiae pairwise extraction; Fingerprint matching; Biocryptosystem;
   Fuzzy vault; Fingerprint authentication system
ID GENERATE STRONG KEYS; BIOMETRICS; EXTRACTORS; ALGORITHM
AB The present work attempts to build a bio-cryptographic system that combines transformed minutiae pairwise feature and user-generated password fuzzy vault. The fingerprint fuzzy vault is based on a new minutiae pairwise structure, which overcomes the fingerprint feature publication while the secret binary vault code is generated according to the fingerprint fuzzy vault result. The authentication process involves two stages: fuzzy vault matching and secret vault code validation. Our minutiae pairwise transformation produces different templates thus resolving the problem of cross matching attacks in fingerprint fuzzy vault. So, the original fingerprint template cannot be recreated because it is protected by the key generated from the user password. In addition, the proposed bio-cryptographic system ensures an acceptable security level for user authentication. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Benhammadi, Farid; Bey, Kadda Beghdad] Ecole Mil Polytech, Algiers, Algeria.
C3 Ecole Military Polytechnic
RP Benhammadi, F (corresponding author), Ecole Mil Polytech, BP 17 Bordj el Bahri, Algiers, Algeria.
EM benhammadif@yahoo.fr
CR Ahmad T, 2011, PATTERN RECOGN, V44, P2555, DOI 10.1016/j.patcog.2011.03.015
   Benhammadi F, 2007, PATTERN RECOGN, V40, P189, DOI 10.1016/j.patcog.2006.06.031
   Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3
   Boult T.E., 2007, P CVPR
   Chen HY, 2011, PATTERN RECOGN LETT, V32, P305, DOI 10.1016/j.patrec.2010.09.007
   Clancy T.C., 2003, P 2003 ACM SIGMM WOR, P45
   Das P, 2012, PATTERN RECOGN, V45, P3373, DOI 10.1016/j.patcog.2012.02.022
   Davida G.I., 1999, PROCWORKSHOP CODING, P129
   Davida GI, 1998, 1998 IEEE SYMPOSIUM ON SECURITY AND PRIVACY - PROCEEDINGS, P148, DOI 10.1109/SECPRI.1998.674831
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   Dodis Y, 2008, SIAM J COMPUT, V38, P97, DOI 10.1137/060651380
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Itakura Y., 2005, International Journal of Information Security, V4, P288, DOI [10.1007/s10207-004-0065-5, DOI 10.1007/S10207-004-0065-5]
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Juels A, 2006, DESIGN CODE CRYPTOGR, V38, P237, DOI 10.1007/s10623-005-6343-z
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Juels A, 2002, ISIT: 2002 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P408, DOI 10.1109/ISIT.2002.1023680
   Kanade S, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P59, DOI 10.1109/BSYM.2008.4655523
   Li P, 2012, EXPERT SYST APPL, V39, P6562, DOI 10.1016/j.eswa.2011.12.048
   Li P, 2010, J NETW COMPUT APPL, V33, P207, DOI 10.1016/j.jnca.2009.12.003
   Maio D, 1997, IEEE T PATTERN ANAL, V19, P27, DOI 10.1109/34.566808
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Mei Y, 2009, IMAGE VISION COMPUT, V27, P1169, DOI 10.1016/j.imavis.2008.11.003
   Merkle J., 2010, LECT NOTES INFORM P, VP-164, P57
   Mihailescu P., 2007, ABS07082974 CORR
   Monrose F, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P73, DOI 10.1145/319709.319720
   Monrose F, 2001, P IEEE S SECUR PRIV, P202, DOI 10.1109/SECPRI.2001.924299
   Moon D., 2009, WORLD ACAD SCI ENG T, V35, P109
   Nandakumar K, 2007, IEEE T INF FOREN SEC, V2, P744, DOI 10.1109/TIFS.2007.908165
   Nandalcumar K., 2007, P ICB
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Scheirer W. J., 2007, CRACKING FUZZY VAULT
   Schouten B, 2009, IMAGE VISION COMPUT, V27, P305, DOI 10.1016/j.imavis.2008.05.008
   Soutar C, 1999, ICSA GUIDE CRYPTOGRA
   Teoh ABJ, 2008, PATTERN RECOGN, V41, P2034, DOI 10.1016/j.patcog.2007.12.002
   Uludag U, 2005, LECT NOTES COMPUT SC, V3546, P310
   Uludag U., 2006, 2006 C COMPUTER VISI, P163
   Wang S., 2014, PATTERN RECOGN, V47, P2544
   Wang S, 2012, PATTERN RECOGN, V45, P4129, DOI 10.1016/j.patcog.2012.05.004
NR 41
TC 25
Z9 26
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 487
EP 496
DI 10.1016/j.imavis.2014.04.014
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600004
DA 2024-07-18
ER

PT J
AU Shreve, M
   Brizzi, J
   Fefilatyev, S
   Luguev, T
   Goldgof, D
   Sarkar, S
AF Shreve, Matthew
   Brizzi, Jesse
   Fefilatyev, Sergiy
   Luguev, Timur
   Goldgof, Dmitry
   Sarkar, Sudeep
TI Automatic expression spotting in videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Expression spotting; Macro-expressions; Micro-expressions
ID FACIAL EXPRESSIONS
AB In this paper, we propose a novel solution for the problem of segmenting macro- and micro-expression frames (or retrieving the expression intervals) in video sequences, which is a prior step for many expression recognition algorithms. The proposed method exploits the non-rigid facial motion that occurs during facial expressions by capturing the optical strain corresponding to the elastic deformation of facial skin tissue. The method is capable of spotting both macro-expressions which are typically associated with expressed emotions and rapid micro- expressions which are typically associated with semi-suppressed macro-expressions. We test our algorithm on several datasets, including a newly released hour-long video with two subjects recorded in a natural setting that includes spontaneous facial expressions. We also report results on a dataset that contains 75 feigned macro-expressions and 37 feigned micro-expressions. We achieve over a 75% true positive rate with a 1% false positive rate for macro-expressions, and a nearly 80% true positive rate for spotting micro-expressions with a .3% false positive rate. (C) 2014 Published by Elsevier B.V.
C1 [Shreve, Matthew; Brizzi, Jesse; Fefilatyev, Sergiy; Luguev, Timur; Goldgof, Dmitry; Sarkar, Sudeep] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.
C3 State University System of Florida; University of South Florida
RP Shreve, M (corresponding author), Univ S Florida, 4202 E Fowler Ave,ENB 118, Tampa, FL 33620 USA.
EM mshreve@mail.usf.edu
RI Sarkar, Sudeep/A-8213-2009; Goldgof, Dmitry/ABF-1366-2020; Luguev,
   Timur/L-5644-2014; Sarkar, Sudeep/ABD-7629-2021
OI Sarkar, Sudeep/0000-0001-7332-4207; Luguev, Timur/0000-0002-2294-9298;
   Sarkar, Sudeep/0000-0001-7332-4207
CR [Anonymous], THESIS U S FLORIDA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2011, International Journal of Wavelets Multiresolution and Information Processing, DOI DOI 10.1142/S021969130400041X
   Black M.J., 1997, RECOGNIZING FACIAL E, V25, P23
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Chen SZ, 2013, IMAGE VISION COMPUT, V31, P175, DOI 10.1016/j.imavis.2012.06.014
   EKMAN P, 1992, PHILOS T ROY SOC B, V335, P63, DOI 10.1098/rstb.1992.0008
   Ekman P., 2001, TELLING LIES CLUES D, V2nd
   Jeni LaszloA., 2013, 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction, P1
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Liwicki S., 2012, LECT NOTES COMPUTER, P162
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Padgett C, 1997, ADV NEUR IN, V9, P894
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pfister T., 2011, P INT C COMP VIS
   Polikovsky S, 2013, IEICE T INF SYST, VE96D, P81, DOI 10.1587/transinf.E96.D.81
   Ruiz-Rivas Joaquin, 2013, 2013 Conference on Lasers & Electro-Optics. Europe & International Quantum Electronics Conference (CLEO EUROPE/IQEC), DOI 10.1109/CLEOE-IQEC.2013.6801849
   Saragih J. M., 2009, INT C COMP VIS SEPT
   Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shreve M., 2009, WORKSH APPL COMP VIS
   SHREVE M, 2011, P 14 INT C COMP AN I, V6854, P512
   Shreve M., 2011, INT C AUT FAC GEST R
   Sung J, 2009, IMAGE VISION COMPUT, V27, P1313, DOI 10.1016/j.imavis.2008.11.010
   Tong Y, 2010, IEEE T PATTERN ANAL, V32, P258, DOI 10.1109/TPAMI.2008.293
   Wu Q, 2011, LECT NOTES COMPUT SC, V6975, P152, DOI 10.1007/978-3-642-24571-8_16
   Yoder NC, 2008, MATER EVAL, V66, P756
   Zaker N., 2012, 2012 IEEE INT C NOV, P1
   Zeng Z., 2006, J MULTIMED, V1, P1, DOI DOI 10.4304/jmm.1.5.1-8
NR 29
TC 31
Z9 38
U1 1
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 476
EP 486
DI 10.1016/j.imavis.2014.04.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600003
DA 2024-07-18
ER

PT J
AU Wang, DH
   Wang, XK
   Kong, S
AF Wang, Donghui
   Wang, Xikui
   Kong, Shu
TI Integration of multi-feature fusion and dictionary learning for face
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dictionary learning; Face recognition; Multiple features fusion; Tensor
   decomposition; Sparse coding
AB Recent research emphasizes more on analyzing multiple features to improve face recognition (FR) performance. One popular scheme is to extend the sparse representation based classification framework with various sparse constraints. Although these methods jointly study multiple features through the constraints, they just process each feature individually such that they overlook the possible high-level relationship among different features. It is reasonable to assume that the low-level features of facial images, such as edge information and smoothed/ low-frequency image, can be fused into a more compact and more discriminative representation based on the latent high-level relationship. FR on the fused features is anticipated to produce better performance than that on the original features, since they provide more favorable properties. Focusing on this, we propose two different strategies which start from fusing multiple features and then exploit the dictionary learning (DL) framework for better FR performance. The first strategy is a simple and efficient two-step model, which learns a fusion matrix from training face images to fuse multiple features and then learns class-specific dictionaries based on the fused features. The second one is a more effective model requiring more computational time that learns the fusion matrix and the class-specific dictionaries simultaneously within an iterative optimization procedure. Besides, the second model considers to separate the shared common components from class-specified dictionaries to enhance the discrimination power of the dictionaries. The proposed strategies, which integrate multi-feature fusion process and dictionary learning framework for FR, realize the following goals: (1) exploiting multiple features of face images for better FR performances; (2) learning a fusion matrix to merge the features into a more compact and more discriminative representation; (3) learning class-specific dictionaries with consideration of the common patterns for better classification performance. We perform a series of experiments on public available databases to evaluate our methods, and the experimental results demonstrate the effectiveness of the proposed models. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Wang, Donghui; Wang, Xikui; Kong, Shu] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Wang, DH (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
EM dhwang@zju.edu.cn; xkwang@zju.edu.cn; aimerykong@zju.edu.cn
FU Natural Science Foundations of China [61071218]; 973 Program
   [2010CB327904]
FX This work is supported by the Natural Science Foundations of China (no.
   61071218) and 973 Program (project no. 2010CB327904).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], CVPR
   [Anonymous], ICCV
   [Anonymous], 1990, Introduction to statistical pattern classification, DOI DOI 10.1016/B978-0-08-047865-4.50007-7
   [Anonymous], 2010, CVPR
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Cai D., 2007, PROC IEEE 11 INT C C
   Ekenel HK, 2005, IMAGE VISION COMPUT, V23, P469, DOI 10.1016/j.imavis.2004.09.002
   Gupta S, 2010, INT J COMPUT VISION, V90, P331, DOI 10.1007/s11263-010-0360-8
   Huang G. B., 2008, WORKSH FAC REAL LIF
   HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838
   Jiang Zhuolin., 2011, CVPR
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kong S., 2013, INT C AUT FAC GEST R
   Kong S., 2012, CORR
   Kong S., 2012, ECCV
   Kusuma GP, 2011, IMAGE VISION COMPUT, V29, P306, DOI 10.1016/j.imavis.2010.12.003
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li H., 2003, EFF ROB FEAT EXTR MA
   Liu ZM, 2010, IEEE T IMAGE PROCESS, V19, P2502, DOI 10.1109/TIP.2010.2048963
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Ramirez I., 2010, CLASS CLUST VIA DICT
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Wang DH, 2012, PATTERN RECOGN LETT, V33, P1695, DOI 10.1016/j.patrec.2012.06.010
   Wang XG, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P284
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Yang M., 2011, ICCV
   Yang M., 2010, MET LEARN SPARS REPR
   Ye J., 2004, ADV NEURAL INFORM PR
   Zhang Haichao., 2011, ICCV
   Zhang L., 2011, SPARS REPR COLL REPR
NR 36
TC 11
Z9 13
U1 0
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2013
VL 31
IS 12
BP 895
EP 904
DI 10.1016/j.imavis.2013.10.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 282DU
UT WOS:000329151300001
DA 2024-07-18
ER

PT J
AU Torsello, A
   Albarelli, A
   Rodolà, E
AF Torsello, Andrea
   Albarelli, Andrea
   Rodola, Emanuele
TI Stable and fast techniques for unambiguous compound phase coding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Structured light; 3D reconstruction; Phase shift
ID FOURIER-TRANSFORM PROFILOMETRY; NONSINUSOIDAL WAVE-FORMS; STRUCTURED
   LIGHT; SURFACE RECONSTRUCTION
AB Phase shift methods have proven to be very robust and accurate for photometric 3D reconstruction. One problem of these approaches is the existence of ambiguities arising from the periodicity of the fringe patterns. While several techniques for disambiguation exist, all of them require the projection of a significant number of additional patterns. For instance, a global Gray coding sequence or supplemental sinusoidal patterns of different periods are commonly used to complement the basic phase shift technique. In this paper we propose four new coding strategies that encode the index of the projected column using several phases and that mix the resulting phases into a controllable number of projected patterns from which the position can be recovered with subpixel precision. One notable characteristic of the proposed approaches is that we can allocate the additional number of patterns specifically to improve precision or provide higher robustness to noise. The proposed approaches are analyzed and compared with the state of the art, showing their ability to be tuned towards high precision in low noise conditions or robustness with respect to noise. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Torsello, Andrea; Albarelli, Andrea; Rodola, Emanuele] Univ Ca Foscari Venezia, Dipartimento Sci Ambientali Informat & Stat, I-30172 Venice, Italy.
C3 Universita Ca Foscari Venezia
RP Albarelli, A (corresponding author), Univ Ca Foscari Venezia, Dipartimento Sci Ambientali Informat & Stat, Via Torino 155, I-30172 Venice, Italy.
EM albarelli@unive.it
RI ; Torsello, Andrea/K-6352-2016; Rodola, Emanuele/M-4137-2016
OI Albarelli, Andrea/0000-0002-3659-5099; Torsello,
   Andrea/0000-0001-9189-4924; Rodola, Emanuele/0000-0003-0091-7241
CR Albarelli Andrea, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1670, DOI 10.1109/ICCVW.2009.5457484
   Baker M. J., 2004, 2004 Conference on Optoelectronic and Microelectronic Materials and Devices. Proceedings. (IEEE Cat. No. 04EX973), P261
   Batlle J, 1998, PATTERN RECOGN, V31, P963, DOI 10.1016/S0031-3203(97)00074-5
   BERGMANN D, 1995, PROC SPIE, V2572, P2, DOI 10.1117/12.216931
   BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869
   Guo HW, 2004, APPL OPTICS, V43, P2906, DOI 10.1364/AO.43.002906
   HIBINO K, 1995, J OPT SOC AM A, V12, P761, DOI 10.1364/JOSAA.12.000761
   Huang PS, 2002, APPL OPTICS, V41, P4503, DOI 10.1364/AO.41.004503
   Li ZW, 2008, OPT ENG, V47, DOI 10.1117/1.2931517
   Lilienblum E, 2007, J COMPUT, V2, P73, DOI 10.4304/jcp.2.2.73-83
   Pan B, 2009, OPT LETT, V34, P416, DOI 10.1364/OL.34.000416
   Pribanic T, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/474389
   Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Surrel Y, 1996, APPL OPTICS, V35, P51, DOI 10.1364/AO.35.000051
   TAKEDA M, 1983, APPL OPTICS, V22, P3977, DOI 10.1364/AO.22.003977
   Wang ZY, 2010, OPT LASER ENG, V48, P218, DOI 10.1016/j.optlaseng.2009.06.005
   Wiora G, 2000, P SOC PHOTO-OPT INS, V4117, P289, DOI 10.1117/12.404832
   WIZINOWICH PL, 1990, APPL OPTICS, V29, P3271, DOI 10.1364/AO.29.003271
   Yi J, 1997, OPT LASER ENG, V27, P493, DOI 10.1016/S0143-8166(96)00042-5
   Zhang S, 2007, APPL OPTICS, V46, P36, DOI 10.1364/AO.46.000036
NR 21
TC 2
Z9 2
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2013
VL 31
IS 4
BP 341
EP 356
DI 10.1016/j.imavis.2013.02.004
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 136QV
UT WOS:000318379400004
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Ali, I
   Dailey, MN
AF Ali, Irshad
   Dailey, Matthew N.
TI Multiple human tracking in high-density crowds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Head detection; Pedestrian tracking; Crowd tracking; Particle filters;
   3D object tracking; 3D head plane estimation; Human detection;
   Least-squares plane estimation; AdaBoost detection cascade
ID PEOPLE TRACKING; ASSOCIATION; PERFORMANCE
AB In this paper, we introduce a fully automatic algorithm to detect and track multiple humans in high-density crowds in the presence of extreme occlusion. Typical approaches such as background modeling and body part-based pedestrian detection fail when most of the scene is in motion and most body parts of most of the pedestrians are occluded. To overcome this problem, we integrate human detection and tracking into a single framework and introduce a confirmation-by-classification method for tracking that associates detections with tracks, tracks humans through occlusions, and eliminates false positive tracks. We use a Viola and Jones AdaBoost detection cascade, a particle filter for tracking, and color histograms for appearance modeling. To further reduce false detections due to dense features and shadows, we introduce a method for estimation and utilization of a 3D head plane that reduces false positives while preserving high detection rates. The algorithm learns the head plane from observations of human heads incrementally, without any a priori extrinsic camera calibration information, and only begins to utilize the head plane once confidence in the parameter estimates is sufficiently high. In an experimental evaluation, we show that confirmation-by-classification and head plane estimation together enable the construction of an excellent pedestrian tracker for dense crowds. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Ali, Irshad; Dailey, Matthew N.] Asian Inst Technol, Comp Sci & Informat Management Program, Pathum Thani, Thailand.
C3 Asian Institute of Technology
RP Ali, I (corresponding author), Asian Inst Technol, Comp Sci & Informat Management Dept, POB 4, Klongluang 12120, Pathumthani, Thailand.
EM Irshad.Ali@ait.asia; mdailey@ait.asia
OI Ali, Irshad/0000-0001-5398-8911
FU Higher Education Commission of Pakistan (HEC); Asian Institute of
   Technology (AIT)
FX This research was supported by graduate fellowships from the Higher
   Education Commission of Pakistan (HEC) and the Asian Institute of
   Technology (AIT) to Irshad Ali. We are grateful to Shashi Chard for help
   with ground truth labeling software. We thank Faisal Bukhari and Waheed
   Iqbal for valuable discussions related to this work.
CR Ali I, 2010, I C CONT AUTOMAT ROB, P2054, DOI 10.1109/ICARCV.2010.5707425
   Ali I, 2009, LECT NOTES COMPUT SC, V5807, P540
   Andriluka M., 2008, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ANNOTATION GUIDELINE
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR SIGN PROC C EUSI
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2004, levmar: Levenberg-Marquardt nonlinear least squares algorithms in C/C ++
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS ECCV
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Dalal N., 2005, IEEE C COMP VIS PATT
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Eshel R., 2008, CVPR, P1
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176
   Hoiem D., 2006, IEEE Conf. Comput. Vis. Pattern Recognit, V2, P2137
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kang HG, 2005, PATTERN RECOGN, V38, P1045, DOI 10.1016/j.patcog.2004.12.008
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Leibe B., 2007, IEEE INT C COMPUTER
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Lv FJ, 2006, IEEE T PATTERN ANAL, V28, P1513, DOI 10.1109/TPAMI.2006.178
   Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764
   Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Rodriguez M., 2011, IEEE INT C COMP VIS
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
NR 48
TC 53
Z9 58
U1 0
U2 51
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 966
EP 977
DI 10.1016/j.imavis.2012.08.013
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800005
DA 2024-07-18
ER

PT J
AU Sandbach, G
   Zafeiriou, S
   Pantic, M
   Yin, LJ
AF Sandbach, Georgia
   Zafeiriou, Stefanos
   Pantic, Maja
   Yin, Lijun
TI Static and dynamic 3D facial expression recognition: A comprehensive
   survey
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial behaviour analysis; Facial expression recognition; 3D facial
   surface; 3D facial surface sequences (4D faces)
ID 3-DIMENSIONAL FACE RECOGNITION; HIGH-RESOLUTION; MODEL; RECONSTRUCTION;
   SHAPE; ACQUISITION; IMAGES; RANGE; FORM
AB Automatic facial expression recognition constitutes an active research field due to the latest advances in computing technology that make the user's experience a clear priority. The majority of work conducted in this area involves 2D imagery, despite the problems this presents due to inherent pose and illumination variations. In order to deal with these problems, 3D and 4D (dynamic 3D) recordings are increasingly used in expression analysis research. In this paper we survey the recent advances in 3D and 4D facial expression recognition. We discuss developments in 3D facial data acquisition and tracking, and present currently available 3D/4D face databases suitable for 3D/4D facial expressions analysis as well as the existing facial expression recognition systems that exploit either 3D or 4D data in detail. Finally, challenges that have to be addressed if 3D facial expression recognition systems are to become a part of future applications are extensively discussed. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Sandbach, Georgia; Zafeiriou, Stefanos; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
   [Pantic, Maja] Univ Twente, EEMCS, Twente, Netherlands.
   [Yin, Lijun] SUNY Binghamton, Dept Comp Sci, Binghamton, NY USA.
C3 Imperial College London; University of Twente; State University of New
   York (SUNY) System; State University of New York (SUNY) Binghamton
RP Sandbach, G (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
EM gls09@imperial.ac.uk; s.zafeiriou@imperial.ac.uk;
   m.pantic@imperial.ac.uk; lijun@cs.binghamton.edu
FU EPSRC [EP/H016988/1] Funding Source: UKRI
CR Agrawal A, 2005, IEEE I CONF COMP VIS, P174, DOI 10.1109/ICCV.2005.31
   Agrawal A, 2006, LECT NOTES COMPUT SC, V3951, P578
   Ambadar Z, 2005, PSYCHOL SCI, V16, P403, DOI 10.1111/j.0956-7976.2005.01548.x
   AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   Amberg Brian, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   [Anonymous], IEEE BTAS 1 1 IEEE I
   [Anonymous], 2008, 8 IEEE INT C AUTOMAT, DOI DOI 10.1109/AFGR.2008.4813340
   [Anonymous], P 2009 5 INT C SOFT
   [Anonymous], IMAGE VISION COMPUT
   [Anonymous], NEUROCOMPUT IN PRESS
   [Anonymous], P 9 IEEE INT C COMP
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], 10 INT WORKSH IM AN
   [Anonymous], 2008 23 INT S COMP I
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P ACM INT C MULT INT
   [Anonymous], 1999, INT WORKSH SYNTH NAT
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], 2007 IEEE C COMP VIS
   [Anonymous], P 2001 IEEE COMP SOC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2011, IEEE T AFFECTIVE COM
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   [Anonymous], SYS MAN CYBERN B
   [Anonymous], 2011, P ACM WORKSH HUM GES
   [Anonymous], IM PROC 2006 IEEE IN
   [Anonymous], RANGE SENSING COMPUT
   [Anonymous], 9 INT C AUT FAC GEST
   [Anonymous], FACIAL EXPRESSION AN
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Benedikt L, 2010, IEEE T SYST MAN CY A, V40, P449, DOI 10.1109/TSMCA.2010.2041656
   Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Beumier C., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P704, DOI 10.1109/ICIAP.1999.797677
   Beumier C, 2001, PATTERN RECOGN LETT, V22, P1321, DOI 10.1016/S0167-8655(01)00077-0
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Breuer P, 2008, IEEE INT CONF AUTOMA, P1, DOI 10.1109/AFGR.2008.4813339
   Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293
   Chetverikov D, 2002, INT C PATT RECOG, P545, DOI 10.1109/ICPR.2002.1047997
   Faltemier TC, 2008, COMPUT VIS IMAGE UND, V112, P114, DOI 10.1016/j.cviu.2008.01.004
   FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909
   Geng ZJ, 1996, OPT ENG, V35, P376, DOI 10.1117/1.601023
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gong B., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P569
   Gunes Hatice, 2010, International Journal of Strategic Synthetic Emotions, V1, P68, DOI 10.4018/jse.2010101605
   Gupta SD, 2010, METHODS MOL BIOL, V589, P97, DOI [10.1007/978-1-60327-114-1_10, 10.1109/SSIAI.2010.5483908]
   Hall-Holt O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P359, DOI 10.1109/ICCV.2001.937648
   Hansen MF, 2010, COMPUT VIS IMAGE UND, V114, P942, DOI 10.1016/j.cviu.2010.03.001
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Heseltine T, 2008, IMAGE VISION COMPUT, V26, P382, DOI 10.1016/j.imavis.2006.12.008
   Huang PS, 1999, OPT ENG, V38, P1065, DOI 10.1117/1.602151
   Huang PSS, 2003, OPT ENG, V42, P163, DOI 10.1117/1.1525272
   Kaiser M, 2010, IEEE INT CONF ROBOT, P1002, DOI 10.1109/ROBOT.2010.5509629
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Li XL, 2010, INT CONF SIGN PROCES, P1366, DOI 10.1109/ICOSP.2010.5656891
   Maalej Ahmed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4129, DOI 10.1109/ICPR.2010.1003
   Maalej A, 2011, PATTERN RECOGN, V44, P1581, DOI 10.1016/j.patcog.2011.02.012
   Moreno A.B., 2004, WHITENING RACE ESSAY, P75
   Mpiperis I., 2008, FG'08, P1
   Mpiperis I, 2008, IEEE T INF FOREN SEC, V3, P498, DOI 10.1109/TIFS.2008.924598
   Mpiperis I, 2008, INT CONF ACOUST SPEE, P2133, DOI 10.1109/ICASSP.2008.4518064
   Muñoz E, 2009, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2009.5459366
   Ocegueda O., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1270, DOI 10.1109/ICCVW.2011.6130397
   Pantic Maja, 2008, International Journal of Automomous and Adaptive Communications Systems, V1, P168, DOI 10.1504/IJAACS.2008.019799
   Patel A, 2009, PROC CVPR IEEE, P1327, DOI 10.1109/CVPRW.2009.5206522
   Pinto SCD, 2011, IEEE IMAGE PROC, P1281, DOI 10.1109/ICIP.2011.6115668
   Raskar R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P179, DOI 10.1145/280814.280861
   Rosato M., 2008, BIOMETRICS THEORY AP, P1
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sandbach G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P406, DOI 10.1109/FG.2011.5771434
   Savran Arman, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1993, DOI 10.1109/ICCVW.2009.5457526
   Savran A., 2008, COMPUTER VISION PATT, P1
   Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Sibbing Dominik, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1778, DOI 10.1109/ICCVW.2009.5457498
   SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Soyel H, 2010, TURK J ELECTR ENG CO, V18, P1031, DOI 10.3906/elk-0908-158
   Srivastava R., 2009, TENCON 2009 2009 IEE, P1
   Stewart CV, 2003, IEEE T MED IMAGING, V22, P1379, DOI 10.1109/TMI.2003.819276
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Sun Y, 2010, IEEE T SYST MAN CY A, V40, P461, DOI 10.1109/TSMCA.2010.2041659
   Tang H., 2008, AUTOMATIC FACE GESTU, P1
   Tekgüç U, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P35, DOI 10.1109/ISCIS.2009.5291925
   Tsalakanidou F, 2005, REAL-TIME IMAGING, V11, P358, DOI 10.1016/j.rti.2005.06.006
   Tsalakanidou Filareti, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P4, DOI 10.1109/CVPR.2009.5204281
   Tsalakanidou F, 2010, 3DTV CONF
   Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009
   Venkatesh Y. V., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3772, DOI 10.1109/ICPR.2010.919
   Vieira M.B., 2005, CAMERA PROJECTOR SYS, P96
   Vinciarelli A, 2012, IEEE T AFFECT COMPUT, V3, P69, DOI 10.1109/T-AFFC.2011.27
   Vretos N, 2011, IEEE IMAGE PROC, P773, DOI 10.1109/ICIP.2011.6116669
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wang S., 2008, Computer Vision and Pattern Recognition
   Wang S, 2007, IEEE T PATTERN ANAL, V29, P1209, DOI 10.1109/TPAMI.2007.1050
   Wang SF, 2011, IEEE T PATTERN ANAL, V33, P2115, DOI 10.1109/TPAMI.2011.88
   Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x
   Wang Y, 2008, INT J COMPUT VISION, V76, P283, DOI 10.1007/s11263-007-0063-y
   Weise T., 2007, IEEE CVPR, P1, DOI DOI 10.1109/CVPR.2007.383291
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Wust C., 1991, Machine Vision and Applications, V4, P193, DOI 10.1007/BF01230201
   Xi Zhao, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3724, DOI 10.1109/ICPR.2010.907
   Yin LJ, 2006, INT C PATT RECOG, P1248
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yin LJ, 2008, IEEE INT CONF AUTOMA, P116
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zernike F, 1934, PHYSICA, V1, P689
   Zhang S, 2006, OPT EXPRESS, V14, P2644, DOI 10.1364/OE.14.002644
   Zhang S., 2004, IEEE computer Vision Pattern Recognition Workshop (CVPRW'04), V3, P28, DOI DOI 10.1109/CVPR.2004.86
   Zhao X., 2010, HICSS, P1
NR 116
TC 237
Z9 263
U1 1
U2 90
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2012
VL 30
IS 10
BP 683
EP 697
DI 10.1016/j.imavis.2012.06.005
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 027YD
UT WOS:000310389100002
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Liu, L
   Zhao, LJ
   Long, YL
   Kuang, GY
   Fieguth, P
AF Liu, Li
   Zhao, Lingjun
   Long, Yunli
   Kuang, Gangyao
   Fieguth, Paul
TI Extended local binary patterns for texture classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Texture classification; Local binary pattern (LBP); Bag-of-words (BoW);
   Rotation invariance
ID RECOGNITION; FEATURES
AB This paper presents a novel approach for texture classification, generalizing the well-known local binary pattern (LBP) approach. In the proposed approach, two different and complementary types of features (pixel intensities and differences) are extracted from local patches. The intensity-based features consider the intensity of the central pixel (CI) and those of its neighbors (NI); while for the difference-based feature, two components are computed: the radial-difference (RD) and the angular-difference (AD). Inspired by the LBP approach, two intensity-based descriptors CI-LBP and NI-LBP, and two difference-based descriptors RD-LBP and AD-LBP are developed. All four descriptors are in the same form as conventional LBP codes, so they can be readily combined to form joint histograms to represent textured images. The proposed approach is computationally very simple: it is totally training-free, there is no need to learn a texton dictionary, and no tuning of parameters. We have conducted extensive experiments on three challenging texture databases (Outex. CUReT and KTHTIPS2b). Outex results show significant improvements over the classical LBP approach, which clearly demonstrates the great power of the joint distributions of these proposed descriptors for gray-scale and rotation invariant texture classification. The proposed method produces the best classification results on KTHTIPS2b, and results comparable to the state-of-the-art on CUReT. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Liu, Li; Zhao, Lingjun; Long, Yunli; Kuang, Gangyao] Natl Univ Def Technol, Sch Elect Sci & Engn, Changsha 410073, Hunan, Peoples R China.
   [Fieguth, Paul] Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada.
C3 National University of Defense Technology - China; University of
   Waterloo
RP Liu, L (corresponding author), Natl Univ Def Technol, Sch Elect Sci & Engn, 47 Yanwachi, Changsha 410073, Hunan, Peoples R China.
EM dreamliu2010@gmail.com; lingjun.zhao@gmail.com; feiyunlyi@hotmail.com;
   kuangyeats@vip.sina.com; pfieguth@uwaterloo.ca
RI Liu, Li/JQW-6992-2023; Zhao, Lingjun/HPE-8072-2023
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], FINN SIGN PROC S OUL
   Brodatz P., 1966, Texture: A Photographic Album for Artists and Designers
   Caputo B, 2005, IEEE I CONF COMP VIS, P1597, DOI 10.1109/iccv.2005.54
   Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   HEIKKILA M., 2004, British Machine Vision Conference, P187, DOI DOI 10.5244/C.18.21
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.123
   Mallikarjuna P., The KTH-TIPS and KTH-TIPS2 databases
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2001, PATTERN RECOGN, V34, P727, DOI 10.1016/S0031-3203(00)00010-8
   Pietikäinen M, 2004, PATTERN RECOGN, V37, P313, DOI 10.1016/S0031-3203(03)00231-0
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Rodriguez Y, 2006, LECT NOTES COMPUT SC, V3954, P321
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Xie J, 2010, IEEE IMAGE PROC, P2737, DOI 10.1109/ICIP.2010.5651387
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 36
TC 248
Z9 268
U1 1
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2012
VL 30
IS 2
BP 86
EP 99
DI 10.1016/j.imavis.2012.01.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 934ZJ
UT WOS:000303486200003
DA 2024-07-18
ER

PT J
AU Cosar, S
   Çetin, M
AF Cosar, Serhan
   Cetin, Mujdat
TI A graphical model based solution to the facial feature point tracking
   problem
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial feature tracking; Graphical models; Temporal and spatial models;
   Occlusion detector; Human-computer interaction; Facial expression
   analysis
ID SHAPE MODEL
AB In this paper a facial feature point tracker that is motivated by applications such as human-computer interfaces and facial expression analysis systems is proposed. The proposed tracker is based on a graphical model framework. The facial features are tracked through video streams by incorporating statistical relations in time as well as spatial relations between feature points. By exploiting the spatial relationships between feature points, the proposed method provides robustness in real-world conditions such as arbitrary head movements and occlusions. A Gabor feature-based occlusion detector is developed and used to handle occlusions. The performance of the proposed tracker has been evaluated on real video data under various conditions including occluded facial gestures and head movements. It is also compared to two popular methods, one based on Kalman filtering exploiting temporal relations, and the other based on active appearance models (AAM). Improvements provided by the proposed approach are demonstrated through both visual displays and quantitative analysis. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Cosar, Serhan; Cetin, Mujdat] Sabanci Univ, Fac Engn & Nat Sci, TR-34956 Istanbul, Turkey.
C3 Sabanci University
RP Çetin, M (corresponding author), Sabanci Univ, Fac Engn & Nat Sci, TR-34956 Istanbul, Turkey.
EM serhancosar@su.sabanciuniv.edu; mcetin@sabanciuniv.edu
OI Cosar, Serhan/0000-0003-4358-1063; Cetin, Mujdat/0000-0002-9824-1229
FU Turkish Academy of Sciences; Turkish State Planning Organization;
   Scientific and Technological Research Council of Turkey
FX This work was partially supported by a Turkish Academy of Sciences
   Distinguished Young Scientist Award, the Turkish State Planning
   Organization under the DRIVE-SAFE project, and by a graduate scholarship
   from the Scientific and Technological Research Council of Turkey.
CR ABUT H, 2007, P BIENN DSP IN VEH M
   Ahlberg J, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P68, DOI 10.1109/RATFG.2001.938912
   [Anonymous], 2004, COMP VIS PATT REC WO
   AZARBAYEJANI A, 1993, COMP VIS PATT REC 19, P294
   Baumberg A. M., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P194, DOI 10.1109/MNRAO.1994.346236
   BOLME DS, 2003, THESIS COLORADO STAT
   BOUREL F, 2000, P 11 BRIT MACH VIS C, V1, P232
   CASCIA ML, 1998, IEEE T PATTERN ANAL, V22, P322
   Chen T, 1998, P IEEE, V86, P837, DOI 10.1109/5.664274
   Cootes T., 1998, Proc. ECCV, V2, P484
   CORDEA M, 2001, INSTR MEAS TECHN C 2, V1, P72
   COSAR S, 2008, THESIS SABANCI U
   Feris R. S., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), P22, DOI 10.1109/SIBGRA.2000.883889
   FERIS RS, 2001, ICAPR 01 P 2 INT C A, P311
   Goto T, 2001, IEEE SIGNAL PROC MAG, V18, P17, DOI 10.1109/79.924885
   Gross R, 2006, IMAGE VISION COMPUT, V24, P593, DOI 10.1016/j.imavis.2005.08.001
   Hu CB, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P215
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   KIMA JW, 2000, 2000 IEEE INT S CIRC, P40
   Pearl J., 1988, PROBABILISTIC REASON
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Pupilli M, 2006, INT C PATT RECOG, P199
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Stegmann MB, 2003, IEEE T MED IMAGING, V22, P1319, DOI 10.1109/TMI.2003.817780
   Storer M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P130
   Su CY, 2005, EURASIP J APPL SIG P, V2005, P2091, DOI 10.1155/ASP.2005.2091
   Subbarao R, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P70
   SUDDERTH E, 2002, THESIS MIT
   Tomasi C, 1991, DETECTION TRACKING P
   Tong Y, 2006, INT C PATT RECOG, P283
   Trucco E., 1998, INTRO TECHNIQUES 3D
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   Wan KW, 2005, PATTERN RECOGN LETT, V26, P2409, DOI 10.1016/j.patrec.2005.04.015
   Wang RS, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P233, DOI 10.1109/MMSP.1997.602641
   Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880
   WIEGHARDT J, 2002, P ECCV 2002 COP
   Wiles CS, 2001, IEEE T PATTERN ANAL, V23, P1391, DOI 10.1109/34.977563
   Wong KW, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P518, DOI 10.1109/ISIMP.2001.925447
   Xiao J, 2004, PROC CVPR IEEE, P535
   2005, MACHINE VISION APPL, V16, P105
   2002, REAL TIME IMAGING, V8, P357
NR 41
TC 12
Z9 13
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2011
VL 29
IS 5
BP 335
EP 350
DI 10.1016/j.imavis.2010.12.001
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 751FT
UT WOS:000289603600005
DA 2024-07-18
ER

PT J
AU Bilodeau, GA
   Torabi, A
   Morin, F
AF Bilodeau, G. A.
   Torabi, A.
   Morin, F.
TI Visible and infrared image registration using trajectories and composite
   foreground images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Infrared; Registration; Multi sensors; Trajectories; Foreground images
ID FUSION; COLOR; VIDEO; MODEL
AB The registration of images from multiple types of sensors (particularly infrared sensors and visible color sensors) is a step toward achieving multi sensor fusion This paper proposes a registration method using a novel error function Registration of Infrared and visible color images is performed by using the trajectories of moving objects obtained using background subtraction and simple tracking The trajectory points are matched using a RANSAC based algorithm and a novel registration criterion which is based on the overlap of foreground pixels in composite foreground images This criterion allows performing registration when there are few trajectories and gives more stable results Our method was tested and its performance quantified using nine scenarios It outperforms a related method only based on trajectory points in cases where there are few moving objects (C) 2010 Elsevier B V All rights reserved
C1 [Bilodeau, G. A.; Torabi, A.; Morin, F.] Ecole Polytech, LITIV, Dept Comp & Software Engn, Montreal, PQ H3C 3A7, Canada.
C3 Universite de Montreal; Polytechnique Montreal
RP Bilodeau, GA (corresponding author), Ecole Polytech, LITIV, Dept Comp & Software Engn, POB 6079,Stn Ctr Ville, Montreal, PQ H3C 3A7, Canada.
OI Bilodeau, Guillaume-Alexandre/0000-0003-3227-5060
FU Canadian Foundation for Innovation (CFI); Fonds quebecois de la
   recherche sur la nature et les technologies (FQRNT)
FX We would like to thank the Canadian Foundation for Innovation (CFI) and
   the Fonds quebecois de la recherche sur la nature et les technologies
   (FQRNT) for their support with grants
CR Anuta P. E., 1970, IEEE T GEOSCI ELECTR, V8, P353, DOI 10.1109/TGE.1970.271435
   Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222
   Caspi Y, 2002, INT J COMPUT VISION, V48, P39, DOI 10.1023/A:1014803327923
   Caspi Y, 2006, INT J COMPUT VISION, V68, P53, DOI 10.1007/s11263-005-4842-z
   Charoentam O, 2006, INT C PATT RECOG, P669
   CHEN H, 2003, AVSS 03 P IEEE C ADV, P313
   Coiras E, 2000, OPT ENG, V39, P282, DOI 10.1117/1.602363
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Elbakary MI, 2007, IMAGE VISION COMPUT, V25, P663, DOI 10.1016/j.imavis.2006.05.009
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fuentes LM, 2006, IMAGE VISION COMPUT, V24, P1165, DOI 10.1016/j.imavis.2005.06.006
   Han J, 2007, PATTERN RECOGN, V40, P1771, DOI 10.1016/j.patcog.2006.11.010
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hrkac T, 2007, LECT NOTES COMPUT SC, V4522, P383
   Huang XS, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P773, DOI 10.1109/ICOSP.2002.1181170
   JOO JW, 2003, P 6 INT C INF FUS 20, V1, P277
   Kong SG, 2007, INT J COMPUT VISION, V71, P215, DOI 10.1007/s11263-006-6655-0
   Krotosky SJ, 2007, COMPUT VIS IMAGE UND, V106, P270, DOI 10.1016/j.cviu.2006.10.008
   KYOUNG SK, 2005, 2005 8 INT C INF FUS, V1, P380
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   LIEU SCK, 2003, AUTOMATED MULTICAMER, V1, P259
   LIU Z, 2007, REGISTRATION IR EO V, P459
   OSTLE B., 1996, Engineering Sta- tistics : The Industrial Experience
   Roche A, 1998, LECT NOTES COMPUT SC, V1496, P1115, DOI 10.1007/BFb0056301
   Shoushtarian B, 2005, PATTERN RECOGN LETT, V26, P5, DOI 10.1016/j.patrec.2004.07.013
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 27
TC 29
Z9 44
U1 1
U2 47
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2011
VL 29
IS 1
BP 41
EP 50
DI 10.1016/j.imavis.2010.08.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 679BP
UT WOS:000284134700004
DA 2024-07-18
ER

PT J
AU Pundlik, S
   Woodard, D
   Birchfield, S
AF Pundlik, Shrinivas
   Woodard, Damon
   Birchfield, Stan
TI Iris segmentation in non-ideal images using graph cuts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris segmentation; Graph cuts; Starburst
ID ENERGY MINIMIZATION; RECOGNITION; EYELASH
AB A non-ideal iris image segmentation approach based on graph cuts is presented that uses both the appearance and eye geometry information. A texture measure based on gradients is computed to discriminate between eyelash and non-eyelash regions, combined with image intensity differences between the iris, pupil, and the background (region surrounding the iris) are utilized as cues for segmentation. The texture and intensity distributions for the various regions are learned from histogramming and explicit sampling of the pixels estimated to belong to the corresponding regions. The image is modeled as a Markov Random Field and the energy minimization is achieved via graph cuts to assign each image pixel one of the four possible labels: iris, pupil, background, and eyelash. Furthermore, the iris region is modeled as an ellipse, and the best fitting ellipse to the initial pixel based iris segmentation is computed to further refine the segmented region. As a result, the iris region mask and the parameterized iris shape form the outputs of the proposed approach that allow subsequent iris recognition steps to be performed for the segmented irises. The algorithm is unsupervised and can deal with non-ideality in the iris images due to out-of-plane rotation of the eye, iris occlusion by the eyelids and the eyelashes, multi-modal iris grayscale intensity distribution, and various illumination effects. The proposed segmentation approach is tested on several publicly available non-ideal near infra red (NIR) iris image databases. We compare both the segmentation error and the resulting recognition error with several leading techniques, demonstrating significantly improved results with the proposed technique. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Pundlik, Shrinivas; Woodard, Damon; Birchfield, Stan] Clemson Univ, Clemson, SC 29634 USA.
C3 Clemson University
RP Pundlik, S (corresponding author), Clemson Univ, Clemson, SC 29634 USA.
EM spundli@clemson.edu; woodard@clemson.edu; stb@clemson.edu
OI Pundlik, Shrinivas/0000-0001-8766-7112; Woodard,
   Damon/0000-0002-0471-177X
CR [Anonymous], 2003, Matlab source code for a biometric identification system based on iris patterns
   BACHOO AK, 2005, ANN RES C S AFR I CO, P236
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Camus TA, 2002, INT C PATT RECOG, P389, DOI 10.1109/ICPR.2002.1044732
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Crihalmeanu S.S. S., 2007, PROTOCOL MULTIBIOMET
   Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Feng XH, 2006, INT C PATT RECOG, P553
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   He ZF, 2006, INT C PATT RECOG, P366
   HUANG J, 2004, P IAPR INT C PATT RE, P368
   Kang BJ, 2007, PATTERN RECOGN LETT, V28, P1630, DOI 10.1016/j.patrec.2007.04.004
   Kong WK, 2003, INT J PATTERN RECOGN, V17, P1025, DOI 10.1142/S0218001403002733
   LI D, 2005, WORKSH VIS HUM COMP
   Liu XM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P118
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   PUNDLIK S, 2008, P IEEE COMP SOC WORK
   ROSS A, 2006, P BIOM S
   Schuckers SAC, 2007, IEEE T SYST MAN CY B, V37, P1176, DOI 10.1109/TSMCB.2007.904831
   Shah S, 2009, IEEE T INF FOREN SEC, V4, P824, DOI 10.1109/TIFS.2009.2033225
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Vatsa M, 2008, IEEE T SYST MAN CY B, V38, P1021, DOI 10.1109/TSMCB.2008.922059
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   XU G, 2006, P 5 INT C COGN INF
NR 30
TC 21
Z9 23
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1671
EP 1681
DI 10.1016/j.imavis.2010.05.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300009
DA 2024-07-18
ER

PT J
AU Xiao, B
   Hancock, ER
   Wilson, RC
AF Xiao, Bai
   Hancock, Edwin R.
   Wilson, Richard C.
TI Geometric characterization and clustering of graphs using heat kernel
   embeddings
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Graph spectra; Kernel methods; Graph embedding; Differential geometry;
   Graph clustering
ID ALGORITHM
AB In this paper, we investigate the use of heat kernels as a means of embedding the individual nodes of a graph in a vector space. The reason for turning to the heat kernel is that it encapsulates information concerning the distribution of path lengths and hence node affinities on the graph. The heat kernel of the graph is found by exponentiating the Laplacian eigensystem over time. In this paper, we explore how graphs can be characterized in a geometric manner using embeddings into a vector space obtained from the heat kernel. We explore two different embedding strategies. The first of these is a direct method in which the matrix of embedding co-ordinates is obtained by performing a Young-Householder decomposition on the heat kernel. The second method is indirect and involves performing a low-distortion embedding by applying multidimensional scaling to the geodesic distances between nodes. We show how the required geodesic distances can be computed using parametrix expansion of the heat kernel. Once the nodes of the graph are embedded using one of the two alternative methods, we can characterize them in a geometric manner using the distribution of the node co-ordinates. We investigate several alternative methods of characterization, including spatial moments for the embedded points, the Laplacian spectrum for the Euclidean distance matrix and scalar curvatures computed from the difference in geodesic and Euclidean distances. We experiment with the resulting algorithms on the COIL database. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Xiao, Bai] Beihang Univ, Intelligence Recognit & Image Proc Lab, Sch Engn & Comp Sci, Beijing 100191, Peoples R China.
   [Hancock, Edwin R.; Wilson, Richard C.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
C3 Beihang University; University of York - UK
RP Xiao, B (corresponding author), Beihang Univ, Intelligence Recognit & Image Proc Lab, Sch Engn & Comp Sci, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM baixiao.buaa@googlemail.com; erh@cs.york.ac.uk; wilson@cs.york.ac.uk
RI Hancock, Edwin/N-7548-2019
OI Hancock, Edwin/0000-0003-4496-2028
CR [Anonymous], 1994, Multidimensional Scaling
   Atkins JE, 1998, SIAM J COMPUT, V28, P297, DOI 10.1137/S0097539795285771
   Barlow M., 1998, Lecture Notes in Math, P1
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chung F. R. K., 1997, Spectral graph theory
   DEVERDIERE C, 1998, MATH FRANCE, V4
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   GILKEY PB, 1984, INVARIANT THEORY HEA
   Grigor'yan A, 2001, PROG MATH, V201, P393
   GRIGORYAN A, 2003, HEAT KERNELS MANIFOL
   HARRIS CG, 1994, 4 ALV VIS C
   LAFFERTY J, 2004, CMUCS04101
   LINDMAN H, 1978, J MATH PSYCHOL, V17, P89, DOI 10.1016/0022-2496(78)90025-1
   LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757
   Luo B, 2003, PATTERN RECOGN, V36, P2213, DOI 10.1016/S0031-3203(03)00084-0
   Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602
   NENE SA, 1996, HIROSHI MURASE COLUM
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   SACHS H, 1980, SPECTRA GRAPHS
   SHI J, 1997, INT C COMP VIS PATT
   SHOKOUFANDEH A, 1999, INT C COMP VIS PATT
   SMOLA AJ, 2004, KERNELS REGULARISATI
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778
   WILSON RC, 2003, IEEE T PATTERN ANAL, V27, P2220
   Xiao B, 2006, LECT NOTES COMPUT SC, V4109, P306
   YAU ST, 1988, DIFFERENTIAL GEOMETR
NR 28
TC 43
Z9 49
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 1003
EP 1021
DI 10.1016/j.imavis.2009.05.011
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200014
DA 2024-07-18
ER

PT J
AU Nikolaou, N
   Makridis, M
   Gatos, B
   Stamatopoulos, N
   Papamarkos, N
AF Nikolaou, Nikos
   Makridis, Michael
   Gatos, Basilis
   Stamatopoulos, Nikolaos
   Papamarkos, Nikos
TI Segmentation of historical machine-printed documents using Adaptive Run
   Length Smoothing and skeleton segmentation paths
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Text line segmentation; Word segmentation; Character segmentation;
   Historical machine-printed documents; Run Length Smoothing Algorithm
ID HANDWRITTEN; RECOGNITION; EXTRACTION; CHARACTERS
AB In this paper, we strive towards the development of efficient techniques in order to segment document pages resulting from the digitization of historical machine-printed sources. This kind of documents often suffer from low quality and local skew, several degradations due to the old printing matrix quality or ink diffusion, and exhibit complex and dense layout. To face these problems, we introduce the following innovative aspects: (i) use of a novel Adaptive Run Length Smoothing Algorithm (ARLSA) in order to face the problem of complex and dense document layout, (ii) detection of noisy areas and punctuation marks that are usual in historical machine-printed documents, (iii) detection of possible obstacles formed from background areas in order to separate neighboring text columns or text lines, and (iv) use of skeleton segmentation paths in order to isolate possible connected characters. Comparative experiments using several historical machine-printed documents prove the efficiency of the proposed technique. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Nikolaou, Nikos; Makridis, Michael; Papamarkos, Nikos] Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
   [Nikolaou, Nikos; Gatos, Basilis; Stamatopoulos, Nikolaos] Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Computat Intelligence Lab, Athens 15310, Greece.
C3 Democritus University of Thrace; National Centre of Scientific Research
   "Demokritos"
RP Nikolaou, N (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
EM nnikol@ee.duth.gr; mmakridi@ee.duth.gr; bgat@iit.demokritos.gr;
   nstam@iit.demokritos.gr; papamark@ee.duth.gr
RI Makridis, Michail/Q-6506-2017
OI Makridis, Michail/0000-0001-7462-4674
FU European Community's Seventh Framework Programme [215064]; Greek
   Ministry of Research
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme under grant agreement
   No. 215064 (project IMPACT) as well as from the Greek Ministry of
   Research funded R&D project POLYTIMO.
CR Antonacopoulos A, 2005, PROC INT CONF DOC, P75, DOI 10.1109/ICDAR.2005.184
   Antonacopoulos A, 2005, PROC INT CONF DOC, P48, DOI 10.1109/ICDAR.2005.215
   BAIRD HS, 1994, DOCUMENT IMAGE ANAL, P17
   BREUEL TM, 2002, P INT WORKSH DOC AN, V5, P188
   Bruzzone E., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P749, DOI 10.1109/ICDAR.1999.791896
   Chen YK, 2000, IEEE T PATTERN ANAL, V22, P1304, DOI 10.1109/34.888715
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Feldbach M, 2001, PROC INT CONF DOC, P743, DOI 10.1109/ICDAR.2001.953888
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   He J, 2003, PROC INT CONF DOC, P498
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Kavallieratou E, 2000, INT C PATT RECOG, P634, DOI 10.1109/ICPR.2000.906155
   Kennard DJ, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P12, DOI 10.1109/DIAL.2006.40
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Konidaris T, 2007, INT J DOC ANAL RECOG, V9, P167, DOI 10.1007/s10032-007-0042-4
   LEE HJ, 1992, PATTERN RECOGN, V25, P543, DOI 10.1016/0031-3203(92)90052-K
   Lemaitre A, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P38, DOI 10.1109/DIAL.2006.41
   Li Y, 2006, INT C PATT RECOG, P1030
   LIANG S, 1994, PATTERN RECOGN, V27, P825, DOI 10.1016/0031-3203(94)90167-8
   Likforman-Sulem L., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P774, DOI 10.1109/ICDAR.1995.602017
   LINKFORMANSUMEM L, 2006, INT J DOC ANAL RECOG, V9, P1433
   LU Y, 2001, 6 INT C DOC AN REC I, P10
   Makhoul J., 1999, Proceedings of DARPA Broadcast News Workshop, P249
   Manmatha R, 2005, IEEE T PATTERN ANAL, V27, P1212, DOI 10.1109/TPAMI.2005.150
   Marcolino A., 2000, Proceedings of the 5th IberoAmerican Sympsium on Pattern Recognition (SIARP00), P123
   Nagy G., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P347
   Nomura S, 2005, PATTERN RECOGN, V38, P1961, DOI 10.1016/j.patcog.2005.01.026
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   Pal U, 2003, PATTERN RECOGN LETT, V24, P261, DOI 10.1016/S0167-8655(02)00240-4
   PARK HC, 2001, INT J DOC ANAL RECOG, V4, P115
   Park J, 2002, PATTERN RECOGN, V35, P245, DOI 10.1016/S0031-3203(00)00176-X
   Phillips IT, 1999, IEEE T PATTERN ANAL, V21, P849, DOI 10.1109/34.790427
   Ramel JY, 2007, INT J DOC ANAL RECOG, V9, P243, DOI 10.1007/s10032-007-0040-6
   Shi ZX, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P306
   STAMATOPOULOS N, 2007, 2 INT WORKSH CAM BAS, P71
   WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4
   WEIHUA H, 2001, INT C IM PROC ICIP 2, P8
   Xiao XH, 2000, PATTERN RECOGN LETT, V21, P945, DOI 10.1016/S0167-8655(00)00049-0
   Yanikoglu B, 1998, PATTERN RECOGN, V31, P1825, DOI 10.1016/S0031-3203(98)00081-8
NR 39
TC 70
Z9 79
U1 2
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 590
EP 604
DI 10.1016/j.imavis.2009.09.013
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600005
DA 2024-07-18
ER

PT J
AU Schuller, B
   Müller, R
   Eyben, F
   Gast, J
   Hörnler, B
   Wöllmer, M
   Rigoll, G
   Höthker, A
   Konosu, H
AF Schuller, Bjoern
   Mueller, Ronald
   Eyben, Florian
   Gast, Juergen
   Hoernler, Benedikt
   Woellmer, Martin
   Rigoll, Gerhard
   Hoethker, Anja
   Konosu, Hitoshi
TI Being bored? Recognising natural interest by extensive audiovisual
   integration for real-life application
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Interest recognition; Affective computing; Audiovisual processing
ID RECOGNITION; EXPRESSIONS
AB Automatic detection of the level of human interest is of high relevance for many technical applications, such as automatic customer care or tutoring systems. However, the recognition of spontaneous interest in natural conversations independently of the subject remains a challenge. Identification of human affective states relying on single modalities only is often impossible, even for humans, since different modalities contain partially disjunctive cues. Multimodal approaches to human affect recognition generally are shown to boost recognition performance, yet are evaluated in restrictive laboratory settings only. Herein we introduce a fully automatic processing combination of Active-Appearance-Model-based facial expression, vision-based eye-activity estimation, acoustic features, linguistic analysis, non-linguistic vocalisations, and temporal context information in an early feature fusion process. We provide detailed subject-independent results for classification and regression of the Level of Interest using Support-Vector Machines on an audiovisual interest corpus (AVIC) consisting of spontaneous, conversational speech demonstrating "theoretical" effectiveness of the approach. Further, to evaluate the approach with regards to real-life usability a user-study is conducted for proof of "practical" effectiveness. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Schuller, Bjoern; Eyben, Florian; Gast, Juergen; Hoernler, Benedikt; Woellmer, Martin; Rigoll, Gerhard] Tech Univ Munich, Inst Human Machine Commun, D-80333 Munich, Germany.
   [Mueller, Ronald] Altran Technol, D-80636 Munich, Germany.
   [Hoethker, Anja] Toyota Motor Europe, Prod Engn Adv Technol, B-1930 Zaventem, Belgium.
   [Konosu, Hitoshi] Toyota Motor Co Ltd, Toyota, Aichi 4718571, Japan.
C3 Technical University of Munich; Toyota Motor Corporation; Toyota Motor
   Corporation
RP Schuller, B (corresponding author), Tech Univ Munich, Inst Human Machine Commun, D-80333 Munich, Germany.
EM schuller@tum.de; mueller@mmer-systems.eu;
   Anja.Hoethker@toyota-europe.com; hitoshi_konosu@mail.toyota.co.jp
RI Schuller, Björn Wolfgang/D-3241-2011
OI Schuller, Björn Wolfgang/0000-0002-6478-8699
FU European Community [FP7/2007-2013, 211486]
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme (FP7/2007-2013) under
   Grant Agreement No. 211486 (SEMAINE).
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P 4 IEEE TUT RES WOR
   [Anonymous], P WORKSH AD INT STYL
   [Anonymous], 1997, PROSODY SPEECH UNDER
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P 4 INT WORKSH HUM C
   [Anonymous], 2006, HTK BOOK V3 4
   [Anonymous], 2004, Statistical Models of Appearance for Computer Vision
   [Anonymous], 2005, P 6 INT 2005 9 EUR C
   ARSIC D, 2006, SUBMOTION HIDDED MAR
   Ashraf AB, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P9
   AXELROD L, 2005, P C HUM FACT COMP SY, P1192
   Batliner A, 2008, INT CONF ACOUST SPEE, P4497, DOI 10.1109/ICASSP.2008.4518655
   Batliner Anton., 2006, Proc. IS-LTC 2006, P240
   Batur AU, 2005, IEEE T IMAGE PROCESS, V14, P1707, DOI 10.1109/TIP.2005.854473
   Bianchi-Berthouze N, 2002, USER MODEL USER-ADAP, V12, P49, DOI 10.1023/A:1013365332180
   CAMPBELL N, 2007, COST 2102 WORKSH, P117
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   COHN J, 2007, LECT NOTES ARTIF INT, P1
   COOTES T, 1998, P BRIT MACH VIS C, V2, P680
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   DECAIRE MW, 2000, DETECTION DECEPTION
   EKMAN P, 1999, HDB COGNITION EMOTIO, pCH16
   El Kaliouby R., 2004, 2004 Conference on Computer Vision and Pattern Recognition Workshop, P154, DOI DOI 10.1109/CVPR.2004.153
   Friedman J., ADDITIVE LOGISTIC RE
   Gatica-Perez D., 2005, P IEEE INT C AC SPEE
   GOTO M, 1999, EUROSPEECH 99, P227
   Grimm M, 2007, LECT NOTES COMPUT SC, V4738, P126
   Gu HS, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P111
   Gunes H, 2005, IEEE SYS MAN CYBERN, P3437
   HAIN T, 2000, P SPEECH TRANSCR WOR
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   JOACHIMS T, 1997, 23 LS 8
   Kapoor A, 2004, INT C PATT RECOG, P969, DOI 10.1109/ICPR.2004.1334690
   KENNEDY L, 2003, P ASRU VIRG ISL
   Kipp M., 2001, Proceedings of the European Conference on Speech Communication and Technology, P1367
   KNOX M, 2007, P INTERSPEECH 2007
   LEE CM, 2002, P INT C SPEECH LANG
   Lickley R.J., 1991, Proceedings of Eurospeech 91, V3, P1499
   Liscombe J., 2005, Interspeech, P1845
   LITMAN D, 2003, P HUM LANG TECHN C N
   Maat L, 2007, LECT NOTES COMPUT SC, V4451, P251
   MOTA S, 2003, P WORKSH CVPR HCI MA
   MULLER R, 2008, THESIS TU MUNCHEN TU
   Neumann DL, 2002, AUST J PSYCHOL, V54, P174, DOI 10.1080/00049530412331312764
   Nieschulz R., 2002, IT+TI Informationstechnik und Technische Informatik, V44, P23, DOI 10.1524/itit.2002.44.1.023
   PALEARI M, 2006, P 1 ACM INT WORKSH H, P99
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   PANTIC M, 2007, FACE RECOGNITION, P327
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   POGGI I, 2001, P 2 WORKSH ATT PERS, P7
   Poletti M, 2008, J VISION, V8, DOI 10.1167/8.14.4
   Qvarfordt P, 2005, LECT NOTES COMPUT SC, V3585, P767, DOI 10.1007/11555261_61
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   SCHULLER B, 2006, P ISCA SPEECH PROS 2
   SCHULLER B, 2002, P IEEE INT C SYST MA, V4
   SCHULLER B, 2005, P INT 2005 ISCA LISB
   Schuller B, 2008, LECT NOTES ARTIF INT, V5078, P99, DOI 10.1007/978-3-540-69369-7_12
   Schuller B, 2007, INT CONF ACOUST SPEE, P941
   Schuller B, 2007, INT CONF ACOUST SPEE, P733
   Schuller B, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P793
   Schuller B, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P30
   SCHULTZ T, 1995, P ICASSP, V1, P293
   Sebe N., 2005, Handbook of Pattern Recognition and Computer Vision
   SHRIBERG E, 2005, P EUR C SPEECH COMM
   Stiefelhagen R, 2002, IEEE T NEURAL NETWOR, V13, P928, DOI 10.1109/TNN.2002.1021893
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]
   WALLHOFF F, 2006, P IEEE INT C MULT FU
   Wallhoff F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P493, DOI 10.1109/ICME.2006.262433
   WIMMER M, 2008, P 3 INT C COMP VIS T
   Witten I. H., 2005, DATA MINING PRACTICA
   Wöllmer M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P597
   Wu LZ, 1999, IEEE T MULTIMEDIA, V1, P334, DOI 10.1109/6046.807953
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 80
TC 113
Z9 118
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2009
VL 27
IS 12
SI SI
BP 1760
EP 1774
DI 10.1016/j.imavis.2009.02.013
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 513PL
UT WOS:000271335000003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, Y
   Blum, RS
AF Chen, Yin
   Blum, Rick S.
TI A new automated quality assessment algorithm for image fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image fusion; Image quality; Human visual system model; Contrast
ID PERFORMANCE; CONTRAST; MASKING
AB Automated image quality assessment is highly desirable to evaluate the performance of various image fusion algorithms for night vision applications. In this paper we propose a perceptual quality evaluation method for image fusion which is based on human visual system (HVS) models. Our method assesses the image quality of a fused image using the following steps. First, the source and fused images are filtered by a contrast sensitivity function (CSF) after which a local contrast map is computed for each image. Second, a contrast preservation map is generated to describe the relationship between the fused image and each source image. Finally, the preservation maps are weighted by a saliency map to obtain an overall quality map. The mean of the quality map indicates the quality of the fused image. Experimental results compare the predictions made by our algorithm with human perceptual evaluations for several different parameter settings in our algorithm. The most popular existing algorithms are also evaluated. For some specific parameter settings, we find our algorithm provides better predictions, which are more closely matched to human perceptual evaluations, than the existing algorithms. The evaluations focus on the night vision application, but the algorithm we propose is applicable to other applications also. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Chen, Yin; Blum, Rick S.] Lehigh Univ, ECE Dept, Bethlehem, PA 18015 USA.
C3 Lehigh University
RP Chen, Y (corresponding author), Lehigh Univ, ECE Dept, Bethlehem, PA 18015 USA.
EM yic3@lehigh.edu
RI cai, bo/G-1491-2010
OI Blum, Rick S/0000-0002-1024-6771
FU Army Research Laboratory [W91 INF-06-20020]
FX Research was sponsored by the Army Research Laboratory and was
   accomplished under Cooperative Agreement Number W91 INF-06-20020. The
   views and conclusions contained in the document are those of the authors
   and should not be interpreted as representing the official policies,
   either expressed or implied, of the Army Research Laboratory or the U.S.
   Government. The U.S. Government is authorized to reproduce and
   distribute reprints for Government purposes notwithstanding any
   copyright notation heron.
CR ANDERSON CH, 1987, Patent No. 4718104
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   BENDER EJ, 2002, P SPIE VACUUM SOLID, V4796, P140
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen H, 2005, P SOC PHOTO-OPT INS, V5813, P34, DOI 10.1117/12.605784
   Chen Y., 2005, P 8 INT C INF FUS
   FOLEY JM, 1994, J OPT SOC AM A, V11, P1710, DOI 10.1364/JOSAA.11.001710
   FRECHETTE S, 2005, IEEE C ADV VID SIGN, P486
   HUNTSBERGER T, 1993, P SOC PHOTO-OPT INS, V2059, P488, DOI 10.1117/12.150252
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   LUBIN J, 1995, VISUAL MODELS TARGET, pCH10
   Pappas T.N., 2000, HDB IMAGE VIDEO PROC
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   PETROVIC V, 2000, P 3 INT C IM FUS, V2, P14
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Raj R.G., 2005, Proceedings of the 2005 IEEE International Conference on Image Processing, V3, P1152
   Rockinger O, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P288, DOI 10.1109/ICIP.1997.632093
   SADJADI F, 2005, JOINT IEEE INT WORKS, P8
   TOET A, 1989, PATTERN RECOGN LETT, V9, P255, DOI 10.1016/0167-8655(89)90004-4
   Varshney P. K., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P532, DOI 10.1109/ICIP.1999.817171
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Watson AB, 2005, J VISION, V5, P717, DOI 10.1167/5.9.6
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
NR 26
TC 310
Z9 340
U1 3
U2 52
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1421
EP 1432
DI 10.1016/j.imavis.2007.12.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800002
DA 2024-07-18
ER

PT J
AU Li, BP
   Meng, MQH
AF Li, Baopu
   Meng, Max Q. -H.
TI Texture analysis for ulcer detection in capsule endoscopy images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Capsule endoscopy image; Texture features; Curvelet transform; Local
   binary pattern; Neural network; Support vector machines
ID CLASSIFICATION; REPRESENTATION; GRAY
AB Capsule endoscopy (CE) has gradually seen its wide application in hospitals in the last few years because it can view the entire small bowel without invasiveness. However, CE produces too many images each time, thus causing a huge burden to physicians, so it is meaningful to help clinicians if we can employ computerized methods to diagnose. This paper presents a new texture extraction scheme for ulcer region discrimination in CE images. A new idea of curvelet based local binary pattern is proposed as textural features to distinguish ulcer regions from normal regions, which makes full use of curvelet transformation and local binary pattern. The proposed new textural features can capture multi-directional features and show robustness to illumination changes. Extensive classification experiments using multilayer perceptron neural network and support vector machines on our image data validate that it is promising to employ the proposed texture features to recognize ulcer regions in CE images. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Li, Baopu; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Li, BP (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM greenfigo2008@gmail.com
RI meng, meng/GWZ-7461-2022; Meng, Max Q.-H./C-8078-2009; Meng,
   Q./GSI-6185-2022
FU Hong Kong government [CUHK4213/04E]
FX The authors show sincere thanks to the unknown reviewers for their
   valuable comments which lead to a significant improvement of the paper.
   This project is supported by RGC Competitive Earmarked Research Grant
   #CUHK4213/04E of the Hong Kong government, awarded to Max Meng, and the
   authors should also thank James Lau and Yawen Chan, two experts in
   Prince of Wales Hospital in Hong Kong, for providing and collecting CE
   image data.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2003, Hosp Physician
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   Boulougoura M, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P405
   CANDES EJ, 2006, ACTA NUMER, P1
   CANDES EJ, THESIS STANFORD U
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Daubechies I., 1992, Ten lectures on wavelets, DOI [DOI 10.1137/1.9781611970104, 10.1137/1.9781611970104]
   FOURATI W, 2005, J TEST EVAL, V33, P181
   FRANCI RD, 2004, P 3 INT C CAPS END M
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HAYKIN S, 1996, NEURAL NETWORKS COMP
   *HONG KONG CANC RE, 2003, HIGHL CANC STAT
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   LAKOVIDIS DK, 2005, P 18 IEEE S COMP BAS
   Liao S, 2007, INT CONF ACOUST SPEE, P1221
   MINH ND, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI DOI 10.1109/TIP.2002.806252
   Mulcahy C., 1997, SPELMAN SCI MATH J, V1, P22
   OH JH, 2006, P SPIE MED IMAGING, V6144, P577
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140
   Starck JL, 2003, ASTRON ASTROPHYS, V398, P785, DOI 10.1051/0004-6361:20021571
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   TUCEYAN M, HDB PATTERN RECOGNIT, P207
   WU CM, 1992, IEEE T MED IMAGING, V11, P141, DOI 10.1109/42.141636
   Yoshida H, 2003, PHYS MED BIOL, V48, P3735, DOI 10.1088/0031-9155/48/22/008
NR 31
TC 100
Z9 109
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1336
EP 1342
DI 10.1016/j.imavis.2008.12.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200010
DA 2024-07-18
ER

PT J
AU Li, CQ
   Li, S
   Chen, GR
   Halang, WA
AF Li, Chengqing
   Li, Shujun
   Chen, Guanrong
   Halang, Wolfgang A.
TI Cryptanalysis of an image encryption scheme based on a compound chaotic
   sequence
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cryptanalysis; Image encryption; Chaos; Differential chosen-plaintext
   attack; Randomness test
ID SIGNAL SECURITY SYSTEM
AB Recently, an image encryption scheme based on a compound chaotic sequence was proposed. In this paper, the security of the scheme is studied and the following problems are found: (I) a differential chosen-plaintext attack can break the scheme with only three chosen plain-images; (2) there is a number of weak keys and some equivalent keys for encryption; (3) the scheme is not sensitive to the changes of plain-images; and (4) the compound chaotic sequence does not work as a good random number source. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Li, Chengqing] Hong Kong Polytech Univ, Elect & Informat Engn Dept, Hong Kong, Hong Kong, Peoples R China.
   [Li, Shujun] Univ Konstanz, Fachbereich Informat & Informat Wissensch, D-78457 Constance, Germany.
   [Chen, Guanrong] City Univ Hong Kong, Dept Elect Engn, Kowloon Tong, Hong Kong, Peoples R China.
   [Halang, Wolfgang A.] Fernuniv, Lehrstuhl Informat Tech, D-58084 Hagen, Germany.
C3 Hong Kong Polytechnic University; University of Konstanz; City
   University of Hong Kong; Fern University Hagen
RP Li, CQ (corresponding author), Hong Kong Polytech Univ, Elect & Informat Engn Dept, Hong Kong, Hong Kong, Peoples R China.
EM zjulcq@gmail.com
RI Halang, Wolfgang A./O-3573-2016; Li, Shujun/A-9032-2008; Chen,
   Guanrong/F-6000-2011; Li, Chengqing/B-9388-2008
OI Li, Shujun/0000-0001-5628-7328; Chen, Guanrong/0000-0003-1381-7418; Li,
   Chengqing/0000-0002-5385-7644
FU City University of Hong Kong [7002134]; Alexander von Humboldt
   Foundation of Germany
FX This research was supported by the City University of Hong Kong under
   the SRG Grant 7002134. In particular, Shujun Li was supported by a
   research fellowship of the Alexander von Humboldt Foundation of Germany.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2001, NIST SPECIAL PUBLICA
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen HC, 2003, EURASIP J APPL SIG P, V2003, P1291, DOI 10.1155/S1110865703309011
   Chen HC, 2003, J SYST ARCHITECT, V49, P355, DOI 10.1016/S1383-7621(03)00087-0
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Li CQ, 2005, EURASIP J APPL SIG P, V2005, P1277, DOI 10.1155/ASP.2005.1277
   Li SJ, 2008, J SYST SOFTWARE, V81, P1130, DOI 10.1016/j.jss.2007.07.037
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Li SJ, 2005, INTERNET COMMUN SER, P133
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   *NIST, 1994, FED INF PROC STAND P, V1401
   *NIST, 2002, FED PROC STAND PUBL, P140
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Tong XJ, 2008, IMAGE VISION COMPUT, V26, P843, DOI 10.1016/j.imavis.2007.09.005
   Yen JC, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P49, DOI 10.1109/ISCAS.2000.858685
NR 17
TC 97
Z9 100
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1035
EP 1039
DI 10.1016/j.imavis.2008.09.004
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shan, CF
   Gong, SG
   McOwan, PW
AF Shan, Caifeng
   Gong, Shaogang
   McOwan, Peter W.
TI Facial expression recognition based on Local Binary Patterns: A
   comprehensive study
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Local Binary Patterns; Support vector
   machine; Adaboost; Linear discriminant analysis; Linear programming
ID AUTOMATIC-ANALYSIS; CLASSIFICATION; SEQUENCES; DYNAMICS
AB Automatic facial expression analysis is an interesting and challenging problem, and impacts important applications in many areas such as human-computer interaction and data-driven animation. Deriving an effective facial representation from original face images is a vital step for successful facial expression recognition. In this paper, we empirically evaluate facial representation based on statistical local features, Local Binary Patterns, for person-independent facial expression recognition. Different machine learning methods are systematically examined on several databases. Extensive experiments illustrate that LBP features are effective and efficient for facial expression recognition. We further formulate Boosted-LBP to extract the most discriminant LBP features, and the best recognition performance is obtained by using Support Vector Machine classifiers with Boosted-LBP features. Moreover, we investigate LBP features for low-resolution facial expression recognition, which is a critical problem but seldom addressed in the existing work. We observe in our experiments that LBP features perform stably and robustly over a useful range of low resolutions of face images, and yield promising performance in Compressed low-resolution video sequences captured in real-world environments. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Shan, Caifeng] Philips Res Labs, NL-5656 AE Eindhoven, Netherlands.
   [Gong, Shaogang; McOwan, Peter W.] Univ London, Dept Comp Sci, London E1 4NS, England.
C3 Philips; Philips Research; University of London
RP Shan, CF (corresponding author), Philips Res Labs, High Tech Campus 36, NL-5656 AE Eindhoven, Netherlands.
EM caifeng.shan@philips.com; sgg@dcs.qmul.ac.uk; pmco@dcs.qmul.ac.uk
RI Shan, Caifeng/W-6178-2019
OI Shan, Caifeng/0000-0002-2131-1671
CR [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 1965, The expression of emotions in man and animal
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], IEEE INT C MULT EXPO
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], 2005, HDB FACE RECOGNITION
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 1976, Pictures of facial affect
   [Anonymous], 1991, IEEE C COMP VIS PATT
   [Anonymous], 1978, INT JOINT C PATTERN, DOI DOI 10.1145/2522848.2531745
   Bartlett M, 2003, CVPR WORKSH CVPR HCI
   BARTLETT M, 2004, IEEE INT C SYST MAN
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bolme DS, 2003, LECT NOTES COMPUT SC, V2626, P304
   Chang Y, 2004, PROC CVPR IEEE, P520
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Dornaika F, 2005, IEEE I CONF COMP VIS, P1733, DOI 10.1109/ICCV.2005.225
   Ekman P, 1978, FACIAL ACTION CODING
   Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232
   Everingham M, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P441
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Feng X., 2005, Pattern Recognition and Image Analysis, V15, P546
   Feng XY, 2004, LECT NOTES COMPUT SC, V3212, P668
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Hadid A., 2004, IEEE C COMP VIS PATT
   Hampapur A., 2003, P IEEE WORKSH
   HOEY J, 2004, IEEE C COMP VIS PATT
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   KALIOUBY RE, 2004, IEEE CVPR WORKSH REA
   LEE CS, 2005, IEEE INT WORKSH AN M
   Liao S, 2006, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2006.312418
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Padgett C., 1997, Advances in Neural Information Processing Systems
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   SHAN C, 2005, IM PROC 2005 ICIP 20, V2, P370, DOI DOI 10.1109/ICIP.2005.1530069
   SHAN C, 2005, BRIT MACH VIS C BMVC, V1, P399
   SHAN C, 2005, IEEE ICCV WORKSH HUM, V3723, P221
   Tian Y., 2004, CVPR WORKSH FAC PROC
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   VALSTAR M., 2005, COMPUTER VISION PATT, P76, DOI DOI 10.1109/CVPR.2005.457
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Viola P, 2001, P 2001 IEEE COMP SOC, pII
   Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334, DOI 10.1109/TPAMI.2005.165
   Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414
   Yeasin M., 2004, IEEE C COMP VIS PATT
   YIN L, 2004, ACM MULTIMEDIA
   Zhang G., 2004, CHIN C BIOM REC, P179
   Zhang Z, 1998, IEEE INT C AUT FAC G
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 61
TC 1403
Z9 1534
U1 4
U2 286
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 803
EP 816
DI 10.1016/j.imavis.2008.08.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000019
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Khatoonabadi, SH
   Rahmati, M
AF Khatoonabadi, Seyed Hossein
   Rahmati, Mohammad
TI Automatic soccer players tracking in goal scenes by camera motion
   elimination
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Grass field extraction; Lines tracking; Membership identification;
   Occlusion reasoning; Players tracking; Soccer goal scenes
AB In this paper, we propose a novel and effective algorithm for tracking soccer players in goal scenes, by eliminating fast camera motions effect through the correspondence between line marks in soccer Held model and image sequences. The proposed algorithm comprises four steps. At the first step, we introduce an automatic grass field extraction algorithm that is tested for various soccer video types and conditions. The field line marks, which are used to locate the players, are detected at the second step using Hough Transform and tracked in all frames by predicting their positions using Kalman Filter. At the third step, we introduce a novel approach for estimating the players' positions during the Course of tracking players. We estimate a player's position in the current frame by observing his position in the old frame within the soccer field model, using Perspective Transformation of the old frame to the real world coordinate system, and then by projecting back the obtained player's position into the Current frame. At the final step, the players are tracked by applying the region-based detection algorithm, the Histogram Back-Projection algorithm or a combination of the Merge-Split approach and the Template-Matching algorithm around the estimated positions, depending on whether or not the occlusion has Occurred and if yes, how it has occurred, Then their memberships are identified by an algorithm that employs both appearance and spatial information of the players. Image sequences of different soccer games were captured from different sources, and all experiments were performed off-line. The results of our experimentations show that our algorithm is highly robust to occlusion, different soccer field colours, different lights such as sunlight and spotlight, shadows of players and fading the whole screen due to fast camera movements. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Khatoonabadi, Seyed Hossein; Rahmati, Mohammad] Amirkabir Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Amirkabir University of Technology
RP Rahmati, M (corresponding author), Amirkabir Univ Technol, Dept Comp Engn, Hafez St, Tehran, Iran.
EM hossein.khatoonabadi@gmail.com; mohammad.rahmati@gmail.com
OI Rahmati, Mohammad/0000-0002-0591-6910
CR [Anonymous], 1995, P IEEE INT C MULT CO
   CHEN SC, 2004, P IEEE INT C MULT EX, V1, P265
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   EKIN A, 2002, S EL IM SCI TECHN VI, P763
   Figueroa P, 2004, INT C PATT RECOG, P787, DOI 10.1109/ICPR.2004.1333890
   Gabriel Pierre F, 2003, Advanced Concepts for Intelligent Vision Systems, P166
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   INTILLE SS, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P672, DOI 10.1109/ICCV.1995.466874
   Iwase S, 2004, INT C PATT RECOG, P751, DOI 10.1109/ICPR.2004.1333881
   LEFEVRE S, 2000, IAPR INT WORKSH MACH, P501
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   Mills S., 2003, The British Machine Vision Conference, P173
   Pers J, 2001, ISPA 2001: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P362, DOI 10.1109/ISPA.2001.938656
   PERS J, 2001, P 1 INT WORKSH IM SI, P81
   PERS J, 2001, P 9 INT C COMP AN IM, P374
   Seo Y., 1997, International Conference on Image Analysis and Processing, P196, DOI DOI 10.1007/3-540-63508-4
   Sonka M., 1993, IMAGE PROCESSING ANA
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Utsumi O, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P45, DOI 10.1109/ICME.2002.1035714
   VANDENBROUCKE N, 1997, P INT C SYST MAN CYB, V4, P3660
   Xu Peng., 2001, Proceedings of the 2001 IEEE International Conference on Multimedia and Expo (ICME), P721, DOI [10.1109/ICME.2001.1237822, DOI 10.1109/ICME.2001.1237822]
   Yamada A, 2002, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2002.1044697
   Yang YQ, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3759
   Yoon HS, 2002, ETRI J, V24, P443, DOI 10.4218/etrij.02.0102.0005
   YOW D, 1995, P AS C COMP VIS, P167
NR 26
TC 38
Z9 46
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 469
EP 479
DI 10.1016/j.imavis.2008.06.015
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600017
DA 2024-07-18
ER

PT J
AU Scheidat, T
   Vielhauer, C
   Dittman, J
AF Scheidat, Tobias
   Vielhauer, Claus
   Dittman, Jana
TI Handwriting verification - Comparison of a multi-algorithmic and a
   multi-semantic approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Distance measures; Multi-algorithmic fusion; Multi-semantic
   fusion; Online handwriting
AB In this paper, a comparison of an existing multi-algorithmic and a new multi-semantic fusion approach for biometric online handwriting user verification is presented. First, in order to improve the authentication performance of a biometric online handwriting system four classification algorithms are combined using several weighting strategies for matching score level fusion. Second, based on the best two algorithms and the best weighting strategy found during the test of the In multi-algorithmic approach, a new multi-semantic fusion approach using a pair wise combination of four semantics on matching score level is proposed. As semantics we understand alternative handwritten contents (e.g. symbols) in addition to signatures. We show that both fusion approaches, multi-algorithmic and multi-semantic, can lead to a fusion result which is better than the result of the best single algorithm or semantics involved. While the improvement for the multi-algorithmic system yields 19'%, we observe more than 57% for the multi-semantic approach. (C) 2008 Published by Elsevier B.V.
C1 [Scheidat, Tobias; Vielhauer, Claus; Dittman, Jana] Otto VonGuericke Univ Magdegurg, Res Grp Multimedia & Secur, Inst Tech & Business Informat Syst, Dept Comp Sci, D-39106 Magdeburg, Germany.
C3 Otto von Guericke University
RP Scheidat, T (corresponding author), Otto VonGuericke Univ Magdegurg, Res Grp Multimedia & Secur, Inst Tech & Business Informat Syst, Dept Comp Sci, Univ Pl 2, D-39106 Magdeburg, Germany.
EM tobias.scheidat@iti.cs.uni-magdeburg.de;
   claus.vielhauer@iti.cs.uni-magdebure.de;
   jana.dittmann@iti.cs.uni-magdeburg.de
FU European Commission [IST-2002-507634]; Deutsche Forschungsgemeinschaf
   (DFG, German Research Foundation)
FX The work described in this paper has been supported in part by the
   European Commission through the IST Programme under Contract
   IST-2002-507634 BIOSECURE. The work on biometric hashes for verification
   purposes is partly supported by the Deutsche Forschungsgemeinschaft
   (DFG, German Research Foundation). The database acquisition used in this
   publication has been produced with the assistance of the European Union
   (project CultureTech). The content of this publication is the sole
   responsibility of the University Magdeburg and their co-authors and can
   in no way be taken to reflect the views of the European Union.
CR [Anonymous], P 4 INT C AUD VID BA
   CHANG K, 2003, P WORKSH MULT US AUT
   *CULT TECH PROJ, 2006, CULT DIM DIG MULT SE
   Czyz J, 2002, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2002.1048228
   Garcia-Salicetti S, 2007, ANN TELECOMMUN, V62, P36
   Jain AK, 2004, COMMUN ACM, V47, P34, DOI 10.1145/962081.962102
   JAIN AK, 1999, TR9914 MSU
   Kato Y, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA585
   LYVAN B, 2003, P WORKSH MULT US AUT, P13
   Ross A., 2004, P EUROPEAN SIGNAL PR, P1221
   SCHEIDAT T, 2006, SPIE, V6072, P106
   SCHEIDAT T, 2005, P IEEE INT C MULT EX
   SCHMIDT C, 1999, ON LINE UNTERSCHRIFT
   Van BL, 2004, LECT NOTES COMPUT SC, V3087, P318
   Vielhauer C, 2005, PROC SPIE, V5684, P63, DOI 10.1117/12.585869
   Vielhauer C, 2005, LECT NOTES COMPUT SC, V3677, P191
   Vielhauer C, 2002, INT C PATT RECOG, P123, DOI 10.1109/ICPR.2002.1044628
   Vielhauer C., 2006, Biometric user authentication for IT security
   YANIKOGLU B, 2004, P ICPR BCTP WORKSH
NR 19
TC 6
Z9 6
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 2
PY 2009
VL 27
IS 3
SI SI
BP 269
EP 278
DI 10.1016/j.imavis.2007.03.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 393QA
UT WOS:000262386600006
DA 2024-07-18
ER

PT J
AU Mekuz, N
   Bauckhage, C
   Tsotsos, JK
AF Mekuz, Nathan
   Bauckhage, Christian
   Tsotsos, John K.
TI Subspace manifold learning with sample weights
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Subspace learning; Nonlinear dimensionality reduction; Locally linear
   embedding; Face recognition
ID FACE RECOGNITION; EIGENFACES
AB Subspace manifold learning represents a popular class of techniques in statistical image analysis and object recognition. Recent research in the field has focused on nonlinear representations; locally linear embedding (LLE) is one such technique that has recently gained popularity. We present and apply a generalization of LLE that introduces sample weights. We demonstrate the application of the technique to face recognition, where a model exists to describe each face's probability of occurrence. These probabilities are used as weights in the learning of the low-dimensional face manifold. Results of face recognition using this approach are compared against standard nonweighted LLE and PCA. A significant improvement in recognition rates is realized using weighted LLE on a data set where face occurrences follow the modeled distribution. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Mekuz, Nathan; Bauckhage, Christian; Tsotsos, John K.] York Univ, Dept Comp Sci & Engn, Ctr Vis Res, N York, ON M3J 1P3, Canada.
C3 York University - Canada
RP Mekuz, N (corresponding author), York Univ, Dept Comp Sci & Engn, Ctr Vis Res, CSE 3031,4700 Keele St, N York, ON M3J 1P3, Canada.
EM mekuz@cs.yorku.ca
RI Tsotsos, John/N-1131-2019; Tsotsos, John K/G-3436-2011; Tsotsos,
   John/HTO-0616-2023; Bauckhage, Christian/M-7872-2014
OI Tsotsos, John/0000-0002-8621-9147; Bauckhage,
   Christian/0000-0001-6615-2128
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bellman R. E., 1961, ADAPTIVE CONTROL PRO
   Bishop CM, 1998, IEEE T PATTERN ANAL, V20, P281, DOI 10.1109/34.667885
   De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X
   Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669
   Li SZ, 2001, PROC CVPR IEEE, P207
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shashua A, 2002, INT C PATT RECOG, P590, DOI 10.1109/ICPR.2002.1048008
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Skocaj D, 2002, LECT NOTES COMPUT SC, V2353, P761
   Taylor B, 1969, METHODUS INCREMENTOR, V3
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thurstone LL, 1931, PSYCHOL REV, V38, P406, DOI 10.1037/h0069792
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yang MH, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P117
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhao W, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P336, DOI 10.1109/AFGR.1998.670971
NR 25
TC 0
Z9 0
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 80
EP 86
DI 10.1016/j.imavis.2006.10.007
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700009
DA 2024-07-18
ER

PT J
AU Sim, R
   Little, JJ
AF Sim, Robert
   Little, James J.
TI Autonomous vision-based robotic exploration and mapping using hybrid
   maps and particle filters
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Robotics; SLAM; Exploration; Mapping; RBPF; Stereo vision; Hybrid maps;
   SIFT
ID LOCALIZATION
AB This paper addresses the problem of exploring and mapping an unknown environment using a robot equipped with a stereo vision sensor. The main contribution of our work is a fully automatic mapping system that operates without the use of active range sensors (such as laser or sonic transducers), can operate on-line and can consistently produce accurate maps of large-scale environments. Our approach implements a Rao-Blackwellised particle filter (RBPF) to solve the simultaneous localization and mapping problem and uses efficient data structures for real-time data association, mapping, and spatial reasoning. We employ a hybrid map representation that infers 3D point landmarks from image features to achieve precise localization, coupled with occupancy grids for safe navigation. We demonstrate two exploration approaches, one based on a greedy strategy and one based on an iteratively deepening strategy. This paper describes our framework and implementation, and presents our exploration method, and experimental results illustrating the functionality of the system. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Sim, Robert] Braintech Inc, Consumer Robot Lab, N Vancouver, BC V7P 3N4, Canada.
   [Little, James J.] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.
C3 University of British Columbia
RP Sim, R (corresponding author), Braintech Inc, Consumer Robot Lab, 102-930 W 1st St, N Vancouver, BC V7P 3N4, Canada.
EM rsim@braintech.com; little@cs.ubc.ca
CR [Anonymous], 2003, P C INT ROB SYST IRO
   Barfoot T., 2006, INTELLIGENCE SPACE R
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   Davison AJ, 2001, PROC CVPR IEEE, P384
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720
   ELIAZAR AI, 2004, P 2004 IEEE INT C RO
   Elinas P, 2006, IEEE INT CONF ROBOT, P1564, DOI 10.1109/ROBOT.2006.1641930
   Eustice RM, 2005, IEEE INT CONF ROBOT, P2417
   Huang SD, 2005, IEEE INT CONF ROBOT, P1091
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593
   Montemerlo M., 2003, P INT JOINT C ARTIFI, P1151, DOI [10.5555/1630659.1630824, DOI 10.5555/1630659.1630824]
   MURPHY K, 1999, 1999 NEUR INF PROC S, P1015
   Murray D, 2000, AUTON ROBOT, V8, P161, DOI 10.1023/A:1008987612352
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467
   Sim R, 2005, IEEE INT CONF ROBOT, P661
   Sim R., 2005, IEEE IROS WORKSHOP R, P16
   Stachniss C, 2005, IEEE INT CONF ROBOT, P655
   Stachniss C., 2003, P INT C ART INT IJCA
   STACHNISS C, 2007, T ROBOTICS AUTOMATIO, V23, P34
   Stachniss C., 2005, P ROBOTICS SCI SYSTE, P65, DOI [10.15607/RSS.2005.I.009, DOI 10.15607/RSS.2005.I.009]
   YAMAUCHI B, 1998, IEEE INT C ROB AUT L, P2833
NR 23
TC 27
Z9 29
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 167
EP 177
DI 10.1016/j.imavis.2008.04.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700017
DA 2024-07-18
ER

PT J
AU Adán, M
   Adán, A
   Vázquez, AS
   Torres, R
AF Adan, Miguel
   Adan, Antonio
   Vazquez, Andres S.
   Torres, Roberto
TI Biometric verification/identification based on hands natural layout
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE biometric systems; security; hand geometry; invariant features;
   similarity
ID IDENTIFICATION; VERIFICATION
AB In this paper, a hand biometric system for verification and recognition purposes is presented. The method is based on three keys. Firstly, the system is based on using a Natural Reference System (NRS) defined on the hand's natural layout. Consequently, neither hand-pose training nor a pre-fixed position is required in the registration process. Secondly, the hand's features are obtained through the polar representation of the hand's contour. This implies minimum image processing and low computational cost. Thirdly, instead of common methods that use one hand, we use right and left hands. This allows us to consider distance measures for direct (R/R, L/L) and crossed (R/L, L/R) hands obtaining improvements in FAR/FRR and identification ratios. The paper shows details about the experimentation and presents the results of the method applied on 5640 images belonging to 470 users. The results are good enough to consider this biometric system for future security/control applications. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Adan, Miguel; Adan, Antonio; Vazquez, Andres S.; Torres, Roberto] UCLM, Escuela Super Informat, Ciudad Real 13071, Spain.
C3 Universidad de Castilla-La Mancha
RP Adán, M (corresponding author), UCLM, Escuela Super Informat, Paseo De La Univ 4, Ciudad Real 13071, Spain.
EM Miguel.Adan@uclni.es; Antonio.Adan@uclm.es; Andres.Vazquez@uclm.es;
   Roberto.Torres@uclm.es
RI Adán, Antonio/A-1153-2012; Vázquez, Andres S./ABA-8641-2020
OI Adán, Antonio/0000-0002-0370-9651; Vázquez, Andres
   S./0000-0002-8144-9429
CR Adan M., 2005, C MACH VIS APPL TSUK, P160
   Golfarelli M, 1997, IEEE T PATTERN ANAL, V19, P786, DOI 10.1109/34.598237
   González S, 2003, 37TH ANNUAL 2003 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P281
   Han CC, 2004, IMAGE VISION COMPUT, V22, P909, DOI 10.1016/j.imavis.2004.05.008
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   Jain A. K., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P857, DOI 10.1109/ICIP.1999.823019
   Jain A.K., 1999, Proceedings of Second International Conference on Audio and Video-Based Biometric Person Authentication (AVBPA), P166
   Joshi DG, 1998, PATTERN RECOGN, V31, P15, DOI 10.1016/S0031-3203(97)00034-4
   Kumar A, 2003, LECT NOTES COMPUT SC, V2688, P668
   Li Q, 2004, LECT NOTES COMPUT SC, V3338, P680
   Öden C, 2001, LECT NOTES COMPUT SC, V2091, P336
   ONG MGK, 2003, WBMA03
   Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796
   SIDLAUSKAS D, 1987, I NUCL MAT MANAGEMEN, V16, P442
   WONG A, 2002, IAPR WORKSH MACH VIS
   Wu XQ, 2004, PATTERN RECOGN, V37, P1987, DOI 10.1016/j.patcog.2004.02.015
   Xiong W, 2005, PATTERN RECOGN, V38, P1651, DOI 10.1016/j.patcog.2004.07.008
   You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
   ZUNKEL RL, 1999, BIOMETRICS, P87
NR 21
TC 28
Z9 34
U1 0
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 451
EP 465
DI 10.1016/j.imavis.2007.08.010
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100001
DA 2024-07-18
ER

PT J
AU Fernández-García, NL
   Carmona-Poyato, A
   Medina-Carnicer, R
   Madrid-Cuevas, FJ
AF Fernandez-Garcia, N. L.
   Carmona-Poyato, A.
   Medina-Carnicer, R.
   Madrid-Cuevas, F. J.
TI Automatic generation of <i>consensus</i> ground truth for the comparison
   of edge detection techniques
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE consensus ground truth; empirical discrepancy measurement; edge
   detection
AB Two new methods are proposed to automatically generate consensus ground truth for real images: Minimean and Minimax methods. These methods and a version of the Yitzhaky and Peli method have been used to provide ground truth for the comparison of edge detection techniques. The developed experiments have revealed that the Minimean consensus method is suitable for the comparison of edge detectors because its results are equivalent to those obtained with artificial or manual ground truth. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Fernandez-Garcia, N. L.; Carmona-Poyato, A.; Medina-Carnicer, R.; Madrid-Cuevas, F. J.] Univ Cordoba, Dept Informat & Anal Numerico, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba
RP Fernández-García, NL (corresponding author), Univ Cordoba, Dept Informat & Anal Numerico, Edificio Einstein,Campus De Rabanales, E-14071 Cordoba, Spain.
EM malfegan@uco.es
RI Fernández García, Nicolás Luis/AAP-9118-2021; Madrid-Cuevas, Francisco
   Jose/H-1396-2015; Carmona-Poyato, Angel/G-1593-2015; Medina-Carnicer,
   Rafael/G-3401-2015
OI Fernández García, Nicolás Luis/0000-0002-1267-6986; Madrid-Cuevas,
   Francisco Jose/0000-0001-6557-7431; Carmona-Poyato,
   Angel/0000-0002-8820-8396; Medina-Carnicer, Rafael/0000-0003-4481-0614
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   ALLEN JT, 1989, IEEE S EASTCON 89, P722
   [Anonymous], 1999, ANAL VARIANCE
   BADDELEY AJ, 1992, KARLSRUHE, P59
   BAKER S, 1999, IEEE C COMP VIS PATT, V2, P373
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   Brown AM, 2005, COMPUT METH PROG BIO, V79, P89, DOI 10.1016/j.cmpb.2005.02.007
   Bryant D. J., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P138
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Christensen HI, 1997, MACH VISION APPL, V9, P215, DOI 10.1007/s001380050042
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   DOUGHERTY S, 1998, EMPIRICAL EVALUATION, P211
   Egnal G, 2004, IMAGE VISION COMPUT, V22, P943, DOI 10.1016/j.imavis.2004.03.018
   Fernández-García NL, 2004, PATTERN RECOGN LETT, V25, P35, DOI 10.1016/j.patrec.2003.08.011
   FORSTNER W, 1996, WORKSH PERFORMANCE C, P59
   Gauch J., 1992, VISUAL COMMUN-US, V1818, P1168
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   HARALICK RM, 1994, CVGIP-IMAG UNDERSTAN, V60, P245, DOI 10.1006/cviu.1994.1055
   Heath M, 1998, COMPUT VIS IMAGE UND, V69, P38, DOI 10.1006/cviu.1997.0587
   HOOVER A, 1995, 9501 U S FLOR DEP CO
   KADONAGA T, 1995, WORKSH GRAPHICS RECO, P3
   Koschan A., 1995, Proceedings of the 2nd Asian Conference on Computer Vision, V3, P574
   LEE HC, 1991, IEEE T SIGNAL PROCES, V39, P1181, DOI 10.1109/78.80971
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   MARTIN D, 2004, IEEE T PATTERN ANAL, V25, P1
   Medina-Carnicer R, 2005, PATTERN RECOGN LETT, V26, P1423, DOI 10.1016/j.patrec.2004.11.024
   Novak CL., 1987, P DARPA IMAGE UNDERS, V1, P35
   PIETIKAINEN M, 1986, INT C PATT REC, P594
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   SALOTTI M, 1996, WORKSH PERFORMANCE C
   Scharcanski J, 1997, IEEE T CIRC SYST VID, V7, P397, DOI 10.1109/76.564116
   SCHEFFE H, 1953, BIOMETRIKA, V40, P87, DOI 10.1093/biomet/40.1-2.87
   SHIOZAKI A, 1986, COMPUT VISION GRAPH, V36, P1, DOI 10.1016/S0734-189X(86)80025-1
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P259, DOI 10.1109/83.217230
   Trahanias PE, 1996, IEEE T SYST MAN CY B, V26, P135, DOI 10.1109/3477.484445
   WEYIN L, 1997, MACH VISION APPL, V9, P215
   Yitzhaky Y, 2003, IEEE T PATTERN ANAL, V25, P1027, DOI 10.1109/TPAMI.2003.1217608
   Zhang YJ, 1997, PATTERN RECOGN LETT, V18, P963, DOI 10.1016/S0167-8655(97)00083-4
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
   ZHANG YZ, 1992, SIGNAL PROCESSING 6, V1, P551
   ZHOU YT, 1989, IEEE T PATTERN ANAL, V11, P84, DOI 10.1109/34.23115
   Zhu SY, 1999, OPT ENG, V38, P612, DOI 10.1117/1.602105
   2003, BERKELEY SEGMENTATIO
NR 45
TC 42
Z9 49
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 496
EP 511
DI 10.1016/j.imavis.2007.06.009
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100004
DA 2024-07-18
ER

PT J
AU Kingston, A
   Svalbe, I
AF Kingston, Andrew
   Svalbe, Imants
TI Generalised finite radon transform for NxN images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE discrete radon transform; discrete projection; Fourier slice theorem;
   image representation
ID PROJECTIONS; RECONSTRUCTION
AB This paper extends the domain of the finite radon transform (FRT) to apply to square arrays of arbitrary size. The FRT is a discrete formalism of the Radon transform that assumes the image is periodic over the finite array, Z(N)(2) and requires only arithmetic operations for both forward and exact inverse transformation. The FRT is useful in image processing applications such as tomographic reconstruction [I. Svalbe, D. van der Spek, Reconstruction of tomographic images using analog projections and the digital Radon transform, Linear Algebra and Its Applications 339 (15) (2001) 125-145.], image representation [M. Do, M. Vetterli, Finite ridgelet transform for image representation, IEEE Transactions on Image Processing 12(l).] image convolution [D. Lun, T. Chan, T. Hsung, D. Feng, Y. Chan, Efficient blind image restoration using discrete periodic Radon transform, IEEE Transactions on Image Processing 13(2) (2004) 188-200.], image watermarking and encryption [A. Kingston, I. Svalbe, Projective transforms on periodic discrete image arrays, to appear in P. Hawkes (Ed), Advances in Imaging and Electron Physics (2006).], and robust data transmission [A. Kingston, I. Svalbe, Geometric shape effects in redundant keys used to encrypt data transformed by finite discrete Radon projections, In: Proc. 8th Int. Conf. on Digital Image Computing: Techniques and Applications (2005).].
   The original definition by Matus and Flusser in 1993 [F. Matus, J. Flusser, Image representation via a finite Radon transform, IEEE Transactions on Pattern Analysis and Machine Intelligence 15(10) (1993) 996-1006.] was restricted to apply only to square arrays of prime size, pxp. Hsung, Lun and Siu developed an FRT that also applied to dyadic square arrays, 2(n)x2(n), called the discrete periodic radon transform (DPRT) [T. Hsung, D. Lun, W. Siu, The discrete periodic Radon transform, IEEE Transactions on Signal Processing 44(10) (1996) 2651-2657.]. Kingston further extended this to define an FRT that applies to prime-adic arrays, p(n)xp(n). This paper defines a generalised FRT that applies to square arrays of arbitrary size, NxN for N E N The Fourier slice theorem and convolution property (two important properties of the classical Radon transform) are established for this FRT. The original image can be reconstructed exactly from the FRT projections using Fourier inversion and back-projection. New methods are identified to correct for the over-representation of pixels due to the compositeness of N. A remarkable result is established that enables 2D sampling patterns to be corrected by an angle invariant 1D filter prior to back-projection. (c) 2006 Elsevier B.V. All rights reserved.
C1 Monash Univ, Sch Phys, Melbourne, Vic 3800, Australia.
C3 Monash University
RP Kingston, A (corresponding author), Monash Univ, Sch Phys, Melbourne, Vic 3800, Australia.
EM andrew.kingston@univ-nantes.fr; imants.svalbe@sci.monash.edu.au
RI kingston, andrew/D-2635-2009
OI kingston, andrew/0000-0002-0606-4094
CR AVERBUCH A, IN PRESS SIAM J SCI
   BEYLKIN G, 1987, IEEE T ACOUST SPEECH, V35, P162, DOI 10.1109/TASSP.1987.1165108
   DEANS SR, 1993, RADON TRANSFORM ITS
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Do MN, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P367, DOI 10.1109/ICIP.2000.899394
   DO MN, 2000, P SPIE C WAV APPL SI
   EDHOLM PR, 1987, IEEE T MED IMAGING, V6, P301, DOI 10.1109/TMI.1987.4307847
   Hardy G.H., 1979, An introduction to the theory of numbers
   Hsung TC, 1996, IEEE T SIGNAL PROCES, V44, P2651, DOI 10.1109/78.539055
   Kak A.C. Slaney M., 1999, PRINCIPLES COMPUTERI
   KINGSTON A, 2003, ELECT NOTES DISCRETE, V12
   KINGSTON A, 2005, LNCS, V2429, P136
   KINGSTON A, 2005, P 8 INT C DIG IM COM
   KINGSTON A, 2005, THESIS MONASH U
   KINGSTON A, 2006, IN PRESS SIGNAL PROC
   Kingston A., 2003, Digital Image Computing: Techniques and Applications, P263
   KINGSTON A, 2006, ADV IMAGING ELECT PH, V139
   Lun DPK, 2004, IEEE T IMAGE PROCESS, V13, P188, DOI 10.1109/TIP.2004.823820
   Lun DPK, 2003, SIGNAL PROCESS, V83, P941, DOI 10.1016/S0165-1684(02)00498-X
   MATUS F, 1993, IEEE T PATTERN ANAL, V15, P996, DOI 10.1109/34.254058
   Normand N, 1996, P SOC PHOTO-OPT INS, V2727, P1070, DOI 10.1117/12.233180
   Svalbe I, 2003, LECT NOTES COMPUT SC, V2886, P485
   Svalbe I, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1015, DOI 10.1109/ICIP.2001.958298
   Svalbe I, 2001, LINEAR ALGEBRA APPL, V339, P125, DOI 10.1016/S0024-3795(01)00487-6
NR 24
TC 17
Z9 17
U1 0
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1620
EP 1630
DI 10.1016/j.imavis.2006.03.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200010
OA Green Published
DA 2024-07-18
ER

PT J
AU Prasad, L
AF Prasad, Lakshman
TI Rectification of the chordal axis transform skeleton and criteria for
   shape decomposition
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE shape; delaunay triangulation; chordal axis; medial axis; skeleton;
   shape decomposition; co-circularity; shape graph; grouping
AB Skeletonization and parts-based decomposition are important to the analysis, characterization, and recognition of shapes. In earlier works we proposed the chordal axis transform (CAT), based on constrained Delatmay triangulations (CDT), for analyzing discrete shapes. In this paper, we refine the CAT skeleton to have smoother branches and stable branch points of any degree based on approximate co-circularity of edge-adjacent triangles. We also introduce new criteria for obtaining visually meaningful shape decompositions using approximate co-circularity and a discrete axial derivative for shapes based on their CDTs. (c) 2006 Elsevier B.V. All rights reserved.
C1 Los Alamos Natl Lab, Int Space & Response Div, Space & Remote Sensing Sci Grp ISR 2, Los Alamos, NM 87545 USA.
C3 United States Department of Energy (DOE); Los Alamos National Laboratory
RP Prasad, L (corresponding author), Los Alamos Natl Lab, Int Space & Response Div, Space & Remote Sensing Sci Grp ISR 2, Los Alamos, NM 87545 USA.
EM prasad@lanl.gov
OI Prasad, Lakshman/0000-0003-3967-3643
CR ARVO J, 2000, AAAI SPRING S SMART, P140
   ATTALI D, 1997, COMPUTER VISION IMAG, V67
   ATTALI D, STABILITY COMPUTATIO
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   August J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P42, DOI 10.1109/CVPR.1999.784606
   Binford T.O., 1971, VISUAL PERCEPTION CO
   Blum H., 1967, S MOD SPEECH VIS FOR
   Borgefors G, 2001, IEEE T PATTERN ANAL, V23, P1296, DOI 10.1109/34.969119
   DIBAJA GS, 1994, PATTERN RECOGN, V27, P1039, DOI 10.1016/0031-3203(94)90143-0
   Felzenszwalb PF, 2003, PROC CVPR IEEE, P102
   FREEMAN H, 1978, PATTERN RECOGN, V10, P159, DOI 10.1016/0031-3203(78)90024-9
   Goodman J.E., 1997, Handbook of Discrete and Computational Geometry
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Katz RA, 2003, INT J COMPUT VISION, V55, P139, DOI 10.1023/A:1026183017197
   OGNIEWICZ RL, 1994, P IEEE CVPR SEATT WA
   Prasad L, 2005, LECT NOTES COMPUT SC, V3429, P263
   PRASAD L, 2000, P SPIE VIS GEOM 9, V4117
   PRASAD L, 1997, LALP97010139 CTR NON
   PRASAD L, 2000, P SPIE, V4117
   PRASAD L, 1997, 5 SIAM C GEOM DES NA
   RICHARDS WA, 1987, J OPT SOC AM A, V4, P1168, DOI 10.1364/JOSAA.4.001168
   SHAPIRO LG, 1979, IEEE T PATTERN ANAL, V1, P10, DOI 10.1109/TPAMI.1979.4766871
   SIDDIQI K, 1995, PARTS VISUAL FORM CO, V17
   Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P636, DOI 10.3758/BF03205536
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   YAMAKAWA S, 2001, QUAD LAYER LAYERED Q
NR 27
TC 10
Z9 11
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1557
EP 1571
DI 10.1016/j.imavis.2006.06.025
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200005
DA 2024-07-18
ER

PT J
AU Bosch, A
   Muñoz, X
   Freixenet, J
AF Bosch, A.
   Munoz, X.
   Freixenet, J.
TI Segmentation and description of natural outdoor scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image understanding; object classification; object segmentation
ID IMAGE; CLASSIFICATION; FEATURES; OBJECTS; REGIONS
AB A scene description and segmentation system capable of recognising natural objects (e.g. sky, trees, grass) under different outdoor conditions is presented. We propose an hybrid and probabilistic classifier of image regions as a first step in solving the problem of scene context generation. We focus our work in the problem of image regions labeling to classify every pixel of a given image into one of several predefined classes. The result is both a segmentation of the image and a recognition of each segment as a given object class or as an unknown segmented object. Classification performance has been evaluated with the Outex dataset and compared to the approach of Marti et al. (IVC 2001) and He et al. (CVPR 2004) using their own datasets, showing the superiority of our method. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Girona, Inst Informat & Applicat, Girona 17071, Spain.
C3 Universitat de Girona
RP Bosch, A (corresponding author), Univ Girona, Inst Informat & Applicat, Campus Montilivi,Edifici P4,Av Lluis Santalo SN, Girona 17071, Spain.
EM aboschr@eia.udg.es; xmunoz@eia.udg.es; jordif@eia.udg.es
RI Munoz, Xavier/R-9446-2018; Freixenet, Jordi/I-1689-2014
OI Munoz, Xavier/0000-0002-2560-3540; Freixenet, Jordi/0000-0001-9524-3328
CR Barnard K, 2003, PROC CVPR IEEE, P675
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   Batlle J, 2000, IMAGE VISION COMPUT, V18, P515, DOI 10.1016/S0262-8856(99)00040-2
   CELENK M, 1990, COMPUT VISION GRAPH, V52, P145, DOI 10.1016/0734-189X(90)90052-W
   CHU CC, 1992, IEEE T PATTERN ANAL, V14, P840, DOI 10.1109/34.149595
   Drummond T, 2000, COMPUT VIS IMAGE UND, V80, P315, DOI 10.1006/cviu.2000.0882
   Fan JP, 2005, PATTERN RECOGN, V38, P865, DOI 10.1016/j.patcog.2004.07.011
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   FERGUS R, 2005, INT C COMP VIS BEIJ
   FREIXENET J, 2004, EUR C COMP VIS PRAG, V2, P250
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He XM, 2004, PROC CVPR IEEE, P695
   HUDELOT M, 2003, IEEE INT C TOOLS ART
   Kumar S, 2003, IMAGE VISION COMPUT, V21, P87, DOI 10.1016/S0262-8856(02)00125-7
   Kumar VP, 1996, IEEE T PATTERN ANAL, V18, P74, DOI 10.1109/34.476423
   Li F. F., 2004, WORKSH GEN MOD BAS V
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JB, 2003, PATTERN RECOGN, V36, P2781, DOI 10.1016/S0031-3203(03)00170-5
   Martí J, 2001, IMAGE VISION COMPUT, V19, P1041, DOI 10.1016/S0262-8856(01)00065-8
   Milch B, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1352
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Oliva Aude., INT J COMPUTER VISIO, V42, P145
   Pantofaru C, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1314
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   SCHAFFALITZKY F, 2001, INT C COMP VIS, V2, P636
   Serrano N, 2004, PATTERN RECOGN, V37, P1773, DOI 10.1016/j.patcog.2004.03.003
   Singhal A, 2003, PROC CVPR IEEE, P235
   SIVIC J, 2005, 2005005 AI MIT COMP
   STRAT TM, 1991, IEEE T PATTERN ANAL, V13, P1050, DOI 10.1109/34.99238
   Sudderth EB, 2005, IEEE I CONF COMP VIS, P1331
   Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951
   TU Z, 2003, ICCV, V1, P18
   Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   VOGEL J, 2004, SELECTED READINGS VI, V33
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 41
TC 33
Z9 38
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 727
EP 740
DI 10.1016/j.imavis.2006.05.015
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200018
DA 2024-07-18
ER

PT J
AU Elbakary, MI
   Sundareshan, MK
AF Elbakary, M. I.
   Sundareshan, M. K.
TI Multi-modal image registration using local frequency representation and
   computer-aided design (CAD) models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image registration; object recognition; multi-sensor signal processing;
   sensor fusion
ID TARGET RECOGNITION
AB Given two images of roughly the same scene, image registration is the process of determining the transformation that nearly maps one image to another. While some efficient procedures have been developed lately, the registration of images acquired from sensors operating in different modalities is still a challenging problem. In general, such images have different gray level characteristics and the features in the two images to be registered are often not well preserved, rendering registration techniques such as those based on feature extraction and area correlation generally not efficient, and hence not feasible in all cases. In this paper, we propose a new algorithm for multi-sensor image registration based on using the local frequency representation of the images together with image representation of computer-aided design (CAD) models that permit region-of-interest-to-region-of-interest, ROI-to-ROI, space to solve image registration problem (instead of relying only on the captured images to solve image registration problem using image-to-image space). The key point underlying the proposed approach is the employment of local frequency representations of CAD models images to efficiently determine sets of matching points from the images to be registered, which in turn enables obtaining correspondence between these sets for estimating the transformation parameters. Performance evaluation results reported here indicate that the proposed technique is robust and yields promising results for multi-modal image registration. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Arizona, Dept Elect & Comp Engn, Tucson, AZ 85721 USA.
C3 University of Arizona
RP Elbakary, MI (corresponding author), Univ Arizona, Dept Elect & Comp Engn, Tucson, AZ 85721 USA.
EM elbakary@ece.arizona.edu; sundareshan@ece.arizona.edu
CR Ali MA, 2002, INT GEOSCI REMOTE SE, P1331, DOI 10.1109/IGARSS.2002.1026106
   [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], P INT C IM PROC
   BHATTACHARYA P, 1994, OPT ENG, V33, P3334, DOI 10.1117/12.179385
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Coiras E, 2000, OPT ENG, V39, P282, DOI 10.1117/1.602363
   DAVID P, 2003, P IEEE COMP SOC C CO
   Elbakary M, 2005, PATTERN RECOGN LETT, V26, P2164, DOI 10.1016/j.patrec.2005.03.035
   ELBAKARY MI, 2003, IPDSL82003 U AR ECE
   Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1
   GRUEN A., 1997, AUTOMATIC EXTRACTION
   HAMILTON MK, 1993, 27 AS C SIGN SYST CO, P283
   LANTERMAN AD, 1995, RADAR LADAR PROCESSI, V2562
   LI H, 1995, IEEE T IMAGE PROCESS, V4, P320, DOI 10.1109/83.366480
   Liu J, 2002, IEEE T MED IMAGING, V21, P462, DOI 10.1109/TMI.2002.1009382
   Liu J, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P120, DOI 10.1109/WACV.2000.895412
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Miller MI, 1997, IEEE T IMAGE PROCESS, V6, P157, DOI 10.1109/83.552104
   Stevens MR, 1997, IEEE T IMAGE PROCESS, V6, P126, DOI 10.1109/83.552102
   TIPDECHO T, 2002, P OP SOURC GIS GRASS
   WUNSCH P, 1996, P IEEE INT C PATT RE
   Zheng QF, 1998, PROC CVPR IEEE, P515, DOI 10.1109/CVPR.1998.698654
   Zheng QF, 2001, IEEE T IMAGE PROCESS, V10, P565, DOI 10.1109/83.913591
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 24
TC 11
Z9 13
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 663
EP 670
DI 10.1016/j.imavis.2006.05.009
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200012
DA 2024-07-18
ER

PT J
AU Welk, M
   Weickert, J
   Galic, I
AF Welk, Martin
   Weickert, Joachim
   Galic, Irena
TI Theoretical foundations for spatially discrete 1-D shock filtering
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE shock filters; analytical solution; well-posedness; dynamical systems;
   mode filters
ID IMAGE SEGMENTATION; ENHANCEMENT; DIFFUSION
AB While shock filters are popular morphological image enhancement methods, no well-posedness theory is available for their corresponding partial differential equations (PDEs). By analysing the dynamical system of ordinary differential equations that results from a space discretisation of a PDE for 1-D shock filtering, we derive an analytical solution and prove well-posedness. We show that the results carry over to the fully discrete case when an explicit time discretisation is applied. Finally we establish an equivalence result between discrete shock filtering and local mode filtering.(c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Saarland, Mathemat Image Anal Grp, Fac Math & Comp Sci, D-66041 Saarbrucken, Germany.
C3 Saarland University
RP Welk, M (corresponding author), Univ Saarland, Mathemat Image Anal Grp, Fac Math & Comp Sci, Bldg E11, D-66041 Saarbrucken, Germany.
EM welk@mia.uni-saarland.de; weickert@mia.uni-saarland.de;
   galic@mia.uni-saarland.de
RI Galić, Irena/AAA-6768-2020; Galić, Irena/HMO-6935-2023
OI Galić, Irena/0000-0002-0211-4568; Galić, Irena/0000-0002-0211-4568;
   Welk, Martin/0000-0002-6268-7050
CR ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   Brockett RW, 1992, P IEEE INT C AC SPEE, V3, P125
   COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327
   Gilboa G, 2002, LECT NOTES COMPUT SC, V2350, P399
   Griffin LD, 2000, P ROY SOC A-MATH PHY, V456, P2995, DOI 10.1098/rspa.2000.0650
   Guichard F, 2001, LECT NOTES COMPUT SC, V2106, P75
   Kornprobst P, 1997, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.1997.609344
   KRAMER HP, 1975, PATTERN RECOGN, V7, P53, DOI 10.1016/0031-3203(75)90013-8
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   OSHER S, 1991, P SOC PHOTO-OPT INS, V1567, P414, DOI 10.1117/12.50835
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   Pollak I, 2000, IEEE T IMAGE PROCESS, V9, P256, DOI 10.1109/83.821738
   Remaki L, 2003, J MATH IMAGING VIS, V18, P129, DOI 10.1023/A:1022160416128
   Schavemaker JGM, 2000, PATTERN RECOGN, V33, P997, DOI 10.1016/S0031-3203(99)00160-0
   Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429
   TORROBA PL, 1994, OPT ENG, V33, P528, DOI 10.1117/12.152006
   van den Boomgaard R, 2002, INT C PATT RECOG, P927, DOI 10.1109/ICPR.2002.1048187
   Weickert J, 2003, LECT NOTES COMPUT SC, V2781, P1
   Weickert J., 1998, ANISOTROPIC DIFUSION, Vthird
   Welk M, 2005, COMPUT IMAGING VIS, V30, P311
   Welk M, 2005, LECT NOTES COMPUT SC, V3459, P585
NR 21
TC 10
Z9 11
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 455
EP 463
DI 10.1016/j.imavis.2006.06.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600008
DA 2024-07-18
ER

PT J
AU Al Aghbari, Z
   Al-Haj, R
AF Al Aghbari, Zaher
   Al-Haj, Ruba
TI Hill-manipulation: An effective algorithm for color image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image segmentation; Hill-Manipulation; color segmentation
AB In cluster-based image segmentation techniques, clusters may be viewed as hills in a histogram. These techniques may suffer from large hills that dominate the smaller hills and thus they result in a loss of image details in the segmentation process. In this paper, we propose a novel approach, called Hill-Manipulation algorithm, to solve the problems of the traditional cluster-based image segmentation methods. It starts by segmenting the 3D color histogram into hills according to the number of local maxima found, and then each hill is checked against defined criteria for possible splitting into more homogenous smaller hills. As a result, details of an image are distinguished and the details are captured in the segmentation. Finally, the resulting hills undergo a post-processing task that filters out the small non-significant regions. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates.
C3 University of Sharjah
RP Al Aghbari, Z (corresponding author), Univ Sharjah, Dept Comp Sci, POB 27272, Sharjah, U Arab Emirates.
EM zaher@sharjah.ac.ae; ruba@sharjah.ac.ae
RI cai, bo/G-1491-2010
CR [Anonymous], P IEEE COMP SOC C CO
   Belongie S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P675, DOI 10.1109/ICCV.1998.710790
   BHAGAVATHY S, 2002, P IEEE INT C PATT RE
   CARDANI D, 2001, ADV DEV HANDS C JUL
   CHANG CI, 1994, PATTERN RECOGN, V27, P1275, DOI 10.1016/0031-3203(94)90011-6
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Deng Yining., 2001, IEEE T PATTERN ANAL
   EL M, 2003, IEEE INT C IM PROC I
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   FREDERIX G, 2004, STAT PRINCIPLED APPR
   Freixenet J., 2002, P 7 EUR C COMP VIS 3
   GRINIAS I, 2001, INT WORKSH LOW BIT R
   ISHIKAWA H, 2001, P 8 IEEE INT C COMP
   Jermyn I. H., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P904, DOI 10.1109/ICCV.1999.790318
   Liew AWC, 2000, IEE P-VIS IMAGE SIGN, V147, P185, DOI 10.1049/ip-vis:20000218
   Lucchese L, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P74, DOI 10.1109/IVL.1999.781127
   Lucchese L, 1999, GLOBECOM'99: SEAMLESS INTERCONNECTION FOR UNIVERSAL SERVICES, VOL 1-5, P2038, DOI 10.1109/GLOCOM.1999.827563
   LUI L, 1994, IEEE T PAMI, V16, P689
   Manjunath B.S., 2001, IEEE T CIRCUITS SYST
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Newsam S, 2001, ACTA ASTRONAUT, V48, P567, DOI 10.1016/S0094-5765(01)00021-2
   OHASHI T, 2003, IASTED INT C SIGNAL, P2003
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   PARK HS, 1998, P INT WORKSH VER LOW, P149
   Park SH, 1998, PATTERN RECOGN, V31, P1061, DOI 10.1016/S0031-3203(97)00116-7
   PRAMANIK S, 2002, INT C IM PROC ROCH N
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SAHOO P, 1988, SURVEY THRESHOLDING
   SCHETTINI R, 1993, PATTERN RECOGN LETT, V14, P499, DOI 10.1016/0167-8655(93)90030-H
   SHAFFREY CW, 2002, P IEEE INT C IM PROC
   SUMENGEN B, 2002, P IEEE INT C PATT RE
   SUMENGEN B, 2003, P IEEE INT C IM PROC
   TOMINAGA S, 1992, COLOR RES APPL, V17, P230, DOI 10.1002/col.5080170405
   WANG L, 2003, IEEE INT C IM PROC I
   Winkeler J. F., 1997, Genetic Programming 1997 Proceedings of the Second Annual Conference, P330
   Wu P, 2000, SIGNAL PROCESS-IMAGE, V16, P33, DOI 10.1016/S0923-5965(00)00016-3
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 37
TC 35
Z9 43
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 894
EP 903
DI 10.1016/j.imavis.2006.02.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100010
DA 2024-07-18
ER

PT J
AU Kim, DY
   Park, JW
AF Kim, DY
   Park, JW
TI Connectivity-based local adaptive thresholding for carotid artery
   segmentation using MRA images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE carotid artery; region-of-interest; local adaptive thresholding; medical
   image segmentation
ID RECONSTRUCTION; QUANTIFICATION; TRACKING; STENOSIS; MODELS
AB The computer algorithms for the delineation of anatomical structures and other regions of interest on the medical imagery are important component in assisting and automating specific radiological tasks. In addition. the segmentation of region is an important first step for. image related application and visualization tasks. In this paper, we propose a fast and automated connectivity-based local adaptive thresholding (CLAT) algorithm to segment the carotid artery in sequence medical imagery. This algorithm provides the new feature that is the circumscribed quadrangle on the segmented carotid artery for region-of-interest (ROI) determination. By using the preserved connectivity between consecutive slice images, the size of the ROI is adjusted like a moving window according to the segmentation result of previous slice image. The histogram is prepared for each ROI and then smoothed by local averaging for the threshold selection. The threshold value for carotid artery segmentation is locally selected on each slice image and is adaptively determined through the sequence image. In terms of automated features and computing time, this algorithm is more effective than region growing and deformable model approaches. This algorithm is also applicable to segment the cylinder shape structures and tree-like blood vessels such as renal artery and coronary artery in the medical imagery. Experiments have been conducted on synthesized images, phantom and clinical data sets with various Gaussian noise. (C) 2005 Elsevier B.V. All rights reserved.
C1 Chungnam Natl Univ, Dept Informat & Commun Engn, Taejon 305764, South Korea.
C3 Chungnam National University
RP 108-302 CheongGu Apt,462-4 Jeonmin Dong, Taejon 305729, South Korea.
EM dykim@ns.kopec.co.krs
RI cai, bo/G-1491-2010
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], 1992, R. woods digital image processing
   Barratt DC, 2004, IEEE T MED IMAGING, V23, P567, DOI 10.1109/TMI.2004.825601
   CALOTTO MJ, 1987, IEEE T PAMI, P121
   CHANG YL, 1994, IEEE T IMAGE PROCESS, V3, P868, DOI 10.1109/83.336259
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   GULLBERG GT, 1992, IEEE T MED IMAGING, V11, P91, DOI 10.1109/42.126915
   HIGGINS WE, 1989, P IEEE EMBS, V11, P563, DOI 10.1109/IEMBS.1989.95874
   Higgins WE, 1996, IEEE T MED IMAGING, V15, P377, DOI 10.1109/42.500146
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jain R., 1995, MACHINE VISION
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kawata Y, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB500
   Kawata Y., 1995, IEEE NUCL SCI S MED, V3, P1660
   Kirbas C, 2004, ACM COMPUT SURV, V36, P81, DOI 10.1145/1031120.1031121
   KLEIN A, 1994, IEEE COMPUTERS CARDI, P113
   Kozerke S, 1999, J MAGN RESON IMAGING, V10, P41, DOI 10.1002/(SICI)1522-2586(199907)10:1<41::AID-JMRI6>3.0.CO;2-J
   LEI TH, 1992, IEEE T MED IMAGING, V11, P62, DOI 10.1109/42.126911
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   MAO F, 2000, IEEE ENG MED BIOL C, P1734
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Molina C, 1998, P SOC PHOTO-OPT INS, V3338, P504, DOI 10.1117/12.310929
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   NIKI N, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1873, DOI 10.1109/NSSMIC.1993.373618
   OBRIEN JF, 1994, P SPIE VISUALIZATION, V2359, P25
   Parker J. R., 1997, ALGORITHM IMAGE PROC
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   RUECKERT D, 1995, COMPUTER ASSISTED RADIOLOGY, P137
   Rueckert D, 1997, IEEE T MED IMAGING, V16, P581, DOI 10.1109/42.640747
   Schmitt H, 2002, IEEE T MED IMAGING, V21, P251, DOI 10.1109/42.996343
   Sonka M., 2014, Image processing, analysis, and machine vision
   Sorantin E, 2002, IEEE T MED IMAGING, V21, P263, DOI 10.1109/42.996344
   Tozaki T., 1995, IEEE NUCL SCI S MEDI, V3, P1470
   Umbaugh SE., 1998, Computer Vision and Image Processing: A practical approach using CVIP tools, V6st ed.
   Vaidyanathan M, 1997, MAGN RESON IMAGING, V15, P323, DOI 10.1016/S0730-725X(96)00386-4
   van Bemmel CM, 2004, MAGN RESON MED, V51, P753, DOI 10.1002/mrm.20020
   VANBEMMEL CM, 2002, LECT NOTES COMPUTER, V2489, P36
   Wust P, 1998, PHYS MED BIOL, V43, P3295, DOI 10.1088/0031-9155/43/11/009
   Xu C., 2000, HDB MEDICAL IMAGING, V2, P129, DOI [10.1117/3.831079.ch3, DOI 10.1117/3.831079.CH3]
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yim PJ, 2000, IEEE T MED IMAGING, V19, P568, DOI 10.1109/42.870662
   Yim PJ, 2000, PROC SPIE, V3978, P245, DOI 10.1117/12.383404
   Zaidi H, 1999, MED PHYS, V26, P574, DOI 10.1118/1.598559
   ZUBAL IG, 1994, MED PHYS, V21, P299, DOI 10.1118/1.597290
NR 48
TC 24
Z9 33
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 12
PY 2005
VL 23
IS 14
BP 1277
EP 1287
DI 10.1016/j.imavis.2005.09.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 997KJ
UT WOS:000234243800004
DA 2024-07-18
ER

PT J
AU Shamaie, A
   Sutherland, A
AF Shamaie, A
   Sutherland, A
TI Hand tracking in bimanual movements
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE hand tracking; bimanual movement; Kalman filtering; motor control
ID BEHAVIOR
AB A general hand-tracking algorithm is presented for tracking hands in bimanual movements. The problem is approached from a neuroscience point of view. Using a dynamic model and some motor control phenomena, the movement of the hands during a bimanual movement is recognised. By capturing the hands velocities and recognising the bimanual synchronisation, the hands are tracked and reacquired in different types of movements. This includes tracking hands when they are separated, and reacquiring them at the end of hand-hand occlusion. Different applications are demonstrated including active vision where the camera view direction and position change. (C) 2005 Elsevier Ltd All rights reserved.
C1 Dublin City Univ, Sch Comp, Ctr Digital Video Proc, Dublin 9, Ireland.
C3 Dublin City University
RP GestureTek R&D, 240 Catherine St,Suite 403, Ottawa, ON K2P 2G8, Canada.
EM atid@ieee.org; alistair@computing.dcu.ie
CR Anderson R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.131
   [Anonymous], 1997, Statistical Methods for Speech Recognition
   [Anonymous], 1999, KALMAN FILTERING REA
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   BONNAUD L, 1997, P INT C IM PROC WASH
   Brown R. G., 1997, Introduction to Random Signals and Applied Kalman Filtering, V3rd
   CHEN J, 2003, VISUAL MODELLING EVA, V6, P1
   Davis J, 1999, INT J PATTERN RECOGN, V13, P381, DOI 10.1142/S0218001499000227
   DIEDRICHSEN J, 2001, PSYCHOL SCI, P6
   DOCKSTADER SL, 2000, WORKSH HUM MOT HUMO
   DONCHIN O, 1998, NATURE, P395
   Gong SG, 2002, IMAGE VISION COMPUT, V20, P873, DOI 10.1016/S0262-8856(02)00096-3
   HARRIS CM, 1998, SIGNAL DEPENDENT NOI, P394
   IANNIZZOTTO G, 2001, PUI 2001 ORL US
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   JACKSON GM, 2000, BRAIN, P123
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   KAWATO S, 2000, 5 INT C SIGN PROC BE
   KENNERLEY SW, 2002, NATURE NEUROSCIENCE
   KOHLER MRJ, 1997, INT C VIRT SYST MULT
   KOJIC N, 1999, P IEEE INT C COMP VI
   LU S, 2003, IEEE C COMP VIS PATT
   MAMMEN JP, 2001, P BRIT MACH VIS C
   McAllister G, 2002, IMAGE VISION COMPUT, V20, P827, DOI 10.1016/S0262-8856(02)00093-8
   McKenna SJ, 1998, PATTERN RECOGN, V31, P1883, DOI 10.1016/S0031-3203(98)00066-1
   MECHSNER F, 2002, MAX PLANK RES    JAN
   MECHSNER F, 2001, NATURE, P414
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   Pitas I., 1993, DIGITAL IMAGE PROCES
   RAJA Y, 1998, P AS C COMP VIS HONG
   REHG JM, 1994, VISUAL TRACKING HIGH
   SATO Y, 2000, P IEEE INT C AUT FAC
   SHAMAIE A, 2003, 5 INT WORKSH GEST SI
   SHAMAIE A, 2003, THESIS DUBLIN CITY U
   SHERRAH J, 2000, P BRIT MACH VIS C BM
   STRICKON J, 1998, ACM CHI C LOS ANG US
   TANIBATA N, 2002, 15 INT C VIS INT CAL
   Theodoridis S., 1999, Pattern recognition, P3
   TSURUOKA S, 1997, INT C VIRT SYST MULT
   Wolpert DM, 2001, TRENDS COGN SCI, V5, P487, DOI 10.1016/S1364-6613(00)01773-3
   ZHOU H, 2003, 10 INT C HUM COMP IN
   ZIEREN J, HANDS TRACKING FRONT
NR 42
TC 7
Z9 9
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1131
EP 1149
DI 10.1016/j.imavis.2005.07.010
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500003
DA 2024-07-18
ER

PT J
AU Tsai, DM
   Yang, RH
AF Tsai, DM
   Yang, RH
TI An eigenvalue-based similarity measure and its application in defect
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE similarity measure; defect detection; eigenvalues; template matching
ID INSPECTION; RECOGNITION
AB In this paper, we propose an eigenvalue-based similarity measure between two gray-level images and, in particular, aim at the application in defect detection. The pair-wise gray levels at coincident pixel locations in two compared images are used as the coordinates to plot the correspondence map. If two compared images are identical, the plot in the correspondence map is a diagonal straight line. Otherwise, it results in a non-linear shape in the correspondence map. The smaller eigenvalue of the covariance matrix of the data points in the correspondence map is used as the similarity measure. It will be approximately zero for two resembled images, and distinctly large for dissimilar images. Experimental results from a number of assembled PCBs (printed circuit boards) have shown the effectiveness of the proposed similarity measure for detecting local defects in complicated images. (c) 2005 Elsevier Ltd. All rights reserved.
C1 Yuan Ze Univ, Dept Ind Engn & Management, Taoyuan, Taiwan.
C3 Yuan Ze University
RP Yuan Ze Univ, Dept Ind Engn & Management, 135 Yuan Tung Rd, Taoyuan, Taiwan.
EM iedmtsai@saturn.yzu.edu.tw
CR Chang MC, 2001, INT J PATTERN RECOGN, V15, P675, DOI 10.1142/S0218001401001039
   CHATTERJEE C, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P4095, DOI 10.1109/ICNN.1994.374870
   Costa CE, 2000, MACH VISION APPL, V11, P225, DOI 10.1007/s001380050105
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Ibrahim Z, 2005, INTEGR COMPUT-AID E, V12, P201
   Ibrahim Z, 2002, SICE 2002: PROCEEDINGS OF THE 41ST SICE ANNUAL CONFERENCE, VOLS 1-5, P2108
   Kim JH, 1996, ENG APPL ARTIF INTEL, V9, P655, DOI 10.1016/S0952-1976(96)00046-2
   OOI J, 1991, P SOC PHOTO-OPT INS, V1468, P740, DOI 10.1117/12.28670
   Penz H, 2001, P SOC PHOTO-OPT INS, V4303, P127, DOI 10.1117/12.424946
   Strang G., 1988, LINEAR ALGEBRA ITS A
   SZU HH, 1993, IEEE T IND ELECTRON, V40, P197, DOI 10.1109/41.222641
   Tsai DM, 2002, PATTERN RECOGN LETT, V23, P191, DOI 10.1016/S0167-8655(01)00099-X
   Wu WY, 1996, COMPUT IND, V28, P103, DOI 10.1016/0166-3615(95)00063-1
   Yazdi HR, 1998, REAL-TIME IMAGING, V4, P317, DOI 10.1016/S1077-2014(98)90002-X
NR 14
TC 32
Z9 34
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2005
VL 23
IS 12
BP 1094
EP 1101
DI 10.1016/j.imavis.2005.07.014
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 971ZK
UT WOS:000232423400006
DA 2024-07-18
ER

PT J
AU Sykora, D
   Buriánek, J
   Zára, J
AF Sykora, D
   Buriánek, J
   Zára, J
TI Colorization of black-and-white cartoons
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE colorization; image registration; image segmentation; edge detection;
   image analogies; image restoration; color-by-example; patch-based
   sampling; probabilistic relaxation
ID ALGORITHM; CONVOLUTION
AB We introduce a novel colorization framework for old black-and-white cartoons originally produced by a cel or paper based technology. In this case, the dynamic part of the scene is represented by a set of outlined homogeneous regions which superimpose the static background. To reduce a large amount of manual intervention we combine unsupervised image segmentation, background reconstruction, and structural prediction. Our system allows the user to specify the brightness of applied colors unlike the most of previous approaches which operate only with hue and saturation. We also present simple but effective color modulation, composition and dust spot removal techniques able to produce color images in broadcast quality without additional user intervention. (c) 2005 Elsevier B.V. All rights reserved.
C1 Czech Tech Univ, Dept Comp Sci & Engn, FEE, Prague 16627 6, Czech Republic.
   Digital Media Prod, Prague 14000 4, Czech Republic.
C3 Czech Technical University Prague
RP Czech Tech Univ, Dept Comp Sci & Engn, FEE, Tech 2, Prague 16627 6, Czech Republic.
EM sykorad@fel.cvut.cz
RI Zara, Jiri/AAA-2219-2021; Sýkora, Daniel/C-3075-2014
OI Zara, Jiri/0000-0003-2612-7942; 
CR AHMADYFARD A, 2000, P BRIT MACH VIS C, P745
   [Anonymous], 1982, Digital Picture Processing
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   BANCROFT DJ, 2000, BROADC ENG C P
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chang CW, 1997, J VISUAL COMP ANIMAT, V8, P165, DOI 10.1002/(SICI)1099-1778(199707)8:3<165::AID-VIS157>3.0.CO;2-2
   CHEN JS, 1987, IEEE T PATTERN ANAL, V9, P584, DOI 10.1109/TPAMI.1987.4767946
   Chen Tongbo., 2004, P ASIAN C COMPUTER V, P1164
   Chen YS, 2001, IEEE T IMAGE PROCESS, V10, P1212, DOI 10.1109/83.935037
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P2071, DOI 10.1109/83.887975
   Chuang YY, 2001, PROC CVPR IEEE, P264
   CLARK JJ, 1989, IEEE T PATTERN ANAL, V11, P43, DOI 10.1109/34.23112
   COOPER R, 1990, JOURNALISM Q URBANA, V68, P465
   Gonzalez R.C., 1987, DIGITAL IMAGE PROCES, VSecond
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Horiuchi T, 2003, IEEE IMAGE PROC, P457
   Horiuchi T, 2002, INT C PATT RECOG, P867, DOI 10.1109/ICPR.2002.1048165
   HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838
   Kilthau SL, 2002, IEEE IMAGE PROC, P669
   KING D, 1982, ISG102 U SO CAL
   KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5
   Kokaram A., 1998, Motion Picture Restoration
   LEIBOWITZ F, 1991, J AESTHET ART CRITIC, V49, P363, DOI 10.2307/431036
   LENBURG L, 1999, ENCY ANIMATED CARTOO
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   LEVIN A, 2004, P EUR C COMP VIS, P377
   Lucas B. D., 1981, P IJCAI, P674
   Madeira JS, 1996, VISUAL COMPUT, V12, P1
   MARKLE W, 1984, SMPTE J, V93, P632, DOI 10.5594/J03526
   Markle W., 1991, Canadian Patent, Patent No. 1291260
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   NAM KM, 1995, IEEE T CIRC SYST VID, V5, P344, DOI 10.1109/76.465087
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   Pan Z., 2004, 12th International Conference on Computer Graphics, Visualization and Computer Vision (WSCG), P515
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Qiu J, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P175
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   ROMASI C, 1991, CMUCS91132 SCH COMP
   SAPIRO G, 2004, IMA PREPRINT SERIES, V1979
   Sapiro G., 2001, Geometric Partial Differential Equations and Image Analysis
   Seah HS, 2000, VISUAL COMPUT, V16, P289, DOI 10.1007/s003719900068
   SERRA J, 1993, IMAGE ANAL MATH MORP, V1
   SOTAK GE, 1989, COMPUT VISION GRAPH, V48, P147, DOI 10.1016/S0734-189X(89)80036-2
   Sykora D., 2003, P SPRING C COMP GRAP, P245
   SYKORA D, 2004, P 3 INT S NONPH AN R, P121
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   WITKIN AP, 1986, PIXELS PREDICATES RE, P5
   YATZIV L, 2004, IMA PREPRINT SERIES, V2010
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 51
TC 26
Z9 29
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2005
VL 23
IS 9
BP 767
EP 782
DI 10.1016/j.imavis.2005.05.010
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VF
UT WOS:000231400700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lai, JZC
   Liaw, YC
AF Lai, JZC
   Liaw, YC
TI A fast search algorithm for mean-removed vector quantization using edge
   and texture strengths of a vector
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fast search algorithm; vector quantization; projection value;
   mean-removed vector quantization
ID ENCODING ALGORITHM; COMPRESSION
AB In this paper, a fast search algorithm for mean-removed vector quantization is proposed. Two inequalities are used to reduce distortion computations. Our algorithm makes use of a mean-removed vector's features (edge and texture strengths) to reject many unlikely codewords and it has the same image quality as the full search method. Experimental results show that our algorithm is much better than the full search method in terms of computing time and the number of distortion calculations. Comparing with the full search method, our method can effectively reduce the computing time by 60.2-94.2% and the number of distortion computations by 78.6-97.9% for the codebook sizes of 64-2048. As far as we know, our method is the first of its kind to reduce the encoding time for mean-removed vector quantization. (c) 2005 Elsevier B.V. All rights reserved.
C1 Nanhua Univ, Dept Comp Sci & Informat Engn, Chiayi 622, Taiwan.
   Natl Taiwan Ocean Univ, Dept Comp Sci, Chilung 202, Taiwan.
C3 Nanhua University; National Taiwan Ocean University
RP Liaw, YC (corresponding author), Nanhua Univ, Dept Comp Sci & Informat Engn, Chiayi 622, Taiwan.
EM ycliaw@mail.nhu.edu.tw
CR [Anonymous], 2012, VECTOR QUANTIZATION
   Baek S, 1997, IEEE SIGNAL PROC LET, V4, P325, DOI 10.1109/97.650035
   BEI CD, 1985, IEEE T COMMUN, V33, P1132, DOI 10.1109/TCOM.1985.1096214
   Chang PC, 2001, IEEE T IMAGE PROCESS, V10, P95, DOI 10.1109/83.892446
   CHEN SH, 1989, IEE PROC-I, V136, P391, DOI 10.1049/ip-i-2.1989.0059
   FOSTER J, 1985, IEEE T INFORM THEORY, V31, P348, DOI 10.1109/TIT.1985.1057035
   Hsieh CH, 1996, IEEE T IMAGE PROCESS, V5, P1579, DOI 10.1109/83.541428
   JIM Z, 2004, IEEE T IMAGE PROCESS, V13, P1554
   Kim DH, 2002, IEEE T NANOTECHNOL, V1, P170, DOI 10.1109/TNANO.2002.807382
   Lai JZC, 1996, J VIS COMMUN IMAGE R, V7, P163, DOI 10.1006/jvci.1996.0016
   Lai JZC, 2002, SIGNAL PROCESS, V82, P1375, DOI 10.1016/S0165-1684(02)00277-3
   Lai JZC, 1998, IEEE T IMAGE PROCESS, V7, P1753, DOI 10.1109/83.730390
   Liaw YC, 2002, PATTERN RECOGN, V35, P329, DOI 10.1016/S0031-3203(01)00048-6
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   NASRABADI NM, 1990, IEEE T COMMUN, V38, P2166, DOI 10.1109/26.64659
   Ngan KN, 1992, IEEE T IMAGE PROCESS, V1, P269, DOI 10.1109/83.148602
   Pan JS, 2003, IEEE T IMAGE PROCESS, V12, P265, DOI 10.1109/TIP.2003.810587
   RA SW, 1993, IEEE T CIRCUITS-II, V40, P576, DOI 10.1109/82.257335
   Tai SC, 1996, IEEE T COMMUN, V44, P1623, DOI 10.1109/26.545888
NR 19
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2005
VL 23
IS 8
BP 739
EP 746
DI 10.1016/j.imavis.2005.05.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VD
UT WOS:000231400500006
DA 2024-07-18
ER

PT J
AU Sladoje, N
   Nyström, I
   Saha, PK
AF Sladoje, N
   Nyström, I
   Saha, PK
TI Measurements of digitized objects with fuzzy borders in 2D and 3D
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE fuzzy shape representation; quantitative analysis; precision
ID SCALE IMAGE MEASUREMENTS; SURFACE-AREA ESTIMATION; PERIMETER; LENGTH
AB The results of our investigation of several measurements on digitized 2D and 3D objects with fuzzy borders are presented. The performance of surface area, volume, and roundness measure estimators for digitized balls with fuzzy borders is analyzed. The method we suggest provides significant improvement in precision, compared to analogous estimation results obtained on a crisp (hard) segmentation, especially in the case of low resolution images. (C) 2004 Elsevier B.V. All rights reserved.
C1 SLU, Ctr Image Anal, Uppsala, Sweden.
   Uppsala Univ, Ctr Image Anal, Uppsala, Sweden.
   Univ Penn, Dept Radiol, MIPG, Philadelphia, PA 19104 USA.
C3 Swedish University of Agricultural Sciences; Uppsala University;
   University of Pennsylvania
RP SLU, Ctr Image Anal, Uppsala, Sweden.
EM natasa@cb.uu.se; ingela@cb.uu.se; saha@mipg.upenn.edu
RI Saha, Punam K/F-8833-2011
OI Saha, Punam/0000-0003-1576-118X
CR BOGOMOLNY A, 1987, FUZZY SET SYST, V23, P257, DOI 10.1016/0165-0114(87)90062-5
   Coeurjolly D, 2003, LECT NOTES COMPUT SC, V2616, P101
   Coeurjolly D, 2002, INT C PATT RECOG, P330, DOI 10.1109/ICPR.2002.1047463
   DORST L, 1987, COMPUT VISION GRAPH, V40, P311, DOI 10.1016/S0734-189X(87)80145-7
   DUBOIS D, 1987, PATTERN RECOGN LETT, V6, P251, DOI 10.1016/0167-8655(87)90085-7
   EBERLY D, 1991, CVGIP-GRAPH MODEL IM, V53, P538, DOI 10.1016/1049-9652(91)90004-4
   EBERLY D, 1991, CVGIP-GRAPH MODEL IM, V53, P550, DOI 10.1016/1049-9652(91)90005-5
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Kenmochi Y, 2000, PROC SPIE, V4117, P100, DOI 10.1117/12.404839
   Kulpa Z., 1977, COMP GRAPH IMAGE PRO, V6, P434, DOI DOI 10.1016/S0146-664X(77)80021-X
   Lindblad J, 2003, LECT NOTES COMPUT SC, V2886, P348
   LINDBLAD J, 2002, LNCS, V2301, P267
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   ROSENFELD A, 1984, PATTERN RECOGN LETT, V2, P311, DOI 10.1016/0167-8655(84)90018-7
   ROSENFELD A, 1985, PATTERN RECOGN, V18, P125, DOI 10.1016/0031-3203(85)90035-4
   Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902
   Sladoje N, 2003, LECT NOTES COMPUT SC, V2886, P368
   Sladoje N, 2003, LECT NOTES COMPUT SC, V2749, P853
   UDUPA JK, 1994, CVGIP-GRAPH MODEL IM, V56, P311, DOI 10.1006/cgip.1994.1028
   VERBEEK PW, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P749, DOI 10.1109/ICPR.1992.202095
   Wyvill G., 1986, Visual Computer, V2, P227, DOI 10.1007/BF01900346
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 22
TC 34
Z9 44
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 123
EP 132
DI 10.1016/j.imavis.2004.06.011
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800004
DA 2024-07-18
ER

PT J
AU Varma, M
   Zisserman, A
AF Varma, M
   Zisserman, A
TI Unifying statistical texture classification frameworks
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Indian Conference on Vision, Graphics and Image Processing (ICVGIP)
CY DEC 16-18, 2002
CL Ahmedabad, INDIA
DE texture; classification; PDF representation; textons
AB The objective of this paper is to examine statistical approaches to the classification of textured materials from a single image obtained under unknown viewpoint and illumination. The approaches investigated here are based on the joint probability distribution of filter responses.
   We review previous work based on this formulation and make two observations. First, we show that there is a correspondence between the two common representations of filter outputs-textons and binned histograms. Second, we show that two classification methodologies, nearest neighbour matching and Bayesian classification, are equivalent for particular choices of the distance measure. We describe the pros and cons of these alternative representations and distance measures, and illustrate the discussion by classifying all the materials in the Columbia-Utrecht (CUReT) texture database.
   These equivalences allow us to perform direct comparisons between the texton frequency matching framework, best exemplified by the classifiers of Leung and Malik [Int. J. Comput. Vis. 43 (2001) 29], Cula and Dana [Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2001) 1041], and Varma and Zisserman [Proceedings of the Seventh European Conference on Computer Vision 3 (2002) 255], and the Bayesian framework most closely represented by the work of Konishi and Yuille [Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2000) 125]. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England.
C3 University of Oxford
RP Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.
EM manik@robots.ox.ac.uk; az@robots.ox.ac.uk
CR Aherne FJ, 1998, KYBERNETIKA, V34, P363
   [Anonymous], 1988, NUMERICAL RECIPES
   BACH FR, 2000, P 18 C UAI
   CHANTLER MJ, 2000, P BMVC, P486
   Cula OG, 2001, PROC CVPR IEEE, P1041
   Dana KJ, 1998, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.1998.698669
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Endres DM, 2003, IEEE T INFORM THEORY, V49, P1858, DOI 10.1109/TIT.2003.813506
   Konishi S, 2000, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.2000.855809
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schmid C, 2001, PROC CVPR IEEE, P39
   Topsoe F, 2000, IEEE T INFORM THEORY, V46, P1602, DOI 10.1109/18.850703
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   Vasconcelos N, 2000, INT C PATT RECOG, P38, DOI 10.1109/ICPR.2000.905271
   VIOLA P, 1995, 1548 MIT
   ZALESNY A, 2000, LNCS, P124
NR 17
TC 50
Z9 61
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2004
VL 22
IS 14
BP 1175
EP 1183
DI 10.1016/j.imavis.2004.03.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 882LG
UT WOS:000225939800004
DA 2024-07-18
ER

PT J
AU Godtliebsen, F
   Marron, JS
   Chaudhuri, P
AF Godtliebsen, F
   Marron, JS
   Chaudhuri, P
TI Statistical significance of features in digital images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE kernel smoothing; curvature; gradient; scale space; statistical
   significance; SiZer
ID SCALE-SPACE; DIFFUSION; FIELD; FLOW
AB This paper develops a methodology for finding which features in a noisy image are strong enough to be distinguished from background noise. It is based on scale-space, i.e. a family of smooths of the image. Pixel locations having statistically significant gradient and/or curvature are highlighted by colored symbols. The gradient version is enhanced by displaying regions of significance with streamlines. The usefulness of the new methodology is illustrated by the analysis of simulated and real images. (C) 2004 Elsevier B.V. All rights reserved.
C1 Indian Stat Inst, Theoret Stat & Math Div, Kolkata 700108, W Bengal, India.
   Univ Tromso, Dept Math & Stat, N-9037 Tromso, Norway.
   Univ N Carolina, Dept Stat, Chapel Hill, NC 27599 USA.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata; UiT
   The Arctic University of Tromso; University of North Carolina;
   University of North Carolina Chapel Hill
RP Indian Stat Inst, Theoret Stat & Math Div, 203 BT Rd, Kolkata 700108, W Bengal, India.
EM probal@isical.ac.in
CR Aldershof B., 1995, Appl. Anal, V59, P289
   CABRAL B, 1993, COMPUT GRAPH, V27, P263
   Chaudhuri P, 2000, ANN STAT, V28, P408, DOI 10.1214/aos/1016218224
   Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996
   CHAUDHURI P, 2002, UNPUB CURVATURE V SL
   Chu CK, 1998, J AM STAT ASSOC, V93, P526, DOI 10.2307/2670100
   DELMARCELLE T, 1995, COMPUTER VISUALIZATI, P129
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   GHOSH AK, 2004, UNPUB CLASSIFICATION
   GHOSH AK, 2003, P 5 INT C ADV PATT R, P89
   Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596
   GODTLIEBSEN F, 1991, J MAGN RESON, V92, P102, DOI 10.1016/0022-2364(91)90251-N
   GODTLIEBSEN F, 2003, SPATIAL CLUSTER MODE, P23
   GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985
   Hastie T., 1990, Generalized additive model
   HELMAN J, 1989, COMPUTER, V22, P27, DOI 10.1109/2.35197
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   KIM CS, 1999, UNPUB SIZER JUMP DET
   Koenderink JJ, 1999, LECT NOTES COMPUT SC, V1682, P1, DOI 10.1016/B978-044410031-3/50001-3
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Loser T, 1998, CHEM-ING-TECH, V70, P1382, DOI 10.1002/cite.330701105
   PARK C, 2004, UNPUB DEPENDENT SIZE
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Perona P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P16
   ROMENY BMT, 2001, FRONT END VISION MUL
   RONDONOTTI V, 2004, UNPUB SIZER TIME SER
   SIEGMUND DO, 1995, ANN STAT, V23, P608, DOI 10.1214/aos/1176324539
   ter Haar Romeny B., 1994, GEOMETRY DRIVEN DIFF
   van Ginneken B, 1999, LECT NOTES COMPUT SC, V1682, P10
   Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3
   Winkler G., 1995, IMAGE ANAL RANDOM FI
NR 31
TC 28
Z9 29
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2004
VL 22
IS 13
BP 1093
EP 1104
DI 10.1016/j.imavis.2004.05.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 862LY
UT WOS:000224493600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Di Stefano, L
   Marchionni, M
   Mattoccia, S
AF Di Stefano, L
   Marchionni, M
   Mattoccia, S
TI A fast area-based stereo matching algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE stereo; area-based; real-time; uniqueness constraint; bidirectional
   matching
AB This paper proposes an area-based stereo algorithm suitable to real time applications. The core of the algorithm relies on the uniqueness constraint and on a matching process that rejects previous matches as soon as more reliable ones are found. The proposed approach is also compared with bidirectional matching (BM), since the latter is the basic method for detecting unreliable matches in most area-based stereo algorithms. We describe the algorithm's matching core, the additional constraints introduced to improve the reliability and the computational optimizations carried out to achieve a very fast implementation. We provide a large set of experimental results, obtained on a standard set of images with ground-truth as well as on stereo sequences, and computation time measurements. These data are used to evaluate the proposed algorithm and compare it with a well-known algorithm based on BM. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Bologna, Dept Elect Comp Sci & Syst, I-40136 Bologna, Italy.
   Adv Res Ctr, Elect Syst Informat & Commun Technol Ercole Castr, I-40135 Bologna, Italy.
C3 University of Bologna
RP Univ Bologna, Dept Elect Comp Sci & Syst, Viale Risorgimento 2, I-40136 Bologna, Italy.
EM ldistefano@deis.unibo.it; mmarchionni@litio.it; smattoccia@deis.unibo.it
RI Mattoccia, Stefano/AAV-6931-2021; Mattoccia, Stefano/C-5410-2018
OI Mattoccia, Stefano/0000-0002-3681-7704; Mattoccia,
   Stefano/0000-0002-3681-7704
CR [Anonymous], 2001, P INT C COMP VIS
   Di Stefano L, 2000, 5TH INTERNATIONAL WORKSHOP ON COMPUTER ARCHITECTURES FOR MACHINE PERCEPTION, PROCEEDINGS, P356, DOI 10.1109/CAMP.2000.875995
   DISTEFANO L, EXPT RES
   Egnal G, 2000, PROC CVPR IEEE, P466, DOI 10.1109/CVPR.2000.854883
   FAUGERAS O, 1993, 2013 INRIA
   Fua P., 1991, P 12 INT JOINT C ART, P1292
   Fusiello A, 2000, INT J PATTERN RECOGN, V14, P1053, DOI 10.1142/S0218001400000696
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   Hirschmüller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407
   KANADE T, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P95, DOI 10.1109/IROS.1995.525868
   Konolige Kurt., 1997, Eighth International Symposium on Robotics Research, P111
   Lee RB, 1997, SIPS 97 - 1997 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS: DESIGN AND IMPLEMENTATION, P9, DOI 10.1109/SIPS.1997.625683
   Mühlmann K, 2002, INT J COMPUT VISION, V47, P79, DOI 10.1023/A:1014581421794
   Okutomi M, 2002, INT J COMPUT VISION, V47, P261, DOI 10.1023/A:1014510328154
   Peleg A, 1996, IEEE MICRO, V16, P42, DOI 10.1109/40.526924
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   SHREEKANT T, 2000, IEEE MICRO, V20, P47
   SUN C, 1997, P DIG IM COMP TECHN, P95
   Trucco E., 1998, INTRO TECHNIQUES 3D
   van der Wal G., 2001, P 5 INT WORKSHOP COM, P31
   Zabih R., 1994, P ECCV, P151
NR 21
TC 166
Z9 201
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 983
EP 1005
DI 10.1016/j.imavis.2004.03.009
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800006
DA 2024-07-18
ER

PT J
AU Bartolini, F
   Carfagni, M
   Governi, L
AF Bartolini, F
   Carfagni, M
   Governi, L
TI Model-based extraction of femoral medulla ducts from radiographic images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE model-based image processing; medical images processing; surgery aiding
   tools
AB The planning of the hip prosthesis surgical operation is usually performed manually by the surgeon, who 'draws' on a patient's X-ray image the outline of the prosthetic stem in order to choose the one most suitable for the case at hand. In an attempt to give some repeatability and objectivity to the planning phase, a procedure has been devised for hip prosthesis' stem selection based on the extraction of the femoral relevant outlines.
   This work presents a computer aided method aimed at automatically extracting the medulla duct outlines from a human femur radiographic image. The outlines are retrieved by referring to a suitable geometric model of the generic femoral cross-section; the projection function obtained by simulating the radiographic acquisition of such a model is fitted on the grey-level functions corresponding to the rows of the actual digitised radiographic image by means of a least squares algorithm. The resulting outlines are used in a software tool performing the hip prosthesis pre-operational planning. (C) 2003 Published by Elsevier B.V.
C1 Univ Florence, Dipartimento Meccan & Tecnol Ind, I-50139 Florence, Italy.
   Univ Florence, Dipartimento Elettron & Telecommunicaz, I-50139 Florence, Italy.
C3 University of Florence; University of Florence
RP Univ Florence, Dipartimento Meccan & Tecnol Ind, Via Santa Marta 3, I-50139 Florence, Italy.
EM lapo.governi@unifi.it
RI Governi, Lapo/D-7150-2012
OI Governi, Lapo/0000-0002-7417-3487; Carfagni, Monica/0000-0002-3393-7014
CR Bongini D, 2000, COMPUT METH PROG BIO, V63, P105, DOI 10.1016/S0169-2607(00)00078-X
   DAVIES ER, 1990, MACH VISION THEORY A
   Gonzales R., 1992, DIGITAL IMAGE PROCES
   PENG TT, 2002, THESIS NAT U SINGAPO
   Press W.H., 1993, NUMERICAL RECIPIES C
   Russ J.C., 1992, The Image Processing Handbook
   SAXENA R, 2002, J REHABILITATION RES, V39
NR 7
TC 4
Z9 4
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2004
VL 22
IS 3
BP 173
EP 182
DI 10.1016/S0262-8856(03)00118-5
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 776RH
UT WOS:000189130100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dowdall, J
   Pavlidis, I
   Bebis, G
AF Dowdall, J
   Pavlidis, I
   Bebis, G
TI Face detection in the near-IR spectrum
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT IEEE Workshop in Computer Vision Beyond the Visible Spectrum
CY DEC 14, 2001
CL KAUAI, HI
SP IEEE
DE < near-IR phenomenology; face detection; integral projection
AB Face detection is an important prerequisite step for successful face recognition. The performance of Previous face detection methods reported in the literature is far from perfect and deteriorates ungracefully where lighting conditions cannot be controlled. We propose a method that outperforms state-of-the-art face detection methods in environments with stable lighting. In addition, our method can potentially perform well in environments with variable lighting conditions. The approach capitalizes upon our near-IR skin detection method reported elsewhere [Proceedings IEEE Workshop on Computer Vision beyond the Visible Spectrum: Methods and Applications; 2000, IEEE Trans. Int. Trans. Sys.: vol. 1: 72-85]. It ascertains the existence of a face within the skin region by finding the eyes and eyebrows. The eye-eyebrow pairs are determined by extracting appropriate features from multiple near-IR bands. Very successful feature extraction is achieved by simple algorithmic means like integral projections and template matching. This is because processing is constrained in the skin region and aided by the near-IR phenomenology. The effectiveness of our method is substantiated by comparative experimental results with the Identix face detector [http://www.faceit.com]. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Houston, Dept Comp Sci, Visual Comp Lab, Houston, TX 77204 USA.
   Univ Nevada, Dept Comp Sci, Comp Vis Lab, Reno, NV 89557 USA.
C3 University of Houston System; University of Houston; Nevada System of
   Higher Education (NSHE); University of Nevada Reno
RP Univ Houston, Dept Comp Sci, Visual Comp Lab, Houston, TX 77204 USA.
EM joathan_dowdall@yahoo.com; pavlidis@cs.uh.edu; bebis@cs.unr.edu
RI Pavlidis, Ioannis/AAH-3817-2019
OI Pavlidis, Ioannis/0000-0001-8025-2600
CR Bebis G., 2000, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V9, P225, DOI 10.1142/S0218213000000161
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Huang WM, 2000, J INORG MATER, V15, P722
   Jeon BH, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1149, DOI 10.1109/ICME.2000.871564
   Kanade T., 1973, Picture processing by computer complex and recognition of human faces
   Kawato S, 2000, IEEE SYS MAN CYBERN, P1366, DOI 10.1109/ICSMC.2000.886044
   KIM SH, 2000, P 4 IEEE INT C AUT F, P14
   LI Y, 2000, P 4 INT C KNOWL BAS, V1, P241
   LV X, 2000, P IEEE C COMP VIS PA, V1, P760
   Morimoto C. H., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P8, DOI 10.1109/AFGR.2000.840605
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pavlidis I., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P72, DOI 10.1109/TITS.2000.880964
   Pavlidis I, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P15, DOI 10.1109/CVBVS.2000.855246
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   SINLEY D, 1997, OPTICS PHOTONICS NEW, V32, P32
   Sobottka K, 1998, SIGNAL PROCESS-IMAGE, V12, P263, DOI 10.1016/S0923-5965(97)00042-8
   Wilder J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P182, DOI 10.1109/AFGR.1996.557262
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhu Y, 2000, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2000.855879
NR 19
TC 73
Z9 93
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2003
VL 21
IS 7
BP 565
EP 578
DI 10.1016/S0262-8856(03)00055-6
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 706FR
UT WOS:000184443400002
DA 2024-07-18
ER

PT J
AU Kambhamettu, C
   Goldgof, D
   He, M
   Laskov, P
AF Kambhamettu, C
   Goldgof, D
   He, M
   Laskov, P
TI 3D nonrigid motion analysis under small deformations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D motion analysis; nonrigid motion; point correspondences; differential
   geometry
ID AUTOMATIC EXTRACTION; TRACKING; RECOVERY; DECOMPOSITION; PERSPECTIVE;
   SURFACE; IMAGES; MODELS; PAIR
AB We present a novel method for estimating motion parameters and point correspondences between 3D surfaces under small nonrigid motion. A vector point function is utilized as the motion parameter, called the displacement function. Differential-geometric changes of surfaces are then used in tracking small deformations. Discriminant (of first fundamental form), unit-normal and Gaussian curvature are the invariant differential-geometric parameters that have been utilized for nonrigid motion analysis.
   Tests were performed by generating nonrigid motion on a simulated data set to illustrate performance and accuracy of our algorithms. Experiments were then performed on a Cyberware range data sequence of facial motion. A total of 16 sets of facial motion images were used in our experiments, belonging to eight different persons, each having two facial expressions. We have demonstrated the correct point correspondence recovery by tracking features of the face during each facial expression and comparing against the manual tracking of feature points by different users. In addition, nonrigid motion segmentation and interpolation of intermediate frames of data were successfully performed on these images. We have also performed experiments on cardiac data in order to estimate the motion parameters related to the abnormality in cardiac motion. Two sets of volumetric CT data of the left ventricle of a dog's heart in cardiac cycle were used in our experiments. All our experiments indicate that the system performs very well and proves to be extremely useful in other nonrigid motion analysis applications. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Univ Delaware, Dept Comp & Informat Sci, Video Image Modeling & Synth Lab, Newark, DE 19716 USA.
   Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.
   Nova SE Univ, Dept Math Sci & Technol, Ft Lauderdale, FL 33314 USA.
   Fraunhofer Inst FIRST IDA, D-12489 Berlin, Germany.
C3 University of Delaware; State University System of Florida; University
   of South Florida; Nova Southeastern University; Fraunhofer Gesellschaft
RP Univ Delaware, Dept Comp & Informat Sci, Video Image Modeling & Synth Lab, Newark, DE 19716 USA.
EM chandra@cis.udel.edu; goldgof@csee.usf.edu; hem@nova.edu;
   laskov@first.fhg.de
RI Goldgof, Dmitry/ABF-1366-2020
OI Laskov, Pavel/0000-0002-3212-7167
CR AGGARWAL JK, 1994, P IEEE COMP SOC WORK, P16
   Akgul YS, 1998, PROC CVPR IEEE, P298, DOI 10.1109/CVPR.1998.698623
   Akgul YS, 1999, IEEE T MED IMAGING, V18, P1035, DOI 10.1109/42.811315
   Amini A. A., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P294, DOI 10.1109/WVM.1991.212772
   AMINI AA, 1992, IMAGE VISION COMPUT, V10, P418, DOI 10.1016/0262-8856(92)90027-Z
   [Anonymous], BRIT MACH VIS C SEPT
   [Anonymous], HDB PATERN RECOGNITI
   [Anonymous], 2001, THESIS U DELAWARE
   ASADA M, 1984, PATTERN RECOGN, V17, P57, DOI 10.1016/0031-3203(84)90035-9
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   BREGLER C, 2000, P IEEE COMP SOC C CO
   Bruno B., 1992, Proceedings of the 5th Florida Artificial Intelligence Research Symposium, P247
   CHEN S, 1988, ADV COMPUTER VISION, V3, P179
   COHEN I, 1992, LECT NOTES COMPUT SC, V588, P458
   COHEN I, 1992, COMPUTER VISION GRAP, V56, P42
   DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811
   DeCarlo D, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P113, DOI 10.1109/ICCV.1998.710708
   DEVERNAY F, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P208, DOI 10.1109/CVPR.1994.323831
   Flynn P. J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P110, DOI 10.1109/CVPR.1989.37837
   Goldgof D. B., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P375, DOI 10.1109/CVPR.1988.196262
   GOLDGOF DB, 1989, THESIS U ILLINOIS UR
   Holt RJ, 1997, PATTERN RECOGN, V30, P1435, DOI 10.1016/S0031-3203(96)00179-3
   Huang T. S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P361, DOI 10.1109/ICPR.1990.118129
   Jain R., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P83
   KAMBHAMETTU C, 1994, CVGIP-IMAG UNDERSTAN, V60, P26, DOI 10.1006/ciun.1994.1029
   Kambhamettu C., 1993, Proceedings of IEEE Workshop on Qualitative Vision (Cat. No.93TH0521-5), P118, DOI 10.1109/WQV.1993.262943
   KAMBHAMETTU C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P943, DOI 10.1109/CVPR.1994.323930
   Kambhamettu C., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P222, DOI 10.1109/CVPR.1992.223271
   KAMBHAMETTU C, 1991, SCAND C IM AN, P1126
   KAMBHAMETTU CS, 1994, THESIS U S FLORIDA
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KOENDERINK JJ, 1986, J OPT SOC AM A, V3, P242, DOI 10.1364/JOSAA.3.000242
   KREYSZIG E, 1959, DIFFERENTIAL GEOMETR
   LASKOV P, 2002, ACCV, V1, P19
   Lin M. H., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P648, DOI 10.1109/ICCV.1999.791286
   Metaxas D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P337, DOI 10.1109/CVPR.1991.139712
   METAXAS D, 1993, IEEE T PATTERN ANAL, P15
   Mishra S. K., 1992, International Journal of Imaging Systems and Technology, V4, P214, DOI 10.1002/ima.1850040308
   Pentland A., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P288, DOI 10.1109/WVM.1991.212773
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661
   PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812
   ROBB RA, 1983, P IEEE, V71, P308, DOI 10.1109/PROC.1983.12589
   Sabata B, 1996, COMPUT VIS IMAGE UND, V63, P232, DOI 10.1006/cviu.1996.0017
   SABATA B, 1991, CVGIP-IMAG UNDERSTAN, V54, P309, DOI 10.1016/1049-9660(91)90032-K
   SHULMAN D, 1988, PROC R SOC SER B-BIO, V233, P217, DOI 10.1098/rspb.1988.0020
   Srinark T, 2001, PROC CVPR IEEE, P202
   Szeliski R, 1996, INT J COMPUT VISION, V18, P171, DOI 10.1007/BF00055001
   Terzopoulos D., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P606, DOI 10.1109/ICCV.1990.139605
   Terzopoulos D., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P727, DOI 10.1109/ICCV.1990.139628
   TORRESANI L, 2001, P IEEE COMP SOC C CO
   TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471
   ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255
   Weatherburn C.E., 1927, Differential Geometry of Three Dimensions
   WEATHERBURN CE, 1930, DIFFERENTIAL GEOMETR, V2
   WEATHERBURN CE, 1925, Q J MATH, V50, P272
   XIE X, 1994, PATTERN RECOGN, V27, P791, DOI 10.1016/0031-3203(94)90164-3
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhang J, 2001, T NONFERR METAL SOC, V11, P778
   Zhang Y, 2002, PATTERN RECOGN, V35, P1545, DOI 10.1016/S0031-3203(01)00140-6
   ZHANG Y, 2001, THESIS U DELAWARE
   Zhou L, 2001, IEEE T PATTERN ANAL, V23, P1330, DOI 10.1109/34.969121
   Zhou L, 2000, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2000.854950
   ZHOU L, 1999, GRAPH MODEL IM PROC, V63, P1
   ZHOU L, 2000, THESIS U DELAWARE
   Zhou M, 1999, SHOCK, V11, P73, DOI 10.1097/00024382-199901000-00013
NR 65
TC 21
Z9 22
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2003
VL 21
IS 3
BP 229
EP 245
AR PII S0262-8856(02)00041-0
DI 10.1016/S0262-8856(02)00041-0
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657GN
UT WOS:000181658100001
DA 2024-07-18
ER

PT J
AU Zhou, SR
   Lei, NF
   Zhou, JR
   Xiong, JS
   Zhang, JM
AF Zhou, Shuren
   Lei, Nanfang
   Zhou, Jiarui
   Xiong, Jiasi
   Zhang, Jianming
TI The triple refinement of self-paced learning style for unsupervised
   cross-domain person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Self-paced learning; Data refinement; Person re-identification; Mutually
   learning models
AB Unsupervised cross-domain person re-identification based on clustering typically involves generating pseudo -labels for all training data. However, some data are prone to generating incorrect pseudo-labels in the early stages of training, which leads to a decrease in the accuracy of the model. Based on the idea of self-paced learning, from easy to difficult and from a few to many samples, we propose the Triple Refinement of Self -paced Learning style (TRSL) method to solve this problem. Firstly, we use the density-based clustering algo-rithm DBSCAN to perform the first data refinement on the unlabeled data. Then, in the second refinement step, we calculate the challenge value by exploring the distance distribution between the clustering data and the centroids to refine the data. In the third refinement step, we calculate the credibility value of the data by comparing the k-nearest neighbor ranking lists of the local and global features of the images, use the credibility value to recall the discarded data from the dual refinement process, and perform a third filtering on the retained data. Finally, the processed data is input into a pair of mutually beneficial learning models for training. On top of a strong baseline, our method performs better than the recent state-of-the-art methods in some evaluation metrics.
C1 [Zhou, Shuren; Lei, Nanfang; Zhou, Jiarui; Xiong, Jiasi; Zhang, Jianming] Changsha Univ Sci & Technol, Changsha, Peoples R China.
C3 Changsha University of Science & Technology
RP Zhou, SR (corresponding author), Changsha Univ Sci & Technol, Changsha, Peoples R China.
EM zsr_hn@163.com
RI Zhang, Jianming/AAD-1000-2019
OI Zhang, Jianming/0000-0002-4278-0805; zhou, shuren/0000-0002-0465-3258;
   Zhou, Jiarui/0009-0009-5396-6988
FU Education Reform Project of Hunan Province of China [2020JGZD043]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61972056, in part by the Hunan
   Provincial Natural Science Foundation of China under Grant 2021JJ30743
   and 2022JJ30622, in part by the Degree & Post-graduater Education Reform
   Project of Hunan Province of China under Grant 2020JGZD043. References
CR Cho Y, 2022, PROC CVPR IEEE, P7298, DOI 10.1109/CVPR52688.2022.00716
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Ge Y., 2020, P NIPS, V33, P11309
   Ge YX, 2020, Arxiv, DOI [arXiv:2001.01526, 10.48550/arXiv.2001.01526]
   Ge YX, 2024, IEEE T NEUR NET LEAR, V35, P258, DOI 10.1109/TNNLS.2022.3173489
   Gu XQ, 2022, PROC CVPR IEEE, P1050, DOI 10.1109/CVPR52688.2022.00113
   Guo JY, 2019, IEEE I CONF COMP VIS, P3641, DOI 10.1109/ICCV.2019.00374
   Guo S, 2018, LECT NOTES COMPUT SC, V11214, P139, DOI 10.1007/978-3-030-01249-6_9
   Han J, 2022, AAAI CONF ARTIF INTE, P790
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2022, AAAI CONF ARTIF INTE, P879
   He TY, 2021, PROC CVPR IEEE, P9101, DOI 10.1109/CVPR46437.2021.00899
   Kumar M, 2010, Advances in Neural Information Processing Systems, V23
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Liu XB, 2021, Arxiv, DOI arXiv:2105.04776
   Lu J, 2018, PR MACH LEARN RES, V80
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Peng K, 2018, IEEE ACCESS, V6, P11897, DOI 10.1109/ACCESS.2018.2810267
   Tarvainen A, 2017, ADV NEUR IN, V30
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang HC, 2022, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR52688.2022.00715
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang WH, 2022, IEEE T IMAGE PROCESS, V31, P1532, DOI 10.1109/TIP.2022.3140614
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xu TK, 2022, Arxiv, DOI arXiv:2109.06165
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yang Zou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P87, DOI 10.1007/978-3-030-58536-5_6
   Yixiao Ge, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P369, DOI 10.1007/978-3-030-58548-8_22
   Yukun Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14072, DOI 10.1109/CVPR42600.2020.01409
   Yunpeng Zhai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9018, DOI 10.1109/CVPR42600.2020.00904
   Zhai Y, 2020, COMPUTER VISION ECCV, P594, DOI DOI 10.1007/978-3-030-58571-6_35
   Zhang MY, 2021, AAAI CONF ARTIF INTE, V35, P3360
   Zhang X, 2021, PROC CVPR IEEE, P3435, DOI 10.1109/CVPR46437.2021.00344
   Zhang XY, 2022, PROC CVPR IEEE, P7359, DOI 10.1109/CVPR52688.2022.00722
   Zhang Z, 2021, PROC CVPR IEEE, P12131, DOI 10.1109/CVPR46437.2021.01196
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng KC, 2021, AAAI CONF ARTIF INTE, V35, P3538
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou ZP, 2015, CHIN CONT DECIS CONF, P5552, DOI 10.1109/CCDC.2015.7161787
NR 45
TC 0
Z9 0
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104870
DI 10.1016/j.imavis.2023.104870
EA NOV 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DB9H2
UT WOS:001129684800001
DA 2024-07-18
ER

PT J
AU Liu, X
   Tang, H
AF Liu, Xing
   Tang, Hao
TI STRFormer: Spatial-Temporal-ReTemporal Transformer for 3D human pose
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D human pose estimation; Spatial-temporal-ReTemporal; Transformer;
   Reverse temporal encoder; MPJAE loss
AB Transformer-based methods have emerged as the golden standard in 2D-3D human pose estimation from video sequences, largely thanks to their powerful spatial-temporal feature encoders. In the past, researchers have made concerted efforts to engineer spatial and temporal encoders using transformer blocks. This approach involved a dramatic reshaping of the input, transforming it from mere joint information to dynamic joint trajectories. Despite this, the inherent limitations of the spatial-temporal structure have resulted in an inadequate acquisition and subsequent utilization of temporal information. In an attempt to rectify this prevalent issue, our paper proposes a new model, dubbed Spatial-Temporal-ReTemporal Transformer (i.e., STRFormer). This model ingeniously employs two separate temporal transformer blocks to extract the essential temporal motion information from video sequences. Intriguingly, one temporal transformer block is dedicated to the original video sequence, while the other concerns itself with the reversed order video. This novel approach allows for a more thorough investigation and utilization of temporal information from the video sequences. In order to alternate the processing of these two blocks effectively with the spatial block, we focus on maximizing the extraction of temporal domain information. This method leads to a more comprehensive understanding of the pose estimation and its evolution over time. Furthermore, we introduce a novel error metric, Mean Per-Joint Position Acceleration Error (i.e., MPJAE). This advanced metric takes into account the body part velocity in adjacent predicted frames, allowing for a more detailed evaluation of the predicted poses. We conduct extensive experiments on various open benchmarks to evaluate the effectiveness of our proposed model. The results demonstrate that our STRFormer, coupled with the MPJAE loss, achieves highly competitive results when compared with other stateof-the-art models. This illustrates its promising potential and practical applicability in 2D-3D human pose estimation tasks. We plan to release our code publicly for further research.
C1 [Liu, Xing] Tongji Univ, Coll Elect & Informat Engn, Shanghai 201804, Peoples R China.
   [Tang, Hao] Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland.
C3 Tongji University; Swiss Federal Institutes of Technology Domain; ETH
   Zurich
RP Tang, H (corresponding author), Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland.
EM liuxing@sz.pku.edu.cn; hao.tang@vision.ee.ethz.ch
FU National Natural Science Foundation of China [62272345]
FX <B>Acknowledgments</B> This work is supported by National Natural
   Science Foundation of China (No.62272345) .
CR Ailing Zeng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P507, DOI 10.1007/978-3-030-58568-6_30
   Bai GH, 2023, IMAGE VISION COMPUT, V132, DOI 10.1016/j.imavis.2023.104649
   Baniata LH, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10193666
   Cai JL, 2023, Arxiv, DOI arXiv:2302.09790
   Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen TL, 2022, IEEE T CIRC SYST VID, V32, P198, DOI 10.1109/TCSVT.2021.3057267
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Ci H, 2019, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2019.00235
   Dai L., 2022, IEEE TCSVT, P3
   Difini GM, 2021, PROCEEDINGS OF THE 27TH BRAZILIAN SYMPOSIUM ON MULTIMEDIA AND THE WEB (WEBMEDIA '21), P189, DOI 10.1145/3470482.3479633
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Errity A., 2016, An Introduction to Cyberpsychology, P263
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Gong J, 2023, Arxiv, DOI arXiv:2211.16940
   Gong KH, 2021, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR46437.2021.00847
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Holmquist Karl, 2022, arXiv preprint arXiv:2211.16487
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Huang ZY, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON UNIVERSAL VILLAGE (IEEE UV 2018)
   Ionescu C., 2013, IEEE Trans. Pattern Anal. Mach. Intell., V36, P5
   Jingbo Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P764, DOI 10.1007/978-3-030-58601-0_45
   Kipf T.N., 2017, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Li C, 2020, Arxiv, DOI arXiv:2008.05770
   Li S., 2014, Revised Selected Papers, P2
   Li SC, 2020, PROC CVPR IEEE, P6172, DOI 10.1109/CVPR42600.2020.00621
   Li WH, 2023, IEEE T MULTIMEDIA, V25, P1282, DOI 10.1109/TMM.2022.3141231
   Li WH, 2023, PATTERN RECOGN, V141, DOI 10.1016/j.patcog.2023.109631
   Li WH, 2022, PROC CVPR IEEE, P13137, DOI 10.1109/CVPR52688.2022.01280
   Lin J., 2019, arXiv
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Lin LL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2490, DOI 10.1145/3394171.3413548
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu RX, 2020, PROC CVPR IEEE, P5063, DOI 10.1109/CVPR42600.2020.00511
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Ma XX, 2021, PROC CVPR IEEE, P6234, DOI 10.1109/CVPR46437.2021.00617
   Martinez Julieta, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2659, DOI 10.1109/ICCV.2017.288
   Mazzia V, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108487
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Qiu ZW, 2023, PATTERN RECOGN, V139, DOI 10.1016/j.patcog.2023.109497
   Shen LZ, 2023, MEAS SCI TECHNOL, V34, DOI 10.1088/1361-6501/acb075
   Shen X., 2023, IJCAI, P3
   Stojanovic V, 2014, CIRC SYST SIGNAL PR, V33, P97, DOI 10.1007/s00034-013-9633-0
   Tang H., 2023, CVPR, P3
   Tang H., 2023, TMM, P3
   Tao HF, 2022, MEAS SCI TECHNOL, V33, DOI 10.1088/1361-6501/ac8368
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wehrbein T., 2021, ICCV, P11199
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Yang GL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16249, DOI 10.1109/ICCV48922.2021.01596
   Yeh RA, 2019, ADV NEUR IN, V32
   Yuan YH, 2021, Arxiv, DOI arXiv:1909.11065
   Zeng AL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11416, DOI 10.1109/ICCV48922.2021.01124
   Zhang C, 2022, PROC CVPR IEEE, P14011, DOI 10.1109/CVPR52688.2022.01364
   Zhang JL, 2022, PROC CVPR IEEE, P13222, DOI 10.1109/CVPR52688.2022.01288
   Zhang Y., 2023, IEEE Internet Things J., V2, P3
   Zhao M., 2023, ACM Transactions on Multimedia Computing, Communications and Applications, P3
   Zhao QT, 2023, PROC CVPR IEEE, P8877, DOI 10.1109/CVPR52729.2023.00857
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zhu WT, 2022, Arxiv, DOI arXiv:2210.06551
NR 65
TC 0
Z9 0
U1 9
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104863
DI 10.1016/j.imavis.2023.104863
EA NOV 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Z9BD6
UT WOS:001114944800001
DA 2024-07-18
ER

PT J
AU Hu, CY
   Shi, WW
   Tian, L
AF Hu, Chengyin
   Shi, Weiwen
   Tian, Ling
TI Adversarial color projection: A projector-based physical-world attack to
   DNNs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE DNNs; Black -box projector-based physical attack; Adversarial color
   projection; Effectiveness; Stealthiness; Robustness
AB While deep neural networks (DNNs) have made remarkable advancements in various fields recently, the latest research indicates that DNNs are susceptible to disruptions from minor perturbations. However, conventional physical attacks employing stickers as physical perturbations to deceive classifiers encounter challenges in achieving stealthiness and are susceptible to issues such as printing quality loss. Recent advancements in physical attacks have harnessed light beams to execute attacks, producing artificial optical patterns rather than natural ones. In this study, we introduce a black-box projector-based physical attack called Adversarial Color Projection (AdvCP), which manipulates the physical parameters of color projection to execute adversarial attacks. AdvCP revolves around three pivotal criteria: effectiveness, stealthiness, and robustness. In a digital environment, our approach attains an impressive attack success rate of 97.60% on a subset of ImageNet.In the physical realm, we achieve a remarkable 100% attack success rate in indoor testing and 82.14% in outdoor testing. To underscore the stealthiness of our approach, we juxtapose the adversarial samples generated by AdvCP with baseline samples. When applied to challenge advanced and robust DNNs, our experimental results reveal that our method achieves an attack success rate exceeding 85% across most all of the models, establishing the robustness of AdvCP. Finally, we contemplate the potential threats posed by AdvCP to future vision-based systems and applications, and proffer some innovative concepts pertaining to light-based physical attacks. Our code can be accessed from the following link: https://github.com/ChengYinHu/AdvCP.git
C1 [Hu, Chengyin; Shi, Weiwen; Tian, Ling] Univ Elect Sci & Technol China, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Tian, L (corresponding author), Univ Elect Sci & Technol China, Chengdu 611731, Sichuan, Peoples R China.
EM lingtian@uestc.edu.cn
RI Hu, Chengyin/KCK-2616-2024
OI Hu, Chengyin/0009-0006-9589-0182; shi, weiwen/0009-0007-3574-8261
FU Fundamental Research Funds for the Central Universities [ZYGX2020ZB034]
FX This work was supported by Fundamental Research Funds for the Central
   Universities (No. ZYGX2020ZB034 and No.ZYGX2021J019) .
CR Athalye A, 2018, PR MACH LEARN RES, V80
   Bonnet B, 2022, IEEE T INF FOREN SEC, V17, P373, DOI 10.1109/TIFS.2021.3138616
   Chen ST, 2019, LECT NOTES ARTIF INT, V11051, P52, DOI 10.1007/978-3-030-10925-7_4
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Nguyen DL, 2020, IEEE COMPUT SOC CONF, P3548, DOI 10.1109/CVPRW50498.2020.00415
   Doan BG, 2022, IEEE T INF FOREN SEC, V17, P3816, DOI 10.1109/TIFS.2022.3198857
   Dong YP, 2022, IEEE T PATTERN ANAL, V44, P9536, DOI 10.1109/TPAMI.2021.3126733
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Duan RJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7486, DOI 10.1109/ICCV48922.2021.00741
   Duan RJ, 2021, PROC CVPR IEEE, P16057, DOI 10.1109/CVPR46437.2021.01580
   Duan RJ, 2020, PROC CVPR IEEE, P997, DOI 10.1109/CVPR42600.2020.00108
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Fang ML, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104057
   Fang YX, 2023, PROC CVPR IEEE, P19358, DOI 10.1109/CVPR52729.2023.01855
   Feng SY, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534119
   Gnanasambandam A, 2021, IEEE INT CONF COMP V, P92, DOI 10.1109/ICCVW54120.2021.00016
   Guesmi A, 2023, Arxiv, DOI arXiv:2303.01338
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu C., 2023, PMLR, P483
   Hu ZH, 2022, PROC CVPR IEEE, P13297, DOI 10.1109/CVPR52688.2022.01295
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang SZ, 2021, COMPUT SECUR, V104, DOI 10.1016/j.cose.2020.102120
   Jia S, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.11.004
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2016, WORKSHOP TRACK P
   Li C, 2023, APPL SOFT COMPUT, V142, DOI 10.1016/j.asoc.2023.110370
   Li C, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.108979
   Li JCB, 2019, PR MACH LEARN RES, V97
   Li Q, 2021, IEEE T INF FOREN SEC, V16, P2447, DOI 10.1109/TIFS.2020.3047752
   Liu H, 2019, INT C LEARNING REPRE, DOI DOI 10.1109/CVPR42600.2020.00243
   Liu JY, 2023, Arxiv, DOI arXiv:2302.14267
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lovisotto G, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1865
   Meng Shen, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351261
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sayles A, 2021, PROC CVPR IEEE, P14661, DOI 10.1109/CVPR46437.2021.01443
   Shamsabadi AS, 2020, PROC CVPR IEEE, P1148, DOI 10.1109/CVPR42600.2020.00123
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song D., 2018, 12 USENIX WORKSH OFF
   Suryanto N, 2022, PROC CVPR IEEE, P15284, DOI 10.1109/CVPR52688.2022.01487
   Szegedy C, 2014, INT C LEARN REPR
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang DH, 2022, AAAI CONF ARTIF INTE, P2414
   Wei H., 2023, P AAAI C ARTIFICIAL, V37, P15233
   Wei XX, 2023, IEEE T PATTERN ANAL, V45, P2711, DOI 10.1109/TPAMI.2022.3176760
   Zeng XH, 2019, PROC CVPR IEEE, P4297, DOI 10.1109/CVPR.2019.00443
   Zhai L., 2020, arXiv
   Zhang YG, 2020, IEEE T IMAGE PROCESS, V29, P4804, DOI 10.1109/TIP.2020.2975918
   Zhang Y, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109435
   Zhao ZY, 2020, PROC CVPR IEEE, P1036, DOI 10.1109/CVPR42600.2020.00112
   Zheng X, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.109009
   Zhong YQ, 2022, PROC CVPR IEEE, P15324, DOI 10.1109/CVPR52688.2022.01491
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou Z, 2018, Arxiv, DOI arXiv:1803.04683
NR 58
TC 2
Z9 2
U1 6
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104861
DI 10.1016/j.imavis.2023.104861
EA NOV 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Z2BD2
UT WOS:001110174800001
DA 2024-07-18
ER

PT J
AU Chen, L
   Liu, Q
AF Chen, Lu
   Liu, Qiong
TI Relation-balanced graph convolutional network for 3D human pose
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D human pose estimation; Graph convolutional network; Relation
   modeling; Feature fusion
AB Graph convolutional networks (GCNs) have been applied to 2D-to-3D human pose estimation (HPE) and have shown encouraging performance. However, existing GCNs model the relations between joints via individual kernels, which can be overly flexible and fail to capture common relational patterns due to the symmetric nature of the human body. Although some GCNs share kernels to capture common relations, the unified way for all neighbors limits relational diversity to some extent. In order to balance the diversity and commonality of relations, we conduct a comprehensive study of existing kernel-sharing strategies and propose a Relation-balanced Graph Convolutional Network (RbGC-Net). RbGC-Net introduces the Part-Specific Kernel-Sharing strategy (PSKS) that assigns kernels based on the semantic meanings of neighbors to establish specific relational patterns for different types of neighborhoods. Furthermore, RbGC-Net incorporates a Local-Global Feature Fusion module (LGFF) that extracts the local relations among joints and balances them with the final global relations to improve the interactions between joints. Compared with state-of-the-art methods for 3D HPE, our RbGC-Net achieves the optimal balance between model size and estimation errors. Results on two benchmark Human3.6 M and MPIINF-3DHP datasets demonstrate the excellent performance and strong generalization ability of our pure GCNbased method.
C1 [Chen, Lu; Liu, Qiong] South China Univ Technol, Sch Software Engn, Guangzhou 510006, Peoples R China.
C3 South China University of Technology
RP Liu, Q (corresponding author), South China Univ Technol, Sch Software Engn, Guangzhou 510006, Peoples R China.
EM 202121046655@mail.scut.edu.cn; liuqiong@scut.edu.cn
FU Guangdong Basic and Applied Basic Research Foundation [2021A1515011349]
FX This work was supported by the Guangdong Basic and Applied Basic
   Research Foundation (No. 2021A1515011349) .
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Ailing Zeng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P507, DOI 10.1007/978-3-030-58568-6_30
   Bai GH, 2023, IMAGE VISION COMPUT, V132, DOI 10.1016/j.imavis.2023.104649
   Bai GH, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104452
   Ben Gamra M, 2021, IMAGE VISION COMPUT, V114, DOI 10.1016/j.imavis.2021.104282
   Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chen YX, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107321
   Ci H, 2019, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2019.00235
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Gan J, 2019, NEURAL COMPUT APPL, V31, P3155, DOI 10.1007/s00521-017-3260-9
   Han CC, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108934
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Ionescu C, 2011, IEEE I CONF COMP VIS, P2220, DOI 10.1109/ICCV.2011.6126500
   Jiang SY, 2021, IEEE COMPUT SOC CONF, P3408, DOI 10.1109/CVPRW53098.2021.00380
   Kenkun Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P318, DOI 10.1007/978-3-030-58607-2_19
   Lee J.Y., 2022, 33 BRIT MACH VIS C 2
   Levie R, 2019, IEEE T SIGNAL PROCES, V67, P97, DOI 10.1109/TSP.2018.2879624
   Li H, 2023, Arxiv, DOI arXiv:2111.11927
   Li H, 2023, Arxiv, DOI [arXiv:2302.07408, 10.1609/aaai.v37i1.25213, DOI 10.1609/AAAI.V37I1.25213]
   Li WH, 2022, Arxiv, DOI arXiv:2206.06420
   Lin HX, 2023, Arxiv, DOI arXiv:2210.04216
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu K., 2020, PROC IEEE ASIAN C CO, P89
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Ning GH, 2020, IEEE COMPUT SOC CONF, P4456, DOI 10.1109/CVPRW50498.2020.00525
   Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139
   Shan WK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3446, DOI 10.1145/3474085.3475504
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Wang JB, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103225
   Wang J, 2019, IEEE I CONF COMP VIS, P7770, DOI 10.1109/ICCV.2019.00786
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Zerui Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P715, DOI 10.1007/978-3-030-58580-8_42
   Zhang DJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10182267
   Zhang Z., 2022, Group Graph Convolutional Networks for 3d Human Pose Estimation
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zhao WX, 2022, PROC CVPR IEEE, P20406, DOI 10.1109/CVPR52688.2022.01979
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
   Zou Z, 2020, BMVC
   Zou ZM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11457, DOI 10.1109/ICCV48922.2021.01128
NR 49
TC 0
Z9 0
U1 5
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104841
DI 10.1016/j.imavis.2023.104841
EA OCT 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA X9KO3
UT WOS:001101559400001
DA 2024-07-18
ER

PT J
AU Tiwari, H
   Kurmi, VK
   Subramanian, VK
   Chen, YS
AF Tiwari, Hitika
   Kurmi, Vinod K.
   Subramanian, Venkatesh K.
   Chen, Yong Sheng
TI Distilling knowledge for occlusion robust monocular 3D face
   reconstruction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face reconstruction; Occlusion robustness; Knowledge distillation;
   Distillation Assisted Mono Image Occlusion; Robustification; Duplicate
   Images Assisted Multi Occlusions
AB Recently, there have been significant advancements in the 3D face reconstruction field, largely driven by monocular image-based deep learning methods. However, these methods still face challenges in reliable deployments due to their sensitivity to facial occlusions and inability to maintain identity consistency across different occlusions within the same facial image. To address these issues, we propose two frameworks: Distillation Assisted Mono Image Occlusion Robustification (DAMIOR) and Duplicate Images Assisted Multi Occlusions Robustification (DIAMOR). The DAMIOR framework leverages the knowledge from the Occlusion Frail Trainer (OFT) network to enhance robustness against facial occlusions. Our proposed method overcomes the sensitivity to occlusions and improves reconstruction accuracy. To tackle the issue of identity inconsistency, the DIAMOR framework utilizes the estimates from DAMIOR to mitigate inconsistencies in geometry and texture, collectively known as identity, of the reconstructed 3D faces. We evaluate the performance of DAMIOR on two variations of the CelebA test dataset: empirical occlusions and irrational occlusions. Furthermore, we analyze the performance of the proposed DIAMOR framework using the irrational occlusion-based variant of the CelebA test dataset. Our methods outperform state-of-the-art approaches by a significant margin. For example, DAMIOR reduces the 3D vertex-based shape error by 41.1% and the texture error by 21.8% for empirical occlusions. Besides, for facial data with irrational occlusions, DIAMOR achieves a substantial decrease in shape error by 42.5% and texture error by 30.5%. These results demonstrate the effectiveness of our proposed methods.
C1 [Tiwari, Hitika; Subramanian, Venkatesh K.] Indian Inst Technol Kanpur, Dept Elect Engn, Kanpur, India.
   [Tiwari, Hitika; Chen, Yong Sheng] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Kurmi, Vinod K.] Indian Inst Sci Educ & Res, Dept Data Sci & Engn, Bhopal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur; National Yang Ming Chiao Tung University;
   Indian Institute of Science Education & Research (IISER) - Bhopal
RP Tiwari, H (corresponding author), Indian Inst Technol Kanpur, Dept Elect Engn, Kanpur, India.
EM hitika@iitk.ac.in; vinodkk@iiserb.ac.in; venkats@iitk.ac.in;
   yschen@nycu.edu.tw
RI KURMI, VINOD K/AAY-7289-2021
CR Adjabi I, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081188
   Tran AT, 2018, PROC CVPR IEEE, P3935, DOI 10.1109/CVPR.2018.00414
   [Anonymous], 2016, BMVC
   Bas A, 2017, IEEE INT CONF COMP V, P895, DOI 10.1109/ICCVW.2017.110
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen AP, 2019, IEEE I CONF COMP VIS, P9428, DOI 10.1109/ICCV.2019.00952
   Chen D, 2016, LECT NOTES COMPUT SC, V9909, P122, DOI 10.1007/978-3-319-46454-1_8
   Deng QX, 2022, IEEE T VIS COMPUT GR, V28, P3113, DOI 10.1109/TVCG.2021.3051251
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Deng Y, 2020, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR42600.2020.00520
   Feng Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459936
   Fried O, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925933
   Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874
   Jian ZH, 2021, Arxiv, DOI arXiv:2103.14984
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kingma D, 2014, ICLR P, V2014, P1
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Lin JK, 2021, AAAI CONF ARTIF INTE, V35, P311
   Lin JK, 2020, PROC CVPR IEEE, P5890, DOI 10.1109/CVPR42600.2020.00593
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Liu Ziwei, 2018, Largescale celebfaces attributes (celeba) dataset, P11
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Pears N., 2020, 3D Imaging, Analysis and Applications, P569
   Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56
   Romdhani S, 2005, PROC CVPR IEEE, P986
   Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175
   Tewari A, 2020, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR42600.2020.00618
   Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270
   Tewari A, 2017, IEEE INT CONF COMP V, P1274, DOI 10.1109/ICCVW.2017.153
   Tiwari H., Self-supervised robustifying guidance for monocular 3d face reconstruction
   Tiwari H., 2022, VISUAL COMPUT, P1
   Tiwari H, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01257-z
   Tiwari H, 2022, IEEE IMAGE PROC, P1021, DOI 10.1109/ICIP46576.2022.9897677
   Tiwari H, 2022, IEEE IMAGE PROC, P236, DOI 10.1109/ICIP46576.2022.9897765
   Trân AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   Ye D, 2020, INT J IMAGE GRAPH, V20, DOI 10.1142/S0219467820500035
   Yuan XW, 2019, IEEE I CONF COMP VIS, P10061, DOI 10.1109/ICCV.2019.01016
NR 46
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104763
DI 10.1016/j.imavis.2023.104763
EA JUL 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Q6UM5
UT WOS:001058855800001
DA 2024-07-18
ER

PT J
AU Wang, SM
   Ma, R
   Wu, TR
   Cao, Y
AF Wang, Shuangmei
   Ma, Rui
   Wu, Tieru
   Cao, Yang
TI P3DC-shot: Prior-driven discrete data calibration for nearest-neighbor
   few-shot classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Few-shot learning; Image classification; Prototype; Calibration
ID NETWORKS
AB Nearest-Neighbor (NN) classification has been proven as a simple and effective approach for few-shot learning. The query data can be classified efficiently by finding the nearest support class based on features extracted by pre-trained deep models. However, NN-based methods are sensitive to the data distribution and may produce false prediction if the samples in the support set happen to lie around the distribution boundary of different classes. To solve this issue, we present P3DC-shot, an improved nearest-neighbor based few-shot classification method empowered by prior-driven data calibration. Inspired by the distribution calibration technique which utilizes the distribution or statistics of the base classes to calibrate the data for few-shot tasks, we propose a novel discrete data calibration operation which is more suitable for NN-based few-shot classification. Specifically, we treat the prototypes representing each base class as priors and calibrate each support data based on its similarity to different base prototypes. Then, we perform NN classification using these discretely calibrated support data. Results from extensive experiments on various datasets show our efficient non-learning based method can outperform or at least comparable to SOTA methods which need additional learning steps.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Wang, Shuangmei; Ma, Rui; Wu, Tieru; Cao, Yang] Jilin Univ, 2699 Qianjin St, Changchun 130012, Peoples R China.
   [Ma, Rui; Wu, Tieru] MOE, Engn Res Ctr Knowledge Driven Human Machine Intell, Changchun, Peoples R China.
C3 Jilin University
RP Wu, TR; Cao, Y (corresponding author), Jilin Univ, 2699 Qianjin St, Changchun 130012, Peoples R China.
EM wsm20@mails.jlu.edu.cn; ruim@jlu.edu.cn; wutr@jlu.edu.cn;
   caoyang@jlu.edu.cn
RI Ma, Rui/Y-3479-2019
OI Ma, Rui/0000-0002-3477-1466
FU National Key Research and Development Program of China [61872162];
   National Natural Science Foundation of China [62202199]; 
   [2020YFA0714103]
FX * This work is supported in part by the National Key Research and
   Development Program of China (Grant No. 2020YFA0714103) and the National
   Natural Science Foundation of China (Grant No. 61872162 and 62202199) .
CR AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Bin Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P438, DOI 10.1007/978-3-030-58548-8_26
   Cao T., 2019, INT C LEARN REPRESEN
   Chen DZ, 2017, SIAM J COMPUT, V46, P1679, DOI 10.1137/15M1044874
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen W.-Y., 2019, INT C LEARN REPRESEN
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhillon G.S., 2020, INT C LEARN REPRESEN
   Fangyu Wu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P237, DOI 10.1007/978-3-030-58604-1_15
   Finn C, 2017, PR MACH LEARN RES, V70
   Ge WF, 2017, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2017.9
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo YR, 2022, IEEE T IMAGE PROCESS, V31, P4543, DOI 10.1109/TIP.2022.3184813
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Hospedales T, 2022, IEEE T PATTERN ANAL, V44, P5149, DOI 10.1109/TPAMI.2021.3079209
   Huang G., IEEE T PATTERN ANAL
   Huang JY, 2022, INT CONF ACOUST SPEE, P1660, DOI 10.1109/ICASSP43922.2022.9747666
   Jamal MA, 2019, PROC CVPR IEEE, P11711, DOI 10.1109/CVPR.2019.01199
   Ji Z, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3260121
   Ji Z, 2023, IEEE T IMAGE PROCESS, V32, P937, DOI 10.1109/TIP.2023.3236160
   Ji Z, 2022, IEEE T IMAGE PROCESS, V31, P1520, DOI 10.1109/TIP.2022.3143005
   Ji Z, 2021, NEUROCOMPUTING, V423, P13, DOI 10.1016/j.neucom.2020.07.128
   Jinlu Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P741, DOI 10.1007/978-3-030-58452-8_43
   Koch G, 2015, P 32 INT C MACHINE L
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2022, AAAI CONF ARTIF INTE, P1828
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu J, 2020, Arxiv, DOI arXiv:2009.02653
   Ma C., 2023, FEW SHOT LEARNING CL
   Ma C., 2022, INT C LEARN REPRESEN, P1
   Mangla P, 2020, IEEE WINT CONF APPL, P2207, DOI [10.1109/wacv45572.2020.9093338, 10.1109/WACV45572.2020.9093338]
   Radford A, 2021, PR MACH LEARN RES, V139
   Ravi S., 2023, OPTIMIZATION MODEL F
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren M., 2018, INT C LEARN REPRESEN
   Ren S., 2015, NEURAL INFORM PROCES, V28, P91, DOI DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A.A., 2019, INT C LEARN REPRESEN
   Sbai O., 2023, EUR C COMPUT VIS
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tian YL, 2020, Arxiv, DOI arXiv:2003.11539
   Torrey Lisa, 2010, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, P242
   Tukey J.W., 1977, EXPLORATORY DATA ANA
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wah C., 2023, The caltech-ucsd birds-200-2011 dataset
   Wang XM, 2022, NEUROCOMPUTING, V490, P283, DOI 10.1016/j.neucom.2021.11.092
   Wang Y, 2019, Arxiv, DOI arXiv:1911.04623
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wu X, 2023, IEEE T IMAGE PROCESS, V32, P364, DOI 10.1109/TIP.2022.3228497
   Wu X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3124913
   Xu J, 2022, Advances in neural information processing systems
   Xu W., 2021, INT C LEARN REPR
   Xue WQ, 2020, AAAI CONF ARTIF INTE, V34, P6558
   Yang S., 2021, INT C LEARN REPRESEN
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zhou K, 2022, P IEEECVF C COMPUTER, P16816
   Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1
   Zhou LJ, 2020, PROC CVPR IEEE, P4623, DOI 10.1109/CVPR42600.2020.00468
   Zhou LJ, 2019, PROC CVPR IEEE, P11489, DOI 10.1109/CVPR.2019.01176
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 72
TC 3
Z9 3
U1 8
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104736
DI 10.1016/j.imavis.2023.104736
EA JUN 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Q2PR1
UT WOS:001055991800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Poonja, HA
   Shirazi, MA
   Khan, MJ
   Javed, K
AF Poonja, Hasnain Ali
   Shirazi, Muhammad Ayaz
   Khan, Muhammad Jawad
   Javed, Kashif
TI Engagement detection and enhancement for STEM education through computer
   vision, augmented reality, and haptics
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Engagement detection; Engagement enhancement; Computer vision; Augmented
   reality; Haptics; Online learning
ID VIRTUAL-REALITY
AB STEM (Science, technology, engineering, and mathematics) based education is being revolutionized with the rapid development of the applications of intelligent Haptics. Theoretical knowledge may now be put into prac-tice, and complex ideas can now be presented using three-dimensional models that are enhanced in the actual environment via Augmented Reality (AR) and computer Haptics to enhance the student's interest in concepts and studies. This article presents a novel design and development of an AR and Haptics-based STEM product com-prising of World Map with Haptic feedback using Vuforia, Unity 3D, and Open-Haptics to enhance student en-gagement. To detect students' engagement in online learning, a computer vision-based system is also designed and deployed in the real-time website that uses the features, such as facial emotions, pose estimation, and head rotation. Marker-based augmentation is employed, and a sense of touch is included for an immersive expe-rience for the students with the use of the haptic Touch Omni device. Hence, the proposed approach can improve classroom learning activities by using Augmented reality and Haptics-based STEM product and by its evaluation using a computer vision system. To validate the improvement in engagement, a comprehensive user study is per-formed and analyzed on the proposed setup. & COPY; 2023 Published by Elsevier B.V.
C1 [Poonja, Hasnain Ali; Khan, Muhammad Jawad; Javed, Kashif] Natl Univ Sci & Technol NUST, Sch Mech & Mfg Engn SMME, Dept Robot & Intelligent Machine, Islamabad 44000, Pakistan.
   [Shirazi, Muhammad Ayaz] Natl Univ Sci & Technol, PN Engn Coll, Dept Elect & Power Engn, Karachi 75350, Pakistan.
C3 National University of Sciences & Technology - Pakistan; National
   University of Sciences & Technology - Pakistan
RP Khan, MJ (corresponding author), Natl Univ Sci & Technol NUST, Sch Mech & Mfg Engn SMME, Dept Robot & Intelligent Machine, Islamabad 44000, Pakistan.
EM jawad.khan@smme.nust.edu.pk
OI Ali, Hasnain/0009-0003-5584-4673
CR Abate AF, 2021, FUTURE GENER COMP SY, V125, P774, DOI 10.1016/j.future.2021.07.026
   Abedi A, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P151, DOI 10.1109/CRV52889.2021.00028
   Ahuja Karan, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351229
   Altuwairqi K, 2021, SIGNAL IMAGE VIDEO P, V15, P1387, DOI 10.1007/s11760-021-01869-7
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bhardwaj P, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107277
   Bortone I, 2018, IEEE T NEUR SYS REH, V26, P1469, DOI 10.1109/TNSRE.2018.2846814
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Dewan MAA, 2019, SMART LEARN ENVIRON, V6, DOI 10.1186/s40561-018-0080-z
   Dewan MAA, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P1895, DOI 10.1109/SmartWorld.2018.00318
   Duraes D., 2019, PROGR ART INT 19 EPI
   Edwards BI, 2019, VIRTUAL REAL-LONDON, V23, P363, DOI 10.1007/s10055-018-0345-4
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Ghanbari S., 2014, J STEM ED INNOVATION, V15, P5
   Goldberg P, 2021, EDUC PSYCHOL REV, V33, P27, DOI 10.1007/s10648-019-09514-z
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Gupta A, 2022, Arxiv, DOI arXiv:1609.01885
   Hamza-Lup F.J.A.P.A., 2019, KINESTHETIC LEARNING
   HART S G, 1988, P139
   Kennedy TJ., 2014, SCI ED INT, V25, P246
   Ketkar N., 2017, Introduction to keras. Deep learning with python: a hands-on introduction, P97
   Koul M.H., 2017, P ADV ROB, P1
   Lee LK, 2017, 2017 INTERNATIONAL SYMPOSIUM ON EDUCATIONAL TECHNOLOGY (ISET 2017), P53, DOI 10.1109/ISET.2017.20
   Liao JC, 2021, APPL INTELL, V51, P6609, DOI 10.1007/s10489-020-02139-8
   Liaw A., 2002, R NEWS, V2, P18
   Lugaresi C, 2019, Arxiv, DOI [arXiv:1906.08172, DOI 10.48550/ARXIV.1906.08172]
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Moubayed A, 2020, AM J DISTANCE EDUC, V34, P137, DOI 10.1080/08923647.2020.1696140
   Newmann F., 1992, STUDENT ENGAGEMENT A
   Nezami O.M., 2019, JOINT EUR C MACH LEA
   Ninaus M, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103641
   Petrov PD, 2020, INFORMATION, V11, DOI 10.3390/info11040209
   Pila S, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040087
   Rothkrantz L., 2016, INT C COMP SUPP ED
   Sanfilippo F, 2022, ROBOTICS, V11, DOI 10.3390/robotics11020041
   Sarosa M., 2019, J PHYS C SERIES
   Seifi H, 2020, IEEE T HAPTICS, V13, P791, DOI 10.1109/TOH.2020.2968903
   Sharma P., 2023, TECH-EDU 2022, V1720, P52, DOI [10.1007/97830312291835, DOI 10.1007/97830312291835]
   Sirakaya M, 2022, INTERACT LEARN ENVIR, V30, P1556, DOI 10.1080/10494820.2020.1722713
   Sunil S., 2017, 2017 INT C COMP APPL
   Toti D., 2021, ADV P2P PARALLEL GRI, V15
   Vanneste P, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9030287
   Videnovik M, 2020, MULTIMED TOOLS APPL, V79, P23861, DOI 10.1007/s11042-020-09046-7
   Wang Y. M., 2010, 2010 3rd International Conference on Information Sciences and Interaction Sciences (ICIS), P403, DOI 10.1109/ICICIS.2010.5534797
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Yamaguchi K, 2017, Arxiv, DOI arXiv:1708.01892
   Yu M., 2017, 2017 IEEE FRONT ED C
   Zaletelj J, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0228-8
NR 49
TC 2
Z9 2
U1 11
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104720
DI 10.1016/j.imavis.2023.104720
EA JUN 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA M2WM9
UT WOS:001028834500001
DA 2024-07-18
ER

PT J
AU Li, SH
   Bi, X
   Zhao, YJ
   Bi, HL
AF Li, Shuaihao
   Bi, Xiang
   Zhao, Yajun
   Bi, Hongliang
TI Extended neighborhood-based road and median filter for impulse noise
   removal from depth map
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth map denoising; Impulse noise removal; Rank -ordered absolute
   differences; Median filter
ID IMAGE
AB In recent years there has been growing interest in the study of depth map's impulse noise detection and removal. The Rank-ordered Absolute Differences (ROAD) based on neighborhood statistics can effectively detect impulse noise for RGB images. However, since the statistical object of the ROAD is each pixel value in the neighborhood, and the neighborhood may contain other impulse noise, invalid depth zero-pixel points and other singular points, especially for large areas with depth missing, it is difficult for the algorithm to ensure the correctness and accuracy of the detection results. Therefore, the ROAD algorithm is not fully applicable to depth maps. Sim-ilarly, the median filter, as an effective impulse noise filtering algorithm, also has the same deficiency, so it is not suitable for areas in depth maps with no depth value. To address these issues, we present here an Extended Neighborhood-based ROAD and Median Filter algorithm to remove impulse noise from depth map. This approach improves the functionality of the ROAD algorithm and the Median Filter by extending the neighborhood of the current pixel adaptively, shielding zero-valued pixels and filtering out detected impulse noises in real time during detection, therefore effectively improving the accuracy of impulse noise filtering. It consequently reduces the miss rate and the error detection rate, and ultimately achieves a better edge-preserving and denoising effect. Our empirical evidence shows that the proposed algorithm outperforms existing denoising algorithms on both quantitative measures and visual perception qualities.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Li, Shuaihao] Sichuan Int Studies Univ, Sch Int Business & Management, Chongqing 400031, Peoples R China.
   [Bi, Xiang] Hubei Univ Arts & Sci, Sch Literature & Media, Xiangyang 441053, Peoples R China.
   [Zhao, Yajun] CHN Energy Chongqing Wanzhou Elect Power Co Ltd, Chongqing 400031, Peoples R China.
   [Bi, Hongliang] Northwestern Polytech Univ, Sch Cybersecur, Xian 710072, Peoples R China.
C3 Sichuan International Studies University; Hubei University of Arts &
   Science; Northwestern Polytechnical University
RP Bi, HL (corresponding author), Northwestern Polytech Univ, Sch Cybersecur, Xian 710072, Peoples R China.
EM bihongliang@nwpu.edu.cn
FU Natural Science Foundation of Chongqing [CSTB2023NSCQ-MSX2742]; National
   Natural Science Foundation of China [62202384]; Natural Science Basic
   Research Program of Shaanxi [D5110220128]; National Social Science
   Foundation of China [19CTQ008]; Major Project of Philosophy and Social
   Science Research in Hubei Universities of China [21ZD116]
FX This study was funded by the Natural Science Foundation of Chongqing
   under Grant CSTB2023NSCQ-MSX2742, in part by the National Natural
   Science Foundation of China under Grant 62202384, in part by the Natural
   Science Basic Research Program of Shaanxi under Grant D5110220128, in
   part by the National Social Science Foundation of China under Grant
   19CTQ008, and in part by the Major Project of Philosophy and Social
   Science Research in Hubei Universities of China under Grant 21ZD116.
CR ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Baek E.T., 2017, SIGNAL INFORM PROCES
   Bouboulis P., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2660, DOI 10.1109/ICPR.2010.652
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Chen JQ, 2019, IEEE ACCESS, V7, P124647, DOI 10.1109/ACCESS.2019.2938799
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Dey D, 2011, COMM COM INF SC, V205, P173
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Hafiane A, 2014, INT C PATT RECOG, P1138, DOI 10.1109/ICPR.2014.205
   Hirner D, 2021, INT C PATT RECOG, P2482, DOI 10.1109/ICPR48806.2021.9413281
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hong S, 2016, J DISP TECHNOL, V12, P1301, DOI 10.1109/JDT.2016.2594076
   Huang R, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103301
   Huhle Benjamin, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563158
   [冀中 Ji Zhong], 2018, [计算机工程与科学, Computer Engineering and Science], V40, P507
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Kim B, 2021, INT J COMPUT VISION, V129, P579, DOI 10.1007/s11263-020-01386-z
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Li L., 2021, ICMLC 2021 2021 13 I
   Li SH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73342-3
   Li Z, 2022, PATTERN RECOGN, V125, DOI 10.1016/j.patcog.2022.108537
   Loosli C, 2012, LECT NOTES COMPUT SC, V7584, P492, DOI 10.1007/978-3-642-33868-7_49
   Mandal JK, 2011, COMM COM INF SC, V245, P212
   Mishiba K, 2020, IEEE T IMAGE PROCESS, V29, P4232, DOI 10.1109/TIP.2020.2970814
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Oikonomopoulos A, 2009, IMAGE VISION COMPUT, V27, P1814, DOI 10.1016/j.imavis.2009.05.010
   Ong S, 2020, IEEE IMAGE PROC, P1261, DOI [10.1109/icip40778.2020.9191093, 10.1109/ICIP40778.2020.9191093]
   Pang TY, 2021, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR46437.2021.00208
   Patanavijit V., 2016, INT C EL ENG EL IEEE
   Pei W, 2009, IMAGE VISION COMPUT, V27, P782, DOI 10.1016/j.imavis.2008.08.001
   Riegler G, 2016, Arxiv, DOI arXiv:1607.08569
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sathya P., 2014, INT J COMP VISION IJ, P78
   Smolka B., 2018, REAL TIME IMAGE VIDE, P14
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Tachella J, 2021, PROC CVPR IEEE, P8614, DOI 10.1109/CVPR46437.2021.00851
   Thumhofer-Hemsi K, 2020, IEEE IMAGE PROC, P3015, DOI 10.1109/ICIP40778.2020.9191237
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Tu ZG, 2015, LECT NOTES COMPUT SC, V9007, P413, DOI 10.1007/978-3-319-16814-2_27
   Wang FQ, 2020, IEEE T IMAGE PROCESS, V29, P1246, DOI 10.1109/TIP.2019.2940496
   Wang MM, 2017, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2017.510
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Xia XJ, 2020, IEEE T MULTIMEDIA, V22, P569, DOI 10.1109/TMM.2019.2933330
   Xu L.F., 2019, COMPUTER KNOWLEDGE T
   Yang K.H., 2015, INT J COMP VISION IJ, V112
   Yang M, 2019, INT CONF WIRE COMMUN, DOI 10.1109/wcsp.2019.8928021
   Yin JL, 2018, IEEE T MULTIMEDIA, V20, P3045, DOI 10.1109/TMM.2018.2820910
   Yuan GZ, 2019, IEEE T PATTERN ANAL, V41, P352, DOI 10.1109/TPAMI.2017.2783936
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
NR 51
TC 1
Z9 2
U1 2
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104709
DI 10.1016/j.imavis.2023.104709
EA MAY 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA J6LJ2
UT WOS:001010708100001
DA 2024-07-18
ER

PT J
AU Jia, XZ
   DongYe, C
   Peng, YJ
AF Jia, XingZhao
   DongYe, ChangLei
   Peng, YanJun
TI SiaTrans: Siamese transformer network for RGB-D salient object detection
   with depth image classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Transformer; RGB-D salient object detection; Siamese network; Image
   classi fication
ID MODEL
AB RGB-D SOD uses depth information to handle challenging scenes and obtain high-quality saliency maps. Existing state-of-the-art RGB-D saliency detection methods overwhelmingly rely on the strategy of directly fusing depth information. Although these methods improve the accuracy of saliency prediction through various cross -modality fusion strategies, misinformation provided by some poor-quality depth images can affect the saliency prediction result. To address this issue, a novel RGB-D salient object detection model (SiaTrans) is proposed in this paper, which allows training on depth image quality classification at the same time as training on SOD. In light of the common information between RGB and depth images on salient objects, SiaTrans uses a Siamese transformer network with shared weight parameters as the encoder and extracts RGB and depth features concatenated on the batch dimension, saving space resources without compromising performance. SiaTrans uses the class token in the backbone network (T2T-ViT) to classify the quality of depth images without prevent-ing the token sequence from going on with the saliency detection task. The greatest benefit of our cross-modality fusion (CMF) and decoder is that they maintain consistency between RGB and RGB-D information decoding. In the test, SiaTrans decides whether to perform an RGB-D or RGB saliency detection task according to the quality classification signal of the depth image. Comprehensive experiments on nine RGB-D SOD benchmark datasets show that SiaTrans has the best overall performance and the least computation compared with recent state-of-the-art methods.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Jia, XingZhao; DongYe, ChangLei; Peng, YanJun] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP DongYe, C (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM dycl@sdust.edu.cn
FU SDUST Young Teachers Teaching Talent Training Plan; National Natural
   Science Foundation of China;  [BJRC20180501];  [61976125]
FX Funding This work was supported by SDUST Young Teachers Teaching Talent
   Training Plan (BJRC20180501) ; National Natural Science Foundation of
   China (Grant No. 61976125) .
CR Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Chen S., 2020, ECCV, P520, DOI DOI 10.1007/978-3-030-58598-3_31
   Chen ZY, 2021, IEEE T IMAGE PROCESS, V30, P7012, DOI 10.1109/TIP.2020.3028289
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Chongyi Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P225, DOI 10.1007/978-3-030-58598-3_14
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan DP, 2018, Arxiv, DOI arXiv:1805.10421
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu KR, 2022, IEEE T PATTERN ANAL, V44, P5541, DOI 10.1109/TPAMI.2021.3073689
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Huang NI, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108359
   Ji W, 2021, PROC CVPR IEEE, P9466, DOI 10.1109/CVPR46437.2021.00935
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Kingma D. P., 2014, arXiv
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu GH, 2014, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CLOUD COMPUTING COMPANION (ISCC-C), P728, DOI 10.1109/ISCC-C.2013.21
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu N., 2021, IEEE INT C COMP VIS, P4722
   Liu N, 2020, Arxiv, DOI arXiv:2010.05537
   Liu ZY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4481, DOI 10.1145/3474085.3475601
   Liu ZY, 2019, NEUROCOMPUTING, V363, P46, DOI 10.1016/j.neucom.2019.07.012
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Miao Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P374, DOI 10.1007/978-3-030-58604-1_23
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Pan L, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103964
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Qin X., P IEEECVF C COMPUTER, P7479
   Tao Zhou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10274, DOI 10.1109/CVPR42600.2020.01029
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wei Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P52, DOI 10.1007/978-3-030-58523-5_4
   Wu Q, 2022, IMAGE VISION COMPUT, V122, DOI 10.1016/j.imavis.2022.104442
   Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Yuan L., P IEEECVF INT C COMP, P558
   Zhang J, 2022, IEEE T PATTERN ANAL, V44, P5761, DOI 10.1109/TPAMI.2021.3073564
   Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353
   Zhang W., P 29 ACM INT C MULTI, P731
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhu CB, 2017, IEEE INT CONF COMP V, P3008, DOI 10.1109/ICCVW.2017.355
NR 58
TC 8
Z9 9
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104549
DI 10.1016/j.imavis.2022.104549
EA SEP 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Raja, K
   Gupta, G
   Venkatesh, S
   Ramachandra, R
   Busch, C
AF Raja, Kiran
   Gupta, Gourav
   Venkatesh, Sushma
   Ramachandra, Raghavendra
   Busch, Christoph
TI Towards generalized morphing attack detection by learning residuals*
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Morphing attacks; Morphing attack detection; Face recognition;
   Vulnerability of biometric systems
AB Face recognition systems (FRS) are vulnerable to different kinds of attacks. Morphing attack combines multiple face images to obtain a single face image that can verify equally against all contributing subjects. Various Morphing Attack Detection (MAD) algorithms have been proposed in recent years albeit limited generalizability. We present a new approach for MAD in this work with better generalization than state-of-the-art (SOTA) algo-rithms. We propose an end-to-end multi-stage encoder-decoder network for learning the residuals of morphing process to detect attacks. Leveraging the residuals, we learn an efficient classifier using cross-entropy loss and asymmetric loss. The use of asymmetric loss in our approach is motivated by imbalanced distribution of morphs and bona fides. An extensive set of experiments are conducted on five different datasets consisting of two land-mark based and three Generative Adversarial Network (GAN) based morphs in various settings such as digital, print-scan and print-scan-compression. We first demonstrate a near-ideal performance of the proposed MAD with Detection Equal Error Rate (D-EER) of 0% in the best case and 2.58% in the worst case in the digital domain in closed-set protocol, i.e., known attacks. Further, we demonstrate the applicability of the proposed approach on 60 different combinations where the testing set contains unknown morphing attacks in open-set protocol to illustrate the generalization ability of our proposed approach. Through training the proposed approach on landmark-based morph generation data alone, we obtain an EER of 3.59% in the best case and 12.89% in the worst case for morphed images in the digital domain, reducing the error rates from 45.67% and 30.23% respec-tively, in open-set protocol. We further present an extensive analysis of the proposed approach through Class Activation Maps (CAM) to explain the decisions using by making use of three complementary CAM analysis.(c) 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Raja, Kiran; Gupta, Gourav; Venkatesh, Sushma; Ramachandra, Raghavendra; Busch, Christoph] Norwegian Univ Sci & Technol, Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU)
RP Raja, K (corresponding author), Norwegian Univ Sci & Technol, Trondheim, Norway.
EM kiran.raja@ntnu.no
OI Gupta, Gourav/0000-0003-3122-1976
CR Aghdaie P., 2021, 2021 IEEE International Joint Conference on Biometrics (IJCB), P1
   Aghdaie P, 2022, IEEE WINT CONF APPL, P311, DOI 10.1109/WACVW54805.2022.00037
   boep-ubo, 2015, BEST PRACT TECHN GUI
   Borghi G, 2021, IEEE ACCESS, V9, P136561, DOI 10.1109/ACCESS.2021.3117718
   Cognitec Systems GmbH, 2020, FACEVACS TECHN VERS
   Damer Naser, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P518, DOI 10.1007/978-3-030-12939-2_36
   Damer N., 2019, INT CONF BIOMETR THE
   Damer N., 2021, INT S VIS COMP
   Damer N., 22TH INT C INFORM FU, P1
   Damer N., 22 INT C INFORM FUSI, P2
   Damer N, 2018, INT CONF BIOMETR THE
   Debiasi L, 2018, I W BIOMETRIC FORENS
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Desai S, 2020, IEEE WINT CONF APPL, P972, DOI [10.1109/wacv45572.2020.9093360, 10.1109/WACV45572.2020.9093360]
   DNP Imagingcomm America Corporation, 2020, DNP PRINT
   Ferrara M, 2018, IEEE T INF FOREN SEC, V13, P1008, DOI 10.1109/TIFS.2017.2777340
   Ferrara M, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Ferrara M, 2021, IET BIOMETRICS, V10, P290, DOI 10.1049/bme2.12021
   Gomez-Barrero M, 2017, I W BIOMETRIC FORENS
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hildebrandt M, 2017, I W BIOMETRIC FORENS
   International Civil Aviation Organization, 2015, MACH READ PASSP 9
   ISO/IEC, 2017, International Standard ISO/IEC 30107-3, VFirst
   Kraetzer C, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P21, DOI 10.1145/3082031.3083244
   Makrushin A, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902533
   Neurotechnology, 2020, NEUR VERILOOK SDK
   Ngan M., 2021, 8292 NISTIR
   NTNU, 2019, STAT ART MORPH DET S
   OHaire K., 2021, ARXIV
   Ortega-Delcampo D., 2020, IEEE ACCESS, P1
   Peng F, 2019, IEEE ACCESS, V7, P75122, DOI 10.1109/ACCESS.2019.2920713
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Raghavendra R, 2016, INT CONF BIOMETR THE
   Raghavendra R, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P555, DOI 10.1109/BTAS.2017.8272742
   Raghavendra R, 2017, IEEE COMPUT SOC CONF, P1822, DOI 10.1109/CVPRW.2017.228
   Raghavendra R., 2018, IAPR INT C COMP VIS, P1
   Raja K, 2021, IEEE T INF FOREN SEC, V16, P4336, DOI 10.1109/TIFS.2020.3035252
   Ridnik T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P82, DOI 10.1109/ICCV48922.2021.00015
   Scherhag Ulrich, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P302, DOI 10.1109/TBIOM.2019.2942395
   Scherhag U, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P187, DOI 10.1109/DAS.2018.11
   Scherhag U, 2017, 2017 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Scherhag U., 2018, P INT C BIOM ENG APP, P6, DOI DOI 10.1145/3230820.3230822
   Scherhag U, 2020, IEEE T INF FOREN SEC, V15, P3625, DOI 10.1109/TIFS.2020.2994750
   Scherhag U, 2017, I W BIOMETRIC FORENS
   Scherhag U, 2019, IEEE ACCESS, V7, P23012, DOI 10.1109/ACCESS.2019.2899367
   Seibold C, 2021, COMPUTERS, V10, DOI 10.3390/computers10090117
   Seibold C, 2019, LECT NOTE INFORM, VP-296
   Seibold C, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102526
   Seibold C, 2018, EUR SIGNAL PR CONF, P1022, DOI 10.23919/EUSIPCO.2018.8553116
   Seibold C, 2017, LECT NOTES COMPUT SC, V10431, P107, DOI 10.1007/978-3-319-64185-0_9
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Soleymani Sobhan, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12666), P560, DOI 10.1007/978-3-030-68780-9_44
   Soleymani S, 2021, IEEE WINT CONF APPL, P1730, DOI 10.1109/WACV48630.2021.00177
   Venkatesh Sushma, 2021, IEEE Transactions on Technology and Society, V2, P128, DOI 10.1109/TTS.2021.3066254
   Venkatesh S., 2019, 5 INT C ID SEC BEH A, P1
   Venkatesh S, 2020, PROCEEDINGS OF 2020 23RD INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2020), P1094, DOI 10.23919/fusion45008.2020.9190629
   Venkatesh S, 2020, I W BIOMETRIC FORENS, DOI 10.1109/iwbf49977.2020.9107970
   Venkatesh S, 2020, IEEE WINT CONF APPL, P269, DOI [10.1109/WACV45572.2020.9093488, 10.36227/techrxiv.11630571]
   Wang HJ, 2020, Cambria Sinophone Wo, P111, DOI 10.1109/CVPRW50498.2020.00020
   Zhang H., 2021, IEEE T BIOM BEHAV ID
NR 61
TC 8
Z9 8
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104535
DI 10.1016/j.imavis.2022.104535
EA SEP 2022
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5Q3YO
UT WOS:000873771400004
OA Green Published
DA 2024-07-18
ER

PT J
AU Zhang, J
   Liang, QW
   Shi, YJ
AF Zhang, Jin
   Liang, Qiuwei
   Shi, Yanjiao
TI Accurate and efficient salient object detection via position prior
   attention
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Salient object detection; Position prior; Feature fusion
ID NETWORK
AB The excessive pursuit of accuracy has resulted in complex and huge structures of most existing salient object de-tection (SOD) models, and the meticulously designed lightweight SOD models cannot accurately detect salient objects. To improve the practicality of SOD, we design a novel position prior attention network (PPANet) for fast and accurate salient object detection in this paper. In detail, we propose a position prior attention module (PPAM), which first assigns different weights to positions based on the prior that objects near the image center are more attractive to people, and then perceives object context information through different receptive fields. In addition, we propose a context fusion module (CFM) to prevent the coarse resolution of high-level features from diluting the salient object boundaries during fusion. We present two PPANet versions: a heavyweight PPANet-R aimed at high accuracy SOD and a lightweight PPANet-M that achieves a good balance between accuracy and ef-ficiency. Besides, we construct a structural polishing loss that gives more attention to object boundary and solves the problem of sample imbalance. Experimental results on 5 popular benchmark datasets demonstrate that the proposed PPANet-R outperforms existing SOD models, and PPANet-M achieves accuracy comparable to the state-of-the-art heavyweight SOD methods with 150 FPS real-time detection speed. (c) 2022 Published by Elsevier B.V.
C1 [Zhang, Jin; Shi, Yanjiao] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
   [Liang, Qiuwei] Wenzhou Med Univ, Sch Biomed Engn, Sch Ophthalmol & Optometry, Wenzhou 325027, Peoples R China.
   [Liang, Qiuwei] Wenzhou Med Univ, Eye Hosp, Wenzhou 325027, Peoples R China.
C3 Shanghai Institute of Technology; Wenzhou Medical University; Wenzhou
   Medical University
RP Shi, YJ (corresponding author), Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
EM shiyanjiao616@163.com
FU National Natural Science Foundation of China [61806126, 61903256,
   61976140, 61973307, 62062040]; Natural Science Foundation of Shanghai
   [19ZR1455300, 21ZR1462600]
FX Acknowledgements This work was supported by the National Natural Science
   Foundation of China (61806126, 61903256, 61976140, 61973307, 62062040)
   and Natural Science Foundation of Shanghai (19ZR1455300, 21ZR1462600) .
   We thank the GPUs provided by BaiDu PaddlePaddle AI Studio.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Bokhovkin A, 2019, LECT NOTES COMPUT SC, V11555, P388, DOI 10.1007/978-3-030-22808-8_38
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2021, IEEE T IMAGE PROCESS, V30, P6855, DOI 10.1109/TIP.2021.3099405
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu JJ, 2020, IEEE T IMAGE PROCESS, V29, P8652, DOI 10.1109/TIP.2020.3017352
   Liu N, 2021, Arxiv, DOI arXiv:2104.12099
   Liu Y, 2021, IEEE T IMAGE PROCESS, V30, P3804, DOI 10.1109/TIP.2021.3065239
   Liu Y, 2022, IEEE T CYBERNETICS, V52, P6131, DOI 10.1109/TCYB.2021.3051350
   Liu Y, 2021, IEEE T CYBERNETICS, V51, P4439, DOI 10.1109/TCYB.2020.3035613
   Mac B, 2020, PR MACH LEARN RES, V121, P503
   Miao Z., 2021, ACM MULTIM C, V2021
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Pang YW, 2018, IEEE T CIRC SYST VID, V28, P640, DOI 10.1109/TCSVT.2016.2630731
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shimoda W, 2020, COMPUT VIS IMAGE UND, V191, DOI 10.1016/j.cviu.2018.08.006
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xu BW, 2021, AAAI CONF ARTIF INTE, V35, P3004
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yao YZ, 2021, PROC CVPR IEEE, P2623, DOI 10.1109/CVPR46437.2021.00265
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang DW, 2017, Arxiv, DOI arXiv:1703.01290
   Zhang J, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104337
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao J.-X., P IEEECVF INT C COMP, P8779
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhao Z., P 29 ACM INT C MULTI, P4967
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
NR 55
TC 3
Z9 3
U1 2
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104508
DI 10.1016/j.imavis.2022.104508
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3F6VI
UT WOS:000830804100009
DA 2024-07-18
ER

PT J
AU Yang, F
   Wang, Z
   Wu, Y
   Sakti, S
   Nakamura, S
AF Yang, Fan
   Wang, Zheng
   Wu, Yang
   Sakti, Sakriani
   Nakamura, Satoshi
TI Tackling multiple object tracking with complicated motions-Re-designing
   the integration of motion and appearance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiple object tracking; Data association
AB Although numerous data association methods have been proposed for Multiple Object Tracking (MOT), how to integrate different features in the data association remains an open problem. For instance, over-relying on the motion feature may fail to do the necessary data association when object movements are complicated, while only depending on the appearance feature may lead to incorrect association results when intra-frame objects have similar appearances. To make an improved trade-off between the appearance feature and motion feature, we re-designed the integration of motion and appearance. In our online approach, the location and motion of each object are cast to adaptive searching windows, and within searching windows, matching is only related to the similarity of appearance features. In our offline approach, tracklets generated from our online approach are refined by forming the motion feature as spatiotemporal constraints and utilizing the appearance for cluster-ing. We conduct experiments on multiple MOT datasets from diverse perspectives, including variant motion speed, illumination condition, object categories, etc., and verify that our method can reach robust performance. Moreover, this method also demonstrates its effectiveness by further improving our previous 1st place solutions in two CVPR 2020 MOT challenges.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yang, Fan; Nakamura, Satoshi] Nara Inst Sci & Technol, Ikoma, Japan.
   [Wang, Zheng] Wuhan Univ, Wuhan, Peoples R China.
   [Wu, Yang] Tencent PCG, ARC Lab, Shenzhen, Peoples R China.
   [Sakti, Sakriani] Japan Adv Inst Sci & Technol, Nomi, Japan.
C3 Nara Institute of Science & Technology; Wuhan University; Japan Advanced
   Institute of Science & Technology (JAIST)
RP Yang, F (corresponding author), Nara Inst Sci & Technol, Ikoma, Japan.
EM hongheyangfan@gmail.com
FU JSPS KAKENHI [JP17H06101]
FX This work was supported by JSPS KAKENHI Grant Number JP17H06101.
CR Andriluka M, 2018, PROC CVPR IEEE, P5167, DOI 10.1109/CVPR.2018.00542
   Babaee M, 2018, arXiv
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Brasó G, 2020, PROC CVPR IEEE, P6246, DOI 10.1109/CVPR42600.2020.00628
   CHANG CB, 1982, IEEE T AUTOMAT CONTR, V27, P1250, DOI 10.1109/TAC.1982.1103107
   Chang MF, 2019, PROC CVPR IEEE, P8740, DOI 10.1109/CVPR.2019.00895
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Cohen-Addad V, 2018, SODA'18: PROCEEDINGS OF THE TWENTY-NINTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P378
   Crouse DF, 2016, IEEE T AERO ELEC SYS, V52, P1679, DOI 10.1109/TAES.2016.140952
   Dubuisson S, 2006, IEEE IMAGE PROC, P2805, DOI 10.1109/ICIP.2006.312991
   Fernando T, 2018, IEEE WINT CONF APPL, P1122, DOI 10.1109/WACV.2018.00128
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jiang XL, 2019, Arxiv, DOI arXiv:1907.05315
   Leal-Taix‚ L, 2015, Arxiv, DOI arXiv:1504.01942
   Li JH, 2020, IEEE WINT CONF APPL, P708, DOI 10.1109/WACV45572.2020.9093347
   Li WQ, 2019, IEEE INT CONF COMP V, P161, DOI 10.1109/ICCVW.2019.00025
   Luiten J, 2020, IEEE ROBOT AUTOM LET, V5, P1803, DOI 10.1109/LRA.2020.2969183
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Ma C, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P253, DOI 10.1145/3323873.3325010
   Mhalla A, 2019, IMAGE VISION COMPUT, V88, P120, DOI 10.1016/j.imavis.2019.03.002
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Munjal B, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103932
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Su H, 2019, INT CONF INFO SCI, P350, DOI [10.1109/icist.2019.8836764, 10.1109/ICIST.2019.8836764]
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wen LY, 2014, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2014.167
   Weng XS, 2020, PROC CVPR IEEE, P6498, DOI 10.1109/CVPR42600.2020.00653
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu Jialian., Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P12352
   Wu Y., 2019, Detectron 2
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xin Li, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P1862, DOI 10.1109/ICINFA.2010.5512258
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Xu Z., 2020, P EUROPEAN C COMPUTE, P1
   Yang F., 2020, ABS200703200 CORR, pabs/2007.03200
   Yang F, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104091
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zhang S, 2015, PATTERN RECOGN, V48, P580, DOI 10.1016/j.patcog.2014.08.013
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
NR 45
TC 6
Z9 6
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104514
DI 10.1016/j.imavis.2022.104514
EA JUL 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3F6VI
UT WOS:000830804100001
DA 2024-07-18
ER

PT J
AU Balachandran, G
   Krishnan, JVG
AF Balachandran, G.
   Krishnan, J. Venu Gopala
TI Machine learning based video segmentation of moving scene by motion
   index using IO detector and shot segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video segmentation; Machine learning; Soft voting; Segmentation; Gray
   level matrix; Audio transformation
ID OBJECT SEGMENTATION
AB Video segmentation has a major role in several applications like autonomous vehicles, medical image analysis, video surveillance, and augmented reality. Portrait segmentation, a subset of semantic image segmentation, is the key step of preprocessing step in numerous applications and a few among them are entertainment applications, security systems, video conferences, and so on. For the given video, every object exhibiting independent motion in at least a single frame is segmented. This is formulated as a learning problem and designed as an Ensemble Soft Voting Algorithm based on Supervised Machine Learning (ESVA-SML). The motion stream requires an ensemble learning method trained on synthetic videos for segmenting independent objects at motion in the optical flow field. The spatial-temporal features are extracted from each sub-bands which efficiently resembles the human visual system characteristics concerning the feature extract using Gray Level Size Zone Matrix (GLSZM). This method linear combines the previous vectors within a stipulated time interval thereby describing each spatial-temporal feature vector. Based on the prediction errors, shot boundaries of every shot are efficiently identified from which at least a single keyframe is extracted for further analysis. The proposed method is extensively evaluated using SegTrack-v2, DAVIS, and Fusion databases by comparing eight standard methods in various parameters. By analyzing all these three databases, SegTrack-v2 is best in terms of accuracy, precision, and recall. While both DAVIS and Fusion databases produce less MAE. Finally, Fusion produces less RMSE and RAE with minimal response time.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Balachandran, G.] Sathyabama Inst Sci & Technol, Chennai, India.
   [Krishnan, J. Venu Gopala] Madha Engn Coll, Chennai, India.
C3 Sathyabama Institute of Science & Technology
RP Balachandran, G (corresponding author), Sathyabama Inst Sci & Technol, Chennai, India.
EM balachendreng@outlook.com; jvenu123@gmail.com
RI G, Balachandran/JPK-8101-2023
OI G, Balachandran/0000-0002-7024-7848
CR Agarwal A., 2022, NANOSTRUCTURES BIOCH
   Ahilan A, 2019, IEEE ACCESS, V7, P89570, DOI 10.1109/ACCESS.2019.2891632
   Divya A., 2020, INT J ADV SCI TECHNO, V29, P13201
   Huang Xun, ICCV 2015, P262
   Jose T.J, 2019, INT J ENG ADV TECHNO, V9, P4332, DOI DOI 10.35940/IJEAT.A1812.109119
   Kamarasan M, 2018, J EMERG TECHNOL INNO, V5
   Kayalvizhi M, 2015, Biomed Sci Instrum, V51, P332
   Kim YW, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23020197
   Lee Yong Jae, ICCV 2011, P1995
   Li Y., 2009 IEEE 12 INT C C, P1957
   Lim T, 2012, PATTERN RECOGN, V45, P1696, DOI 10.1016/j.patcog.2011.10.018
   Lin Guosheng, P IEEE C COMPUTER VI, P3194
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu Y, 2005, IEEE T CIRC SYST VID, V15, P885, DOI 10.1109/TCSVT.2005.848346
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Mnih V., 2016, International Conference on Machine Learning, P1928
   Ochs Peter, ICCV 2011, P1583
   Parkinson A.R., 2018, Optimization Methods for Engineering Design, V2
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Ramesh S, 2021, MULTIMED TOOLS APPL, V80, P11789, DOI 10.1007/s11042-020-10351-4
   Ross MG, 2009, IEEE T PATTERN ANAL, V31, P661, DOI 10.1109/TPAMI.2008.109
   Salam AOA, 2019, ICT EXPRESS, V5, P31, DOI 10.1016/j.icte.2018.02.002
   Slimene A, 2019, EXPERT SYST APPL, V128, P271, DOI 10.1016/j.eswa.2019.03.038
   Taylor B., 2015, CVPR
   Thibault G, 2014, IEEE T BIO-MED ENG, V61, P630, DOI 10.1109/TBME.2013.2284600
   Tian Y, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107158
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Trojahn TH, 2021, MULTIMED TOOLS APPL, V80, P17487, DOI 10.1007/s11042-020-10450-2
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P10195, DOI 10.1007/s11042-017-5318-1
   Varol G, 2015, EXPERT SYST APPL, V42, P8274, DOI 10.1016/j.eswa.2015.06.013
   Wang JD, 2011, PATTERN RECOGN, V44, P2274, DOI 10.1016/j.patcog.2010.07.015
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang YH, 2017, PATTERN RECOGN, V64, P437, DOI 10.1016/j.patcog.2016.09.046
   Yang B., 2013, IEEE T SIGN PROC, V43, P95
   Yin P, 2011, IEEE T PATTERN ANAL, V33, P30, DOI 10.1109/TPAMI.2010.65
   Zemgulys J, 2018, PROCEDIA COMPUT SCI, V130, P953, DOI 10.1016/j.procs.2018.04.095
   Zhang L, 2020, IEEE ACCESS, V8, P30355, DOI 10.1109/ACCESS.2020.2971964
   Zhou Z.-H, 2012, ENSEMBLE METHODS FDN, P75
   Zhu WJ, 2021, NEUROCOMPUTING, V455, P325, DOI 10.1016/j.neucom.2021.04.090
NR 40
TC 1
Z9 1
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104443
DI 10.1016/j.imavis.2022.104443
EA APR 2022
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1F1NU
UT WOS:000794942300003
DA 2024-07-18
ER

PT J
AU Liang, Q
   Li, Q
   Yang, S
AF Liang, Qi
   Li, Qiang
   Yang, Song
TI LP-GAN: Learning perturbations based on generative adversarial networks
   for point cloud adversarial attacks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D model; Point cloud; Adversarial attack; GAN
AB With the rapid development of technologies for 3D model construction and analysis, the 3D model has been utilized in many applications, such as 3D reconstruction, object detection, and self-driving vehicles. Moreover, the development of deep learning theory has also enabled 3D model analysis to achieve revolutionary performance in many tasks. However, the adversarial robustness of these models has not received sufficient attention. Few methods focus on the generation of better adversarial samples for attacking the point cloud models that are utilized for testing the adversarial robustness. Many approaches only focus on shifting the critical points based on the perturbation metric but ignore the characteristics of adversarial points. In this work, we propose a novel generative model to produce adversarial samples. Based on the GAN, the generator can learn the representation of the adversarial points effectively, and adjust the adversarial samples to fool the point cloud models according to different point clouds. Furthermore, we hope that the adversarial samples not only fool the point cloud models but also can fool the human visual system with unnoticeable points, which is also the characteristic of the adversarial examples. Here, we propose a perception loss to improve the quality of the adversarial samples according to the original sample. Based on the generative model and perception loss, the final adversarial samples can effectively be utilized to improve the adversarial robustness of the point cloud models. Extensive attack experiments conducted on the ModelNet with state-of-the-art point cloud models demonstrate the effectiveness of our method. (c) 2021 Published by Elsevier B.V.
C1 [Liang, Qi; Li, Qiang; Yang, Song] Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Yang, S (corresponding author), Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
EM yangsong_1014@tju.edu.cn
FU National Natural Science Foundation of China [61471263]; Natural Science
   Foundation of Tianjin [16JCZDJC31100]
FX This work was supported in part by the National Natural Science
   Foundation of China (61471263) , the Natural Science Foundation of
   Tianjin (16JCZDJC31100) .
CR Achlioptas P, 2018, PR MACH LEARN RES, V80
   Alexiou E, 2018, INT WORK QUAL MULTIM, P132
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Franke J, 2020, IEEE T MED IMAGING, V39, P4335, DOI 10.1109/TMI.2020.3017160
   Gadelha M, 2018, LECT NOTES COMPUT SC, V11211, P105, DOI 10.1007/978-3-030-01234-2_7
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Gou B, 2019, IEEE T IND ELECTRON, V66, P9817, DOI 10.1109/TIE.2018.2880719
   Hamdi Abdullah, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P241, DOI 10.1007/978-3-030-58610-2_15
   Hang Zhou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10353, DOI 10.1109/CVPR42600.2020.01037
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hu BT, 2019, INFORM SCIENCES, V504, P202, DOI 10.1016/j.ins.2019.07.039
   Ilyas A, 2019, ADV NEUR IN, V32
   Kingma D. P., 2014, arXiv
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Komatsu T, 2020, INT CONF ACOUST SPEE, P646, DOI [10.1109/icassp40776.2020.9053702, 10.1109/ICASSP40776.2020.9053702]
   Kumawat S, 2019, PROC CVPR IEEE, P4898, DOI 10.1109/CVPR.2019.00504
   Kwon H, 2020, NEUROCOMPUTING, V417, P357, DOI 10.1016/j.neucom.2020.07.101
   Li C., 2019, ICLR 2019 WORKSH
   Li YC, 2020, INFORM SCIENCES, V507, P124, DOI 10.1016/j.ins.2019.08.038
   Li ZH, 2018, IEEE T NEUR NET LEAR, V29, P6323, DOI 10.1109/TNNLS.2018.2829867
   Liu Daniel, 2019, 2019 IEEE International Conference on Image Processing (ICIP). Proceedings, P2279, DOI 10.1109/ICIP.2019.8803770
   Liu SJ, 2018, INFORM SCIENCES, V451, P161, DOI 10.1016/j.ins.2018.03.064
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Lu Y, 2020, IEEE J BIOMED HEALTH, V24, P1367, DOI 10.1109/JBHI.2019.2943228
   Nie WZ, 2021, IEEE T MULTIMEDIA, V23, P1962, DOI 10.1109/TMM.2020.3006371
   Nie WZ, 2021, IEEE T IMAGE PROCESS, V30, P4371, DOI 10.1109/TIP.2021.3071687
   Nie WZ, 2020, IEEE ACCESS, V8, P5979, DOI 10.1109/ACCESS.2019.2963511
   Nie WZ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P908, DOI 10.1145/3343031.3351009
   Pumarola Albert, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7946, DOI 10.1109/CVPR42600.2020.00797
   Qi C. R., 2017, Advances in neural information processing systems, P5099
   Ren PZ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447582
   Russo DJ, 2018, FOUND TRENDS MACH LE, V11, P1, DOI 10.1561/2200000070
   Shetty GN, 2020, IEEE T MED IMAGING, V39, P688, DOI 10.1109/TMI.2019.2934125
   Sun YB, 2020, IEEE WINT CONF APPL, P61, DOI [10.1109/wacv45572.2020.9093430, 10.1109/WACV45572.2020.9093430]
   Szegedy C, 2014, INT C LEARN REPR
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tsai T, 2020, AAAI CONF ARTIF INTE, V34, P954
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wicker M, 2019, PROC CVPR IEEE, P11759, DOI 10.1109/CVPR.2019.01204
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiang C, 2019, PROC CVPR IEEE, P9128, DOI 10.1109/CVPR.2019.00935
   Xie L, 2020, AAAI CONF ARTIF INTE, V34, P12460
   Xu N, 2020, IEEE T MULTIMEDIA, V22, P1372, DOI 10.1109/TMM.2019.2941820
   Zamorski M, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102921
   Zhao Y, 2020, PROC CVPR IEEE, P1198, DOI 10.1109/CVPR42600.2020.00128
   Zheng TH, 2019, IEEE I CONF COMP VIS, P1598, DOI 10.1109/ICCV.2019.00168
   Zhou H, 2019, IEEE I CONF COMP VIS, P1961, DOI 10.1109/ICCV.2019.00205
NR 49
TC 5
Z9 5
U1 2
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104370
DI 10.1016/j.imavis.2021.104370
EA FEB 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500009
DA 2024-07-18
ER

PT J
AU Xia, YF
   He, YQ
   Peng, SF
   Yang, QQ
   Yin, BQ
AF Xia, Yinfeng
   He, Yuqiang
   Peng, Sifan
   Yang, Qianqian
   Yin, Baoqun
TI CFFNet: Coordinated feature fusion network for crowd counting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Crowd counting; Feature fusion; Spatial alignment; Semantic consistency
ID DENSITY-ESTIMATION
AB Long skip connection or encoder-decoder networks for crowd counting have proven to be effective methods to generate high-resolution density maps. However, the simple and coarse feature fusion ignores the disharmony between features, that is, spatial misalignment and semantic inconsistency, which will weaken feature represen-tation and degrade network performance. In this paper, we propose an end-to-end trainable architecture called Coordinated Feature Fusion Network (CFFNet) to tackle the aforementioned problems. The proposed model con-tains a powerful baseline network and embeds two primary modules: Spatial Alignment Module (SAM) and Se-mantic Consistency Module (SCM). Specifically, the SAM can learn the transformation offset of pixels to alleviate the spatial misalignment caused by the feature resolution difference; the SCM based on the multi-scale attention mechanism can capture pixel-wise weight to alleviate the semantic inconsistency due to the feature level gap. Extensive experiments on four benchmark crowd datasets (the ShanghaiTech, the UCF-QNRF, the JHU-CRWORD++ and the NWPU-Crowd), indicate that CFFNet can achieve state-of-the-art counting performance and high robustness. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Xia, Yinfeng; He, Yuqiang; Peng, Sifan; Yang, Qianqian; Yin, Baoqun] Univ Sci & Technol China, Dept Automation, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Yin, BQ (corresponding author), Univ Sci & Technol China, Dept Automation, Hefei 230027, Anhui, Peoples R China.
EM julyxia@mail.ustc.edu.cn; hyq94@mail.ustc.edu.cn;
   sifan@mail.ustc.edu.cn; yanghcqq@mail.ustc.edu.cn; bqyin@ustc.edu.cn
RI yang, qian/HTS-5357-2023
FU Equipment Pre-Research Foundation of China [61403120201]
FX This work is supported by the Equipment Pre-Research Foundation of China
   under grant No.61403120201.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bochkovskiy A., 2021, ARXIV PREPRINT ARXIV
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cheng J, 2021, IEEE T IMAGE PROCESS, V30, P2862, DOI 10.1109/TIP.2021.3055631
   Dai YM, 2021, IEEE WINT CONF APPL, P3559, DOI 10.1109/WACV48630.2021.00360
   Ding XH, 2021, IEEE T INTELL TRANSP, V22, P4776, DOI 10.1109/TITS.2020.2983475
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Fu Chenglong, 2021, ARXIV PREPRINT ARXIV
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006
   Gao J., 2021, ARXIV PREPRINT ARXIV, P2021
   Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139
   Gao JY, 2019, NEUROCOMPUTING, V363, P1, DOI 10.1016/j.neucom.2019.08.018
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2022, IEEE T PATTERN ANAL, V44, P550, DOI 10.1109/TPAMI.2021.3062772
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Jiang XH, 2020, IEEE T NEUR NET LEAR, V31, P2705, DOI 10.1109/TNNLS.2019.2933920
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu LB, 2019, IEEE I CONF COMP VIS, P1774, DOI 10.1109/ICCV.2019.00186
   Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Lu H, 2019, IEEE I CONF COMP VIS, P3265, DOI 10.1109/ICCV.2019.00336
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Paragios N, 2001, PROC CVPR IEEE, P1034
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rong LZ, 2021, IEEE WINT CONF APPL, P3674, DOI 10.1109/WACV48630.2021.00372
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Sam DB, 2021, IEEE T PATTERN ANAL, V43, P2739, DOI 10.1109/TPAMI.2020.2974830
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shi MJ, 2019, PROC CVPR IEEE, P7271, DOI 10.1109/CVPR.2019.00745
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2022, IEEE T PATTERN ANAL, V44, P2594, DOI 10.1109/TPAMI.2020.3035969
   Sindagi VA, 2019, IEEE I CONF COMP VIS, P1002, DOI 10.1109/ICCV.2019.00109
   Thanasutives P, 2021, INT C PATT RECOG, P2382, DOI 10.1109/ICPR48806.2021.9413286
   Tian Y, 2011, LECT NOTES COMPUT SC, V6494, P679, DOI 10.1007/978-3-642-19318-7_53
   Tian YK, 2020, IEEE T IMAGE PROCESS, V29, P2714, DOI 10.1109/TIP.2019.2952083
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wang Bailin, ARXIV PREPRINT ARXIV
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Xiong HP, 2019, IEEE I CONF COMP VIS, P8361, DOI 10.1109/ICCV.2019.00845
   Yan ZY, 2019, IEEE I CONF COMP VIS, P952, DOI 10.1109/ICCV.2019.00104
   Yi Q., 2021, ARXIV PREPRINT ARXIV
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 60
TC 4
Z9 4
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104242
DI 10.1016/j.imavis.2021.104242
EA JUN 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100003
DA 2024-07-18
ER

PT J
AU Han, Y
   Roy, SK
   Petersson, L
   Harandi, M
AF Han, Yan
   Roy, Soumava Kumar
   Petersson, Lars
   Harandi, Mehrtash
TI Discrepant collaborative training by Sinkhorn divergences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Co-training; Noisy labels; Weak-supervised learning
AB Deep Co-Training algorithms are typically comprised of two distinct and diverse feature extractors that simultaneously attempt to learn task-specific features from the same inputs. Achieving such an objective is, however, not trivial, despite its innocent look. This is because homogeneous networks tend to mimic each other under the collaborative training setup. Keeping this difficulty in mind, we make use of the newly proposed S-C divergence to encourage diversity between homogeneous networks. The S-C divergence encapsulates popular measures such as maximum mean discrepancy and the Wasserstein distance under the same umbrella and provides us with a principled, yet simple and straightforward mechanism. Our empirical results in two domains, classification in the presence of noisy labels and semi-supervised image classification, clearly demonstrate the benefits of the proposed framework in learning distinct and diverse features. We show that in these respective settings, we achieve impressive results by a notable margin. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Han, Yan; Roy, Soumava Kumar; Petersson, Lars] Australian Natl Univ, New Acton, ACT 2601, Australia.
   [Han, Yan; Roy, Soumava Kumar; Petersson, Lars; Harandi, Mehrtash] DATA61 CSIRO, Acton, ACT 2601, Australia.
   [Harandi, Mehrtash] Monash Univ, Clayton, Vic 3800, Australia.
C3 Australian National University; Commonwealth Scientific & Industrial
   Research Organisation (CSIRO); Monash University
RP Han, Y (corresponding author), Australian Natl Univ, New Acton, ACT 2601, Australia.
EM yan.han@anu.edu.au; soumava.kumarroy@anu.edu.au;
   lars.petersson@data61.csiro.au; mehrtash.harandi@monash.au
RI Petersson, Lars/C-2568-2019; Harandi, Mehrtash/D-6586-2018
OI Petersson, Lars/0000-0002-0103-1904; Harandi,
   Mehrtash/0000-0002-6937-6300
CR Alvarez MA, 2012, FOUND TRENDS MACH LE, V4, P195, DOI 10.1561/2200000036
   [Anonymous], 2005, INTRO STOCHASTIC SEA
   [Anonymous], MNIST DATABASE HANDW
   Argyriou A., 2007, NIPS, P41
   Banfield R. E., 2005, Information Fusion, V6, P49, DOI 10.1016/j.inffus.2004.04.005
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546
   Chen S., ARXIV PREPRINT ARXIV
   Deng J., 2014, ACM C HUM FACT COMP
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feydy J., ARXIV PREPRINT ARXIV
   Genevay A, 2016, ADV NEUR IN, V29
   Genevay A, 2018, PR MACH LEARN RES, V84
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han B., ARXIV PREPRINT ARXIV
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Han Y., IEEE WINT C APPL COM, P3169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, COMPUT SCI, V2
   Jiang L., INT C MACH LEARN PML, P4804
   Kingma D. P., 2014, arXiv
   Kiritchenko S., 2011, P 2011 C CTR ADV STU, P301
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Laine S., ARXIV PREPRINT ARXIV
   Li YJ, 2015, PR MACH LEARN RES, V37, P1718
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Malach E, 2017, ADV NEUR IN, V30
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Miyato T., ARXIV PREPRINT ARXIV
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805
   Ortego D., ARXIV PREPRINT ARXIV
   Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240
   Qiao SY, 2018, LECT NOTES COMPUT SC, V11219, P142, DOI 10.1007/978-3-030-01267-0_9
   Ren M., ARXIV PREPRINT ARXIV
   Sajjadi M, 2016, ADV NEUR IN, V29
   Salimans T, 2016, ADV NEUR IN, V29
   Sun YQ, 2017, LECT NOTES COMPUT SC, V10178, P545, DOI 10.1007/978-3-319-55699-4_33
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tarvainen A, 2017, ADV NEUR IN, V30
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wei Hongxin, 2020, P IEEE C COMP VIS PA
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhou Z., ARXIV PREPRINT ARXIV
NR 49
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104213
DI 10.1016/j.imavis.2021.104213
EA JUN 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100002
DA 2024-07-18
ER

PT J
AU Wang, W
   Cheng, J
   Liu, SY
AF Wang, Wen
   Cheng, Jian
   Liu, Siyu
TI DCT-net: A deep co-interactive transformer network for video temporal
   grounding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video temporal grounding; Co-interactive transformer; Multi-modal
   feature fusion
AB Language-guided video temporal grounding is to temporally localize the best matched video segment in an untrimmed long video according to a given natural language query (sentence). The main challenge in this task lies in how to fuse visual and linguistic information effectively. Recent works have shown that the attention mechanism is beneficial to the multi-modal feature fusion process. In this paper, we present a concise yet valid Deep Co Interactive Transformer Network (DCT-Net) which repurposes a Transformer-style architecture to sufficiently model cross modality interactions. It consists of Co-Interactive Transformer (CIT) layers cascaded in depth for multi-step interactions between a video-sentence pair. With the help of the proposed CIT layer, both visual and language features can share the mutually improved benefits from each other. Extensive experiments on two public datasets, i.e. ActivityNet-Caption and TACOS, demonstrate the effectiveness of our proposed model compared to state-of-the-art methods.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wang, Wen; Cheng, Jian; Liu, Siyu] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Cheng, J (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Sichuan, Peoples R China.
EM chengjian@uestc.edu.cn
RI Wang, Wen/JXO-0101-2024
FU National Natural Science Foundation of China [61671125, 62071104];
   Sichuan Science and Technology Program [2020YFG0085, 2019YFS0427,
   2021YFG0328]; Intelligent Terminal Key Laboratory of Sichuan
   [SCITLAB0017]
FX This work is partially supported by the National Natural Science
   Foundation of China (61671125, 62071104) , partially supported by the
   Sichuan Science and Technology Program (2020YFG0085, 2019YFS0427,
   2021YFG0328) , and partially supported by the Intelligent Terminal Key
   Laboratory of Sichuan (SCITLAB0017) .
CR Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bin D., 2020, IEEE WINT CONF APPL, DOI DOI 10.1109/WACV48630.2021.00406
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen JY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P162
   Chen L, 2020, AAAI CONF ARTIF INTE, V34, P27
   Chen P, 2020, CVPR
   Chen Shaoxiang, 2019, Semantic proposal for activity localizaiton in videos via sentence query
   Chen Z., 2020, ABS200109308 ARXIV
   Cho K., 2014, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Hauptmann A.G, 2019, ABS190402755 CORR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendricks Lisa Anne, 2018, EMNLP
   Huang D., 2020, J MED VIROL
   Kipf TN, 2016, ARXIV
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Liu MY, 2018, INT TEST CONF P
   Liu W., 2019, Neural Inf. Process. Syst., P536
   Mithun Niluthpol Chowdhury, 2019, CVPR
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Regneri M., 2013, TACL, V1, P25, DOI DOI 10.1162/TACL_A_00207
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rohrbach M, 2012, LECT NOTES COMPUT SC, V7572, P144, DOI 10.1007/978-3-642-33718-5_11
   Saenko K, 2017, P ASME INTERNAL COMB
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Sigal L., 2019, The Carbon Footprint Analysis of Wastewater Treatment Plants and Nitrous Oxide Emissions from Full-Scale Biological Nitrogen Removal Process in Spain
   Sigal L., 2019, ICCV
   Singha J., NEURAL COMPUT APPL
   Song Y, 2020, ARXIV
   Tan Reuben, 2021, WACV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JW, 2020, AAAI CONF ARTIF INTE, V34, P12168
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wu J., 2020, REINFORCEMENT LEARNI, P1283, DOI [10.1145/3394171.3413862, DOI 10.1145/3394171.3413862]
   Xiao J, 2019, EMNLP
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Yuan YT, 2019, AAAI CONF ARTIF INTE, P9159
   Zhang B., 2020, ARXIV200911232
   Zhang D, 2019, PROC CVPR IEEE, P1247, DOI 10.1109/CVPR.2019.00134
   Zhang Houyu, 2020, P 58 ANN M ASS COMP
   Zhang Z, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P655, DOI 10.1145/3331184.3331235
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhao ZX, 2020, IEEE INT SYMP CIRC S
   Zhu Y, 2020, CVPR
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 50
TC 2
Z9 2
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104183
DI 10.1016/j.imavis.2021.104183
EA APR 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700003
DA 2024-07-18
ER

PT J
AU Chen, XW
   Zhang, Q
   Zhang, LQ
AF Chen, Xiaowei
   Zhang, Qing
   Zhang, Liqian
TI Edge-aware salient object detection network via context guidance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; Saliency; Context guidance; Attention;
   Multi-scale feature
AB Fully convolutional network (FCN) based salient object detection methods have shown their advantages in highlighting salient regions because they can obtain global semantic information. And the high-level semantics are usually passed in a top-down pathway. However, the semantic information would be diluted progressively among different level features. To alleviate this issue, we propose a novel edge-aware salient object detection network. Our network utilizes high-level semantic information to assist the feature selection of shallower layers. Specifically, we extract refined features from different levels of the backbone. Then, we obtain global contextual information to locate the salient objects by extracting multi-scale features and emphasizing the important feature channels. In order to assist the shallower layers to pay attention to the learning of meaningful local information, we adopt a context guidance strategy to fuse the high-level and low-level information. Finally, we supervise the generation of low-level edge information to preserve the salient object boundaries. Extensive experiments demonstrate that the proposed mode performs favorably against most state-of-the-art methods under different evaluation metrics on six popular benchmarks.& nbsp; (c) 2021 Published by Elsevier B.V.
C1 [Chen, Xiaowei; Zhang, Qing; Zhang, Liqian] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
C3 Shanghai Institute of Technology
RP Zhang, Q (corresponding author), Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
EM zhangqing@sit.edu.cn
RI li, yao/IYJ-1364-2023; liu, xq/JDW-2596-2023; Yang, Ying/ABD-2481-2022;
   Li, Ly/JCD-4746-2023; Liu, Gui/JHU-8707-2023
FU Natural Science Foundation of Shanghai [19ZR1455300]; National Natural
   Science Foundation of China [61806126]
FX This work is supported by Natural Science Foundation of Shanghai under
   Grant No.19ZR1455300 and National Natural Science Foundation of China
   under Grant No.61806126.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Adam H., 2017, INT C COMP VIS PATT
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   FANG D, 2018, P EUR C COMP VIS, P186
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hu J., P IEEE C COMPUTER VI, P7132
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Máttyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Mohammadi S, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107303
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang L, 2018, IEEE IPCCC
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu YY, 2019, IEEE I CONF COMP VIS, P3788, DOI 10.1109/ICCV.2019.00389
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 57
TC 7
Z9 8
U1 1
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104166
DI 10.1016/j.imavis.2021.104166
EA APR 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700007
DA 2024-07-18
ER

PT J
AU Liu, G
   Zhao, LL
   Fang, XZ
AF Liu, Ge
   Zhao, Linglan
   Fang, Xiangzhong
TI PDA: Proxy-based domain adaptation for few-shot image recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Few-shot image recognition; Domain adaptation; Few-shot learning;
   Transfer learning
AB Learning from limited supervision is a challenging problem that has recently attracted wide attention in the ma -chine learning community. With scarce annotated samples available in target categories, so-called few-shot image recognition aims to transfer basic knowledge from a large-scale image set to recognize unseen classes. Many existing approaches tend to learn a general source data representation and apply it to address the few-shot task by building a target classifier on scare support features, which performs favorably only if source and target data distributions are similar. We argue that ignoring the distribution gap and directly leveraging fro -zen representations lead to a sub-optimal solution. Taking domain shift into consideration, we explore an effi-cient task adaptation strategy that can jointly achieve task and domain transfer. Accordingly, we propose a simple yet effective method, called proxy-based domain adaptation (PDA), to optimize the pre-trained represen-tation and a target classifier simultaneously. PDA can be characterized as: (1) a source-data-independent ap-proach that only leverages few support data from the target domain (2) a non-parametric adaptation method that performs model adaptation by minimizing a designed loss without involving any parametric modules addi-tionally. We extensively conduct experiments on multiple few-shot image recognition benchmarks, highlighting the superiority of PDA over many SOTA methods. Besides, careful ablation studies verify each component's effec-tiveness in our method and demonstrate the significance of domain adaptation in few-shot image recognition.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Ge; Zhao, Linglan; Fang, Xiangzhong] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Liu, G (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.
EM liu.ge@sjtu.edu.cn
OI Zhao, Linglan/0000-0002-2241-6977
CR Afrasiyabi Arman, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P18, DOI 10.1007/978-3-030-58558-7_2
   Bertinetto Luca, 2019, PROC INT C LEARN REP
   Chen W.Y., 2019, ICLR, DOI DOI 10.1109/MSR.2015.54
   Chen Y., 2020, ARXIV200304390
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Dvornik N., 2020, EUR C COMP VIS ECCV
   Dvornik N, 2019, IEEE I CONF COMP VIS, P3722, DOI 10.1109/ICCV.2019.00382
   Finn C, 2017, PR MACH LEARN RES, V70
   Ganin Y., 2015, ICML
   Gidaris S, 2019, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2019.00011
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermann KM, 2015, ADV NEURAL INFORM PR, V28, P1693
   Kang BY, 2019, IEEE I CONF COMP VIS, P8419, DOI 10.1109/ICCV.2019.00851
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li H., 2019, P IEEE CVF C COMP VI, P9522, DOI [DOI 10.1109/CVPR.2019.00975, 10.1109/CVPR.2019.00975]
   Li R., 2020, P IEEE CVF C COMP VI, P9641, DOI DOI 10.1109/CVPR42600.2020.00966
   Li WB, 2019, AAAI CONF ARTIF INTE, P8642
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Lifchitz Y, 2019, PROC CVPR IEEE, P9250, DOI 10.1109/CVPR.2019.00948
   Liu B., 2020, ARXIV PREPRINT ARXIV
   Liu WY, 2016, PR MACH LEARN RES, V48
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Qi H, 2018, PROC CVPR IEEE, P5822, DOI 10.1109/CVPR.2018.00610
   Ravi S., 2016, INT C LEARN REPR ICL
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A. A., 2019, INT C LEARN REPR
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Snell J, 2017, ADV NEUR IN, V30
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Thrun S, 1998, LEARNING TO LEARN, P181
   Tian Y., 2020, EUR C COMP VIS ECCV, P9
   Tzeng E., 2014, ARXIV14123474
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wang Yan, 2019, CoRR
   Yosinski J, 2014, ADV NEUR IN, V27
NR 44
TC 9
Z9 9
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104164
DI 10.1016/j.imavis.2021.104164
EA MAR 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700011
DA 2024-07-18
ER

PT J
AU Wang, WM
   You, Y
   Liu, WH
   Lu, CW
AF Wang, Weiming
   You, Yang
   Liu, Wenhai
   Lu, Cewu
TI Point cloud classification with deep normalized Reeb graph convolution
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Reeb graph; Point cloud; Graph normalization
ID RECOGNITION
AB Recently, plenty of deep learning methods have been proposed to handle point clouds. Almost all of them input the entire point cloud and ignore the information redundancy lying in point clouds. This paper addresses this problem by extracting the Reeb graph from point clouds, which is a much more informative and compact representation of point clouds, and then filter the graph with deep graph convolution. To be able to classify or segment point clouds well, we propose (1) Graph Normalization to transform various graphs into a canonical graph space; (2) Normalized Similarity Distance to better identify the graph structure;(3) Reeb Graph Guided Node Pooling in order to aggregate high-level features from kNN graphs. Besides, our method naturally fits into the problem of classifying point clouds with unknown orientations. In the results, we show that our method gives a competitive performance to the state-of-the-art methods and outperforms previous methods by a large margin on handling point clouds with unknown orientations. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Wang, Weiming; You, Yang; Liu, Wenhai] Shanghai Jiao Tong Univ, Dept Mech & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Lu, Cewu] Shanghai Jiao Tong Univ, Dept Eletron Informat & Elect Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Wang, Weiming; You, Yang; Liu, Wenhai; Lu, Cewu] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai
   Jiao Tong University
RP Wang, WM (corresponding author), Shanghai Jiao Tong Univ, Dept Mech & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM wangweiming@sjtu.edu.cn; qq456cvb@sjtu.edu.cn; sjtu-wenhai@sjtu.edu.cn;
   lucewu@sjtu.edu.cn
RI You, Yang/GQQ-9174-2022; Liu, Wenhai/JCE-5367-2023; You,
   Yang/ADR-4244-2022
OI Liu, Wenhai/0000-0003-0166-7774; 
FU National Natural Science Foundation of China [51675342, 51975350];
   Shanghai industrial foundation project [GYQJ-20118-1-13]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 51675342, and Grant 51975350. This work was also
   supported by the Shanghai industrial foundation project
   (GYQJ-20118-1-13).
CR [Anonymous], 2017, CoRR
   [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2018, PointSIFT: A SIFT-like Network Module for 3D Point Cloud Semantic Segmentation
   Armeni I, 2016, PROC CVPR IEEE, P1534, DOI 10.1109/CVPR.2016.170
   Barrow Harry G, 1977, Tech. Rep.
   Bauer U., 2014, P 30 ANN S COMP GEOM, P464
   Berretti S, 2009, IMAGE VISION COMPUT, V27, P1540, DOI 10.1016/j.imavis.2009.02.004
   Biasotti S, 2008, MATH VIS, P145, DOI 10.1007/978-3-540-33265-7_5
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Carlsson G.E., SPBG, P91
   Chen SH, 2017, INT CONF ACOUST SPEE, P2941, DOI 10.1109/ICASSP.2017.7952695
   Cohen T.S., 2018, P 6 INT C LEARN REPR, P1
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Defferrard M, 2016, ADV NEUR IN, V29
   Fabry T., 2008, IEEE 2 INT C BIOM TH, P1
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Kim DI, 2014, IEEE INT CONF ROBOT, P5578, DOI 10.1109/ICRA.2014.6907679
   Kim P, 2018, AUTOMAT CONSTR, V89, P38, DOI 10.1016/j.autcon.2018.01.009
   King DB, 2015, ACS SYM SER, V1214, P1
   Kipf TN, 2016, ARXIV
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Li Yaguang, 2018, INT C LEARN REPR
   Liu X, 2018, INT CONF DAT MIN WOR, P905, DOI 10.1109/ICDMW.2018.00132
   Lozes F, 2015, IEEE SIGNAL PROC MAG, V32, P103, DOI 10.1109/MSP.2015.2408631
   Mahmoudi M, 2009, GRAPH MODELS, V71, P22, DOI 10.1016/j.gmod.2008.10.002
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Natali M, 2011, GRAPH MODELS, V73, P151, DOI 10.1016/j.gmod.2011.03.002
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Smeets D, 2012, IEEE T SYST MAN CY C, V42, P710, DOI 10.1109/TSMCC.2011.2174221
   Solomon J.M, 2018, ACM T GRAPHIC, DOI DOI 10.1145/3326362
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sung M., 2018, ARXIV PREPRINT ARXIV
   Tchapmi LP, 2017, INT CONF 3D VISION, P537, DOI 10.1109/3DV.2017.00067
   Thanou D, 2016, IEEE T IMAGE PROCESS, V25, P1765, DOI 10.1109/TIP.2016.2529506
   Tierny J, 2009, IEEE T VIS COMPUT GR, V15, P1177, DOI 10.1109/TVCG.2009.163
   Tombari F., 2010, P ACM WORKSH 3D OBJ, P57, DOI DOI 10.1145/1877808.1877821
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Whitty M., 2010 AUSTR C ROB AUT, P1
   Wu B., 2018, ARXIV PREPRINT ARXIV
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   You Y, 2018, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2018), P307, DOI 10.1145/3205289.3205290
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu YT, 2015, IEEE T INTELL TRANSP, V16, P2167, DOI 10.1109/TITS.2015.2399492
   Yue XY, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P458, DOI 10.1145/3206025.3206080
   Zaheer Manzil, 2017, P ADV NEURAL INFORM, P3391
   Zhang Y., 2018, 2018 IEEE INT C AC S
NR 54
TC 8
Z9 10
U1 1
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104092
DI 10.1016/j.imavis.2020.104092
EA JAN 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700003
DA 2024-07-18
ER

PT J
AU Yu, Y
   Xu, LD
   Jia, W
   Zhu, WJ
   Fu, YX
   Lu, Q
AF Yu, Ye
   Xu, Longdao
   Jia, Wei
   Zhu, Wenjia
   Fu, Yunxiang
   Lu, Qiang
TI CAM: A fine-grained vehicle model recognition method based on visual
   attention model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vehicle model recognition; Visual attention mechanism; Long short-term
   memory (LSTM) network; Convolutional LSTM
AB Vehicle model recognition (VMR) is a typical fine-grained classification task in computer vision. To improve the representation power of classical CNN networks for this special task, we focus on enhancing the subtle difference of features and their spatial encoding based on the attention mechanism, and then propose a novel architectural unit, which we term the "convolutional attention model" (CAM). It adopts a two-stage attention mechanism for VMR, which includes the global feature map attention (GFMA) algorithm, applied at the lower part of the main network flow to enhance the subtle feature difference from the beginning, and the feature spatial relationship attention (FSRA) algorithm, applied at the higher part to enhance the spatial relationship of features. The experiments are conducted on the benchmark CompCars web-nature and Stanford Car datasets and demonstrate the effectiveness of CAM when integrated with some classical CNN architectures. CAM can improve the top-1 recognition accuracy by an average of 1.15% and top-5 by an average of 0.78%. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Yu, Ye; Xu, Longdao; Jia, Wei; Fu, Yunxiang; Lu, Qiang] Hefei Univ Technol, Sch Comp & Informat, Hefei 230601, Peoples R China.
   [Yu, Ye; Xu, Longdao; Jia, Wei; Fu, Yunxiang; Lu, Qiang] Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Peoples R China.
   [Zhu, Wenjia] Anhui Baicheng Huitong Co Ltd, Hefei 230088, Peoples R China.
C3 Hefei University of Technology
RP Jia, W (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230601, Peoples R China.; Jia, W (corresponding author), Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Peoples R China.
EM china.jiawei@139.com
RI Lu, Qiang/AAU-9248-2020; Yu, Ye/JDX-1258-2023; zhu, wenjia/AAP-1277-2020
FU National Natural Science Foundation of China [61906061, 62076086,
   61972130]; Provincial Key Research and Development Program of Anhui
   Province [201904d07020010, 202004d07020008]
FX This work is partly supported by the grants of the National Natural
   Science Foundation of China, No. 61906061, 62076086 and 61972130, and
   partly supported by the grant of the Provincial Key Research and
   Development Program of Anhui Province, No. 201904d07020010,
   202004d07020008.
CR [Anonymous], 2014, IEEE INT C DES AUT T
   Nogra JA, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P62, DOI 10.1109/CCOMS.2019.8821789
   Awani AB, 2014, 2014 NATIONAL SOFTWARE ENGINEERING CONFERENCE (NSEC - 2014), P25, DOI 10.1109/NSEC.2014.6998236
   Bai Y, 2017, IEEE INT CON MULTI, P1452, DOI 10.1109/ICME.2017.8019371
   Biglari M, 2018, IEEE T INTELL TRANSP, V19, P273, DOI 10.1109/TITS.2017.2749961
   Chorowski Jan K, 2015, ADV NEURAL INFORM PR, DOI [DOI 10.1016/0167-739X(94)90007-8, 10.1016/j.asr.2015.02.035, DOI 10.1016/J.ASR.2015.02.035]
   Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325
   Dai XY, 2017, IEEE INT CONF COMP V, P996, DOI 10.1109/ICCVW.2017.122
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315
   Hajiaghayi M, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (IEEE BIGDATASERVICE 2019), P55, DOI 10.1109/BigDataService.2019.00014
   He HS, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2437998
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu B, 2017, NEUROCOMPUTING, V243, P60, DOI 10.1016/j.neucom.2017.02.085
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krause J, 2014, INT C PATT RECOG, P26, DOI 10.1109/ICPR.2014.15
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li X., 2019, SEMANTIC BILINEAR PO
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Medina JR, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P547, DOI 10.1109/ICMLA.2018.00088
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Shi X., 2015, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.1506.04214
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sochor J, 2016, PROC CVPR IEEE, P3006, DOI 10.1109/CVPR.2016.328
   Soon FC, 2019, IEEE T INTELL TRANSP, V20, P749, DOI 10.1109/TITS.2018.2833620
   Sridevi T, 2017, IEEE INT ADV COMPUT, P566, DOI [10.1109/IACC.2017.0122, 10.1109/IACC.2017.113]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Zhang YW, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P1052, DOI 10.1109/ICCT.2018.8599961
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zhao DB, 2017, IEEE T COGN DEV SYST, V9, P356, DOI 10.1109/TCDS.2016.2614675
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhu YS, 2019, IEEE T IMAGE PROCESS, V28, P113, DOI 10.1109/TIP.2018.2865280
NR 40
TC 9
Z9 10
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104027
DI 10.1016/j.imavis.2020.104027
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800011
OA Bronze
DA 2024-07-18
ER

PT J
AU Altameem, T
   Altameem, A
AF Altameem, Torki
   Altameem, Ayman
TI Facial expression recognition using human machine interaction and
   multi-modal visualization analysis for healthcare applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CNN; Computer vision; Face visualization; Healthcare systems;
   Human-machine interaction
ID VISION
AB The application of computer vision (CV) in healthcare applications is familiarwith the wireless and communication technology. CVmethods are incorporated in the healthcare for providing programmed interactions towards patientmonitoring. The requirements of systems are the analysis and detection of the images' visualization of patients. In this paper, a multi-modal visualization analysis (MMVA) method is introduced for improving the lesscomplex processing nature of programmed human-machine interactions (HMI) in health monitoring. In particular, the proposed method is designed to identify facial expressions of a patient using facial expression and textures of the input visualization. The proposedmethod relies on three layers of convolution neural network (CNN) for texture classification, correlation, and detection of facial visualization using stored information. The processes of the three-layers are chained to reduce the complexity and misdetection in the analysis. The feature-based tuning chain in the first layer of CNN attains to minimize the impact of facial and textural variants resulting in misdetection. The second layer is a correlation to attain the accurate matching of expression from the captured image. The third layer is facial visualization to find the quick decision and used to store the error data as the training set. The experimental results show that proposed method achieves 95.702% of recognition accuracy compared to other conventional methods. The analysis time and misdetection are minimized. Also, the recognition ratio is improved. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Altameem, Torki] King Saud Univ, Comp Sci, CC, Riyadh, Saudi Arabia.
   [Altameem, Ayman] King Saud Univ, Coll Appl Studies, Riyadh, Saudi Arabia.
C3 King Saud University; King Saud University
RP Altameem, T (corresponding author), King Saud Univ, Comp Sci, CC, Riyadh, Saudi Arabia.
EM altameem@ksu.edu.sa
FU Deanship of Scientific Research at King Saud University [RGP -1436-035]
FX The authors would like to extend their sincere appreciation to the
   Deanship of Scientific Research at King Saud University for its funding
   this research group No. (RGP -1436-035).
CR Alsiddiky A, 2020, MEASUREMENT, V159, DOI 10.1016/j.measurement.2020.107772
   [Anonymous], 2019, IEEE ACCESS, DOI DOI 10.1109/ACCESS.2019.2945423
   Beringer M, 2019, COGN SYST RES, V56, P119, DOI 10.1016/j.cogsys.2019.03.009
   Brunetti A, 2018, NEUROCOMPUTING, V300, P17, DOI 10.1016/j.neucom.2018.01.092
   Chen LF, 2020, IEEE T SYST MAN CY-S, V50, P490, DOI 10.1109/TSMC.2017.2756447
   Del Coco M, 2018, IEEE T COGN DEV SYST, V10, P993, DOI 10.1109/TCDS.2017.2783684
   Deng J, 2019, IEEE ACCESS, V7, P9848, DOI 10.1109/ACCESS.2019.2891668
   Erol BA, 2020, IEEE T COMPUT SOC SY, V7, P234, DOI 10.1109/TCSS.2019.2922593
   Fouad H, 2022, NEURAL COMPUT APPL, V34, P13133, DOI 10.1007/s00521-020-04935-2
   Fouad H, 2020, IEEE ACCESS, V8, P17299, DOI 10.1109/ACCESS.2020.2966272
   Hsu GSJ, 2019, IEEE ACCESS, V7, P4833, DOI 10.1109/ACCESS.2018.2884969
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Liliana DY, 2019, COGN PROCESS, V20, P391, DOI 10.1007/s10339-019-00923-0
   Lotti G, 2019, IFAC PAPERSONLINE, V52, P31, DOI 10.1016/j.ifacol.2019.12.080
   Mahmoud NM, 2020, CLUSTER COMPUT, V23, P1647, DOI 10.1007/s10586-020-03104-3
   Revina IM, 2021, J KING SAUD UNIV-COM, V33, P392, DOI 10.1016/j.jksuci.2018.03.015
   Ruiz-Garcia A, 2018, NEURAL COMPUT APPL, V29, P359, DOI 10.1007/s00521-018-3358-8
   Sadeghi H, 2019, MULTIMED TOOLS APPL, V78, P30335, DOI 10.1007/s11042-019-07863-z
   Sajjad M, 2018, CLUSTER COMPUT, V21, P549, DOI 10.1007/s10586-017-0935-z
   Samara A, 2019, J AMB INTEL HUM COMP, V10, P2175, DOI 10.1007/s12652-017-0636-8
   Shakeel PM, 2020, INT J TECHNOL HUM IN, V16, P94, DOI 10.4018/IJTHI.2020010107
   Shakeel PM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1045-z
   Shi M, 2020, IEEE ACCESS, V8, P57606, DOI 10.1109/ACCESS.2020.2982286
   Shi Y., 2019, J VIS COMMUN IMAGE R
   Storey G, 2019, IEEE ACCESS, V7, P121655, DOI 10.1109/ACCESS.2019.2937285
   Tsai HH, 2018, SOFT COMPUT, V22, P4389, DOI 10.1007/s00500-017-2634-3
   Ulusoy SI, 2020, GEN HOSP PSYCHIAT, V65, P9, DOI 10.1016/j.genhosppsych.2020.04.008
   Wang FY, 2019, J VIS COMMUN IMAGE R, V59, P84, DOI 10.1016/j.jvcir.2018.11.010
   Wu HT, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.103031
   Xiao GR, 2020, MECH SYST SIGNAL PR, V142, DOI 10.1016/j.ymssp.2020.106736
   Yousefi B, 2018, APPL SOFT COMPUT, V62, P57, DOI 10.1016/j.asoc.2017.10.021
NR 32
TC 19
Z9 19
U1 6
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104044
DI 10.1016/j.imavis.2020.104044
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000017
DA 2024-07-18
ER

PT J
AU Wang, HD
   Wang, SZ
   Lv, JY
   Hu, CM
   Li, ZY
AF Wang, Haidong
   Wang, Saizhou
   Lv, Jingyi
   Hu, Chenming
   Li, Zhiyong
TI Non-local attention association scheme for online multi-object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Data association; Multi-object tracking; Non-local attention
AB Online multi-object tracking (MOT) is a fundamental problem in video analysis and multimedia applications. The major challenge in the popular tracking-by-detection framework is knowing how to associate candidate detections results with existing tracklets. In this, we propose a non-local attention association approach and apply it to a unified online MOT framework that integrates the merits of single object tracking and data association methods. Specifically, we use non-local attention association networks (NAAN) to incorporate both spatial and temporal characteristics to associate new detections. The non-local attention mechanism generates global attention maps across space and time, enabling the network to focus on the whole tracklet information, as opposed to the local attention mechanism to overcome the problems of noisy detections, occlusion, and frequent interactions between targets. Experimental results on MOT benchmark datasets show that the proposed algorithm performs favorably against various online trackers on the basis of identity-preserving metrics. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Wang, Haidong; Wang, Saizhou; Lv, Jingyi; Hu, Chenming; Li, Zhiyong] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University
RP Li, ZY (corresponding author), Key Lab Embedded & Network Comp, Changsha 410082, Hunan, Peoples R China.
EM zhiyong.li@hnu.edu.cn
RI li, zy/HZM-1892-2023; wang, qi/ITT-9652-2023; Liu, Kai/IST-6808-2023;
   Liu, Chang/ISV-3950-2023
OI Wang, Haidong/0000-0002-4614-5817
FU National Key Research and Development Program of China [2018YFB1308604];
   National Natural Science Foundation of China [61672215, 61976086]; Hunan
   Science and Technology Innovation Project [2017XK2102]
FX This work was partially supported by National Key Research and
   Development Program of China (No.2018YFB1308604), National Natural
   Science Foundation of China (No.61672215, No.61976086) and Hunan Science
   and Technology Innovation Project (No.2017XK2102).
CR [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, ASK ATTEND ANSWER EX
   Bae S.H., 2018, IEEE T PATTERN ANAL
   Ban YT, 2016, LECT NOTES COMPUT SC, V9914, P52, DOI 10.1007/978-3-319-48881-3_5
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen JJ, 2017, LECT NOTES COMPUT SC, V10261, P18, DOI 10.1007/978-3-319-59072-1_3
   Chen X., 2014, Learning a Recurrent Visual Representation for Image Caption Generation
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Geiger A., 2012, CVPR
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Jiang X., 2019, ARXIV190705315
   Kieritz H, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P122, DOI 10.1109/AVSS.2016.7738059
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   Li ZL, 2016, OXID MED CELL LONGEV, V2016, P12, DOI DOI 10.1007/S10529-016-2066-7
   Milan A., 2016, ARXIV160300831
   Nai K, 2018, IEEE T IMAGE PROCESS, V27, P4958, DOI 10.1109/TIP.2018.2848465
   Paszke A., 2019, ADV NEURAL INFORM PR, P8026, DOI DOI 10.48550/ARXIV.1912.01703
   Ren S., 2020, INT C NEUR INF PROC, P91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sheng Hao., 2018, IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)
   Tang S, 2017, ROUTL RES GEND ASIA, P170
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Yang F, 2016, PROCEEDINGS OF THE BATH/ASME SYMPOSIUM ON FLUID POWER AND MOTION CONTROL
   Zhang L., 2008, 2008 IEEE COMP SOC C
   Zheng YM, 2013, IEEE T IND INFORM, V9, P2318, DOI 10.1109/TII.2012.2228875
NR 34
TC 6
Z9 6
U1 1
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103983
DI 10.1016/j.imavis.2020.103983
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700008
DA 2024-07-18
ER

PT J
AU Islam, K
AF Islam, Khawar
TI Person search: New paradigm of person re-identification: A survey and
   outlook of recent works
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Person search; Literature survey; Metric
   learning; Loss functions
ID NETWORK; ATTENTION
AB Person Search (PS) has become a major field because of its need in community and in the field of research among researchers. This task aims to find a probe person from whole scene which shows great significance in video surveillance field to track lost people, re-identification, and verification of person. In last few years, deep learning has played unremarkable role for the solution of re-identification problem. Deep learning shows incredible performance in person (re-ID) and search. Researchers experience more flexibility in proposing new methods and solve challenging issues such as low resolution, pose variation, background clutter, occlusion, viewpoints, and low illumination. Specially, convolutional neural network (CNN) achieves breakthrough performance and extracts useful patterns and characteristics. Development of new framework takes substantial efforts; hard work and computation cost are required to acquire excellent results. This survey paper includes brief discussion about feature representation learning and deep metric learning with novel loss functions. We thoroughly review datasets with performance analysis on existing datasets. Finally, we are reviewing current solutions for further consideration. (C) 2020 The Author. Published by Elsevier B.V.
C1 [Islam, Khawar] FloppyDiskAI, Karachi, Pakistan.
RP Islam, K (corresponding author), FloppyDiskAI, Karachi, Pakistan.
EM khawar512@gmail.com
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Ainam JP, 2019, IEEE ACCESS, V7, P27899, DOI 10.1109/ACCESS.2019.2901599
   [Anonymous], 2018, ARXIV180705284
   [Anonymous], 2016, CORR
   [Anonymous], 2016, ARXIV
   [Anonymous], Simple baseline for visual question answering
   [Anonymous], 2018, ARXIV181210305
   [Anonymous], 2013, ARXIV13075748
   Bedagkar-Gala A., 2014, Asian Conference on Computer Vision, P633
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Carley C, 2019, IEEE COMPUT SOC CONF, P2345, DOI 10.1109/CVPRW.2019.00288
   Chang XJ, 2018, LECT NOTES COMPUT SC, V11213, P86, DOI 10.1007/978-3-030-01240-3_6
   Chen D, 2018, LECT NOTES COMPUT SC, V11211, P764, DOI 10.1007/978-3-030-01234-2_45
   Chen GY, 2019, IEEE T IMAGE PROCESS, V28, P4192, DOI 10.1109/TIP.2019.2908062
   Chen Y., 2018, ARXIV180807301
   Chu X, 2016, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2016.510
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   D'Orazio T, 2012, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2012.6467181
   Dong YY, 2017, 2016 INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION, BIG DATA & SMART CITY (ICITBS), P225, DOI 10.1109/ICITBS.2016.57
   El-Alfy ESM, 2019, J AMB INTEL HUM COMP, V10, P2495, DOI 10.1007/s12652-018-0728-0
   Gao CY, 2019, NEUROCOMPUTING, V369, P29, DOI 10.1016/j.neucom.2019.08.038
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4
   Gong S., 2014, ADV COMPUTER VISION, P301
   Han CC, 2019, IEEE I CONF COMP VIS, P9813, DOI 10.1109/ICCV.2019.00991
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Z., 2018, ACCV, P349
   Hong ZR, 2019, IEEE ACCESS, V7, P139692, DOI 10.1109/ACCESS.2019.2943112
   Howard A. G., 2017, PREPRINT
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang QQ, 2018, LECT NOTES COMPUT SC, V11217, P437, DOI 10.1007/978-3-030-01261-8_26
   Ji Z, 2018, PATTERN RECOGN LETT, V116, P205, DOI 10.1016/j.patrec.2018.10.020
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan X, 2018, LECT NOTES COMPUT SC, V11205, P553, DOI 10.1007/978-3-030-01246-5_33
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li JH, 2019, IEEE INT CON MULTI, P1114, DOI 10.1109/ICME.2019.00195
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao GH, 2008, I C COMP AID DES CON, P680, DOI 10.1109/CAIDCD.2008.4730656
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu H, 2017, IEEE I CONF COMP VIS, P493, DOI 10.1109/ICCV.2017.61
   Liu H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1668, DOI 10.1109/ICASSP.2018.8462484
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loesch A, 2019, IEEE IMAGE PROC, P4574, DOI [10.1109/icip.2019.8803643, 10.1109/ICIP.2019.8803643]
   Lu Y, 2019, IEEE IMAGE PROC, P3935, DOI [10.1109/ICIP.2019.8803580, 10.1109/icip.2019.8803580]
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Munjal Bharti, 2019, BMVC
   Nambiar A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3243043
   Ouyang DQ, 2019, PATTERN RECOGN LETT, V117, P153, DOI 10.1016/j.patrec.2018.05.009
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Rao S., 2018, ARXIV181011261
   Ren M., 2015, Proc Adv Neural Inf Process Syst, V1, P5
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saghafi MA, 2014, IET COMPUT VIS, V8, P455, DOI 10.1049/iet-cvi.2013.0180
   Shi W, 2018, IEEE IMAGE PROC, P4108, DOI 10.1109/ICIP.2018.8451028
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang KJ, 2018, CAAI T INTELL TECHNO, V3, P219, DOI 10.1049/trit.2018.1001
   Wang Lingxiao, 2017, ARXIV171109515
   Wang YY, 2019, INT CONF ACOUST SPEE, P2057, DOI 10.1109/ICASSP.2019.8682456
   Wang Z., 2020, IJCAI
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Xiao JM, 2019, PATTERN RECOGN, V87, P332, DOI 10.1016/j.patcog.2018.10.028
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Xu YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P937, DOI 10.1145/2647868.2654965
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yang JF, 2017, COMM COM INF SC, V773, P315, DOI 10.1007/978-981-10-7305-2_28
   Ye Mang, 2020, ARXIV200104193
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Zhai S., 2019, MULTIMED TOOLS APPL, P1
   Zheng D., 2019, ARXIV190810179
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zijie Z., 2018, ICME, V5, P8
NR 86
TC 34
Z9 34
U1 3
U2 41
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2020
VL 101
AR 103970
DI 10.1016/j.imavis.2020.103970
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NP4HG
UT WOS:000570137900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, JY
   Bai, TY
AF Chen, Junying
   Bai, Tongyao
TI SAANet: Spatial adaptive alignment network for object detection in
   automatic driving
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Fusion-based deep framework; Local orientation
   encoding; Spatial adaptive alignment; Autonomous driving
AB images and point clouds are beneficial for object detection in a visual navigation module for autonomous driving. The spatial relationships between different objects at different times in a bimodal space can vary significantly. It is difficult to combine bimodal descriptions into a unified model to effectively detect objects in an efficient amount of time. In addition, conventional voxelization methods resolve point clouds into voxels at a global level, and often overlook local attributes of the voxels. To address these problems, we propose a novel fusionbased deep framework named SAANet. SAANet utilizes a spatial adaptive alignment (SAA) module to align point cloud features and image features, by automatically discovering the complementary information between point clouds and images. Specifically, we transform the point clouds into 3D voxels, and introduce local orientation encoding to represent the point clouds. Then, we use a sparse convolutional neural network to learn a point cloud feature. Simultaneously, a ResNet-like 2D convolutional neural network is used to extract an image feature. Next, the point cloud feature and image feature are fused by our SAA block to derive a comprehensive feature. Then, the labels and 3D boxes for objects are learned using a multi-task learning network Finally, an experimental evaluation on the KITFI benchmark demonstrates the advantages of our method in terms of average precision and inference time, as compared to previous state-of-the-art results for 3D object detection. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Chen, Junying; Bai, Tongyao] Xian Univ Architecture & Technol, Sch Informat & Control Engn, Xian 710055, Peoples R China.
C3 Xi'an University of Architecture & Technology
RP Chen, JY; Bai, TY (corresponding author), Xian Univ Architecture & Technol, Sch Informat & Control Engn, Xian 710055, Peoples R China.
EM vcjy2019@gmail.com; tongyaobai@gmail.com
FU Foundation of the China Scholarship Council [201808615030]
FX This work was supported by the Foundation of the China Scholarship
   Council under grant no. 201808615030.
CR [Anonymous], 2015, ROBOTICS SCI SYSTEMS
   [Anonymous], 2005, P IEEE COMP SOC C CO
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   González A, 2015, IEEE INT VEH SYM, P356, DOI 10.1109/IVS.2015.7225711
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Ku J, 2019, PROC CVPR IEEE, P11859, DOI 10.1109/CVPR.2019.01214
   Li B, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668
   Premebida C, 2014, IEEE INT C INT ROBOT, P4112, DOI 10.1109/IROS.2014.6943141
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00
   Tuzel O, 2014, LECT NOTES COMPUT SC, V8689, P520, DOI 10.1007/978-3-319-10590-1_34
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 33
TC 19
Z9 21
U1 3
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103873
DI 10.1016/j.imavis.2020.103873
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900013
DA 2024-07-18
ER

PT J
AU Panagiotakis, C
   Argyros, A
AF Panagiotakis, Costas
   Argyros, Antonis
TI Region-based Fitting of Overlapping Ellipses and its application to
   cells segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cell segmentation; 2D shape modeling; Overlapping objects; Ellipse
   fitting; AIC
ID LEVEL SET METHOD; IMAGE SEGMENTATION; ROBUST
AB We present RFOVE, a region-based method for approximating an arbitrary 2D shape with an automatically determined number of possibly overlapping ellipses. RFOVE is completely unsupervised, operates without any assumption or prior knowledge on the object's shape and extends and improves the Decremental Ellipse Fitting Algorithm (DEFA) [1]. Both RFOVE and DEFA solve the multi-ellipse fitting problem by performing model selection that is guided by the minimization of the Akaike Information Criterion on a suitably defined shape complexity measure. However, in contrast to DEFA, RFOVE minimizes an objective function that allows for ellipses with higher degree of overlap and, thus, achieves better ellipse-based shape approximation. A comparative evaluation of RFOVE with DEFA on several standard datasets shows that RFOVE achieves better shape coverage with simpler models (less ellipses). As a practical exploitation of RFOVE, we present its application to the problem of detecting and segmenting potentially overlapping cells in fluorescence microscopy images. Quantitative results obtained in three public datasets (one synthetic and two with more than 4000 actual stained cells) show the superiority of RFOVE over the state of the art in overlapping cells segmentation. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Panagiotakis, Costas] Hellenic Mediterranean Univ, Management Sci & Technol Dept, Agios Nikolaos 72100, Crete, Greece.
   [Argyros, Antonis] Univ Crete, Comp Sci Dept, Iraklion 70013, Crete, Greece.
   [Panagiotakis, Costas; Argyros, Antonis] FORTH, Inst Comp Sci, Iraklion 70013, Crete, Greece.
C3 University of Crete; Foundation for Research & Technology - Hellas
   (FORTH)
RP Panagiotakis, C (corresponding author), Hellenic Mediterranean Univ, Management Sci & Technol Dept, Agios Nikolaos 72100, Crete, Greece.
EM cpanag@ics.forth.gr; argyros@ics.forth.gr
RI Argyros, Antonis/GPK-4775-2022; Argyros, Antonis/AAD-9251-2019;
   Panagiotakis, Costas/K-8603-2014; Panagiotakis, Costas/I-5115-2019
OI Argyros, Antonis/0000-0001-8230-3192; Panagiotakis,
   Costas/0000-0003-3680-7087
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   [Anonymous], [No title captured]
   Bai XZ, 2009, PATTERN RECOGN, V42, P2434, DOI 10.1016/j.patcog.2009.04.003
   Ben XY, 2012, NEUROCOMPUTING, V79, P173, DOI 10.1016/j.neucom.2011.10.009
   Bergeest JP, 2012, MED IMAGE ANAL, V16, P1436, DOI 10.1016/j.media.2012.05.012
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Chen YT, 2010, PATTERN RECOGN, V43, P3699, DOI 10.1016/j.patcog.2010.05.027
   Choi E, 2003, PATTERN RECOGN, V36, P1703, DOI 10.1016/S0031-3203(03)00035-9
   Coelho L. P., 2009, P 2009 IEEE INT S BI
   COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327
   Da Xu RY, 2010, IEEE T IMAGE PROCESS, V19, P1673, DOI 10.1109/TIP.2010.2045071
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Fornaciari M, 2014, PATTERN RECOGN, V47, P3693, DOI 10.1016/j.patcog.2014.05.012
   Gharipour A, 2016, PATTERN RECOGN, V58, P1, DOI 10.1016/j.patcog.2016.03.030
   Goldfeder C, 2007, IEEE INT CONF ROBOT, P4679, DOI 10.1109/ROBOT.2007.364200
   He T, 2017, IMAGE VISION COMPUT, V60, P142, DOI 10.1016/j.imavis.2016.11.010
   Huang JY, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P93
   Ibtehaz N., 2019, MultiResUNet: Rethinking the U-Net Architecture for Multimodal Biomedical Image Segmentation
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Ji Q, 2002, IMAGE VISION COMPUT, V20, P499, DOI 10.1016/S0262-8856(02)00024-0
   KASA I, 1976, IEEE T INSTRUM MEAS, V25, P8, DOI 10.1109/TIM.1976.6312298
   Kimia B., 2002, A Large Binary Image Database
   Kyriazis N, 2014, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2014.438
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Leonardis A, 1997, IEEE T PATTERN ANAL, V19, P1289, DOI 10.1109/34.632988
   Levinshtein A, 2018, IMAGE VISION COMPUT, V71, P17, DOI 10.1016/j.imavis.2018.01.003
   Liao M, 2016, NEUROCOMPUTING, V173, P615, DOI 10.1016/j.neucom.2015.08.006
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601
   Mai F, 2008, PATTERN RECOGN, V41, P2512, DOI 10.1016/j.patcog.2008.01.027
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panagiotakis C, 2007, PATTERN RECOGN LETT, V28, P582, DOI 10.1016/j.patrec.2006.10.005
   Panagiotakis C, 2018, IEEE IMAGE PROC, P2426, DOI 10.1109/ICIP.2018.8451852
   Panagiotakis C, 2016, PATTERN RECOGN, V53, P259, DOI 10.1016/j.patcog.2015.11.004
   Panagiotakis C, 2013, PATTERN RECOGN, V46, P2940, DOI 10.1016/j.patcog.2013.04.004
   Panagiotakis C, 2010, LECT NOTES COMPUT SC, V6388, P253, DOI 10.1007/978-3-642-17711-8_26
   Panagiotakis C, 2011, IEEE T IMAGE PROCESS, V20, P2276, DOI 10.1109/TIP.2011.2114893
   Panagiotakis C, 2008, INT J PATTERN RECOGN, V22, P1187, DOI 10.1142/S0218001408006752
   Park C, 2013, IEEE T PATTERN ANAL, V35, P669, DOI 10.1109/TPAMI.2012.163
   Pereira CS, 2007, LECT NOTES COMPUT SC, V4478, P170
   Rocha L, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P99, DOI 10.1109/SIBGRA.2002.1167130
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Song YY, 2017, IEEE T MED IMAGING, V36, P288, DOI 10.1109/TMI.2016.2606380
   Su H, 2014, IEEE ACM T COMPUT BI, V11, P714, DOI 10.1109/TCBB.2013.151
   Toshev A, 2012, INT J COMPUT VISION, V99, P123, DOI 10.1007/s11263-012-0521-z
   Trinh NH, 2011, INT J COMPUT VISION, V94, P215, DOI 10.1007/s11263-010-0412-0
   Wählby C, 2002, ANAL CELL PATHOL, V24, P101
   Wang JZ, 2015, LECT NOTES COMPUT SC, V9351, P226, DOI 10.1007/978-3-319-24574-4_27
   Yang X, 2015, IEEE T IMAGE PROCESS, V24, P9, DOI 10.1109/TIP.2014.2372615
   Yao J, 2005, PATTERN ANAL APPL, V8, P149, DOI 10.1007/s10044-005-0252-7
   Yeom I, 2015, MICROW OPT TECHN LET, V57, DOI 10.1002/mop.29010
   Zafari S, 2015, IEEE T IMAGE PROCESS, V24, P5942, DOI 10.1109/TIP.2015.2492828
   Zhang SC, 2005, PATTERN RECOGN, V38, P273, DOI 10.1016/j.patcog.2004.03.014
   Zhang WJ, 2017, PATTERN RECOGN, V71, P349, DOI 10.1016/j.patcog.2017.06.021
   Zhang WH, 2012, PATTERN RECOGN LETT, V33, P1543, DOI 10.1016/j.patrec.2012.03.027
NR 56
TC 32
Z9 33
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103810
DI 10.1016/j.imavis.2019.09.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000004
DA 2024-07-18
ER

PT J
AU Choi, HS
   An, K
   Kang, M
AF Choi, Han-Soo
   An, Keunhoi
   Kang, Myungjoo
TI Regression with residual neural network for vanishing point detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vanishing point detection; Deep learning; Naver Street View dataset;
   ResNet; Regression
AB This paper aims to propose a regression method with a residual neural network (ResNet) for vanishing point detection. The purpose of this study is to estimate the position of the vanishing point accurately. Our newly collected Naver Maps' Street View dataset is used for training regression ResNet-34 and for comparison with previous methods. It is concluded that the trained regression ResNet outperforms previous methods in terms of both computation time and accuracy. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Choi, Han-Soo; An, Keunhoi] Seoul Natl Univ, Dept Computat Sci & Technol, Seoul, South Korea.
   [Kang, Myungjoo] Seoul Natl Univ, Dept Math Sci, Seoul, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU)
RP Kang, M (corresponding author), Seoul Natl Univ, Dept Math Sci, Seoul, South Korea.
EM hschoi86@snu.ac.kr; khahn0213@snu.ac.kr; mkang@snu.ac.kr
FU National Research Foundation of Korea (NRF) [2015R1A15A1009350,
   2017RIA2A1A17069644]
FX The research of Myungjoo Kang was supported by the National Research
   Foundation of Korea (NRF) (2015R1A15A1009350, 2017RIA2A1A17069644).
CR Angladon V., 2015, PROCEEDINGS OF THE 6
   Borji Ali., 2016, Vanishing Point Detection With Convolutional Neural Networks
   Bui T.H., 2013, THE SICE ANNUAL CONF
   Chang C.K., 2018, IEEE INT C ROB AUT I
   Chang CK, 2012, IEEE INT C INT ROBOT, P1043, DOI 10.1109/IROS.2012.6385703
   Company P., 2014, LECTURE NOTES IN COM, V8746
   Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15
   He K., 2016, COMPUTER VISION AND
   Hua-jun L, 2006, ROAD IMAGES 2006 6TH
   Itu R, 2017, INT C INTELL COMP CO, P273, DOI 10.1109/ICCP.2017.8117016
   Kluger F, 2017, LECT NOTES COMPUT SC, V10496, P17, DOI 10.1007/978-3-319-66709-6_2
   Kong H, 2010, IEEE T IMAGE PROCESS, V19, P2211, DOI 10.1109/TIP.2010.2045715
   Le ManhCuong., 2014, Computer Vision-ACCV 2014, P414
   Li B, 2012, PATTERN RECOGN LETT, V33, P1, DOI 10.1016/j.patrec.2011.09.027
   Miraldo P, 2018, PROC CVPR IEEE, P2012, DOI 10.1109/CVPR.2018.00215
   Moon YY, 2018, SWARM EVOL COMPUT, V41, P111, DOI 10.1016/j.swevo.2018.02.007
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Shuai Y., 2017, 32ND YOUTH ACADEMIC
   Tretyak E, 2012, INT J COMPUT VISION, V97, P305, DOI 10.1007/s11263-011-0488-1
   Wu ZS, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16070948
   Xu YL, 2013, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR.2013.181
   Zhou Z., 2017, IEEE TRANS MULTIMEDI, V19
NR 22
TC 8
Z9 8
U1 2
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2019
VL 91
AR 103797
DI 10.1016/j.imavis.2019.08.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU3YI
UT WOS:000501614200002
DA 2024-07-18
ER

PT J
AU Sanodiya, RK
   Mathew, J
AF Sanodiya, Rakesh Kumar
   Mathew, Jimson
TI A novel unsupervised Globality-Locality Preserving Projections in
   transfer learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Discriminant analysis; Transfer learning; Domain adaptation; Manifold;
   Classification; Unsupervised learning; Dimensionality reduction
ID DISCRIMINANT-ANALYSIS; EIGENFACES; FRAMEWORK
AB In this paper, a novel unsupervised dimensionality reduction algorithm, unsupervised Globality-Locality Preserving Projections in Transfer Learning (UGLPTL) is proposed, based on the conventional Globality-Locality Preserving dimensionality reduction algorithm (GLPP) that does not work well in real-world Transfer Learning (TL) applications. In TL applications, one application (source domain) contains sufficient labeled data, but the related application contains only unlabeled data (target domain). Compared to the existing TL methods, our proposed method incorporates all the objectives, such as minimizing the marginal and conditional distributions between both the domains, maximizing the variance of the target domain, and performing Geometrical Diffusion on Manifolds, all of which are essential for transfer learning applications. UGLPTL seeks a projection vector that projects the source and the target domains data into a common subspace where both the labeled source data and the unlabeled target data can be utilized to perform dimensionality reduction. Comprehensive experiments have verified that the proposed method outperforms many state-of-the-art non-transfer learning and transfer learning methods on two popular real-world cross-domain visual transfer learning data sets. Our proposed UGLPTL approach achieved 82.18% and 87.14% mean accuracies over all the tasks of PIE Face and Office-Caltech data sets, respectively. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Sanodiya, Rakesh Kumar; Mathew, Jimson] Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801103, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology System (IIT System)
RP Sanodiya, RK (corresponding author), Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801103, Bihar, India.
EM rakesh.pcs16@iitp.ac.in; jimson@iitp.ac.in
CR [Anonymous], 2012, P ICML
   [Anonymous], 2017, ARXIV170505498
   [Anonymous], 2007, PROC IEEE INT C COMP
   [Anonymous], 2017, P IEEE C COMP VIS PA
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen J, 2011, ARTIF INTELL REV, V36, P29, DOI 10.1007/s10462-010-9200-z
   Dai Wenyuan, 2007, P 24 INT C MACHINE L, P193
   Ding ZM, 2017, IEEE T IMAGE PROCESS, V26, P660, DOI 10.1109/TIP.2016.2631887
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   Huang KK, 2017, PATTERN RECOGN, V62, P87, DOI 10.1016/j.patcog.2016.08.024
   Huang S, 2014, IEEE COMPUT SOC CONF, P15, DOI 10.1109/CVPRW.2014.8
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Li HF, 2004, ADV NEUR IN, V16, P97
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   LUO L, 2017, ARXIV171210042
   Nie FP, 2009, PATTERN RECOGN, V42, P2615, DOI 10.1016/j.patcog.2009.04.001
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Sanodiya R.K., 2019, KNOWL BASED SYST
   Sanodiya RK, 2019, IEEE ACCESS, V7, P42956, DOI 10.1109/ACCESS.2019.2907571
   Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6
   Shi L, 2016, IEEE GEOSCI REMOTE S, V13, P902, DOI 10.1109/LGRS.2016.2553046
   Shu L, 2015, IPSN'15: PROCEEDINGS OF THE 14TH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P390, DOI 10.1145/2737095.2737136
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Sun B., 2015, P BRIT MACH VIS C, V24, P1
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wan MH, 2011, APPL MATH COMPUT, V217, P9659, DOI 10.1016/j.amc.2011.04.050
   Wang H., 2014, 28 AAAI C ART INT
   Wang S, 2016, PATTERN RECOGN, V57, P179, DOI 10.1016/j.patcog.2016.02.019
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Xie CC, 2013, INT CONF COMPUTAT, P222, DOI 10.1109/ICCPS.2013.6893597
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Xu YH, 2017, IEEE T KNOWL DATA EN, V29, P1158, DOI 10.1109/TKDE.2017.2669193
   Yamamoto S, 2012, DENT MATER, V28, P736, DOI 10.1016/j.dental.2012.03.010
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zang SF, 2018, ARTIF INTELL REV, V49, P581, DOI 10.1007/s10462-016-9533-3
   Zhou W, 2013, IEICE T INF SYST, VE96D, P550, DOI 10.1587/transinf.E96.D.550
   Zuo H, 2017, IEEE T FUZZY SYST, V25, P1795, DOI 10.1109/TFUZZ.2016.2633376
NR 47
TC 8
Z9 8
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2019
VL 90
AR 103802
DI 10.1016/j.imavis.2019.08.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU0WT
UT WOS:000501400600001
DA 2024-07-18
ER

PT J
AU Zhang, X
   Jiang, ZG
   Zhang, HP
AF Zhang, Xin
   Jiang, Zhiguo
   Zhang, Haopeng
TI Real-time 6D pose estimation from a single RGB image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 6D pose estimation; Real-time processing; Coordinate localization;
   Backbone design
AB We propose an end-to-end deep learning architecture for simultaneously detecting objects and recovering 6D poses in an RGB image. Concretely, we extend the 2D detection pipeline with a pose estimation module to indirectly regress the image coordinates of the object's 3D vertices based on 2D detection results. Then the object's 6D pose can be estimated using a Perspective-n-Point algorithm without any post-refinements. Moreover, we elaborately design a backbone structure to maintain spatial resolution of low level features for pose estimation task. Compared with state-of-the-art RGB based pose estimation methods, our approach achieves competitive or superior performance on two benchmark datasets at an inference speed of 25 fps on a GTX 1080Ti GPU, which is capable of real-time processing. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Zhang, Xin; Jiang, Zhiguo; Zhang, Haopeng] Beihang Univ, Sch Astronaut, Image Proc Ctr, Beijing 100191, Peoples R China.
   [Zhang, Xin; Jiang, Zhiguo; Zhang, Haopeng] Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zhang, Xin; Jiang, Zhiguo; Zhang, Haopeng] Minist Educ, Key Lab Spacecraft Design Optimizat & Dynam Simul, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhang, HP (corresponding author), Beihang Univ, Sch Astronaut, Image Proc Ctr, Beijing 100191, Peoples R China.
EM zhang_xin_by@buaa.edu.cn; jiangzg@buaa.edu.cn; zhanghaopeng@buaa.edu.cn
RI Zhang, Haopeng/C-5472-2014
OI Zhang, Haopeng/0000-0003-1981-8307
FU National Natural Science Foundation of China [61501009, 61771031,
   61371134]; National Key Research and Development Program of China
   [2016YFB0501300, 2016YFB0501302]; Fundamental Research Funds for the
   Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61501009, 61771031, and 61371134), the
   National Key Research and Development Program of China (2016YFB0501300
   and 2016YFB0501302), and the Fundamental Research Funds for the Central
   Universities.
CR [Anonymous], 2013, PROC ASIAN C COMPUT
   [Anonymous], 2018, ARXIV180406215
   Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267
   Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Cao Z, 2016, IEEE INT CONF ROBOT, P2441, DOI 10.1109/ICRA.2016.7487396
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Do Thanh-Toan, 2018, Deep-6dpose: Recovering 6d object pose from a single rgb image
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinterstoisser S, 2016, LECT NOTES COMPUT SC, V9907, P834, DOI 10.1007/978-3-319-46487-9_51
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Kehl W, 2016, LECT NOTES COMPUT SC, V9907, P205, DOI 10.1007/978-3-319-46487-9_13
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Rad M, 2018, PROC CVPR IEEE, P4663, DOI 10.1109/CVPR.2018.00490
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Rubio A, 2015, IEEE INT CONF ROBOT, P1397, DOI 10.1109/ICRA.2015.7139372
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43
   Svärm L, 2014, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2014.75
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Tulsiani S, 2015, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2015.7298758
   Vidal J, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P405, DOI 10.1109/ICCAR.2018.8384709
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
NR 32
TC 15
Z9 17
U1 1
U2 47
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 1
EP 11
DI 10.1016/j.imavis.2019.06.013
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900001
DA 2024-07-18
ER

PT J
AU Santra, B
   Mukherjee, DP
AF Santra, Bikash
   Mukherjee, Dipti Prasad
TI A comprehensive survey on computer vision based approaches for automatic
   identification of products in retail store
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Survey; Product detection; Product recognition; Planogram compliance;
   Multiple object detection; Out-of-stock detection
ID APPROXIMATE NEAREST-NEIGHBOR; OBJECT RECOGNITION; COMBINING COLOR;
   IMAGE; INFORMATION; FEATURES; MODEL; SCALE; CLASSIFICATION; LOCALIZATION
AB The ability to recognize a product on the shelf of a retail store is an ordinary human skill. The same recognition problem presents an exceptional challenge for machine vision systems. Automatic detection of products on the shelf of a retail store provides enhanced value-added consumer experience and commercial benefits to retailers. Compared to machine vision based object recognition system, automatic detection of retail products in a store setting has lesser number of successful attempts. In this paper, we present a survey of machine vision based retail product recognition system and define a new taxonomy for this field. We also describe the intrinsic challenges associated with the problem. In this comprehensive survey of published papers, we analyze features used in state-of-the-art attempts. The performances of these approaches are compared. The details of publicly available datasets are presented. The paper concludes pointing to possible directions of research in related fields. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Santra, Bikash; Mukherjee, Dipti Prasad] Indian Stat Inst, Elect & Commun Sci Unit, Kolkata, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Santra, B (corresponding author), Indian Stat Inst, Elect & Commun Sci Unit, Kolkata, India.
EM bikash.santra@isical.ac.in; dipti@isical.ac.in
OI Santra, Bikash/0000-0002-6833-140X
CR Advani S, 2015, IEEE SYM EMBED SYST, P103, DOI 10.1109/ESTIMedia.2015.7351774
   Alhalabi W., 2016, P INT C IM PROC COMP, P49
   Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005
   [Anonymous], 2010, 2010 IEEE COMPUTER S
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2010, 2010 IEEE COMP SOC C
   Aragon-Camarasa G, 2010, PATTERN RECOGN LETT, V31, P1274, DOI 10.1016/j.patrec.2010.03.003
   Auclair A, 2008, LECT NOTES COMPUT SC, V4918, P224, DOI 10.1007/978-3-540-79860-6_18
   Bao R., 2014, P 12 AS C COMP VIS A, P600
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Baz I, 2016, 2016 IEEE 12TH IMAGE, VIDEO, AND MULTIDIMENSIONAL SIGNAL PROCESSING WORKSHOP (IVMSP)
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bishop T, 2016, GEEKWIRE
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Brenner R, 2016, LECT NOTES COMPUT SC, V9914, P360, DOI 10.1007/978-3-319-48881-3_25
   Bruce NDB, 2007, LECT NOTES ARTIF INT, V4840, P171
   Brunelli R., 2009, Template matching techniques in computer vision: theory and practice, DOI DOI 10.1002/9780470744055
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chong Timothy., Deep learning approach to planogram compliance in retail stores
   Choudhary S, 2014, IEEE INT C INT ROBOT, P1018, DOI 10.1109/IROS.2014.6942683
   Cleveland J., 2016, IEEE T AUTOMATION SC
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cremers D, 2012, IMAGE VISION COMPUT, V30, P476, DOI 10.1016/j.imavis.2011.12.011
   Cruz L., 2012, 2012 XXV SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T), P36, DOI 10.1109/SIBGRAPI-T.2012.13
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEVIJVER PA, 1985, PATTERN RECOGN LETT, V3, P369, DOI 10.1016/0167-8655(85)90023-6
   Dingli A, 2016, ADV INTELL SYST COMP, V500, P487, DOI 10.1007/978-3-319-41962-6_43
   Diplaros A, 2006, IEEE T IMAGE PROCESS, V15, P1, DOI 10.1109/TIP.2005.860320
   Diplaros A., 2003, IEEE WORKSH COL PHOT, P1
   Dougherty E.R., 1992, TUTORIAL TEXTS OPTIC
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Duda RO., 2012, Pattern classificatio
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FORESTI GL, 1994, IEEE IND ELEC, P984, DOI 10.1109/IECON.1994.397923
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Franco A, 2017, EXPERT SYST APPL, V81, P163, DOI 10.1016/j.eswa.2017.02.050
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Fritz M, 2005, IEEE I CONF COMP VIS, P1363
   Frontoni E., 2014, Mechatronic and Embedded Systems and Applications (MESA), P1
   Fukunaga K., 1999, Handbook Of Pattern Recognition And Computer Vision, P33
   Ge Z, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1, DOI 10.1109/ROBIO.2016.7866266
   George M, 2014, LECT NOTES COMPUT SC, V8690, P440, DOI 10.1007/978-3-319-10605-2_29
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Gevers T, 2004, IEEE T PATTERN ANAL, V26, P113, DOI 10.1109/TPAMI.2004.1261083
   Gevers T, 1999, IMAGE VISION COMPUT, V17, P475, DOI 10.1016/S0262-8856(98)00140-1
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   Gevers T., 2001, COMP VIS 2001 ICCV 2, V1, P615
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Goldman E., 2017, CORR
   Gruen T., 2002, Retail out-of-stocks: A worldwide examination of extent, causes and consumer responses
   Haladová Z, 2014, LECT NOTES COMPUT SC, V8671, P246, DOI 10.1007/978-3-319-11331-9_30
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He HB, 2008, IEEE T NEURAL NETWOR, V19, P1727, DOI 10.1109/TNN.2008.2001774
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He XM, 2004, PROC CVPR IEEE, P695
   Higa K, 2013, IEEE IMAGE PROC, P2973, DOI 10.1109/ICIP.2013.6738612
   Huang D, 2017, IMAGE VISION COMPUT, V58, P266, DOI 10.1016/j.imavis.2016.07.001
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Iwamoto K, 2013, IEEE IMAGE PROC, P2915, DOI 10.1109/ICIP.2013.6738600
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jafri R, 2014, VISUAL COMPUT, V30, P1197, DOI 10.1007/s00371-013-0886-1
   JAMESON D, 1989, ANNU REV PSYCHOL, V40, P1, DOI 10.1146/annurev.ps.40.020189.000245
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Jund P., 2016, ARXIV161105799
   Karlinsky L, 2017, PROC CVPR IEEE, P965, DOI 10.1109/CVPR.2017.109
   Kejriwal Nishant., 2015, IEEE Conference on Technologies for Practical Robot Applications, TePRA, P1
   Kesidis AL, 2000, IMAGE VISION COMPUT, V18, P607, DOI 10.1016/S0262-8856(99)00067-0
   Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Kulyukin V., 2014, The Open Rehabilitation Journal, V3, P158, DOI DOI 10.2174/1874943701003010158
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LeCun V. A., 2012, EFFICIENT BACKPROP N, P9
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Liu JC, 2013, PROC CVPR IEEE, P2003, DOI 10.1109/CVPR.2013.261
   Liu S, 2016, IEEE MULTIMEDIA, V23, P54, DOI 10.1109/MMUL.2016.19
   Liu S, 2015, IEEE INT SYM MULTIM, P27, DOI 10.1109/ISM.2015.72
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   López-de-Ipiña D, 2011, LECT NOTES COMPUT SC, V6693, P33, DOI 10.1007/978-3-642-21303-8_5
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590
   Marder M, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2394513
   Matei B, 2006, IEEE T PATTERN ANAL, V28, P1111, DOI 10.1109/TPAMI.2006.148
   Medina M. O. M., 2015, uS Patent App, Patent No. [14/921,899, 14921899]
   Melek CG, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P145, DOI 10.1109/UBMK.2017.8093584
   Merler M, 2007, PROC CVPR IEEE, P3634
   Metzger C. P., 2008, THESIS
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nicholson J., 2009, OPEN REHABIL J, V2, P11, DOI [10.2174/1874943700902010011, DOI 10.2174/1874943700902010011]
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Novak C. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P599, DOI 10.1109/CVPR.1992.223129
   Oh K, 2016, IMAGE VISION COMPUT, V54, P31, DOI 10.1016/j.imavis.2016.07.007
   Papageorgiou C., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P35, DOI 10.1109/ICIP.1999.819462
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Piccinini P, 2012, IMAGE VISION COMPUT, V30, P573, DOI 10.1016/j.imavis.2012.06.004
   Raju USN, 2015, IEEE INT C SEMANT CO, P157, DOI 10.1109/ICOSC.2015.7050797
   Ray A., 2018, P EUR C COMP VIS ECC, P586
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saran A, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P576, DOI 10.1109/MVA.2015.7153257
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Schwiegerling J., 2004, FIELD GUIDE VISUAL O
   Shapiro M., 2009, EXECUTING BEST PLANO
   Sharma A, 2012, WOODHEAD PUBL FOOD S, P73
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Silverman, 2018, DENSITY ESTIMATION S, DOI 10.1201/9781315140919
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Sobel I., 2014, History and definition of the sobel operator
   Sun T, 2017, IMAGE VISION COMPUT, V64, P47, DOI 10.1016/j.imavis.2017.06.003
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Thakoor KaveriA., 2013, Multimedia and Expo Workshops (ICMEW), 2013 IEEE International Conference on, P1
   Tonioni A, 2017, LECT NOTES COMPUT SC, V10484, P682, DOI 10.1007/978-3-319-68560-1_61
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Varol G, 2015, PROC SPIE, V9443, DOI 10.1117/12.2179127
   Varol G, 2014, SIG PROCESS COMMUN, P1031, DOI 10.1109/SIU.2014.6830408
   Villamizar M, 2016, COMPUT VIS IMAGE UND, V149, P51, DOI 10.1016/j.cviu.2016.03.010
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola PA., 2006, uS Patent, Patent No. [7,031,499, 7031499]
   Vo BN, 2010, IEEE T SIGNAL PROCES, V58, P5129, DOI 10.1109/TSP.2010.2050482
   Wang C, 2015, IMAGE VISION COMPUT, V38, P65, DOI 10.1016/j.imavis.2014.10.013
   Wang JJ, 2015, IMAGE VISION COMPUT, V34, P51, DOI 10.1016/j.imavis.2014.10.014
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Xie CH, 2017, IEEE I CONF COMP VIS, P1378, DOI 10.1109/ICCV.2017.153
   Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368
   Yao HT, 2017, IMAGE VISION COMPUT, V63, P24, DOI 10.1016/j.imavis.2017.05.003
   Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739
   Yörük E, 2016, INT C PATT RECOG, P1352, DOI 10.1109/ICPR.2016.7899825
   Yuhang Zhang, 2007, Computer Vision - ACCV 2007. Proceedings 8th Asian Conference on Computer Vision. Part I. (Lecture Notes in Computer Science vol. 4843), P800
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang Q., 2016, J SENSORS 2016
   Zhang Q, 2016, 2016 IEEE INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P174, DOI 10.1109/ITNEC.2016.7560343
   Zhang YH, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P468, DOI 10.1109/DICTA.2009.79
   Zickler S, 2006, IEEE-RAS INT C HUMAN, P20, DOI 10.1109/ICHR.2006.321358
   Zientara P, 2017, IEEE CONSUM ELECTR M, V6, P73, DOI 10.1109/MCE.2016.2614422
   Zientara PA, 2017, COMPUTER, V50, P16, DOI 10.1109/MC.2017.36
NR 152
TC 35
Z9 39
U1 1
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2019
VL 86
BP 45
EP 63
DI 10.1016/j.imavis.2019.03.005
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IC8DN
UT WOS:000471206600005
DA 2024-07-18
ER

PT J
AU Banno, A
AF Banno, Atsuhiko
TI A P3P problem solver representing all parameters as a linear combination
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE P3P problem; Localization; Camera parameter; Grobner basis
ID PERSPECTIVE-3-POINT PROBLEM; POSE DETERMINATION
AB We propose a novel strategy for the Perspective-Three-Point (P3P) problem that determines the position and orientation of a calibrated camera from three known point pairs of 2D-3D correspondences. Starting from three similarity transformation equations that relate the global and the camera-oriented coordinates, our method treats all the extrinsic camera parameters as a linear combination of known vectors with unknown coefficients. By reducing the number of unknowns and using a Grbbner basis, the problem is converted into a fourth-order polynomial equation with a single unknown parameter. Experimental results show that our method is highly practical and precise. Moreover, the performance of our method and its robustness to image noise are similar to those of a state-of-the-art method. In addition, our method exhibits greater computational efficiency than other methods. (C) 2018 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license (http: licreativecommons.org/licenses/by/4.0/).
C1 [Banno, Atsuhiko] Natl Inst Adv Ind Sci & Technol, Cent 2,1-1-1 Umezono, Tsukuba, Ibaraki 3058568, Japan.
C3 National Institute of Advanced Industrial Science & Technology (AIST)
RP Banno, A (corresponding author), Natl Inst Adv Ind Sci & Technol, Cent 2,1-1-1 Umezono, Tsukuba, Ibaraki 3058568, Japan.
EM atsuhiko.banno@aist.go.jp
FU Project of the NARO Bio-oriented Technology Research Advancement
   Institution (the special scheme project on vitalizing management
   entities of agriculture, forestry and fisheries);  [26330305]
FX This research was supported in part by Grant-in-Aid for Scientific
   Research (C) 26330305, and the Project of the NARO Bio-oriented
   Technology Research Advancement Institution (the special scheme project
   on vitalizing management entities of agriculture, forestry and
   fisheries).
CR Ameller Marc-Andre., 2000, CAMERA POSE REVISITE
   Cox D., 1997, IDEALS VARIABLES ALG
   DEMENTHON D, 1992, IEEE T PATTERN ANAL, V14, P1100, DOI 10.1109/34.166625
   DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852
   DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365
   Finsterwalder S., 1937, Das ruckwartseinschneiden im raum
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao XS, 2006, J MATH IMAGING VIS, V25, P79, DOI 10.1007/s10851-006-5149-6
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Garro V, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P262, DOI 10.1109/3DIMPVT.2012.40
   Grunert JA., 1841, Archiv der Mathematik und Physik, V1, P238
   Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759
   HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352
   HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2
   Jianliang Tang, 2006, Journal of Systems Science and Complexity, V19, P219
   Kneip Laurent., 2011, A novel parametrization of the perspective-three-point problem for a direct computation of absolute camera position and orientation
   Kukelova Zuzana, 2008, AUTOMATIC GENERATOR
   Lee PY, 2005, J IND MANAG OPTIM, V1, P565, DOI 10.3934/jimo.2005.1.565
   Li SQ, 2011, INT J PATTERN RECOGN, V25, P627, DOI 10.1142/S0218001411008774
   LINNAINMAA S, 1988, IEEE T PATTERN ANAL, V10, P634, DOI 10.1109/34.6772
   Liu Y., 2003, LECT NOTES COMPUT SC
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Merritt EL., 1949, Photogrammetric Engineering, V15, P649
   Moreno-Noguer Francesc, 2007, ACCURATE NONITERATIV, P1
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nistér D, 2007, J MATH IMAGING VIS, V27, P67, DOI 10.1007/s10851-006-0450-y
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Rieck MQ, 2014, J MATH IMAGING VIS, V48, P499, DOI 10.1007/s10851-013-0425-8
   Stewenius H., 2005, MINIMAL SOLUTION REL
   Tang J., 2009, SIGAPP 09 ACM S APPL, P1138
   Triggs B., 1999, CAMERA POSE CALIBRAT
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   WOLFE WJ, 1991, IEEE T PATTERN ANAL, V13, P66, DOI 10.1109/34.67632
   Wu YH, 2006, J MATH IMAGING VIS, V24, P131, DOI 10.1007/s10851-005-3617-z
NR 34
TC 6
Z9 7
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2018
VL 70
BP 55
EP 62
DI 10.1016/j.imavis.2018.01.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GA7AR
UT WOS:000428487500006
OA hybrid
DA 2024-07-18
ER

PT J
AU Borji, A
AF Borji, Ali
TI Negative results in computer vision: A perspective
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Negative results; All results; Computer vision; Biological vision;
   Statistical testing
ID HIERARCHICAL-MODELS; NEURAL-NETWORKS; RECOGNITION; INFORMATION
AB A negative result is when the outcome of an experiment or a model is not what is expected or when a hypothesis does not hold. Despite being often overlooked in the scientific community, negative results are results and they carry value. While this topic has been extensively discussed in other fields such as social sciences and biosciences, less attention has been paid to it in the computer vision community. The unique characteristics of computer vision, particularly its experimental aspect, call for a special treatment of this matter. In this manuscript, I will address what makes negative results important, how they should be disseminated and incentivized, and what lessons can be learned from cognitive vision research in this regard. Further, I will discuss matters such as experimental design, statistical hypothesis testing, explanatory versus predictive modeling, performance evaluation, model comparison, reproducibility of findings, the confluence of computer vision and human vision, as well as computer vision research culture. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Borji, Ali] Univ Cent Florida, Ctr Comp Vis Res, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Borji, A (corresponding author), Univ Cent Florida, Ctr Comp Vis Res, Orlando, FL 32816 USA.
EM aborji@crcv.ucf.edu
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   [Anonymous], ARXIV150606579
   [Anonymous], TECH REP
   Asendorpf JB, 2013, EUR J PERSONALITY, V27, P108, DOI 10.1002/per.1919
   Belia S, 2005, PSYCHOL METHODS, V10, P389, DOI 10.1037/1082-989X.10.4.389
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Borji A, 2014, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2014.22
   Borji A, 2014, J VISION, V14, DOI 10.1167/14.3.29
   Borji A, 2013, J VISION, V13, DOI 10.1167/13.10.18
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Brendel W., ARXIV170401547
   Chellappa R, 2012, IMAGE VISION COMPUT, V30, P467, DOI 10.1016/j.imavis.2012.03.008
   Cox DR, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1700768
   Cox DD, 2014, CURR BIOL, V24, pR921, DOI 10.1016/j.cub.2014.08.026
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Denton E, 2015, ADV NEUR IN, V28
   Devlin J., ARXIV150504467
   DiCarlo JJ, 2007, TRENDS COGN SCI, V11, P333, DOI 10.1016/j.tics.2007.06.010
   DUNNETT CW, 1955, J AM STAT ASSOC, V50, P1096, DOI 10.2307/2281208
   Efron B, 2016, INST MATH STAT MG, P1, DOI 10.1017/CBO9781316576533
   Fong R., ARXIV170305463
   Fukushima S., 1982, inCompetition and Cooperation in Neural Nets, P267, DOI 10.1007/978-3-642-46466-9_18
   Geman D, 2016, P NATL ACAD SCI USA, V113, P9384, DOI 10.1073/pnas.1609793113
   Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9
   Greene MR, 2012, VISION RES, V62, P1, DOI 10.1016/j.visres.2012.03.019
   HARALICK RM, 1986, COMPUT VISION GRAPH, V36, P372, DOI 10.1016/0734-189X(86)90082-4
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81
   Kovashka A, 2014, FOUND TRENDS COMPUT, V10, pI, DOI 10.1561/0600000071
   Kriegeskorte N, 2015, ANNU REV VIS SCI, V1, P417, DOI 10.1146/annurev-vision-082114-035447
   Krüger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Lian H, 2015, INT J ENV RES PUB HE, V12, P9068, DOI 10.3390/ijerph120809068
   Matthews R., 2000, Teaching Statistics, V22, P36, DOI DOI 10.1111/1467-9639.00013
   Medathati NVK, 2016, COMPUT VIS IMAGE UND, V150, P1, DOI 10.1016/j.cviu.2016.04.009
   Nayebi A., ARXIV170309202
   Nelson LD, 2012, PSYCHOL INQ, V23, P291, DOI 10.1080/1047840X.2012.705245
   Parikh D, 2011, PROC CVPR IEEE, P1425, DOI 10.1109/CVPR.2011.5995450
   Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027
   Pious S., 1993, PSYCHOL JUDGMENT DEC
   POTTER MC, 1975, SCIENCE, V187, P965, DOI 10.1126/science.1145183
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   ROSENTHAL R, 1979, PSYCHOL BULL, V86, P638, DOI 10.1037/0033-2909.86.3.638
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P1679, DOI 10.1109/TPAMI.2013.2297711
   Serre T., IEEE T PATTERN ANAL, V29
   SHANKLAND RS, 1964, AM J PHYS, V32, P16, DOI 10.1119/1.1970063
   STERLING TD, 1959, J AM STAT ASSOC, V54, P30, DOI 10.2307/2282137
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tan C, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00374
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   TORRALBA A, 2011, PROC CVPR IEEE, P1521, DOI DOI 10.1109/CVPR.2011.5995347
   VanRullen R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00142
   Vogel J., 2006, P 3 S APPL PERCEPTIO, V153, P33
   Vondrick C., 2015, Advances in Neural Information Processing Systems, P289
   Vondrick C, 2013, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2013.8
   Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111
   Yarbus A.L., 1967, EYE MOVEMENTS VISION, DOI [10.1007/978-1-4899-5379-7, DOI 10.1007/978-1-4899-5379-7]
   Yuille AL, 2012, IMAGE VISION COMPUT, V30, P469, DOI 10.1016/j.imavis.2011.12.013
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 67
TC 21
Z9 23
U1 2
U2 37
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 1
EP 8
DI 10.1016/j.imavis.2017.10.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Szirtes, G
   Orozco, J
   István, P
   Daniel, S
   Akos, U
   Cohn, JF
AF Szirtes, Gabor
   Orozco, Javier
   Istvan, Petras
   Daniel, Szolgay
   Akos, Utasi
   Cohn, Jeffrey F.
TI Behavioral cues help predict impact of advertising on future sales
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Market research; Behavioral cue; Predictive modeling; Facial expression
   analysis
AB Advertising aims to influence consumer preferences, appraisals, action tendencies, and behavior in order to increase sales. These are all components of emotion. In the past, they have been measured through self report or panel discussions. While informative, these approaches are difficult to scale to large numbers of consumers, fail to capture moment-to-moment changes in appraisals that may be predictive of sales, and depend on verbal mediation. We used web-cam technology to sample non-verbal responses to television commercials from four product categories in six different countries. For each participant, head pose, head motion, and more frequent facial expressions like smiling, surprise and disgust were automatically measured at each video frame and aggregated across subjects. Dynamic features from the aggregated series were input to simple linear ensemble classifier with 10-fold cross-validation to predict product sales. Sales were predicted with ROC AUC = 0.75, 95% CI [0.727,0.773] and predictions for unseen categories were consistent for all, but one product groups (ROC AUC varies between 0.74 and 0.83, except for Confections with 0.61). Predictions for unseen countries showed similar pattern: ROC AUC varied between 0.71 and 0.89, with the exception of Russia with ROC AUC 0.53. In comparison with previous attempts, our approach yielded higher overall performance and greater generalization over not modeled factors like country or category. These findings support the feasibility, efficiency, and predictive validity of sales predictions from large-scale sampling of viewers' moment-to-moment responses to commercial media. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Szirtes, Gabor; Orozco, Javier; Istvan, Petras; Daniel, Szolgay; Akos, Utasi] Realeyes OU, Tolgyfa Utca 24, H-1027 Budapest, Hungary.
   [Cohn, Jeffrey F.] Univ Pittsburgh, 4322 Sennott Sq, Pittsburgh, PA 15260 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh
RP Szirtes, G (corresponding author), Realeyes OU, Tolgyfa Utca 24, H-1027 Budapest, Hungary.
EM gabor.szirtes@realeyesit.com
FU European Community [645094]
FX This work was financially supported by the European Community Horizon
   2020 [H2020/2014-2020] under grant agreement no. 645094 (SEWA Automatic
   Sentiment Analysis in the Wild). The authors would like to thank the
   Ehrenberg-Bass Institute for Marketing Science for helping in defining
   the data collection experiment, and MARS, Incorporated for providing the
   valuable sales lift data that made this research possible. The authors
   are especially grateful for the anonymous reviewers for their concerns
   and comments on transparency and simplicity.
CR Airola A, 2010, JMLR WORKSH CONF PRO, V8, P3
   Ambadar Z, 2009, J NONVERBAL BEHAV, V33, P17, DOI 10.1007/s10919-008-0059-5
   [Anonymous], 2014, THESIS
   Calvo MG, 2014, J NONVERBAL BEHAV, V38, P549, DOI 10.1007/s10919-014-0191-3
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Damasio A.R., 1995, DESCARTES ERROR EMOT
   Dibeklioglu H, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P307, DOI 10.1145/2818346.2820776
   Dolnicar S, 2011, INT J MARKET RES, V53, P231, DOI 10.2501/IJMR-53-2-231-252
   Doshi A, 2012, J VISION, V12, DOI 10.1167/12.2.9
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Glauner P. O., 2015, THESIS
   Good P.I., 2012, Common errors in statistics (and how to avoid them)
   Green D. M., 1966, SIGNAL DETECTION THE
   Hammal Z, 2015, INT CONF AFFECT, P281, DOI 10.1109/ACII.2015.7344584
   Jeni LA, 2013, INT CONF AFFECT, P245, DOI 10.1109/ACII.2013.47
   KELTNER D, 1995, J PERS SOC PSYCHOL, V68, P441, DOI 10.1037/0022-3514.68.3.441
   Lafrance m., 1999, SOCIAL CONTEXT NONVE, P45
   Liaukonyte J, 2015, MARKET SCI, V34, P311, DOI 10.1287/mksc.2014.0899
   McDuff D., 2013, P ESOMAR C
   McDuff D, 2015, IEEE T AFFECT COMPUT, V6, P223, DOI 10.1109/TAFFC.2014.2384198
   Opitz D., 1999, J ARTIF INTELL RES, V11, P169, DOI DOI 10.1613/JAIR.614
   Orozco J, 2015, IMAGE VISION COMPUT, V42, P47, DOI 10.1016/j.imavis.2015.07.002
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Rottenberg J., 2007, EMOTION ELICITATION
   Scherer K.R., 2004, FEELINGS EMOTIONS AM, P136, DOI DOI 10.1017/CBO9780511806582.009
   Slaney M., 2014, P 16 INT C MULT INT, P144
   statista. com, 2015, US ADV IND STAT FACT
   Vriens M, 2001, MARK RES, V13, P14
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   ZAJONC RB, 1980, AM PSYCHOL, V35, P151, DOI 10.1037/0003-066X.35.2.151
NR 31
TC 1
Z9 1
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2017
VL 65
SI SI
BP 49
EP 57
DI 10.1016/j.imavis.2017.03.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA FJ3GM
UT WOS:000412618500006
DA 2024-07-18
ER

PT J
AU Wang, XD
   Chen, RC
   Hong, CQ
   Zeng, ZQ
   Zhou, ZL
AF Wang, Xiao-dong
   Chen, Rung-Ching
   Hong, Chao-qun
   Zeng, Zhi-qiang
   Zhou, Zhi-li
TI Semi-supervised multi-label feature selection via label correlation
   analysis with <i>l</i><sub>1</sub>-norm graph embedding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semi-supervised learning; Feature selection; Multi-label learning;
   Shared-subspace learning
ID IMAGE ANNOTATION; WEB
AB In this paper, we propose a novel semi-supervised multi-label feature selection algorithm and apply it to three different applications: natural scene classification, web page annotation, and yeast gene functional classification. Compared with the previous works, there are two advantages of our algorithm: (1) Manifold learning which leverages the underlying geometric structure of the training data is imposed to utilize both labeled and unlabeled data. Besides, the underlying manifold structure is guaranteed to be clear by using the l(1)-norm regularization. (2) Shared subspace learning which has shown its efficiency in multi-label learning scenarios, is also considered in our feature learning algorithm. The proposed objective function involves l(21)-norm and l(1)-norm, making it non-smooth and difficult to solve. We also design an efficient iterative algorithm to optimize it. Experimental results demonstrate the effectiveness of our algorithm compared with sate-of-the-art algorithms on different tasks. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Wang, Xiao-dong; Hong, Chao-qun; Zeng, Zhi-qiang] Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
   [Wang, Xiao-dong; Chen, Rung-Ching] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
   [Zhou, Zhi-li] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Zhou, Zhi-li] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Xiamen University of Technology; Chaoyang University of Technology;
   Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology
RP Wang, XD (corresponding author), Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.; Chen, RC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
EM xdwangjsj@xmut.edu.cn; crching@cyut.edu.tw
RI wang, xiao/HZI-9156-2023
FU National Natural Science Foundation of China [61502405]; National
   Natural Science Foundation of Fujian Province, China [2016J01324,
   2017J01511]; Xiamen University of Technology [E201400400]; Xiamen
   Science and Technology Planning Project [3502Z20143030, 3502Z20133043];
   Fujian Provincial Education Department [JA15385, JAT160357]; Ministry of
   Science and Technology, Taiwan [MOST-104-2221-E-324-019-MY2,
   MOST-103-2632-E-324-001-MY3]
FX This paper is supported by the National Natural Science Foundation of
   China (Grant No. 61502405), the National Natural Science Foundation of
   Fujian Province, China (Grant No. 2016J01324, 2017J01511), the
   International Science and Technology Cooperation Program of Xiamen
   University of Technology (Grant No. E201400400), the Xiamen Science and
   Technology Planning Project (Grant Nos. 3502Z20143030, 3502Z20133043),
   the Scientific Research Fund of Fujian Provincial Education Department
   (Grant Nos. JA15385, JAT160357), and the Ministry of Science and
   Technology, Taiwan (Grant Nos. MOST-104-2221-E-324-019-MY2,
   MOST-103-2632-E-324-001-MY3).
CR Amores J, 2007, IEEE T PATTERN ANAL, V29, P1818, DOI 10.1109/TPAMI.2007.1098
   Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], ADV NEURAL INFORM PR
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2015, AAAI CONF ARTIF INTE, P2532
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chen JH, 2013, IEEE T PATTERN ANAL, V35, P1025, DOI 10.1109/TPAMI.2012.189
   Elguebaly T, 2015, IMAGE VISION COMPUT, V34, P27, DOI 10.1016/j.imavis.2014.10.011
   Elisseeff A, 2002, ADV NEUR IN, V14, P681
   Golub G.H., 1989, MATRIX COMPUTATIONS
   He X., 2005, P ADV NEURAL INFORM, V18, P507
   Ji SW, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1754428.1754431
   Li T, 2016, IMAGE VISION COMPUT, V55, P64, DOI 10.1016/j.imavis.2016.04.002
   Li Z., 2012, P AAAI C ART INT, P1026
   Liu Y, 2013, NEUROCOMPUTING, V105, P12, DOI 10.1016/j.neucom.2012.05.031
   Ma Z., 2012, MM 2012 - Proceedings of the 20th ACM International Conference on Multimedia, P469, DOI DOI 10.1145/2393347.2393414
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2011, IEEE I CONF COMP VIS, P2268
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Ren YZ, 2012, NEUROCOMPUTING, V89, P147, DOI 10.1016/j.neucom.2012.02.021
   Shi CJ, 2015, IMAGE VISION COMPUT, V41, P1, DOI 10.1016/j.imavis.2015.06.006
   Shi CJ, 2014, IMAGE VISION COMPUT, V32, P189, DOI 10.1016/j.imavis.2013.12.013
   Xiaojun Chang, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P74, DOI 10.1007/978-3-319-06605-9_7
   Xu ZL, 2010, IEEE T NEURAL NETWOR, V21, P1033, DOI 10.1109/TNN.2010.2047114
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yang Y, 2013, IEEE T KNOWL DATA EN, V25, P1760, DOI 10.1109/TKDE.2012.118
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Zeng ZQ, 2016, NEUROCOMPUTING, V173, P102, DOI 10.1016/j.neucom.2015.05.119
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang Q., 2016, IMAGE VIS COMPUT
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151
   Zhou Z., 2006, Advances in Neural Information Processing Systems, P1609
NR 45
TC 27
Z9 27
U1 1
U2 38
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2017
VL 63
BP 10
EP 23
DI 10.1016/j.imavis.2017.05.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EY9IN
UT WOS:000404312400002
DA 2024-07-18
ER

PT J
AU Wang, XM
   Li, ZC
   Tang, JH
AF Wang, Xueming
   Li, Zechao
   Tang, Jinhui
TI Multimedia news QA: Extraction and visualization integration with
   multiple-source information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Topic model; Multimedia question answering; Representative image
ID SELECTION
AB Recent years have witnessed the explosion of multimedia news and currently we are living in a sea of multimedia news. Faced with so huge quantities of multimedia news from all corners of the world, people are often confused and feeling overwhelmed because it takes much time and effort for them to access their desired news. As a consequence, multimedia question answering (QA) with the goal of providing precise answers to the query questions has attracted increasing attention in recent years. Towards this end, this work proposes solutions for multimedia news QA to provide an effective news information browsing experience by integrating multimedia information from multiple sources. Specifically, we first collect a large-scale multimedia news data set for question answering. And then topic analysis is used to present concise and reliable answers including textual and visual information. Experiments on the news dataset collected from multiple news websites demonstrate the encouraging performance of the proposed solutions. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Wang, Xueming; Li, Zechao; Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Li, ZC (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM zechao.li@njust.edu.cn
RI Tang, Jinhui/KBR-0891-2024
OI Tang, Jinhui/0000-0001-9008-222X
FU 973 Program of China [201403347600]; National Natural Science Foundation
   of China [61522203, 61402228]; National Ten Thousand Talent Program of
   China (Young Top-Notch Talent)
FX This work was partially supported by the 973 Program of China (project
   201403347600), the National Natural Science Foundation of China (grants
   61522203 and 61402228), and the National Ten Thousand Talent Program of
   China (Young Top-Notch Talent).
CR Abney S, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P296
   [Anonymous], P ACM INT C IM VID R
   [Anonymous], 2008, Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM '08
   [Anonymous], 2004, EFFICIENT NEAR DUPLI
   Bendersky M, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P605
   Bendersky Michael, 2008, P 31 ANN INT ACM SIG, P491
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Ckarke C.L.A., 2001, P 10 TEXT RETR C
   Clarke C. L. A., 2001, SIGIR Forum, P358
   CONG G, 2008, P 31 ANN INT ACM SIG, P467
   Cui H, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1229179.1229182
   Dollar P., 2014, MICROSOFT COCO COMMO, P740
   Dumais S., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P291
   Gao H., 2015, COMPUT SCI
   HARABAGIU S, 2001, P 9 TEXT RETR C TREC, P479
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hong R., 2011, ACM T MULTIMED COMPU, V7
   Hong RC, 2012, IEEE MULTIMEDIA, V19, P72, DOI 10.1109/MMUL.2011.53
   Kwok C., 2010, P 10 WORLD WID WEB C, P150
   Li ZC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2822907
   Li Z, 2013, INT CONF CLOUD COMP, P1, DOI 10.1109/CloudCom.2013.7
   Mollá D, 2007, COMPUT LINGUIST, V33, P41, DOI 10.1162/coli.2007.33.1.41
   Near Z.A., 2008, P BMVC
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Pasca M. A., 2001, SIGIR Forum, P366
   Quarteroni S, 2009, NAT LANG ENG, V15, P73, DOI 10.1017/S1351324908004919
   Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232
   Salton G., 1989, INFORM PROCESSING MA, V4, P513
   Song XN, 2016, MULTIMEDIA SYST, V22, P41, DOI 10.1007/s00530-014-0390-0
   Toutanova K, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P63, DOI 10.3115/1117794.1117802
   Voorhees E.M., 2001, NIST Special Publication 500-250: The Tenth Text REtrieval Conference (TREC 2001), P1
   Yeh Tom., 2008, MM '08 Proceedings of the 16th ACM International Conference on Multimedia, P389
   Zhang JG, 2015, J VIS COMMUN IMAGE R, V30, P376, DOI 10.1016/j.jvcir.2015.05.004
   Zhang W., 2012, P 20 SCI M, P1345
   Zhao WL, 2013, IEEE T IMAGE PROCESS, V22, P980, DOI 10.1109/TIP.2012.2226043
   Zhao WL, 2009, IEEE T IMAGE PROCESS, V18, P412, DOI 10.1109/TIP.2008.2008900
NR 37
TC 2
Z9 2
U1 1
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 162
EP 170
DI 10.1016/j.imavis.2017.01.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800017
DA 2024-07-18
ER

PT J
AU Cheng, SY
   Marras, I
   Zafeiriou, S
   Pantic, M
AF Cheng, Shiyang
   Marras, Ioannis
   Zafeiriou, Stefanos
   Pantic, Maja
TI Statistical non-rigid ICP algorithm and its application to 3D face
   alignment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face alignment; Statistical shape model; Non-rigid ICP algorithm;
   BU-4DFE database; FRGC v2 database
ID RECOGNITION; MODEL; RECONSTRUCTION; OBJECTS
AB The problem of fitting a 3D facial model to a 3D mesh has received a lot of attention the past 15-20years. The majority of the techniques fit a general model consisting of a simple parameterisable surface or a mean 3D facial shape. The drawback of this approach is that is rather difficult to describe the non-rigid aspect of the face using just a single facial model. One way to capture the 3D facial deformations is by means Of a statistical 3D model of the face or its parts. This is particularly evident when we want to capture the deformations of the mouth region. Even though statistical models of face are generally applied for modelling facial intensity, there are few approaches that fit a statistical model of 3D faces. In this paper, in order to capture and describe the non-rigid nature of facial surfaces we build a part-based statistical model of the 3D facial surface and we combine it with non-rigid iterative closest point algorithms. We show that the proposed algorithm largely outperforms state-of-the-art algorithms for 3D face fitting and alignment especially when it comes to the description of the mouth region. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Cheng, Shiyang; Marras, Ioannis; Zafeiriou, Stefanos; Pantic, Maja] Imperial Coll London, Dept Comp, London, England.
   [Pantic, Maja] Univ Twente, EEMCS, NL-7500 AE Enschede, Netherlands.
C3 Imperial College London; University of Twente
RP Cheng, SY (corresponding author), Imperial Coll London, Dept Comp, London, England.
EM shiyang.cheng11@imperial.ac.uk
FU EPSRC [EP/J017787/1, EP/1026813/1]; European Community Horizon 2020
   [645094]; EPSRC [EP/H016988/1, EP/L026813/1, EP/J017787/1, EP/N007743/1]
   Funding Source: UKRI
FX The work of S. Cheng and I. Marras is funded by the EPSRC project
   EP/J017787/1 (4D-FAB). M. Pantic acknowledges support by the European
   Community Horizon 2020 [H2020/2014-2020] under grant agreement no.
   645094 (SEWA). S. Zafeiriou also acknowledges support from EPSRC project
   EP/1026813/1Adaptive Facial Deformable Models for Tracking (ADAManT).
CR Albrecht T., 2008, Computer Vision and Pattern Recognition, P1, DOI 10.1109/CVPR.2008.4587394
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   Amberg B, 2008, IEEE INT CONF AUTOMA, P667
   [Anonymous], ACM SIGGRAPH
   [Anonymous], MULTILINEAR WAVELETS
   [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], JVRB J VIRTUAL REALI
   [Anonymous], 2007, P COMPUTER VISION PA
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], ACM SIGGRAPH
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 4D CAPT SYST
   Asthana A, 2015, IEEE T PATTERN ANAL, V37, P1312, DOI 10.1109/TPAMI.2014.2362142
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Bolkart T, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P103, DOI 10.1109/3DV.2013.22
   Catmull E., 1998, SEMINAL GRAPHICS, P183, DOI DOI 10.1145/280811.280992
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   DUTREVE L., 2008, Proceedings of the 2008 ACM symposium on Virtual reality software and technology, ACM, New York, NY, USA, VRST '08, P197, DOI DOI 10.1145/1450579.1450621
   Fang TH, 2012, IMAGE VISION COMPUT, V30, P738, DOI 10.1016/j.imavis.2012.02.004
   Haehnel D., 2003, IJCAI'03, P915
   Johnson A., 1997, Thesis
   Kakadiaris IA, 2005, PROC CVPR IEEE, P1022
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x
   Loop CT, 1987, THESIS
   MANDAL C., 1999, P 5 ACM S SOLID MODE, P191
   Marras I, 2012, LECT NOTES COMPUT SC, V7584, P230, DOI 10.1007/978-3-642-33868-7_23
   Pan G, 2013, IEEE T IMAGE PROCESS, V22, P4170, DOI 10.1109/TIP.2013.2271115
   Papaioannou G, 2002, IEEE T PATTERN ANAL, V24, P114, DOI 10.1109/34.982888
   Passalis G, 2007, IEEE T PATTERN ANAL, V29, P218, DOI 10.1109/TPAMI.2007.37
   Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Rendall TCS, 2010, J COMPUT PHYS, V229, P2810, DOI 10.1016/j.jcp.2009.12.006
   Salazar A, 2014, MACH VISION APPL, V25, P859, DOI 10.1007/s00138-013-0579-9
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P762, DOI 10.1016/j.imavis.2012.01.006
   Schneider David C., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P304, DOI 10.1109/ICCVW.2009.5457684
   Shuai Tang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P525, DOI 10.1007/978-3-642-37444-9_41
   Siarry P, 1997, ACM T MATH SOFTWARE, V23, P209, DOI 10.1145/264029.264043
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   Wang ZJ, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P295, DOI 10.1109/3DV.2013.46
   Warren J., 2001, SUBDIVISION METHODS
   Xiangyu Zhu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163096
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yin LJ, 2008, IEEE INT CONF AUTOMA, P116
NR 52
TC 35
Z9 40
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 3
EP 12
DI 10.1016/j.imavis.2016.10.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700002
DA 2024-07-18
ER

PT J
AU Gecer, B
   Azzopardi, G
   Petkov, N
AF Gecer, Bads
   Azzopardi, George
   Petkov, Nicolai
TI Color-blob-based COSFIRE filters for object recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object recognition; Object representation; Color; Feature extraction;
   Trainable filters
ID COMBINING COLOR; SHAPE; CATEGORIZATION; VIEWPOINT; CELLS; MODEL
AB Most object recognition methods rely on contour-defined features obtained by edge detection or region segmentation. They are not robust to diffuse region boundaries. Furthermore, such methods do not exploit region color information. We propose color-blob-based COSFIRE (Combination of Shifted Filter Responses) filters to be selective for combinations of diffuse circular regions (blobs) in specific mutual spatial arrangements. Such a filter combines the responses of a certain selection of Difference-of-GausSians filters, essentially blob detectors, of different scales, in certain channels of a color space, and at certain relative positions to each other. Its parameters are determined learned in an automatic configuration process that analyzes the properties of a given prototype object of interest. We use these filters to compute features that are effective for the recognition of the prototype objects. We form feature vectors that we use With an SVM classifier. We evaluate the proposed method on a traffic sign (GTSRB) and a butterfly data sets. For the GTSRB data set we achieve a recognition rate of 98.94%, which is slightly higher than human performance and for the butterfly data set we achieve 89.029 The proposed color-blob-based COSFIRE filters are very effective and outperform the contour-based COSFIRE filters. A COSFIRE filter is trainable, it can be configured with a single prototype pattern and it does not require domain knowledge. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Gecer, Bads] Imperial Coll London, Imperial Comp Vis & Learning Lab ICVL, London, England.
   [Azzopardi, George] Univ Malta, Intelligent Comp Syst, Msida, Malta.
   [Azzopardi, George; Petkov, Nicolai] Univ Groningen, Johann Bernoulli Inst Math & Comp Sci, Groningen, Netherlands.
C3 Imperial College London; University of Malta; University of Groningen
RP Gecer, B (corresponding author), Imperial Coll London, Imperial Comp Vis & Learning Lab ICVL, London, England.
EM b.gecer@imperial.ac.uk; george.azzopardi@um.edu.mt; n.petkov@rug.nl
RI Azzopardi, George/AAJ-1250-2020
OI Azzopardi, George/0000-0001-6552-2596; Gecer, Baris/0000-0002-5684-2843
CR [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2014, ARXIV14047828
   [Anonymous], 2004, Proc. BMVC, DOI [DOI 10.5244/C.18.98, 10.5244/C.18.98]
   Azzopardi G., 2016, INCREASED GEN CAPABI
   Azzopardi G., 2016, GENDER RECOGNITION F
   Azzopardi G, 2015, MED IMAGE ANAL, V19, P46, DOI 10.1016/j.media.2014.08.002
   Azzopardi G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098424
   Azzopardi G, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00080
   Azzopardi G, 2013, IEEE T PATTERN ANAL, V35, P490, DOI 10.1109/TPAMI.2012.106
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bertozzi M, 2000, ROBOT AUTON SYST, V32, P1, DOI 10.1016/S0921-8890(99)00125-6
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bunte K, 2011, PATTERN RECOGN, V44, P1892, DOI 10.1016/j.patcog.2010.10.024
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023
   Conway BR, 2010, J NEUROSCI, V30, P14955, DOI 10.1523/JNEUROSCI.4348-10.2010
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Diplaros A, 2006, IEEE T IMAGE PROCESS, V15, P1, DOI 10.1109/TIP.2005.860320
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   IRVIN GE, 1993, VISUAL NEUROSCI, V10, P363, DOI 10.1017/S0952523800003758
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Kingdom FAA, 1997, VISION RES, V37, P1039
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruizinga P, 2000, BIOL CYBERN, V83, P313, DOI 10.1007/s004220000153
   Laika A., 2007, IMAGE ANAL MULTIMEDI, P10
   Larlus D, 2009, IMAGE VISION COMPUT, V27, P523, DOI 10.1016/j.imavis.2008.04.022
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   LIVINGSTONE MS, 1987, J NEUROSCI, V7, P3416
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mapelli D, 1997, NEUROCASE, V3, P237
   Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011
   Mondéjar-Guerra VM, 2015, INT J APPROX REASON, V60, P57, DOI 10.1016/j.ijar.2015.03.001
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Petkov N., 2005, MODIFICATIONS CTR SU
   Ranzato M., 2007, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition. isbn, P1, DOI DOI 10.1109/CVPR.2007.383157
   Schneider P, 2009, NEURAL COMPUT, V21, P3532, DOI 10.1162/neco.2009.11-08-908
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Solomon SG, 2007, NAT REV NEUROSCI, V8, P276, DOI 10.1038/nrn2094
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tanaka JW, 1999, PERCEPT PSYCHOPHYS, V61, P1140, DOI 10.3758/BF03207619
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Tkalcic M., 2003, COLOUR SPACES PERCEP
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Xu XM, 2002, VISUAL NEUROSCI, V19, P703, DOI 10.1017/S0952523802196027
   Yang KF, 2013, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2013.362
   Yu H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P929, DOI 10.1109/ICIP.2002.1039125
   Zaklouta F, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2151, DOI 10.1109/IJCNN.2011.6033494
   ZEKI S, 1991, J NEUROSCI, V11, P641
   Zhang Y, 2014, BIOL CYBERN, V108, P275, DOI 10.1007/s00422-013-0583-1
NR 63
TC 28
Z9 32
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 165
EP 174
DI 10.1016/j.imavis.2016.10.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800013
OA Green Published
DA 2024-07-18
ER

PT J
AU Bourlai, T
   Mavridis, N
   Narang, N
AF Bourlai, Thirimachos
   Mavridis, Nikolaos
   Narang, Neeru
TI On designing practical long range near infrared-based face recognition
   systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Forensics; Face recognition; Near infrared; Cross-scenario face
   matching; Demographic information; Night-time; Long-distance; Score
   level fusion
ID EIGENFACES
AB Although automated face recognition (AFR) is a well-studied problem with a history of more than three decades, it is still far from being considered a solved problem for the case of difficult exposure conditions, such as during night-time, in environments with unconstrained lighting, or at large distances from the camera. However, in practical forensic scenarios, it is often the case that investigators operate in difficult conditions, where cross-session data need to be matched and where, grouping of the data in the context of demographic information (constitute the grouping in terms of gender, ethnicity) may be used in order to assist law enforcement officials, forensic investigators and security personnel in human identification practices. In this paper, we discuss the challenges in designing a practical near infrared (NIR) FR system and, more specifically, study the problems of intra-spectral, cross-spectral, i.e. VIS-NIR, intra-distance and cross distance NIR FR, in indoors, outdoors, day-time and night-time environments. Furthermore, we propose the usage of a multi-feature scenario dependent fusion scheme that can enhance recognition performance. We also investigate which scenarios used, related to datasets, features useful for face matching or their combination, are most beneficial to the identification accuracy of NIR FR systems, when the gallery set is composed of either visible or NIR band face images. Thus, we illustrate that the selection of specific feature extraction techniques and their fusion are often the key design aspects that can turn practically non-functional systems to effective systems with real-world applicability. As a result, such a strategy can significantly extend the range of conditions under which automated NIR FR systems can operate. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Bourlai, Thirimachos; Narang, Neeru] West Virginia Univ, POB 6201, Morgantown, WV 26506 USA.
   [Mavridis, Nikolaos] NCSR Demokritos, IRML, GR-15310 Attiki, Greece.
C3 West Virginia University; National Centre of Scientific Research
   "Demokritos"
RP Bourlai, T (corresponding author), West Virginia Univ, POB 6201, Morgantown, WV 26506 USA.; Mavridis, N (corresponding author), NCSR Demokritos, IRML, GR-15310 Attiki, Greece.
EM Thirimachos.Bourlai@mail.wvu.edu
OI Bourlai, Thirimachos/0000-0001-8751-0836
FU Center for Identification Technology Research; National Science
   Foundation [1066197]; Direct For Computer & Info Scie & Enginr [1066197]
   Funding Source: National Science Foundation; Division Of Computer and
   Network Systems [1066197] Funding Source: National Science Foundation
FX This material is sponsored partly through the start-up funds of Dr.
   Bourlai, and is also based upon work supported by the Center for
   Identification Technology Research and the National Science Foundation
   under Grant No. 1066197. The authors are also grateful to Dr. J. Dawson,
   Nathan Kalka and other WVU faculty and students that supported this
   work. Thanks to Chuck Coleman (Supervisor Sr. Lab Instr. Spec.,
   Mechanical and Aerospace Engineering, WVU) for designing and developing
   the weatherproof enclosure of our camera system. Thanks to J. VonDollen
   for his help to design the experimental set-up and to collect the data
   as part of his Masters degree. Finally, special thanks to all Vumii
   Imaging Inc. personnel for their great support and guidance to help us
   prepare the system to its current operational form.
CR Abaza A, 2012, INT C PATT RECOG, P3103
   [Anonymous], SPIE NEWSROOM MAGAZI
   [Anonymous], IEEE T INF FORENSICS
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], P SPIE
   [Anonymous], FACEVACS SOFTW DEV K
   [Anonymous], 2013, MSUCSE134
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], THESIS
   [Anonymous], ACM COMPUT SURV
   [Anonymous], P SPIE INFR IM SYST
   Belhumeur P. N., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P45
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bolme DS, 2003, LECT NOTES COMPUT SC, V2626, P304
   Bourke T, 2013, SAGE OPEN, V3, DOI 10.1177/2158244013511261
   Bourlai T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P54, DOI 10.1109/THS.2013.6698976
   Bourlai T., 2012, Proceedings of the 2012 IEEE International Conference on Intelligence and Security Informatics. Cyberspace, Border, and Immigration Securities (ISI 2012), P196, DOI 10.1109/ISI.2012.6284307
   Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832
   Davies M, 2006, POVERTY AND THE PRODUCTION OF WORLD POLITICS, P1
   Davis M., 2005, 13th Annual ACM International Conference on Multimedia, P483, DOI 10.1145/1101149.1101257
   Grattan KTV, 2013, 2013 IEEE 6TH INTERNATIONAL CONFERENCE ON ADVANCED INFOCOMM TECHNOLOGY (ICAIT), P1, DOI 10.1109/ICAIT.2013.6621468
   Huang D, 2007, LECT NOTES COMPUT SC, V4842, P437
   Kalka NathanD., 2011, BIOMETRICS IJCB 2011, P1, DOI DOI 10.1109/1JCB.2011.6117586
   Kang D, 2014, PATTERN RECOGN, V47, P3750, DOI 10.1016/j.patcog.2014.06.004
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Liao SC, 2009, LECT NOTES COMPUT SC, V5558, P209, DOI 10.1007/978-3-642-01793-3_22
   Lin DH, 2010, LECT NOTES COMPUT SC, V6311, P243
   Maeng H., 2012, Asian Conference on Computer Vision Conference on Computer Vision ACCV, P5
   Nefian AV, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P141, DOI 10.1109/ICIP.1998.723445
   Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148
   Pietäinen M, 2005, LECT NOTES COMPUT SC, V3540, P115
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Shen LL, 2012, LECT NOTES ARTIF INT, V6839, P404
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang R, 2009, LECT NOTES COMPUT SC, V5558, P319, DOI 10.1007/978-3-642-01793-3_33
   Wiskott L, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P129, DOI 10.1109/ICIP.1997.647401
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yi D, 2007, LECT NOTES COMPUT SC, V4642, P523
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang ZD, 2011, PHASE TRANSIT, V84, P299, DOI 10.1080/01411594.2010.535351
   Zhao SY, 2005, LECT NOTES ARTIF INT, V3587, P437
NR 48
TC 4
Z9 5
U1 2
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 25
EP 41
DI 10.1016/j.imavis.2016.04.013
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400003
OA hybrid
DA 2024-07-18
ER

PT J
AU Bhole, C
   Pal, C
AF Bhole, Chetan
   Pal, Christopher
TI Fully automatic person segmentation in unconstrained video using
   spatio-temporal conditional random fields
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person segmentation; Video segmentation; Conditional random field;
   Optical flow; Fully automatic
ID POSE ESTIMATION
AB The segmentation of objects and people in particular is an important problem in computer vision. In this paper, we focus on automatically segmenting a person from challenging video sequences in which we place no constraint on camera viewpoint, camera motion or the movements of a person in the scene. Our approach uses the most confident predictions from a pose detector as a form of anchor or keyframe stick figure prediction which helps guide the segmentation of other more challenging frames in the video. Since even state of the art pose detectors are unreliable on many frames especially given that we are interested in segmentations with no camera or motion constraints only the poses or stick figure predictions for frames with the highest confidence in a localized temporal region anchor further processing. The stick figure predictions within confident keyframes are used to extract color, position and optical flow features. Multiple conditional random fields (CRFs) are used to process blocks of video in batches, using a two dimensional CRF for detailed keyframe segmentation as well as 3D CRFs for propagating segmentations to the entire sequence of frames belonging to batches. Location information derived from the pose is also used to refine the results. Importantly, no hand labeled training data is required by our method. We discuss the use of a continuity method that reuses learnt parameters between batches of frames and show how pose predictions can also be improved by our model. We provide an extensive evaluation of our approach, comparing it with a variety of alternative grab cut based methods and a prior state of the art method. We also release our evaluation data to the community to facilitate further experiments. We find that our approach yields state of the art qualitative and quantitative performance compared to prior work and more heuristic alternative approaches. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Bhole, Chetan] Univ Rochester, Rochester, NY 14620 USA.
   [Pal, Christopher] Univ Montreal, Montreal, PQ, Canada.
C3 University of Rochester; Universite de Montreal
RP Bhole, C (corresponding author), Univ Rochester, Rochester, NY 14620 USA.
EM bhole@cs.rochester.edu
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2011, COMPUTER VISION PATT
   [Anonymous], 2010, IEEE C COMP VIS PATT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2004, IEEE T PATT ANAL MAC
   [Anonymous], 2010, PASCAL VISUAL OBJECT
   Bhat P., 2007, P ESRT GREN FRANC, P327
   Bhole C, 2012, INT C PATT RECOG, P3672
   Bi S., 2006, World Congress on Intelligent Control and Automation, V2, P9587
   Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Niebles JC, 2010, PROC CVPR IEEE, P655, DOI 10.1109/CVPR.2010.5540152
   Chen A., 2010, P WNYIPW WORKSH
   Chen A.Y.C., 2011, P 2011 IEEE WORKSH M
   Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572
   Gulshan V., 2011, IEEE WORKSH INT C CO
   Gupta M., 2006, INTERACTIVE SEGMENTA
   Hernandez A., 2010, Computer Vision and Pattern Recognition Workshop, P33
   Jojic N, 2001, PROC CVPR IEEE, P199
   Kohli P, 2008, INT J COMPUT VISION, V79, P285, DOI 10.1007/s11263-007-0120-6
   Kolmogorov V, 2005, PROC CVPR IEEE, P407
   Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234
   Liu Ce, 2009, THESIS
   Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mori G, 2004, PROC CVPR IEEE, P326
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rochan M., 2014, 11 C COMP ROB VIS
   Rodriguez M., 2007, Proceedings of the 15th international conference on Multimedia, MULTIMEDIA '07, P353
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Wang L, 2011, PROC CVPR IEEE
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Yin Pei., 2007, P IEEE C COMPUTER VI, P1, DOI DOI 10.1109/CVPR.2007.383008
   Zhang Lei., 2008, WMVC '08: Proceedings of the 2008 IEEE Workshop on Motion and video Computing, P1
NR 36
TC 5
Z9 7
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2016
VL 51
BP 58
EP 68
DI 10.1016/j.imavis.2016.04.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4HB
UT WOS:000378455900006
DA 2024-07-18
ER

PT J
AU Calarasanu, S
   Fabrizio, J
   Dubuisson, S
AF Calarasanu, Stefania
   Fabrizio, Jonathan
   Dubuisson, Severine
TI What is a good evaluation protocol for text localization systems?
   Concerns, arguments, comparisons and solutions
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Evaluation protocol; Text detection
ID NATURAL SCENE IMAGES; PERFORMANCE EVALUATION; OBJECT DETECTION;
   FRAMEWORK; CONTEXT
AB A trustworthy protocol is essential to evaluate a text detection algorithm in order to, first measure its efficiency and adjust its parameters and, second to compare its performances with those of other algorithms. However, current protocols do not give precise enough evaluations because they use coarse evaluation metrics, and deal with inconsistent matchings between the output of detection algorithms and the ground truth, both often limited to rectangular shapes. In this paper, we propose a new evaluation protocol, named EvaLTex, that solves some of the current problems associated with classical metrics and matching strategies. Our system deals with different kinds of annotations and detection shapes. It also considers different kinds of granularity between detections and ground truth objects and hence provides more realistic and accurate evaluation measures. We use this protocol to evaluate text detection algorithms and highlight some key examples that show that the provided scores are more relevant than those of currently used evaluation protocols. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Calarasanu, Stefania; Fabrizio, Jonathan] EPITA Res & Dev Lab LRDE, 14-16 Rue Voltaire, F-94276 Le Kremlin Bicetre, France.
   [Dubuisson, Severine] Univ Paris 06, Sorbonne Univ, CNRS, UMR 7222,ISIR, F-75005 Paris, France.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS)
RP Calarasanu, S (corresponding author), EPITA Res & Dev Lab LRDE, 14-16 Rue Voltaire, F-94276 Le Kremlin Bicetre, France.
EM calarasanu@lrde.epita.fr
FU FUI 14 (LINX project)
FX This work was partially supported by FUI 14 (LINX project).
CR [Anonymous], 2014, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2014.2353813
   [Anonymous], 2013, INT WORKSHOP BIOMETR, DOI DOI 10.1109/IWBF.2013.6547306
   Anthimopoulos M, 2010, IMAGE VISION COMPUT, V28, P1413, DOI 10.1016/j.imavis.2010.03.004
   Bai B, 2013, PROC INT CONF DOC, P1380, DOI 10.1109/ICDAR.2013.279
   Chucai Yi, 2012, Camera-Based Document Analysis and Recognition. 4th International Workshop, CBDAR 2011. Revised Selected Papers, P15, DOI 10.1007/978-3-642-29364-1_2
   Clavelli A., 2010, Proceedings of the 9th IAPR International Workshop on Document Analysis Systems, P19
   Du YN, 2012, IEEE IMAGE PROC, P1857, DOI 10.1109/ICIP.2012.6467245
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fabrizio J, 2013, PATTERN ANAL APPL, V16, P519, DOI 10.1007/s10044-013-0329-7
   HUA XS, 2001, INT C DOC AN REC, P545
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514
   Karaoglu S., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P635, DOI 10.1109/DICTA.2010.115
   Karaoglu S, 2012, LECT NOTES COMPUT SC, V7585, P456, DOI 10.1007/978-3-642-33885-4_46
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082
   Kumar Deepak., 2013, INT WORKSH MULT OCR, V14:1-14:5
   Lee JJ, 2011, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2011.93
   Li Y, 2013, IEEE IMAGE PROC, P2264, DOI 10.1109/ICIP.2013.6738467
   Lu SJ, 2015, INT J DOC ANAL RECOG, V18, P125, DOI 10.1007/s10032-015-0237-z
   Lucas S. M., 2005, International Journal on Document Analysis and Recognition, V7, P105, DOI 10.1007/s10032-004-0134-3
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Ma YC, 2007, PROC INT CONF DOC, P1033
   Mao J., 2013, Proceedings of ACM MM'13, ACM, P1007
   Mao S., 2002, INT J DOC ANAL RECOG, V4, P205
   Mariano VY, 2002, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2002.1048198
   Merino-Gracia K., 2011, P 4 INT WORKSH CAM B, P29, DOI DOI 10.1007/978-3-642-29364-1_3
   Nagy Robert, 2012, Camera-Based Document Analysis and Recognition. 4th International Workshop, CBDAR 2011. Revised Selected Papers, P150, DOI 10.1007/978-3-642-29364-1_12
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Phan T.Q., 2012, Proceedings of ACM MM'12, ACM, P765
   Posner I, 2010, IEEE INT C INT ROBOT, P3181, DOI 10.1109/IROS.2010.5653151
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   SeongHun Lee, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3983, DOI 10.1109/ICPR.2010.969
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shi CZ, 2014, PATTERN RECOGN, V47, P2853, DOI 10.1016/j.patcog.2014.03.023
   Shi CZ, 2013, PATTERN RECOGN LETT, V34, P107, DOI 10.1016/j.patrec.2012.09.019
   Shivakumara P, 2013, PROC INT CONF DOC, P594, DOI 10.1109/ICDAR.2013.123
   Shivakumara Palaiahnakote, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P156, DOI 10.1109/ICDAR.2009.85
   Shivakumara Palaiahnakote, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1285, DOI 10.1109/ICDAR.2009.83
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Shuang Liu, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P123, DOI 10.1007/978-3-319-13168-9_13
   Sun L, 2014, INT C PATT RECOG, P2715, DOI 10.1109/ICPR.2014.469
   Sun L, 2015, PATTERN RECOGN, V48, P2906, DOI 10.1016/j.patcog.2015.04.002
   Phan TQ, 2013, IEEE I CONF COMP VIS, P569, DOI 10.1109/ICCV.2013.76
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wang XB, 2013, PROC INT CONF DOC, P1375, DOI 10.1109/ICDAR.2013.278
   Weinman JJ, 2009, IEEE T PATTERN ANAL, V31, P1733, DOI 10.1109/TPAMI.2009.38
   Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0
   Xiaodong Huang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3216, DOI 10.1109/ICPR.2010.786
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2014, LECT NOTES COMPUT SC, V8357, P47, DOI 10.1007/978-3-319-05167-3_4
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yi CC, 2011, PROC INT CONF DOC, P177, DOI 10.1109/ICDAR.2011.44
   Yi CC, 2011, IEEE T IMAGE PROCESS, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Yi-Feng Pan, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P6, DOI 10.1109/ICDAR.2009.97
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zagoris K, 2013, PROC INT CONF DOC, P1370, DOI 10.1109/ICDAR.2013.277
   Zhang J, 2014, LECT NOTES COMPUT SC, V8357, P71, DOI 10.1007/978-3-319-05167-3_6
NR 63
TC 6
Z9 6
U1 0
U2 31
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2016
VL 46
BP 1
EP 17
DI 10.1016/j.imavis.2015.12.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DH3IJ
UT WOS:000372680400001
DA 2024-07-18
ER

PT J
AU Serratosa, F
AF Serratosa, Francesc
TI Computation of graph edit distance: Reasoning about optimality and
   speed-up
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Error-tolerant graph matching; Bipartite graph matching algorithm; Fast
   Bipartite; Square Fast Bipartite; Hungarian method; Jonker-Volgenant
   solver
ID OBJECT RECOGNITION; ALGORITHM; ASSIGNMENT; ISOMORPHISM; DATABASE
AB Bipartite graph matching has been demonstrated to be one of the most efficient algorithms to solve error-tolerant graph matching. This algorithm is based on defining a cost matrix between the whole nodes of both graphs and solving the nodes' correspondence through a linear assignment method (for instance, Hungarian or Jonker-Volgenant methods). Recently, two versions of this algorithm have been published called Fast Bipartite and Square Fast Bipartite. They compute the same distance value than Bipartite but with a reduced runtime if some restrictions on the edit costs are considered. In this paper, we do not present a new algorithm but we compare the three versions of Bipartite algorithm and show how the violation of the theoretically imposed restrictions in Fast Bipartite and Square Fast Bipartite do not affect the algorithm's performance. That is, in practice, we show that these restrictions do not affect the optimality of the algorithm and so, the three algorithms obtain similar distances and recognition ratios in classification applications although the restrictions do not hold. Moreover, we conclude that the Square Fast Bipartite with the Jonker-Volgenant solver is the fastest algorithm. (C) 2015 Elsevier B.V. All rights reserved.
C1 Univ Rovira & Virgili, E-43007 Tarragona, Spain.
C3 Universitat Rovira i Virgili
RP Serratosa, F (corresponding author), Univ Rovira & Virgili, E-43007 Tarragona, Spain.
EM francesc.serratosa@urv.cat
RI Serratosa, Francesc/Q-3359-2019
OI Serratosa, Francesc/0000-0001-6112-5913
FU  [DPI2013-42458-P];  [TIN2013-47245-C2-2-R]
FX This research is supported by the Spanish projects DPI2013-42458-P and
   TIN2013-47245-C2-2-R.
CR [Anonymous], PATTERN RECOGN
   [Anonymous], IJPRAI
   [Anonymous], LNCS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 1974, P 6 ANN ACM S THEORY
   BOURGEOIS F, 1971, COMMUN ACM, V14, P802, DOI 10.1145/362919.362945
   Bunke H, 1983, PATTERN RECOGN LETT, V1, P245, DOI 10.1016/0167-8655(83)90033-8
   Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Cortés X, 2015, PATTERN RECOGN LETT, V56, P22, DOI 10.1016/j.patrec.2015.01.009
   Cortés X, 2015, EXPERT SYST APPL, V42, P179, DOI 10.1016/j.eswa.2014.07.051
   Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9
   Dickinson PJ, 2004, PATTERN ANAL APPL, V7, P243, DOI [10.1007/s10044-004-0222-5, 10.1007/s10044-044-0222-5]
   Fankhauser S, 2011, LECT NOTES COMPUT SC, V6658, P102, DOI 10.1007/978-3-642-20844-7_11
   Fischer A, 2015, PATTERN RECOGN, V48, P331, DOI 10.1016/j.patcog.2014.07.015
   Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013
   Gao XB, 2010, PATTERN ANAL APPL, V13, P113, DOI 10.1007/s10044-008-0141-y
   Gaüzère B, 2014, LECT NOTES COMPUT SC, V8621, P73, DOI 10.1007/978-3-662-44415-3_8
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Hancock ER, 2012, PATTERN RECOGN LETT, V33, P833, DOI 10.1016/j.patrec.2011.08.012
   He L, 2004, PATTERN RECOGN, V37, P1557, DOI [10.1016/j.patcog.2003.12.01, 10.1016/j.patcog.2003.12.011]
   Jiang XY, 1999, PATTERN RECOGN, V32, P1273, DOI 10.1016/S0031-3203(98)00145-9
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710
   Justice D, 2006, IEEE T PATTERN ANAL, V28, P1200, DOI 10.1109/TPAMI.2006.152
   Konc J, 2007, LECT NOTES COMPUT SC, V4432, P399
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   LUKS EM, 1982, J COMPUT SYST SCI, V25, P42, DOI 10.1016/0022-0000(82)90009-5
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Myers R, 2000, IEEE T PATTERN ANAL, V22, P628, DOI 10.1109/34.862201
   Neuhaus M, 2004, LECT NOTES COMPUT SC, V3138, P180
   Rebagliati N, 2012, INT C PATT RECOG, P1080
   Riesen Kaspar, 2014, Artificial Neural Networks in Pattern Recognition. 6th IAPR TC 3 International Workshop, ANNPR 2014. Proceedings: LNCS 8774, P117, DOI 10.1007/978-3-319-11656-3_11
   Riesen K, 2014, LECT NOTES COMPUT SC, V8621, P63, DOI 10.1007/978-3-662-44415-3_7
   Riesen K, 2009, IMAGE VISION COMPUT, V27, P950, DOI 10.1016/j.imavis.2008.04.004
   Riesen K, 2008, LECT NOTES COMPUT SC, V5342, P287
   Sanfeliu A, 2004, INT J PATTERN RECOGN, V18, P375, DOI 10.1142/S0218001404003253
   SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175
   Sanfeliu A, 2002, PATTERN RECOGN, V35, P639, DOI 10.1016/S0031-3203(01)00066-8
   Sanromà G, 2012, COMPUT VIS IMAGE UND, V116, P292, DOI 10.1016/j.cviu.2011.10.009
   Serratosa F, 2015, PATTERN RECOGN, V48, P1364, DOI 10.1016/j.patcog.2014.10.033
   Serratosa F, 2014, PATTERN RECOGN LETT, V45, P244, DOI 10.1016/j.patrec.2014.04.015
   Serratosa F, 2013, EXPERT SYST APPL, V40, P2493, DOI 10.1016/j.eswa.2012.10.071
   Serratosa F, 2012, EXPERT SYST APPL, V39, P7302, DOI 10.1016/j.eswa.2012.01.088
   Solé-Ribalta A, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413500018
   Solé-Ribalta A, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S021800141260004X
   Solé-Ribalta A, 2011, COMPUT VIS IMAGE UND, V115, P929, DOI 10.1016/j.cviu.2010.12.007
   Sorlin S, 2005, LECT NOTES COMPUT SC, V3434, P172
   Torsello A, 2005, IEEE T PATTERN ANAL, V27, P1087, DOI 10.1109/TPAMI.2005.146
   UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778
   Williams ML, 1997, PATTERN RECOGN LETT, V18, P1275, DOI 10.1016/S0167-8655(97)00117-7
   Wilson RC, 2005, IEEE T PATTERN ANAL, V27, P1112, DOI 10.1109/TPAMI.2005.145
   Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251
NR 52
TC 41
Z9 41
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2015
VL 40
BP 38
EP 48
DI 10.1016/j.imavis.2015.06.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CO4YD
UT WOS:000359165900004
DA 2024-07-18
ER

PT J
AU Khim, S
   Hong, S
   Kim, Y
   Rhee, PK
AF Khim, Sarang
   Hong, Sungjin
   Kim, Yoonyoung
   Rhee, Phill Kyu
TI Adaptive visual tracking using the prioritized Q-learning algorithm:
   MDP-based parameter learning approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Adaptive visual tracking; Prioritized Q-learning; Markov decision
   process; Dynamic parameter optimization
ID IMAGE SEGMENTATION; OBJECT TRACKING; RECOGNITION; MODELS
AB This paper introduces an adaptive visual tracking method that combines the adaptive appearance model and the optimization capability of the Markov decision process. Most tracking algorithms are limited due to variations in object appearance from changes in illumination, viewing angle, object scale, and object shape. This paper is motivated by the fact that tracking performance degradation is caused not only by changes in object appearance but also by the inflexible controls of tracker parameters. To the best of our knowledge, optimization of tracker parameters has not been thoroughly investigated, even though it critically influences tracking performance. The challenge is to equip an adaptive tracking algorithm with an optimization capability for a more flexible and robust appearance model. In this paper, the Markov decision process, which has been applied successfully in many dynamic systems, is employed to optimize an adaptive appearance model-based tracking algorithm. The adaptive visual tracking is formulated as a Markov decision process based dynamic parameter optimization problem with uncertain and incomplete information. The high computation requirements of the Markov decision process formulation are solved by the proposed prioritized Q-learning approach. We carried out extensive experiments using realistic video sets, and achieved very encouraging and competitive results. (C) 2014 Inha University. Published by Elsevier B.V.
C1 [Khim, Sarang; Hong, Sungjin; Kim, Yoonyoung] Inha Univ, Inchon, South Korea.
   [Rhee, Phill Kyu] Inha Univ, Dept Comp Sci & Informat Technol, Inchon, South Korea.
C3 Inha University; Inha University
RP Khim, S (corresponding author), Inha Univ, 235 Yong Hyun Dong, Inchon, South Korea.
EM sarang.khim@gmail.com; sjhong0117@gmail.com; yoonyoung.kim@inha.ac.kr;
   pkrhee@inha.ac.kr
RI Rhee, Phill Kyu/AAP-5810-2021
FU Ministry of Education, Science Technology; Inha University; Inha
   University research grant
FX This work was supported by an Inha University research grant. And
   following are results of a study on the "Leaders in industry-university
   Cooperation" Project, supported by the Ministry of Education, Science &
   Technology and Inha University.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2012, P EUR C COMP VIS
   [Anonymous], 1994, P IEEE C COMP VIS PA
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2012, P EUR C COMP VIS
   [Anonymous], 2006, P SIGGRAPH COURSE
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   BARTO AG, 1995, ARTIF INTELL, V72, P81, DOI 10.1016/0004-3702(94)00011-O
   Bhanu B, 2000, IEEE T SYST MAN CY C, V30, P427, DOI 10.1109/5326.897070
   Busoniu L, 2008, IEEE T SYST MAN CY C, V38, P156, DOI 10.1109/TSMCC.2007.913919
   Chen Q, 2010, IEEE T CIRC SYST VID, V20, P605, DOI 10.1109/TCSVT.2010.2041819
   Chu-Carroll J, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P180
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Czitrom V, 1999, AM STAT, V53, P126, DOI 10.2307/2685731
   Grabner H., 2006, BMVC, P47
   Grabner H., 2010, IEEE C COMP VIS PATT
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Kalal Z., 2009, P INT C COMP VIS
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502
   Leibe B., IEEE T PATTERN ANAL, V30
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Paquet S., 2006, P WORKSH MULT SEQ DE
   Peng J, 1998, IEEE T SYST MAN CY C, V28, P482, DOI 10.1109/5326.704593
   Rahimi A, 2008, COMPUT VIS IMAGE UND, V109, P97, DOI 10.1016/j.cviu.2006.12.004
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Ross S, 2008, J ARTIF INTELL RES, V32, P663, DOI 10.1613/jair.2567
   Salti S, 2012, IEEE T IMAGE PROCESS, V21, P4334, DOI 10.1109/TIP.2012.2206035
   Shani G, 2005, J MACH LEARN RES, V6, P1265
   Shen Y, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013031
   Stalder Severin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1409, DOI 10.1109/ICCVW.2009.5457445
   Sutton R., 1998, Reinforcement Learning: An Introduction
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Wang JB, 2012, ADV INTEL SOFT COMPU, V137, P69
   Watkins C. J. C. H., 1989, LEARNING DELAYED REW
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang M, 2009, IEEE I CONF COMP VIS, P1554, DOI 10.1109/ICCV.2009.5459252
   Yang M, 2009, IEEE T IMAGE PROCESS, V18, P1633, DOI 10.1109/TIP.2009.2019807
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 46
TC 4
Z9 6
U1 1
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1090
EP 1101
DI 10.1016/j.imavis.2014.08.009
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600011
OA hybrid
DA 2024-07-18
ER

PT J
AU Xiao, JW
   Wei, H
AF Xiao, Jinwen
   Wei, Hui
TI Scale-invariant contour segment context in object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Shape descriptor; Scale-invariant; Contour segment
   context
ID SHAPE MODEL; RECOGNITION
AB The evaluation of the scale of an object in a cluttered background is a serious problem in computer vision. The most existing contour-based approaches relevant to object detection address this problem by normalizing descriptor or multi-scale searching, such as sliding-window searching, spatial pyramid model etc. Besides, Hough-voting framework can predict the scale of an object according to some meaning fragments. However, utilizing scale-variant descriptor or complicated structure in these measures reduces the efficiency of detection. In the present paper, we propose a novel shape feature called scale-invariant contour segment context (CSC). This feature is based on the angle between contour line segments. It remains unchanged as scale varies. Most importantly, it evaluates the scale of objects located in cluttered images and facilitates localization of the boundary of the object in unseen images simultaneously. In this way, we need to focus on just the shape matching algorithm without considering the variant scale of the object in an image. This is a procedure which absolutely differs from voting and sliding window searching. We do experiments on ETHZ shape dataset Weizmann horses dataset, and the bottle subset from PASCAL datasets. The results confirm that the present model of object detection, based on CSC, outperforms state-of-the-art of shape-based detection methods. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Xiao, Jinwen; Wei, Hui] Fudan Univ, Lab Cognit Algorithm Model, Dept Comp Sci, Shanghai Key Lab Data Sci, Shanghai 200433, Peoples R China.
C3 Fudan University
RP Wei, H (corresponding author), Fudan Univ, Lab Cognit Algorithm Model, Dept Comp Sci, Shanghai Key Lab Data Sci, Shanghai 200433, Peoples R China.
EM xiaojinwen@fudan.edu.cn; weihui@fudan.edu.cn
RI Wei, Hui/K-5819-2019
FU 973 Program [2010CB327900]; NSFC project [61375122, 81373556]; National
   Twelfth 5-Year Plan for Science Technology [2012BAI37B06]
FX This work was supported by the 973 Program (Project No. 2010CB327900),
   the NSFC project (Project No. 61375122, No. 81373556) and the National
   Twelfth 5-Year Plan for Science & Technology (Project No. 2012BAI37B06).
CR [Anonymous], MATLAB and Octave functions for computer vision and image processing
   [Anonymous], 2011, ADV NEURAL INFORM PR
   [Anonymous], COMP VIS PATT REC WO
   Bai X, 2009, IEEE I CONF COMP VIS, P575, DOI 10.1109/ICCV.2009.5459188
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cao X., 2013, COMP VIS ICCV 2013 I
   Chang W, 2013, IET COMPUT VIS, V7, P90, DOI 10.1049/iet-cvi.2011.0180
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Hu WZ, 2011, IEEE I CONF COMP VIS, P1808, DOI 10.1109/ICCV.2011.6126447
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Laptev I, 2009, IMAGE VISION COMPUT, V27, P535, DOI 10.1016/j.imavis.2008.08.010
   Leng DW, 2011, IET COMPUT VIS, V5, P291, DOI 10.1049/iet-cvi.2010.0098
   Lin L, 2012, PROC CVPR IEEE, P135, DOI 10.1109/CVPR.2012.6247668
   Lin LA, 2010, IEEE T PATTERN ANAL, V32, P1426, DOI 10.1109/TPAMI.2009.150
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu MY, 2010, PROC CVPR IEEE, P1696, DOI 10.1109/CVPR.2010.5539837
   Lu CE, 2009, IEEE I CONF COMP VIS, P2288, DOI 10.1109/ICCV.2009.5459446
   Ma TY, 2011, PROC CVPR IEEE, P1441, DOI 10.1109/CVPR.2011.5995591
   Maji S, 2009, PROC CVPR IEEE, P1038, DOI 10.1109/CVPRW.2009.5206693
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   Riemenschneider H, 2010, LECT NOTES COMPUT SC, V6315, P29, DOI 10.1007/978-3-642-15555-0_3
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Shokoufandeh A, 2012, IET COMPUT VIS, V6, P500, DOI 10.1049/iet-cvi.2012.0030
   Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772
   Shotton Jamie., 2008, BMVC, P1
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Srinivasan P, 2010, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2010.5539834
   Thayananthan A, 2003, PROC CVPR IEEE, P127
   Wang B, 2010, LECT NOTES COMPUT SC, V6315, P15, DOI 10.1007/978-3-642-15555-0_2
   Wang XG, 2012, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.2012.6247670
   Wei H, 2013, APPL SOFT COMPUT, V13, P302, DOI 10.1016/j.asoc.2012.08.036
   Weiyu Zhang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2393, DOI 10.1109/CVPR.2011.5995342
   Yang XW, 2012, PATTERN RECOGN, V45, P1927, DOI 10.1016/j.patcog.2011.11.010
   Yarlagadda P, 2012, LECT NOTES COMPUT SC, V7572, P766, DOI 10.1007/978-3-642-33718-5_55
   Yarlagadda P, 2010, LECT NOTES COMPUT SC, V6315, P197, DOI 10.1007/978-3-642-15555-0_15
   Zhu QH, 2008, LECT NOTES COMPUT SC, V5303, P774
NR 43
TC 9
Z9 10
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1055
EP 1066
DI 10.1016/j.imavis.2014.08.013
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600008
DA 2024-07-18
ER

PT J
AU Marras, I
   Tzimiropoulos, G
   Zafeiriou, S
   Pantic, M
AF Marras, Ioannis
   Tzimiropoulos, Georgios
   Zafeiriou, Stefanos
   Pantic, Maja
TI Online learning and fusion of orientation appearance models for robust
   rigid object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Rigid object tracking; Fusion of orientation appearance models; Subspace
   learning; Online learning; Face analysis; RGB-D
ID PRINCIPAL GEODESIC ANALYSIS; FACE RECOGNITION; PHOTOMETRIC STEREO;
   VISUAL TRACKING; 3D
AB We introduce a robust framework for learning and fusing of orientation appearance models based on both texture and depth information for rigid object tracking. Our framework fuses data obtained from a standard visual camera and dense depth maps obtained by low-cost consumer depth cameras such as the Kinect. To combine these two completely different modalities, we propose to use features that do not depend on the data representation: angles. More specifically, our framework combines image gradient orientations as extracted from intensity images with the directions of surface normals computed from dense depth fields. We propose to capture the correlations between the obtained orientation appearance models using a fusion approach motivated by the original Active Appearance Models (AAMs). To incorporate these features in a learning framework, we use a robust kernel based on the Euler representation of angles which does not require off-line training, and can be efficiently implemented online. The robustness of learning from orientation appearance models is presented both theoretically and experimentally in this work. This kernel enables us to cope with gross measurement errors, missing data as well as other typical problems such as illumination changes and occlusions. By combining the proposed models with a particle filter, the proposed framework was used for performing 2D plus 3D rigid object tracking, achieving robust performance in very difficult tracking scenarios including extreme pose variations. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Marras, Ioannis; Tzimiropoulos, Georgios; Zafeiriou, Stefanos; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
   [Tzimiropoulos, Georgios] Lincoln Univ, Sch Comp Sci, Lincoln LN6 7TS, England.
   [Pantic, Maja] Univ Twente, Dept Comp Sci, NL-7522 NB Enschede, Netherlands.
C3 Imperial College London; University of Lincoln; University of Twente
RP Marras, I (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.
EM i.marras@imperial.ac.uk; gt204@imperial.ac.uk;
   s.zafeiriou@imperial.ac.uk; m.pantic@imperial.ac.uk
OI Tzimiropoulos, Georgios/0000-0002-1803-5338
FU European Community [288235]; European Research Council under the ERC
   [ERC-2007-StG-203143]; EPSRC [EP/J017787/1]; EPSRC [EP/J017787/1,
   EP/H016988/1] Funding Source: UKRI
FX The research presented in this paper has been funded by the European
   Community 7th Framework Programme [FP7/2007-2013] under grant agreement
   no. 288235 (FROG). The work of Maja Pantic is funded by the European
   Research Council under the ERC Starting Grant agreement no.
   ERC-2007-StG-203143 (MAHNOB). The work of Stefanos Zafeiriou and
   partially the work of Ioannis Marras were funded by the EPSRC project
   EP/J017787/1 (4D-FAB).
CR [Anonymous], 2011, DAGM
   [Anonymous], 1996, Computer graphics: principles and practice
   [Anonymous], 2011, 2011 IEEE INT C AUTO, DOI 10.1109/FG.2011.5771457
   [Anonymous], 2009, P 2009 ACM SIGGRAPHE, DOI [DOI 10.1145/1599470.1599472, 10.1145/1599470.1599472]
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Baker S, 2001, PROC CVPR IEEE, P1090
   Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898
   Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Bronstein AM, 2007, IEEE T IMAGE PROCESS, V16, P188, DOI 10.1109/TIP.2006.884940
   Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Chin TJ, 2007, IEEE T IMAGE PROCESS, V16, P1662, DOI 10.1109/TIP.2007.896668
   Cook J., 2006, PROC BRIT MACHINE VI, P83
   Cootes T. F., 2001, IEEE C COMP VIS PATT
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Fanelli G., 2012, INT J COMPUT VIS
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   FISHER R, 1953, PROC R SOC LON SER-A, V217, P295, DOI 10.1098/rspa.1953.0064
   Fitch A. J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P133
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Gökberk B, 2008, IEEE T SYST MAN CY B, V38, P155, DOI 10.1109/TSMCB.2007.908865
   Grabner H., 2006, BMVC, P47
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Husken M., 2005, IEEE WORKSHOP FACE R, P174
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   KRZANOWSKI WJ, 1979, J AM STAT ASSOC, V74, P703, DOI 10.2307/2286995
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Marras I, 2012, LECT NOTES COMPUT SC, V7584, P230, DOI 10.1007/978-3-642-33868-7_23
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Moghaddam B., 1994, AUTOM SYST IDENTIF I, V2277, P1
   Morency LP, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P45
   Morency LP, 2003, PROC CVPR IEEE, P803
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari A, 2010, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2010.5539937
   Smith WAP, 2008, INT J COMPUT VISION, V76, P71, DOI 10.1007/s11263-007-0074-8
   Smith WAP, 2006, IEEE T PATTERN ANAL, V28, P1914, DOI 10.1109/TPAMI.2006.251
   Tsalakanidou F, 2005, IEEE T IMAGE PROCESS, V14, P152, DOI 10.1109/TIP.2004.840714
   Tzimiropoulos G, 2012, IEEE T PATTERN ANAL, V34, P2454, DOI 10.1109/TPAMI.2012.40
   Tzimiropoulos G, 2010, IEEE T PATTERN ANAL, V32, P1899, DOI 10.1109/TPAMI.2010.107
   Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Yang RG, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P255, DOI 10.1109/AFGR.2002.1004163
   Zafeiriou S, 2013, IEEE T INF FOREN SEC, V8, P121, DOI 10.1109/TIFS.2012.2224109
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 60
TC 4
Z9 4
U1 0
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 707
EP 727
DI 10.1016/j.imavis.2014.04.017
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700009
OA Green Accepted, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, YZ
   Dick, A
   Li, X
   van den Hengel, A
AF Chen, Yanzhi
   Dick, Anthony
   Li, Xi
   van den Hengel, Anton
TI Spatially aware feature selection and weighting for object retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object retrieval; Bag-of-words; Spatial expansion; Visual word
   re-weighting
AB Many recent image retrieval methods are based on the "bag-of-words" (BOW) model with some additional spatial consistency checking. This paper proposes a more accurate similarity measurement that takes into account spatial layout of visual words in an offline manner. The similarity measurement is embedded in the standard pipeline of the BoW model, and improves two features of the model: i) latent visual words are added to a query based on spatial co-occurrence, to improve query recall; and ii) weights of reliable visual words are increased to improve the precision. The combination of these methods leads to a more accurate measurement of image similarity. This is similar in concept to the combination of query expansion and spatial verification, but does not require query time processing, which is too expensive to apply to full list of ranked results. Experimental results demonstrate the effectiveness of our proposed method on three public datasets. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Chen, Yanzhi; Dick, Anthony; Li, Xi; van den Hengel, Anton] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
C3 University of Adelaide
RP Li, X (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
EM xi.li03@adelaide.edu.au
RI Li, Xi/L-1234-2013
OI Li, Xi/0000-0003-3023-1662; Dick, Anthony/0000-0001-9049-7345; van den
   Hengel, Anton/0000-0003-3027-8364
CR Agarwal S., 2009, P INT C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], BRIT MACH VIS C
   [Anonymous], THESIS U OXFORD
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2004, WORKSH STAT LEARN CO
   [Anonymous], 2005, P INT C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Chen Y, 2010, 2010 INTERNATIONAL FORUM ON BIOMEDICAL TEXTILE MATERIALS, PROCEEDINGS, P8, DOI 10.1109/DICTA.2010.11
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2010, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2010.5539997
   Chum O, 2010, IEEE T PATTERN ANAL, V32, P371, DOI 10.1109/TPAMI.2009.166
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fergus R, 2003, PROC CVPR IEEE, P264
   Gavves Efstratios., 2010, Proceedings of the International Conference on Multimedia, MM '10, P1123
   Jain M., 2011, P ACM INT C MULT
   JAYNES ET, 1957, PHYS REV, V108, P171, DOI 10.1103/PhysRev.108.171
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Jiang Yuning, 2012, P IEEE C COMP VIS PA
   Lebrun J., IMAGE VISION COMPUTI
   Mikulík A, 2010, LECT NOTES COMPUT SC, V6313, P1
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nister David, 2006, CVPR
   Philbin J, 2011, INT J COMPUT VISION, V95, P138, DOI 10.1007/s11263-010-0363-5
   Philbin J, 2010, LECT NOTES COMPUT SC, V6313, P677
   Qin Danfeng, 2011, P IEEE C COMP VIS PA
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Tang W., 2011, P 19 ACM INT C MULT, P503
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
NR 37
TC 6
Z9 12
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2013
VL 31
IS 12
BP 935
EP 948
DI 10.1016/j.imavis.2013.09.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 282DU
UT WOS:000329151300004
DA 2024-07-18
ER

PT J
AU Asmaa, O
   Mokhtar, K
   Abdelaziz, O
AF Asmaa, Ouessai
   Mokhtar, Keche
   Abdelaziz, Ouamri
TI Road traffic density estimation using microscopic and macroscopic
   parameters
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Road traffic density estimation; Microscopic and macroscopic traffic
   parameters; Motion detection and tracking; KNN; LVQ; SVM
AB In this paper we present a comparative study of two approaches for road traffic density estimation. The first approach uses the microscopic parameters which are extracted using both motion detection and tracking methods from a video sequence, and the second approach uses the macroscopic parameters which are directly estimated by analyzing the global motion in the video scene. The extracted parameters are applied to three classifiers, the K Nearest Neighbor (KNN) classifier, the LVQ classifier and the SVM classifier, in order to classify the road traffic in three categories: light, medium and heavy. The methods are compared based on their robustness to the classification of different road traffic states. The goal of this study is to propose an algorithm for road traffic density estimation with a high precision. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Asmaa, Ouessai; Mokhtar, Keche; Abdelaziz, Ouamri] Univ Sci & Technol USTO MB, Dept Elect, Signals & Images Lab, El Mnaouar Bir El Djir O, Algeria.
C3 Universite des Sciences et de la Technologie d'Oran Mohamed Boudiaf
RP Asmaa, O (corresponding author), Univ Sci & Technol USTO MB, Dept Elect, Signals & Images Lab, BP 1505, El Mnaouar Bir El Djir O, Algeria.
EM ouessai.as@gmail.com
RI Ouessai, Asmaa/V-6925-2019
OI Ouessai, Asmaa/0000-0002-7231-2252
CR Bardet F., 2010, P 11 INT IEEE C INT, P185
   Chan A.B., 2005, IEEE INT VEH S LAS V
   Chang C.C., LIBSVM: a library for support vector machines
   Cheung SCS, 2004, PROC SPIE, V5308, P881, DOI 10.1117/12.526886
   Dailey D. J., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P98, DOI 10.1109/6979.880967
   Derpanis K. G., 2011, 2011 IEEE Workshop on Applications of Computer Vision (WACV), P606, DOI DOI 10.1109/WACV.2011.5711560
   Guoliang Mo, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P751, DOI 10.1109/ICNC.2010.5583178
   Huang L., 2010, IEEE INT VEH S U CAL
   Jin-Cyuan Lai, 2010, 2010 International Conference on Green Circuits and Systems (ICGCS 2010), P666, DOI 10.1109/ICGCS.2010.5542980
   Kim J.B., 2001, TENCON 2001 P IEEE R, V1, P313
   Kim J.W., 1995, SPIES VIS COMM IM PR
   Kim Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P524
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Madasu V.K., 2008, IEEE INTELLIGENT TRA, P539
   Martin RJ, 2000, IEEE T SIGNAL PROCES, V48, P1164, DOI 10.1109/78.827549
   MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814
   Porikli F., 2004, MITS EL RES LAB IEEE
   Remagnino P., 1997, PROC BRIT MACHINE VI, P380
   Scholkopf B., 2001, LEARNING KERNEL SUPP
   Shen XJ, 2009, 2009 INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND MECHATRONICS AUTOMATION, VOL III, P318, DOI 10.1109/ICMTMA.2009.242
   Song JunFang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P522, DOI 10.1109/CISP.2011.6099921
   Tuceiyan M., 1998, HDB PATTERN RECOGNIT
   Vachier C., 1995, THESIS ECOLE NATL SU
   Wassantachat T, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P13, DOI 10.1109/AVSS.2009.43
   Young-Kee Jung, 1999, Proceedings 199 IEEE/IEEJ/JSAI International Conference on Intelligent Transportation Systems (Cat. No.99TH8383), P764, DOI 10.1109/ITSC.1999.821157
   Zhidong Li, 2008, 2008 Digital Image Computing: Techniques and Applications, P117, DOI 10.1109/DICTA.2008.30
NR 26
TC 30
Z9 31
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2013
VL 31
IS 11
BP 887
EP 894
DI 10.1016/j.imavis.2013.09.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 268PX
UT WOS:000328184100006
DA 2024-07-18
ER

PT J
AU Delmerico, JA
   David, P
   Corso, JJ
AF Delmerico, Jeffrey A.
   David, Philip
   Corso, Jason J.
TI Building facade detection, segmentation, and parameter estimation for
   mobile robot stereo vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo vision; Mobile robot perception; Hierarchical Markov random
   field; Building facade detection; Model-based stereo vision
ID TEXTURES; SCENE
AB Building facade detection is an important problem in computer vision, with applications in mobile robotics and semantic scene understanding. In particular, mobile platform localization and guidance in urban environments can be enabled with accurate models of the various building facades in a scene. Toward that end, we present a system for detection, segmentation, and parameter estimation of building facades in stereo imagery. The proposed method incorporates multilevel appearance and disparity features in a binary discriminative model, and generates a set of candidate planes by sampling and clustering points from the image with Random Sample Consensus (RANSAC), using local normal estimates derived from Principal Component Analysis (PCA) to inform the planar models. These two models are incorporated into a two-layer Markov Random Field (MRF): an appearance- and disparity-based discriminative classifier at the mid-level, and a geometric model to segment the building pixels into facades at the high-level. By using object-specific stereo features, our discriminative classifier is able to achieve substantially higher accuracy than standard boosting or modeling with only appearance-based features. Furthermore, the results of our MRF classification indicate a strong improvement in accuracy for the binary building detection problem and the labeled planar surface models provide a good approximation to the ground truth planes. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Delmerico, Jeffrey A.; Corso, Jason J.] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
   [David, Philip] Army Res Lab, Adelphi, MD 20783 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo; United States Department of Defense; US Army Research,
   Development & Engineering Command (RDECOM); US Army Research Laboratory
   (ARL); United States Army
RP Delmerico, JA (corresponding author), Univ Hawaii Manoa, Dept Mech Engn, 2540 Dole St,Holmes Hall 310, Honolulu, HI 96822 USA.
EM jad12@buffalo.edu; philip.j.david4.civ@mail.mil; jcorso@buffalo.edu
OI Corso, Jason/0000-0001-6454-9594
FU NSF [IIS-0845282]; DARPA [W911NF-10-2-0062]; ARO [W911NF-11-1-0090];
   United States Army Research Laboratory; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [0845282] Funding
   Source: National Science Foundation
FX The authors are grateful for the financial support provided in part by
   NSF CAREER IIS-0845282, DARPA W911NF-10-2-0062, and ARO Young
   Investigator W911NF-11-1-0090. We are also thankful to the support of
   the United States Army Research Laboratory.
CR Bauer J., 2003, PROC 27 WORKSHOP AUS, P253
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Corso J, 2003, IEEE INT CONF ROBOT, P875
   David P., 2008, DETECTING PLANAR SUR
   Delmerico J. A., 2010, E P W NEW YORK IM PR
   Delmerico JA, 2011, IEEE INT C INT ROBOT, P1632, DOI 10.1109/IROS.2011.6048385
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Flint A, 2011, IEEE I CONF COMP VIS, P2228, DOI 10.1109/ICCV.2011.6126501
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Frhlich B., 2012, P AS C COMP VIS DAEJ, P218
   Frohlich Bjorn, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3029, DOI 10.1109/ICPR.2010.742
   Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804
   Georgiev A, 2004, IEEE T ROBOTIC AUTOM, V20, P851, DOI 10.1109/TRO.2004.829506
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Konolige K., 2008, P INT S EXP ROB
   Korah T, 2008, LECT NOTES COMPUT SC, V5302, P359, DOI 10.1007/978-3-540-88682-2_28
   Korc F., 2009, etrims image database for interpreting images of man-made scenes
   Kosecká J, 2005, COMPUT VIS IMAGE UND, V100, P274, DOI 10.1016/j.cviu.2005.04.005
   Lee SC, 2002, COMPUT GRAPH FORUM, V21, P511, DOI 10.1111/1467-8659.00701
   Li L., 2010, P CAN C COMP ROB VIS
   Luo W., 1990, P 10 INT C PATT REC
   Posner I, 2007, IEEE INT CONF ROBOT, P4962, DOI 10.1109/ROBOT.2007.364244
   Recky M., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P358, DOI 10.1109/3DIMPVT.2011.52
   Robertson D., 2004, P BRIT MACH VIS C KI, P260
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Tu Z., 2008, P IEEE C COMP VIS PA
   Walk S., 2010, P EUR C COMP VIS
   Wang R., 2011, APPL COMPUTER VISION, P58
   Wendel A, 2010, LECT NOTES COMPUT SC, V6376, P51
   Xiao JX, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618460
   Yang AY, 2005, PROC CVPR IEEE, P154
   Yang Michael Ying, 2011, TRIGGP20112 U BONN D, V2, P41
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80
NR 36
TC 10
Z9 11
U1 2
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2013
VL 31
IS 11
BP 841
EP 852
DI 10.1016/j.imavis.2013.08.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 268PX
UT WOS:000328184100002
DA 2024-07-18
ER

PT J
AU Heinrich, SB
AF Heinrich, Stuart B.
TI Efficient and robust model fitting with unknown noise scale
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Robust estimation; RANSAC; Scale estimation; Structure from motion
ID RANDOM SAMPLE CONSENSUS; SEGMENTATION; ESTIMATOR; RANSAC; PARAMETER
AB This paper addresses the general problem of robust parametric model estimation from data that has both an unknown (and possibly majority) fraction of outliers as well as an unknown scale of measurement noise. We focus on computer vision applications from image correspondences, such as camera resectioning, estimation of the fundamental matrix or relative pose for 3D reconstruction, and estimation of 2D homographies for image registration and motion segmentation, although there are many other applications. In practice, these methods typically rely on a predefined inlier thresholds because automatic scale detection is usually too unreliable or too slow. We propose a new method for robust estimation with automatic scale detection that is faster, more precise and more robust than previous alternatives, and show that it can be practically applied to these problems. (C) 2013 Elsevier B.V. All rights reserved.
C1 N Carolina State Univ, Raleigh, NC 27695 USA.
C3 North Carolina State University
RP Heinrich, SB (corresponding author), N Carolina State Univ, Box 8206, Raleigh, NC 27695 USA.
EM sbheinri@ncsu.edu
CR [Anonymous], STABLE DISTRIBUTIONS
   Appleby Austin, 2013, MURMURHASH3 SMHASHER
   Bab-Hadiashar A, 1999, ROBOTICA, V17, P649, DOI 10.1017/S0263574799001812
   BRANHAM RL, 1982, ASTRON J, V87, P928, DOI 10.1086/113176
   Capel D., 2005, Proc. BMVC, P629
   Chen H., 2003, COMP VIS P 9 IEEE IN, V2, P878
   Chin T.-J., 2009, COMP VIS 2009 IEEE 1
   Choi J, 2009, PROC CVPR IEEE, P675, DOI 10.1109/CVPRW.2009.5206678
   Chum O, 2005, PROC CVPR IEEE, P772
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   DYER DD, 1973, TECHNOMETRICS, V15, P489
   Fan LX, 2008, LECT NOTES COMPUT SC, V5304, P182
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frahm J-M, 2006, 2006 IEEE COMP SOC C, P453
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R.I., 2004, MULTIPLE VIEW GEOMET, V2nd, P238
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Huber Peter J, 2011, ROBUST STAT, P1248
   HUBER PJ, 1972, ANN MATH STAT, V43, P1041, DOI 10.1214/aoms/1177692459
   Kanatani K., 1996, STAT OPTIMIZATION GE
   Kanazawa Y, 2004, IMAGE VISION COMPUT, V22, P93, DOI 10.1016/j.imavis.2003.07.001
   Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940
   Matas J, 2004, IMAGE VISION COMPUT, V22, P837, DOI 10.1016/j.imavis.2004.02.009
   Nistér D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P199
   R.C.A. Victor Company, 1935, DALL AER SURV CO PHO
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Raguram R, 2011, IEEE I CONF COMP VIS, P1299, DOI 10.1109/ICCV.2011.6126382
   Rousseeuw P. J, 1987, Robust Regression and Outlier Detection
   ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718
   Rozenfeld S, 2005, PROC CVPR IEEE, P1113
   Silverman, 2018, DENSITY ESTIMATION S, DOI 10.1201/9781315140919
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Subbarao R., 2006, P 2006 C COMP VIS PA
   Subbarao R., 2005, CVPR WORKSH IEEE COM
   Toldo R, 2009, LECT NOTES COMPUT SC, V5716, P123, DOI 10.1007/978-3-642-04146-4_15
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Wang HZ, 2012, IEEE T PATTERN ANAL, V34, P1177, DOI 10.1109/TPAMI.2011.216
   Wang HZ, 2010, IEEE T PATTERN ANAL, V32, P178, DOI 10.1109/TPAMI.2009.148
   Wang HZ, 2004, IEEE T PATTERN ANAL, V26, P1459, DOI 10.1109/TPAMI.2004.109
   Wang HZ, 2004, INT J COMPUT VISION, V59, P139, DOI 10.1023/B:VISI.0000022287.61260.b0
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443
NR 48
TC 7
Z9 7
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 735
EP 747
DI 10.1016/j.imavis.2013.07.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900005
DA 2024-07-18
ER

PT J
AU Ghiasi, G
   Safabakhsh, R
AF Ghiasi, Golnaz
   Safabakhsh, Reza
TI Offline text-independent writer identification using codebook and
   efficient code extraction methods
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Handwritten documents; Writer identification; Farsi handwriting; English
   handwriting; Codebook
ID CONNECTED-COMPONENT CONTOURS; VERIFICATION; ORIENTATION; FEATURES
AB In this paper, an efficient method for text-independent writer identification using a codebook method is proposed. The method uses the occurrence histogram of the shapes in a codebook to create a feature vector for each specific manuscript. For cursive handwritings, a wide variety of different shapes exist in the connected components obtained from the handwriting. Small fragments of connected components are used to avoid complex patterns. Two efficient methods for extracting codes from contours are introduced. One method uses the actual pixel coordinates of contour fragments while the other one uses a linear piece-wise approximation using segment angles and lengths. To evaluate the methods, writer identification is conducted on two English and three Farsi handwriting databases. Both methods show promising performances with the performance of second method being better than the first one. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Ghiasi, Golnaz; Safabakhsh, Reza] Amirkabir Univ Technol, Comp Engn & Informat Technol Dept, Tehran, Iran.
C3 Amirkabir University of Technology
RP Safabakhsh, R (corresponding author), Amirkabir Univ Technol, Comp Engn & Informat Technol Dept, Tehran, Iran.
EM g.ghiasi@aut.ac.ir; safa@aut.ac.ir
RI Safabakhsh, Reza/K-9687-2018
OI Safabakhsh, Reza/0000-0002-4937-8026
CR Ballard L., 2006, The 10 th International Workshop on the Foundations of Handwriting Recognition, P461
   Bensefia A, 2005, PATTERN RECOGN LETT, V26, P2080, DOI 10.1016/j.patrec.2005.03.024
   Bensefia A., 2005, Electronic Letters on Computer Vision and Image Analysis, V5, P72, DOI DOI 10.5565/REV/ELCVIA.97
   Brink AA, 2012, PATTERN RECOGN, V45, P162, DOI 10.1016/j.patcog.2011.07.005
   Bulacu M, 2005, PROC INT CONF DOC, P1275, DOI 10.1109/ICDAR.2005.4
   Bulacu M, 2003, LECT NOTES COMPUT SC, V2756, P460
   Bulacu M, 2007, PROC INT CONF DOC, P769
   Bulacu M, 2007, IEEE T PATTERN ANAL, V29, P701, DOI 10.1109/TPAMI.2007.1009
   El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288
   Fornes Alicia, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P996, DOI 10.1109/ICDAR.2009.100
   Fornés A, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P347, DOI 10.1109/DAS.2008.29
   Ghiasi Golnaz, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1245, DOI 10.1109/ICPR.2010.310
   GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870
   Hao Feng, 2002, Information Management & Computer Security, V10, P159, DOI 10.1108/09685220210436949
   Helli B, 2010, PATTERN RECOGN, V43, P2199, DOI 10.1016/j.patcog.2009.11.026
   Helli B, 2008, IEEE INT SYMP SIGNAL, P203, DOI 10.1109/ISSPIT.2008.4775690
   Kirli O., 2011, 2011 International Symposium on Innovations in Intelligent Systems and Applications (INISTA 2011), P133, DOI 10.1109/INISTA.2011.5946056
   Marti U., 2001, P 6 INT C DOC AN REC, P765
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Nejad FS, 2007, PROC INT CONF DOC, P829
   Ram SS, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P728, DOI 10.1109/ICIME.2009.71
   Said HES, 2000, PATTERN RECOGN, V33, P149, DOI 10.1016/S0031-3203(99)00006-0
   Sas J, 2006, LECT NOTES COMPUT SC, V4029, P682, DOI 10.1007/11785231_71
   Schlapbach A, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P167, DOI 10.1109/IWFHR.2004.107
   Schlapbach A, 2007, PATTERN ANAL APPL, V10, P33, DOI 10.1007/s10044-006-0047-5
   Schlapbach A, 2006, INT C PATT RECOG, P992
   Schomaker L, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P185, DOI 10.1109/IWFHR.2004.22
   Schomaker L, 2004, IEEE T PATTERN ANAL, V26, P787, DOI 10.1109/TPAMI.2004.18
   Schomaker L., 2000, Technical report
   Schomaker L, 2007, PATTERN RECOGN LETT, V28, P719, DOI 10.1016/j.patrec.2006.08.005
   Siddiqi Imran, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P981, DOI 10.1109/ICDAR.2009.136
   Siddiqi I., 2008, 11 INT C FRONT HANDW, P19
   Siddiqi I, 2010, PATTERN RECOGN, V43, P3853, DOI 10.1016/j.patcog.2010.05.019
   Siddiqi I, 2009, LECT NOTES COMPUT SC, V5702, P245, DOI 10.1007/978-3-642-03767-2_30
   Tapiador M, 2004, LECT NOTES COMPUT SC, V3029, P625
   Ziaratban M., 2009, 10 INT C DOC AN REC, P4
NR 36
TC 61
Z9 65
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2013
VL 31
IS 5
BP 379
EP 391
DI 10.1016/j.imavis.2013.03.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 154YR
UT WOS:000319713100002
DA 2024-07-18
ER

PT J
AU Lee, S
AF Lee, Seungkyu
TI Symmetry-driven shape description for image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape description; Shape matching; Regular pattern
ID RECOGNITION; PERCEPTION; MODELS
AB We propose a novel symmetry-driven Bayesian framework to incorporate structural shape into conventional geometrical shape descriptor of an image indexing and retrieval. We use rotation and reflection symmetries for structural shape description. Symmetry detection on each shape image provides a qualitative and a quantitative categorization of the types and the degrees of symmetry level. The posterior shape similarity enhances the shape matching performance based on the symmetry structural discrimination. Experimental results show statistically significant improvement on retrieval accuracy over the state of the art methods on MPEG-7 data set. (C) 2013 Elsevier B.V. All rights reserved.
C1 Kyung Hee Univ, Seoul, South Korea.
C3 Kyung Hee University
RP Lee, S (corresponding author), Kyung Hee Univ, Seoul, South Korea.
EM seungkyu74@gmail.com
CR [Anonymous], 2008, BRIT MACHINE VISION
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI 10.1109/CVPR.2007.383018
   [Anonymous], 2008, Computer Vision and Pattern Recognition
   [Anonymous], 1997, Image Databases and Multi-Media Search, DOI DOI 10.1142/9789812797988_
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BOBER M, 1999, JTC1SC29WG11MPEG99M4
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   Keller Y, 2006, IEEE T IMAGE PROCESS, V15, P2198, DOI 10.1109/TIP.2006.875227
   Kontschieder Peter., 2009, ACCV
   Kurki I, 2004, NEUROSCI LETT, V360, P100, DOI 10.1016/j.neulet.2004.01.053
   Lakaemper M., 2008, P IEEE INT C COMPUTE, P1
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Lee S, 2012, IEEE T PATTERN ANAL, V34, P266, DOI 10.1109/TPAMI.2011.118
   Lei YW, 1999, PATTERN RECOGN, V32, P167, DOI 10.1016/S0031-3203(98)00135-6
   Lin LA, 2009, PROC CVPR IEEE, P1351, DOI 10.1109/CVPRW.2009.5206585
   Lin Y.-Y., 2011, IEEE TPAMI, V33
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling Haibin., 2010, ECCV
   Liu MZ, 2010, PROC CVPR IEEE, P3463, DOI 10.1109/CVPR.2010.5539979
   Liu Y., 2005, SIGGRAPH 2005 TECHNI
   Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332
   Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   Mcneill G., 2006, IEEE COMPUTER SOC C, V1, P885
   Park Madison., 2008, CNN.com, P1
   Prasad VSN, 2005, IEEE I CONF COMP VIS, P954
   Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951
   Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396
   Tari S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1123, DOI 10.1109/ICCV.1998.710857
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   UEDA N, 1993, IEEE T PATTERN ANAL, V15, P337, DOI 10.1109/34.206954
   Xingwei Yang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2369, DOI 10.1109/CVPR.2011.5995325
   Yang XW, 2008, LECT NOTES COMPUT SC, V5305, P788, DOI 10.1007/978-3-540-88693-8_58
   Zhao B., 2009, P SDM
NR 35
TC 10
Z9 11
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2013
VL 31
IS 4
BP 357
EP 363
DI 10.1016/j.imavis.2013.02.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 136QV
UT WOS:000318379400005
DA 2024-07-18
ER

PT J
AU Rougier, C
   Meunier, J
   St-Arnaud, A
   Rousseau, J
AF Rougier, Caroline
   Meunier, Jean
   St-Arnaud, Alain
   Rousseau, Jacqueline
TI 3D head tracking for fall detection using a single calibrated camera
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; 3D; Head tracking; Monocular; Particle Filter; Video
   surveillance; Fall detection
ID VELOCITY
AB The head trajectory is an interesting source of information for behavior recognition and can be very useful for video surveillance applications, especially for fall detection. Consequently, much work has been done to track the head in the 2D image plane using a single camera or in a 3D world using multiple cameras. Tracking the head in real-time with a single camera could be very useful for fall detection. Thus, in this article, an original method to extract the 3D head trajectory of a person in a room is proposed using only one calibrated camera. The head is represented as a 3D ellipsoid, which is tracked with a hierarchical particle filter based on color histograms and shape information. Experiments demonstrated that this method can run in quasi-real-time, providing reasonable 3D errors for a monocular system. Results on fall detection using the head 3D vertical velocity or height obtained from the 3D trajectory are also presented. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Rougier, Caroline; Meunier, Jean] Univ Montreal, Dept Comp Sci & Operat Res DIRO, Montreal, PQ H3C 3J7, Canada.
   [St-Arnaud, Alain] Hlth & Social Serv Ctr Lucille Teasdale, Montreal, PQ, Canada.
   [Rousseau, Jacqueline] Univ Montreal, Geriatr Inst, Res Ctr, Montreal, PQ H3C 3J7, Canada.
C3 Universite de Montreal; Universite de Montreal
RP Rougier, C (corresponding author), Univ Montreal, Dept Comp Sci & Operat Res DIRO, Montreal, PQ H3C 3J7, Canada.
EM rougierc@iro.umontreal.ca; meunier@iro.umontreal.ca;
   astarnaud@ssss.gouv.qc.ca; jacqueline.rousseau@umontreal.ca
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX The authors wish to thank Edouard Auvinet for aiding in the design and
   construction of the dataset. This work was supported by the Natural
   Sciences and Engineering Research Council of Canada (NSERC).
CR [Anonymous], 2012, WIR EM RESP SYST
   [Anonymous], 2006, CS0608 BROWN U
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Bouguet J., 2010, CAMERA CALIBRATION T
   Bradski G., 2008, LEARNING OPENCV
   Campbell N., 2009, 2 IEEE INT WORKSH TR
   Charif HN, 2006, MACH VISION APPL, V17, P83, DOI 10.1007/s00138-006-0015-5
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   Gadspot, 2012, IP CAM
   Greif T, 2011, IEEE INT CON MULTI
   Hild M, 2004, INT C PATT RECOG, P231, DOI 10.1109/ICPR.2004.1333746
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kangas M, 2008, GAIT POSTURE, V28, P285, DOI 10.1016/j.gaitpost.2008.01.003
   Kawanaka H, 2006, INT C PATT RECOG, P826
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Moreno F, 2002, INT C PATT RECOG, P368, DOI 10.1109/ICPR.2002.1044727
   Noury N, 2008, IRBM, V29, P340, DOI 10.1016/j.irbm.2008.08.002
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Nyan MN, 2008, J BIOMECH, V41, P3475, DOI 10.1016/j.jbiomech.2008.08.009
   Rougier Caroline, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6384
   Stenger B., 2001, British Machine Vision Conference, P63
   Suzuki N., 2006, P BRIT MACH VIS C BM, P37
   Tunstall, 2012, FALL DET
   Usabiaga J, 2007, COMPUT INTELL-US, V23, P484, DOI 10.1111/j.1467-8640.2007.00317.x
   Vondrak L., 2008, 2008 IEEE C COMPUTER, P1, DOI [DOI 10.1109/CVPR.2008.4587580, 10.1109/CVPR.2008.4587580]
   Wang Y.-K., EURASIP J A IN PRESS
   Wu CF, 2008, J NEUROGENET, V22, P1, DOI 10.1080/01677060801918016
   Wu G, 2000, J BIOMECH, V33, P1497, DOI 10.1016/S0021-9290(00)00117-2
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 31
TC 63
Z9 66
U1 1
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2013
VL 31
IS 3
BP 246
EP 254
DI 10.1016/j.imavis.2012.11.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 122NK
UT WOS:000317324600003
DA 2024-07-18
ER

PT J
AU Elder, JH
   Oleskiw, TD
   Yakubovich, A
   Peyré, G
AF Elder, James H.
   Oleskiw, Timothy D.
   Yakubovich, Alex
   Peyre, Gabriel
TI On growth and formlets: Sparse multi-scale coding of planar shape
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Planar shape; Deformation; Sparse coding; Contour completion
ID RECOGNITION
AB We propose a sparse representation of 2D planar shape through the composition of warping functions, termed formlets, localized in scale and space. Each formlet subjects the 2D space in which the shape is embedded to a localized isotropic radial deformation. By constraining these localized warping transformations to be diffeomorphisms, the topology of shape is preserved, and the set of simple closed curves is closed under any sequence of these warpings. A generative model based on a composition of formlets applied to an embryonic shape, e.g., an ellipse, has the advantage of synthesizing only those shapes that could correspond to the boundaries of physical objects. To compute the set of formlets that represent a given boundary, we demonstrate a greedy coarse-to-fine formlet pursuit algorithm that serves as a non-commutative generalization of matching pursuit for sparse approximations. We evaluate our method by pursuing partially occluded shapes, comparing performance against a contour-based sparse shape coding framework. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Elder, James H.; Yakubovich, Alex] York Univ, Ctr Vis Res, Toronto, ON M3J 2R7, Canada.
   [Oleskiw, Timothy D.] Univ Washington, Dept Appl Math, Seattle, WA 98195 USA.
   [Peyre, Gabriel] Univ Paris 09, CEREMADE, Paris, France.
C3 York University - Canada; University of Washington; University of
   Washington Seattle; Universite PSL; Universite Paris-Dauphine
RP Elder, JH (corresponding author), York Univ, Ctr Vis Res, Toronto, ON M3J 2R7, Canada.
EM jelder@yorku.ca; oleskiw@uw.edu; yakuboa@yorku.ca;
   gabriel.peyre@ceremade.dauphine.fr
RI ; Peyre, Gabriel/P-2438-2015
OI Oleskiw, Timothy/0000-0003-2631-4406; Peyre, Gabriel/0000-0002-4477-0387
FU NSERC; GEOIDE; OCE; Fondation Sciences Mathematiques de Paris
FX This work was supported by research grants to J.H. Elder from NSERC,
   GEOIDE and OCE, and by a travel grant to J.H. Elder from the Fondation
   Sciences Mathematiques de Paris.
CR [Anonymous], 1961, GROWTH FORM
   [Anonymous], GEOMETRIC METHODS CO
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6
   BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0
   BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302
   Cavanagh P., 1991, Representations of vision, P295
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dubinskiy A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P249
   Grenander U, 2007, IEEE T MED IMAGING, V26, P648, DOI 10.1109/TMI.2006.891500
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   LEYTON M, 1988, ARTIF INTELL, V34, P213, DOI 10.1016/0004-3702(88)90039-2
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   Oleskiw T., 2010, P IEEE C COMP VIS PA
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pavlidis T., 1977, Structural pattern recognition, V1
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660
   SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502
   Sharon E, 2004, PROC CVPR IEEE, P350
   Trinh N. H., 2007, ICCV 2007, P1, DOI [10.1109/ICCV.2007.4409022, DOI 10.1109/ICCV.2007.4409022]
   Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170, DOI 10.1109/34.809110
NR 25
TC 10
Z9 12
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2013
VL 31
IS 1
BP 1
EP 13
DI 10.1016/j.imavis.2012.11.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 084RP
UT WOS:000314557100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yanulevskaya, V
   Uijlings, J
   Geusebroek, JM
AF Yanulevskaya, Victoria
   Uijlings, Jasper
   Geusebroek, Jan-Mark
TI Salient object detection: From pixels to segments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; Object-based visual attention theory;
   Proto-objects
ID VISUAL-ATTENTION; SEARCH
AB In this paper we propose a novel approach to the task of salient object detection. In contrast to previous salient object detectors that are based on a spotlight attention theory, we follow an object-based attention theory and incorporate the notion of an object directly into our saliency measurements. Particularly, we consider proto-objects as units of the analysis, where a proto-object is a connected image region that can be converted into a plausible object or object-part, once a focus of attention reaches it. As the object-based attention theory suggests, we start with segmenting a complex image into proto-objects and then assess saliency for each proto-object. The most salient proto-object is considered as being a salient object.
   We distinguish two types of object saliency. Firstly, an object is salient if it differs from its surrounding, which we call center-surround saliency. Secondly, an object is salient if it contains rare or outstanding details, which we measure by integrated saliency. We demonstrate that these two types of object saliency have complementary characteristics; moreover, the combination of the two performs at the level of state-of-the-art in salient object detection. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Yanulevskaya, Victoria; Uijlings, Jasper] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
   [Geusebroek, Jan-Mark] Univ Amsterdam, Inst Informat, Amsterdam, Netherlands.
C3 University of Trento; University of Amsterdam
RP Yanulevskaya, V (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
EM yanulevskaya@disi.unitn.it; jrr.uijlings@disi.unitn.it;
   J.M.Geusebroek@uva.nl
CR Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], VIS REC CHALL WORKSH
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], INT C COMP GRAPH INT
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   ERIKSEN CW, 1986, PERCEPT PSYCHOPHYS, V40, P225, DOI 10.3758/BF03211502
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Lampert C. H., 2008, IEEE C COMPUTER VISI, P1
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Rensink RA, 2000, VISION RES, V40, P1469, DOI 10.1016/S0042-6989(00)00003-1
   Scholl BJ, 2001, COGNITION, V80, P1, DOI 10.1016/S0010-0277(00)00152-9
   Spain M, 2011, INT J COMPUT VISION, V91, P59, DOI 10.1007/s11263-010-0376-0
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Uijlings J. R., 2009, P ACM INT C IMAGE VI, P1
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
NR 24
TC 10
Z9 13
U1 1
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2013
VL 31
IS 1
BP 31
EP 42
DI 10.1016/j.imavis.2012.09.009
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 084RP
UT WOS:000314557100003
DA 2024-07-18
ER

PT J
AU López-Méndez, A
   Casas, JR
AF Lopez-Mendez, Adolfo
   Casas, Josep R.
TI Model-based recognition of human actions by trajectory matching in phase
   spaces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Multi-view; Markerless motion capture; Nonlinear
   dynamical systems; Time-delay embeddings
ID EMBEDDING DIMENSION
AB This paper presents a human action recognition framework based on the theory of nonlinear dynamical systems. The ultimate aim of our method is to recognize actions from multi-view video. We estimate and represent human motion by means of a virtual skeleton model providing the basis for a view-invariant representation of human actions. Actions are modeled as a set of weighted dynamical systems associated to different model variables. We use time-delay embeddings on the time series resulting of the evolution of model variables along time to reconstruct phase portraits of appropriate dimensions. These phase portraits characterize the underlying dynamical systems. We propose a distance to compare trajectories within the reconstructed phase portraits. These distances are used to train SVM models for action recognition. Additionally, we propose an efficient method to learn a set of weights reflecting the discriminative power of a given model variable in a given action class. Our approach presents a good behavior on noisy data, even in cases where action sequences last just for a few frames. Experiments with marker-based and markerless motion capture data show the effectiveness of the proposed method. To the best of our knowledge, this contribution is the first to apply time-delay embeddings on data obtained from multi-view video. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Lopez-Mendez, Adolfo; Casas, Josep R.] Tech Univ Catalonia UPC, Image & Video Proc Grp, Barcelona 08034, Spain.
C3 Universitat Politecnica de Catalunya
RP López-Méndez, A (corresponding author), Tech Univ Catalonia UPC, Image & Video Proc Grp, C Jordi Girona 1-3,Campus Nord,Bldg D5, Barcelona 08034, Spain.
EM adolf.lopez@upc.edu; josep.ramon.casas@upc.edu
RI Casas, Josep R./A-2851-2010
OI Casas, Josep R./0000-0003-4639-6904
FU Spanish Ministerio de Ciencia e Innovacion [TEC2010-18094]
FX This work has been partially supported by the Spanish Ministerio de
   Ciencia e Innovacion, under project TEC2010-18094.
CR [Anonymous], ICCV HCI
   [Anonymous], CVPR
   [Anonymous], 2007, ICCV
   [Anonymous], INT J COMPUT VIS
   [Anonymous], P INT WORKSH MACH LE
   [Anonymous], TIME WARPING DYNAMIC
   [Anonymous], ICIP
   [Anonymous], 2011, CVPR
   [Anonymous], 2010, 2010 IEEE GLOBAL TEL
   [Anonymous], 2007, IEEE INT C COMP VIS
   [Anonymous], LECT NOTES COMPUTER
   Basharat A, 2009, IEEE I CONF COMP VIS, P1941, DOI 10.1109/ICCV.2009.5459429
   Berndt D.J., 1996, Advances in Knowledge Discovery and Data Mining, P229
   Blackburn J, 2007, LECT NOTES COMPUT SC, V4814, P285
   CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880
   Cao LY, 1997, PHYSICA D, V110, P43, DOI 10.1016/S0167-2789(97)00118-8
   FRASER AM, 1986, PHYS REV A, V33, P1134, DOI 10.1103/PhysRevA.33.1134
   Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141
   Gkalelis N, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P159, DOI 10.1109/CVMP.2009.19
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Kantz H., 2004, NONLINEAR TIME SERIE, Vsecond, DOI DOI 10.1017/CBO9780511755798
   KENNEL MB, 1992, PHYS REV A, V45, P3403, DOI 10.1103/PhysRevA.45.3403
   Lewandowski M., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P161, DOI 10.1109/ICPR.2010.48
   Lv FJ, 2005, LECT NOTES COMPUT SC, V3766, P120, DOI 10.1007/11573425_12
   Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4
   Pavlovic V, 2000, PROC CVPR IEEE, P788, DOI 10.1109/CVPR.2000.855901
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raptis M, 2010, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2010.5539885
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Urtasun R, 2008, PROC CVPR IEEE, P149
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang L, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN SECURITY AND DEFENSE APPLICATIONS, P1
NR 34
TC 16
Z9 16
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2012
VL 30
IS 11
BP 808
EP 816
DI 10.1016/j.imavis.2012.06.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 052CW
UT WOS:000312176300002
DA 2024-07-18
ER

PT J
AU Tao, WB
   Tai, XC
AF Tao, Wenbing
   Tai, Xue-Cheng
TI Multiple piecewise constant with geodesic active contours (MPC-GAC)
   framework for interactive image segmentation using graph cut
   optimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiple piecewise constant; Active contour without edges; Geodesic
   active contour; Graph cuts; Image segmentation; Level set
ID ENERGY MINIMIZATION; MUMFORD; RESTORATION; SHAPES; SNAKES; MODEL
AB This paper proposes an improved variational model, multiple piecewise constant with geodesic active contour (MPC-GAC) model, which generalizes the region-based active contour model by Chan and Vese, 2001 [11] and merges the edge-based active contour by Caselles et al., 1997 [7] to inherit the advantages of region-based and edge-based image segmentation models. We show that the new MPC-GAC energy functional can be iteratively minimized by graph cut algorithms with high computational efficiency compared with the level set framework. This iterative algorithm alternates between the piecewise constant functional learning and the foreground and background updating so that the energy value gradually decreases to the minimum of the energy functional. The k-means method is used to compute the piecewise constant values of the foreground and background of image. We use a graph cut method to detect and update the foreground and background. Numerical experiments show that the proposed interactive segmentation method based on the MPC-GAC model by graph cut optimization can effectively segment images with inhomogeneous objects and background. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Tao, Wenbing] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Tai, Xue-Cheng] Nanyang Technol Univ, Sch Phys & Math Sci, Div Math Sci, Singapore 637616, Singapore.
   [Tai, Xue-Cheng] Univ Bergen, Dept Math, N-5007 Bergen, Norway.
   [Tao, Wenbing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.
C3 Huazhong University of Science & Technology; Nanyang Technological
   University; University of Bergen; Nanjing University
RP Tao, WB (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM wenbingtao@hust.edu.cn
RI Tai, Xue-Cheng/JDV-5122-2023; cai, bo/G-1491-2010; tai,
   xuecheng/L-9821-2013
OI Tai, Xue-Cheng/0000-0003-3359-9104; tai, xuecheng/0000-0003-3359-9104
FU National Natural Science Foundation of China [61073093]; Fundamental
   Research Funds for the Central Universities of China [HUST: 2010MS025];
   MOE (Ministry of Education, Singapore) [T207N2202,
   NRF2007IDM-IDM002-010]; SUG [20/07]
FX The research has been supported by the National Natural Science
   Foundation of China (Grant 61073093), the Fundamental Research Funds for
   the Central Universities of China (HUST: 2010MS025), MOE (Ministry of
   Education, Singapore) Tier II project T207N2202 and IDM project
   NRF2007IDM-IDM002-010. In addition, support from SUG 20/07 is also
   gratefully acknowledged.
CR [Anonymous], P VIIP
   [Anonymous], IEEE T PATTERN ANAL
   Bae E., 2008, APPL MATH
   Blake A., 1998, ACTIVE CONTOURS
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y., 2003, COMPUTING GEODESICS
   Boykov Y, 2006, LECT NOTES COMPUT SC, V3953, P409, DOI 10.1007/11744078_32
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chambolle A, 2005, LECT NOTES COMPUT SC, V3757, P136, DOI 10.1007/11585978_10
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985
   Darbon J, 2006, J MATH IMAGING VIS, V26, P261, DOI 10.1007/s10851-006-8803-0
   Darolti C, 2008, IEEE T IMAGE PROCESS, V17, P2275, DOI 10.1109/TIP.2008.2006443
   Dinits E. A., 1970, SOVIET MATH DOKLAD, V11, P1277
   Fedkiw R., 2003, LEVEL SET METHODS DY
   Fulkerson D., 1962, FLOW IN NETWORKS
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Goldberg A.V., 1986, P 18 ANN ASS COMP MA, P136, DOI DOI 10.1145/12130.12144
   Grady L., 2010, Discrete calculus: Applied analysis on graphs for computational science
   Grady L, 2009, IEEE T IMAGE PROCESS, V18, P2547, DOI 10.1109/TIP.2009.2028258
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KIMMEL R, 1995, IEEE T PATTERN ANAL, V17, P635, DOI 10.1109/34.387512
   Kobashi S, 2006, IEEE T SYST MAN CY B, V36, P74, DOI 10.1109/TSMCB.2005.852981
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   Lie J, 2006, MATH COMPUT, V75, P1155, DOI 10.1090/S0025-5718-06-01835-7
   Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1998, LEVEL SET METHODS DY
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   PARAGIOS N., 2000, ECCV, P224
   Paragios N., 2005, HDB MATH MODELS COMP
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003
   Tao W., 2009, APPL MATH
   Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Tsai R., 2003, Commun. Math. Sci., V1, P623, DOI DOI 10.4310/CMS.2003.V1.N4.AL
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Xiang SM, 2010, IEEE T PATTERN ANAL, V32, P2039, DOI 10.1109/TPAMI.2010.35
   Xiang SM, 2009, IEEE T IMAGE PROCESS, V18, P1623, DOI 10.1109/TIP.2009.2018570
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Zeng X., 2006, EFFICIENTLY SOLVING
   Zhang T., 2004, P INT C COMP VIS, P1950
NR 52
TC 26
Z9 32
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2011
VL 29
IS 8
BP 499
EP 508
DI 10.1016/j.imavis.2011.03.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 822RB
UT WOS:000295066200001
DA 2024-07-18
ER

PT J
AU Hu, Y
   Lam, KM
   Shen, TZ
   Wang, WJ
AF Hu, Yu
   Lam, Kin Man
   Shen, Tingzhi
   Wang, Weijiang
TI A novel kernel-based framework for facial-image hallucination
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face hallucination; Eigentransformation; Image super-resolution; Kernel
   method
ID SUPERRESOLUTION; REMOVAL; FACE
AB In this paper, we present a kernel-based eigentransformation framework to hallucinate the high-resolution (HR) facial image of a low-resolution (LR) input. The eigentransformation method is a linear subspace approach, which represents an image as a linear combination of training samples. Consequently, those novel facial appearances not included in the training samples cannot be super-resolved properly. To solve this problem, we devise a kernel-based extension of the eigentransformation method, which takes higher-order statistics of the image data into account. To generate HR face images with higher fidelity, the HR face image reconstructed using this kernel-based eigentransformation method is treated as an initial estimation of the target HR face. The corresponding high-frequency components of this estimation are extracted to form a prior in the maximum a posteriori (MAP) formulation of the SR problem so as to derive the final reconstruction result. We have evaluated our proposed method using different kernels and configurations, and have compared these performances with some current SR algorithms. Experimental results show that our kernel-based framework, along with a proper kernel, can produce good HR facial images in terms of both visual quality and reconstruction errors. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Hu, Yu; Lam, Kin Man] Hong Kong Polytech Univ, Elect & Informat Engn Dept, Ctr Signal Proc, Hong Kong, Hong Kong, Peoples R China.
   [Hu, Yu; Shen, Tingzhi; Wang, Weijiang] Beijing Inst Technol, Sch Informat Sci & Technol, Dept Elect Engn, Beijing 100081, Peoples R China.
C3 Hong Kong Polytechnic University; Beijing Institute of Technology
RP Lam, KM (corresponding author), Hong Kong Polytech Univ, Elect & Informat Engn Dept, Ctr Signal Proc, Hong Kong, Hong Kong, Peoples R China.
EM enkmlam@polyu.edu.hk
RI Kan, Kin-Man/A-9352-2014
OI Kan, Kin-Man/0000-0002-0422-8454
FU Centre for Signal Processing; Hong Kong Polytechnic University, Hong
   Kong, China [1-BB88]; Chinese NSFC [60772066]
FX The work described in this paper was supported by an internal grant from
   the Centre for Signal Processing. The Hong Kong Polytechnic University,
   Hong Kong, China (Project No. 1-BB88), and the Chinese NSFC (Project No.
   60772066).
CR [Anonymous], 2004, P IEEE C COMP VIS PA
   [Anonymous], GEORGIA TECH FACE DA
   Baker S, 2000, PROC CVPR IEEE, P372, DOI 10.1109/CVPR.2000.854852
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Du C, 2005, PATTERN RECOGN LETT, V26, P2215, DOI 10.1016/j.patrec.2005.03.031
   Fan W., 2007, Proc. of the CVPR, P1, DOI DOI 10.1109/CVPR.2007.383001
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Li XG, 2009, J VIS COMMUN IMAGE R, V20, P312, DOI 10.1016/j.jvcir.2009.03.008
   Martinez A., 1998, AR FACE DATABASE
   Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016
   Park JS, 2005, IEEE T PATTERN ANAL, V27, P805, DOI 10.1109/TPAMI.2005.103
   PARK SW, 2007, IEEE INT C AC SPEECH
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Qiu GP, 2000, J VIS COMMUN IMAGE R, V11, P360, DOI [10.1006/jvci.2000.0451, 10.1006/jvci.1999.0451]
   Qiu GP, 1999, IEEE T IMAGE PROCESS, V8, P109, DOI 10.1109/83.736699
   Scholkopf B., 2001, LEARNING KERNELS SUP
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Üstün B, 2006, CHEMOMETR INTELL LAB, V81, P29, DOI 10.1016/j.chemolab.2005.09.003
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Zhuang YT, 2007, PATTERN RECOGN, V40, P3178, DOI 10.1016/j.patcog.2007.03.011
NR 22
TC 9
Z9 9
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2011
VL 29
IS 4
BP 219
EP 229
DI 10.1016/j.imavis.2010.10.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 727UR
UT WOS:000287828800002
DA 2024-07-18
ER

PT J
AU John, V
   Trucco, E
   Ivekovic, S
AF John, Vijay
   Trucco, Emanuele
   Ivekovic, Spela
TI Markerless human articulated tracking using hierarchical particle swarm
   optimisation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Articulated human motion tracking; Particle swarm optimisation; Particle
   filtering
ID BODY MODEL ACQUISITION; HUMAN MOTION; CAPTURE
AB In this paper, we address markerless full-body articulated human motion tracking from multi-view video sequences acquired in a studio environment. The tracking is formulated as a multi-dimensional non-linear optimisation and solved using particle swarm optimisation (PSO). a swarm-intelligence algorithm which has gained popularity in recent years due to its ability to solve difficult non-linear optimisation problems. We show that a small number of particles achieves accuracy levels comparable with several recent algorithms. PSO initialises automatically, does not need a sequence-specific motion model and recovers from temporary tracking divergence through the use of a powerful hierarchical search algorithm (HPSO). We compare experimentally HPSO with particle filter (PF), annealed particle filter (APF) and partitioned sampling annealed particle filter (PSAPF) using the computational framework provided by Balan et al. HPSO accuracy and consistency are better than PF and compare favourably with those of APF and PSAPF, outperforming it in sequences with sudden and fast motion. We also report an extensive experimental study of HPSO over ranges of values of its parameters. (C) 2010 Elsevier B.V. All rights reserved.
C1 [John, Vijay; Trucco, Emanuele; Ivekovic, Spela] Univ Dundee, Sch Comp, Dundee, Scotland.
C3 University of Dundee
RP John, V (corresponding author), Univ Dundee, Sch Comp, Dundee, Scotland.
EM vijayjohn@computing.dundee.ac.uk; manueltrucco@computing.dundee.ac.uk;
   spelaivekovic@computing.dundee.ac.uk
OI John, Vijay/0000-0002-9553-0906; Trucco, Emanuele/0000-0002-5055-0794
FU EPSRC [EP/080053/1]; EPSRC [EP/D080053/2] Funding Source: UKRI
FX This work is supported by EPSRC Grant EP/080053/1 Vision-Based Animation
   of People in collaboration with Prof. Adrian Hilton's group at the
   University of Surrey (UK). We refer the readers to [45] for further
   information on the Surrey test sequences. We thank Prof. Adrian Hilton
   and his group for providing us with the test sequences and for many
   useful discussions, and Alexandru Balan from Brown University for kindly
   sharing the evaluation software.
CR [Anonymous], 2000, NIPS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P CVPR 06 NEW YORK J
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Balan A., 2007, P IEEE C COMP VIS PA
   Balan A. O., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P349
   Bandouch J., 2008, P BRIT MACH VIS C BM
   BISSACCO A, 2007, P C COMP VIS PATT RE
   Bregler C, 2004, INT J COMPUT VISION, V56, P179, DOI 10.1023/B:VISI.0000011203.00237.9b
   Caillette F, 2008, COMPUT VIS IMAGE UND, V109, P112, DOI 10.1016/j.cviu.2007.05.005
   CHOO K, 2001, P IEEE INT C COMP VI, P790
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DEAGUIAR E, 2007, P IEEE C COMP VIS PA
   Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c
   FORSYTH D, 2005, FDN TRENDS COMPUTER
   GALL J, INT J COMPUTER VISIO
   HUSZ Z, 2007, CVPR 2 WORKSH EV ART
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   IVEKOVIC S, 2008, EVOLUTIONARY COMPUTA, V16
   Ivekovic S, 2006, IEEE C EVOL COMPUTAT, P1241
   Kakadiaris IA, 1998, INT J COMPUT VISION, V30, P191, DOI 10.1023/A:1008071332753
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   KOBAYASHI T, 2007, P INT C CONTR AUT SY
   LI R, 2006, P EUR C COMP VIS ECC, V2, P137
   MACCORMICK J, 2000, P EUR C COMP VIS, V2, P3
   Mikic I, 2003, INT J COMPUT VISION, V53, P199, DOI 10.1023/A:1023012723347
   MNDERMANN L, 2007, P IEEE C COMP VIS PA
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Ning H., 2008, P IEEE C COMP VIS PA
   PERLIN HA, 2008, IEA AIE 08, P11
   PEURSUM P, 2007, P C COMP VIS PATT RE
   Poli Riccardo, 2008, Journal of Artificial Evolution & Applications, DOI 10.1155/2008/761459
   POLI R, 2009, IEEE T EVOLUTIONARY, V13
   Poli R., 2007, CSM649 U ESS DEP COM
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Robertson C, 2005, ELECTRON LETT, V41, P1370, DOI 10.1049/el:20053672
   ROBERTSON C, 2006, P BRIT MACH VIS C BM
   ROSENHAHN B, 2007, P C COMP VIS PATT RE
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   SIGAL L, 2007, P NEUR INF PROC SYST
   Sminchisescu C, 2005, PROC CVPR IEEE, P390
   Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Urtasun R, 2005, IEEE I CONF COMP VIS, P403
   WANG P, 2006, P IEEE C COMP VIS PA, V2
   Zhang XQ, 2008, PROC CVPR IEEE, P1317, DOI 10.1109/CVPR.2008.4587512
NR 46
TC 68
Z9 81
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2010
VL 28
IS 11
BP 1530
EP 1547
DI 10.1016/j.imavis.2010.03.008
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 639KD
UT WOS:000280972800004
DA 2024-07-18
ER

PT J
AU Sorci, M
   Antonini, G
   Cruz, J
   Robin, T
   Bierlaire, M
   Thiran, JP
AF Sorci, M.
   Antonini, G.
   Cruz, J.
   Robin, T.
   Bierlaire, M.
   Thiran, J. -Ph.
TI Modelling human perception of static facial expressions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expressions; Behavioural modelling; Discrete choice models
ID RECOGNITION; FACES
AB A recent internet based survey of over 35,000 samples has shown that when different human observers are asked to assign labels to static human facial expressions, different individuals categorize differently the same image. This fact results in a lack of an unique ground-truth, an assumption held by the large majority of existing models for classification. This is especially true for highly ambiguous expressions, especially in the lack of a dynamic context. In this paper we propose to address this shortcoming by the use of discrete choice models (DCM) to describe the choice a human observer is faced to when assigning labels to static facial expressions. Different models of increasing complexity are specified to capture the causal effect between features of an image and its associated expression, using several combinations of different measurements. The sets of measurements we used are largely inspired by FACS but also introduce some new ideas, specific to a static framework. These models are calibrated using maximum likelihood techniques and they are compared with each other using a likelihood ratio test, in order to test for significance in the improvement resulting from adding supplemental features. Through a cross-validation procedure we assess the validity of our approach against overfitting and we provide a comparison with an alternative model based on Neural Networks for benchmark purposes. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Sorci, M.; Thiran, J. -Ph.] Ecole Polytech Fed Lausanne, Signal Proc Lab LTS5, Stn 11, CH-1015 Lausanne, Switzerland.
   [Cruz, J.; Robin, T.; Bierlaire, M.] Ecole Polytech Fed Lausanne, Transport & Mobil Lab, Stn 11, CH-1015 Lausanne, Switzerland.
   [Antonini, G.] IBM Zurich Lab, Ruschlikon, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Swiss Federal Institutes of Technology Domain;
   Ecole Polytechnique Federale de Lausanne; International Business
   Machines (IBM)
RP Sorci, M (corresponding author), Ecole Polytech Fed Lausanne, Signal Proc Lab LTS5, Stn 11, CH-1015 Lausanne, Switzerland.
EM matteo.sorci@epfl.ch; gan@zurich.ibm.com; javier.cruz@epfl.ch;
   thomas.robin@epfl.ch; michel.bierlaire@epfl.ch; JP.Thiran@epfl.ch
OI Thiran, Jean-Philippe/0000-0003-2938-9657; Bierlaire,
   Michel/0000-0002-5275-7692
CR Abboud B, 2004, INT C PATT RECOG, P163, DOI 10.1109/ICPR.2004.1333729
   [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], HDB FACE RECOGNITION
   [Anonymous], 1983, EMFACS 7 EMOTIONAL F
   [Anonymous], 2004, Statistical Models of Appearance for Computer Vision
   [Anonymous], 2001, INT WORKSH STAT COMP
   [Anonymous], 1978, DETERMINANTS TRAVEL
   Antonini G, 2006, LECT NOTES COMPUT SC, V4179, P710
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   BASSILI JN, 1978, J EXP PSYCHOL HUMAN, V4, P373, DOI 10.1037/0096-1523.4.3.373
   Ben-Akiva M.E., 1985, Discrete Choice Analysis: Theory and Application to Travel Demand
   Bicego M, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P235, DOI 10.1109/ICIAP.2007.4362785
   Bierlaire M, 2003, P 3 SWISS TRANSPORTA
   Bierlaire M, 2006, ANN OPER RES, V144, P287, DOI 10.1007/s10479-006-0015-x
   Cabeza R, 2000, PSYCHOL SCI, V11, P429, DOI 10.1111/1467-9280.00283
   CAREY S, 1992, PHILOS T ROY SOC B, V335, P95, DOI 10.1098/rstb.1992.0012
   Chang Y, 2004, PROC CVPR IEEE, P520
   CHANGBO H, 2004, COMP VIS PATT REC WO, P81
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   COHN JF, 2006, INT C MULT INT, P233
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   DIAMOND R, 1986, J EXP PSYCHOL GEN, V115, P107, DOI 10.1037/0096-3445.115.2.107
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P, 1978, FACIAL ACTION CODING
   Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232
   Farah MJ, 1998, PSYCHOL REV, V105, P482, DOI 10.1037/0033-295X.105.3.482
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Friesen W., 1984, Emotional facial action coding system
   GABOR DJ, 2002, HDB BRAIN THEORY NEU, P457
   Heckerman David., 1995, TUTORIAL LEARNING BA
   HU C, 2004, CVPRW 04, V5, P81
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Keltner D., 2000, Handbook of emotions, Vsecond, P236
   KOELSTRA S, 2008, IEEE FACE GESTURE RE
   Kullback S., 1959, STAT INFORM THEORY
   LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Malerba D, 2002, MANAG INFORMAT SYST, V6, P31
   MANSKI CF, 1977, THEOR DECIS, V8, P229, DOI 10.1007/BF00133443
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   McFadden D., 1981, Structural analysis of discrete data with econometric applications, P198, DOI DOI 10.1086/296093
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   Meulders M, 2005, J ROY STAT SOC C-APP, V54, P781, DOI 10.1111/j.1467-9876.2005.00515.x
   Mitchell T. M., 1997, MACHINE LEARNING
   Moses Y, 1996, PERCEPTION, V25, P443, DOI 10.1068/p250443
   Padgett C, 1998, PROCEEDINGS OF THE TWENTIETH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P806
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pantic M, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P1026
   Pantic M., 2007, FACE RECOGNITION, P377
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Schneiderman H., 2000, IEEE C COMP VIS PATT
   Schwaninger A, 2002, LECT NOTES COMPUT SC, V2525, P643, DOI 10.1007/3-540-36181-2_64
   SCHWANINGER A, 2003, THESIS UNIVERSITTZRI
   Sorci M., 2007, Facial Expressions Evaluation Survey
   Stegmann M.B., 2000, ACTIVE APPEARANCE MO
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tian Y., 2000, PROC 4 IEEE INT C AU, P484
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tian YL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P229, DOI 10.1109/AFGR.2002.1004159
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Valstar MF, 2007, LECT NOTES COMPUT SC, V4796, P118
   Wallraven C, 2005, NETWORK-COMP NEURAL, V16, P401, DOI 10.1080/09548980500508844
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   YE J, 2004, IEEE INT C SYST MAN, P10
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
NR 72
TC 12
Z9 15
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 790
EP 806
DI 10.1016/j.imavis.2009.10.003
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fan, SF
   Ferrie, FP
AF Fan, Shufei
   Ferrie, Frank P.
TI Photo Hull regularized stereo
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo; Photo Hull; Regularization
AB A regularization-based approach to 3D reconstruction from multiple images is proposed. As one of the most widely used multiple-view 3D reconstruction algorithms, Space Carving can produce a Photo Hull of a scene, which is at best a coarse volumetric model. The two-view stereo algorithm, on the other hand, can generate a more accurate reconstruction of the surfaces, provided that a given surface is visible to both views. The proposed method is essentially a data fusion approach to 3D reconstruction, combining the above two algorithms by means Of regularization. The process is divided into two steps: (I) computing the Photo Hull from multiple calibrated images and (2) selecting two of the images as input and solving the two-view stereo problem by global optimization, using the Photo Hull as the regularizer. Our dynamic programming implementation of this regularization-based stereo approach potentially provides an efficient and robust way of reconstructing 3D surfaces. The results of an implementation of this theory is presented on real data sets and compared with peer algorithms. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Fan, Shufei; Ferrie, Frank P.] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.
C3 McGill University
RP Fan, SF (corresponding author), McGill Univ, Ctr Intelligent Machines, 3480 Univ, Montreal, PQ H3A 2A7, Canada.
EM fansf@cim.mcgill.ca; ferrie@cim.mcgill.ca
FU Natural Sciences and Engineering Research Council of Canada [RGPIN
   36560-06, STPGP-270194-03]; GEOIDE Network of Centers of Excellence
   [TDMDFM-35]
FX The authors would like to acknowledge the support of the Natural
   Sciences and Engineering Research Council of Canada under Grants RGPIN
   36560-06 and STPGP-270194-03, and the GEOIDE Network of Centers of
   Excellence under Grant TDMDFM-35. We also wish to thank the anonymous
   reviewers for their helpful comments in improving this paper.
CR ANWAR Z, 2005, THESIS MCGILL U
   Barnard S.T., 1987, READINGS COMPUTER VI, P21
   Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040
   CULBERTSON W, 1999, P INT WORKSH VIS ALG, P100
   Drouin MA, 2005, PROC CVPR IEEE, P351
   Gong ML, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P610
   Gong ML, 2005, IEEE T PATTERN ANAL, V27, P998, DOI 10.1109/TPAMI.2005.120
   KOLMOGOROV V, 2002, P EUR C COMP VIS
   KUTULAKOS KN, 1999, IEEE INT C COMP VIS, P307
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D., 2010, MIDDLEBURY STEREO VI
   Seitz S.M., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI https://doi.org/10.1109/CVPR.2006.19
   Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462
   SLABAUGH GG, 2001, GRAPHICS
   Strobl K., CAMERA CALIBRATION T
NR 18
TC 1
Z9 1
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 724
EP 730
DI 10.1016/j.imavis.2008.10.008
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600017
DA 2024-07-18
ER

PT J
AU Rocha, R
   Campilho, A
   Silva, J
   Azevedo, E
   Santos, R
AF Rocha, Rui
   Campilho, Aurelio
   Silva, Jorge
   Azevedo, Elsa
   Santos, Rosa
TI Segmentation of the carotid intima-media region in B-mode ultrasound
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ultrasound image; Carotid; Image segmentation; Dynamic programming;
   Geometric snakes; Thresholding
ID ARTERY INTIMA; CLINICAL MEASUREMENT; EDGE-DETECTION; THICKNESS; SYSTEM;
   SNAKES; RISK; WALL
AB This paper proposes a new approach for the segmentation of both near-end and far-end intima-media regions of the common carotid artery in ultrasound images. The method requires minimal user interaction and is able to segment the near-end wall in arteries with large, hypoechogenic and irregular plaques, issues usually not considered previously due to the increased segmentation difficulty.
   The adventitia is detected by searching for the best fit of a cubic spline to edges having features compatible with the adventitia boundary. The algorithm uses a global smoothness constraint and integrates discriminating features of the adventitia to reduce the attraction by other edges. Afterwards, using the information of the adventitia location, the lumen boundary is detected by combining dynamic programming, smooth intensity thresholding surfaces and geometric snakes. Smooth contours that correctly adapt to the intima are produced, even in the presence of deep concavities. Moreover, unlike balloon-based snakes, the propagation force does not depend on gradients and does not require a predefined direction.
   An extensive statistical evaluation is computed, using a set of 47 images from 24 different symptomatic patients, including several classes, sizes and shapes of plaques. Bland-Altman plots of the mean intima-media thickness, for manual segmentations of two medical experts, show a high intra-observer and inter-observer agreement, with mean differences close to zero (mean between -0.10 mm and 0.18 mm) and with the large majority of differences within the limits of agreement (standard deviation between 0.10 mm and 0.12 mm). Similar Plots reveal it good agreement between the automatic and the manual segmentations (mean between -0.07 mm and 0.11 mm and standard deviation between 0.11 mm and 0.12 mm). (C) 2009 Elsevier B.V. All rights reserved.
C1 [Rocha, Rui; Campilho, Aurelio; Silva, Jorge] INEB, Div Sinal & Imagem, P-4200465 Oporto, Portugal.
   [Rocha, Rui] ISEP, Dept Matemat, P-420072 Oporto, Portugal.
   [Campilho, Aurelio; Silva, Jorge] Univ Porto, Fac Engn, P-4200465 Oporto, Portugal.
   [Azevedo, Elsa] Univ Porto, Fac Med, P-4200319 Oporto, Portugal.
   [Azevedo, Elsa; Santos, Rosa] Hosp Sao Joao, Dept Neurol, P-4200319 Oporto, Portugal.
C3 Universidade do Porto; Instituto Politecnico do Porto; Universidade do
   Porto; Universidade do Porto; Sao Joao Hospital
RP Rocha, R (corresponding author), INEB, Div Sinal & Imagem, Campus FEUP, P-4200465 Oporto, Portugal.
EM rhr@isep.ipp.pt
RI cai, bo/G-1491-2010; Azevedo, Elsa I/C-1060-2014; Campilho,
   Aurelio/M-4869-2013; Silva, Jorge/M-7635-2013
OI Azevedo, Elsa I/0000-0003-3731-4508; Santos, Rosa/0000-0003-0126-7420;
   Rocha, Rui/0000-0001-8357-2757; Campilho, Aurelio/0000-0002-5317-6275;
   Silva, Jorge/0000-0001-6226-4667
CR [Anonymous], COMMUN ACM
   [Anonymous], PHYSICA D
   [Anonymous], 2000, Numerical Analysis
   BALCLASSARRE D, 2000, STROKE, V31, P2426
   BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
   BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheng DC, 2002, COMPUT METH PROG BIO, V67, P27, DOI 10.1016/S0169-2607(00)00149-8
   De Boor C, 1978, A Pratical Guide to Splines, V27
   Ellis SM, 2007, ULTRASOUND MED BIOL, V33, P1029, DOI 10.1016/j.ultrasmedbio.2007.02.002
   Fedkiw R., 2003, LEVEL SET METHODS DY
   Fitzpatrick J.M., 2000, HDB MED IMAGING
   GARIEPY J, 1993, HYPERTENSION, V22, P111, DOI 10.1161/01.HYP.22.1.111
   Gee A, 2003, PATTERN RECOGN LETT, V24, P757, DOI 10.1016/S0167-8655(02)00180-0
   Graf IM, 2009, ULTRASOUND MED BIOL, V35, P955, DOI 10.1016/j.ultrasmedbio.2008.12.016
   GUSTAVSSON T, 1994, COMPUT CARDIOL
   Halenka Milan, 1999, Acta Universitatis Palackianae Olomucensis Facultatis Medicae, V142, P7
   Hodis HN, 1998, ANN INTERN MED, V128, P262, DOI 10.7326/0003-4819-128-4-199802150-00002
   Kern R, 2004, STROKE, V35, P870, DOI 10.1161/01.STR.0000120728.72958.4A
   Liang Q, 2000, IEEE T MED IMAGING, V19, P127, DOI 10.1109/42.836372
   Loizou CP, 2007, MED BIOL ENG COMPUT, V45, P35, DOI 10.1007/s11517-006-0140-3
   Loizou CP, 2007, IEEE T INF TECHNOL B, V11, P661, DOI 10.1109/TITB.2006.890019
   Loizou CP, 2005, IEEE T ULTRASON FERR, V52, P1653, DOI 10.1109/TUFFC.2005.1561621
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   O'Leary DH, 1999, NEW ENGL J MED, V340, P14, DOI 10.1056/NEJM199901073400103
   ROCHA R, 2007, THESIS U PORTO PORTO
   Rudin L. I., 1994, Proceedings ICIP-94 (Cat. No.94CH35708), P31, DOI 10.1109/ICIP.1994.413269
   Schmidt-Trucksäss A, 2001, CLIN PHYSIOL, V21, P561, DOI 10.1046/j.1365-2281.2001.00358.x
   SELZER RH, 1994, ATHEROSCLEROSIS, V111, P1, DOI 10.1016/0021-9150(94)90186-4
   Selzer RH, 2001, ATHEROSCLEROSIS, V154, P185, DOI 10.1016/S0021-9150(00)00461-5
   Sethian A.J., 1999, Level Set Methods and Fast Marching Methods
   Stein JH, 2005, J AM SOC ECHOCARDIOG, V18, P244, DOI 10.1016/j.echo.2004.12.002
   Thijssen JM, 2003, PATTERN RECOGN LETT, V24, P659, DOI 10.1016/S0167-8655(02)00173-3
   TOUBOUL PJ, 1992, J HYPERTENS        S, V10, P37
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wendelhag I, 1997, STROKE, V28, P2195, DOI 10.1161/01.STR.28.11.2195
   Werer B., 1999, INT C IM AN PROC, P452
   Yang Z, 2007, ULTRASOUND MED BIOL, V33, P1309, DOI 10.1016/j.ultrasmedbio.2007.02.013
   YANOWITZ SD, 1989, COMPUT VISION GRAPH, V46, P82, DOI 10.1016/S0734-189X(89)80017-9
   Yu YJ, 2004, IEEE T IMAGE PROCESS, V13, P1640, DOI 10.1109/TIP.2004.836166
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   ZACK GW, 1977, J HISTOCHEM CYTOCHEM, V25, P741, DOI 10.1177/25.7.70454
   [No title captured]
NR 45
TC 67
Z9 71
U1 0
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 614
EP 625
DI 10.1016/j.imavis.2009.09.017
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600007
DA 2024-07-18
ER

PT J
AU Luengo-Oroz, MA
   Faure, E
   Angulo, J
AF Luengo-Oroz, Miguel A.
   Faure, Emmanuel
   Angulo, Jesus
TI Robust iris segmentation on uncalibrated noisy images using mathematical
   morphology
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris segmentation; Non-cooperative iris biometry; Spatially variant
   mathematical morphology; Grey-level generalized distance
AB This paper proposes a new approach for fast iris segmentation that relies on the closed nested structures of iris anatomy (the sclera is brighter than the iris, and the iris is brighter than the pupil) and on its polar symmetry. The described method applies mathematical morphology for polar/radial-invariant image filtering and for circular segmentation using shortest paths from generalized grey-level distances. The proposed algorithm obtained good results on the NICE-I contest and showed a very robust behavior, especially when dealing with half-closed eyes, different skin colours/illumination or subjects wearing glasses. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Luengo-Oroz, Miguel A.] Univ Politecn Madrid, Biomed Image Technol Lab, ETSI Telecomunicac, E-28040 Madrid, Spain.
   [Faure, Emmanuel] Ecole Polytech, CNRS, Ctr Rech Epistemol Appl, F-75005 Paris, France.
   [Angulo, Jesus] MINES Paristech, Ctr Morphol Math Math & Syst, F-77300 Fontainebleau, France.
   [Luengo-Oroz, Miguel A.; Faure, Emmanuel] ISC PIF, Complex Syst Inst Paris, F-75005 Paris, France.
C3 Universidad Politecnica de Madrid; Centre National de la Recherche
   Scientifique (CNRS); Universite PSL; MINES ParisTech; Universite Paris
   Cite
RP Luengo-Oroz, MA (corresponding author), Univ Politecn Madrid, Biomed Image Technol Lab, ETSI Telecomunicac, Av Complutense SN, E-28040 Madrid, Spain.
EM maluengo@die.upm.es; emmanuel.faure@polytechnique.edu;
   jesus.angulo@mines-paristech.fr
RI Luengo-Oroz, Miguel A/C-2245-2011
OI Luengo-Oroz, Miguel A/0000-0002-8694-2001; Faure,
   Emmanuel/0000-0003-2787-0885
FU FONTIRIS Biometrics
FX This research has been partially funded by FONTIRIS Biometrics S.L.
CR Luengo-Oroz MA, 2009, IEEE T IMAGE PROCESS, V18, P1090, DOI 10.1109/TIP.2009.2013078
   Angulo Jesus, 2008, Image Analysis & Stereology, V27, P107, DOI 10.5566/ias.v27.p107-124
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Matey JR, 2010, IMAGE VISION COMPUT, V28, P215, DOI 10.1016/j.imavis.2009.05.006
   Proenca H., 2007, First IEEE International Conference on Biometrics: Theory, Applications, and Systems, P1
   ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7
   Serra J., 1988, IMAGE ANAL MATH MORP
   Vincent L, 1998, COMP IMAG VIS, V12, P331
   VINCENT L, 1992, P NATO WORKSH SHAP P
NR 11
TC 38
Z9 46
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2010
VL 28
IS 2
SI SI
BP 278
EP 284
DI 10.1016/j.imavis.2009.04.018
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 538GR
UT WOS:000273173100010
DA 2024-07-18
ER

PT J
AU Matey, JR
   Broussard, R
   Kennell, L
AF Matey, James R.
   Broussard, Randy
   Kennell, Lauren
TI Iris image segmentation and sub-optimal images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometric; Iris recognition; Iris segmentation
ID RECOGNITION
AB Iris recognition is well developed and works well for optimal or near-optimal iris images. Dealing with sub-optimal images remains a challenge. Resolution, wavelength, occlusion and gaze are among the most important factors for sub-optimal images. In this paper, we explore the sensitivity of matching to these factors through analysis and numerical simulation, with particular emphasis on the segmentation portion of the processing chain. (C) 2009 Published by Elsevier B.V.
C1 [Matey, James R.; Broussard, Randy] USN Acad, Ctr Biometr Signal Proc, ECE Dept, Annapolis, MD 21402 USA.
   [Kennell, Lauren] Johns Hopkins Appl Phys Lab, Laurel, MD 20723 USA.
C3 United States Department of Defense; United States Navy; United States
   Naval Academy; Johns Hopkins University; Johns Hopkins University
   Applied Physics Laboratory
RP Matey, JR (corresponding author), USN Acad, Ctr Biometr Signal Proc, ECE Dept, Maury Hall,MS 14B, Annapolis, MD 21402 USA.
EM matey@usna.edu
RI Matey, James R/B-4372-2013
OI Matey, James R/0000-0002-0508-785X
FU US Naval Academy Center
FX This work has been funded through the US Naval Academy Center for
   Biometric Signal Processing.
CR ABHYANKAR A, 2006, P SPIE, V6202
   *AFF HOYOS GROUP, GLOB RAINM
   [Anonymous], 1979, ROBUSTNESS STAT
   Arvacheh EM, 2006, IEEE IMAGE PROC, P2453, DOI 10.1109/ICIP.2006.312773
   BACHOO AK, 2005, ACM INT C P SERIES, V150, P236
   Bashir F, 2008, 2008 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, VOLS 1 AND 2, P426, DOI 10.1109/THS.2008.4534490
   BERTILLON A, 1886, ANN DEMOGRAPHIE INT, V7, P226
   Bertillon Alphonse, 1896, SIGNALETIC INSTRUCTI, P13
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Boyce C., 2006, Computer Vision and Pattern Recognition Workshop, P51
   BOYCE CK, 2006, THESIS W VIRGINIAN U
   BROUSSARD RP, 2009, 2009 IEEE WORK UNPUB
   Camus TA, 2002, INT C PATT RECOG, P389, DOI 10.1109/ICPR.2002.1044732
   CUI JL, 2004, FAST ROBUST IRIS LOC
   Daugman J., 2004, IEEE T CIRCUITS SYST, V14
   Daugman J.G., 1994, U.S. Patent, Patent No. 5291560
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Daugman J, 2006, P IEEE, V94, P1927, DOI 10.1109/JPROC.2006.884092
   DU YZ, 2004, SPIE EUR S OPT PHOT
   FANCOURT C, 2005, P 5 INT C AUD VID BA
   Geterman G., 2008, U.S. Patent Application, Patent No. 20080075334
   He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183
   He ZF, 2008, IEEE IMAGE PROC, P265, DOI 10.1109/ICIP.2008.4711742
   Huang JZ, 2004, INT C PATT RECOG, P554, DOI 10.1109/ICPR.2004.1334589
   Kennell LR, 2006, IEEE IMAGE PROC, P293, DOI 10.1109/ICIP.2006.313183
   KONG W, 2001, P 2001 INT S INT MUL
   Kong WK, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P263, DOI 10.1109/ISIMP.2001.925384
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   MA L, 2002, ACCV2002, V1, P279
   MALHAUS I, CEO IRISGUARD
   Matey JR, 2006, P IEEE, V94, P1936, DOI 10.1109/JPROC.2006.884091
   MATEY JR, 2009, HDB REMOTE IN PRESS
   NORTHCOTT MJ, 2008, Patent No. 20080002863
   Proença H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213
   ROSS A, 2006, SPEC SESS RES BIOM C
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   XU G, 2006, ICCI 2006, V2, P871
NR 38
TC 17
Z9 25
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2010
VL 28
IS 2
SI SI
BP 215
EP 222
DI 10.1016/j.imavis.2009.05.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 538GR
UT WOS:000273173100002
DA 2024-07-18
ER

PT J
AU Minvielle, P
   Doucet, A
   Marrs, A
   Maskell, S
AF Minvielle, Pierre
   Doucet, Arnaud
   Marrs, Alan
   Maskell, Simon
TI A Bayesian approach to joint tracking and identification of geometric
   shapes in video sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Bayesian model selection; Particle filtering; Target tracking
ID MONTE-CARLO; PARTICLE FILTERS; ALGORITHM; PARAMETER
AB A Bayesian approach is proposed for joint tracking and identification. These two problems are often addressed independently in the literature, leading to suboptimal performance. In a Bayesian approach, a prior distribution is set on both the hypothesis space and the associated parameter space. Although this is straightforward from a conceptual viewpoint, it is typically impossible to perform inference in closed-form. We discuss an advanced particle filtering approach to solve this computational problem and apply this algorithm to joint tracking and identification of geometric forms in video sequences. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Minvielle, Pierre] CEA, CESTA, DAM, F-33114 Le Barp, France.
   [Doucet, Arnaud] Inst Stat Math, Tokyo, Japan.
   [Marrs, Alan; Maskell, Simon] QinetiQ Ltd, Malvern, Worcs, England.
C3 CEA; Research Organization of Information & Systems (ROIS); Institute of
   Statistical Mathematics (ISM) - Japan; Qinetiq Group Plc
RP Minvielle, P (corresponding author), CEA, CESTA, DAM, F-33114 Le Barp, France.
EM pierre.minvielle@cea.fr; arnaud@ism.ac.jp; admarrs@qinetiq.com;
   s.maskell@signal.qinetiq.com
RI Doucet, Arnaud/B-2473-2013; Minvielle, Pierre/R-9429-2019
OI Doucet, Arnaud/0000-0002-7662-419X
FU French MOD - DGA/DSFP [02.60.00.060]
FX This research was completed by the French MOD - DGA/DSFP, Contract No.
   02.60.00.060 and was completed at QinetiQ Malvern.
CR ALSPACH DL, 1975, AUTOMATICA, V11, P285, DOI 10.1016/0005-1098(75)90044-8
   Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116
   ANDRIEU C, 1999, P WORK IEEE HOS
   ANDRIEU C, 2000, NEWTOWN I SERIES
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bar-Shalom Yaakov., 1993, ESTIMATION TRACKING
   Berzuini C, 2001, STAT ENG IN, P117
   BERZUINI C, 1997, J AM STAT ASSOC, V92, P1043
   Blackman S., 1999, Design and analysis of modern tracking systems
   BOERS Y, 2001, SPIE SIGNAL DATA PRO
   Challa S, 2001, IEEE T AERO ELEC SYS, V37, P1039, DOI 10.1109/7.953266
   CLAPP T, 2000, THESIS CAMBRIDGE U E
   Crisan D, 2002, IEEE T SIGNAL PROCES, V50, P736, DOI 10.1109/78.984773
   Del Moral P, 2006, J R STAT SOC B, V68, P411, DOI 10.1111/j.1467-9868.2006.00553.x
   DEUTSCHER J, 2000, IEEE C COMP VIS PATT
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Fearnhead P, 2002, J COMPUT GRAPH STAT, V11, P848, DOI 10.1198/106186002835
   Godsill S, 2001, STAT ENG IN, P139
   GORDON N, 2002, SPIE SIGNAL DATA PRO
   Hall D.L., 2001, HDB MULTISENSOR DATA
   HERMAN S, 2002, IEEE AER C 2002 BIG
   Lee DS, 2002, IEEE T SIGNAL PROCES, V50, P326, DOI 10.1109/78.978387
   Liu J, 2001, STAT ENG IN, P197
   Maskell S, 2004, EURASIP J APPL SIG P, V2004, P2339, DOI 10.1155/S1110865704404223
   Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Storvik G, 2002, IEEE T SIGNAL PROCES, V50, P281, DOI 10.1109/78.978383
NR 28
TC 13
Z9 16
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 111
EP 123
DI 10.1016/j.imavis.2009.05.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000012
DA 2024-07-18
ER

PT J
AU Wang, ZB
   Ma, YD
   Cheng, FY
   Yang, LZ
AF Wang, Zhaobin
   Ma, Yide
   Cheng, Feiyan
   Yang, Lizhen
TI Review of pulse-coupled neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Pulse-coupled neural networks (PCNN); Image processing; Artificial
   neural network
ID INTERSECTING CORTICAL MODEL; IMAGE SEGMENTATION; FUSION; PCNN;
   CLASSIFICATION; ROTATION; LINKING; NOISE; SCALE
AB This paper reviews the research status of pulse-coupled neural networks (PCNN) in the past decade. Considering there are too many publications about the PCNN, we summarize main approaches and point out interesting parts of the PCNN researches rather than contemplate to go into details of particular algorithms or describe results of comparative experiments. First, the current status of the PCNN and some modified models are briefly introduced. Second, we review the PCNN applications in the field of image processing (e.g. image segmentation, image enhancement, image fusion, object and edge detection, pattern recognition, etc.), then applications in other fields also are mentioned. Subsequently, some existing problems are summarized, while we give some suggestions for the solutions to some puzzles. Finally, the trend of the PCNN is pointed out. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Wang, Zhaobin; Ma, Yide; Cheng, Feiyan; Yang, Lizhen] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Gansu, Peoples R China.
C3 Lanzhou University
RP Ma, YD (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Gansu, Peoples R China.
EM zhaobin_wang@hotmail.com; ydma@lzu.edu.cn
RI Lin, Lin/JTU-1595-2023
OI Ma, Yide/0000-0001-6098-7853
FU National Natural Science Foundation of China [60572011, 60872109];
   Program for New Century Excellent Talents in University [NCET-06-0900];
   China Scholarship
FX We thank the associate editor, reviewers, and people, who help us to
   improve the paper, for their helpful and constructive suggestions. The
   authors also thank Ying Zhu for her support and help. This paper is
   jointly supported by National Natural Science Foundation of China (Nos.
   60572011 and 60872109), Program for New Century Excellent Talents in
   University (NCET-06-0900), and China Scholarship.
CR Åberg KM, 2001, CHEMOMETR INTELL LAB, V57, P25, DOI 10.1016/S0169-7439(01)00118-6
   Allen FT, 1999, NEURAL NETWORKS, V12, P519, DOI 10.1016/S0893-6080(98)00124-5
   [Anonymous], P INT C ART INT IC A
   [Anonymous], 2008, P 6 INT S APPL MACH, DOI DOI 10.1109/SAMI.2008.4469166
   Becanovic V, 2000, PATTERN RECOGN LETT, V21, P253, DOI 10.1016/S0167-8655(99)00154-3
   BERTHE K, 2001, P INT C INF INFO BEI, V3, P504
   Bi Ying-wei, 2005, Acta Electronica Sinica, V33, P647
   BLASCH EP, 1999, P INT JOINT C NEUR N, V4, P2792
   Broussard RP, 1999, IEEE T NEURAL NETWOR, V10, P554, DOI 10.1109/72.761712
   Caulfield HJ, 1999, IEEE T NEURAL NETWOR, V10, P604, DOI 10.1109/72.761718
   Chacón MMI, 2003, IEEE IJCNN, P1195
   CHACON MMI, 2003, P INT C IM PROC, V1, P877
   Clark N, 1999, IEEE T NEURAL NETWOR, V10, P599, DOI 10.1109/72.761717
   COOLEY JH, 1999, P INT GEOSC REM SENS, V1, P80
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Eckhorn R., 1989, MODELS BRAIN FUNCTIO, P255, DOI DOI 10.1139/W00-039
   Ekblad U, 2004, NUCL INSTRUM METH A, V525, P392, DOI 10.1016/j.nima.2004.03.102
   Ekblad U, 2004, SIGNAL PROCESS, V84, P1131, DOI 10.1016/j.sigpro.2004.03.012
   FENG D, 2007, P 8 INT C EL MEAS IN, V2, P844
   FORGAC R, 2005, P 3 SLOV HUNG JOINT, P107
   FU Q, 2007, P INT C INT SYST KNO, P1
   GODIN C, 1999, P INT JOINT C NEUR N, V3, P1876
   GRASSMANN C, 2002, P EUR S ART NEUR NET, P331
   GU X, 2005, P INT C SIGN PROC, V2, P1597
   GU X, 2005, P INT C NEUR NETW BR, V3, P1328
   Gu XD, 2005, IEEE IJCNN, P1836
   Gu XD, 2005, IEEE T NEURAL NETWOR, V16, P692, DOI 10.1109/TNN.2005.844902
   Gu XD, 2004, LECT NOTES COMPUT SC, V3173, P413
   Gu XD, 2004, PATTERN RECOGN LETT, V25, P1075, DOI 10.1016/j.patrec.2004.03.005
   Gu XD, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P175, DOI 10.1109/ICMLC.2002.1176733
   Gu XD, 2008, NEURAL PROCESS LETT, V27, P25, DOI 10.1007/s11063-007-9057-6
   Gu XD, 2006, IEEE IJCNN, P1036
   [顾晓东 Gu Xiaodong], 2003, [电子与信息学报, Journal of electronics & information technology], V25, P1585
   Guo M, 2006, LECT NOTES ARTIF INT, V4099, P1206
   Huang W., 2007, PATTERN RECOGN LETT, P1
   Iftekharuddin KM, 2002, P ANN INT IEEE EMBS, P1111, DOI 10.1109/IEMBS.2002.1106302
   Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440
   Ji LP, 2007, IEEE T SYST MAN CY B, V37, P1407, DOI 10.1109/TSMCB.2007.903369
   Ji LP, 2006, LECT NOTES COMPUT SC, V4221, P395
   Johnson J., 1998, Neural Networks and Pattern Recognition, P1
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P461, DOI 10.1109/TNN.1999.761704
   JOHNSON JL, 1993, OPT LETT, V18, P1253, DOI 10.1364/OL.18.001253
   JOHNSON JL, 1994, APPL OPTICS, V33, P6239, DOI 10.1364/AO.33.006239
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   JOHNSON JL, 1994, P IEEE INT C NEUR NE, V2, P1279
   Karvonen JA, 2004, IEEE T GEOSCI REMOTE, V42, P1566, DOI 10.1109/TGRS.2004.828179
   Kinser JM, 1997, OPT ENG, V36, P737, DOI 10.1117/1.601271
   Kinser JM, 1998, OPT ENG, V37, P492, DOI 10.1117/1.601637
   Kinser JM, 2000, CHEMOMETR INTELL LAB, V51, P115, DOI 10.1016/S0169-7439(00)00065-4
   Kinser JM, 1996, P SOC PHOTO-OPT INS, V2760, P563, DOI 10.1117/12.235951
   Kinser JM, 1999, IEEE T NEURAL NETWOR, V10, P621, DOI 10.1109/72.761721
   Kuntimad G, 1999, IEEE T NEURAL NETWOR, V10, P591, DOI 10.1109/72.761716
   Li G., 2005, J TEST MEASUREMENT T, V19, P304
   Li Guo-you, 2005, Journal of System Simulation, V17, P1370
   [李国友 Li Guoyou], 2005, [光电子·激光, Journal of Optoelectronics·Laser], V16, P358
   Li M, 2006, LECT NOTES COMPUT SC, V4221, P471
   Li M, 2006, PATTERN RECOGN LETT, V27, P1948, DOI 10.1016/j.patrec.2006.05.004
   LI W, 2005, P 4 INT C MACH LEARN, V9, P5297
   LIM YW, 2004, P INT C CONTR AUT SY, P1048
   Lin W, 2003, IEEE T CIRCUITS-I, V50, P686, DOI 10.1109/TCSI.2003.811015
   LINDBLAD T, 2002, IMAGE PROCESSING USI
   Liu Q, 2007, PROCEEDINGS OF THE 26TH CHINESE CONTROL CONFERENCE, VOL 4, P96
   [刘勍 Liu Qing], 2005, [中国图象图形学报. A, Journal of image and graphics], V10, P579
   [刘勍 Liu Qinge], 2008, [电子与信息学报, Journal of Electronics & Information Technology], V30, P1869
   [陆佳佳 LU Jiajia], 2007, [光电工程, Opto-Electronic Engineering], V34, P50
   Ma Y, 2002, CHINESE SCI BULL, V47, P167
   MA Y, 2006, ACTA ELECT SINICA, V7, P1255
   MA Y, 2006, P INT C SENS COMP AU, P2005
   MA Y, P ISCIT2005, P321
   Ma YD, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P149
   MA YD, 2003, P INT C NEUR NETW SI, V1, P152
   Ma Yi-de, 2002, Journal of China Institute of Communications, V23, P46
   Ma Yi-de, 2008, Journal of Beijing University of Posts and Telecommunications, V31, P108
   Ma Yi-de, 2006, Journal of System Simulation, V18, P722
   Ma YD, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P86, DOI 10.1109/FSKD.2007.93
   Ma YD, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P808, DOI 10.1109/ICIA.2006.305834
   McClurkin John W., 1994, Cerebral Cortex, V10, P443
   [苗启广 Miao Qiguang], 2006, [电子与信息学报, Journal of electronics & information technology], V28, P466
   Muresan RC, 2003, NEUROCOMPUTING, V51, P487, DOI 10.1016/S0925-2312(02)00727-0
   NAZMY TM, 2005, P ICGST INT C GRAPH, V6, P39
   Ogawa Y, 2004, SICE 2004 ANNUAL CONFERENCE, VOLS 1-3, P311
   Ota Y, 1999, IEEE T NEURAL NETWOR, V10, P539, DOI 10.1109/72.761710
   OTA Y, 2002, P 28 ANN C IND EL SO, V4, P3221
   QU H, 2006, CHINA PETROLEUM EXPL, P1
   Ranganath H. S., 1995, Proceedings IEEE Southeastcon '95. Visualize the Future (Cat. No.95CH35793), P37, DOI 10.1109/SECON.1995.513053
   Ranganath HS, 1999, IEEE T NEURAL NETWOR, V10, P615, DOI 10.1109/72.761720
   Reitboeck H. J., 1989, SYNERGISTICS COGNITI, V2, P112
   ROPPELA T, 1999, P INT JOINT C NEUR N, V1, P142
   RUGHOOPUTH H, 1999, P IEEE AF 1999, V2, P749
   RUGHOOPUTH HCS, 2003, P INT C IND TECHN, V1, P89
   RUGHOOPUTH SD, 1999, P INT JOINT C NEUR N, V5, P3143
   RYBAK IA, 1992, NEUROCOMPUTING, V4, P93, DOI 10.1016/0925-2312(92)90047-S
   RYBAK IA, 1991, NEURAL NETWORKS, V4, P3, DOI 10.1016/0893-6080(91)90026-2
   Schäfer M, 1999, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON MICROELECTRONICS FOR NEURAL, FUZZY AND BIO-INSPIRED SYSTEMS, MICORNEURO'99, P316, DOI 10.1109/MN.1999.758881
   Schæfer M, 2002, NEUROCOMPUTING, V48, P647, DOI 10.1016/S0925-2312(01)00633-6
   SHANG L, 2006, NEUROCOMPUTING, V7, P1
   SHI M, 2005, COMPUTER ENG APPL, P235
   [石美红 Shi Meihong], 2004, [计算机应用, Computer Applications], V24, P69
   Stewart RD, 2002, IEEE T NEURAL NETWOR, V13, P1557, DOI 10.1109/TNN.2002.804229
   Sugiyama T., 2004, Artificial Life and Robotics, V7, P156, DOI 10.1007/s10015-003-0248-6
   SZEKELY G, 1999, P C EV COMP, V1, P503
   SZIKELY G, 1999, P INT JOINT C NEUR N, V1, P371
   Takahashi Y, 2004, IEEE T CIRCUITS-II, V51, P468, DOI 10.1109/TCSII.2004.832778
   TANAKA M, 1999, P INT C SYST MAN CYB, V1, P599
   Timoszczuk AP, 2007, IEEE IJCNN, P1965, DOI 10.1109/IJCNN.2007.4371259
   TORIKAI H, 2001, P INT JOINT C NEUR N, V1, P670
   Vega-Pineda J, 2006, IEEE IJCNN, P4051
   Waldemark J, 2000, PATTERN RECOGN LETT, V21, P239, DOI 10.1016/S0167-8655(99)00153-1
   Waldemark K, 2000, PATTERN RECOGN LETT, V21, P227, DOI 10.1016/S0167-8655(99)00152-X
   WANG Z, 2007, INT J INFORM ACQUISI, V4, P69
   Wang ZB, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 1, PROCEEDINGS, P755
   Wang ZB, 2008, INFORM FUSION, V9, P176, DOI 10.1016/j.inffus.2007.04.003
   Wang ZB, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P814, DOI 10.1109/ICIA.2006.305836
   Watanabe T., 2002, Transactions of the Society of Instrument and Control Engineers, V38, P726
   Wolfer J, 1999, COMPUT CARDIOL, V26, P185, DOI 10.1109/CIC.1999.825937
   XU B, 2004, P 5 WORLD C INT CONT, V4, P3679
   Yamada H, 2003, SICE 2003 ANNUAL CONFERENCE, VOLS 1-3, P2784
   YAMAGUCHI U, 2002, P 9 INT C NEUR INF P, V2, P571
   YAMAGUCHI Y, 2002, P SICE, P730
   Yamaoka D, 2003, SICE 2003 ANNUAL CONFERENCE, VOLS 1-3, P2778
   YIDE M, 2008, J SYSTEM SIMULATION, V20, P2897
   Yu B, 2004, IEEE T NEURAL NETWOR, V15, P1186, DOI 10.1109/TNN.2004.832830
   Yu B, 2003, IEEE IJCNN, P1179
   ZETTERLUND N, 2004, P 7 INT C INF FUS, P1014
   ZHANG H, P 2007 INT C NEUR NE, P208
   Zhang J., 2005, P INT C IM PROC, V2, P133
   Zhang J.Y., 2003, CHINA FRUIT PLANT MO, P93
   Zhang JW, 2007, NEURAL NETW WORLD, V17, P121
   [张军英 Zhang Junying], 2004, [计算机仿真, Computer Simulation], V21, P102
   Zhang JY, 2005, SCI CHINA SER F, V48, P322, DOI 10.1360/03ye0168
   Zhang XF, 2004, IEEE T NEURAL NETWOR, V15, P1202, DOI 10.1109/TNN.2004.832817
   Zhao Rong-chang, 2008, Systems Engineering and Electronics, V30, P1785
   Zhao Shi-jiang, 2005, Acta Electronica Sinica, V33, P1342
NR 133
TC 195
Z9 257
U1 3
U2 94
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 5
EP 13
DI 10.1016/j.imavis.2009.06.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000002
DA 2024-07-18
ER

PT J
AU Gatica-Perez, D
AF Gatica-Perez, Daniel
TI Automatic nonverbal analysis of social interaction in small groups: A
   review
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Social interaction analysis; Small group conversations; Nonverbal
   behavior
ID DOMINANCE; BEHAVIOR; SPEAKING; LOOKING; ROLES; POWER
AB An increasing awareness of the scientific and technological value of the automatic understanding of face-to-face social interaction has motivated in the past few years a surge of interest in the devising of computational techniques for conversational analysis. As an alternative to existing linguistic approaches for the automatic analysis of conversations, a relatively recent domain is using findings in social cognition, social psychology, and communication that have established the key role that nonverbal communication plays in the formation, maintenance, and evolution of a number of fundamental social constructs, which emerge from face-to-face interactions in time scales that range from short glimpses all the way to long-term encounters. Small group conversations are a specific case on which much of this work has been conducted. This paper reviews the existing literature on automatic analysis of small group conversations using nonverbal communication, and aims at bridging the current fragmentation of the work in this domain, currently split among half a dozen technical communities. The review is organized around the main themes studied in the literature and discusses, in a comparative fashion, about 100 works addressing problems related to the computational modeling of interaction management, internal states, personality traits, and social relationships in small group conversations, along with pointers to the relevant literature in social science. Some of the many open challenges and opportunities in this domain are also discussed. (C) 2009 Elsevier B.V. All rights reserved.
C1 Ecole Polytech Fed Lausanne, Idiap Res Inst, Martigny, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Gatica-Perez, D (corresponding author), Ecole Polytech Fed Lausanne, Idiap Res Inst, Martigny, Switzerland.
EM gatica@idiap.ch
FU Swiss National Center of Competence in Research on Interactive
   Multimodal Information Management (IM2); EC; US research program
FX The author thanks the support of the Swiss National Center of Competence
   in Research on Interactive Multimodal Information Management (IM2), the
   EC project Augmented Multi-Party Interaction with Distant Access
   (AMIDA), and the US research program on Video Analysis and Content
   Extraction (VACE). He also thanks Jean-Marc Odobez, Hayley Hung, and
   Sileye Ba (Idiap) for discussions about several of the topics presented
   here, and Dinesh Jayagopi (Idiap) for his comments and technical help
   with the manuscript.
CR AJMERA J, 2003, P IEEE AUT SPEECH RE
   AKKER HJA, 2008, P AISB S MULT OUTP G
   ALHAMES M, 2005, P WORKSH MACH LEARN
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], 1999, HDB PERSONALITY THEO
   [Anonymous], THESIS U TWENTE
   [Anonymous], 2008, HONEST SIGNALS, DOI DOI 10.7551/MITPRESS/8022.001.0001
   [Anonymous], P WORKSH MACH LEARN
   [Anonymous], COMPUTER
   [Anonymous], 2001, IEEE SIGNAL PROCESSI
   BA SO, 2008, P IEEE INT C AC SPEE
   BA SO, 2004, P INT C PATT REC ICP
   BACHOUR K, 2008, P EUR C TECHN ENH LE
   Bales RobertF., 1950, INTERACTION PROCESS
   BANERJEE S, 2004, P IEEE INT C AC SPEE
   BANERJEE S, 2004, P INT C SPOK LANG PR
   BASU S, 2001, P IEEE CVPR INT WORK
   BENGIO S, 2002, P C ADV NEUR INF PRO
   BERGSTROM T, 2007, P HAW INT C SYST SCI
   Brand M, 1997, P IEEE C COMP VIS PA
   BRDICZKA O, 2005, P INT C MULT INT ICM
   BURGER S, 2002, P ICSLP DENV SEP
   Burgoon J.K., 2006, SAGE HDB NONVERBAL C
   CAMPBELL N, 2006, P LANG RES EV C LREC
   CAMPBELL N, 2007, P INTERSPEECH
   Campbell N., 2007, P COST 2102 WORKSH V
   CAPPELLA JN, 1985, MULTICHANNEL INTEGRA
   CARLETTA J, 2005, P WORKSH MACH LEARN
   Carletta J, 2007, LANG RESOUR EVAL, V41, P181, DOI 10.1007/s10579-007-9040-x
   CHARTRAND T, 2005, NEW UNCONSCIOUS
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   CHEN L, 2005, P WORKSH MACH LEARN
   CHEN L, 2006, P WORKSH MACH LEARN
   Choi Y., 2005, The new unconscious
   CHOUDHURY T, 2003, P INT C UB COMP SEAT
   CHOUDHURY T, 2004, P NIPS DEC
   CLARK HH, 1982, LANGUAGE, V58, P332, DOI 10.2307/414102
   COOK M, 1975, BRIT J SOCIAL CLIN P
   Curhan JR, 2007, J APPL PSYCHOL, V92, P802, DOI 10.1037/0021-9010.92.3.802
   DIELMANN A, 2004, P IEEE INT C AC SPEE
   Dielmann A, 2007, IEEE T MULTIMEDIA, V9, P25, DOI 10.1109/TMM.2006.886337
   Dong W, 2007, P INT C MULT INT ICM
   DOVIDIO JF, 1982, SOC PSYCHOL QUART, V45, P106, DOI 10.2307/3033933
   Dunbar NE, 2005, SOURCEBOOK OF NONVERBAL MEASURES: GOING BEYOND WORDS, P361
   Dunbar NE, 2005, J SOC PERS RELAT, V22, P207, DOI 10.1177/0265407505050944
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031
   Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479
   EAGLE N, 2003, P INT C UB COMP UBIC
   EFRAN JS, 1968, J PERS SOC PSYCHOL, V10, P21, DOI 10.1037/h0026383
   Ellyson S.L., 1985, POWER DOMINANCE NONV
   EXLINE RV, 1975, ADV STUDY COMMUNICAT
   Favre S, 2008, P INT C MULT INT ICM
   Fay N, 2000, PSYCHOL SCI, V11, P481, DOI 10.1111/1467-9280.00292
   GARG NP, 2008, P ACM INT C MULT VAN
   GAROFOLO J, 2004, P LANG RES EV C LREC
   Gatica-Perez D, 2006, P IEEE INT C MULT FU
   Gatica-Perez D, 2005, P ACM INT C MULT WOR
   Gatica-Perez D., 2005, P IEEE INT C AC SPEE
   GIFFORD R, 2006, SAGE HDB NONVERBAL C
   GOODWIN C, 1981, CONVERSATIONAL ORG I, V11
   Hall JA, 2005, PSYCHOL BULL, V131, P898, DOI 10.1037/0033-2909.131.6.898
   HARE AP, 1994, SMALL GR RES, V25, P433, DOI 10.1177/1046496494253005
   Hassin R., 2005, NEW UNCONSCIOUS
   HEYLEN D, 2007, P COST 2102 WORKSH V
   HEYLEN D, 2006, P LREC WORKSH CORP R
   HILLARD D, 2003, P HLT NAACL C EDM MA
   HUNG H, 2008, P IEEE C COMP VIS PA
   HUNG H, 2008, P INT C MULT INT ICM
   HUNG H, 2008, P IEEE INT C AC SPEE
   HUNG H, 2007, P ACM INT C MULT ACM
   Jayagopi D, 2008, P INT C MULT INT ICM
   JAYAGOPI D, 2009, IEEE T PATTERN ANAL, V17
   Jayagopi D, 2008, P ACM INT C MULT VAN
   JOVANOVIC N, 2004, P SIGDIAL WORKSH DIS
   Jovanovic N., 2006, P C EUR CHAPT ASS CO
   JOVANOVIC N, 2005, P SIGDIAL WORKSH DIS
   KATZENMEIER M, 2004, P INT C MULT INT ICM
   KENNEDY L, 2003, P ASRU VIRG ISL DEC
   KENNEDY L, 2004, P ICASSP
   KIM TM, 2008, P ACM C COMP SUPP CO
   Knapp M.L., 2005, Nonverbal communication in human interaction, V6th
   KNOX M, 2007, P INT ANTW
   KULYK O, 2005, P INT WORKSH MACH LE
   LASKOWSKI K, 2008, P INT WORKSH MACH LE
   LEFFLER A, 1982, SOC PSYCHOL QUART, V45, P153, DOI 10.2307/3033648
   MADAN A, 2005, THESIS MIT
   MADAN A, 2005, P INT C AUGM COGN AC
   MANA N, 2007, P INT C MULT INT ICM
   Manusov V., 2006, The Sage Handbook of Nonverbal Communication
   Mast MS, 2002, HUM COMMUN RES, V28, P420, DOI 10.1111/j.1468-2958.2002.tb00814.x
   McCowan I, 2005, IEEE T PATTERN ANAL, V27, P305, DOI 10.1109/TPAMI.2005.49
   MCCOWAN I, 2003, P IEEE INT C AC SPEE
   McGrath J.E., 1984, GROUPS INTERACTION P
   McNeill D., 2000, LANGUAGE GESTURE
   MORGAN N, 2001, P HUM LANG TECHN C H
   OLIVER N, 2002, P INT C MULT INT ICM
   OTSUKA K, 2006, P IEEE INT C MULT IC
   OTSUKA K, 2006, P ACM CHI MONTR APR
   OTSUKA K, 2008, P INT C MULT INT ICM
   OTSUKA K, 2007, P INT C MULT INT ICM
   OTSUKA K, 2005, P INT C MULT INT ICM
   Pandolfo Anna, 2004, P ACM C COMP SUPP CO
   PETRIDIS S, 2008, P INT C MULT INT ICM
   Pianesi F, 2007, LANGUAGE RESOURCES E, V41
   Pianesi F., 2008, P INT C MULT INT ICM
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   RADUCANU B, 2009, P IEEE INT C AC SPEE
   REIDSMA D, 2006, P LREC GEN MAY
   REITER S, 2006, P IEEE INT C MULT IC
   RIENKS R, 2006, P INT C MULT INT ICM
   RIENKS R, 2007, P INT C MULT INT ICM
   RIENKS RJ, 2005, P WORKSH MACH LEARN
   ROTTER JB, 1965, PSYCHOL MONOGRAPHS, V80
   Salazar AJ, 1996, SMALL GR RES, V27, P475, DOI 10.1177/1046496496274001
   SHRIBERG E, 2005, P EUR C SPEECH COMM
   SHRIBERG E, 2004, P HLT NAACL SIGDIAL
   SMITHLOVIN L, 1989, AM SOCIOL REV, V54, P424, DOI 10.2307/2095614
   STANFORD V, 2003, IEEE T NEURAL NETWOR, V13, P928
   STIEFELHAGEN R, 2002, P INT C MULT INT ICM
   STOLTZMAN WT, 2007, P INT C MULT INT ICM
   TAKEMAE Y, 2004, P IEEE INT WORKSH RO
   TRUONG K, 2005, P INT LISB
   Truong KP, 2007, SPEECH COMMUN, V49, P144, DOI 10.1016/j.specom.2007.01.001
   Tusing KJ, 2000, HUM COMMUN RES, V26, P148, DOI 10.1093/hcr/26.1.148
   VINCIARELLI A, 2008, P ACM INT C MULT VAN
   Vinciarelli A, 2007, IEEE T MULTIMEDIA, V9, P1215, DOI 10.1109/TMM.2007.902882
   WAIBEL A, 2001, P IEEE INT C AC SPEE
   WREDE B, 2003, P IEEE AUT SPEECH RE
   WREDE B, 2003, P EUR GEN SEP
   Zancanaro M, 2006, P INT C MULT INT ICM
   ZHANG D, 2004, P ACM INT C MULT WOR
   ZHANG D, 2004, P IEEE CVPR WORKSH E
   ZHANG D, 2005, P IEEE INT C MULT IC
   Zhang D, 2006, IEEE T MULTIMEDIA, V8, P509, DOI 10.1109/TMM.2006.870735
NR 135
TC 164
Z9 175
U1 1
U2 49
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2009
VL 27
IS 12
SI SI
BP 1775
EP 1787
DI 10.1016/j.imavis.2009.01.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 513PL
UT WOS:000271335000004
DA 2024-07-18
ER

PT J
AU Lam, SCB
   McCane, B
   Allen, R
AF Lam, Shing Chun Benny
   McCane, Brendan
   Allen, Robert
TI Automated tracking in digitized videofluoroscopy sequences for spine
   kinematic analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Videofluoroscopy; Spine kinematics; Particle filter; Dynamic Bayesian
   network; Image processing
ID WHOLE LUMBAR SPINE; FLEXION-EXTENSION; SEGMENTAL MOTION; PARTICLE
   FILTERS; VERTEBRAE; FUSION; CONDENSATION
AB Spine kinematic analysis provides useful information to aid understanding of the segmental motion of the vertebrae. Digitized videofluoroscopy (DVF) is the existing practical modality to image spine motion for kinematic data acquisition. However, obtaining kinematic parameters from DVF sequence requires manual landmarking which is a laborious process and can be subjective and error prone.
   This work develops an automated spine motion tracking algorithm for DVF sequences within a Bayesian framework. By utilizing the anatomical relationships between vertebrae, a dynamic Bayesian network with a particle filter at each node is constructed. The proposed algorithm overcomes the dimensionality problem in a regular particle filter and has more efficient and robust performance. It can provide results of about 1 degrees and 2 pixels (0.2 mm) variability in rotation and translation estimation, respectively, during repeated initialization analysis on sequences from simulation and in vivo healthy human subject studies. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Lam, Shing Chun Benny; Allen, Robert] Univ Southampton, Inst Sound & Vibrat Res, Southampton SO17 1BJ, Hants, England.
   [McCane, Brendan] Univ Otago, Dept Comp Sci, Dunedin, New Zealand.
C3 University of Southampton; University of Otago
RP Lam, SCB (corresponding author), Univ Southampton, Inst Sound & Vibrat Res, Southampton SO17 1BJ, Hants, England.
EM shingchunlam@gmail.com
RI McCane, Brendan/KUD-8799-2024
OI McCane, Brendan/0000-0001-8055-3331
CR ADAMS MA, 1999, LUMBAR SEGMENTAL INS, P3
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], 1998, Image processing, analysis, and machine vision
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   ANSCOMBE FJ, 1948, BIOMETRIKA, V35, P246, DOI 10.2307/2332343
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   BIFULCO P, 1995, P HLTH TEL NAPL IT, P147
   BREEN A, 1989, J MED ENG TECHNOL, V13, P109, DOI 10.3109/03091908909030208
   Breen AC, 2006, BMC MUSCULOSKEL DIS, V7, DOI 10.1186/1471-2474-7-1
   BREEN AC, 1989, J BIOMED ENG, V11, P224, DOI 10.1016/0141-5425(89)90146-5
   Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643
   de Bruijne M, 2005, LECT NOTES COMPUT SC, V3565, P762
   DEBRUIJNE M, 2004, LECT NOTES COMPUTER, V3216, P1175
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DVORAK J, 1991, SPINE, V16, P562
   EISENSTEIN S, 2005, FAILED SPINE, P25
   Fox D, 2003, INT J ROBOT RES, V22, P985, DOI 10.1177/0278364903022012001
   Frobin W, 1996, CLIN BIOMECH, V11, P457, DOI 10.1016/S0268-0033(96)00039-3
   FRYMOYER J, 1990, LUMBAR SPINE, P612
   Gerber M, 2006, SPINE, V31, P762, DOI 10.1097/01.brs.0000206360.83728.d2
   GERTZBEIN SD, 1986, CLIN ORTHOP RELAT R, P48
   Gonzalez R.C., 1987, DIGITAL IMAGE PROCES, VSecond
   Hearn D., 1994, Computer Graphics
   Hue C, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P61, DOI 10.1109/MOT.2001.937982
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   JOHNSSON R, 1990, SPINE, V15, P347, DOI 10.1097/00007632-199005000-00001
   JOHNSSON R, 1992, SPINE, V17, P16, DOI 10.1097/00007632-199201000-00003
   KAIGLE AM, 1995, SPINE, V20, P421, DOI 10.1097/00007632-199502001-00004
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kitagawa G., 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750
   Koller-Meier EB, 2001, ROBOT AUTON SYST, V34, P93, DOI 10.1016/S0921-8890(00)00114-7
   Kondracki M., 1996, Man Ther, V1, P146, DOI 10.1054/math.1996.0263
   KONDRACKI M, 2001, THESIS U SOUTHAMPTON
   Kooi DV, 2004, SPINE, V29, P100, DOI 10.1097/01.BRS.0000103945.75275.56
   Kundel H. L, 2000, HDB MED IMAGING PHYS
   LAM SC, VIDEO DEMONSTRATION
   Lee Sai-wing, 2002, Spine (Phila Pa 1976), V27, pE215, DOI 10.1097/00007632-200204150-00022
   Leivseth G, 1998, SPINE, V23, P2648, DOI 10.1097/00007632-199812010-00021
   Lu WW, 1999, SPINE, V24, P1277, DOI 10.1097/00007632-199907010-00002
   MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374
   Muggleton JM, 1997, MED ENG PHYS, V19, P77, DOI 10.1016/S1350-4533(96)00050-1
   Muggleton JM, 1998, MED ENG PHYS, V20, P21, DOI 10.1016/S1350-4533(97)00045-3
   Okawa A, 1998, SPINE, V23, P1743, DOI 10.1097/00007632-199808150-00007
   PANJABI M, 1992, SPINE, V17, P200, DOI 10.1097/00007632-199202000-00014
   Papoulis A., 1965, PROBABILITY RANDOM V
   PEARCY MJ, 1985, ACTA ORTHOP SCAND, V56, P1, DOI 10.3109/17453678509154154
   Phillips Frank M, 2006, Spine J, V6, P714, DOI 10.1016/j.spinee.2006.02.003
   Rasmussen C, 1998, PROC CVPR IEEE, P16, DOI 10.1109/CVPR.1998.698582
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   SIMONIS C, 1993, TRANSPUTER APPL, V1, P35
   Teyhen DS, 2005, SPINE, V30, pE406, DOI 10.1097/01.brs.0000170589.47555.c6
   THORKELDSEN A, 1994, J MANIP PHYSIOL THER, V17, P359
   Wong KWN, 2006, SPINE, V31, P414, DOI 10.1097/01.brs.0000199955.87517.82
   Wong KWN, 2004, SPINE, V29, P1636, DOI 10.1097/01.BRS.0000132320.39297.6C
   Wong SF, 2004, LECT NOTES COMPUT SC, V3150, P154
   Zheng YL, 2004, IEEE T MED IMAGING, V23, P45, DOI 10.1109/TMI.2003.819927
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 57
TC 10
Z9 11
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1555
EP 1571
DI 10.1016/j.imavis.2009.02.010
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800013
DA 2024-07-18
ER

PT J
AU Sim, D
   Kim, Y
AF Sim, Donggyu
   Kim, Yongmin
TI Detection and compression of moving objects based on new panoramic image
   modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Panning camera; Panoramic image; JPEG-2000; Video coding; Surveillance
   and security
ID VIDEO; SURVEILLANCE
AB In this paper, a parametric video coding method based on new panoramic modeling is proposed for panning cameras. An input video frame from a panning camera is decomposed into a background image, rectangular moving object regions, and a residual image. Each area is then coded separately. In coding the background, we employ a panoramic model that can account for several image formation processes, such as perspective projection, lens distortion, vignetting and illumination effects. Moving objects are detected, and their minimum bounding rectangular regions are coded using a JPEG-2000 coder. The reconstruction error using only the estimated background and the moving objects is computed, and the residual image is separately encoded for image quality enhancement and rate control. We evaluated the effectiveness of the proposed algorithm using several indoor and outdoor sequences and found that the peak signal-to-noise ratio (PSNR) improved by 1.3 similar to 4.4 dB compared to that of JPEG-2000. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Sim, Donggyu] Kwangwoon Univ, Dept Comp Engn, Seoul 139701, South Korea.
   [Kim, Yongmin] Univ Washington, Dept Bioengn, Seattle, WA 98195 USA.
C3 Kwangwoon University; University of Washington; University of Washington
   Seattle
RP Sim, D (corresponding author), Kwangwoon Univ, Dept Comp Engn, 447-1 Wolgye Dong, Seoul 139701, South Korea.
EM dgsim@kw.ac.kr
FU Dr. Donggyu Sim was with the University of Washington
FX This work was mostly conducted when Dr. Donggyu Sim was with the
   University of Washington.
CR Adams MD, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P53, DOI 10.1109/ICIP.2000.899223
   Altunbasak Y, 2003, IEEE T IMAGE PROCESS, V12, P395, DOI 10.1109/TIP.2003.809012
   [Anonymous], 144962 ISOIEC
   [Anonymous], 2000, 154441 ISOIEC
   Asada N., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P186, DOI 10.1109/ICPR.1996.546016
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337
   BURT PJ, 1999, Patent No. 5991444
   Castagno R, 1998, IEEE T CIRC SYST VID, V8, P562, DOI 10.1109/76.718503
   CHRISTOPOULOS C, 2000, INT C IM PROC, V2, P247
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Dai F, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1355
   Ha SJ, 2008, IEEE T CONSUM ELECTR, V54, P16, DOI 10.1109/TCE.2008.4470018
   Kim BY, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P470
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pavlidis A, 2001, P IEEE, V89, P1478, DOI 10.1109/5.959342
   PELEG CS, 1997, P COMP VIS PATT REC, P338
   Qin N, 2006, IEEE INT CONF ROBOT, P3429
   Regazzoni CS, 2001, P IEEE, V89, P1355, DOI 10.1109/5.959335
   Regazzoni CS, 2001, REAL-TIME IMAGING, V7, P381, DOI 10.1006/rtim.2001.0207
   Ricquebourg Y, 2000, IEEE T PATTERN ANAL, V22, P797, DOI 10.1109/34.868682
   Rieger B., 1999, Proceedings IEEE 33rd Annual 1999 International Carnahan Conference on Security Technology (Cat. No.99CH36303), P262, DOI 10.1109/CCST.1999.797924
   Shum HY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P953, DOI 10.1109/ICCV.1998.710831
   Shyamsunder R, 2007, J MED SYST, V31, P109, DOI 10.1007/s10916-006-9036-x
   Sikora T, 1997, IEEE T CIRC SYST VID, V7, P19, DOI 10.1109/76.554415
   Sim DG, 1998, IEEE T PATTERN ANAL, V20, P353, DOI 10.1109/34.677261
   Steedly D, 2005, IEEE I CONF COMP VIS, P1300
   Stein GP, 1997, PROC CVPR IEEE, P602, DOI 10.1109/CVPR.1997.609387
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Vaswani N, 2001, INT CONF ACOUST SPEE, P1617, DOI 10.1109/ICASSP.2001.941245
   ZHANG Z, 1996, P INT C PATT REC, V1, P407
NR 31
TC 4
Z9 5
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1527
EP 1539
DI 10.1016/j.imavis.2009.02.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800011
DA 2024-07-18
ER

PT J
AU Mei, Y
   Sun, HJ
   Xia, DS
AF Mei, Yuan
   Sun, Huaijiang
   Xia, Deshen
TI A gradient-based combined method for the computation of fingerprints'
   orientation field
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Fingerprint recognition; Orientation field; Normalization;
   Consistency; Combined method
ID MODEL; POINTS
AB Estimation of fingerprint orientation fields is an essential module in automatic fingerprint recognition system. Many algorithms based on gradient have been proposed, but their results are unsatisfactory, especially for poor image. In this paper, a gradient-based combined method for the computation of fingerprints' orientation field has been proposed. In our method, we first calculate the first level orientation fields with three different size blocks; and then combine these first level orientation fields together to form the second level orientation field; finally, use the iteration based method to predict orientation. All experiments show that, compared to the prior works, our method is more robust against noise while preserving the accuracy and is capable of predicting. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Mei, Yuan; Sun, Huaijiang; Xia, Deshen] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Mei, Y (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Xiaolinwei St 200, Nanjing 210094, Jiangsu, Peoples R China.
EM chinameiyuan@hotmail.com
CR Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618
   Berry J, 2001, CRC FOR P S, P1
   Federal Bureau of Investigation, 1984, SCI FING CLASS US
   Gu JW, 2004, PATTERN RECOGN, V37, P543, DOI 10.1016/S0031-3203(03)00178-X
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265
   Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674
   Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9
   KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0
   Kulkami JV, 2006, PATTERN RECOGN, V39, P1551, DOI 10.1016/j.patcog.2006.03.007
   Li J, 2006, PATTERN RECOGN, V39, P102, DOI 10.1016/j.patcog.2005.08.010
   Nilsson K, 2003, PATTERN RECOGN LETT, V24, P2135, DOI 10.1016/S0167-8655(03)00083-7
   Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195
   RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908
   RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3
   Sherlock BG, 1993, PATTERN RECOGN, V28, P139
   Vizcaya PR, 1996, PATTERN RECOGN, V29, P1221, DOI 10.1016/0031-3203(95)00154-9
   WANG Y, 2005, P DIG IM COMP TECHN
   Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003
NR 20
TC 17
Z9 22
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1169
EP 1177
DI 10.1016/j.imavis.2008.11.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000017
DA 2024-07-18
ER

PT J
AU Bettahar, S
   Stambouli, AB
AF Bettahar, Salim
   Stambouli, Amine Boudghene
TI Shock filter coupled to curvature diffusion for image denoising and
   sharpening
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE noise; blur; diffusion; shock filter
ID EDGE-DETECTION; GENERALIZED SOLUTION; RESTORED SIGNALS; ENHANCEMENT;
   MODELS; SPACE
AB The frequent problem in low-level vision arises from the goal to eliminate noise and uninteresting details from an image, without blurring semantically important structures such as edges. Partial differential equations (PDEs) have recently dominated image processing research, as a very good tool for noise elimination, image enhancement and edge detection. In this paper, we present a biased PDE filter based on a coupling between shock filter and Curvature diffusion. This model removes noise and sharpens edges efficiently. It preserves well the location of the shocks by synchronising both effects of smoothing and deblurring. Empirical results on different kinds of images confirm these advantages. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Bettahar, Salim; Stambouli, Amine Boudghene] Univ Sci & Technol Oran, Dept Elect, Elect & Elect Engn Fac, El Mnaouar, Oran, Algeria.
C3 Universite des Sciences et de la Technologie d'Oran Mohamed Boudiaf
RP Bettahar, S (corresponding author), Univ Sci & Technol Oran, Dept Elect, Elect & Elect Engn Fac, POB 1505, El Mnaouar, Oran, Algeria.
EM salim_bettahar@yahoo.com; aboudghenes@yahoo.com
CR Abd-Elmoniem KZ, 2002, IEEE T BIO-MED ENG, V49, P997, DOI 10.1109/TBME.2002.1028423
   ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   [Anonymous], 2008, DIGITAL IMAGE PROCES
   [Anonymous], 2003, Front-End Vision and Multi-Scale Image Analysis
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Cheriet M, 2003, J MATH ANAL APPL, V279, P398, DOI 10.1016/S0022-247X(02)00714-X
   CIARLET PG, 1998, INTRO ANAL NUMERIQUE
   EUVRARD D, 1994, RESOLUTION NUMERIQUE
   FU S, 2006, LECT NOTES COMPUTER, V4153
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   GILBOA G, MATLAB CODE LINK
   Kornprobst P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P458, DOI 10.1109/ICIP.1997.638807
   Kuhne G., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P133
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   Papandreou G, 2004, PROC CVPR IEEE, P689
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Remaki L, 2003, J MATH ANAL APPL, V279, P189, DOI 10.1016/S0022-247X(02)00713-8
   Rosebfield A., 1976, DIGITAL PICTURE PROC
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sze CJ, 2001, IEEE T IMAGE PROCESS, V10, P296, DOI 10.1109/83.902294
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vese LA, 2004, J MATH IMAGING VIS, V20, P7, DOI 10.1023/B:JMIV.0000011316.54027.6a
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J, 2003, LECT NOTES COMPUT SC, V2781, P1
   Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4
   WEICKERT J., 2001, Acta Math. Univ. Comenianae, V70, P33
   Whitaker RT, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P142, DOI 10.1109/ICIP.2001.958071
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Yezzi A, 1998, IEEE T IMAGE PROCESS, V7, P345, DOI 10.1109/83.661184
NR 32
TC 24
Z9 27
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1481
EP 1489
DI 10.1016/j.imavis.2008.02.010
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000003
DA 2024-07-18
ER

PT J
AU Aizenberg, I
   Butakoff, C
AF Aizenberg, Igor
   Butakoff, Constantine
TI A windowed Gaussian notch filter for quasi-periodic noise removal
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE nonlinear filtering; spectrum filtering; Fourier transform; periodic
   noise
AB This paper presents an efficient method of quasi-periodic noise detection and filtering. Taking into account that periodic noise leaves peaks in the amplitude spectrum, the proposed approach focuses on their detection and elimination. The detection is performed semiautomatically using a local median whereupon the localized peaks are eliminated by a modified Gaussian notch filter. The proposed approach demonstrates high efficiency for images corrupted by both pure-periodic and quasi-periodic noise. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Butakoff, Constantine] Univ Pompeu Fabra, Dept Informat & Commun Technol, Computat Imaging Lab, Barcelona 08003, Spain.
   [Aizenberg, Igor] Texas A&M Univ Texarkana, Dept Comp Sci, Texarkana, TX 75505 USA.
C3 Pompeu Fabra University; Texas A&M University System; Texas A&M
   University Texarkana
RP Butakoff, C (corresponding author), Univ Pompeu Fabra, Dept Informat & Commun Technol, Computat Imaging Lab, Pg Circumval Lacio 8, Barcelona 08003, Spain.
EM igor.aizenberg@tamut.com; constantine.butakoff@upf.edu
RI Aizenberg, Igor/B-2513-2008; Butakoff, Constantine/A-1904-2009;
   Butakoff, Constantine/E-8644-2016
OI Butakoff, Constantine/0000-0002-8526-5045
CR Aizenberg I, 2002, P SOC PHOTO-OPT INS, V4667, P181, DOI 10.1117/12.467980
   Aizenberg I, 2002, SPIES INT TECHNICAL, V12, P4
   Al Hudhud GA, 2005, IEEE SIGNAL PROC LET, V12, P573, DOI 10.1109/LSP.2005.851257
   Arthur R, 1996, FUNDAMENTALS ELECT I
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Montgomery D.C., 1998, Applied Statistics and Probability for Engineers, V2nd
   Russ J.C., 2001, Forensic uses of digital imaging
   Shimada Y., 1999, Journal of the Acoustical Society of Japan (E), V20, P301, DOI 10.1250/ast.20.301
   YAROSLAVSKY LP, 1996, FUNDAMENTALS DIGITAL
NR 9
TC 42
Z9 43
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1347
EP 1353
DI 10.1016/j.imavis.2007.08.011
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700005
DA 2024-07-18
ER

PT J
AU Pan, X
   Ruan, QQ
AF Pan, Xin
   Ruan, Qiu-Qi
TI Palmprint recognition with improved two-dimensional locality preserving
   projections
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE two-dimensional locality preserving; projections (2DLPP);
   two-dimensional principle component analyses (2DPCA); palmprint
   recognition; Gabor features
ID 2DLPP; IMAGE; PCA
AB Recently, two-dimensional locality preserving projections (2DLPP) was proposed to extract features directly from image matrices based on locality preserving criterion. Though 2DLPP has been applied in many domains including face and palmprint recognition, it still has several disadvantages: the nearest-neighbor graph fails to model the intrinsic manifold structure inside the image; large dimensionality training space affects the calculation efficiency; and too many coefficients are needed for image representation. These problems inspire us to propose an improved 2DLPP (12DLPP) for recognition in this paper. The modifications of the proposed 12DLPP mainly focus on two aspects: firstly, the nearest-neighbor graph is constructed in which each node corresponds to a column inside the matrix, instead of the whole image, to better model the intrinsic manifold structure; secondly, 2DPCA is implemented in the row direction prior to 2DLPP in the column direction, to reduce the calculation complexity and the final feature dimensions. By using the proposed 12DLPP, we achieve a better recognition performance in both accuracy and speed. Furthermore, owing to the robustness of Gabor filter against variations, the improved 2DLPP based on the Gabor features (12DLPPG) can further enhance the recognition rate. Experimental results on the two palmprint databases of our lab demonstrate the effectiveness of the proposed method. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Pan, Xin; Ruan, Qiu-Qi] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Pan, Xin] Inner Mongolia Agr Univ, Coll Comp & Informat Engn, Hohhot 010018, Peoples R China.
C3 Beijing Jiaotong University; Inner Mongolia Agricultural University
RP Pan, X (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM xinpan@yahoo.com
CR Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Chen SB, 2007, NEUROCOMPUTING, V70, P912, DOI 10.1016/j.neucom.2006.10.032
   Cheung KH, 2006, INT C PATT RECOG, P445
   Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9
   Feng GY, 2006, NEUROCOMPUTING, V69, P1733, DOI 10.1016/j.neucom.2006.01.006
   GLOUB GH, 1996, MATRIX COMPUTATION
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hu DW, 2008, PATTERN RECOGN, V41, P1427, DOI 10.1016/j.patcog.2007.09.014
   Hu DW, 2007, PATTERN RECOGN, V40, P339, DOI 10.1016/j.patcog.2006.06.022
   Hu ZL, 2008, PATTERN RECOGN, V41, P1426, DOI 10.1016/j.patcog.2007.07.003
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214
   LI W, 2002, INT J PATTERN RECOGN, V16, P847
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Pan X, 2006, INT CONF SIGN PROCES, P1059
   Saviv T, 2007, PATTERN RECOGN, V40, P3152, DOI 10.1016/j.patcog.2007.03.005
   Wang LW, 2005, PATTERN RECOGN LETT, V26, P57, DOI 10.1016/j.patrec.2004.08.016
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   ZHANG D, 2004, PAIMPRINT AUTHENTICA
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
NR 24
TC 26
Z9 36
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1261
EP 1268
DI 10.1016/j.imavis.2008.03.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300008
DA 2024-07-18
ER

PT J
AU Suhadolnik, A
   Petrisic, J
   Kosel, F
AF Suhadolnik, Alojz
   Petrisic, Joze
   Kosel, Franc
TI Numerical calculation of digital curve length by using anchored discrete
   convolution
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE digital curve; curve length; anchored discrete convolution; digital
   image
AB The paper presents a new method introducing an anchored discrete convolution for calculating the length of a digital curve. The method is based on discrete convolution by using convolution masks and point anchoring in the pixel. The use of ordinary convolution distorts the curve shape and gives large errors in length calculation. The advantage of anchoring is that it limits the point shifting into the pixel during the calculation of the curve length. The method is applied to an analytical arc and various calculations are performed. In addition different methods from the literature were compared and a real sample was tested. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Suhadolnik, Alojz; Petrisic, Joze; Kosel, Franc] Univ Ljubljana, Fac Mech Engn, Ljubljana 1000, Slovenia.
C3 University of Ljubljana
RP Suhadolnik, A (corresponding author), Univ Ljubljana, Fac Mech Engn, Askerceva 6, Ljubljana 1000, Slovenia.
EM alojz.suhadolnik@guest.arnes.si
CR BRAQUELAIRE JP, 1999, GRAPH MODEL IM PROC, V1, P16
   DORST L, 1987, COMPUT VISION GRAPH, V40, P311, DOI 10.1016/S0734-189X(87)80145-7
   EBERLY D, 1991, CVGIP-GRAPH MODEL IM, V53, P538, DOI 10.1016/1049-9652(91)90004-4
   Estrozi LF, 2003, DIGIT SIGNAL PROCESS, V13, P172, DOI 10.1016/S1051-2004(02)00012-X
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   KLETTE R, 2000, MACHINE GRAPHICS VIS, V3, P673
   Klette R, 2006, DIGITAL GEOMETRY
   Lewiner T, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P250, DOI 10.1109/SIBGRA.2004.1352968
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   RITTER GX, 1990, COMPUT VISION GRAPH, V49, P297, DOI 10.1016/0734-189X(90)90106-6
   Sloboda F., 1998, Advances in Digital and Computational Geometry, P113
   Utcke S, 2003, LECT NOTES COMPUT SC, V2695, P657
   VOSSEPOEL AM, 1982, COMPUTER GRAPHICS IM, V4, P347
   WORRING M, 1993, CVGIP-IMAG UNDERSTAN, V58, P366, DOI 10.1006/ciun.1993.1048
NR 14
TC 5
Z9 6
U1 2
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 990
EP 999
DI 10.1016/j.imavis.2007.11.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800012
DA 2024-07-18
ER

PT J
AU Zhang, GJ
   Wei, XG
   Jiang, J
AF Zhang, Guangjun
   Wei, Xinguo
   Jiang, Jie
TI Full-sky autonomous star identification based on radial and cyclic
   features of star pattern
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE star sensor; star identification; star pattern; radial feature; cyclic
   feature
AB An algorithm for full-sky autonomous star identification is presented in this paper. Based on the radial and cyclic features, a star pattern is successfully generated, and a guide database is also established according to the generating process of the star pattern. Since the radial pattern is a kind of reliable rotation-invariant feature independent of other unreliable information, it is used for the initial match. And then the cyclic feature is adopted for the follow-up match. Meanwhile, some constraints are introduced to eliminate the redundant and wrong star pairings. In simulations, using the stars brighter than magnitude 6.0 Mv and a 12 x 12 deg field of view (FOV), the algorithm obtains an identification rate of 97.57% from the statistics of 10,000 random sensor orientations at a positional noise level of 1 pixel. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Zhang, Guangjun; Wei, Xinguo; Jiang, Jie] Beijing Univ Aeronaut & Astronaut, Sch Instrument Sci & Optoelect Engn, Beijing 100083, Peoples R China.
C3 Beihang University
RP Zhang, GJ (corresponding author), Beijing Univ Aeronaut & Astronaut, Sch Instrument Sci & Optoelect Engn, Beijing 100083, Peoples R China.
EM gjzhang@buaa.edu.cn
CR Accardo D, 2002, IEEE T AERO ELEC SYS, V38, P813, DOI 10.1109/TAES.2002.1039401
   ALEXANDER J, 1996, SPIE, V2803
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Eisenman AR, 1998, AEROSP CONF PROC, P111, DOI 10.1109/AERO.1998.686810
   JU G, 1999, AIAA SPAC TECHN C EX
   JUNKINS JL, 1977, J ASTRONAUT SCI, V25, P251
   KIM HY, 2002, IEEE AEROSPACE C P, V5
   KOSIK JC, 1991, J GUID CONTROL DYNAM, V14, P230, DOI 10.2514/3.20632
   LIEBE CC, 1995, IEEE AERO EL SYS MAG, V10, P10, DOI 10.1109/62.387971
   LIEBE CC, 2002, IEEE AEROSPACE C P
   MORRIS M, 1996, ACTA ASTRONAUT, V39, P763
   Padgett C, 1997, J GUID CONTROL DYNAM, V20, P259, DOI 10.2514/2.4061
   PADGETT C, 1997, IEEE AEROSPACE ELECT, V7, P202
   VANBEZOOIJEN RWH, 1989, THESIS STANFORD U CA
NR 15
TC 61
Z9 73
U1 0
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 891
EP 897
DI 10.1016/j.imavis.2007.10.006
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800003
DA 2024-07-18
ER

PT J
AU Boissenin, M
   Wedekind, J
   Selvan, AN
   Amavasai, BP
   Caparrelli, F
   Travis, JR
AF Boissenin, M.
   Wedekind, J.
   Selvan, A. N.
   Amavasai, B. P.
   Caparrelli, F.
   Travis, J. R.
TI Computer vision methods for optical microscopes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE computer vision; microscope imaging; micro-robotics; tracking; depth
   estimation
AB As the fields of micro- and nano-technology mature, there will be an increased need to build tools that are able to work in these areas. Industry will require solutions for assembling and manipulating components, much as it has done in the macro range. With this need in mind, a new set of challenges requiring novel solutions have to be met. One of them is the ability to provide closed-loop feedback control for manipulators. We foresee that machine vision will play a leading role in this area. This paper introduces a technique for integrating machine vision into the field of micro-technology including two methods, one for tracking and one for depth reconstruction under an optical microscope. (C) 2006 Elsevier B.V. All rights reserved.
C1 Sheffield Hallam Univ, Microsyst & Machine Vis Lab, Mat & Engn Res Inst, Sheffield S1 1WB, S Yorkshire, England.
C3 Sheffield Hallam University
RP Wedekind, J (corresponding author), Sheffield Hallam Univ, Microsyst & Machine Vis Lab, Mat & Engn Res Inst, Pond St, Sheffield S1 1WB, S Yorkshire, England.
EM Manuel.Boissenin@student.shu.ac.uk; J.Wedekind@shu.ac.uk;
   b.p.amavasai@shu.ac.uk
CR AMAVASAI B, 2003, IEEE C CYB INT CHALL
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   BERGANDER A, 2004, MECHATRONICS ROBOTIC
   DJURIC P, 2003, IEEE SIGNAL PROCESS
   GEORGIEV A, 2004, IEEE RSJ INT C INT R
   Haynes S. M., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P754
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Johnson A.E., 1997, CMURITR9747
   Lee SJ, 2001, MHS2001: PROCEEDINGS OF THE 2001 INTERNATIONAL SYMPOSIUM ON MICROMECHATRONICS AND HUMAN SCIENCE, P203, DOI 10.1109/MHS.2001.965246
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Watanabe M, 1998, INT J COMPUT VISION, V27, P203, DOI 10.1023/A:1007905828438
   WEDEKIND J, 2004, MECHATRONICS ROBOTIC, P754
   WEDEKIND J, 2002, THESIS U KARLSRUHE T
   YESIN KB, 2004, IEEE RSJ INT C ROB A
   IST200133567 EUR UN
   MIMAS COMPUTER VISIO
NR 16
TC 24
Z9 29
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1107
EP 1116
DI 10.1016/j.imavis.2006.03.009
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300008
DA 2024-07-18
ER

PT J
AU Li, M
   Kambhamettu, C
   Stone, M
AF Li, Min
   Kambhamettu, Chandra
   Stone, Maureen
TI Nonrigid motion recovery for 3D surfaces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE nonrigid motion; correspondence; spline; shape-based methods
ID SHAPE; REGISTRATION; PARAMETERS
AB We present a spline-based nonrigid motion and point correspondence recovery method for 3D surfaces. This method is based on differential geometry. Shape information is used to recover the point correspondences. In contrast to the majority of shape-based methods, which assume that shape (unit normal, curvature) changes are minimum after motion, our method focuses on the nonrigid relationship between before-motion and after-motion shapes. This nonrigid shape relationship is described by modeling the underlying nonrigid motion; we model it as a spline transformation, which has global control over the entire motion field along with the local deformation integrated within. This provides our method certain advantages over some pure differential geometric methods, which also utilize the nonrigid shape relationship but only work on local areas without a global control. For example, motion regularity is hard to implement in these pure differential geometric methods but is not a problem when the motion field is controlled by a spline transformation. the orthogonal parameterization requirement of the nonrigid shape relationship has to be approximated in these previous methods but is easy to meet in our method. Furthermore, the small deformation constraint introduced by the previous works is relaxed in our method.
   Experiments on both synthetic and real motions have been conducted. The quantitative and qualitative evaluations of our method are presented. The application of our method to the human tongue motion analysis is also presented in this paper. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Delaware, Dept Informat & Comp Sci, Newark, DE 19716 USA.
   Univ Maryland, Sch Dent, Vocal Tract Visualizat Lab, Baltimore, MD 21201 USA.
C3 University of Delaware; University System of Maryland; University of
   Maryland Baltimore
RP Li, M (corresponding author), Univ Delaware, Dept Informat & Comp Sci, Newark, DE 19716 USA.
EM mli@cis.udel.edu
CR AGGARWAL JK, 1994, IEEE COMP SOC WORKSH, P16
   AMINI AA, 1992, IMAGE VISION COMPUT, V10, P418, DOI 10.1016/0262-8856(92)90027-Z
   AMINI AA, 1991, MOTION91, P294
   [Anonymous], 6 IASTED INT C COMP
   ARAD N, 1995, COMPUT GRAPH FORUM, V14, P35, DOI 10.1111/1467-8659.1410035
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Carr JC, 1997, IEEE T MED IMAGING, V16, P96, DOI 10.1109/42.552059
   Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148
   DeCarlo D, 2002, IEEE T PATTERN ANAL, V24, P814, DOI 10.1109/TPAMI.2002.1008387
   DUNCAN J, 1991, COMPUTER VISION PATT, P318
   Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998
   FORNEFETT M, 1999, CVPR99, V1, P402
   KAMBHAMETTU C, 1994, CVGIP-IMAG UNDERSTAN, V60, P26, DOI 10.1006/ciun.1994.1029
   Kambhamettu C, 2003, IMAGE VISION COMPUT, V21, P229, DOI 10.1016/S0262-8856(02)00041-0
   KAMBHAMETTU C, 1994, NONRIGID MOTION ANAL, P405
   KAMBHAMETTU C, 1994, CVPR94, P943
   Laskov P, 2003, IEEE T PATTERN ANAL, V25, P1349, DOI 10.1109/TPAMI.2003.1233911
   Li M, 2005, CLIN LINGUIST PHONET, V19, P515, DOI 10.1080/02699200500113863
   Li M, 2005, CLIN LINGUIST PHONET, V19, P545, DOI 10.1080/02699200500113616
   LI M, 2004, IEEE WORKSH ART NONR
   Meier D, 2002, IEEE T MED IMAGING, V21, P31, DOI 10.1109/42.981232
   METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727
   PENTLAND AP, 1991, CVPR91, P325
   SZELISKI R, 1994, DEC
   Tagare HD, 1999, IEEE T MED IMAGING, V18, P570, DOI 10.1109/42.790457
   Tao H, 2002, INT J COMPUT VISION, V50, P111, DOI 10.1023/A:1020389714861
   Wang YM, 2000, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2000.854933
   Weatherburn C.E., 1930, Differential Geometry of Three Dimensions, V1
   Zhang WY, 2002, J INTELL MANUF, V13, P119, DOI 10.1023/A:1014584213713
   Zhou L, 2001, IEEE T PATTERN ANAL, V23, P1330, DOI 10.1109/34.969121
   Zhou L, 2000, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2000.854950
   ZHOU L, 1999, CVPR99, P280
NR 33
TC 7
Z9 10
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 250
EP 261
DI 10.1016/j.imavis.2006.01.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100002
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Goldgof, DB
   Sarkar, S
   Tsap, LV
AF Zhang, Yong
   Goldgof, Dmitry B.
   Sarkar, Sudeep
   Tsap, Leonid V.
TI A sensitivity analysis method and its application in physics-based
   nonrigid motion modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE sensitivity analysis; physical modeling; nonrigid motion; elastic
   parameters
ID DEFORMATIONS; TISSUES; SHAPE
AB Parameters used in physical models for nonrigid and articulated motion analysis are often not known with high precision. It has been recognized that commonly used assumptions about the parameters may have adverse effect on modeling quality. In this paper, we present an efficient sensitivity analysis method to assess the impact of those assumptions by examining the model's spatial response to parameter perturbation. Numerical experiments with a synthetic model and skin tissues show that: (1) normalized sensitivity distribution can help determine the relative importance of different parameters; (2) dimensional sensitivity is useful in the assessment of a particular parameter assumption; and (3) models are more sensitive at the locations of property discontinuity (heterogeneity). The formulation of the proposed sensitivity analysis method is general and can be applied to assessment of other types of assumptions, such as those related to nonlinearity and anisotropy. (c) 2006 Elsevier B.V. All rights reserved.
C1 Youngstown State Univ, Dept Comp Sci & Informat Syst, Youngstown, OH 44555 USA.
   Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.
   Lawrence Livermore Natl Lab, Adv Commun & Signal Proc Grp, Dept Elect Engn, Livermore, CA 94551 USA.
C3 University System of Ohio; Youngstown State University; State University
   System of Florida; University of South Florida; United States Department
   of Energy (DOE); Lawrence Livermore National Laboratory
RP Zhang, Y (corresponding author), Youngstown State Univ, Dept Comp Sci & Informat Syst, Youngstown, OH 44555 USA.
EM yzhang@cis.ysu.edu; goldgof@cse.usf.edu; sarkar@cse.usf.edu;
   tsap@llnl.gov
RI Goldgof, Dmitry/ABF-1366-2020; Sarkar, Sudeep/ABD-7629-2021; Sarkar,
   Sudeep/A-8213-2009
OI Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207
CR Aggarwal JK, 1998, COMPUT VIS IMAGE UND, V70, P142, DOI 10.1006/cviu.1997.0620
   Alterovitz R, 2003, IEEE INT CONF ROBOT, P1793, DOI 10.1109/ROBOT.2003.1241854
   [Anonymous], 2003, Sensitivity & Uncertainty Analysis, Volume 1: Theory
   [Anonymous], HDB PATERN RECOGNITI
   Azar FS, 2002, MED IMAGE ANAL, V6, P1, DOI 10.1016/S1361-8415(01)00053-6
   BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3
   Cotin S, 1999, IEEE T VIS COMPUT GR, V5, P62, DOI 10.1109/2945.764872
   Delingette H, 1998, P IEEE, V86, P512, DOI 10.1109/5.662876
   DEMS K, 1987, J THERM STRESSES, V10, P283, DOI 10.1080/01495738708927014
   Duck F A., 1990, PHYS PROPERTIES TISS
   Fatemi M, 2003, P IEEE, V91, P1503, DOI 10.1109/JPROC.2003.817865
   FOWLKES JB, 1992, RADIOLOGY, V185, P206
   Fung YC, 1993, BIOMECHANICS MECH PR
   Hagemann A, 1999, IEEE T MED IMAGING, V18, P875, DOI 10.1109/42.811267
   Haug E.J., 1986, Design sensitivity analysis of structural systems
   HAUNG WC, 1993, SPIE GEOMETRIC METHO, V2, P404
   KLEIBER M, 1992, DESIGN SENSITIVITY A
   KOCH R.M., 1996, P SIGGRAPH, P421
   LEE Y, 1995, REALISTIC MODELING F, P55
   Metaxas D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P337, DOI 10.1109/CVPR.1991.139712
   METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727
   Metaxas D.N., 1997, PHYS BASED DEFORMABL
   MUTHUPILLAI R, 1995, SCIENCE, V269, P1854, DOI 10.1126/science.7569924
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Sclaroff S., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P158, DOI 10.1109/MNRAO.1994.346241
   SHAH M., 1997, MOTION BASED RECOGNI
   Tanner C, 2001, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P11, DOI 10.1109/MMBIA.2001.991694
   Tsap LV, 1998, IEEE T MED IMAGING, V17, P620, DOI 10.1109/42.730406
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   YACOOB Y, 1995, INT WORKSH AUT FAC G, P278
   YACOOB Y, 2002, INT C FAC REC GEST A, P52
   Zhang Y, 2004, INT C PATT RECOG, P19
   Zhang Y, 2002, INT C PATT RECOG, P10, DOI 10.1109/ICPR.2002.1048224
   ZHANG Y, 2003, 2 INT WORKSH BIOM IM, P358
   Zhou L, 2001, IEEE T PATTERN ANAL, V23, P1330, DOI 10.1109/34.969121
   Zienkiewicz O.C., 1977, The Finite Element Method, V3
NR 37
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 262
EP 273
DI 10.1016/j.imavis.2005.08.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100003
DA 2024-07-18
ER

PT J
AU Senior, A
   Hampapur, A
   Tian, YL
   Brown, L
   Pankanti, S
   Bolle, R
AF Senior, Andrew
   Hampapur, Arun
   Tian, Ying-Li
   Brown, Lisa
   Pankanti, Sharath
   Bolle, Ruud
TI Appearance models for occlusion handling
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Performance Evaluation of Tracking and Surveillance (PETS)
CY DEC09, 2001
CL Kauai, HI
SP IEEE
DE probabilistic color appearance models; visual vehicle and people
   tracking; occlusion resolution; moving object segmentation; surveillance
AB Objects in the world exhibit complex interactions. When captured in a video sequence, sortie interactions manifest themselves as occlusions. A visual tracking system must be able to track objects, which are partially or even fully occluded. In this paper we present a method of tracking objects through occlusions using appearance models. These models are used to localize objects during partial occlusions, detect complete occlusions and resolve depth ordering of objects during occlusions. This paper presents a tracking system which successfully deals with complex real world interactions, as demonstrated on the PETS 2001 dataset. (c) 2005 Elsevier B.V. All rights reserved.
C1 IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
C3 International Business Machines (IBM)
RP Senior, A (corresponding author), IBM Corp, Thomas J Watson Res Ctr, POB 704, Yorktown Hts, NY 10598 USA.
EM aws@us.ibm.com; arunh@us.ibm.com; yltian@us.ibm.com; lisabr@us.ibm.com;
   sharat@us.ibm.com; bolle@us.ibm.com
OI Tian, Yingli/0000-0003-4458-360X
CR Bobick A. F., 1999, TELEOPERATORS VIRTUA, V8, P367
   Chang T., 2000, P 11 BRIT MACH VIS C
   Dockstader SL, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P95, DOI 10.1109/MOT.2001.937987
   Elgammal AM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P145, DOI 10.1109/ICCV.2001.937617
   ELLIS T, 2001, INT WORKSH PERF EV T
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Haritaoglu I., 2001, DETECTION TRACKING S
   HORPRASERT T, 1999, ICCV 99 FRAM RAT WOR
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   KHAN S, 2000, AS C COMP
   Lipton A.J., 1998, P 4 IEEE WORKSH APPL
   MCKENNA SJ, 2000, IEEE INT C AUT FAC G, P348
   Pingali SG, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P33
   Rosales R, 1998, IEEE CVPR WORKSH INT
   Senior A., 2002, 3 INT WORKSH PERF EV
   Tao H., 2000, P INT C PATT REC
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   ZHAO T, 2001, C COMP VIS PATT
NR 20
TC 114
Z9 140
U1 1
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2006
VL 24
IS 11
BP 1233
EP 1243
DI 10.1016/j.imavis.2005.06.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 101CJ
UT WOS:000241716200008
DA 2024-07-18
ER

PT J
AU Xu, M
   Ellis, T
AF Xu, Ming
   Ellis, Tim
TI Augmented tracking with incomplete observation and probabilistic
   reasoning
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Performance Evaluation of Tracking and Surveillance (PETS)
CY DEC09, 2001
CL Kauai, HI
SP IEEE
DE motion and tracking; Kalman filtering; occlusion; partial observation;
   BAYESIAN network
AB An on-line algorithm for multi-object tracking is presented for monitoring a real-world scene from a single fixed camera. Potential objects are detected with adaptive backgrounds modelled by intensity-plus-chromaticity mixtures of Gaussians to cope with illumination variation. The region-based representations of each object are tracked and predicted using a Kalman filter. A scene model is created to help interpret the occluded or exiting objects. The uncertainty in the domain knowledge is encoded in a Bayesian network for reasoning about object status. Unlike traditional blind tracking during occlusion, the object states are estimated using partial observations whenever available. The observability of each object depends on the predicted measurement of the object, the foreground region measurement, and the scene model. This makes the algorithm more robust in terms of both qualitative and quantitative criteria. (c) 2005 Elsevier B.V. All rights reserved.
C1 Kingston Univ, Digital Imaging Res Ctr, Kingston upon Thames KT1 2EE, Surrey, England.
C3 Kingston University
RP Ellis, T (corresponding author), Kingston Univ, Digital Imaging Res Ctr, Kingston upon Thames KT1 2EE, Surrey, England.
EM t.ellis@kingston.ac.uk
CR [Anonymous], 2003, JOINT IEEE INT WORKS
   [Anonymous], P IEEE WORKSH EV MIN
   BUXTON H, 1995, ARTIF INTELL, V78, P431, DOI 10.1016/0004-3702(95)00041-0
   Dockstader SL, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P88, DOI 10.1109/HUMO.2000.897376
   ELLIS T, 2001, P PERF EV TRACK SURV
   GERSHON R, 1986, J OPT SOC AM A, V3, P1700, DOI 10.1364/JOSAA.3.001700
   Heckerman D., 1995, MSRTR9506 MICR RES
   HUANG T, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P966
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   Ivanov Y, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P82, DOI 10.1109/VS.1999.780272
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Makris D, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P183, DOI 10.1109/AVSS.2003.1217920
   MAMMEN JP, 2001, P BRIT MACH VIS C MA, P83
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Pearl J., 1988, PROBABILISTIC REASON
   Raja Y., 1998, P ASIAN C COMPUTER V, P607
   Remagnino P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P857, DOI 10.1109/ICCV.1998.710817
   Rosales R., 1998, IEEE CVPR WORKSHOP I, P117
   SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872
   SHERRAH J, 2002, P ECCV 2000, P150
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   XU M, 2001, P BRIT MACH VIS C, P163
   XU M, 2002, P BRIT MACH VIS C, P163
NR 24
TC 9
Z9 12
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2006
VL 24
IS 11
BP 1202
EP 1217
DI 10.1016/j.imavis.2005.06.004
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 101CJ
UT WOS:000241716200006
DA 2024-07-18
ER

PT J
AU Liu, Y
   Liang, DW
   Huang, QM
   Gao, W
AF Liu, Yang
   Liang, Dawei
   Huang, Qingming
   Gao, Wen
TI Extracting 3D information from broadcast soccer video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D estimation; ball detection; tracking; soccer video; broadcast
ID SELF-CALIBRATION
AB In this paper, we propose a new method to estimate players' and ball's positions from monocular broadcast soccer video. With the relationship between objects and the camera in perspective projection, we derive the formula for estimating the moving objects' positions in real world, even when the ball is in the air. This method calibrates the camera's position in the stadium through the homography between the image and the playfield, and the self-calibration for rotating and zooming camera. Thus, the method can estimate the ball's position in the air without referring to other reference object with known height. In order to reduce manual interference, the players are detected based on the playfield detection. For the ball, we combine the detection procedure and tracking procedure organically. First, we extract candidate regions in each frame, then search the most likely regions in consecutive frames using Viterbi decoding algorithm. Once detected, the ball will be tracked by Kalman filter, which can help improve the detection recall. The system checks whether the ball is lost automatically. If it is lost, the detection procedure restarts. Experiments on synthesized data verify the proposed method, and promising results are obtained on real video data. (c) 2006 Elsevier B.V. All rights reserved.
C1 Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   Chinese Acad Sci, Grad Sch, Beijing 100039, Peoples R China.
C3 Harbin Institute of Technology; Chinese Academy of Sciences; University
   of Chinese Academy of Sciences, CAS
RP Liu, Y (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92,W Da Zhi St, Harbin 150001, Peoples R China.
EM yliu@jdl.ac.cn
RI Huang, Qingming/GLR-3473-2022; de Barros, Ricardo Machado
   Leite/AAF-4555-2020
OI Huang, Qingming/0000-0002-3025-7099; de Barros, Ricardo Machado
   Leite/0000-0002-9554-1381
CR Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694
   Ancona N, 2003, IMAGE VISION COMPUT, V21, P675, DOI 10.1016/S0262-8856(03)00063-5
   [Anonymous], P ACM MM
   [Anonymous], 1994, P IEEE C COMP VIS PA
   [Anonymous], 2005, P INT C IMAGE PROCES
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   BEBIE T, 1998, P IEEE INT C IM PROC
   BEBIE T, 2000, VIDEO BASED 3D RECON
   CHOI S, 1997, P INT C IM AN PROC
   D'Orazio T, 2004, PATTERN RECOGN, V37, P393, DOI 10.1016/S0031-3203(03)00228-0
   Farin D., 2004, SPIE STORAGE RETRIEV
   FIFA, LAWS GAM
   Hartley R., MULTIPLE VIEW GEOMET
   IWASE S, 2003, P VIS COMM IM PROC
   IWASE S, 2004, P INT C PATT REC
   Kim H, 2001, PATTERN ANAL APPL, V4, P9, DOI 10.1007/s100440170020
   Kim T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P721, DOI 10.1109/ICCV.1998.710797
   Matsui K, 1998, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.1998.698705
   Ohno Y, 2000, INT C PATT RECOG, P145, DOI 10.1109/ICPR.2000.905293
   PEURA M, 1997, ASPECTS VISUAL FORM, P443
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   REID I, 1998, P BMVC, P863
   REN J, 2004, P IEEE INT C IM PROC
   SAITO H, 2004, P IEEE INT C MULT EX
   SEO Y, 1998, P IAPR WORKSH MACH V, P274
   WELCH G, 1995, TR95041 UNC CHAP HIL
   XU M, 2004, P IEEE INT C IM PROC
   Yamada A, 2002, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2002.1044697
   YE Q, 2003, P INT C AC SPEECH SI, V3, P345
   YU X, 2004, P ACM MULT NEW YORK
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Zhang Zhengyou., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, V1, P0, DOI DOI 10.1109/ICCV.1999.791289
NR 32
TC 34
Z9 41
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1146
EP 1162
DI 10.1016/j.imavis.2006.04.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300010
DA 2024-07-18
ER

PT J
AU van Ouwerkerk, JD
AF van Ouwerkerk, J. D.
TI Image super-resolution survey
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE super-resolution; single frame
ID INTERPOLATION
AB The shortcomings in commonly used kernel-based super-resolution drive the study of improved super-resolution algorithms of higher quality. In the past years a wide range of very different approaches has been taken to improve super-resolution.
   This paper compares approaches to high quality super-resolution by looking at theoretical backgrounds and practical results. Strengths and weaknesses are listed with the intent to spot chances for combination or improvement of techniques, thereby forming a base for future improved super-resolution algorithms. (c) 2006 Elsevier B.V. All rights reserved.
C1 Delft Univ Technol, Dept Media & Knowledge Engn, NL-2628 CL Delft, Netherlands.
C3 Delft University of Technology
RP van Ouwerkerk, JD (corresponding author), Delft Univ Technol, Dept Media & Knowledge Engn, Mekelweg 4, NL-2628 CL Delft, Netherlands.
EM jos@jvojava.com
CR [Anonymous], P 34 ANN C INF SCI S
   [Anonymous], 2003, NEURAL NETWORK IMAGE
   Atkins C.B., 1999, P C IMAGE PROCESSING, P405
   Atkins CB, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P864, DOI 10.1109/ICIP.2001.958257
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Battiato S, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P572, DOI 10.1109/ICIAP.2003.1234111
   Battiato S, 2002, IMAGE VISION COMPUT, V20, P805, DOI 10.1016/S0262-8856(02)00089-6
   BATTIATO S, 2003, P SPIE EL IM 2003
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Candocia FM, 1999, IEEE T NEURAL NETWOR, V10, P372, DOI 10.1109/72.750566
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dodgson NA, 1997, IEEE T IMAGE PROCESS, V6, P1322, DOI 10.1109/83.623195
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   KINEBUCHI K, 2001, IEEE ICASSP
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Muresan DD, 2004, IEEE T IMAGE PROCESS, V13, P690, DOI 10.1109/TIP.2004.826097
   Muresan DD, 2001, INT CONF ACOUST SPEE, P1949, DOI 10.1109/ICASSP.2001.941328
   MURESAN DD, 2000, P IEEE ICIP
   MURESAN DD, 2000, P IEEE ICIP SEPT
   MURESAN DD, 2001, IEEE 2001 W NEW YORK
   SU D, 2004, COMPUTER GRAPHICS FO, V23
   Tappen M.F., 2003, EXPLOITING SPARSE DE
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   XU X, 2001, INT J INFORMATION TE, V7
   Yu XH, 2001, IEEE COMPUT GRAPH, V21, P62, DOI 10.1109/38.920628
NR 27
TC 221
Z9 240
U1 4
U2 61
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1039
EP 1052
DI 10.1016/j.imavis.2006.02.026
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300001
DA 2024-07-18
ER

PT J
AU Gautama, S
   Goeman, W
   D'Haeyer, J
   Philips, W
AF Gautama, S.
   Goeman, W.
   D'Haeyer, J.
   Philips, W.
TI Characterizing the performance of automatic road detection using error
   propagation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE road detection; performance characterization; error propagation
ID EXTRACTION
AB A methodology is introduced to predict the performance of automatic road detection using image examples of typical road types. In contrast to previous work on road detection, the focus is on characterizing the detection performance to achieve reliable performance measures of the detection. It is studied how noise, like road markings, shadows, trees and buildings, influences the detection of road. This noise is modeled using second-order statistics and its effects are calculated using error propagation on the detection equations. The method predicts the performance in terms of detection rate and gives the optimal parameter set that is needed for this detection. Experiments have been conducted on a set of images of typical roads in very high-resolution satellite images. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Ghent, Dept Telecommun & Informat Proc, TELIN, B-9000 Ghent, Belgium.
C3 Ghent University
RP Gautama, S (corresponding author), Univ Ghent, Dept Telecommun & Informat Proc, TELIN, St Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM sidharta.gautama@ugent.be
RI Gautama, Sidharta/CAF-3303-2022; Gautama, Sidharta/O-6679-2017; Gautama,
   Sidharta/CAH-9344-2022; Goeman, Werner/E-3715-2012
OI Gautama, Sidharta/0000-0001-5628-6974; Gautama,
   Sidharta/0000-0001-5628-6974; 
CR [Anonymous], 1998, P EMPIRICAL EVAL TEC
   Baumgartner A, 1999, PHOTOGRAMM ENG REM S, V65, P777
   Borra S, 1997, IEEE T PATTERN ANAL, V19, P1306, DOI 10.1109/34.632991
   Bowyer  Kevin, 1998, EMPIRICAL EVALUATION
   Chalmond B, 2001, IEEE T IMAGE PROCESS, V10, P1039, DOI 10.1109/83.931098
   Cho K, 1997, IEEE T PATTERN ANAL, V19, P1185, DOI 10.1109/34.632979
   Christensen HI, 1997, MACH VISION APPL, V9, P215, DOI 10.1007/s001380050042
   Courtney P., 2001, IMAGING VISION SYSTE
   D'Agostino R., 1986, GOODNESS FIT TECHNIQ
   Danielsson PE, 2001, J VIS COMMUN IMAGE R, V12, P255, DOI 10.1006/jvci.2000.0472
   Dorst L, 2005, IEEE T PATTERN ANAL, V27, P221, DOI 10.1109/TPAMI.2005.29
   GAUTAMA S, 2004, FLEXIBLE QUERYING RE, P351
   Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006
   Haralick RM, 1996, INT J PATTERN RECOGN, V10, P561, DOI 10.1142/S0218001496000347
   HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Mena JB, 2003, PATTERN RECOGN LETT, V24, P3037, DOI 10.1016/S0167-8655(03)00164-8
   RAMESH V, 1993, DARPA IM UND WORKSH, P1071
   Rockett PI, 2003, IEEE T IMAGE PROCESS, V12, P1668, DOI 10.1109/TIP.2003.818041
   Seber G A., 2009, Multivariate observations, DOI DOI 10.1002/9780470316641
   Steger C, 1998, IEEE T PATTERN ANAL, V20, P113, DOI 10.1109/34.659930
NR 22
TC 4
Z9 4
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 1001
EP 1009
DI 10.1016/j.imavis.2006.02.018
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200009
DA 2024-07-18
ER

PT J
AU Hang, XY
   Greenberg, NL
   Thomas, JD
AF Hang, Xiyi
   Greenberg, Neil L.
   Thomas, James D.
TI Compression of pre-scan-converted echocardiographic video using wavelet
   packet and integer wavelet transforms
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE wavelet packet transform; integer wavelet transform; SPIHT;
   echocardiography; compression
AB An efficient compression strategy is indispensable for digital echocardiography, which is very important for clinical practice of cardiology. In this study, we investigated a new compression strategy applied to pre-scan-converted polar format echocardiographic video instead of scanconverted raster format video. A lossy compression strategy, using modified SPIHT based on wavelet packet transform, is used to compress tissue data; while a lossless compression strategy based On integer wavelet transform, is used to compress Doppler data. The proposed algorithm can achieve very high compression ratio while retaining excellent image quality. Furthermore, the modified SPIHT surpasses the original SPIHT for the compression of tissue data. (c) 2006 Elsevier B.V. All rights reserved.
C1 Calif State Univ Northridge, Dept Elect & Comp Engn, Northridge, CA 91330 USA.
   Cleveland Clin Fdn, Dept Cardiovasc Med, Cleveland, OH 44195 USA.
C3 California State University System; California State University
   Northridge; Cleveland Clinic Foundation
RP Hang, XY (corresponding author), Calif State Univ Northridge, Dept Elect & Comp Engn, 18111 Nordhoff St, Northridge, CA 91330 USA.
EM xhang@csun.edu; greenbn@ccf.org
CR Andrew RK, 1999, P SOC PHOTO-OPT INS, V3658, P396, DOI 10.1117/12.349451
   Brislawn CM, 1995, IEEE T SIGNAL PROCES, V43, P3046, DOI 10.1109/78.476454
   Cabral JE, 1998, P SOC PHOTO-OPT INS, V3335, P378, DOI 10.1117/12.312514
   CABRAL JE, 2000, SPIE, V3976, P350
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   DAUBECHIES I, 1996, FACTORING WAVELET TR
   EDWARDS CD, 1999, TMO PROGR REPORT, V42, P1
   Garcia MJ, 2001, J AM SOC ECHOCARDIOG, V14, P114, DOI 10.1067/mje.2001.110270
   GREENBERG NL, 2000, DIGITAL ECHOCARDIOGR, P279
   HEER VK, 1990, SPIE MED IMAGING 4, V1233, P354
   Karson T H, 1996, J Am Soc Echocardiogr, V9, P769, DOI 10.1016/S0894-7317(96)90467-8
   Karson T H, 1995, J Am Soc Echocardiogr, V8, P306, DOI 10.1016/S0894-7317(05)80041-0
   Main ML, 2000, J AM SOC ECHOCARDIOG, V13, P764, DOI 10.1067/mje.2000.106075
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Said A, 1996, IEEE T IMAGE PROCESS, V5, P1303, DOI 10.1109/83.535842
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Thomas J D, 1996, J Am Soc Echocardiogr, V9, P606, DOI 10.1016/S0894-7317(96)90055-3
   Thomas J D, 1994, J Am Soc Echocardiogr, V7, P100
   Weyman A.E., 1994, Principles and Practice of Echocardiography
NR 24
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 915
EP 925
DI 10.1016/j.imavis.2006.02.022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200001
DA 2024-07-18
ER

PT J
AU Hall, D
AF Hall, Daniela
TI Automatic parameter regulation of perceptual systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE system architecture; tracking; autonomic computing; learning
ID VISION
AB Changes in environmental conditions frequently degrade the performance of perceptual systems. This article proposes a system architecture with a control component that auto-regulates parameters to provide a reduction in the sensitivity to environmental changes. We demonstrate the benefit of this architecture using the example of a long-term tracking system.
   The control component consists of modules for auto-critical evaluation, for auto-regulation of parameters and for error recovery. Both modules require a measure of the goodness of system output with respect to a scene reference model. We describe the generation of the scene reference model and propose measures for the model quality and for the goodness of system output in form of measurement trajectories. Our self-adaptive tracking system achieves better recall than a manually tuned tracking system on a public benchmark data set. (c) 2006 Elsevier B.V. All rights reserved.
C1 INRIA Rhone Alpes, Prima Grp, F-38330 Montbonnot St Martin, France.
RP Hall, D (corresponding author), INRIA Rhone Alpes, Prima Grp, 655,Ave Europe, F-38330 Montbonnot St Martin, France.
EM daniela.hall@free.fr
CR Bishop C. M., 1995, NEURAL NETWORKS PATT
   CAPOROSSI A, 2004, INT WORKSH PERF EV T, P23
   Chang C.-C., LIBSVMA LIB SUPPORT
   CSURKA G, 2004, EUR C COMP VIS PRAG
   FISHER R, 2004, INT WORKSH PERF EV T
   GEORIS B, 2003, INT C VIS IM IM P
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   HALL D, 2005, INT WORKSH COMP ARCH, P39
   Kephart JO, 2003, COMPUTER, V36, P41, DOI 10.1109/MC.2003.1160055
   LEUNG T, 1999, INT C COMP VIS CORF
   List T, 2004, INT C PATT RECOG, P789, DOI 10.1109/ICPR.2004.1334335
   Makris D, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P183, DOI 10.1109/AVSS.2003.1217920
   Min J, 2004, IEEE T SYST MAN CY B, V34, P263, DOI 10.1109/TSMCB.2003.811118
   Murino V, 1996, IEEE T SYST MAN CY B, V26, P1, DOI 10.1109/3477.484434
   PIATER JH, 2001, INT WORKSH PERF EV T
   Robertson P, 1999, IEEE INTELL SYST APP, V14, P30, DOI 10.1109/5254.769882
   Schmid C, 2001, PROC CVPR IEEE, P39
   Shekhar C, 1999, IMAGE VISION COMPUT, V17, P667, DOI 10.1016/S0262-8856(98)00137-1
   SRINIVAS M, 1994, COMPUTER, V27, P17, DOI 10.1109/2.294849
NR 19
TC 11
Z9 14
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 870
EP 881
DI 10.1016/j.imavis.2006.02.011
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100008
DA 2024-07-18
ER

PT J
AU Zhong, ZG
   Yi, JQ
   Zhao, DB
   Hong, YP
AF Zhong, ZG
   Yi, JQ
   Zhao, DB
   Hong, YP
TI Effective pose estimation from point pairs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE depth estimations; motion estimation; extrinsic calibration; motion
   vision
ID 3-D MOTION ESTIMATION; OPTICAL-FLOW; PARAMETERS; ALGORITHM; STEREO;
   ROBUST; SCENE; DEPTH
AB This paper presents a new technique for depth and motion estimation from image sequence, aiming at the model-based pose estimation problem. The key of the proposed technique is a novel depth estimation approach. It can compute directly the depths of model points in consecutive camera coordinate systems according to geometric relationships between a camera and model point pairs instead of individual model point. Based on the proposed depth estimation method, two strategies are discussed to tackle three different cases of camera motion. Both strategies first compute depths, independent of motion parameters, from two images. The difference between them is two or three images are required to estimate efficiently the camera motion. If the camera only translates, two images are needed to compute directly the translation. The strategy requiring three images is mainly for the case that the camera translates with large rotation, which is difficult to be recovered accurately from two images. However, if the camera translates with small rotation, then the two strategies are applicable. The main contributions of this paper are the proposed point pairs based depth estimation method and three images based strategy to recover large rotational motion. The presented technique is simple and appealing. Extensive experiments are performed on synthetic data and real images to demonstrate its efficiency and robustness. (c) 2005 Elsevier B.V. All rights reserved.
C1 Chinese Acad Sci, Lab Complex Syst & Intelligence Sci, Inst Automat, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Chinese Acad Sci, Lab Complex Syst & Intelligence Sci, Inst Automat, Beijing 100080, Peoples R China.
EM zhiguang.zhong@mail.ia.ac.cn; jianqiang.yi@maii.ia.ac.cn;
   dongbin.zhao@mail.ia.ac.cn; yiping.hong@mail.ia.ac.cn
RI Yi, Jianqiang/AAD-4898-2020; Yi, Jian/IUO-2019-2023
CR ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678
   ALOIMONOS Y, 1994, INTJ COMPUTER VISION, V1, P33
   AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503
   BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557
   DAVID V, 1990, IEEE T ROBOTIC AUTOM, V6, P509
   DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852
   FISCHLER AM, 1981, COMMUN ACM, V24, P381
   HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281
   Hung YS, 1999, IEEE T PATTERN ANAL, V21, P570, DOI 10.1109/34.771330
   LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   Ma Y, 2001, INT J COMPUT VISION, V44, P219, DOI 10.1023/A:1012276232049
   NEGAHDARIPOUR S, 1995, IEEE T ROBOTIC AUTOM, V11, P829, DOI 10.1109/70.478430
   NEWMAN PM, 1999, THESIS U SYNDEY
   NUNO G, 2002, IEEE INT C INT ROB S, V1, P7
   Oberkampf D, 1996, COMPUT VIS IMAGE UND, V63, P495, DOI 10.1006/cviu.1996.0037
   Or SH, 1998, IMAGE VISION COMPUT, V16, P353, DOI 10.1016/S0262-8856(97)00073-5
   Park SK, 2001, PATTERN RECOGN, V34, P1713, DOI 10.1016/S0031-3203(00)00104-7
   Tagawa N, 2001, IEICE T INF SYST, VE84D, P485
   TOSHIHARU M, 1997, IEEE INT C INT ROB S, V2, P740
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Wang FY, 2004, IEEE T ROBOTIC AUTOM, V20, P121, DOI 10.1109/TRA.2003.820919
   WANG J, 1992, IEEE T ROBOT AUTOMAT, V8, P362
NR 25
TC 5
Z9 10
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2005
VL 23
IS 7
BP 651
EP 660
DI 10.1016/j.imavis.2005.03.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 940LX
UT WOS:000230147100004
DA 2024-07-18
ER

PT J
AU Connie, T
   Jin, ATB
   Ong, MGK
   Ling, DNC
AF Connie, T
   Jin, ATB
   Ong, MGK
   Ling, DNC
TI An automated palmprint recognition system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE biometric; palmprint recognition; palmprint pre-processing; subspace
   projection methods; similarity matching
ID FEATURE-EXTRACTION; EIGENFACES; ALGORITHMS
AB Recently, biometric palmprint has received wide attention from researchers. It is well-known for several advantages such as stable line features, low-resolution imaging, low-cost capturing device, and user-friendly. In this paper, an automated scanner-based palmprint recognition system is proposed. The system automatically captures and aligns the palmprint images for further processing. Several linear subspace projection techniques have been tested and compared. In specific, we focus on principal component analysis (PCA), fisher discriminant analysis (FDA) and independent component analysis (ICA). In order to analyze the palmprint images in multi-resolution-multi-frequency representation, wavelet transformation is also adopted. The images are decomposed into different frequency subbands and the best performing subband is selected for further processing. Experimental result shows that application of FDA on wavelet subband is able to yield both FAR and FRR as low as 1.356 and 1.492% using our palmprint database. (c) 2005 Elsevier B.V. All rights reserved.
C1 Multimedia Univ, Fac Informat Sci & Technol, Melaka 75450, Malaysia.
C3 Multimedia University
RP Multimedia Univ, Fac Informat Sci & Technol, Melaka 75450, Malaysia.
EM tee.connie@mmu.edu.my
RI Tee, Connie/F-8478-2012; Ngo, David C. L./E-3307-2012; Teoh, Andrew Beng
   Jin/F-4422-2010; Goh, Kah Ong Michael/F-8404-2012
OI Tee, Connie/0000-0002-0901-3831; Teoh, Andrew Beng
   Jin/0000-0001-5063-9484; Goh, Kah Ong Michael/0000-0002-9217-6390
CR [Anonymous], IMAGE PROCESSING ANA
   Baek K, 2002, PROCEEDINGS OF THE 6TH JOINT CONFERENCE ON INFORMATION SCIENCES, P824
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Chen J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P234, DOI 10.1109/ICIP.2001.958094
   CORNON P, 2002, SIGNAL PROCESS, V36, P287
   Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9
   FENG GC, 2000, SPIE J ELECT IMAGINI, V9
   Funada J, 1998, INT C PATT RECOG, P1849, DOI 10.1109/ICPR.1998.712091
   GOH KO, 2003, 3 INT S COMM INF TEC, P720
   HAN CC, 2003, PATTERN RECOGN, V36, P281
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757
   LU G, 2003, PATTERN RECOGN, V24, P1473
   MASTER T, 1993, PRACTICAL NEURAL NET, pCH12
   MASTERS T, 1993, ADV METHODS NEURAL C, P35
   SHI W, 2001, INT J IMAGE GRAPHICS, V1, P135
   Specht D.F., 1988, IEEE International Conference on Neural Networks, V1, P525, DOI DOI 10.1109/ICNN.1988.23820
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Ten Daubechies I., 1992, lecture on wavelets
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang XC, 2003, PATTERN RECOGN, V36, P2429, DOI 10.1016/S0031-3203(03)00044-X
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Wu XQ, 2002, INT C PATT RECOG, P95, DOI 10.1109/ICPR.2002.1044621
   You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
NR 29
TC 170
Z9 186
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2005
VL 23
IS 5
BP 501
EP 515
DI 10.1016/j.imavis.2005.01.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 917XA
UT WOS:000228501300005
DA 2024-07-18
ER

PT J
AU Guerra, C
   Pascucci, V
AF Guerra, C
   Pascucci, V
TI Line-based object recognition using Hausdorff distance: from range
   images to molecular secondary structures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D object recognition; range images; Hausdorff distance; geometric
   pattern matching; molecular recognition
ID PROTEINS; SEGMENTS; MOTION
AB Object recognition algorithms are fundamental tools in automatic matching of geometric shapes within a background scene. Many approaches have been proposed in the past to solve the object recognition problem. Two of the key aspects that distinguish them in terms of their practical usability are: (i) the type of input model description and (ii) the comparison criteria used. In this paper we introduce a novel scheme for 3D object recognition based on line segment representation of the input shapes and comparison using the Hausdorff distance. This choice of model representation provides the flexibility to apply the scheme in different application areas. We define several variants of the Hausdorff distance to compare the models within the framework of well-defined metric spaces. We present a matching algorithm that efficiently finds a pattern in a 3D scene. The algorithm approximates a minimization procedure of the Hausdorff distance. The output error due to the approximation is guaranteed to be within a known constant bound. Practical results are presented for two classes of objects: (i) polyhedral shapes extracted from segmented range images and (ii) secondary structures of large molecules. In both cases the use of our approximate algorithm allows to match correctly the pattern in the background while achieving the efficiency necessary for practical use of the scheme. In particular the performance is improved substantially with minor degradation of the quality of the matching. (C) 2004 Elsevier B.V All rights reserved.
C1 Univ Padua, Dept Informat Engn, Padua, Italy.
   Lawrence Livermore Natl Lab, CASC, Livermore, CA USA.
C3 University of Padua; United States Department of Energy (DOE); Lawrence
   Livermore National Laboratory
RP Guerra, C (corresponding author), Univ Padua, Dept Informat Engn, Via Gradenigo 6-A, Padua, Italy.
EM guerra@dei.unipd.it
CR Abola EE, 1997, METHOD ENZYMOL, V277, P556, DOI 10.1016/S0076-6879(97)77031-9
   ALTER TD, 1993, ICCV 93, P113
   ARMAN F, 1993, ACM COMPUT SURV, V25, P6
   ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573
   BOCK ME, 1999, P 2 INT C 3D DIG IM, P261
   Bourne P.E., 2003, Structural Bioinformatics
   BOYTER B, 1986, IEEE EXPERT, V10, P47
   BRANDEN C, 1999, INTR PROTEIN STRUCTU
   CHEN HH, 1990, IEEE T PATTERN ANAL, V12, P1002, DOI 10.1109/34.58872
   Chew LP, 1997, COMP GEOM-THEOR APPL, V7, P113, DOI 10.1016/0925-7721(95)00047-X
   CHEW PL, 1995, ALGORITHMS ESA 95, V979, P264
   Comin M, 2004, J COMPUT BIOL, V11, P1061, DOI 10.1089/cmb.2004.11.1061
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   FERRARI C, 2003, PROTEIN STRUCTURE AN, P57
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   GERSTEIN M, 1992, ACTA CRYSTALLOGR A, V48, P271, DOI 10.1107/S0108767391012680
   Glover F., 1997, Tabu Search. Kluwer
   Goodrich MT, 1999, IEEE T PATTERN ANAL, V21, P371, DOI 10.1109/34.761267
   GRINDLEY HM, 1993, J MOL BIOL, V229, P707, DOI 10.1006/jmbi.1993.1074
   Guerra C, 2001, IEICE T INF SYST, VE84D, P1739
   Hagedoorn M, 1999, INT J COMPUT VISION, V31, P203, DOI 10.1023/A:1008022116857
   HOOVER A, 1996, IEEE T PAMI      JUL, P1
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jiang XY, 1999, COMPUT VIS IMAGE UND, V73, P183, DOI 10.1006/cviu.1998.0715
   KANMGARPARSI B, 1997, IEEE T PATTERN ANAL, V19, P1090
   Lemmen C, 2000, J COMPUT AID MOL DES, V14, P215, DOI 10.1023/A:1008194019144
   LESK A, 1994, COMPUTATIONAL MOL BI, V31
   MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2
   PRINCEN J, 1990, COMPUT VISION GRAPH, V52, P57, DOI 10.1016/0734-189X(90)90123-D
   RICHARDSON JS, 1977, NATURE, V268, P495, DOI 10.1038/268495a0
   Rucklidge WJ, 1997, INT J COMPUT VISION, V24, P251, DOI 10.1023/A:1007975324482
   THOMPSON AC, 1996, ENCY MATH APPL CAMBR, V63
   Yi XL, 1999, IEEE T PATTERN ANAL, V21, P901, DOI 10.1109/34.790430
NR 34
TC 15
Z9 16
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2005
VL 23
IS 4
BP 405
EP 415
DI 10.1016/j.imavis.2004.11.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NR
UT WOS:000227222100004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, ZZ
   Qi, FH
AF Wang, ZZ
   Qi, FH
TI Analysis of multiframe super-resolution reconstruction for image
   anti-aliasing and deblurring
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE super-resolution; ill-posedness; perturbation; discrete picard
   condition; regularization; anti-aliasing; deblurring
ID HIGH-RESOLUTION IMAGE; LIMITS; NOISY; MAP
AB Novel theoretical results for the super-resolution reconstruction (SRR) are presented under the case of arbitrary image warping. The SRR model is reasonably separated into two parts of anti-aliasing and deblurring. The anti-aliasing part is proved to be well-posed. The ill-posedness of the entire SRR process is shown to be mainly caused by the deblurring part. The motion estimation error results in a multiplicative perturbation to the warping matrix, and the perturbation bound is derived. The common regularization algorithms used in SRR are analyzed through the discrete Picard condition, which provides a theoretical measure for limits on SRR. Experiments and examples are supplied to validate the presented theories. (C) 2004 Elsevier B.V. All rights reserved.
C1 Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University
RP Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 1954 Huashan Rd, Shanghai 200030, Peoples R China.
EM wang-zz@cs.sjtu.edu.cn
CR Andrews H.C., 1977, DIGITAL IMAGE RESTOR
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214
   BORMAN S, 1999, IEEE INT C IM PROC, V3, P469
   Chiang MC, 2000, IMAGE VISION COMPUT, V18, P761, DOI 10.1016/S0262-8856(99)00044-X
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Elad M, 1999, IEEE T PATTERN ANAL, V21, P817, DOI 10.1109/34.790425
   FORBES K, 1994, J OPT SOC AM A, V11, P1727, DOI 10.1364/JOSAA.11.001727
   Golub G.H., 1989, MATRIX COMPUTATIONS
   HANSEN PC, 1990, BIT, V30, P658, DOI 10.1007/BF01933214
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Lertrattanapanich S, 2002, IEEE T IMAGE PROCESS, V11, P1427, DOI 10.1109/TIP.2002.806234
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   MILINAZZO F, 1987, IEEE T ACOUST SPEECH, V35, P471, DOI 10.1109/TASSP.1987.1165145
   Ng MK, 2003, IEEE SIGNAL PROC MAG, V20, P62, DOI 10.1109/MSP.2003.1203210
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   PAPOULIS A, 1977, IEEE T CIRCUITS SYST, V24, P652, DOI 10.1109/TCS.1977.1084284
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Patti AJ, 1997, IEEE T IMAGE PROCESS, V6, P1064, DOI 10.1109/83.605404
   Patti AJ, 2001, IEEE T IMAGE PROCESS, V10, P179, DOI 10.1109/83.892456
   Rajan D, 2003, IEEE T PATTERN ANAL, V25, P1102, DOI 10.1109/TPAMI.2003.1227986
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Shekarforoush H, 1999, J OPT SOC AM A, V16, P481, DOI 10.1364/JOSAA.16.000481
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   STEWART GW, 1977, SIAM REV, V19, P634, DOI 10.1137/1019104
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   UR H, 1992, CVGIP-GRAPH MODEL IM, V54, P181, DOI 10.1016/1049-9652(92)90065-6
   Wang ZZ, 2004, IEEE SIGNAL PROC LET, V11, P678, DOI 10.1109/LSP.2004.831674
   Wang ZZ, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P853
   Wedin P.-A., 1973, BIT (Nordisk Tidskrift for Informationsbehandling), V13, P217, DOI 10.1007/BF01933494
   Zhao WY, 2002, LECT NOTES COMPUT SC, V2350, P599
NR 33
TC 13
Z9 14
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2005
VL 23
IS 4
BP 393
EP 404
DI 10.1016/j.imavis.2004.11.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NR
UT WOS:000227222100003
DA 2024-07-18
ER

PT J
AU Yang, CY
   Chou, JJ
AF Yang, CY
   Chou, JJ
TI A comparative evaluation approach for the classification of rotifers
   with modified non-parametric <i>k</i>NN
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE biological identification; microscopic rotifer image; k-nearest-neighbor
   rule; pattern recognition; classification; modified model
ID PATTERN-RECOGNITION; MOMENT INVARIANTS
AB In this study-aimed to achieve optimal accuracy in the classification of rotifers according to the number of eggs carried-several modifications to the basic kNN method have been proposed and assessed. Six distinct kNN rules as well as several additional hybrid models were, in fact, devised or employed and their precision compared. Meanwhile, the data sets used in the evaluation of each of these methods were acquired from rotifer images generated via the shape moments approach. Both the original data sets and the edited ones, formed by removing outliers from the originals, were used in the evaluation of these adjusted models. Through a process of comparative evaluation, several of the modified algorithms proposed-comprising both individual and hybrid models-were found to perform better overall than the classical kNN method. Refinements related to class-size weighting, in particular, were shown to heighten the accuracy of the classical kNN model considerably. Close evaluation of the various models created revealed kNN-CCS and F-kNN-CCS, in their application to the edited data sets, to be the most reliable individual modified and hybrid models respectively, with levels of accuracy greater than 95%. (C) 2004 Elsevier B.V. All rights reserved.
C1 Natl Taiwan Univ, Dept Bioind Mechatron Engn, Taipei 106, Taiwan.
   No Taiwan Inst Sci & Technol, Dept Mech Engn, Taipei 112, Taiwan.
C3 National Taiwan University
RP Chou, JJ (corresponding author), Natl Taiwan Univ, Dept Bioind Mechatron Engn, 1 Roosevelt Rd,Sect 4, Taipei 106, Taiwan.
EM jjchou@ntu.edu.tw
OI Yang, Chan-Yun/0000-0001-5329-6368
CR COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dasarathy B. V., 1977, Proceedings of the International Conference on Cybernetics and Society, P630
   Dasarathy Belur V., 1991, IEEE COMPUTER SOC TU
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6, P325, DOI 10.1109/TSMC.1976.5408784
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Hoff F.H., 1997, Plankton culture manual, V4th
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   LI YJ, 1992, PATTERN RECOGN, V25, P723, DOI 10.1016/0031-3203(92)90135-6
   PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1
   SCHALFOFF JR, 1992, PATTERN RECOGNITION
   WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137
   Yang CY, 2000, AQUACULT ENG, V24, P33, DOI 10.1016/S0144-8609(00)00065-0
NR 14
TC 3
Z9 4
U1 1
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2005
VL 23
IS 4
BP 427
EP 439
DI 10.1016/j.imavis.2004.11.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NR
UT WOS:000227222100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Grigorescu, C
   Petkov, N
   Westenberg, MA
AF Grigorescu, C
   Petkov, N
   Westenberg, MA
TI Contour and boundary detection improved by surround suppression of
   texture edges
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE edge; region boundary; contour detection; texture; inhibition;
   non-classical receptive field; surround suppression; context; Canny;
   SUSAN
ID PERFORMANCE; PERCEPTION; FEATURES; CORTEX
AB We propose a computational step, called surround suppression, to improve detection of object contours and region boundaries in natural scenes. This step is inspired by the mechanism of non-classical receptive field inhibition that is exhibited by most orientation selective neurons in the primary visual cortex and that influences the perception of groups of edges or lines. We illustrate the principle and the effect of surround suppression by adding this step to the Canny edge detector. The resulting operator responds strongly to isolated lines and edges, region boundaries, and object contours, but exhibits a weaker or no response to texture edges. Additionally, we introduce a new post-processing method that further suppresses texture edges. We use natural images with associated subjectively defined desired output contour and boundary maps to evaluate the performance of the proposed additional steps. In a contour detection task, the Canny operator augmented with the proposed suppression and post-processing step achieves better results than the traditional Canny edge detector and the SUSAN edge detector. The performance gain is highest at scales for which these latter operators strongly react to texture in the input image. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Groningen, Inst Math & Comp Sci, NL-9700 AV Groningen, Netherlands.
C3 University of Groningen
RP Univ Groningen, Dept Comp Sci, POB 800, NL-9700 AV Groningen, Netherlands.
EM cosmin@cs.rug.nl; petkov@cs.rug.nl; michel@cs.rug.nl
CR Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990
   Ando S, 2000, IEEE T PATTERN ANAL, V22, P179, DOI 10.1109/34.825756
   [Anonymous], INT J PATTERN RECOGN
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2
   CHEN G, 1995, IEEE T SYST MAN CYB, V25, P636, DOI 10.1109/21.370194
   Chen Y, 2001, COMPUT VIS IMAGE UND, V82, P85, DOI 10.1006/cviu.2001.0903
   Dubuc B, 2001, INT J COMPUT VISION, V42, P83, DOI 10.1023/A:1011141618114
   FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q
   Folsom TC, 1998, IEEE T PATTERN ANAL, V20, P1161, DOI 10.1109/34.730552
   FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733
   Galli A., 1931, Zeitschrift fur Psychologie, V123, P308
   Gavrila DM, 1998, INT C PATT RECOG, P439, DOI 10.1109/ICPR.1998.711175
   GHOSAL S, 1994, IEEE T IMAGE PROCESS, V3, P14, DOI 10.1109/83.265977
   GREGSON PH, 1993, IEEE T PATTERN ANAL, V15, P682, DOI 10.1109/34.221169
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Grossberg S, 1997, TRENDS NEUROSCI, V20, P106, DOI 10.1016/S0166-2236(96)01002-8
   GROSSBERG S, 1985, PERCEPT PSYCHOPHYS, V38, P141, DOI 10.3758/BF03198851
   HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   Heitger F, 1995, TR163 SWISS FED I TE
   HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2
   Jones HE, 2001, J NEUROPHYSIOL, V86, P2011, DOI 10.1152/jn.2001.86.4.2011
   Kanizsa G., 1979, Organization in Vision: Essays on Gestalt Perception
   Kapadia MK, 2000, J NEUROPHYSIOL, V84, P2048, DOI 10.1152/jn.2000.84.4.2048
   KNIERIM JJ, 1992, J NEUROPHYSIOL, V67, P961, DOI 10.1152/jn.1992.67.4.961
   Kovesi P., 1999, Videre, V1
   Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   MANJUNATH BS, 1993, IEEE T NEURAL NETWOR, V4, P96, DOI 10.1109/72.182699
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martens JB, 1997, IEEE T IMAGE PROCESS, V6, P1103, DOI 10.1109/83.605408
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4
   NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852
   NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0
   NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593
   Nothdurft HC, 1999, VISUAL NEUROSCI, V16, P15, DOI 10.1017/S0952523899156189
   NOTHDURFT HC, 1991, VISION RES, V31, P1073, DOI 10.1016/0042-6989(91)90211-M
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petkov N, 2003, BIOL CYBERN, V88, P236, DOI 10.1007/s00422-002-0378-2
   Petkov N, 1997, BIOL CYBERN, V76, P83, DOI 10.1007/s004220050323
   RICHARDS W, 1988, NATURAL COMPUTATION, P55
   Schwartz L., 1950, THEORIE DISTRIBUTION, VII
   SHIN M, 1998, EMPIRICAL EVALUATION, P235
   Shin MC, 2001, COMPUT VIS IMAGE UND, V84, P160, DOI 10.1006/cviu.2001.0932
   SHIN MC, 1999, P IEEE COMP VIS PATT, V1, P360
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   SOLOMON JA, 1994, NATURE, V369, P395, DOI 10.1038/369395a0
   Sonka M., 2014, Image processing, analysis, and machine vision
   TAGARE HD, 1990, IEEE T PATTERN ANAL, V12, P1186, DOI 10.1117/12.19530
   Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3
   ZUNIGA OA, 1987, IEEE T SYST MAN CYB, V17, P508, DOI 10.1109/TSMC.1987.4309068
NR 58
TC 163
Z9 187
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2004
VL 22
IS 8
BP 609
EP 622
DI 10.1016/j.imavis.2003.12.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RV
UT WOS:000221481200003
OA Green Published
DA 2024-07-18
ER

PT J
AU Kong, XW
   Liu, Y
   Liu, HJ
   Yang, DL
AF Kong, XW
   Liu, Y
   Liu, HJ
   Yang, DL
TI Object watermarks for digital images and video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE copyright protection; object watermark; security; shape
   adaptive-discrete wavelet transform
AB The growth of new image technologies has created a need for techniques that can be used for copyright protection of digital images and video. One approach for copyright protection is to introduce an invisible signal, known as a digital watermark, into an image or video sequence. With the development of MPEG-4, frame-based approach has been migrating to object-based approach. Therefore, object-based watermarking schemes are needed. In this article, we propose a novel blind object watermarking scheme for images and video using shape adaptive-discrete wavelet transform (SA-DWT). To make the watermark robust and perceptual invisible, we embed it in the weighting mean of the wavelet blocks using the quantisation visual model based on the human visual system. Watermark detection is accomplished without the original, unwatermarked object by using statistical detection technique. Experimental results demonstrate that the proposed watermarking scheme is perceptual invisible and robust against many attacks such as lossy image/video compression (e.g. JPEG, JPEG2000 and MPEG-4), scaling, adding noise, filtering, D/A and A/D conversion, etc. (C) 2003 Elsevier B.V. All rights reserved.
C1 Dalian Univ Technol, Sch Elect & Informat Engn, Dept Elect Engn, Dalian 116023, Peoples R China.
C3 Dalian University of Technology
RP Dalian Univ Technol, Sch Elect & Informat Engn, Dept Elect Engn, Dalian 116023, Peoples R China.
EM kongxw@dlut.edu.cn; yuvliu@yahoo.com.cn
RI Kong, Xiangwei/IWL-9350-2023
CR Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   *ISO IEC, 1998, JTC1SC29WGII ISO IEC
   *ISO IEC, 1995, 138182 ISO IEC
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Kaewkamnerd N, 2000, ELECTRON LETT, V36, P312, DOI 10.1049/el:20000269
   KIM GY, 1999, ICCE 99 JUN 22 24, P100
   KUHN MG, 1997, PET STIRM
   Li SP, 2000, IEEE T CIRC SYST VID, V10, P725, DOI 10.1109/76.856450
   *LUR, 2000, LUR SMARTC
   Petitcolas FAP, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P574, DOI 10.1109/MMCS.1999.779264
   PIVA A, 2000, P IEEE INT C IM PROC, V3, P5
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Solachidis V, 1999, INT CONF ACOUST SPEE, P3469, DOI 10.1109/ICASSP.1999.757589
   SU P, 1999, IS T SPIE C SEC WAT, P296
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Wu XY, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL I, P212, DOI 10.1109/ISCAS.2000.857065
   Yu GJ, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P706, DOI 10.1109/ICIP.2000.899552
NR 17
TC 18
Z9 19
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2004
VL 22
IS 8
BP 583
EP 595
DI 10.1016/j.imavis.2003.09.016
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RV
UT WOS:000221481200001
DA 2024-07-18
ER

PT J
AU Maki, A
AF Maki, A
TI Photometric subspace for multibody motion segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE subspace separation; motion segmentation; physics-based vision
ID SHAPE
AB This paper presents a new method for automatically separating the motion of multiple independently moving objects in a sequence of images based on the notion of photometric subspace. We show that intensities of observed trajectories of image features on a single body lie on a linearly independent frame space with three, or fewer, dimensions. We then argue that it is possible in theory to determine the grouping of the feature points by way of separating the photometric subspaces. As a clue for practical separation, we also introduce the surface interaction matrix which is valid for Lambertian reflectance surface. Recently, several authors have presented different algorithms on this task of grouping by factorization-based procedures using the coordinates of image features. While the challenges in their approaches are to realize the robust performance in the presence of noise, we propose to incorporate the above photometric analysis available at given feature points in the conventional schemes of motion segmentation, and show that the performance is indeed stabilized through experiments on real and synthetic image sequences. (C) 2004 Elsevier B.V. All rights reserved.
C1 Kyoto Univ, Acad Ctr Comp & Media Studies, Sakyo Ku, Kyoto 6068501, Japan.
C3 Kyoto University
RP Maki, A (corresponding author), Kyoto Univ, Acad Ctr Comp & Media Studies, Sakyo Ku, Yoshida Honmachi, Kyoto 6068501, Japan.
EM maki@media.kyoto-u.ac.jp
CR [Anonymous], 7 INT C COMP VIS ICC
   [Anonymous], 4 EUR C COMP VIS ECC
   Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484
   Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999
   Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903
   Horn B.K. P., 1992, Robot Vision
   HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0
   ICHIMURA N, 1999, 7 ICCV, P600
   IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0
   Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679
   KANATANI K, 1992, GEOMETRIC COMPUTATIO
   Maki A, 2001, PROC CVPR IEEE, P11
   Maki A, 2002, INT J COMPUT VISION, V48, P75, DOI 10.1023/A:1016057422703
   MAKI A, 2000, 6 ECCV, P725
   Mundy J., 1992, GEOMETRIC INVARIANCE
   NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367
   ONN R, 1990, INT J COMPUT VISION, V5, P105, DOI 10.1007/BF00056773
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P879, DOI 10.1109/34.93807
   PERONA P, 1999, 5 ECCV, P655
   SHASHUA A, 1992, THESIS DEP BRAIN COG
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Wiles CS, 2001, IEEE T PATTERN ANAL, V23, P1391, DOI 10.1109/34.977563
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
NR 24
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2004
VL 22
IS 8
BP 655
EP 662
DI 10.1016/j.imavis.2004.01.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RV
UT WOS:000221481200006
DA 2024-07-18
ER

PT J
AU Li, YM
   Gong, SG
   Sherrah, J
   Liddell, H
AF Li, YM
   Gong, SG
   Sherrah, J
   Liddell, H
TI Support vector machine based multi-view face detection and recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; multi-view face detection; head pose estimation;
   support vector machines
ID POSE; GAZE
AB Detecting faces across multiple views is more challenging than in a fixed view, e.g. frontal view, owing to the significant non-linear variation caused by rotation in depth, self-occlusion and self-shadowing. To address this problem, a novel approach is presented in this paper. The view sphere is separated into several small segments. On each segment, a face detector is constructed. We explicitly estimate the pose of an image regardless of whether or not it is a face. A pose estimator is constructed using Support Vector Regression. The pose information is used to choose the appropriate face detector to determine if it is a face. With this pose-estimation based method, considerable computational efficiency is achieved. Meanwhile, the detection accuracy is also improved since each detector is constructed on a small range of views. We developed a novel algorithm for face detection by combining the Eigenface and SVM methods which performs almost as fast as the Eigenface method but with a significant improved speed. Detailed experimental results are presented in this paper including tuning the parameters of the pose estimators and face detectors, performance evaluation, and applications to video based face detection and frontal-view face recognition. (C) 2004 Elsevier B.V. All rights reserved.
C1 Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England.
   Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England.
   Safehouse Technol Pty Ltd, Collingwood, Vic 3066, Australia.
C3 Brunel University; University of London; Queen Mary University London
RP Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England.
EM yongmin.li@brunel.ac.uk
OI Li, Yongmin/0000-0003-1668-2440
CR [Anonymous], SPIE
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], CMUCS97201
   [Anonymous], IEEE INT C AUT FAC G
   BEYMER D, 1993, MIT AI MEMO, V1431
   BRUCE V, 1987, APPL COGNITIVE PSYCH, V1, P109, DOI 10.1002/acp.2350010204
   Burl MC, 1996, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.1996.517078
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Elagin E, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P136, DOI 10.1109/AFGR.1998.670938
   GEE A, 1994, IMAGE VISION COMPUT, V12, P639, DOI 10.1016/0262-8856(94)90039-6
   Gong S., 2000, Dynamic vision from images to face recognition
   GONG S, 1998, AS C COMP VIS, V2, P679
   GONG S, 1998, BRIT MACH VIS C SOUT, P54
   Gong SG, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P265, DOI 10.1109/AFGR.1996.557275
   Horprasert T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P242, DOI 10.1109/AFGR.1996.557271
   HUTCHINSON TE, 1989, IEEE T SYST MAN CYB, V19, P1527, DOI 10.1109/21.44068
   JONES PVM, 2001, IEEE C COMP VIS PATT
   Kjeldsen R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P312, DOI 10.1109/AFGR.1996.557283
   KROUSE FL, 1981, J APPL PSYCHOL, V66, P651, DOI 10.1037/0021-9010.66.5.651
   Kruger N, 1997, IMAGE VISION COMPUT, V15, P665, DOI 10.1016/S0262-8856(97)00012-7
   LI SZ, 2002, EUR C COMP VIS COP D
   LI Y, 2000, 4 INT C KNOWL BAS IN, P241
   LOGIE RH, 1987, APPL COGNITIVE PSYCH, V1, P53, DOI 10.1002/acp.2350010108
   Matsumoto Y., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P499, DOI 10.1109/AFGR.2000.840680
   Maurer T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P176, DOI 10.1109/AFGR.1996.557261
   McKenna S, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P271, DOI 10.1109/AFGR.1996.557276
   MCKENNA S, 1996, BMVC, P755
   MCKENNA S, 1997, BRIT MACH VIS C U EX, P140
   McKenna SJ, 1998, PATTERN RECOGN, V31, P1883, DOI 10.1016/S0031-3203(98)00066-1
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Moghaddam B, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P30, DOI 10.1109/AFGR.1998.670921
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   NG J, 1999, IEEE INT WORKSH REC, P14
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Osuna E., 1997, AI MEMO, V1602
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   RAJA Y, 1998, EUR C COMP VIS FREIB
   RAJA Y, 1998, AS C COMP VIS HONG K
   ROWLEY H, 1998, IEEE C COMPUTER VISI
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Rowley HA, 1996, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.1996.517075
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   SCHOLKOPF B, 1998, SUPPROT VECTOR REGRE, P111
   Smola A, 1999, IEE CONF PUBL, P575, DOI 10.1049/cp:19991171
   Soulie F. F., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P721, DOI 10.1142/S0218001493000364
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   SUNG KK, 1994, AI MEMO, V1521
   VANDERBEI RJ, 1994, 9415 SOR PRINC U
   Vapnik V., 1999, NATURE STAT LEARNING
   Xu M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P82, DOI 10.1109/AFGR.1998.670929
   Yow KC, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P295, DOI 10.1109/AFGR.1996.557280
   Yow KC, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P16, DOI 10.1109/AFGR.1996.557238
   ZHANG Z, 2002, IEEE INT C AUT FAC G
NR 53
TC 97
Z9 124
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2004
VL 22
IS 5
BP 413
EP 427
DI 10.1016/j.imavis.2003.12.005
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 806GN
UT WOS:000220422500006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kadyrov, A
   Petrou, M
AF Kadyrov, A
   Petrou, M
TI Object signatures invariant to affine distortions derived from the Trace
   transform
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE trace transform; affine distortions; invariance; database image
   retrieval; moments
ID MOMENT INVARIANTS; RECOGNITION
AB The Trace transform is a generalisation of the Radon transform that allows one to construct image features that are invariant to a chosen group of image transformations. In this paper we use some functionals on the image function, and derive a set of signatures for each object that can be used to describe the object in an affine invariant way. The functionals are computed along batches of parallel lines tracing the image in all possible orientations. We demonstrate the usefulness of the constructed image descriptors in retrieving images from an image database and compare it with the moments based method. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Surrey, Sch Elect & Phys Sci, Guildford GU2 7XH, Surrey, England.
C3 University of Surrey
RP Petrou, M (corresponding author), Univ Surrey, Sch Elect & Phys Sci, Guildford GU2 7XH, Surrey, England.
CR FLUSSER J, 1994, IEEE T GEOSCI REMOTE, V32, P382, DOI 10.1109/36.295052
   FLUSSER J, 1994, PATTERN RECOGN LETT, V15, P433, DOI 10.1016/0167-8655(94)90092-2
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Kadyrov A, 2001, IEEE T PATTERN ANAL, V23, P811, DOI 10.1109/34.946986
   PETROU M, 2004, IEEE T PATTERN ANAL, P26
   PETROU M, 2001, ICIP 2001 THESS GREE, V3, P852
   Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412
NR 7
TC 16
Z9 19
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1135
EP 1143
DI 10.1016/j.imavis.2003.08.013
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100008
DA 2024-07-18
ER

PT J
AU Li, YM
   Gong, SG
   Liddell, H
AF Li, YM
   Gong, SG
   Liddell, H
TI Recognising trajectories of facial identities using kernel discriminant
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE face recognition; Kernel discriminant analysis; identity surfaces;
   multi-view face models
ID IMAGE
AB We present a comprehensive approach to address three challenging problems in face recognition: modelling faces across multi-views, extracting the nonlinear discriminating features, and recognising moving faces dynamically in image sequences. A multi-view dynamic face model is designed to extract the shape-and-pose-free facial texture patterns. Kernel discriminant analysis, which employs the kernel technique to perform linear discriminant analysis in a high-dimensional feature space, is developed to extract the significant nonlinear features which maximise the between-class variance and minimise the within-class variance. Finally, an identity surface based face recognition is performed dynamically from video input by matching object and model trajectories. (C) 2003 Elsevier B.V. All fights reserved.
C1 BT Exact, Content & Coding Lab, Ipswich IP5 3RE, Suffolk, England.
   Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England.
C3 University of London; Queen Mary University London
RP BT Exact, Content & Coding Lab, Adastral Pk, Ipswich IP5 3RE, Suffolk, England.
EM yongmin.li@bt.com
OI Li, Yongmin/0000-0003-1668-2440
CR [Anonymous], 1972, Introduction to Statistical Pattern Recognition
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], P 13 INT C MACH LEAR
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Bruce V, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P408, DOI 10.1109/AFGR.1998.670983
   Burges CJC, 1997, ADV NEUR IN, V9, P375
   Cootes T., 1998, Proc. ECCV, V2, P484
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P260, DOI 10.1109/AFGR.1998.670958
   Gong S., 2000, Dynamic vision from images to face recognition
   Gong S., 1994, EUR WORKSH COMB REAL, P96
   Knight B, 1997, VIS COGN, V4, P265, DOI 10.1080/713756764
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Li YM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P554, DOI 10.1109/ICCV.2001.937565
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Roth V, 2000, ADV NEUR IN, V12, P568
   SCHLKOPF B, 1997, LECT NOTES COMPUTER, P583
   SCHOLKOPF B, 1997, SUPPORT VECTOR LEANI
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   VANDERBEI RJ, 1994, 9415 SOR PRINC U
   Vapnik V., 1999, NATURE STAT LEARNING
   Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230
NR 24
TC 18
Z9 21
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1077
EP 1086
DI 10.1016/j.imavis.2003.08.010
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, YT
   Qi, X
   Saudagar, AKJ
   Badshah, AM
   Muhammad, K
   Liu, S
AF Li, Yating
   Qi, Xin
   Saudagar, Abdul Khader Jilani
   Badshah, Abdul Malik
   Muhammad, Khan
   Liu, Shuai
TI Student behavior recognition for interaction detection in the classroom
   environment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Surveillance; Relational reasoning; Human -to -object interaction;
   Action recognition; Smart classroom; Intelligent education
AB With the development of multimedia technologies, surveillance videos and other multimedia data have received widespread attention in several fields. Surveillance videos can monitor students' learning statuses in real time. However, the current action recognition methods for teaching have limitations. First, the ethical privacy of AI and education makes public datasets on student behavior scarce. Therefore, based on the summarization of seven typical student behaviors in the classroom, course videos were obtained from the smart classroom to gen-erate a dataset of student behavior. Compared with existing student behavior recognition datasets, the proposed dataset is distinguished by cluttered backgrounds, crowded scenes, and occlusions. Second, relational reasoning using existing methods is not ideal for distinguishing between students' body parts and small objects in a cluttered background; the interactive utilization rate of different relational features is low, and it cannot take ad-vantage of the complementarity of different relational features, resulting in poor performance of interaction ac-tion recognition. Therefore, the attention-based relational reasoning module strengthens the interactive representation between small objects and human body parts. At the same time, considering that there is a certain complementary relationship between relational features, this study constructs a relational feature fusion module which models a human-to-human interaction relationship built upon supporting human's body part and sur-rounding context. Finally, the reconstructed features and human-appearance features were fused to achieve ac-curate interactive action recognition. Through an experimental comparison between the proposed and current mainstream algorithms on the generated student behavior dataset, it was verified that the proposed model achieves state-of-the-art performance in action recognition.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Li, Yating; Qi, Xin; Liu, Shuai] Hunan Normal Univ, Sch Educ Sci, Changsha 410081, Peoples R China.
   [Li, Yating; Qi, Xin; Liu, Shuai] Hunan Normal Univ, Coll Comp Sci & Engn, Changsha 410081, Peoples R China.
   [Saudagar, Abdul Khader Jilani] Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Informat Syst Dept, Riyadh 11432, Saudi Arabia.
   [Badshah, Abdul Malik] Univ Missouri Kansas City, Dept Comp Sci & Elect Engn, Kansas City, MO USA.
   [Muhammad, Khan] Sungkyunkwan Univ, Coll Comp & Informat, Sch Convergence, Dept Appl Artificial Intelligence,Visual Analyt La, Seoul 03063, South Korea.
   [Muhammad, Khan; Liu, Shuai] Sungkyunkwan Univ, Coll Comp & Informat, Sch Convergence, Seoul 03063, South Korea.
C3 Hunan Normal University; Hunan Normal University; Imam Mohammad Ibn Saud
   Islamic University (IMSIU); University of Missouri System; University of
   Missouri Kansas City; Sungkyunkwan University (SKKU); Sungkyunkwan
   University (SKKU)
RP Liu, S (corresponding author), Hunan Normal Univ, Sch Educ Sci, Changsha 410081, Peoples R China.; Muhammad, K; Liu, S (corresponding author), Sungkyunkwan Univ, Coll Comp & Informat, Sch Convergence, Seoul 03063, South Korea.
EM khan.muhammad@ieee.org; liushuai@hunnu.edu.cn
RI Saudagar, Abdul/HHY-9939-2022; Liu, Shuai/P-3939-2017
OI Liu, Shuai/0000-0001-9909-0664
CR Alairaji Roa'a M., 2022, Advanced Computational Paradigms and Hybrid Intelligent Computing: Proceedings of ICACCP 2021. Advances in Intelligent Systems and Computing (1373), P113, DOI 10.1007/978-981-16-4369-9_12
   Alfasly Saghir, 2022, P IEEECVF C COMPUTER
   Bakas J, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03511-3
   Behera NKS, 2020, PATTERN RECOGN LETT, V138, P282, DOI 10.1016/j.patrec.2020.07.030
   Bottou Leon, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P421, DOI 10.1007/978-3-642-35289-8_25
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doshi K, 2020, IEEE COMPUT SOC CONF, P4037, DOI 10.1109/CVPRW50498.2020.00475
   Duan HD, 2022, PROC CVPR IEEE, P2959, DOI 10.1109/CVPR52688.2022.00298
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Faure G.J., 2023, P IEEECVF WINTER C A, P3340
   Faure Gueter Josmy, 2023, P IEEECVF WINTER C A
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao C., 2018, ARXIV
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Jan AT, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03702-6
   Jiaxi Wu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P456, DOI 10.1007/978-3-030-58517-4_27
   Kar NB, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104445
   Kumar Akash, 2022, P IEEECVF C COMPUTER, P14700
   Kumar M, 2021, MULTIMED TOOLS APPL, V80, P31277, DOI 10.1007/s11042-020-10471-x
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Neimark D, 2021, IEEE INT CONF COMP V, P3156, DOI [arXiv:2102.00719, 10.1109/ICCVW54120.2021.00355]
   Pan JT, 2021, PROC CVPR IEEE, P464, DOI 10.1109/CVPR46437.2021.00053
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Santoro A, 2017, ADV NEUR IN, V30
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Tang J., 2020, COMPUTER VISION ECCV, P71
   Tay N.C., 2019, 2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE), P1, DOI DOI 10.1109/ICECIE47765.2019.8974824
   Vaezi Joze Hamid Reza, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13286, DOI 10.1109/CVPR42600.2020.01330
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZW, 2021, PROC CVPR IEEE, P13209, DOI 10.1109/CVPR46437.2021.01301
   Wenbo Lan, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1547, DOI 10.1109/ICMA.2018.8484698
   Xiao FY, 2020, Arxiv, DOI arXiv:2001.08740
   YiWen Zhang, 2020, 2020 International Conference on Artificial Intelligence and Education (ICAIE), P93, DOI 10.1109/ICAIE50891.2020.00029
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zhao Y, 2022, LECT NOTES ARTIF INT, V13458, P679, DOI 10.1007/978-3-031-13841-6_61
   Zheng R, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P680
NR 38
TC 7
Z9 7
U1 23
U2 41
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104726
DI 10.1016/j.imavis.2023.104726
EA JUN 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N1HA0
UT WOS:001034595200001
DA 2024-07-18
ER

PT J
AU Oruganti, M
   Meenpal, T
   Majumder, S
AF Oruganti, Madhu
   Meenpal, T.
   Majumder, Saikat
TI Easy pair selection method for Kinship Verification using fixed age
   group images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep features; Easy-pair; Fixed age group dataset; Kinship Verification
AB Kinship Verification (KV) by using facial images is a relevant and challenging research problem in the field of computer vision. Facial features are extracted from the input pair of images and subsequently analyzed to find out existence of kin relation between them. Weights of the training model are suitably learned and adapted for the same. In most of the existing schemes, non kin pairs are randomly generated from the existing kin pair database for the learning process of the model. Since non-kin pairs are formed randomly from the true kin pair database itself, hence there is a significant probability that some non kin pairs have more similarity in feature space which is ideally undesirable and leads to improper learning of the model and results into errors. To reduce such errors, we have proposed a new scheme called easy-pair selection method for KV. Kin and non kin pairs are categorized into easy and hard pairs based on sum of square distance with respect to the feature space of the pairs. Suitable kin-margin (KM) value is chosen to classify the pair as easy or hard. Further, selected easy pairs are used to compute the optimized training weights (W) from the training dataset. The obtained weights will ensure to minimize the distance of kin pairs and maximize the distance of non-kin pairs in feature space. A fixed age group image database (FAG) have also been proposed through this article which contains the corresponding facial images of the parents and their children from the same age group to minimize the issue of age in-variance as well. Extensive experiments have been performed to validate the accuracy of the proposed scheme and is found to outperform the existing relevant schemes for KV.
C1 [Oruganti, Madhu; Meenpal, T.; Majumder, Saikat] Natl Inst Technol, Dept ECE, GE Rd, Raipur 492010, CG, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Oruganti, M (corresponding author), Natl Inst Technol, Dept ECE, GE Rd, Raipur 492010, CG, India.
EM moruganti.phd2019.ece@nitrr.ac.in
RI Oruganti, Madhu/KIJ-9331-2024
OI Oruganti, Madhu/0000-0002-6274-3606
CR Alirezazadeh P, 2015, IEEE SIGNAL PROC LET, V22, P2459, DOI 10.1109/LSP.2015.2490805
   Ben Fredj H, 2021, INT J COMPUT SCI NET, V21, P256, DOI 10.22937/IJCSNS.2021.21.5.35
   Cui LY, 2017, IEEE INT CON MULTI, P751, DOI 10.1109/ICME.2017.8019326
   Dong GN, 2021, IEEE T INF FOREN SEC, V16, P4197, DOI 10.1109/TIFS.2021.3098165
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Faraki M, 2017, PATTERN RECOGN LETT, V98, P83, DOI 10.1016/j.patrec.2017.09.017
   Goyal A, 2021, INFORM SCIENCES, V578, P507, DOI 10.1016/j.ins.2021.07.046
   Goyal A, 2021, IEEE T IMAGE PROCESS, V30, P191, DOI 10.1109/TIP.2020.3034027
   Goyal A, 2021, PATTERN ANAL APPL, V24, P119, DOI 10.1007/s10044-020-00906-4
   Goyal Aarti, 2020, COMPUTATIONAL INTELL
   Guo GD, 2012, IEEE T INSTRUM MEAS, V61, P2322, DOI 10.1109/TIM.2012.2187468
   Kim H, 2023, COMPUT VIS IMAGE UND, V231, DOI 10.1016/j.cviu.2023.103662
   Kim Hyeonwoo, 2022, 2022 IEEE INT C BIG
   Kohli N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P245, DOI 10.1109/BTAS.2012.6374584
   Kohli N, 2019, IEEE T IMAGE PROCESS, V28, P1329, DOI 10.1109/TIP.2018.2840880
   Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811
   Li Wei, 2020, 2020 IEEE INT C MULT, P1
   Liang JQ, 2019, IEEE T IMAGE PROCESS, V28, P1149, DOI 10.1109/TIP.2018.2875346
   Liu Qingfeng, 2016, 2016 IEEE WINT C APP, P1
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Mahpod S, 2018, COMPUT VIS IMAGE UND, V167, P28, DOI 10.1016/j.cviu.2017.12.003
   Mukherjee M, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103470
   Oruganti M, 2021, 2021 NAT C COMM NCC, P1
   Patel B, 2017, COMPUT VIS IMAGE UND, V160, P24, DOI 10.1016/j.cviu.2017.04.009
   Prakash R. Meena, 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P861, DOI 10.1109/ICSSIT46314.2019.8987899
   Puthenputhussery A, 2016, IEEE IMAGE PROC, P2921, DOI 10.1109/ICIP.2016.7532894
   Qin XQ, 2020, NEUROCOMPUTING, V377, P213, DOI 10.1016/j.neucom.2019.09.089
   Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462
   Robinson JP, 2021, IEEE T MULTIMEDIA, V24, P3582, DOI 10.1109/TMM.2021.3103074
   Robinson JP, 2018, IEEE T PATTERN ANAL, V40, P2624, DOI 10.1109/TPAMI.2018.2826549
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shan SG, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P314
   Wang YQ, 2014, IMAGE PROCESS ON LIN, V4, P128, DOI 10.5201/ipol.2014.104
   Wu HS, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103265
   Wu XT, 2022, INT J COMPUT VISION, V130, P1494, DOI 10.1007/s11263-022-01605-9
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Yan HB, 2017, IMAGE VISION COMPUT, V60, P91, DOI 10.1016/j.imavis.2016.08.009
   Yan HB, 2015, IEEE T CYBERNETICS, V45, P2535, DOI 10.1109/TCYB.2014.2376934
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Yang Y., 2017, DESTECH T COMPUT SCI
   Zhang HM, 2019, IEEE IMAGE PROC, P3856, DOI [10.1109/ICIP.2019.8803647, 10.1109/icip.2019.8803647]
   Zhang L, 2021, IEEE T CYBERNETICS, V51, P5883, DOI 10.1109/TCYB.2019.2959403
   Zhang YT, 2015, PROC CVPR IEEE, P249, DOI 10.1109/CVPR.2015.7298621
   Zhao YG, 2018, INFORM SCIENCES, V430, P247, DOI 10.1016/j.ins.2017.11.048
   Zhou X., 2011, ACM Multimedia, P953
NR 45
TC 0
Z9 0
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104727
DI 10.1016/j.imavis.2023.104727
EA JUN 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA L7AL2
UT WOS:001024747500001
DA 2024-07-18
ER

PT J
AU Lee, HK
   Ro, YM
AF Lee, Hakmin
   Ro, Yong Man
TI Adversarial anchor-guided feature refinement for adversarial defense
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Adversarial example; Adversarial robustness; Adversarial anchor;
   Covariate shift; Feature refinement
ID ROBUSTNESS
AB Adversarial training (AT), which is known as a robust training method for defending against adversarial examples, usually loses the performance of models for clean examples due to the feature distribution discrepancy between clean and adversarial. In this paper, we propose a novel Adversarial Anchor-guided Feature Refinement (AAFR) defense method aimed at reducing the discrepancy and delivering reliable performances for both clean and adversarial examples. We devise adversarial anchor that detects whether the feature comes from clean or adversarial example. Then, we use adversarial anchor to refine the feature to reduce the discrepancy. As a result, the proposed method substantially achieves adversarial robustness while preserving the performance for clean examples. The effectiveness of the proposed method is verified with comprehensive experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet datasets.
C1 [Lee, Hakmin; Ro, Yong Man] Korea Adv Inst Sci & Technol KAIST, Sch Elect Engn, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, HK (corresponding author), Korea Adv Inst Sci & Technol KAIST, Sch Elect Engn, Daejeon 34141, South Korea.
EM zpqlam12@kaist.ac.kr; ymro@kaist.ac.kr
CR Ackerman E., 2017, IEEE Spectrum, V1
   Amodei D, 2016, PR MACH LEARN RES, V48
   Andriushchenko Maksym, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P484, DOI 10.1007/978-3-030-58592-1_29
   Athalye A, 2018, PR MACH LEARN RES, V80
   Benz P., 2021, P IEEECVF INT C COMP, P7818
   Benz P, 2021, IEEE WINT CONF APPL, P494, DOI 10.1109/WACV48630.2021.00054
   Bhagoji A.N., 2018, WORKSH SEC MACH LEAR
   Brock A., 2021, INT C LEARNING REPRE
   Bryniarski Oliver, 2021, arXiv
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542
   Chen X., 2021, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P16622
   Chen Z., ADVERSARIAL ATTACK C
   Cohen G., 2020, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, P14453
   Croce F., INT C MACH LEARN PML, P2196
   Croce F, 2020, PR MACH LEARN RES, V119
   Cui JQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15701, DOI 10.1109/ICCV48922.2021.01543
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong YP, 2020, Advances in Neural Information Processing Systems, V33
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399
   Galloway A, 2019, Arxiv, DOI arXiv:1905.02161
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Hou XX, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103926
   Hwang U, 2019, IEEE ACCESS, V7, P126582, DOI 10.1109/ACCESS.2019.2939352
   Ilyas A, 2019, ADV NEUR IN, V32
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Jin G., 2022, P IEEECVF C COMPUTER, P15273
   Kannan H, 2018, Arxiv, DOI arXiv:1803.06373
   Kaya Y., 2022, INT C MACH LEARN PML, P10895
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2016, Adversarial machine learning at scale
   Kurakin Alexey, 2017, INT C LEARN REPR
   Lee Hakmin, 2020, ARXIV200510757
   Lee K, 2018, 32 C NEURAL INFORM P
   Lee S, 2020, PROC CVPR IEEE, P269, DOI 10.1109/CVPR42600.2020.00035
   Li J., INT C MACH LEARN PML, P3896
   Li X, 2017, IEEE I CONF COMP VIS, P5775, DOI 10.1109/ICCV.2017.615
   Li YH, 2018, PATTERN RECOGN, V80, P109, DOI 10.1016/j.patcog.2018.03.005
   Li ZR, 2020, IEEE ACCESS, V8, P88594, DOI 10.1109/ACCESS.2020.2993304
   Liang Q, 2022, IMAGE VISION COMPUT, V120, DOI 10.1016/j.imavis.2021.104370
   Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191
   Liu BY, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104469
   Liu XQ, 2018, LECT NOTES COMPUT SC, V11211, P381, DOI 10.1007/978-3-030-01234-2_23
   Luo WJ, 2022, APPL SOFT COMPUT, V117, DOI 10.1016/j.asoc.2021.108383
   Ma X., 2018, INT C LEARNING REPRE
   Madry A., 2018, ARXIV
   Merchant A, 2020, Arxiv, DOI arXiv:2010.07810
   Metzen J.H, 2017, INT C LEARNING REPRE
   Nado Z, 2021, Arxiv, DOI arXiv:2006.10963
   Nandy J., 2021, 9 INT C LEARN REPR I, P1
   Naseer M., 2022, INT C LEARN REPR
   Naseer M., 2022, IEEE T PATTERN ANAL
   Naseer M, 2020, PROC CVPR IEEE, P259, DOI 10.1109/CVPR42600.2020.00034
   Nie W., INT C MACH LEARN PML, P16805
   Samangouei P., 2018, DEFENSE GAN PROTECTI
   Schneider Steffen, 2020, ADV NEURAL INFORM PR, V33, P11539
   Scholkopf B., 2012, ICML
   Shin Richard, 2017, NIPS 2017 WORKSH MAC, V1
   Song Y., 2018, INT C LEARNING REPRE
   Sriramanan G, 2020, Advances in neural information processing systems (NeurIPS)
   Sriramanan G, 2021, ADV NEUR IN
   Sugiyama M, 2012, ADAPT COMPUT MACH LE, P1
   Sun B., 2015, P BRIT MACH VIS C, V24, P1
   Sun P, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104036
   Sun Y., 2020, P 37 INT C MACHINE L, P9229
   Sun YD, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104318
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tian JY, 2021, AAAI CONF ARTIF INTE, V35, P9877
   Tsipras D., 2019, P 7 INT C LEARN REPR
   Tummon HM, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519863077
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang Haoran, 2021, Advances in Neural Information Processing Systems (NeurIPS)
   Wang Haorui, 2022, INT C LEARN REPR
   Wang Haotao, 2022, INT C MACH LEARN, P23433
   Wang Y., 2019, INT C LEARNING REPRE, P1
   Wang Y., INT C MACH LEARN PML, P6586
   Wojtowicz A., 2018, ICEIS 1, P555
   Xie C., 2020, INT C LEARNING REPRE
   Xie C, 2020, PROC CVPR IEEE, P816, DOI 10.1109/CVPR42600.2020.00090
   Xie CH, 2019, PROC CVPR IEEE, P501, DOI 10.1109/CVPR.2019.00059
   Xu W., 2018, Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks
   Yucel MK, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104392
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang H., INT C MACH LEARN PML, P7472
   Zhang Z., 2020, P IEEE CVF C COMP VI
NR 92
TC 0
Z9 0
U1 3
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104722
DI 10.1016/j.imavis.2023.104722
EA JUN 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA L8MV7
UT WOS:001025759700001
DA 2024-07-18
ER

PT J
AU Srivastava, S
   Vidyarthi, A
   Jain, S
AF Srivastava, Somya
   Vidyarthi, Ankit
   Jain, Shikha
TI A regressive encoder-decoder-based deep attention model for segmentation
   of fetal head in 2D-ultrasound images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ultrasound imaging; Deep learning; Fetus head segmentation; Head
   circumference assessment; Regression-attention model
AB Ultrasound imaging is the most commonly used imaging during pregnancy for tracking the fetus's growth and monitoring other biological parameters. The assessment of the development of the baby's growth requires imaging-based analysis in every trimester. The automatic computerized software and systems provide the platform for radiologists to more accurately access the fetus's head circumference as compared to manual estimation. The improvement of such computerized algorithms is always the key demand to improve accuracy and precision. This paper proposes an improved encoder-decoder model for the segmentation of the fetal head segmentation in 2D-ultrasound images. The proposed model uses regression in combination with attention to the encoderdecoder model to determine the fetus's head circumference. The model is further extended with the postprocessing ellipse fitting to superimpose the segmentation region on ultrasound images for clear visualization of the fetus's head. Further, the proposed model performance is evaluated by using various statistical measures using segmented regions and available ground truth. The experimental results demonstrate a similarity score of 94.56%. The comparative result suggests that the proposed model is providing a more accurate fetus head segmentation region on 2D-ultrasound images as compared to other existing approaches.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Srivastava, Somya; Vidyarthi, Ankit; Jain, Shikha] Jaypee Inst Informat Technol, Dept CSE&IT, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Vidyarthi, A (corresponding author), Jaypee Inst Informat Technol, Dept CSE&IT, Noida, India.
EM somya.srivastava0509@gmail.com; dr.ankit.vidyarthi@gmail.com;
   shikha.jain@jiit.ac.in
OI Srivastava, Somya/0000-0003-1214-459X
CR Al-Bander B, 2020, COMM COM INF SC, V1065, P142, DOI 10.1007/978-3-030-39343-4_12
   Avisdris N, 2021, INT J COMPUT ASS RAD, V16, P1481, DOI 10.1007/s11548-021-02436-8
   Burgos-Artizzu XP, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67076-5
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Garcia-Canadilla P, 2020, FETAL DIAGN THER, V47, P363, DOI 10.1159/000505021
   Gofer S, 2022, J ULTRAS MED, V41, P1773, DOI 10.1002/jum.15860
   Huang QH, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/5137904
   Jardim SMGVB, 2005, ULTRASOUND MED BIOL, V31, P243, DOI 10.1016/j.ultrasmedbio.2004.11.003
   Lu W, 2005, ULTRASOUND MED BIOL, V31, P929, DOI 10.1016/j.ultrasmedbio.2005.04.002
   Nardozza LMM, 2017, ARCH GYNECOL OBSTET, V295, P1061, DOI 10.1007/s00404-017-4341-9
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Oghli M.G., 2020, IEEE NUCL SCI S MEDI, P1
   Ravishankar H, 2016, I S BIOMED IMAGING, P779, DOI 10.1109/ISBI.2016.7493382
   Rong YB, 2019, BIOMED OPT EXPRESS, V10, P3800, DOI 10.1364/BOE.10.003800
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rueda S, 2014, IEEE T MED IMAGING, V33, P797, DOI 10.1109/TMI.2013.2276943
   Schmidt U, 2014, EUR J OBSTET GYN R B, V178, P153, DOI 10.1016/j.ejogrb.2014.03.047
   Seo H, 2020, MED PHYS, V47, pE148, DOI 10.1002/mp.13649
   Sobhaninia Z., 2020, 2020 25 INT COMPUTER, P1
   Sobhaninia Z, 2019, IEEE ENG MED BIO, P6545, DOI [10.1109/EMBC.2019.8856981, 10.1109/embc.2019.8856981]
   van den Heuvel TLA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200412
   Vidyarthi A., 2015, Systems Conference (NSC), 2015 39th National, P1, DOI [10.1109/NATSYS.2015.7489135, DOI 10.1109/NATSYS.2015.7489133]
   Vidyarthi Ankit, 2012, INT J COMP ENG TECHN, V3, P85
   Xie BH, 2020, INT J COMPUT ASS RAD, V15, P1303, DOI 10.1007/s11548-020-02182-3
   Yang X, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105519
   Yaqub M, 2013, LECT NOTES COMPUT SC, V8184, P25, DOI 10.1007/978-3-319-02267-3_4
   Zeng W, 2022, MED PHYS, V49, P5081, DOI 10.1002/mp.15700
NR 27
TC 1
Z9 1
U1 2
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104725
DI 10.1016/j.imavis.2023.104725
EA JUN 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA M3AZ6
UT WOS:001028952100001
DA 2024-07-18
ER

PT J
AU Chang, HH
   Yeh, CH
AF Chang, Herng-Hua
   Yeh, Chun-Hsiao
TI Face anti-spoofing detection based on multi-scale image quality
   assessment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Image quality assessment; Face presentation attack
   detection; Local face trait; Top gradient similarity
ID LIVENESS DETECTION; MOTION
AB This article introduces an effective face PAD algorithm based on multiscale perceptual image quality assessment features. Unique hand-crafted texture features extracted from face images are exploited for spoofing detection. The proposed features are classified into three major models: generalized Gaussian density-based, asymmetric generalized Gaussian density-based, and top gradient similarity deviation features. In light of the essential attributes of these models, a total of 21 multiscale features are acquired for classification, which is performed through a support vector machine (SVM). Extensive experiments on five benchmark databases, CASIA, Replay-Attack, UVAD, OULU-NPU, and SiW along with our new dataset demonstrated the effectiveness of the proposed framework. Experimental results indicated that our face PAD algorithm produced satisfactory detection accuracy on the tested datasets based on both intra-dataset and cross-dataset protocols. While outperforming a number of traditional face PAD methods, the proposed scheme achieved comparable results with many state-of-the-art deep learning-based networks. The introduction of the image quality assessment features with multiscale analysis into face PAD is promising for detection accuracy improvement.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Chang, Herng-Hua; Yeh, Chun-Hsiao] Natl Taiwan Univ, Dept Engn Sci & Ocean Engn, Computat Biomed Engn Lab CBEL, 1 Sec 4 Roosevelt Rd, Taipei 10617, Taiwan.
   [Yeh, Chun-Hsiao] Univ Calif Berkeley, Dept Vis Sci, Berkeley, CA 94720 USA.
C3 National Taiwan University; University of California System; University
   of California Berkeley
RP Chang, HH (corresponding author), Natl Taiwan Univ, Dept Engn Sci & Ocean Engn, Computat Biomed Engn Lab CBEL, 1 Sec 4 Roosevelt Rd, Taipei 10617, Taiwan.
EM herbertchang@ntu.edu.tw
FU Ministry of Science and Technology of Taiwan [108-2221-E-002-080-MY3];
   MOST
FX Acknowledgements This work was supported in part by the Ministry of
   Science and Technology of Taiwan under Grant No. MOST 106-2221-E-002-082
   and Grant No. MOST 108-2221-E-002-080-MY3.
CR Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   Anjos Andre, 2011, P INT JOINT C BIOM I, P1, DOI DOI 10.1109/IJCB.2011.6117503
   [Anonymous], 2002, Inf. Secur. Tech. Rep., DOI DOI 10.1016/S1363-4127(02)00407-7
   [Anonymous], 2006, Handbook of Multibiometrics
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arashloo SR, 2015, IEEE T INF FOREN SEC, V10, P2396, DOI 10.1109/TIFS.2015.2458700
   Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Benlamoudi A, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.4.043007
   Bharadwaj S., P IEEE C COMPUTER VI, P105
   Boulkenafet Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P688, DOI 10.1109/BTAS.2017.8272758
   Boulkenafet Z., 2017 12 IEEE INT C A, P612
   Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Cai RZ, 2021, IEEE T INF FOREN SEC, V16, P937, DOI 10.1109/TIFS.2020.3026553
   Chan PPK, 2018, IEEE T INF FOREN SEC, V13, P521, DOI 10.1109/TIFS.2017.2758748
   Chen HN, 2019, IEEE ACCESS, V7, P170116, DOI 10.1109/ACCESS.2019.2955383
   Chingovska Ivana, 2012, BIOSIG
   Conotter V., 2014 IEEE INT C IMAG, P248
   de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Hadid A., 2016, IPTA, P1
   ISO/IEC, 2016, JTC1SC37 ISO IEC
   Jourabloo A, 2018, LECT NOTES COMPUT SC, V11217, P297, DOI 10.1007/978-3-030-01261-8_18
   Kim DO, 2010, IEEE T CONSUM ELECTR, V56, P930, DOI 10.1109/TCE.2010.5506022
   Kim S, 2013, EUR CONF NETW OPTIC, P1, DOI 10.1109/NOC-OCI.2013.6582859
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Kim Y, 2011, IEEE T CONSUM ELECTR, V57, P756, DOI 10.1109/TCE.2011.5955219
   Kollreider K, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P75, DOI 10.1109/AUTOID.2005.20
   Komulainen Jukka, 2013, 2013 IEEE 6 INT C BI
   Lasmar NE, 2009, IEEE IMAGE PROC, P2281, DOI 10.1109/ICIP.2009.5414404
   Lee JY, 1999, PROCEEDINGS OF THE IEEE SIGNAL PROCESSING WORKSHOP ON HIGHER-ORDER STATISTICS, P255, DOI 10.1109/HOST.1999.778737
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P1794, DOI 10.1109/TIFS.2018.2801312
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu Y., 2018 IEEECVF C COMPU, P389
   Lucena O., 2017, TRANSFER LEARNING US, P27
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Manjani I., 2017, IEEE T INF FOREN SEC
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pan G., 2007 IEEE 11 INT C C, P1
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Peng F, 2018, MULTIMED TOOLS APPL, V77, P8883, DOI 10.1007/s11042-017-4780-0
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Pinto A, 2015, IEEE T IMAGE PROCESS, V24, P4726, DOI 10.1109/TIP.2015.2466088
   Pinto A, 2015, IEEE T INF FOREN SEC, V10, P1025, DOI 10.1109/TIFS.2015.2395139
   Roy K, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082799
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Sepas-Moghaddam A, 2018, IET BIOMETRICS, V7, P39, DOI 10.1049/iet-bmt.2017.0095
   Shao R, 2019, IEEE T INF FOREN SEC, V14, P923, DOI 10.1109/TIFS.2018.2868230
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Steiner H., BIOMETRICS ICB 2016, P1
   Sun L, 2007, LECT NOTES COMPUT SC, V4642, P252
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Tesei A, 1998, SIGNAL PROCESS, V65, P267, DOI 10.1016/S0165-1684(97)00223-5
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Tu X., 2017, ULTRA DEEP NEURAL NE, P686
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang J., 2014, CORR, P1
   Yang JW, 2015, IEEE T INF FOREN SEC, V10, P797, DOI 10.1109/TIFS.2015.2403306
   Yang JS, 2013, IEEE GLOB COMM CONF, P1, DOI 10.1109/GLOCOM.2013.6831038
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 67
TC 11
Z9 12
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104428
DI 10.1016/j.imavis.2022.104428
EA MAR 2022
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0Z8MP
UT WOS:000791325900001
DA 2024-07-18
ER

PT J
AU Gu, WC
   Bai, S
   Kong, LX
AF Gu, Wenchao
   Bai, Shuang
   Kong, Lingxing
TI A review on 2D instance segmentation based on deep neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Instance segmentation; Deep neural networks; Computer vision; Review
ID IMAGE
AB Image instance segmentation involves labeling pixels of images with classes and instances, which is one of the pivotal technologies in many domains, such as natural scenes understanding, intelligent driving, augmented reality and medical image analysis. With the power of deep learning, instance segmentation methods that use this technique have recently achieved remarkable progress. In this survey, we mainly discuss the representative 2D instance segmentation methods based on deep neural networks. Firstly, we summarize current fully-, weakly and semi-supervised instance segmentation methods, and divide existing fully-supervised methods into three sub-categories depending on the number of stages. Based on our investigation, we conclude that currently, two-stage methods dominate the frontier of general instance segmentation; single-stage methods can achieve a better speed-accuracy trade-off, and multi-stage methods can achieve higher accuracy. Secondly, we introduce eleven datasets and three evaluation metrics for evaluating instance segmentation methods that can help researchers decide which one to choose to meet their needs and goals. Then the innovation and quantitative results of state-of-the-art general instance segmentation methods and specific instance segmentation methods (including salient instance segmentation, person instance segmentation, and amodal instance segmentation) are reviewed. In what follows, the common backbone networks are reviewed to better explain the reasons that why deep neural networks-based instance segmentation methods can achieve excellent performance. Finally, the future research directions and potential applications of instance segmentation are discussed, which can facilitates researchers to realize the existing technical difficulties and recent research hotspots.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Gu, Wenchao; Bai, Shuang] Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shang Yuan Cun, Beijing, Peoples R China.
   [Kong, Lingxing] China Elect Power Res Inst, State Key Lab Operat & Control Renewable Energy &, Beijing, Peoples R China.
RP Bai, S (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shang Yuan Cun, Beijing, Peoples R China.
EM shuangb@bjtu.edu.cn
RI Gu, Wenchao/JFS-6293-2023
OI Gu, Wenchao/0000-0002-0884-3542; Kong, Lingxing/0000-0002-0238-8497
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2002, P 10 ACM INT C MULT
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arnab A, 2017, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2017.100
   Arnab Anurag, 2016, ARXIV160902583
   Bai M, 2017, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2017.305
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Bellver M., 2019, IEEE C COMP VIS PATT, P93
   Benenson R, 2019, PROC CVPR IEEE, P11692, DOI 10.1109/CVPR.2019.01197
   Bolya D, 2019, ARXIV191206218
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Chen H., P IEEE CVF C COMP VI, P8573
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen L.C., P EUROPEAN C COMPUTE, P801
   Chen LC, 2018, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2018.00422
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2014, PROC CVPR IEEE, P3198, DOI 10.1109/CVPR.2014.409
   Chen XL, 2019, IEEE I CONF COMP VIS, P2061, DOI 10.1109/ICCV.2019.00215
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Cheng Bowen, 2021, ARXIV211201527
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai J., 2021, ICLR
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dai JF, 2016, LECT NOTES COMPUT SC, V9910, P534, DOI 10.1007/978-3-319-46466-4_32
   De Brabandere B., P IEEE C COMP VIS PA, P7
   De Brabandere B, 2017, IEEE COMPUT SOC CONF, P478, DOI 10.1109/CVPRW.2017.66
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dong Bin, 2021, ARXIV210602351
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   Fan R., P IEEE C COMP VIS PA, P6103
   Fang HS, 2019, IEEE I CONF COMP VIS, P682, DOI 10.1109/ICCV.2019.00077
   Fang Y., 2021, ICCV, P6910
   Fathi Alireza, 2017, Semantic instance segmentation via deep metric learning
   Follmann P, 2019, IEEE WINT CONF APPL, P1328, DOI 10.1109/WACV.2019.00146
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao NY, 2019, IEEE I CONF COMP VIS, P642, DOI 10.1109/ICCV.2019.00073
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550
   Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu Jie, 2021, ARXIV210500637
   Hu R, 2018, PROC CVPR IEEE, P4233, DOI 10.1109/CVPR.2018.00445
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Iglovikov V, 2018, IEEE COMPUT SOC CONF, P228, DOI 10.1109/CVPRW.2018.00042
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963
   Kisantal M., 2019, P 9 INT C ADV COMP I, DOI 10.5121/csit.2019.91713
   Kong S, 2018, PROC CVPR IEEE, P9018, DOI 10.1109/CVPR.2018.00940
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Laradji Issam H, 2019, ARXIV PREPRINT ARXIV
   Latorre-Carmona P, 2019, IMAGE VISION COMPUT, V86, P28, DOI 10.1016/j.imavis.2019.03.007
   Lee Y., P IEEE CVF C COMP VI, P13906
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li K, 2016, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2016.398
   Li K, 2016, LECT NOTES COMPUT SC, V9906, P677, DOI 10.1007/978-3-319-46475-6_42
   Li QZ, 2018, LECT NOTES COMPUT SC, V11219, P106, DOI 10.1007/978-3-030-01267-0_7
   Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472
   Liang XD, 2018, IEEE T PATTERN ANAL, V40, P2978, DOI 10.1109/TPAMI.2017.2775623
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu R, 2018, ADV NEUR IN, V31
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu S, 2017, IEEE I CONF COMP VIS, P3516, DOI 10.1109/ICCV.2017.378
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y., P EUR C COMP VIS ECC, P686
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Ze, 2021, arXiv
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maninis KK, 2018, IEEE T PATTERN ANAL, V40, P819, DOI 10.1109/TPAMI.2017.2700300
   Michaelis Claudio, 2018, ARXIV181111507
   Minaei S, 2022, INT J SPORT NUTR EXE, V32, P16, DOI 10.1123/ijsnem.2021-0090
   Minervini M, 2016, PATTERN RECOGN LETT, V81, P80, DOI 10.1016/j.patrec.2015.10.013
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Neven D, 2018, IEEE INT VEH SYM, P286
   Neven D, 2019, PROC CVPR IEEE, P8829, DOI 10.1109/CVPR.2019.00904
   Newell A, 2017, ADV NEUR IN, V30
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Paszke A, 2019, ADV NEUR IN, V32
   Pham T, 2018, LECT NOTES COMPUT SC, V11214, P3, DOI 10.1007/978-3-030-01249-6_1
   Pinheiro P.O., 2015, Learning to Segment Object Candidates
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Qi L, 2019, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR.2019.00313
   Pham QH, 2019, PROC CVPR IEEE, P8819, DOI 10.1109/CVPR.2019.00903
   Redmon J., 2018, P IEEE C COMP VIS PA
   Ren MY, 2017, PROC CVPR IEEE, P293, DOI 10.1109/CVPR.2017.39
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romera-Paredes B, 2016, LECT NOTES COMPUT SC, V9910, P312, DOI 10.1007/978-3-319-46466-4_19
   Rosenfeld, 2005, SEMISUPERVISED LEARN
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salvador Amaia, 2017, ARXIV171200617
   Savarese S., 2017, Joint 2d-3d-semantic data for indoor scene understanding
   Scharr H., 2014, EUROPEAN C COMPUTER, P6
   Scharr H, 2016, MACH VISION APPL, V27, P585, DOI 10.1007/s00138-015-0737-3
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shen XY, 2016, COMPUT GRAPH FORUM, V35, P93, DOI 10.1111/cgf.12814
   Shi XJ, 2015, ADV NEUR IN, V28
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   Sida Peng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8530, DOI 10.1109/CVPR42600.2020.00856
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sirinukunwattana K, 2017, MED IMAGE ANAL, V35, P489, DOI 10.1016/j.media.2016.08.008
   Song-Hai Zhang, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P889, DOI 10.1109/CVPR.2019.00098
   Sultana F, 2020, KNOWL-BASED SYST, V201, DOI 10.1016/j.knosys.2020.106062
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Sun P., P IEEE CVF C COMP VI, P14454
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan JG, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104129
   Tang Q, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104309
   Tian D., J ELECTRON IMAGING, V31
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Tripathi Subarna, 2017, ARXIV170401152
   Uhrig J, 2018, IEEE INT VEH SYM, P292, DOI 10.1109/IVS.2018.8500621
   Uhrig J, 2016, LECT NOTES COMPUT SC, V9796, P14, DOI 10.1007/978-3-319-45886-1_2
   Vaswani A, 2017, ADV NEUR IN, V30
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang Shaoru, 2019, ARXIV191205070
   Wang WY, 2018, PROC CVPR IEEE, P2569, DOI 10.1109/CVPR.2018.00272
   Wang X., 2020, Advances in Neural information processing systems
   Wang XL, 2019, PROC CVPR IEEE, P4091, DOI 10.1109/CVPR.2019.00422
   Wang Y., P IEEE CVF C COMP VI, P9313
   Wang Y., P IEEE CVF C COMP VI, P8741
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xinlong Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P649, DOI 10.1007/978-3-030-58523-5_38
   Xiong YW, 2019, PROC CVPR IEEE, P8810, DOI 10.1109/CVPR.2019.00902
   Xu WQ, 2019, IEEE I CONF COMP VIS, P5167, DOI 10.1109/ICCV.2019.00527
   Xu Y, 2017, IEEE T BIO-MED ENG, V64, P2901, DOI 10.1109/TBME.2017.2686418
   Yan Xu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P496, DOI 10.1007/978-3-319-46723-8_57
   Yang B., 2019, ADV NEURAL INFORM PR, P6740
   Yang LJ, 2019, IEEE I CONF COMP VIS, P5187, DOI 10.1109/ICCV.2019.00529
   Ying H., 2019, Embedmask: Embedding coupling for one-stage instance segmentation
   Zhang H, 2020, IEEE T IMAGE PROCESS, V29, P2078, DOI 10.1109/TIP.2019.2947806
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhang W., ADV NEURAL INF PROCE, V34
   Zhang YF, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104042
   Zhang ZY, 2016, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2016.79
   Zhang ZY, 2015, IEEE I CONF COMP VIS, P2614, DOI 10.1109/ICCV.2015.300
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zhi Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P282, DOI 10.1007/978-3-030-58452-8_17
   Zhou YZ, 2018, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2018.00399
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zhu Y, 2017, PROC CVPR IEEE, P3001, DOI 10.1109/CVPR.2017.320
NR 178
TC 66
Z9 70
U1 42
U2 251
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104401
DI 10.1016/j.imavis.2022.104401
EA FEB 2022
PG 31
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500002
DA 2024-07-18
ER

PT J
AU Sun, HW
   Wang, TY
   Yu, EL
AF Sun, Haowen
   Wang, Taiyong
   Yu, Enlin
TI A dynamic keypoint selection network for 6DoF pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dynamic keypoint selection; Scene feature fusion; 6 DoF pose estimation
AB 6 DoF pose estimation problem aims to estimate the rotation and translation parameters between two coordinates, such as object world coordinate and camera world coordinate. Although some advances are made with the help of deep learning, how to full use scene information is still a problem. Prior works tackle the problem by pixel-wise feature fusion but need to randomly select numerous points from images, which can not satisfy the demands of fast inference simultaneously and accurate pose estimation. In this work, we present a novel deep neural network based on dynamic keypoint selection designed for 6DoF pose estimation from a single RGBD image. Our network includes three parts, instance semantic segmentation, edge points detection and 6DoF pose estimation. Given an RGBD image, our network is trained to predict pixel category and the translation to edge points and center points. Then, a least-square fitting manner is applied to estimate the 6DoF pose parameters. Specifically, we propose a dynamic keypoint selection algorithm to choose keypoints from the foreground feature map. It allows us to leverage geometric and appearance information. During 6DoF pose estimation, we utilize the instance semantic segmentation result to filter out background points and only use foreground points to finish edge points detection and 6DoF pose estimation. Experiments on two commonly used 6DoF estimation benchmark datasets, YCB-Video and LineMoD, demonstrate that our method outperforms the state-of-the-art methods and achieves significant improvements over other same category methods time efficiency.(c) 2022 Published by Elsevier B.V.
C1 [Sun, Haowen; Wang, Taiyong; Yu, Enlin] Tianjin Univ, Sch Mech Engn, 135 Yaguan Rd,Haihe Educ Pk, Tianjin 300350, Peoples R China.
   [Wang, Taiyong] Tianjin Univ, Renai Coll, Tianjin 301636, Peoples R China.
C3 Tianjin University; Tianjin University
RP Wang, TY (corresponding author), Tianjin Univ, Sch Mech Engn, 135 Yaguan Rd,Haihe Educ Pk, Tianjin 300350, Peoples R China.
EM tyWang@tju.edu.cn
RI yan, su/KHT-1728-2024
FU National Natural Science Foundation of China [51975402]; Basic
   Innovation Team Program of China North Industries Group Corporation
   Limited [2017CX031]
FX Declaration of Competing Interest The authors declare that they have no
   known competing financial interests or personal relationships that could
   have appeared to influ-ence the work reported in this paper.This work is
   partially supported by the National Natural Science Foundation of China
   (No. 51975402) , the Basic Innovation Team Program of China North
   Industries Group Corporation Limited (No. 2017CX031) .
CR [Anonymous], 2017, 31 INT CONFNEURAL IN
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Besl P J, 1992, P SENSOR FUSION 4 CO, V1611, P586
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Buch AG, 2017, IEEE I CONF COMP VIS, P4137, DOI 10.1109/ICCV.2017.443
   Cai M., P IEEE CVF C COMP VI, P3153
   Calli B, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P510, DOI 10.1109/ICAR.2015.7251504
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Collet A, 2011, INT J ROBOT RES, V30, P1284, DOI 10.1177/0278364911401765
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y., P IEEE CVF C COMP VI, P3003
   He Y, P IEEE CVF C COMP VI, P11632
   Hinterstoisser S, 2011, IEEE I CONF COMP VIS, P858, DOI 10.1109/ICCV.2011.6126326
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Hodan T., P IEEE CVF C COMP VI, P11703
   Hu Q., P IEEE CVF C COMP VI, P11108
   Jurie F, 2001, PROC CVPR IEEE, P791
   Li C, 2018, LECT NOTES COMPUT SC, V11220, P263, DOI 10.1007/978-3-030-01270-0_16
   Li Y, 2018, LECT NOTES COMPUT SC, V11210, P695, DOI [10.1007/s11263-019-01250-9, 10.1007/978-3-030-01231-1_42]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   Mellado N, 2014, COMPUT GRAPH FORUM, V33, P205, DOI 10.1111/cgf.12446
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Tremblay J., PMLR, P306
   Vidal J, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P405, DOI 10.1109/ICCAR.2018.8384709
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Zakharov S, 2019, IEEE I CONF COMP VIS, P1941, DOI 10.1109/ICCV.2019.00203
   Zhang X, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103854
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou GL, 2021, IEEE T MULTIMEDIA, V23, P1630, DOI 10.1109/TMM.2020.3001533
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 46
TC 4
Z9 4
U1 3
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2022
VL 118
AR 104372
DI 10.1016/j.imavis.2022.104372
EA JAN 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0F3OZ
UT WOS:000777273700002
DA 2024-07-18
ER

PT J
AU Wu, PS
   Li, H
   Zeng, NY
   Li, FP
AF Wu, Peishu
   Li, Han
   Zeng, Nianyin
   Li, Fengping
TI FMD-Yolo: An efficient face mask detection method for COVID-19
   prevention and control in public
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face mask detection; COVID-19; Improved YoloV3 algorithm; Feature
   extraction and fusion
AB Coronavirus disease 2019 (COVID-19) is a world-wide epidemic and efficient prevention and control of this disease has become the focus of global scientific communities. In this paper, a novel face mask detection framework FMDYolo is proposed to monitor whether people wear masks in a right way in public, which is an effective way to block the virus transmission. In particular, the feature extractor employs Im-Res2Net-101 which combines Res2Net module and deep residual network, where utilization of hierarchical convolutional structure, deformable convolution and non-local mechanisms enables thorough information extraction from the input. Afterwards, an enhanced path aggregation network En-PAN is applied for feature fusion, where high-level semantic information and low-level details are sufficiently merged so that the model robustness and generalization ability can be enhanced. Moreover, localization loss is designed and adopted in model training phase, and Matrix NMS method is used in the inference stage to improve the detection efficiency and accuracy. Benchmark evaluation is performed on two public databases with the results compared with other eight state-of-the-art detection algorithms. At IoU = 0.5 level, proposed FMD-Yolo has achieved the best precision AP50 of 92.0% and 88.4% on the two datasets, and AP75 at IoU = 0.75 has improved 5.5% and 3.9% respectively compared with the second one, which demonstrates the superiority of FMD-Yolo in face mask detection with both theoretical values and practical significance. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wu, Peishu; Li, Han; Zeng, Nianyin] Xiamen Univ, Dept Instrumental & Elect Engn, Xiamen 361005, Fujian, Peoples R China.
   [Li, Fengping] Wenzhou Univ, Inst Laser & Optoelect Intelligent Mfg, Wenzhou 325035, Peoples R China.
C3 Xiamen University; Wenzhou University
RP Zeng, NY (corresponding author), Xiamen Univ, Dept Instrumental & Elect Engn, Xiamen 361005, Fujian, Peoples R China.
EM zny@xmu.edu.cn
RI Li, Han/JQT-3361-2023; Zeng, Nianyin/A-5094-2019
OI Zeng, Nianyin/0000-0002-6957-2942; Li, Han/0000-0003-0276-9756
CR [Anonymous], 2014, P INT C LEARN REPR
   Bassi A, 2021, J HOSP INFECT, V112, P127, DOI 10.1016/j.jhin.2021.02.020
   Bazarevsky V., 2019, ARXIV PREPRINT ARXIV
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chinrungrueng C., 1991, IJCNN 91 SEATTLE INT, V1, P855
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Ghiasi G, 2018, ADV NEUR IN, V31
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jain DK, 2020, PATTERN RECOGN LETT, V139, P157, DOI 10.1016/j.patrec.2017.06.025
   Jain DK, 2018, PATTERN RECOGN LETT, V115, P92, DOI 10.1016/j.patrec.2018.02.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Liao MR, 2021, CURR OPIN COLLOID IN, V52, DOI 10.1016/j.cocis.2021.101417
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu R., P 32 INT C NEUR INF, P9628
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loey Mohamed, 2021, Sustain Cities Soc, V65, P102600, DOI 10.1016/j.scs.2020.102600
   Mahbub U, 2019, IMAGE VISION COMPUT, V82, P1, DOI 10.1016/j.imavis.2018.12.003
   Meivel S., 2021, MATER TODAY-PROC
   Rahmani AM, 2021, SUSTAIN CITIES SOC, V64, DOI 10.1016/j.scs.2020.102568
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Sun K., 2019 IEEE C COMP VIS, P5693
   Tan M., 2020 IEEE CVF C COMP, P10781
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang X., 2020, ADV NEURAL INFORM PR, V33, P17721, DOI DOI 10.48550/ARXIV.2003.10152
   Wu DH, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105742
   Wu SK, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103911
   Ye XY, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103978
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zeng NY, 2023, NEURAL COMPUT APPL, V35, P11599, DOI 10.1007/s00521-021-06149-6
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zheng GY, 2021, INFORM SCIENCES, V568, P265, DOI 10.1016/j.ins.2021.03.027
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 45
TC 78
Z9 79
U1 17
U2 180
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104341
DI 10.1016/j.imavis.2021.104341
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4VF
UT WOS:000772585200003
PM 34848910
OA Green Published
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Li, X
AF Zhang, Qing
   Li, Xiang
TI Salient object detection network with multi-scale feature refinement and
   boundary feedback
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; Saliency detection; Multi-scale features;
   Boundary; Attention
ID MODEL
AB Benefiting from the development of convolutional neural networks, salient object detection has achieved prominent progress in recent years. However, there are still two limitations when handling challenging scenarios. On the one hand, upsampling and pooling operations might cause blurry boundaries. On the other hand, multi-level features having different characteristics might incur fusion problems. To address these issues, we propose a novel pixel-wise salient object detection method equipped with multi-scale feature refinement and boundary feedback in this paper. Firstly, a feature interaction scheme is designed to depict the multi-scale representation of side output features and the interactions between intra-layer features. Secondly, we design a context-aware feature refinement module to adaptively select useful side-output information for generating coarse saliency features. Finally, we obtain the predicted saliency maps with the help of extracted boundary information in a coarse-to-fine manner. Extensive experimental results on four benchmark datasets show that our proposed model performs favorably against state-of-the-art methods. (c) 2021 Published by Elsevier B.V.
C1 [Zhang, Qing; Li, Xiang] Sch Comp Sci & Informat Engn, Shanghai Inst Technol, Shanghai 201418, Peoples R China.
C3 Shanghai Institute of Technology
RP Zhang, Q (corresponding author), Sch Comp Sci & Informat Engn, Shanghai Inst Technol, Shanghai 201418, Peoples R China.
EM zhangqing@sit.edu.cn
FU Natural Science Foundation of Shanghai [19ZR1455300, 21ZR1462600];
   National Natu-ral Science Foundation of China [61806126]
FX This work is supported by Natural Science Foundation of Shanghai under
   Grant Nos. 19ZR1455300 and 21ZR1462600, and National Natu-ral Science
   Foundation of China Under Grant No. 61806126.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2011, ADV NEURAL INF PROCE
   [Anonymous], 2017, C COMP VIS PATT REC
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9
   Cai Q, 2019, PATTERN RECOGN, V93, P147, DOI 10.1016/j.patcog.2019.04.019
   Chen SH, 2020, IEEE T CYBERNETICS, V50, P2050, DOI 10.1109/TCYB.2018.2879859
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Craye C, 2016, IEEE INT CONF ROBOT, P2303, DOI 10.1109/ICRA.2016.7487379
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li JY, 2021, IEEE T CYBERNETICS, V51, P3925, DOI 10.1109/TCYB.2020.3008280
   Li JX, 2021, IEEE T MULTIMEDIA, V23, P1397, DOI 10.1109/TMM.2020.2997192
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu JJ, 2020, IEEE T IMAGE PROCESS, V29, P8652, DOI 10.1109/TIP.2020.3017352
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu Y, 2022, IEEE T CYBERNETICS, V52, P6131, DOI 10.1109/TCYB.2021.3051350
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Máttyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372
   Mohammadi S, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107303
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Simonyan K., 2014, P INT C COMP VIS PAT
   Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y., 2021, P2T PYRAMID POOLING
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xu YY, 2019, IEEE I CONF COMP VIS, P3788, DOI 10.1109/ICCV.2019.00389
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang Q, 2020, NEUROCOMPUTING, V411, P268, DOI 10.1016/j.neucom.2020.05.083
   Zhang Q, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107484
   Zhang Q, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P582, DOI 10.1145/3240508.3240595
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
NR 64
TC 0
Z9 0
U1 2
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104326
DI 10.1016/j.imavis.2021.104326
EA NOV 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WZ2LF
UT WOS:000719802700004
DA 2024-07-18
ER

PT J
AU Sun, YD
   Yin, J
   Wu, CH
   Zheng, KF
   Niu, XX
AF Sun, Yudao
   Yin, Juan
   Wu, Chunhua
   Zheng, KangFeng
   Niu, XinXin
TI Generating facial expression adversarial examples based on saliency map
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Adversarial example; Facial expression adversarial example; Saliency
   map; Facial expression recognition
ID RECOGNITION; EMOTION
AB The security demands in humanization should be considered as important, because artificial intelligence is developing rapidly in this area. Recent studies have shown the vulnerability of many deep learning models to adversarial examples; however, only a few studies on facial expression adversarial examples have been conducted. Thus, in this paper, we propose a novel method for generating facial expression adversarial examples using facial saliency maps and facial masking maps. Extensive numerical experiments demonstrate the outstanding performance of our method in terms of attack accuracy, structural similarity index measure score, and computational time, compared with other leading methods, such as the fast gradient sign method, projected gradient descent method, and Carlini-Wagner attacks. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Sun, Yudao; Wu, Chunhua; Zheng, KangFeng; Niu, XinXin] Beijing Univ Posts & Telecommun, Sch Cyberspace Secur, Beijing, Peoples R China.
   [Yin, Juan] Beijing Inst Technol, Sch Management & Econ, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing Institute of
   Technology
RP Wu, CH (corresponding author), Beijing Univ Posts & Telecommun, Sch Cyberspace Secur, Beijing, Peoples R China.
EM wuchunhua@bupt.edu.cn
OI wu, chunhua/0000-0003-0535-6236
FU National Key R&D Program of China [2017YFB0802800]
FX Thisworkwas supported by the National Key R&D Program of China under
   Grant 2017YFB0802800. We would like to thank the editor and reviewers
   for their detailed and valuable comments, which helped improve our
   paper.
CR Abd Latif M. H., 2015, 2015 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS), P214, DOI 10.1109/IRIS.2015.7451614
   Altameem T, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104044
   [Anonymous], 2014, WORKSHOP INT C LEARN
   [Anonymous], 2015, 2015 ANN IEEE INDICO
   Bose A, 2018, ARXIV180512302
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Cruz AC, 2014, IEEE T AFFECT COMPUT, V5, P418, DOI 10.1109/TAFFC.2014.2316151
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Engstrom L., 2017, A rotation and a translation suffice: Fooling cnns with simple transformations
   Flynn Jeremy R., 2013, Engineering Psychology and Cognitive Ergonomics. Understanding Human Cognition. 10th International Conference, EPCE 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8019, P23, DOI 10.1007/978-3-642-39360-0_3
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109
   Kanbak C., 2017, ARXIV171109115
   Kurakin A., 2016, WORKSHOP TRACK P
   Li HY, 2019, IMAGE VISION COMPUT, V83-84, P70, DOI 10.1016/j.imavis.2019.02.005
   Li XL, 2015, SIGNAL PROCESS, V108, P297, DOI 10.1016/j.sigpro.2014.09.033
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Luo RH, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103876
   Lyons MJ., 1998, The Japanese female facial expression (JAFFE) database
   Madry A., 2018, ARXIV
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Shih FY, 2008, INT J PATTERN RECOGN, V22, P445, DOI 10.1142/S0218001408006284
   Shunan Zhao, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4813, DOI 10.1109/ICASSP.2014.6854516
   Sun YD, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421520169
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wei-Lun Chao, 2015, Signal Processing, V117, P1, DOI 10.1016/j.sigpro.2015.04.007
   Wiyatno R., 2018, ARXIV180807945
   Xiao CW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3905
   Yanbin Sun, 2010, 2010 2nd IEEE International Conference on Information Management and Engineering (ICIME 2010), P727, DOI 10.1109/ICIME.2010.5477962
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
   Zhou XF, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103888
NR 34
TC 6
Z9 6
U1 2
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104318
DI 10.1016/j.imavis.2021.104318
EA NOV 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WU6KE
UT WOS:000716651500005
DA 2024-07-18
ER

PT J
AU Wang, HX
   Chen, X
   Liu, C
AF Wang, HongXia
   Chen, Xiang
   Liu, Chun
TI Pose-guided part matching network via shrinking and reweighting for
   occluded person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Pose estimation; Graph matching; Soft
   thresholding
AB Occluded person re-identification (ReID) isa challenging task, which aims at retrieving an occluded person across multiple non-overlapping cameras. To address this issue, we propose a novel framework named Shrinking and Reweighting Network (SRNet) that jointly learns global features by shrinking and reweights part features for matching in an end-to-end framework. Specifically, we use a strong backbone that combines some effective de-signs and training tricks to learn the robust and discriminative global features. Even so, there exist noise-related features due to the occlusion, so we utilize the Deep Residual Shrinkage Module (DRS Module) to eliminate un-important features by automatically determining the soft thresholds. When aligning two groups of part features from two images, we view it as a graph matching problem and design an effectively Reweight Module for Part Matching (RMPM) to learn self-adaptive weights for part features before the part matching stage, the proposed RMPM can alleviate the influence of meaningless part features in the part matching stage. Eventually, extensive experimental results on occluded, partial, and holistic re-id datasets clearly demonstrate that the proposed method achieves competitive performance to the state-of-the-art methods. Specifically, our framework remark-ably outperforms state-of-the-art by 8.9% mAP scores on Occluded-Duke dataset. Code is available at https:// github.com/chenxiangzZ/SRNet. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wang, HongXia; Chen, Xiang; Liu, Chun] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430070, Peoples R China.
C3 Wuhan University of Technology
RP Liu, C (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430070, Peoples R China.
EM liuchun@whut.edu.cn
RI Wang, Peiyun/JVE-1196-2024; zhou, bolin/KHX-0072-2024
OI Chen, Xiang/0000-0002-1594-3488
CR [Anonymous], 2019, ABS190703253 CORR
   FAN X, 2018, P AS C COMP VIS, P19, DOI DOI 10.1007/978-3-030-20890-5_2
   Feng J., P IEEE CVF INT C COM, P8450
   Gong SG, 2011, VISUAL ANALYSIS OF BEHAVIOUR: FROM PIXELS TO SEMANTICS, P301, DOI 10.1007/978-0-85729-670-2_14
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   He LH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P364
   Hermans Alexander, 2017, ARXIV170307737
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Huang HY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI [10.1002/pra2.374, 10.1145/3313831.3376476]
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liao SC, 2013, IEEE T PATTERN ANAL, V35, P1193, DOI 10.1109/TPAMI.2012.191
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan HL, 2020, IEEE ACCESS, V8, P63632, DOI 10.1109/ACCESS.2020.2984915
   Ulyanov Dmitry, 2016, arXiv
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang RZ, 2019, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2019.00315
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zanfir A, 2018, PROC CVPR IEEE, P2684, DOI 10.1109/CVPR.2018.00284
   Zhang Xucong, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), V41, P162
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao MH, 2020, IEEE T IND INFORM, V16, P4681, DOI 10.1109/TII.2019.2943898
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 44
TC 8
Z9 8
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104186
DI 10.1016/j.imavis.2021.104186
EA MAY 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700013
DA 2024-07-18
ER

PT J
AU Aslan, S
   Güdükbay, U
   Dibeklioglu, H
AF Aslan, Suleyman
   Gudukbay, Ugur
   Dibeklioglu, Hamdi
TI Multimodal assessment of apparent personality using feature attention
   and error consistency constraint
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Apparent personality; Multimodal modeling; Information
   fusion; Feature attention; Error consistency
ID 5-FACTOR MODEL; TRAITS; RECOGNITION; PERCEPTION; AUDIO; MUSIC; LIFE
AB Personality computing and affective computing, where the recognition of personality traits is essential, have gained increasing interest and attention in many research areas recently. We propose a novel approach to recognize the Big Five personality traits of people from videos. To this end, we use four different modalities, namely, ambient appearance (scene), facial appearance, voice, and transcribed speech. Through a specialized subnetwork for each of these modalities, our model learns reliable modality-specific representations and fuse them using an attention mechanism that re-weights each dimension of these representations to obtain an optimal combination of multimodal information. A novel loss function is employed to enforce the proposed model to give an equivalent importance for each of the personality traits to be estimated through a consistency constraint that keeps the trait-specific errors as close as possible. To further enhance the reliability of our model, we employ (pre-trained) state-of-the-art architectures (i.e., ResNet, VGGish, ELMo) as the backbones of the modality-specific subnetworks, which are complemented by multilayered Long Short-Term Memory networks to capture temporal dynamics. To minimize the computational complexity of multimodal optimization, we use two-stage modeling, where the modality-specific subnetworks are first trained individually, and the whole network is then finetuned to jointly model multimodal data. On the large scale ChaLearn First Impressions V2 challenge dataset, we evaluate the reliability of our model as well as investigating the informativeness of the considered modalities. Experimental results show the effectiveness of the proposed attention mechanism and the error consistency constraint. While the best performance is obtained using facial information among individual modalities, with the use of all four modalities, our model achieves a mean accuracy of 91.8%, improving the state of the art in automatic personality analysis.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Aslan, Suleyman; Gudukbay, Ugur; Dibeklioglu, Hamdi] Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Dibeklioglu, H (corresponding author), Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
EM suleyman.aslan@bilkent.edu.tr; gudukbay@cs.bilkent.edu.tr;
   dibeklioglu@cs.bilkent.edu.tr
RI Gudukbay, Ugur/F-1012-2011
OI Gudukbay, Ugur/0000-0003-2462-6959
CR Abu-El-Haija S., 2016, ABS160908675 CORR
   [Anonymous], 2013, AAAI WORKSHOP
   [Anonymous], 2014, P ACM MULT MED WORKS
   [Anonymous], 2008, P ICMI 2008, DOI DOI 10.1145/1452392.1452404
   [Anonymous], 2013, CEUR WORKSH P SHLOM
   Arapakis I, 2009, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2009.5202773
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Basak AE, 2018, COMPUT GRAPH-UK, V72, P70, DOI 10.1016/j.cag.2018.02.004
   Batrinca L, 2011, P 13 INT C MULT INT, P255, DOI [DOI 10.1145/2070481.2070528, 10.1145/2070481.2070528]
   Batrinca L, 2016, IEEE T MULTIMEDIA, V18, P659, DOI 10.1109/TMM.2016.2522763
   Bekhouche SE, 2017, IEEE COMPUT SOC CONF, P1660, DOI 10.1109/CVPRW.2017.211
   Bera A, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P112
   BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324
   Çeliktutan O, 2017, IEEE T AFFECT COMPUT, V8, P29, DOI 10.1109/TAFFC.2015.2513401
   Cervone D., 2013, PERSONALITY THEORY R, V12th
   ChaLearn, 1 IMPR V2 CVPR 17 DA
   Chamorro-Premuzic T, 2007, BRIT J PSYCHOL, V98, P175, DOI 10.1348/000712606X111177
   Chelba C., 2013, CORR ABS13123005
   Chen BY, 2016, LECT NOTES COMPUT SC, V9915, P419, DOI 10.1007/978-3-319-49409-8_33
   Cucurull G., 2018, ARXIV PREPRINT ARXIV
   Deniz ME, 2011, KURAM UYGUL EGIT BIL, V11, P105
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Escalante H. J., 2020, IEEE T AFFECT COMPUT
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Farnadi G, 2016, USER MODEL USER-ADAP, V26, P109, DOI 10.1007/s11257-016-9171-0
   Fernando T, 2016, ADV COMP SCI, V5, P40
   Fink B, 2005, PERS INDIV DIFFER, V39, P523, DOI 10.1016/j.paid.2005.02.002
   GOLDBERG LR, 1993, AM PSYCHOL, V48, P26, DOI 10.1037/0003-066X.48.1.26
   Güçlütürk Y, 2018, IEEE T AFFECT COMPUT, V9, P316, DOI 10.1109/TAFFC.2017.2751469
   Gucluturk Y, 2016, LECT NOTES COMPUT SC, V9915, P349, DOI 10.1007/978-3-319-49409-8_28
   Gürpinar F, 2016, INT C PATT RECOG, P43, DOI 10.1109/ICPR.2016.7899605
   Gürpinar F, 2016, LECT NOTES COMPUT SC, V9915, P372, DOI 10.1007/978-3-319-49409-8_30
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hu R, 2010, LECT NOTES COMPUT SC, V6075, P291
   Kahneman D, 2015, FORTUNE, V172, P20
   KASMAR JV, 1968, J CONSULT CLIN PSYCH, V32, P223, DOI 10.1037/h0025618
   Kaya H, 2017, IEEE COMPUT SOC CONF, P1651, DOI 10.1109/CVPRW.2017.210
   Lin JJ, 2017, KNOWL-BASED SYST, V132, P204, DOI 10.1016/j.knosys.2017.06.031
   Little AC, 2007, BRIT J PSYCHOL, V98, P111, DOI 10.1348/000712606X109648
   Madzlan N.A., P ANN C INT SPEECH C, P1826
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   MCCRAE RR, 1987, J PERS SOC PSYCHOL, V52, P81, DOI 10.1037/0022-3514.52.1.81
   Mehl MR, 2006, J PERS SOC PSYCHOL, V90, P862, DOI 10.1037/0022-3514.90.5.862
   Nass C, 2001, J EXP PSYCHOL-APPL, V7, P171, DOI 10.1037//1076-898X.7.3.171
   Pfister HR, 2008, JUDGM DECIS MAK, V3, P5
   Picard R.W., 2000, Affective Computing
   Ponce-López V, 2016, LECT NOTES COMPUT SC, V9915, P400, DOI 10.1007/978-3-319-49409-8_32
   Qin RZ, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-016-9174-0
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Recio-Garca J.A., 2009, RecSys, P325
   Rentfrow PJ, 2003, J PERS SOC PSYCHOL, V84, P1236, DOI 10.1037/0022-3514.84.6.1236
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarkar Chandrima, 2014, P 2014 ACM MULT WORK, P11
   Segalin C, 2017, COMPUT VIS IMAGE UND, V156, P34, DOI 10.1016/j.cviu.2016.10.013
   Shen LP, 2009, EDUC TECHNOL SOC, V12, P176
   Stemmler G, 2010, BIOL PSYCHOL, V84, P541, DOI 10.1016/j.biopsycho.2009.09.012
   Subramaniam A, 2016, LECT NOTES COMPUT SC, V9915, P337, DOI 10.1007/978-3-319-49409-8_27
   Subramanian R, 2018, IEEE T AFFECT COMPUT, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Tkalcic M, 2016, HUM-COMPUT INT-SPRIN, P3, DOI 10.1007/978-3-319-31413-6_1
   Tlili A, 2016, COMPUT HUM BEHAV, V64, P805, DOI 10.1016/j.chb.2016.07.043
   TUPES EC, 1992, J PERS, V60, P225, DOI 10.1111/j.1467-6494.1992.tb00973.x
   Valente F, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1182
   Van Lier et R., 2019, IEEE T AFFECT COMPUT
   Ventura C, 2017, IEEE COMPUT SOC CONF, P1705, DOI 10.1109/CVPRW.2017.217
   Vernon RJW, 2014, P NATL ACAD SCI USA, V111, pE3353, DOI 10.1073/pnas.1409860111
   Vinciarelli A, 2014, IEEE T AFFECT COMPUT, V5, P273, DOI 10.1109/TAFFC.2014.2330816
   Wei XS, 2018, IEEE T AFFECT COMPUT, V9, P303, DOI 10.1109/TAFFC.2017.2762299
   Xu M, 2004, LECT NOTES COMPUT SC, V3333, P566
   Yan Yan, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P540, DOI 10.1007/978-3-319-27671-7_45
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang CL, 2016, LECT NOTES COMPUT SC, V9915, P311, DOI 10.1007/978-3-319-49409-8_25
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 74
TC 13
Z9 13
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104163
DI 10.1016/j.imavis.2021.104163
EA APR 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700005
DA 2024-07-18
ER

PT J
AU Aslam, A
   Curry, E
AF Aslam, Asra
   Curry, Edward
TI A Survey on Object Detection for the Internet of Multimedia Things
   (IoMT) using Deep Learning and Event-based Middleware: Approaches,
   Challenges, and Future Directions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Internet of Multimedia Things; Event Processing; Multimedia Events;
   Object Detection; Smart Cities; Deep Neural Networks; Machine Learning
ID BIG DATA; IOT; TAXONOMY; VISION
AB An enormous amount of sensing devices (scalar or multimedia) collect and generate information (in the form of events) over the Internet of Things (IoT). Present research on IoT mainly focus on the processing of scalar sensor data events and barely considers the challenges posed by multimedia based events. In this paper, we systematically review the existing solutions available for the Internet of Multimedia Things (IoMT) by analyzing sensing, networking, service, and application-level services provided by IoT. We present state-of-the-art event-based middleware methods and their suitability for multimedia event processing methods. We observe that existing IoT event-based middleware solutions focus on structured (scalar) events and possess only domain-specific characteristics for unstructured (multimedia) events. A case study for object detection is also presented to demonstrate the requirements associated with the processing of multimedia events within smart cities, even with common image recognition based applications. In order to validate the existing issues in the detection of objects, we also presented an evaluation of object detection models using existing datasets. At the end of each section, we shed light on trends, gaps, and possible solutions based on our analysis, experiments, and review of the existing research. Finally, we summarize the challenges and future research directions for the generalized multimedia event processing (by taking detection of each and every object as an example) based on applications using IoMT. Our experiments demonstrate that existing models are very slow to respond to any unseen class, and existing rich datasets do not have a sufficient number of classes to meet the requirements of real-time applications of smart cities. We show that although there is a significantly large technical literature on IoT, and research on IoMT is also quite actively growing, there have not been much research efforts directed towards the processing of multimedia events. As an example, although deep learning techniques have been shown to achieve impressive performance in applications like image recognition, the methods are deficient in detecting new (previously unseen) objects for multimedia based applications in smart cities. In light of these facts, it becomes imperative to conduct research on bringing together the abilities of event-based middleware for IoMT, and low response-time based online training and adaptation techniques. (C) 2020 The Author(s). Published by Elsevier B.V.
C1 [Aslam, Asra; Curry, Edward] NUI Galway, Insight Ctr Data Analyt, Galway, Ireland.
C3 Ollscoil na Gaillimhe-University of Galway
RP Aslam, A (corresponding author), NUI Galway, Insight Ctr Data Analyt, Galway, Ireland.
EM asra.aslam@insight-centre.org; edward.curry@insight-centre.org
RI Aslam, Asra/GLT-8541-2022
OI Aslam, Asra/0000-0002-2654-4255; Curry, Edward/0000-0001-8236-6433
FU Science Foundation Ireland (SFI) [SFI/12/RC/2289_P2]; European Regional
   Development Fund
FX This publication has emanated from research supported in part by a
   research grant from Science Foundation Ireland (SFI) under Grant Number
   SFI/12/RC/2289_P2, co-funded by the European Regional Development Fund.
   The Titan Xp used for this research was donated by the NVIDIA
   Corporation.
CR Aggarwal Charu C, 2012, A survey of text clustering algorithms, P163, DOI [10.1007/978-1-4614-3223-4, DOI 10.1007/978-1-4614-3223-46]
   Aggarwal Gaurav, 2002, US PATENT
   Ahmad K, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3306240
   AHMAD S, 2017, MED WORKSH DUBL IR
   Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Aliyu A, 2018, COMPUT COMMUN, V118, P93, DOI 10.1016/j.comcom.2017.10.003
   Alvi SA, 2015, AD HOC NETW, V33, P87, DOI 10.1016/j.adhoc.2015.04.006
   Angsuchotmetee C, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES 2016), P99, DOI 10.1145/3012071.3012098
   [Anonymous], P 2020 INT C MULT RE, P373
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   Aslam A, 2018, IEEE ACCESS, V6, P25573, DOI 10.1109/ACCESS.2018.2823590
   Aslam Asra, P 2020 INT C MULT RE, P261
   Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555
   Bacon J, 2000, COMPUTER, V33, P68, DOI 10.1109/2.825698
   Bascol K, 2019, IEEE IMAGE PROC, P3043, DOI [10.1109/icip.2019.8803325, 10.1109/ICIP.2019.8803325]
   Bera S, 2018, IEEE INT CONF COMM
   Bergstra J., P 30 INT C INT C MAC, V28
   Bischke Benjamin., 2017, The Multimedia Satellite Task at MediaEval
   Boll S, 2018, IEEE MULTIMEDIA, V25, P51, DOI 10.1109/MMUL.2018.011921235
   Boonma Pruet, 2012, WIRELESS TECHNOLOGIE, P819
   Botterman Maarten, 2009, WORKSHOP REPORT, P15
   Burcea I, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P39
   Cahill Vinny, 2003, LOCATION AWARE EVENT
   Carzaniga A, 2001, ACM T COMPUT SYST, V19, P332, DOI 10.1145/380749.380767
   Carzaniga A., 2000, Proceeding of the Nineteenth Annual ACM Symposium on Principles of Distributed Computing, P219, DOI 10.1145/343477.343622
   Chen SC, 2010, INT J MULTIMED DATA, V1, P1, DOI 10.4018/jmdem.2010111201
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Chou Philip A., 2011, MULTIMEDIA IP WIRELE
   Colakovic A, 2018, COMPUT NETW, V144, P17, DOI 10.1016/j.comnet.2018.07.017
   Cugola G, 2001, IEEE T SOFTWARE ENG, V27, P827, DOI 10.1109/32.950318
   Cugola G., 2002, ACM SIGMOBILE Mobile Computing and Communications Review, V6, P25
   Cugola G, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2187671.2187677
   Cullen Cam, 2020, GLOBAL INTERNET PHEN
   Curry Edward, 2019, P EYRE 19 2 INT WORK
   Curry Edward, 2004, MIDDLEWARE COMMUN, P1
   Curry Edward, 2020, INT J GRAPH COMPUT, V1, P23
   Curry Edward, ARXIV200800928
   Dai JF, 2016, ADV NEUR IN, V29
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davies S., 2005, Websphere mq v6 fundamentals
   Döller M, 2008, IEEE MULTIMEDIA, V15, P82, DOI 10.1109/MMUL.2008.96
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Du Terrail Jean Ogier, ARXIV180903193
   Dunkels A., 2008, WHITE PAPER 1
   Elgala Hany, 2018, MULTIMED TOOLS APPL, P1
   Elshafeey Ahmed, 2017, International Journal of Cyber-Security and Digital Forensics, V6, P44
   Eugster PT, 2003, ACM COMPUT SURV, V35, P114, DOI 10.1145/857076.857078
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fernandez Gustavo, 2008, P 11 INT IEEE C INTE, P950, DOI DOI 10.1109/ITSC.2008.4732555
   Fiege L, 2006, IEEE INTERNET COMPUT, V10, P48, DOI 10.1109/MIC.2006.17
   Fiege L, 2003, LECT NOTES COMPUT SC, V2672, P103
   Fiege L, 2002, LECT NOTES COMPUT SC, V2374, P309
   Fiege L., 2000, REBECA EVENT BASED E
   Fielding Roy Thomas, 2000, Architectural styles and the design of network-based software architectures, Patent No. AAI9980887
   Floris A, 2015, IEEE INT CONF COMM, P1747, DOI 10.1109/ICCW.2015.7247433
   Frances Carlos R., 2005, P 3 INT IFIP ACM LAT, P1
   Frank Nack, 2002, SYNTAX MULTIMEDIA SE
   Gama K, 2012, COMPUT COMMUN, V35, P405, DOI 10.1016/j.comcom.2011.11.003
   Gao Huang, P IEEE INT C COMP VI, P1891
   Gauen K, 2017, 2017 IEEE 18TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI 2017), P346, DOI 10.1109/IRI.2017.59
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gershenfeld N., 2004, Scientific American, V291, P76, DOI DOI 10.1038/SCIENTIFICAMERICAN1004-76
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guan L, 2012, IMAGE PROCESS SER, P1, DOI 10.1201/b11716
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Guinard Dominique., 2009, Workshop on Mashups, Enterprise Mashups and Lightweight Composition on the Web (MEM 2009), in proceedings of WWW (International World Wide Web Conferences), Madrid, Spain, P15
   Guo X, 2019, SMART CITIES-BASEL, V2, P402, DOI 10.3390/smartcities2030025
   Guo YH, 2019, AAAI CONF ARTIF INTE, P8368
   Haahr M, 2000, INTERNATIONAL SYMPOSIUM ON SOFTWARE ENGINEERING FOR PARALLEL AND DISTRIBUTED SYSTEMS, PROCEEDINGS, P83, DOI 10.1109/PDSE.2000.847853
   Haifeng Liu, 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P1107
   Hasan S., 2012, Proc. 6th ACM Int'l Conf. on Distributed Event-Based Systems (DEBS '12), P252, DOI DOI 10.1145/2335484.2335512
   Hasan Souleiman, 2016, Loose Coupling in Heterogeneous Event-Based Systems Via Approximate Semantic Matching and Dynamic Enrichment
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hengstler S, 2006, 2006 2ND INTERNATIONAL CONFERENCE ON TESTBEDS AND RESEARCH INFRASTRUCTURES FOR THE DEVELOPMENT OF NETWORKS & COMMUNITIES, P86
   Hoffman J., 2014, NIPS (News Physiol. Sci.), P3536
   Hoffman Judith, 2016, Adaptive learning algorithms for transferable visual recognition
   Hoffman M., 2010, ADV NEURAL INFORM PR, V23, P856
   Hoi SCH, 2014, J MACH LEARN RES, V15, P495
   Hou SH, 2019, PROC CVPR IEEE, P831, DOI 10.1109/CVPR.2019.00092
   Hu L, 2018, IEEE INTERNET THINGS, V5, P747, DOI 10.1109/JIOT.2017.2705560
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Huang J, 2017, IEEE INTERNET THINGS, V4, P215, DOI 10.1109/JIOT.2016.2642643
   Hui TKL, 2017, FUTURE GENER COMP SY, V76, P358, DOI 10.1016/j.future.2016.10.026
   Trinh H, 2018, IEEE T MULTIMEDIA, V20, P2562, DOI 10.1109/TMM.2018.2865661
   in cooperation with the Working Group, 2008, RFID ETP EPOSS INFSO
   Information Society European Commission and Media, 2008, NFSO D 4NETWORKED EN
   Inoue N, 2018, PROC CVPR IEEE, P5001, DOI 10.1109/CVPR.2018.00525
   ITU Internet Reports, 2005, INTERNET REPORTS 200
   Javier Hidalgo-Carrio, P IEEE CVF C COMP VI, P3586
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Jridi Maher, 2018, Journal of Low Power Electronics and Applications, V8, DOI 10.3390/jlpea8010001
   Kamilaris Andreas, 2018, ARXIV180711805
   Katasonov A, 2008, ICINCO 2008: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL ICSO, P169
   Khedo K.K., 2006, P 2 INT C WIR COMM S, P207
   Khedo Kavi K., 2007, 2007 3 INT C WIR COM, P31
   Khodabandeh M, 2019, IEEE I CONF COMP VIS, P480, DOI 10.1109/ICCV.2019.00057
   Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991
   Krasin I., Open-images: A public dataset for large-scale multi-label and multi-class image classification
   Küçükkeçeci C, 2018, BIG DATA RES, V11, P33, DOI 10.1016/j.bdr.2017.09.003
   Kudyba S, 2014, BIG DATA, MINING, AND ANALYTICS: COMPONENTS OF STRATEGIC DECISION MAKING, P1
   Kumar Ashish, 2019 6 INT C SIGN PR, P472
   Kumari A, 2018, J NETW COMPUT APPL, V124, P169, DOI 10.1016/j.jnca.2018.09.014
   Kuo TCT, 2000, IEEE T MULTIMEDIA, V2, P1, DOI 10.1109/6046.825790
   Kuroki S, 2019, AAAI CONF ARTIF INTE, P4122
   Kuznetsova Alina, ARXIV181100982
   Lai CH, 2010, CONF TECHNOL APPL, P195, DOI 10.1109/TAAI.2010.41
   Lai S, 2009, INT CONF PERVAS COMP, P625
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Haifeng, 2004, P 30 INT C VER LARG, V30, P1281
   Liu HF, 2004, PROC INT CONF DATA, P510, DOI 10.1109/ICDE.2004.1320023
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2016, PROCEDIA COMPUT SCI, V91, P566, DOI 10.1016/j.procs.2016.07.144
   Lopez-Fuentes L., 2017, MediaEval, P1
   Lu Chenglang, 2015, Int. J. Database Theory Appl, V8, P235, DOI DOI 10.14257/IJDTA.2015.8.3.20
   Ma J., 2009, P 26 ANN INT C MACH, P681, DOI DOI 10.1145/1553374.1553462
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   Manjunath TN, 2010, INT J COMPUT SCI NET, V10, P165
   Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979
   Maybury M.T., 1997, Intelligent multimedia information retrieval
   Meier R, 2005, LECT NOTES COMPUT SC, V3543, P115
   Meier R, 2005, COMPUT J, V48, P602, DOI 10.1093/comjnl/bxh120
   Meier R, 2002, 22ND INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOP, PROCEEDINGS, P639, DOI 10.1109/ICDCSW.2002.1030841
   Meier Rene, 2005, IFIP INT C DISTR APP, P1
   Min Wu, P IEEE CVF C COMP VI, P311
   Mohammadi M, 2018, IEEE COMMUN SURV TUT, V20, P2923, DOI 10.1109/COMST.2018.2844341
   Mohapatra Badri, 2019, ACCENTS T IMAGE PROC, V4
   Molina J, 2010, WIRELESS SENSOR NETWORKS: APPLICATION-CENTRIC DESIGN, P449
   Musolesi M, 2006, PERS UBIQUIT COMPUT, V10, P28, DOI 10.1007/s00779-005-0037-4
   Mustamo Pirkko, 2018, OBJ DET SPORTS TENS
   Nauman A, 2020, IEEE ACCESS, V8, P8202, DOI 10.1109/ACCESS.2020.2964280
   Nordrum A, 2016, IEEE SPECTRUM, V53, P12, DOI 10.1109/MSPEC.2016.7572524
   Noura H, 2018, MULTIMED TOOLS APPL, V77, P18383, DOI 10.1007/s11042-018-5660-y
   Object Management Group, 2000, CORB COMM OBJ SERV S
   ObjectManagement Group, 1995, CORBASERVICES COMMON
   Pedersen T, 2004, HLT NAACL 2004, VHLTNAACL, P38, DOI DOI 10.3115/1614025.1614037
   Perez-Rua Juan-Manuel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13843, DOI 10.1109/CVPR42600.2020.01386
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Petrovic M., 2003, P 29 INT C VERY LARG, P1101
   Pietzuch PR, 2002, 22ND INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOP, PROCEEDINGS, P611, DOI 10.1109/ICDCSW.2002.1030837
   Pirsch P, 1998, IEEE T CIRC SYST VID, V8, P878, DOI 10.1109/76.735383
   Pontes Felipe Arruda, 2020, EDGEWAYS 2020
   Presser M., 2009, EURESCOM MESSAGE MAG, V2
   Purkait P., 2017, ARXIV171203452
   Qiu T, 2018, IEEE COMMUN SURV TUT, V20, P2011, DOI 10.1109/COMST.2018.2803740
   Rao K.R., 2002, Multimedia Communication Systems
   Razzaque MA, 2016, IEEE INTERNET THINGS, V3, P70, DOI 10.1109/JIOT.2015.2498900
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ricci Elisa, P IEEE INT C COMP VI, P382
   Rochan M, 2015, PROC CVPR IEEE, P4315, DOI 10.1109/CVPR.2015.7299060
   Roger A., 2017, J OPEN SOURCE SOFTW, V2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sagiroglu S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P42
   Sakamura K., 2006, Proceeding of the 28th International Conference on Software Engineering - ICSE'06, P713
   Segall Bill., 2000, Proceedings AUUG2k
   Seng KP, 2018, IEEE T MULTI-SCALE C, V4, P500, DOI 10.1109/TMSCS.2018.2886843
   Sharif A, 2009, IEEE INTL CONF IND I, P606, DOI 10.1109/INDIN.2009.5195872
   Shu CF, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P318
   Shu Y, 2019, AAAI CONF ARTIF INTE, P4951
   Silva Jose R., 2014, P 10 ADV INT C TEL P, V2024, P8797
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivaharan T, 2005, LECT NOTES COMPUT SC, V3760, P732
   Solves Jean-Yves, 2004, US Patent, Patent No. [6,725,279, 6725279]
   Souto E, 2006, PERS UBIQUIT COMPUT, V10, P37, DOI 10.1007/s00779-005-0038-3
   Starovic G., 1996, OOIS '95. 1995 International Conference on Object Oriented Information Systems Proceedings, P72
   Sterling B., 2005, Shaping Things
   Sundaram H, 2012, P IEEE, V100, P2737, DOI 10.1109/JPROC.2012.2191529
   Sundmaeker H., 2010, CLUSTER EUROPEAN RES, V3, P34, DOI DOI 10.2759/26127
   Sutton P, 2001, FIRST IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, PROCEEDINGS, P277, DOI 10.1109/CCGRID.2001.923204
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang YX, 2018, IEEE T PATTERN ANAL, V40, P3045, DOI 10.1109/TPAMI.2017.2771779
   Tang YX, 2016, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2016.233
   Tian YH, 2010, COMPUTER, V43, P27, DOI 10.1109/MC.2010.188
   Titus Balan, 2017, MOB INF SYST
   Toma Ioan., 2009, P 3 STI ROADMAPPING, P140
   Troncy R, 2011, MULTIMEDIA SEMANTICS: METADATA, ANALYSIS AND INTERACTION, P1
   Tsai Chun-Wei, 2015, Journal of Big Data, P1, DOI [DOI 10.1186/S40537-015-0030-3, 10.1186/s40537-015-0030-3]
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, IJCV, DOI DOI 10.1007/S11263-013-0620-5
   Vazquez Inaki, 2009, SOCIAL DEVICES SEMAN
   Vermesan O., 2014, INTERNET THINGS FROM, V29
   Vermesan O, 2013, RIVER PUBL SER COMM, P7
   Wahlster W., DRESD FUT FOR 2008, P100
   Wang JL, 2004, LECT NOTES COMPUT SC, V3231, P232
   Wang LM, 2018, INT J COMPUT VISION, V126, P390, DOI 10.1007/s11263-017-1043-5
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang Qin, 2017, INT GEOSCI REMOTE SE, P1
   Wu si, P IEEE CVF C COMP VI, P9641
   Wu Y., 2004, ACM INT C MULTIMEDIA, P572, DOI DOI 10.1145/1027527.1027665
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xu G, 2018, IEEE INTERNET THINGS, V5, P403, DOI 10.1109/JIOT.2017.2762731
   Yadav N., 2017, Int. Res. J. Eng. Technol. (IRJET), P586
   Yadav P, 2019, IEEE INT CONF BIG DA, P2513, DOI 10.1109/BigData47090.2019.9006018
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang Jinfei, 2017, IEEE INT CONF COMM, P1
   Zaarour Tarek, 2017, P 11 ACM INT C DISTR, P310
   Zhang Weiwei, 2008, 2008 INT C COMP INT, P111
   Zhang YS, 2018, IEEE INTERNET THINGS, V5, P3442, DOI 10.1109/JIOT.2017.2781737
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhiyuan Wang, 2020, IEEE ACCESS, V8
   Zhou L, 2011, IEEE NETWORK, V25, P35, DOI 10.1109/MNET.2011.5772059
NR 208
TC 23
Z9 23
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104095
DI 10.1016/j.imavis.2020.104095
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700008
OA hybrid
DA 2024-07-18
ER

PT J
AU Sheron, PSF
   Sridhar, KP
   Baskar, S
   Shakeel, PM
AF Sheron, P. S. Febin
   Sridhar, K. P.
   Baskar, S.
   Shakeel, P. Mohamed
TI Projection-dependent input processing for 3D object recognition in human
   robot interaction systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D images; Dimension modeling; HRI; Principle component analysis; Space
   projection
AB Human-Robot Interaction (HRI) provides assisted services in different real-time applications. The robotic systems identify objects through digital visualization wherein a three-dimensional (3D) image is converged to a plane-based projection. The projection is analyzed using the co-ordinates and identification points for recognizing the object. In such a converging process, the misidentification of projections in different planes results in recognition errors. This article proposes projection-dependent input processing (PDIP) method to reduce the misidentifications in object recognition. In this method, the input is the visualizing image projected in all the possible dimensions to identify the conjoining indices. The conjoined indices without intersection are segregated using labeled analysis. The non-correlating indices are identified in the possible dimension projections to prevent errors. The deviations in planes and indices matching are prevented by correlating the input with similar stored inputs with labels. The proposed method is verified using the metrics recognition ratio (96.4%), time (630.36 ms), complexity (5.93), and error (0.605). (C) 2020 Elsevier B.V. All rights reserved.
C1 [Sheron, P. S. Febin; Sridhar, K. P.; Baskar, S.] Karpagam Acad Higher Educ, Dept Elect & Commun, Coimbatore, Tamil Nadu, India.
   [Shakeel, P. Mohamed] Univ Teknikal Malaysia Melaka, Fac Informat & Commun Technol, Melaka, Malaysia.
C3 Karpagam Academy of Higher Education (KAHE); Universiti Teknologi
   Malaysia; University Teknikal Malaysia Melaka
RP Sheron, PSF (corresponding author), Karpagam Acad Higher Educ, Dept Elect & Commun, Coimbatore, Tamil Nadu, India.
EM febinsheronpps@gmail.com
RI S, Baskar/R-6346-2017; K P, Sridhar/GQH-0369-2022; Mohamed Shakeel,
   Pethuraj/P-4135-2019
OI S, Baskar/0000-0003-3570-3059; 
FU SERB, Science and Engineering Research Board; Department of Science and
   Technology(DST), New Delhi, India
FX The authors would like to thank SERB, Science and Engineering Research
   Board, and Department of Science and Technology(DST), New Delhi, India
   for the funding to carry out the research work at our institution.
CR Arnold E, 2019, IEEE T INTELL TRANSP, V20, P3782, DOI 10.1109/TITS.2019.2892405
   Arun KK, 2022, INTEL SERV ROBOT, V15, P427, DOI 10.1007/s11370-020-00320-z
   Baba A., J KING SAUD U COMPUT
   Berz EL, 2018, IET CYBER PHYS SYST, V3, P81, DOI 10.1049/iet-cps.2017.0067
   Bo Huang, 2019, Wuhan University Journal of Natural Sciences, V24, P360, DOI 10.1007/s11859-019-1407-5
   Boutteau R, 2020, J INTELL ROBOT SYST, V99, P359, DOI 10.1007/s10846-019-01114-x
   Crivellaro A, 2018, IEEE T PATTERN ANAL, V40, P1465, DOI 10.1109/TPAMI.2017.2708711
   Deng J, 2019, IEEE ACCESS, V7, P9848, DOI 10.1109/ACCESS.2019.2891668
   Guo BH, 2019, IEEE ACCESS, V7, P73593, DOI 10.1109/ACCESS.2019.2920511
   He Y, 2019, IEEE ACCESS, V7, P12495, DOI 10.1109/ACCESS.2019.2891693
   Li Q, 2020, ISPRS J PHOTOGRAMM, V161, P13, DOI 10.1016/j.isprsjprs.2020.01.008
   Li X, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115686
   Lyu D., 2018, EURASIP J IMAGE VIDE, V1, P2018
   Nir O, 2018, BIOSYST ENG, V173, P4, DOI 10.1016/j.biosystemseng.2017.11.014
   Pire T., 2019, J INTELL ROBOT SYST, V98, P377
   Probst T, 2018, IEEE ROBOT AUTOM LET, V3, P612, DOI 10.1109/LRA.2017.2778020
   Rahman MM, 2019, INFORM SCIENCES, V476, P147, DOI 10.1016/j.ins.2018.09.040
   Ren YZ, 2018, J VIS COMMUN IMAGE R, V55, P131, DOI 10.1016/j.jvcir.2018.05.019
   Ren ZL, 2020, IEEE T PATTERN ANAL, V42, P2670, DOI 10.1109/TPAMI.2019.2923201
   Rosas-Cervantes V, 2020, INT J CONTROL AUTOM, V18, P2955, DOI 10.1007/s12555-019-0313-0
   Martínez SS, 2019, INT J ADV MANUF TECH, V104, P1403, DOI 10.1007/s00170-019-04058-6
   Tsai CY, 2018, IEEE ACCESS, V6, P28859, DOI 10.1109/ACCESS.2018.2808225
   Wang DW, 2019, IEEE ACCESS, V7, P171461, DOI 10.1109/ACCESS.2019.2955995
   Wang L, 2020, SUSTAIN CITIES SOC, V54, DOI 10.1016/j.scs.2019.102002
   Weibel JB, 2020, IEEE ROBOT AUTOM LET, V5, P407, DOI 10.1109/LRA.2019.2959497
   Yang JX, 2020, J RUSS LASER RES, V41, P390, DOI 10.1007/s10946-020-09891-9
   Yang Y, 2018, INT J AUTOM COMPUT, V15, P194, DOI 10.1007/s11633-018-1118-y
   Yongbin Gao, 2019, Wuhan University Journal of Natural Sciences, V24, P369, DOI 10.1007/s11859-019-1408-4
   Zhang J., 2017, MACH VISION APPL, V29, P285
   Zhang JH, 2020, MULTIMED TOOLS APPL, V79, P2427, DOI 10.1007/s11042-019-08302-9
NR 30
TC 16
Z9 16
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104089
DI 10.1016/j.imavis.2020.104089
EA JAN 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700009
DA 2024-07-18
ER

PT J
AU Ali, SS
   Baghel, VS
   Ganapathi, II
   Prakash, S
AF Ali, Syed Sadaf
   Baghel, Vivek Singh
   Ganapathi, Iyyakutti Iyappan
   Prakash, Surya
TI Robust biometric authentication system with a secure user template
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Authentication; Security; Fingerprint; Biometric; Pattern recognition
ID FINGERPRINT SHELL; PRIVACY; CODE; PROTECTION
AB Biometric feature based human authentication systems provide various advantages over the classical authentication systems. Out of numerous biometric features in a human body, the fingerprint is the most commonly used biometric feature for the authentication of a person. Typically, the fingerprint-based systems rely on minutiae points information and use it directly as a user template. Several studies have shown that the use of minutiae points directly as a user template is unreliable as it may lead to the reconstruction of the original fingerprint. As databases are vulnerable to attacks, it is important to secure fingerprint information. In this paper, we propose a technique in which a strong 3-dimensional template is created from the fingerprint of a user. From the minutiae points of the fingerprint, minutiae triplets are computed, through which a secured user template is generated. The user template developed using the proposed technique is found to be robust and shows good revocability, diversity, security, and performance. The experimental results obtained on various fingerprint databases are extremely encouraging and demonstrate the effectiveness of the proposed technique. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Ali, Syed Sadaf; Baghel, Vivek Singh; Ganapathi, Iyyakutti Iyappan; Prakash, Surya] Indian Inst Technol Indore, Discipline Comp Sci & Engn, Indore 453552, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore
RP Ali, SS; Prakash, S (corresponding author), Indian Inst Technol Indore, Discipline Comp Sci & Engn, Indore 453552, India.
EM phd1301201006@iiti.ac.in; phd1801201005@iiti.ac.in;
   phd1501101002@iiti.ac.in; surya@iiti.ac.in
RI Baghel, Vivek Singh/HKF-5192-2023; Ganapathi, Iyyakutti
   Iyappan/CAH-5689-2022; ali, Syed mansoor/I-7636-2019
OI Baghel, Vivek Singh/0000-0002-6076-7831; Ali, Syed
   Sadaf/0000-0002-0198-8319; Ganapathi, Iyyakutti
   Iyappan/0000-0001-6312-5765
CR Ahmad T, 2011, PATTERN RECOGN, V44, P2555, DOI 10.1016/j.patcog.2011.03.015
   Ali S.S., 2019, FEW TECHNIQUES FINGE
   Ali S.S., 2019, IEEE T EMERGING TOPI
   Ali SS, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P801, DOI 10.1109/SPIN.2015.7095438
   Ali SS, 2020, PATTERN RECOGN LETT, V129, P263, DOI 10.1016/j.patrec.2019.11.037
   Ali SS, 2019, J INTELL FUZZY SYST, V36, P4091, DOI 10.3233/JIFS-169969
   Ali SS, 2017, COMPUTE'17: PROCEEDINGS OF THE 10TH ANNUAL ACM INDIA COMPUTE CONFERENCE, P91, DOI 10.1145/3140107.3140113
   Ali SS, 2019, PATTERN RECOGN LETT, V126, P68, DOI 10.1016/j.patrec.2018.04.017
   Ali SS, 2018, IET BIOMETRICS, V7, P536, DOI 10.1049/iet-bmt.2018.5070
   [Anonymous], CYBERSPACE SAFETY SE
   Benhammadi F, 2014, IMAGE VISION COMPUT, V32, P487, DOI 10.1016/j.imavis.2014.04.014
   Bringer J, 2017, IMAGE VISION COMPUT, V58, P239, DOI 10.1016/j.imavis.2016.08.002
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Chen FL, 2009, IEEE T IMAGE PROCESS, V18, P1665, DOI 10.1109/TIP.2009.2017995
   Das P, 2012, PATTERN RECOGN, V45, P3373, DOI 10.1016/j.patcog.2012.02.022
   Dave I.R., 2018, P INDICON 2018
   Dwivedi R, 2017, COMPUT SECUR, V65, P373, DOI 10.1016/j.cose.2016.10.004
   Feng JJ, 2011, IEEE T PATTERN ANAL, V33, P209, DOI 10.1109/TPAMI.2010.77
   Ferrara M., 2014, IEEE International Joint Conference on Biometrics, Clearwater, FL, USA, P1, DOI [DOI 10.1109/BTAS.2014.6996240, 10.1109/BTAS.2014.6996240]
   Ferrara M, 2012, IEEE T INF FOREN SEC, V7, P1727, DOI 10.1109/TIFS.2012.2215326
   Ganapathi II, 2018, IET BIOMETRICS, V7, P519, DOI 10.1049/iet-bmt.2018.5064
   Gomez-Barrero M, 2018, IEEE T INF FOREN SEC, V13, P1406, DOI 10.1109/TIFS.2017.2788000
   Iyappan G.I., 2018, VISUAL COMPUTER
   Iyappan GanapathiIyyakutti, 2019, PROC BIOSIG 2019, P1
   Jin ATB, 2004, IMAGE VISION COMPUT, V22, P503, DOI 10.1016/j.imavis.2003.12.002
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Jin Z, 2012, EXPERT SYST APPL, V39, P6157, DOI 10.1016/j.eswa.2011.11.091
   Lam HK, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P967, DOI 10.1109/ICARCV.2008.4795649
   Liu EY, 2017, NEUROCOMPUTING, V259, P3, DOI 10.1016/j.neucom.2016.06.083
   Mai G, 2017, IMAGE VISION COMPUT, V58, P254, DOI 10.1016/j.imavis.2016.11.011
   Moujahdi C, 2014, PATTERN RECOGN LETT, V45, P189, DOI 10.1016/j.patrec.2014.04.001
   Nandakumar Karthik., 2010, IEEE InternationalWorkshop on Information Forensics and Security (WIFS), P1
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Ross A, 2007, IEEE T PATTERN ANAL, V29, P544, DOI 10.1109/TPAMI.2007.1018
   Ryabko BY, 2004, J STAT PLAN INFER, V123, P365, DOI 10.1016/S0378-3758(03)00149-6
   Sandhya M, 2017, IET BIOMETRICS, V6, P173, DOI 10.1049/iet-bmt.2016.0008
   Sandhya M, 2016, IET BIOMETRICS, V5, P131, DOI 10.1049/iet-bmt.2015.0034
   Sandhya M, 2015, INT CONF BIOMETR, P386, DOI 10.1109/ICB.2015.7139100
   Wang S, 2017, PATTERN RECOGN, V66, P295, DOI 10.1016/j.patcog.2017.01.019
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Wang S, 2012, PATTERN RECOGN, V45, P4129, DOI 10.1016/j.patcog.2012.05.004
   Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003
   Wilcox R., 2005, KOLMOGORO SMIRNOV TE
   Wong WJ, 2013, PATTERN RECOGN LETT, V34, P1221, DOI 10.1016/j.patrec.2013.03.039
   Yang WC, 2014, PATTERN RECOGN, V47, P1309, DOI 10.1016/j.patcog.2013.10.001
   Zhu E, 2016, PATTERN RECOGN, V56, P116, DOI 10.1016/j.patcog.2016.02.015
   Zimmerman DW, 1997, J EDUC BEHAV STAT, V22, P349, DOI 10.3102/10769986022003349
NR 48
TC 16
Z9 16
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104004
DI 10.1016/j.imavis.2020.104004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800005
DA 2024-07-18
ER

PT J
AU Singh, P
   Raj, P
   Namboodiri, VP
AF Singh, Pravendra
   Raj, Prem
   Namboodiri, Vinay P.
TI EDS pooling layer
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature pooling layer; Convolutional neural network; Deep learning;
   Object recognition
AB Convolutional neural networks (CNNs) have been the source of recent breakthroughs in many vision tasks. Feature pooling layers are being widely used in CNNs to reduce the spatial dimensions of the feature maps of the hidden layers. This gives CNNs the property of spatial invariance and also results in speed-up and reduces overfitting. However, this also causes significant information loss. All existing feature pooling layers follow a one-step procedure for spatial pooling, which affects the overall performance due to significant information loss. Not much work has been done to do efficient feature pooling operation in CNNs. To reduce the loss of information at this critical operation of the CNNs, we propose a new EDS layer (Expansion Downsampling learnable-Scaling) to replace the existing pooling mechanism. We propose a two-step procedure to minimize the information loss by increasing the number of channels in pooling operation. We also use feature scaling in the proposed EDS layer to highlight the most relevant channels/feature-maps. Our results show a significant improvement over the generally used pooling methods such as MaxPool, AvgPool, and StridePool (strided convolutions with stride >1). We have done the experiments on image classification and object detection task. ResNet-50 with our proposed EDS layer has performed comparably to ResNet-152 with stride pooling on the ImageNet dataset. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Singh, Pravendra; Raj, Prem; Namboodiri, Vinay P.] Indian Inst Technol Kanpur, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur
RP Singh, P (corresponding author), Indian Inst Technol Kanpur, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
EM psingh@iitk.ac.in; praj@iitk.ac.in; vinaypn@iitk.ac.in
RI Singh, Pravendra/ABC-9247-2020
OI Singh, Pravendra/0000-0003-1001-2219; Namboodiri,
   Vinay/0000-0001-5262-9722
CR [Anonymous], 2017, INFORM TECHNOLOGY MA
   [Anonymous], 2018, BRIT MACH VIS C BMVC
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2015, INT C LEARN REPR ICL
   [Anonymous], 2014, Arxiv
   [Anonymous], 2013, ARXIV201313013557
   [Anonymous], EUR C COMP VIS
   [Anonymous], PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2018.00745, DOI 10.1109/TPAMI.2019.2913372]
   [Anonymous], IEEE INT C COMP VIS
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Howard A. G., 2017, PREPRINT
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kobayashi T., P IEEE INT C COMPUTE, P3365
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Li PH, 2018, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2018.00105
   Li PH, 2017, IEEE I CONF COMP VIS, P2089, DOI 10.1109/ICCV.2017.228
   Li YH, 2017, IEEE I CONF COMP VIS, P2098, DOI 10.1109/ICCV.2017.229
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Parker J, 1983, IEEE Trans Med Imaging, V2, P31, DOI 10.1109/TMI.1983.4307610
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saeedan F, 2018, PROC CVPR IEEE, P9108, DOI 10.1109/CVPR.2018.00949
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P., 2019, ARXIV190304407
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang Y, 2017, IEEE I CONF COMP VIS, P1368, DOI 10.1109/ICCV.2017.152
   Yu DJ, 2014, LECT NOTES ARTIF INT, V8818, P364, DOI 10.1007/978-3-319-11740-9_34
   Zagoruyko Sergey, 2016, BRIT MACH VIS C 2016
   Zangeneh M, 2015, ECOPRODUCTION, P25, DOI 10.1007/978-3-642-33935-6_2
NR 32
TC 19
Z9 19
U1 4
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2020
VL 98
AR 103923
DI 10.1016/j.imavis.2020.103923
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR9US
UT WOS:000536040700005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Iranmanesh, SM
   Riggan, B
   Hu, SW
   Nasrabadi, NM
AF Iranmanesh, Seyed Mehdi
   Riggan, Benjamin
   Hu, Shuowen
   Nasrabadi, Nasser M.
TI Coupled generative adversarial network for heterogeneous face
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Heterogeneous face recognition; Generative adversarial networks; Face
   verification; Coupled deep neural network; Common latent subspace;
   Biometrics
AB The large modality gap between faces captured in different spectra makes heterogeneous face recognition (HFR) a challenging problem. In this paper, we present a coupled generative adversarial network (CpGAN) to address the problem of matching non-visible facial imagery against a gallery of visible faces. Our CpGAN architecture consists of two sub-networks one dedicated to the visible spectrum and the other sub-network dedicated to the non-visible spectrum. Each sub-network consists of a generative adversarial network (GAN) architecture. Inspired by a dense network which is capable of maximizing the information flow among features at different levels, we utilize a densely connected encoder-decoder structure as the generator in each GAN sub-network. The proposed CpGAN framework uses multiple loss functions to force the features from each sub-network to be as close as possible for the same identities in a common latent subspace. To achieve a realistic photo reconstruction while preserving the discriminative information, we also added a perceptual loss function to the coupling loss function. An ablation study is performed to show the effectiveness of different loss functions in optimizing the proposed method. Moreover, the superiority of the model compared to the state-of-the-art models in HFR is demonstrated using multiple datasets. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Iranmanesh, Seyed Mehdi; Nasrabadi, Nasser M.] West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26505 USA.
   [Riggan, Benjamin; Hu, Shuowen] US Army Res Lab, Adelphi, MD 20783 USA.
C3 West Virginia University; United States Department of Defense; United
   States Army; US Army Research, Development & Engineering Command
   (RDECOM); US Army Research Laboratory (ARL)
RP Iranmanesh, SM (corresponding author), West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26505 USA.
EM seiranmanesh@mix.wvu.edu
RI Riggan, Benjamin/AAG-6282-2021
CR Bourlai T., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1343, DOI 10.1109/ICPR.2010.1115
   Bourlai T, 2012, PROC SPIE, V8371, DOI 10.1117/12.918899
   Byrd K.A., 2013, Proc. SPIE, V8734, P34
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   Chen X., 2003, P ACM WORKSHOP MULTI, P48
   Choi J., 2012, Thermal to Visible Face Recognition
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong Yi, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163093
   Gonzalez-Sosa E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2015, P IEEE C COMPUTER VI
   He YH, 2016, IEEE T MULTIMEDIA, V18, P1363, DOI 10.1109/TMM.2016.2558463
   Hu SW, 2016, IEEE COMPUT SOC CONF, P187, DOI 10.1109/CVPRW.2016.30
   Hu SW, 2018, PROC SPIE, V10655, DOI 10.1117/12.2299761
   Hu SW, 2015, J OPT SOC AM A, V32, P431, DOI 10.1364/JOSAA.32.000431
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Juefei-Xu Felix, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P141, DOI 10.1109/CVPRW.2015.7301308
   Kingma D. P., 2014, arXiv
   Klare B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1513, DOI 10.1109/ICPR.2010.374
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Li S., 2015, P IEEE C COMPUTER VI
   Li SZ., 2009, IEEE COMPUTER SOC C, P1
   Liu XX, 2016, INT CONF BIOMETR
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nicolò F, 2012, IEEE T INF FOREN SEC, V7, P1717, DOI 10.1109/TIFS.2012.2213813
   Ouyang S., 2014, arXiv preprint arXiv:1409.5114
   Reale C., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, P32
   Reale C, 2016, IEEE COMPUT SOC CONF, P320, DOI 10.1109/CVPRW.2016.47
   Reale C, 2014, IEEE IMAGE PROC, P328, DOI 10.1109/ICIP.2014.7025065
   Riggan B.S., 2018, IEEE WINTER C APPL C
   Riggan BS, 2016, INT CONF BIOMETR THE
   Riggan BS, 2016, IEEE WINT CONF APPL
   Riggan BS, 2015, IEEE ACCESS, V3, P1620, DOI 10.1109/ACCESS.2015.2479620
   Sarfraz M.S., 2015, arXiv preprint a rXiv:1507.02879
   Saxena S, 2016, LECT NOTES COMPUT SC, V9915, P483, DOI 10.1007/978-3-319-49409-8_40
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Short N, 2015, INT CONF BIOMETR THE
   Short N, 2015, OPT LETT, V40, P882, DOI 10.1364/OL.40.000882
   Sun Y., 2015, ARXIV150200873
   Sun Y., 2012, Advances in Neural Information Processing Systems
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yi D, 2007, LECT NOTES COMPUT SC, V4642, P523
   Yousefi N, 2019, RELIAB ENG SYST SAFE, V192, DOI 10.1016/j.ress.2019.106547
   Yuffa AJ, 2014, APPL OPTICS, V53, P8514, DOI 10.1364/AO.53.008514
   Zhang H., 2018, ARXIV180508318
   Zhang HW, 2018, PROC CVPR IEEE, P4158, DOI 10.1109/CVPR.2018.00437
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977
   Zhu Y, 2017, IEEE IMAGE PROC, P790, DOI 10.1109/ICIP.2017.8296389
NR 59
TC 17
Z9 18
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103861
DI 10.1016/j.imavis.2019.103861
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900011
DA 2024-07-18
ER

PT J
AU Liu, W
   Yao, RG
   Qiu, GP
AF Liu, Wei
   Yao, Rongguo
   Qiu, Guoping
TI A physics based generative adversarial network for single image
   defogging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Single image defogging; Image restoration; Image enhancement; CycleGAN;
   Subjective evaluation
ID QUALITY ASSESSMENT; RETINEX; VISIBILITY; REMOVAL
AB In the field of single image defogging, there are two main methods. One is the image restoration method based on the atmospheric scattering theory which can recover the image texture details well. The other is the image enhancement method based on Retinex theory which can improve the image contrast well. In practice, however, the former can easily lead to low contrast images; the latter is prone to losing texture details. Therefore, how to effectively combine the advantages of both to remove fog is a key issue in the field. In this paper, we have developed a physics based generative adversarial network (PBGAN) to exploit the advantages between those two methods in parallel. To our knowledge, it is the first learning defogging framework that incorporates these two methods and to enable them to work together and complement each other. Our method has two generative adversarial modules, the Contrast Enhancement (CE) module and the Texture Restoration (TR) module. To improve contrast in the CE module, we introduced a novel inversion-adversarial loss and a novel inversion-cycle consistency loss for training the generator. To improve the texture in the TR module, we introduced two convolutional neural networks to learn the atmospheric light coefficient and the transmission map, respectively. Extensive experiments on both synthetic and real-world datasets demonstrate that the proposed approach performs better than several state-of-the-art methods quantitatively and qualitatively. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Liu, Wei; Yao, Rongguo; Qiu, Guoping] Shenzhen Univ, Coll Informat Engn, Shenzhen, Guangdong, Peoples R China.
   [Liu, Wei; Yao, Rongguo; Qiu, Guoping] Shenzhen Inst Artificial Intelligence & Robot Soc, Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Guangdong, Peoples R China.
   [Qiu, Guoping] Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.
C3 Shenzhen University; Shenzhen Institute of Artificial Intelligence &
   Robotics for Society; University of Nottingham
RP Qiu, GP (corresponding author), Shenzhen Univ, Coll Informat Engn, Shenzhen, Guangdong, Peoples R China.
EM josephson870921@163.com; qiu@szu.edu.cn
OI Qiu, Guoping/0000-0002-5877-5648
CR Ancuti C. O., 2018, IEEE C COMP VIS PATT
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2017, P IEEE INT C COMP VI
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2014, Computer Science
   [Anonymous], 2018, C COMPUT VIS PATTERN
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen BH, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2710024
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Du Y, 2002, IEEE T GEOSCI REMOTE, V40, P210, DOI 10.1109/36.981363
   Engin Deniz, 2018, ARXIV180505308
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang YT, 2017, IEEE T IMAGE PROCESS, V26, P3397, DOI 10.1109/TIP.2017.2700720
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Li B., 2017, ARXIV PREPRINT ARXIV
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   McCartney E.J., 1976, OPTICS ATMOSPHERE
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Ren W., 2018, IEEE C COMPUTER VISI
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Sun W, 2017, PATTERN RECOGN, V61, P153, DOI 10.1016/j.patcog.2016.07.033
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang W, 2018, IEEE CONF COMPUT
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, P2223, DOI DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 43
TC 13
Z9 15
U1 3
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2019
VL 92
AR 103815
DI 10.1016/j.imavis.2019.10.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JW2JO
UT WOS:000502884200009
DA 2024-07-18
ER

PT J
AU Xiao, Y
   Kamat, VR
   Menassa, CC
AF Xiao, Yong
   Kamat, Vineet R.
   Menassa, Carol C.
TI Human tracking from single RGB-D camera using online learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human-robot collaboration; RGB-D cameras; Online classifier; Candidate
   sampling
ID REAL-TIME; PEOPLE TRACKING; LOCALIZATION
AB Human detection and tracking is an essential component in several robotics applications, especially in indoor built environments where humans and robots are expected to coexist or collaborate. Due to their low cost and capability to capture both color and depth data, RGB-D cameras have shown significant promise in human detection and tracking for robotic applications. In this paper, a new human tracking method is proposed to detect and track a specific individual from a single RGB-D sensor using online learning classifiers with no ground plane assumption. Given a previous target human position, a candidate sampling method is designed to find potential positive samples while negative samples are obtained by a random sampling process. The kernelized Support Vector Machine (SVM) is employed as the online classifier to recognize the target human and updated using both the positive and negative examples. The experimental results on six RGB-D videos of a public dataset demonstrate that the proposed method achieves higher success rates compared to a 2D tracker and a 3D human detection method at a frame rate of 3.8 fps, and is capable of efficiently retrieving the target human following intermittent occlusion. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Xiao, Yong; Kamat, Vineet R.; Menassa, Carol C.] Univ Michigan, Dept Civil & Environm Engn, 2350 Hayward St,2340 GG Brown Bldg, Ann Arbor, MI 48109 USA.
C3 University of Michigan System; University of Michigan
RP Xiao, Y (corresponding author), Univ Michigan, Dept Civil & Environm Engn, 2350 Hayward St,2340 GG Brown Bldg, Ann Arbor, MI 48109 USA.
EM yongxiao@umich.edu; vkamat@umich.edu; menassa@umich.edu
OI Kamat, Vineet/0000-0003-0788-5588
CR Ali B, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1714, DOI 10.1109/ICMA.2013.6618174
   [Anonymous], 2005, Computer Vision and Pattern Recognition-Workshops
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bibi A, 2016, PROC CVPR IEEE, P1439, DOI 10.1109/CVPR.2016.160
   Bodor R., P P 11 MED C CONTR A, P18
   Camplani M, 2015, BRIT MACH VIS C
   Carraro M, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.041007
   Cheng T, 2013, J COMPUT CIVIL ENG, V27, P320, DOI 10.1061/(ASCE)CP.1943-5487.0000222
   Chung W, 2012, IEEE T IND ELECTRON, V59, P3156, DOI 10.1109/TIE.2011.2170389
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dang QK, 2011, 2011 11TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P1054
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ghidary SS, 2000, IEEE SYS MAN CYBERN, P1360, DOI 10.1109/ICSMC.2000.886043
   Gritti AP, 2014, IEEE INT C INT ROBOT, P4096, DOI 10.1109/IROS.2014.6943139
   Han S., 2013, Visualization in Engineering Volume, V1, P1, DOI [DOI 10.1186/2213-7459-1-6, 10.1186/2213-7459-1-6]
   Han S, 2013, J COMPUT CIVIL ENG, V27, P635, DOI 10.1061/(ASCE)CP.1943-5487.0000279
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Jiang G.-P., 2018, TMM, V21, P664
   Khosrowpour A, 2014, AUTOMAT CONSTR, V48, P74, DOI 10.1016/j.autcon.2014.08.003
   Li HY, 2015, SENSORS-BASEL, V15, P31244, DOI 10.3390/s151229850
   Liu H., 2016, International Journal of Advanced Robotic Systems, V13
   Liu J, 2015, J VIS COMMUN IMAGE R, V31, P177, DOI 10.1016/j.jvcir.2015.06.014
   Liu J, 2015, PATTERN RECOGN LETT, V53, P16, DOI 10.1016/j.patrec.2014.09.013
   Liu MY, 2016, CONSTRUCTION RESEARCH CONGRESS 2016: OLD AND NEW CONSTRUCTION TECHNOLOGIES CONVERGE IN HISTORIC SAN JUAN, P951
   Luber M, 2011, IEEE INT C INT ROBOT, P3844, DOI 10.1109/IROS.2011.6048836
   Mashuk MS, 2018, IEEE POSITION LOCAT, P216, DOI 10.1109/PLANS.2018.8373384
   Meshgi K, 2016, COMPUT VIS IMAGE UND, V150, P81, DOI 10.1016/j.cviu.2016.05.011
   Miyaho N, 2009, 2009 4TH INTERNATIONAL CONFERENCE ON SYSTEMS AND NETWORKS COMMUNICATIONS (ICSNC 2009), P217, DOI 10.1109/ICSNC.2009.112
   Morioka K, 2004, IEEE T IND ELECTRON, V51, P229, DOI 10.1109/TIE.2003.821894
   Munaro M, 2016, ROBOT AUTON SYST, V75, P525, DOI 10.1016/j.robot.2015.10.004
   Munaro M, 2014, AUTON ROBOT, V37, P227, DOI 10.1007/s10514-014-9385-0
   Nez J.C., 2016, Multimedia Tools and Applications, V76, P4249
   Park MW, 2016, AUTOMAT CONSTR, V72, P129, DOI 10.1016/j.autcon.2016.08.039
   Park MW, 2012, AUTOMAT CONSTR, V28, P15, DOI 10.1016/j.autcon.2012.06.001
   Ray SJ, 2012, ADV ENG INFORM, V26, P439, DOI 10.1016/j.aei.2012.02.011
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Susperregi L, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56123
   Vo DM, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P689, DOI 10.1109/ROBIO.2014.7090411
   Wang D, 2015, J CONSTR ENG M, V141, DOI 10.1061/(ASCE)CO.1943-7862.0000979
   Xu RY, 2015, MULTIMED TOOLS APPL, V74, P729, DOI 10.1007/s11042-014-2177-x
   Xue HY, 2016, NEUROCOMPUTING, V204, P70, DOI 10.1016/j.neucom.2015.06.112
   Zarka N, 2008, 3 INT C ICTTA, P1
   Zhang GY, 2017, IEEE SIGNAL PROC LET, V24, P1666, DOI 10.1109/LSP.2017.2731952
   Zhao ZL, 2017, C LOCAL COMPUT NETW, P535, DOI 10.1109/LCN.2017.65
NR 44
TC 14
Z9 14
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 67
EP 75
DI 10.1016/j.imavis.2019.05.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400007
DA 2024-07-18
ER

PT J
AU Heinsohn, D
   Villalobos, E
   Prieto, L
   Mery, D
AF Heinsohn, Daniel
   Villalobos, Esteban
   Prieto, Loreto
   Mery, Domingo
TI Face recognition in low-quality images using adaptive sparse
   representations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Sparse representations; Deep learning;
   Superresolution; Low-quality images; Low-resolution
ID ROBUST; DICTIONARY; EIGENFACES; DEFENSE; BLUR
AB Although unconstrained face recognition has been widely studied over the recent years, state-of-the-art algorithms still result in an unsatisfactory performance for low-quality images. In this paper, we make two contributions to this field: the first one is the release of a new dataset called 'AR-LQ' that can be used in conjunction with the well-known 'AR' dataset to evaluate face recognition algorithms on blurred and low resolution face images. The proposed dataset contains five new blurred faces (at five different levels, from low to severe blurriness) and five new low-resolution images (at five different levels, from 66 x 48 to 7 x 5 pixels) for each of the hundred subjects of the 'AR' dataset. The new blurred images were acquired by using a DLSR camera with manual focus that takes an out-of-focus photograph of a monitor that displays a sharp face image. In the same way, the low-resolution images were acquired from the monitor by a DLSR at different distances. Thus, an attempt is made to acquire low-quality images that have been degraded by a real degradation process. Our second contribution is an extension of a known face recognition technique based on sparse representations (ASR) that takes into account low-resolution face images. The proposed method, called blur-ASR or bASR, was designed to recognize faces using dictionaries with different levels of blurriness. These were obtained by digitally blurring the training images, and a sharpness metric for matching blurriness between the query image and the dictionaries. These two main adjustments made the algorithm more robust with respect to low-quality images. In our experiments, bASR consistently outperforms other state-of-the-art methods including hand-crafted features, sparse representations, and seven well-known deep learning face recognition techniques with and without super resolution techniques. On average, bASR obtained 88.8% of accuracy, whereas the rest obtained less than 78.4%. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Heinsohn, Daniel; Villalobos, Esteban; Prieto, Loreto; Mery, Domingo] Pontificia Univ Catolica Chile, Dept Ciencia Computac, Av Vicuna Mackenna 4860 143, Santiago, Chile.
C3 Pontificia Universidad Catolica de Chile
RP Mery, D (corresponding author), Pontificia Univ Catolica Chile, Dept Ciencia Computac, Av Vicuna Mackenna 4860 143, Santiago, Chile.
EM domingo.mery@uc.cl
RI Mery, Domingo/D-1385-2014
OI Mery, Domingo/0000-0003-4748-3882
FU FONDECYT from CONICYT-Chile [1161314]
FX This work was supported in part by FONDECYT grant 1161314 from
   CONICYT-Chile.
CR Aggarwal G., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P153, DOI 10.1109/WACV.2012.6163007
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P 22 BRIT MACH VIS C
   [Anonymous], 2018, ARXIV180511529
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benavente R, 1998, 24 COMP VIS CTR
   Biswas  S., 2012, IEEE T PATTERN ANAL
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Chen J, 2014, J VIS COMMUN IMAGE R, V25, P763, DOI 10.1016/j.jvcir.2014.01.015
   Chen L, 2017, MULTIMED TOOLS APPL, V76, P10231, DOI 10.1007/s11042-016-3611-z
   Chen Y, 2010, IEEE IMAGE PROC, P1657, DOI 10.1109/ICIP.2010.5652203
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Flusser J, 2016, IEEE T IMAGE PROCESS, V25, P790, DOI 10.1109/TIP.2015.2512108
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Gopalan R, 2012, IEEE T PATTERN ANAL, V34, P1220, DOI 10.1109/TPAMI.2012.15
   Grm K, 2018, IET BIOMETRICS, V7, P81, DOI 10.1049/iet-bmt.2017.0083
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Heinsohn  D., 2015, WORKSH FOR APPL COMP, P1
   Hennings-Yeomans PH, 2008, PROC CVPR IEEE, P3637
   Herrmann C, 2017, LECT NOTES COMPUT SC, V10270, P377, DOI 10.1007/978-3-319-59129-2_32
   Huang GW, 2017, INT CONF ADV CLOUD B, P7, DOI 10.1109/CBD.2017.10
   Jia K, 2012, LECT NOTES COMPUT SC, V7575, P331, DOI 10.1007/978-3-642-33765-9_24
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Larrain T, 2017, IEEE T INF FOREN SEC, V12, P1646, DOI 10.1109/TIFS.2017.2680403
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lei Z, 2007, LECT NOTES COMPUT SC, V4642, P49
   Levin A., 2011, Computer Science and Artificial Intelligence Laboratory Technical Report; Efficient Marginal Likelihood Optimization in Blind Deconvolution
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Li P, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P243, DOI 10.1109/BTAS.2017.8272704
   Liu D, 2016, IEEE T IMAGE PROCESS, V25, P3194, DOI 10.1109/TIP.2016.2564643
   Lu ZJ, 2018, IEEE ACCESS, V6, DOI [10.1109/ACCESS.2018.2864189, 10.1109/LSP.2018.2810121]
   Ludwiczuk B., 2016, Tech. Rep. CMU-CS-16-118
   Mery  D., 2014, IEEE WORKSH INF FOR
   Mery  D., 2018, INT C AC SPEECH SIGN, P1
   Mery  D., 2016, 2016 IEEE 8 INT C BI, P1
   Mery D, 2015, PATTERN RECOGN LETT, V68, P260, DOI 10.1016/j.patrec.2015.05.005
   Mudunuri SP, 2016, IEEE T PATTERN ANAL, V38, P1034, DOI 10.1109/TPAMI.2015.2469282
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Phillips P.J., 2011, Proc. IEEE Conference on Automatic Face and Gesture Recognition, P346
   Ptucha R, 2013, IEEE COMPUT SOC CONF, P854, DOI 10.1109/CVPRW.2013.126
   Qiu Q, 2014, IEEE T PATTERN ANAL, V36, P2173, DOI 10.1109/TPAMI.2014.2316824
   Ren CX, 2012, IEEE T IMAGE PROCESS, V21, P3770, DOI 10.1109/TIP.2012.2192285
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shi XS, 2014, PATTERN RECOGN, V47, P2447, DOI 10.1016/j.patcog.2014.01.007
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tikhonov A. N., 1977, SOLUTIONS ILL POSED
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang J, 2014, IEEE T CYBERNETICS, V44, P2368, DOI 10.1109/TCYB.2014.2307067
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wang ZF, 2014, VISUAL COMPUT, V30, P359, DOI 10.1007/s00371-013-0861-x
   Wang ZH, 2016, PROCEEDINGS OF THE 4TH INTERNATIONAL WORKSHOP ON ENERGY HARVESTING AND ENERGY-NEUTRAL SENSING SYSTEMS (ENSSYS'16), P1, DOI [10.1109/ICAUMS.2016.8479999, 10.1145/2996884.2996885]
   Wei X., 2012, EVID-BASED COMPL ALT, V2012, P1
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiao  Y., 2017, INFORM SCI
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhen Lei, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P161, DOI 10.1109/FG.2011.5771391
   Zhu X, 2009, INT WORK QUAL MULTIM, P64, DOI 10.1109/QOMEX.2009.5246976
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 71
TC 13
Z9 14
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2019
VL 85
BP 46
EP 58
DI 10.1016/j.imavis.2019.02.012
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HZ9DE
UT WOS:000469155200005
DA 2024-07-18
ER

PT J
AU Pujol-Miró, A
   Casas, JR
   Ruiz-Hidalgo, J
AF Pujol-Miro, Alba
   Casas, Josep R.
   Ruiz-Hidalgo, Javier
TI Correspondence matching in unorganized 3D point clouds using
   Convolutional Neural Networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Matching; Point cloud; Convolutional Neural Networks
AB This document presents a novel method based on Convolutional Neural Networks (CNN) to obtain correspondence matchings between sets of keypoints of several unorganized 3D point cloud captures, independently of the sensor used. The proposed technique extends a state-of-the-art method for correspondence matching in standard 2D images to sets of unorganized 3D point clouds. The strategy consists of projecting the 3D neighborhood of the keypoint onto an RGBD patch, and the classification of patch pairs using CNNs. The objective evaluation of the proposed 3D point matching based on CNNs outperforms existing 3D feature descriptors, especially when intensity or color data is available. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Pujol-Miro, Alba; Casas, Josep R.; Ruiz-Hidalgo, Javier] Univ Politecn Cataluna, Jordi Girona 1-3, ES-08034 Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Pujol-Miró, A (corresponding author), Univ Politecn Cataluna, Jordi Girona 1-3, ES-08034 Barcelona, Spain.
EM alba.pujol@upc.edu
RI Casas, Josep R./A-2851-2010
OI Casas, Josep R./0000-0003-4639-6904
FU Ministry of Science, Innovation and Universities (Ministerio de Ciencia,
   innovacion y Universidades); European Regional Development Fund (ERDF);
   Ministry of Industry, Economy and Competitiveness (Ministerio de
   Economia, Industria y Competitividad) [TEC2016-75976-R]
FX This research was supported by the Ministry of Science, Innovation and
   Universities (Ministerio de Ciencia, innovacion y Universidades) via a
   doctoral grant to the first author (FPU2014), and developed in the
   framework of project TEC2016-75976-R, financed by the Ministry of
   Industry, Economy and Competitiveness (Ministerio de Economia, Industria
   y Competitividad) and the European Regional Development Fund (ERDF).
CR [Anonymous], 2012, P INT C INT ROB SYST
   [Anonymous], 2009, IEEE INT C ROB AUT
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2017, 2017 JOINT URBAN REM, DOI DOI 10.1109/JURSE.2017.7924566
   [Anonymous], 2017, ARXIV170602413
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Johnson A., 1998, IMAGE VIS COMPUT
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Qi C.R., 2016, P IEEE CVF C COMPUTE
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Wasenmüller O, 2016, IEEE WINT CONF APPL
   Winder SAJ, 2007, PROC CVPR IEEE, P17
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
NR 20
TC 13
Z9 14
U1 3
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR-APR
PY 2019
VL 83-84
BP 51
EP 60
DI 10.1016/j.imavis.2019.02.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HW6TR
UT WOS:000466824000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Malawski, F
   Kwolek, B
AF Malawski, Filip
   Kwolek, Bogdan
TI Recognition of action dynamics in fencing using multimodal cues
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Depth maps; Multimodal cues; Motion analysis
ID MOTION; TRACKING; ACCELEROMETER; BIOMECHANICS; SENSORS; SYSTEM
AB Most current approaches to action recognition follow strategies, which permit classification of significantly different actions. However, in some sports disciplines, actions may be distinguished mainly by the dynamics of the motion rather than the trajectory. In this work, we propose a novel approach for recognition of sports actions. The novelty consists in the use of dynamics in the analysis of similar motion patterns We propose informative motion descriptors based on accelerometric data, skeleton joints features and depth maps, and demonstrate their potential to model the motion dynamics. We show that fusing data from multiple modalities permits better recognition accuracy. We make publicly available a dedicated dataset with fencing footwork samples of ten fencers that consists of depth, skeletal and inertial data of six types of dynamic actions, most of which have similar average trajectories but different dynamics of the motion. We show that on our Fencing Footwork Dataset the proposed method outperforms current state-of-the-art methods for general action recognition. (C) 2018 Elsevier B.V All rights reserved.
C1 [Malawski, Filip; Kwolek, Bogdan] AGH Univ Sci & Technol, 30 Mickiewicza Av, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Kwolek, B (corresponding author), AGH Univ Sci & Technol, 30 Mickiewicza Av, PL-30059 Krakow, Poland.
EM bkw@agh.edu.pl
RI Malawski, Filip/J-3479-2018; Kwolek, Bogdan/M-4552-2013
OI Kwolek, Bogdan/0000-0002-7715-1435
FU Polish National Science Center (NCN) [2014/15/B/ST6/02808,
   11.11.230.124]
FX This work was partially supported by Polish National Science Center
   (NCN) under a research grant 2014/15/B/ST6/02808 and a grant
   11.11.230.124. We would like to thank the fencers from Aramis Fencing
   School (aramis.pl) for their help in acquiring the Fencing Footwork
   Dataset.
CR [Anonymous], 2014, ADV COMPUT VIS PATTE, DOI 10.1007/978-3-319-09396-3_9
   Avci A., 2010, 23 INT C ARCH COMP S, P1
   Berndt D.J., 1994, AAAI 94 WORKSH KNOWL, V10, P359, DOI [10.5555/3000850.3000887, DOI 10.5555/3000850.3000887]
   Bloom V., 2012, 2012 IEEE COMP SOC C, P7, DOI [DOI 10.1109/CVPRW.2012.6239175, 10.1109/CVPRW.2012.6239175]
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Borysiuk Z., 2013, J COMBAT SPORT MARTI, V4, P135, DOI [10.5604/20815735.1090658, DOI 10.5604/20815735.1090658]
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Cheema M. S., STOCHASTIC LATE FUSI
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Czajkowski Z., 2005, Understanding Fencing: The Unity and Practice
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Eckardt F, 2014, J EQUINE VET SCI, V34, P1294, DOI 10.1016/j.jevs.2014.09.009
   Gholipour M., 2008, SPORTS SCI, V2, p32U
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Gourgari S, 2013, IEEE COMPUT SOC CONF, P676, DOI 10.1109/CVPRW.2013.102
   Hachaj T, 2015, INT C NETWB INFO, P332, DOI 10.1109/NBiS.2015.51
   Hamalainen Perttu, 2004, P 3 NORD C HUM COMP, P199, DOI [10.1145/1028014.1028044, DOI 10.1145/1028014.1028044]
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Jiang YG, 2015, IEEE T IMAGE PROCESS, V24, P3781, DOI 10.1109/TIP.2015.2456412
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   King K, 2008, SENSOR ACTUAT A-PHYS, V141, P619, DOI 10.1016/j.sna.2007.08.028
   Knudson DuaneV., 2013, Qualitative diagnosis of human movement: improving performance in sport and exercise
   Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lo Presti L, 2015, IMAGE VISION COMPUT, V44, P29, DOI 10.1016/j.imavis.2015.09.007
   Malawski F., 2015, INT C SIGN PROC ALG, P51
   Mantovani G, 2010, PROCEDIA ENGINEER, V2, P3423, DOI 10.1016/j.proeng.2010.04.168
   Margarito J, 2016, IEEE T BIO-MED ENG, V63, P788, DOI 10.1109/TBME.2015.2471094
   Mauthner T., 2008, INT J COMPUTER SCI S, V6, P21
   McGinnis P., 1999, BIOMECHANICS SPORT E
   Moore KC, 2015, PROCEDIA ENGINEER, V112, P473, DOI 10.1016/j.proeng.2015.07.227
   Nam CNK, 2014, IEEE T INSTRUM MEAS, V63, P943, DOI 10.1109/TIM.2013.2283548
   Noiumkar S, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATICS AND CREATIVE MULTIMEDIA (ICICM), P310, DOI 10.1109/ICICM.2013.58
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Pan MS, 2016, PERVASIVE MOB COMPUT, V31, P37, DOI 10.1016/j.pmcj.2016.01.011
   Amaro JP, 2016, IEEE IND ELEC, P5171, DOI 10.1109/IECON.2016.7793729
   Platt JC, 2000, ADV NEUR IN, P61
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shao L, 2012, PATTERN RECOGN LETT, V33, P438, DOI 10.1016/j.patrec.2011.05.015
   Urtasun R, 2005, PROC CVPR IEEE, P932
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yeadon MR, 1994, J SPORT SCI, V12, P3, DOI 10.1080/02640419408732156
   Zhang LC, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P711
   Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007
   Zhu R, 2004, IEEE T NEUR SYS REH, V12, P295, DOI 10.1109/TNSRE.2004.827825
NR 50
TC 12
Z9 12
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2018
VL 75
BP 1
EP 10
DI 10.1016/j.imavis.2018.04.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GM3LM
UT WOS:000438006100001
DA 2024-07-18
ER

PT J
AU Bringer, J
   Morel, C
   Rathgeb, C
AF Bringer, Julien
   Morel, Constance
   Rathgeb, Christian
TI Security analysis and improvement of some biometric protected templates
   based on Bloom filters
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Bloom filter; Biometric security
AB In this work, we develop an unlinkability and irreversibility analysis of the so-called Bloom filter-based iris biometric template protection introduced at ICB 2013. We go further than the unlinkability analysis of Hermans et al. presented at BIOSIG 2014. Firstly we analyse unlinkability on protected templates built from two different iriscodes coming from the same iris whereas Hermans et al. analysed only protected templates from the same iriscode. Moreover we introduce an irreversibility analysis that exploits non-uniformity of the biometric data. Our experiments demonstrate new vulnerabilities of this scheme. Then we will discuss the security of other similar protected biometric templates based on Blooms filters that have been suggested in the literature since 2013. Finally we suggest a Secure Multiparty Computation (SMC) protocol, that benefits of the alignment-free feature of this Bloom filter construction, in order to compute efficiently and securely the matching scores. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Bringer, Julien; Morel, Constance] Safran Ident & Secur, Issy Les Moulineaux, France.
   [Rathgeb, Christian] Hsch Darmstadt, Da Sec Biometr & Internet Secur Res Grp, Darmstadt, Germany.
C3 Hochschule Darmstadt
RP Morel, C (corresponding author), Safran Ident & Secur, Issy Les Moulineaux, France.
EM bringer.julien@safrangroup.com; morel.constance@safrangroup.com;
   christian.rathgeb@h-da.de
RI Bringer, Julien/KVY-0557-2024
FU European FP7 FIDELITY project [SEC-2011-284862]; FP7 BEAT project
   [SEC-2011-284989]
FX This work has been partially funded by the European FP7 FIDELITY project
   (SEC-2011-284862) and the FP7 BEAT project (SEC-2011-284989).
CR [Anonymous], 1987, STOC, DOI DOI 10.1145/28395.28420
   [Anonymous], 2011, 20 USENIX SEC S SAN
   [Anonymous], 2008, IEEE 19 INT C PATT R
   [Anonymous], [No title captured]
   [Anonymous], 2013, Financial Cryptography and Data Security
   Asharov Gilad, 2013, ACM CCS 2013, P535, DOI DOI 10.1145/2508859.2516738
   Bringer J., 2014, P ACM INF HID MULT S
   Ishai Y, 2003, LECT NOTES COMPUT SC, V2729, P145
   Kolesnikov V, 2008, LECT NOTES COMPUT SC, V5126, P486, DOI 10.1007/978-3-540-70583-3_40
   Kolesnikov V, 2009, LECT NOTES COMPUT SC, V5888, P1, DOI 10.1007/978-3-642-10433-6_1
   Naor Moni, 1999, P 1 ACM C EL COMM DE, P129
   Pinkas B, 2009, LECT NOTES COMPUT SC, V5912, P250, DOI 10.1007/978-3-642-10366-7_15
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2014, COMPUT SECUR, V42, P1, DOI 10.1016/j.cose.2013.12.005
   Rathgeb C., 2001, P INT WORKSH BIOM FO, P448
   Rathgeb C., 2013, P ICB, P1, DOI DOI 10.1109/ICB.2013.6612976
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
NR 17
TC 26
Z9 26
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 239
EP 253
DI 10.1016/j.imavis.2016.08.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700023
DA 2024-07-18
ER

PT J
AU Persch, N
   Schroers, C
   Setzer, S
   Weickert, J
AF Persch, Nico
   Schroers, Christopher
   Setzer, Simon
   Weickert, Joachim
TI Physically inspired depth-from-defocus
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth-from-defocus; Joint denoising and depth-from-defocus;
   Multiplicative Euler-Lagrange formalism
ID VARIATIONAL APPROACH; SHAPE; IMAGES; FIELD; REGULARIZATION;
   DECONVOLUTION; FOCUS
AB We propose a novel variational approach to the depth-from-defocus problem. The quality of such methods strongly depends on the modelling of the image formation (forward operator) that connects depth with out of-focus blur. Therefore, we discuss different image formation models and design a forward operator that preserves essential physical properties such as a maximum minimum principle for the intensity values. This allows us to approximate the thin-lens camera model in a better way than previous approaches. Our forward operator refrains from any equifocal assumptions and fits well into a variational framework. Additionally, we extend our model to the multi-channel case and show the benefits of a robustification. To cope with noisy input data, we embed our method in a joint depth-from-defocus and denoising approach. For the minimisation of our energy functional, we show the advantages of a multiplicative Euler Lagrange formalism in two aspects: First, it constrains our soltition to the plausible positive range. Second, we are able to develop a semi implicit gradient descent scheme with a higher stability range. While synthetic experiments confirm the achieved improvements, experiments on real data illustrate the applicability of the overall method. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Persch, Nico; Schroers, Christopher; Setzer, Simon; Weickert, Joachim] Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, Campus E1-7, D-66041 Saarbrucken, Germany.
C3 Saarland University
RP Persch, N (corresponding author), Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, Campus E1-7, D-66041 Saarbrucken, Germany.
EM persch@mia.uni-saarland.de; schroers@mia.uni-saarland.de;
   setzer@mia.uni-saarland.de; weickert@mia.uni-saarland.de
FU Deutsche Forschungsgemeinschaft (DFG); Cluster of Excellence Multimodal
   Computing and Interaction
FX Our research has been partly funded by the Deutsche
   Forschungsgemeinschaft (DFG) through a Gottfried Wilhelm Leibniz Prize
   for Joachim Weickert and the Cluster of Excellence Multimodal Computing
   and Interaction.
CR Aguet F, 2008, IEEE T IMAGE PROCESS, V17, P1144, DOI 10.1109/TIP.2008.924393
   Bailey S.W., 2014, VISUAL COMPUT, V31, P1
   Barsky BA, 2008, REC ADV COMPUT ENG, P999
   BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962
   Bhasin SS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P488, DOI 10.1109/ICCV.2001.937556
   Born M., 1970, Principles of Optics: Electromagnetic Theory of Propagation, Interference, and Diffraction of Light, V4th
   Cant R., 2012, 2012 UKSim 14th International Conference on Computer Modelling and Simulation (UKSim), P159, DOI 10.1109/UKSim.2012.30
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Chaudhuri S., 1999, DEPTH DEFOCUS REAL A
   Cook R. L., 1984, Computers & Graphics, V18, P137
   Favaro P, 2003, PROC CVPR IEEE, P179
   Favaro P, 2000, LECT NOTES COMPUT SC, V1842, P755
   Favaro P, 2008, IEEE T PATTERN ANAL, V30, P518, DOI 10.1109/TPAMI.2007.1175
   Gelfand I.M., 2000, Calculus of Variations
   Hong L, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P212, DOI 10.1109/ICMV.2009.32
   Hu H, 2007, LECT NOTES COMPUT SC, V4678, P461
   Huber P J, 2004, ROBUST STAT, V1
   Jin HL, 2002, LECT NOTES COMPUT SC, V2351, P18
   Ludusan C, 2012, PATTERN RECOGN LETT, V33, P1388, DOI 10.1016/j.patrec.2012.02.017
   Luenberger Y Ye D.G., 2008, LINEAR NONLINEAR PRO, V3rd
   Marquina A, 1999, LECT NOTES COMPUT SC, V1682, P429
   Namboodiri V.P., 2004, P 4 IND C COMP VIS G, P133
   Namboodiri VP, 2007, PATTERN RECOGN LETT, V28, P311, DOI 10.1016/j.patrec.2006.04.011
   Namboodiri VP, 2008, IEEE IMAGE PROC, P1520, DOI 10.1109/ICIP.2008.4712056
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Persch N, 2014, LECT NOTES COMPUT SC, V8753, P15, DOI 10.1007/978-3-319-11752-2_2
   Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011
   Pharr M., 2004, PHYS BASED THEORY IM
   Rajagopalan AN, 1997, IEEE T PATTERN ANAL, V19, P1158, DOI 10.1109/34.625126
   ROKITA P, 1993, COMPUT GRAPH, V17, P593, DOI 10.1016/0097-8493(93)90010-7
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   RUDIN LI, 1994, IEEE IMAGE PROC, P31
   Subbarao M., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P149, DOI 10.1109/CCV.1988.589986
   Subbarao M, 1997, P SOC PHOTO-OPT INS, V3174, P174, DOI 10.1117/12.279778
   SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349
   SUGIMOTO SA, 1985, APPL OPTICS, V24, P2076, DOI 10.1364/AO.24.002076
   Tikhonov A.N., 1963, SOV MATH DOKL, V5, P1035, DOI DOI 10.1111/J.1365-246X.2012.05699.X
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei YJ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P1887
   Welk M, 2005, LECT NOTES COMPUT SC, V3663, P485
   Welk M, 2007, LECT NOTES COMPUT SC, V4477, P386
   Whittaker ET., 1923, P EDINBURGH MATH SOC, V41, P65
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P416, DOI 10.1109/83.491316
   You YL, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P461, DOI 10.1109/ICIP.1996.560885
NR 46
TC 7
Z9 7
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 114
EP 129
DI 10.1016/j.imavis.2016.08.011
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800010
DA 2024-07-18
ER

PT J
AU Schuckers, S
AF Schuckers, Stephanie
TI Presentations and attacks, and spoofs, oh my
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Biometrics Conference
CY OCT, 2015
CL London, ENGLAND
DE Biometric recognition; Spoofing; Presentation attacks; Fingerprint
AB "Presentation attacks" are attacks at a biometric recognition data capture sensor which interfere with its normal operation. When artificial materials are used to create a fake biometric characteristic, it has been more commonly termed spoofing and the artifacts used to attack the system have been called spoofs. This paper gives an overview of this field, describes vocabulary formalized by the recent publication of an ISO standard for biometric "presentation attack detection," and discusses evaluating the performance of systems which incorporate methods to detect and reject presentation attacks. In particular, this paper describes terms such as "attack presentation classification error rate" and "attack presentation match rate" from the ISO standard. To reduce confusion, it is important to differentiate metrics related to presentation attacks from the false accept rate which is specifically referring "zero-effort" imposter attempts, not a presentation attack. Last, some considerations for the future which relate to evaluating the performance of presentation attack detection are discussed. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Schuckers, Stephanie] Clarkson Univ, Potsdam, NY 13699 USA.
C3 Clarkson University
RP Schuckers, S (corresponding author), Clarkson Univ, Potsdam, NY 13699 USA.
EM sschucke@clarkson.edu
RI Schuckers, Stephanie/F-6197-2017
OI Schuckers, Stephanie/0000-0002-9365-9642
FU Direct For Computer & Info Scie & Enginr; Division Of Computer and
   Network Systems [1068055] Funding Source: National Science Foundation
CR Anjos A., 2013, P IEEE C COMP VIS PA
   [Anonymous], 19 INT C PATT REC, DOI [10.1109/ICPR.2008.4761673., DOI 10.1109/ICPR.2008.4761673]
   [Anonymous], 2013, BBC News
   Derakhshani R, 2003, PATTERN RECOGN, V36, P383, DOI 10.1016/S0031-3203(02)00038-9
   Henniger O., 2010, SECURITY EVALUATION
   International Standards Organization, 2016, 37 ISOIEC TC JTC1SC
   International Standards Organization, 37 ISOIEC TC JTC1SC
   International Standards Organization, 1979512006 ISOIEC
   Johnson P., 2014, EVALUATION PRESENTAT
   Marasco E, 2011, LECT NOTES COMPUT SC, V6713, P309, DOI 10.1007/978-3-642-21557-5_33
   Matsumoto T., 2002, P SPIE, V4677
   Newton E., 2016, INT BIOM PERF C
   Peterson A., 2015, The Washington Post
   Zhang YY, 2007, LECT NOTES COMPUT SC, V4642, P742
NR 14
TC 15
Z9 17
U1 1
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
BP 26
EP 30
DI 10.1016/j.imavis.2016.03.016
PN 1
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA ED8BO
UT WOS:000389097100008
OA hybrid
DA 2024-07-18
ER

PT J
AU Lim, J
   Ryu, M
AF Lim, Jongwoo
   Ryu, Minsoo
TI Optimized projection patterns for stereo systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active stereo; Stereo matching; Projection pattern; De Bruijn sequence;
   Structured light
ID SPACETIME STEREO
AB This paper describes how to generate optimal projection patterns to supplement general stereo camera systems. In contrast to structured light, the active stereo systems utilize the projected patterns only as auxiliary information in correspondence search, whereas the structured light systems have to detect the patterns and decode them to compute depth. The concept of non-recurring De Bruijn sequences is introduced, and a few algorithms based on the non-recurring De Bruijn sequence are designed to build optimized projection patterns for several stereo parameters. When only the search window size of a stereo system is given, we show that a non-recurring De Bruijn sequence with corresponding parameters makes the longest functional pattern, and presents experimental results using real scenes to show the effectiveness of the proposed projection patterns. Additionally if the pattern length is given in the form of maximum disparity search range, the algorithm using branch-and-bound search scheme to find an optimal sub-sequence of a non-recurring De Bruijn sequence is proposed. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Lim, Jongwoo; Ryu, Minsoo] Hanyang Univ, Div Comp Sci & Engn, Seoul 133791, South Korea.
C3 Hanyang University
RP Lim, J (corresponding author), Hanyang Univ, Rm 505,IT BT Bldg,222 Wangsimni Ro, Seoul 133791, South Korea.
EM jlim@hanyang.ac.kr
FU MSIP, Korea, under the ICT R\D programs [10047078, 14-824-09-006];
   C-ITRC [IITP-2015-H8601-15-1005]
FX We thank the reviewers for valuable comments and suggestions. The work
   is supported by the MSIP, Korea, under the ICT R\&D programs (No.
   10047078 and No. 14-824-09-006) and the C-ITRC
   (IITP-2015-H8601-15-1005), supervised by the IITP.
CR [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587702
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37
   FREDRICKSEN H, 1982, SIAM REV, V24, P195, DOI 10.1137/1024041
   IDDAN G, 2001, SPIE, V4298
   Konolige K, 2010, IEEE INT CONF ROBOT, P148, DOI 10.1109/ROBOT.2010.5509796
   LEIBE B, 2007, P COMP VIS PATT REC
   LIM J., 2009, Robotics and Automation, P2823
   Maurice X., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2497, DOI 10.1109/CVPR.2011.5995490
   Oggier T, 2006, LECT NOTES ARTIF INT, V4021, P212
   Pagès J, 2005, IMAGE VISION COMPUT, V23, P707, DOI 10.1016/j.imavis.2005.05.007
   Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Taguchi Y., 2012, EUR C COMP VIS ECCV
   Tombari F., 2010, CONTR AUT ROB VIS IC, P1886
   Young M., 2007, CVPR, P1
   Zalevsky Z., 2007, Patent Application, Patent No. [WO/2007/043036, 20070430364]
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang L, 2003, PROC CVPR IEEE, P367
   Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035
NR 20
TC 1
Z9 3
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2015
VL 39
BP 10
EP 22
DI 10.1016/j.imavis.2015.04.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CM2WQ
UT WOS:000357543400002
DA 2024-07-18
ER

PT J
AU Pehlivan, S
   Forsyth, DA
AF Pehlivan, Selen
   Forsyth, David A.
TI Recognizing activities in multiple views with fusion of frame judgments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video analysis; Human activity recognition; Multiple views; Multiple
   camera
ID RECOGNITION; REPRESENTATION; MOTION
AB This paper focuses on activity recognition when multiple views are available. In the literature, this is often performed using two different approaches. In the first one, the systems build a 3D reconstruction and match that. However, there are practical disadvantages to this methodology since a sufficient number of overlapping views is needed to reconstruct, and one must calibrate the cameras. A simpler alternative is to match the frames individually. This offers significant advantages in the system architecture (e.g., it is easy to incorporate new features and camera dropouts can be tolerated). In this paper, the second approach is employed and a novel fusion method is proposed. Our fusion method collects the activity labels over frames and cameras, and then fuses activity judgments as the sequence label. It is shown that there is no performance penalty when a straightforward weighted voting scheme is used. In particular, when there are enough overlapping views to generate a volumetric reconstruction, our recognition performance is comparable with that produced by volumetric reconstructions. However, if the overlapping views are not adequate, the performance degrades fairly gracefully, even in cases where test and training views do not overlap. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Pehlivan, Selen] Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
   [Forsyth, David A.] Univ Illinois, Dept Comp Sci, Urbana, IL USA.
C3 Ihsan Dogramaci Bilkent University; University of Illinois System;
   University of Illinois Urbana-Champaign
RP Pehlivan, S (corresponding author), TED Univ, Dept Comp Engn, Ankara, Turkey.
EM selen.pehlivan@tedu.edu.tr
OI Narzullaev, Davronbek/0000-0002-3073-2697
FU research fellowship of Scientific and Technical Research Council of
   Turkey; University of Illinois at Urbana-Champaign
FX S. Pehlivan was supported in part by the research fellowship of
   Scientific and Technical Research Council of Turkey while studying as a
   visiting scholar at University of Illinois at Urbana-Champaign.
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Andoni A., 2006, FDN COMPUTER SCI
   [Anonymous], 2009, ICCV
   [Anonymous], 2009, CVPR
   [Anonymous], 2011, CVPR
   [Anonymous], 2007, CVPR
   [Anonymous], 2003, ICCV
   [Anonymous], 2004, ICPR
   [Anonymous], 2010, ECCV
   [Anonymous], 1994, CVPR
   [Anonymous], 2005, ICCV
   [Anonymous], 2008, CVPR
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Doll'ar P., 2008, ECCV
   Farhadi Ali., 2008, ECCV
   Forsyth D., 2006, Foundations and Trends in Computer Graphics and Vision, V1, P1
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang F., 2006, ARTICULATED MOTION D
   Ikizler N, 2008, INT J COMPUT VISION, V80, P337, DOI 10.1007/s11263-008-0142-8
   Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002
   Junejo Imran N, 2010, IEEE T PATTERN ANAL
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I., 2007, ICCV
   Lin Z., 2009, ICCV
   Liu J., 2008, CVPR
   Naiel M.A., 2011, IEEE WORKSH WACV
   Parameswaran V, 2005, COMPUT VIS IMAGE UND, V98, P295, DOI 10.1016/j.cviu.2004.09.002
   Pehlivan S, 2011, COMPUT VIS IMAGE UND, V115, P140, DOI 10.1016/j.cviu.2010.11.004
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ramanan D, 2011, IEEE T PATTERN ANAL, V33, P794, DOI 10.1109/TPAMI.2010.127
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Scovanner Paul., 2007, ACM Multimedia
   Syeda-Mahmood T, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P64, DOI 10.1109/EVENT.2001.938868
   Tran D., 2008, ECCV
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Wang P, 2013, INT J COMPUT VISION, V103, P1, DOI 10.1007/s11263-012-0588-6
   Wang Y., 2007, ACCV
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Weinland Daniel., 2010, ECCV
   Yan P., 2008, CVPR
   Yimaz A, 2006, COMPUT VIS IMAGE UND, V104, P221, DOI 10.1016/j.cviu.2006.07.012
NR 46
TC 8
Z9 10
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2014
VL 32
IS 4
BP 237
EP 249
DI 10.1016/j.imavis.2014.01.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AG0MN
UT WOS:000335109700002
DA 2024-07-18
ER

PT J
AU Slama, R
   Wannous, H
   Daoudi, M
AF Slama, Rim
   Wannous, Hazem
   Daoudi, Mohamed
TI 3D human motion analysis framework for shape similarity and retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Motion analysis; Shape similarity; 3D video retrieval; 3D human action
ID SEGMENTATION; RECOGNITION; POINT; POSE
AB 3D shape similarity from video is a challenging problem lying at the heart of many primary research areas in computer graphics and computer vision applications. In this paper, we address within a new framework the problem of 3D shape representation and shape similarity in human video sequences. Our shape representation is formulated using extremal human curve (EHC) descriptor extracted from the body surface. It allows taking benefits from Riemannian geometry in the open curve shape space and therefore computing statistics on it. It also allows subject pose comparison regardless of geometrical transformations and elastic surface change. Shape similarity is performed by an efficient method which takes advantage of a compact EHC representation in open curve shape space and an elastic distance measure. Thanks to these main assets, several important exploitations of the human action analysis are performed: shape similarity computation, video sequence comparison, video segmentation, video clustering, summarization and motion retrieval.
   Experiments on both synthetic and real 3D human video sequences show that our approach provides an accurate static and temporal shape similarity for pose retrieval in video, compared with the state-of-the-art approaches. Moreover, local 3D video retrieval is performed using motion segmentation and dynamic time warping (DTW) algorithm in the feature vector space. The obtained results are promising and show the potential of this approach. Crown Copyright (C) 2014 Published by Elsevier B.V. All rights reserved.
C1 [Slama, Rim; Wannous, Hazem; Daoudi, Mohamed] Univ Lille 1, Ctr Hyperfrequences & Semicond, CNRS, LIFL Lab,UMR 8022, F-59655 Villeneuve Dascq, France.
   [Slama, Rim; Wannous, Hazem] Univ Lille 1, F-59655 Villeneuve Dascq, France.
   [Daoudi, Mohamed] Inst Mines Telecom Telecom Lille, Villeneuve Dascq, France.
C3 Universite de Lille; Centre National de la Recherche Scientifique
   (CNRS); Universite de Lille
RP Wannous, H (corresponding author), Rue Marconi, F-59650 Villeneuve Dascq, France.
EM rim.slama@telecom-lille.fr; hazem.wannous@telecom-lille.fr;
   mohamed.daoudi@telecom-lille.fr
RI Rim, Slama/AER-7993-2022; Daoudi, Mohammed/H-5935-2013
OI Daoudi, Mohammed/0000-0003-4219-7860; Slama Salmi,
   Rim/0000-0003-2723-9874
FU Region Nord-Pas de Calais (France)
FX This research program is supported partially by the Region Nord-Pas de
   Calais (France).
CR Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], 2003, 7 CENTR EUR SEM COMP
   [Anonymous], P ACM S SOL MOD APP
   [Anonymous], P 4 INT S 3D DAT PRO
   Cheung KM, 2005, INT J COMPUT VISION, V62, P221, DOI 10.1007/s11263-005-4881-5
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   El Khoury R, 2012, INT C PATT RECOG, P1964
   Giorgino T, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i07
   Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x
   Huang P., 2010, P 5 INT S 3D DAT PRO
   Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9
   Jing Wang, 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE), P498
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Joshi Shantanu H, 2007, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2007, P1
   Kahol K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P883, DOI 10.1109/AFGR.2004.1301645
   Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394
   Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378
   Mahmoudi S, 2007, PATTERN RECOGN LETT, V28, P1705, DOI 10.1016/j.patrec.2007.04.012
   Michor PW, 2006, J EUR MATH SOC, V8, P1, DOI 10.4171/JEMS/37
   Mortara M, 2002, SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P245, DOI 10.1109/SMI.2002.1003552
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Ovsjanikov M, 2010, COMPUT GRAPH FORUM, V29, P1555, DOI 10.1111/j.1467-8659.2010.01764.x
   Peng Huang, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1510, DOI 10.1109/ICCVW.2009.5457434
   Rui Y, 2000, PROC CVPR IEEE, P111, DOI 10.1109/CVPR.2000.855807
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Shiratori T, 2003, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P89, DOI 10.1109/MFI-2003.2003.1232638
   Slama R., 2013, P IEEE INT C WORKSH, P1
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tabia H, 2011, IEEE T PATTERN ANAL, V33, P852, DOI 10.1109/TPAMI.2010.202
   Tak YS, 2012, ENG APPL ARTIF INTEL, V25, P1301, DOI 10.1016/j.engappai.2012.03.020
   Tierny J, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P105
   Tung T., 2005, International Journal of Shape Modeling, V11, P91, DOI 10.1142/S0218654305000748
   Tung T, 2012, IEEE T PATTERN ANAL, V34, P1645, DOI 10.1109/TPAMI.2011.258
   Tung T, 2009, IEEE I CONF COMP VIS, P1709, DOI 10.1109/ICCV.2009.5459384
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang L, 2011, IEEE T IMAGE PROCESS, V20, P1725, DOI 10.1109/TIP.2010.2102043
   Wang TS, 2001, LECT NOTES COMPUT SC, V2195, P174
   Xu J., 2005, IEEE INT C IM PROC I, V1, P701
   Yamasaki T, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/59535
   Yamasaki T, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1909, DOI 10.1109/ICME.2006.262929
   Yezzi A, 2005, IEEE I CONF COMP VIS, P913
   ZHENG YY, 2013, PAIRWISE HARMONICS S, V19, P1172
NR 52
TC 17
Z9 17
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2014
VL 32
IS 2
BP 131
EP 154
DI 10.1016/j.imavis.2013.12.011
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AD0DS
UT WOS:000332905300004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Han, JW
   McKenna, SJ
AF Han, Junwei
   McKenna, Stephen J.
TI Lattice estimation from images of patterns that exhibit translational
   symmetry
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Texture; Statistical image representation; Pattern recognition
ID REGULAR TEXTURE ANALYSIS; MODEL SELECTION; PERIODICITY; FEATURES; SHAPE
AB The analysis of regular texture images is cast in a model comparison framework. Texel lattice hypotheses are used to define statistical models which are compared in terms of their ability to explain the images. This approach is used to estimate lattice geometry from patterns that exhibit translational symmetry (regular textures). It is also used to determine whether images consist of such regular textures. A method based on this approach is described in which lattice hypotheses are generated using analysis of peaks in the image autocorrelation function, statistical models are based on Gaussian or Gaussian mixture clusters, and model comparison is performed using the marginal likelihood as approximated by the Bayes Information Criterion (BIC). Experiments on public domain images and a commercial textile image archive demonstrate substantially improved accuracy compared to several alternative methods. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Han, Junwei] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
   [Han, Junwei; McKenna, Stephen J.] Univ Dundee, Sch Comp, Dundee DD1 4HN, Scotland.
C3 Northwestern Polytechnical University; University of Dundee
RP McKenna, SJ (corresponding author), Univ Dundee, Sch Comp, Dundee DD1 4HN, Scotland.
EM jhan@nwpu.edu.cn; stephen@computing.dundee.ac.uk
RI McKenna, Stephen/AAL-8335-2020
OI McKenna, Stephen/0000-0003-0530-2035
FU UK Technology Strategy Board; Liberty Art Fabrics; System Simulation
   Ltd.; Victoria 82 Albert Museum
FX The authors are grateful to Ruixuan Wang and Annette Ward for their
   helpful discussions. They would like to thank J. Hays and M. Park for
   providing their source code. This research was supported by the UK
   Technology Strategy Board grant "FABRIC: Fashion and Apparel Browsing
   for Inspirational Content" in collaboration with Liberty Art Fabrics,
   System Simulation Ltd., and the Victoria 82 Albert Museum.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   [Anonymous], CMURITR0736
   Charalampidis D, 2006, IEEE T IMAGE PROCESS, V15, P777, DOI 10.1109/TIP.2005.860604
   Chetverikov D, 2000, IMAGE VISION COMPUT, V18, P975, DOI 10.1016/S0262-8856(00)00041-X
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Forsyth DA, 2002, LECT NOTES COMPUT SC, V2352, P225
   Gimel'farb G., 2003, GEOMETRY MORPHOLOGY, P137
   Han JW, 2008, LECT NOTES COMPUT SC, V5305, P242
   Han JW, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P347
   Hays J., 2006, EUR C COMP VIS GRAZ, P533
   Lee K. L., 2002, Pattern Recognition and Image Analysis, V12, P400
   Lee KL, 2005, IMAGE VISION COMPUT, V23, P479, DOI 10.1016/j.imavis.2004.12.002
   Leu JG, 2001, IMAGE VISION COMPUT, V19, P987, DOI 10.1016/S0262-8856(01)00061-0
   Leung T.K., 1996, P EUR C COMP VIS ECC, VI, P546
   Lin HC, 1997, PATTERN RECOGN LETT, V18, P433, DOI 10.1016/S0167-8655(97)00030-5
   Lin WC, 2007, IEEE T PATTERN ANAL, V29, P777, DOI 10.1109/TPAMI.2007.1053
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   Liu Y., IEEE T PATTERN ANAL, V26
   Liu YX, 2004, ACM T GRAPHIC, V23, P368, DOI 10.1145/1015706.1015731
   Lobay A, 2004, PROC CVPR IEEE, P400
   MacKay D., 2003, INFORM THEORY INFERE
   Park M., 2010, ACCV 3, P329
   Park M., 2008, COMP VIS PATT REC C
   Park M, 2008, LECT NOTES COMPUT SC, V5303, P474, DOI 10.1007/978-3-540-88688-4_35
   Park M, 2009, IEEE T PATTERN ANAL, V31, P1804, DOI 10.1109/TPAMI.2009.73
   Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063
   Schaffalitzky F, 1999, LECT NOTES COMPUT SC, V1681, P165
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Starovoitov VV, 1998, IEEE T SYST MAN CY A, V28, P839, DOI 10.1109/3468.725354
   Tuytelaars T, 2003, IEEE T PATTERN ANAL, V25, P418, DOI 10.1109/TPAMI.2003.1190569
   Wu F, 2007, PATTERN RECOGN, V40, P2271, DOI 10.1016/j.patcog.2006.10.017
   Wu P, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P3, DOI 10.1109/IVL.1999.781114
   Zeng G., 2008, COMPUTER VISION PATT, P1
NR 33
TC 7
Z9 7
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2014
VL 32
IS 1
BP 64
EP 73
DI 10.1016/j.imavis.2013.12.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AB0RV
UT WOS:000331500700006
DA 2024-07-18
ER

PT J
AU Zhao, X
   Dellandréa, E
   Zou, JH
   Chen, LM
AF Zhao, Xi
   Dellandrea, Emmanuel
   Zou, Jianhua
   Chen, Liming
TI A unified probabilistic framework for automatic 3D facial expression
   analysis based on a Bayesian belief inference and statistical feature
   models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Bayesian Belief Network; Statistical feature model; 3D face; Facial
   expression recognition; Action units recognition; Automatic landmarking
ID RECOGNITION; FACE
AB Textured 3D face models capture precise facial surfaces along with the associated textures, making it possible for an accurate description of facial activities. In this paper, we present a unified probabilistic framework based on a novel Bayesian Belief Network (BBN) for 3D facial expression and Action Unit (AU) recognition. The proposed BBN performs Bayesian inference based on Statistical Feature Models (SFM) and Gibbs-Boltzmann distribution and feature a hybrid approach in fusing both geometric and appearance features along with morphological ones. When combined with our previously developed morphable partial face model (SFAM), the proposed BBN has the capacity of conducting fully automatic facial expression analysis. We conducted extensive experiments on the two public databases, namely the BU-3DFE dataset and the Bosphorus dataset. When using manually labeled landmarks, the proposed framework achieved an average recognition rate of 94.2% and 85.6% for the 7 and 16 AU on face data from the Bosphorus dataset respectively, and 89.2% for the six universal expressions on the BU-3DFE dataset. Using the landmarks automatically located by SFAM, the proposed BBN still achieved an average recognition rate of 84.9% for the six prototypical facial expressions. These experimental results demonstrate the effectiveness of the proposed approach and its robustness in landmark localization errors. Published by Elsevier B.V.
C1 [Zhao, Xi; Dellandrea, Emmanuel; Chen, Liming] Univ Lyon, CNRS, Ecole Cent Lyon, LIRIS,UMR5205, F-69134 Lyon, France.
   [Zou, Jianhua] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Ecole Centrale de Lyon; Centre National de la Recherche Scientifique
   (CNRS); Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Xi'an Jiaotong University
RP Zhao, X (corresponding author), Univ Lyon, CNRS, Ecole Cent Lyon, LIRIS,UMR5205, F-69134 Lyon, France.
EM zhaoxi1@hotmail.com; emmanuel.dellandrea@ec-lyon.fr;
   jhzou@sei.xjtu.edu.cn; liming.chen@ec-lyon.fr
RI zhao, xi/E-9335-2013; Zou, Jianhua/AAE-5536-2020
OI zhao, xi/0000-0001-9983-6366; 
FU French National Research Agency, Agence Nationale de Recherche
   (ANR),through the ANR FAR3D project [ANR-07-SESU-004-03]; French
   National Research Agency, Agence Nationale de Recherche (ANR),through
   the ANR 3D Face Analyzer project [ANR 2010 INTB 0301 01]
FX This work was supported in part by the French National Research Agency,
   Agence Nationale de Recherche (ANR),through the ANR FAR3D project under
   the grant ANR-07-SESU-004-03, and the ANR 3D Face Analyzer project under
   the grant ANR 2010 INTB 0301 01.
CR [Anonymous], ICCV09 WORKSH HUM CO
   [Anonymous], HDB FACE RECOGNITION
   [Anonymous], 2008 23 INT S COMP I
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], BRIT MACH VIS C
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], RECOGNIZING FACIAL E
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], INT C SYST MAN CYB
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], 1 COST 2101 WORKSH B
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Chan CH, 2007, LECT NOTES COMPUT SC, V4642, P809
   Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Duda R., 1973, Pattern Classification and Scene Analysis
   Ekman P., 2005, WHAT FACE REVEALS BA
   Ekman P, 1978, FACIAL ACTION CODING
   Fang T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P603, DOI 10.1109/FG.2011.5771466
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Gökberk B, 2008, IEEE T SYST MAN CY B, V38, P155, DOI 10.1109/TSMCB.2007.908865
   Hall M., 1999, PhD thesis, DOI 10.1.1.149.3848
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Huang D., 2010, Consumer Communications and Networking Conference (CCNC), P1
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Mpiperis I, 2008, IEEE T INF FOREN SEC, V3, P498, DOI 10.1109/TIFS.2008.924598
   Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M., 2006, PROC MULTIMODAL INTE, P239
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Kassim SRA, 2006, IEEE IMAGE PROC, P661
   Rosato M., 2008, INT C BIOMETRICS THE, P1
   Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008
   Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022
   Tang H., 2008, IEEE INT C AUTOMATIC, P1
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Tong Y, 2010, IEEE T PATTERN ANAL, V32, P258, DOI 10.1109/TPAMI.2008.293
   Venkatesh YV, 2009, PATTERN RECOGN LETT, V30, P1128, DOI 10.1016/j.patrec.2009.04.007
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhao X., 2011, IEEE Trans. Syst Man Cybern. B, P1
   Zhao X, 2009, LECT NOTES COMPUT SC, V5807, P686
NR 50
TC 23
Z9 25
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2013
VL 31
IS 3
BP 231
EP 245
DI 10.1016/j.imavis.2012.10.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 122NK
UT WOS:000317324600002
DA 2024-07-18
ER

PT J
AU Vosters, L
   Shan, CF
   Gritti, T
AF Vosters, Luc
   Shan, Caifeng
   Gritti, Tommaso
TI Real-time robust background subtraction under rapidly changing
   illumination conditions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Background subtraction; EM; Eigenbackground; Illumination changes
AB Fast robust background subtraction under sudden lighting changes is a challenging problem in many applications. In this paper, we propose a real-time approach, which combines the Eigenbackground and Statistical Illumination method to address this issue. The first algorithm is used to reconstruct the background frame, while the latter improves the foreground segmentation. In addition, we introduce an online spatial likelihood model by detecting reliable background pixels. Extensive quantitative experiments illustrate our approach consistently achieves significantly higher precision at high recall rates, compared to several state-of-the-art illumination invariant background subtraction methods. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Vosters, Luc] Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands.
   [Shan, Caifeng; Gritti, Tommaso] Philips Res, Eindhoven, Netherlands.
C3 Eindhoven University of Technology; Philips; Philips Research
RP Vosters, L (corresponding author), Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands.
EM l.p.j.vosters@tue.nl; caifeng.shan@philips.com;
   tommaso.gritti@philips.com
RI Shan, Caifeng/W-6178-2019
OI Shan, Caifeng/0000-0002-2131-1671
CR [Anonymous], EUR WORKSH ADV VID B
   Di Stefano L., 2007, ACCV WORKSH MULT MUL
   Friedman N., 1997, PROC UNCERTAINTY ART, P175
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525
   Han BH, 2007, LECT NOTES COMPUT SC, V4842, P162
   MCDONNELL MJ, 1981, COMPUT VISION GRAPH, V17, P65, DOI 10.1016/S0146-664X(81)80009-3
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Pilet J, 2008, LECT NOTES COMPUT SC, V5305, P567, DOI 10.1007/978-3-540-88693-8_42
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tombari F, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P376, DOI 10.1109/ICIAP.2007.4362807
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Vosters L., 2011, DATASET DEMO SEQUENC
   Vosters L. P. J., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P384, DOI 10.1109/AVSS.2010.72
   Xie BL, 2004, IMAGE VISION COMPUT, V22, P117, DOI 10.1016/j.imavis.2003.07.003
   Xu ZF, 2006, LECT NOTES COMPUT SC, V4261, P779
NR 18
TC 18
Z9 21
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 1004
EP 1015
DI 10.1016/j.imavis.2012.08.017
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800008
DA 2024-07-18
ER

PT J
AU Chiranjeevi, P
   Sengupta, S
AF Chiranjeevi, P.
   Sengupta, S.
TI Robust detection of moving objects in video sequences through rough set
   theory framework
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Background subtraction; Rough set; 3D histon; 3D fuzzy histon; 3D HRI;
   3D FHRI
ID BACKGROUND SUBTRACTION; SEGMENTATION
AB Detection of moving objects in the presence of challenging background situations like swaying vegetation, rippling water, camera jitter etc., is known to be a difficult task. Background subtraction is considered to be better than the other approaches in terms of robustness. Its success primarily depends on the proper choice of background model(s) associated with every pixel for its foreground/background labeling. In this work, we have adopted rough-set theoretic measures to embed the spatial similarity around a neighborhood as a model for the pixel. Basic histon and its associated measure Basic Histon Roughness Index (BHRI) have been reported in the literature. It was applied to still image segmentation with impressive performance. Its adoption in video sequences for foreground/background labeling is proposed herein. We extended the histon concept to a 3D histon, which considers the intensities across the color planes in a combined manner, instead of considering independent color planes. Further, we also incorporated fuzziness into the 3D HRI measure. The labeling decision is based on Bhattacharyya distance between the model HRI and the corresponding measure in the current frame. Adoption of rough set theoretic concept into moving object segmentation is nontrivial, as the model updating requires careful consideration so that the pixels associated with gradually changing background or dynamic background are labeled as background and at the same time, slow moving objects are never adopted into the background model. A novel background model update strategy proposed herein takes these into consideration and also eliminates the need of having exclusive ideal background frame initially. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Chiranjeevi, P.; Sengupta, S.] Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Chiranjeevi, P (corresponding author), Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
EM chiru.pojala@gmail.com; ssg@ece.iitkgp.ernet.in
RI Kolekar, Maheshkumar/ABF-8942-2020
OI Kolekar, Maheshkumar/0000-0002-4272-3528
CR [Anonymous], RECENT PAT COMPUT SC
   [Anonymous], 2008, PROC 5 INT ICST C MO
   [Anonymous], IEEE WORKSH HAPT AUD
   [Anonymous], LOCAL KERNEL COLOR H
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], INT WORKSH INT COMP
   [Anonymous], P CVPR
   [Anonymous], LNCS
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Chen YT, 2007, PATTERN RECOGN, V40, P2706, DOI 10.1016/j.patcog.2006.11.023
   Chiranjeevi P, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3662910
   Cristani M, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/343057
   El Baf F, 2008, LECT NOTES COMPUT SC, V5358, P772, DOI 10.1007/978-3-540-89639-5_74
   Guo-Wu Yuan, 2011, Advanced Intelligent Computing Theories and Applications. With Aspects of Artificial Intelligence. 7th International Conference, ICIC 2011. Revised Selected Papers, P541, DOI 10.1007/978-3-642-25944-9_70
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Herrero S, 2009, LECT NOTES COMPUT SC, V5807, P33
   Jang D, 2008, LECT NOTES COMPUT SC, V5068, P222
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lee Yongcheol., 2011, Frontiers of Computer Vision (FCV), 2011 17th Korea-Japan Joint Workshop on, P1
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Mason M, 2001, 30TH APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P154, DOI 10.1109/AIPR.2001.991219
   Matsuyama T., 2000, P AS C COMP VIS, P622
   Mohabey A, 2000, IEEE SYS MAN CYBERN, P1529, DOI 10.1109/ICSMC.2000.886073
   Mohabey A, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P338, DOI 10.1109/NAFIPS.2000.877448
   Mushrif MM, 2008, PATTERN RECOGN LETT, V29, P483, DOI 10.1016/j.patrec.2007.10.026
   Pawlak Z., 1991, ROUGH SETS THEORETIC
   Pojala C., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P255, DOI 10.1109/ICSIPA.2011.6144098
   Russell D, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P417
   Satpathy A, 2008, LECT NOTES COMPUT SC, V5358, P406, DOI 10.1007/978-3-540-89639-5_39
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Wei Zhou, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P314, DOI 10.1109/ICIG.2011.76
   Xue G., 2011, ICME, P1
   Xue GJ, 2010, IEEE INT CON MULTI, P1050, DOI 10.1109/ICME.2010.5582601
   Zhang SP, 2009, INT J PATTERN RECOGN, V23, P1397, DOI 10.1142/S0218001409007569
   Zhang SP, 2008, IEEE IMAGE PROC, P1556, DOI 10.1109/ICIP.2008.4712065
NR 35
TC 20
Z9 23
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2012
VL 30
IS 11
BP 829
EP 842
DI 10.1016/j.imavis.2012.06.015
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 052CW
UT WOS:000312176300004
DA 2024-07-18
ER

PT J
AU Phillips, PJ
   Beveridge, JR
   Draper, BA
   Givens, G
   O'Toole, AJ
   Bolme, D
   Dunlop, J
   Lui, YM
   Sahibzada, H
   Weimer, S
AF Phillips, P. Jonathon
   Beveridge, J. Ross
   Draper, Bruce A.
   Givens, Geof
   O'Toole, Alice J.
   Bolme, David
   Dunlop, Joseph
   Lui, Yui Man
   Sahibzada, Hassan
   Weimer, Samuel
TI The Good, the Bad, and the Ugly Face Challenge Problem
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Face recognition; Challenge problem
ID RECOGNITION ALGORITHMS
AB The Good, the Bad, and the Ugly Face Challenge Problem was created to encourage the development of algorithms that are robust to recognition across changes that occur in still frontal faces. The Good, the Bad, and the Ugly consists of three partitions. The Good partition contains pairs of images that are considered easy to recognize. The base verification rate (VR) is 0.98 at a false accept rate (FAR) of 0.001. The Bad partition contains pairs of images of average difficulty to recognize. For the Bad partition, the VR is 0.80 at a FAR of 0.001. The Ugly partition contains pairs of images considered difficult to recognize, with a VR of 0.15 at a FAR of 0.001. The base performance is from fusing the output of three of the top performers in the FRVT 2006. The design of the Good, the Bad, and the Ugly controls for posevariation, subject aging, and subject "recognizability." Subject recognizability is controlled by having the same number of images of each subject in every partition. This implies that the differences in performance among the partitions are a result of how a face is presented in each image. Published by Elsevier B.V.
C1 [Phillips, P. Jonathon; Sahibzada, Hassan] Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA.
   [Beveridge, J. Ross; Draper, Bruce A.; Givens, Geof; Bolme, David; Lui, Yui Man] Colorado State Univ, Ft Collins, CO USA.
   [O'Toole, Alice J.; Dunlop, Joseph; Weimer, Samuel] Univ Texas Dallas, Richardson, TX 75083 USA.
C3 National Institute of Standards & Technology (NIST) - USA; Colorado
   State University; University of Texas System; University of Texas Dallas
RP Phillips, PJ (corresponding author), Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA.
EM jonathon@nist.gov
OI Bolme, David/0000-0003-3807-7436; O'Toole, Alice/0000-0001-7981-1508;
   Beveridge, Ross/0000-0001-6489-6676
CR [Anonymous], P 9 INT C AUT FAC GE
   [Anonymous], 2006, P 2 INT WORKSHOP MUL
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Beveridge J.R., 2011, P 9 INT C AUT FAC GE
   Beveridge J. R., 2010, P IEEE COMP SOC IEEE
   DODDINGTON G, 1998, P ICSLP 98
   Grother P., 2010, Report on the evaluation of 2d still-image face recognition algorithms
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   LUI YM, 2009, IEEE 3 INT C BIOM TH
   Phillips P. J., 2009, P 3 IAPR INT C BIOM
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Ross A., 2009, IEEE 3 INT C BIOM TH
   SIM T, 2001, CVPR WORKSH MOD VERS
   Teli M.N., 2011, INT JOINT C BIOM
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang H., 2004, P INT C IM PROC, V2, P1397
   Yager N, 2010, IEEE T PATTERN ANAL, V32, P220, DOI 10.1109/TPAMI.2008.291
   Zou X., 2007, IEEE INT C BIOM THEO
NR 21
TC 45
Z9 52
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 177
EP 185
DI 10.1016/j.imavis.2012.01.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000006
DA 2024-07-18
ER

PT J
AU Vretos, N
   Solachidis, V
   Pitas, I
AF Vretos, N.
   Solachidis, V.
   Pitas, I.
TI A mutual information based face clustering algorithm for movie content
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face clustering; Mutual information; Normalized cuts; Spectral graph
   analysis; Image processing
ID REGISTRATION; ENTROPY
AB This paper investigates facial image clustering, primarily for movie video content analysis with respect to actor appearance. Our aim is to use novel formulation of the mutual information as a facial image similarity criterion and, by using spectral graph analysis, to cluster a similarity matrix containing the mutual information of facial images. To this end, we use the HSV color space of a facial image ( more precisely, only the hue and saturation channels) in order to calculate the mutual information similarity matrix of a set of facial images. We make full use of the similarity matrix symmetries, so as to lower the computational complexity of the new mutual information calculation. We assign each row of this matrix as feature vector describing a facial image for producing a global similarity criterion for face clustering. In order to test our proposed method, we conducted two sets of experiments that have produced clustering accuracy of more than 80%. We also compared our algorithm with other clustering approaches, such as the k-means and fuzzy c-means (FCM) algorithms. Finally, in order to provide a baseline comparison for our approach, we compared the proposed global similarity measure with another one recently reported in the literature. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Vretos, N.; Solachidis, V.; Pitas, I.] Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Vretos, N (corresponding author), Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
EM vretos@aiia.csd.auth.gr; pitas@aiia.csd.auth.gr
RI Vretos, Nicholas/ABA-6038-2021; Solachidis, Vassilios/C-3895-2013
OI Vretos, Nicholas/0000-0003-3604-9685; Solachidis,
   Vassilios/0000-0002-0761-5396
CR CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248, DOI 10.1109/TPAMI.1986.4767778
   Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Cherif I, 2006, INT FED INFO PROC, V217, P385
   Chung F. R. K., 1997, Spectral graph theory
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Cullum J., 2002, LANCZOS ALGORITHMS L
   Fitzgibbon A, 2002, LECT NOTES COMPUT SC, V2352, P304
   Fitzgibbon A., 2003, COMP VIS PATT REC 20, V1, P1
   Foucher S, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P113, DOI 10.1109/CRV.2007.13
   KRINIDIS M, 2005, P IEEE INT C AC SPEE, P452
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Likar B, 2001, IMAGE VISION COMPUT, V19, P33, DOI 10.1016/S0262-8856(00)00053-6
   Liu ZM, 2010, IEEE T IMAGE PROCESS, V19, P2502, DOI 10.1109/TIP.2010.2048963
   Loutas E, 2004, IEEE T CIRC SYST VID, V14, P128, DOI 10.1109/TCSVT.2003.819178
   Messer K, 1999, Second International Conference on Audio and Video-based Biometric Person Authentication, P72
   Paninski L, 2003, NEURAL COMPUT, V15, P1191, DOI 10.1162/089976603321780272
   Petajan E., 1995, PROC 1 INT WORKSHOP, P41
   Pluim JPW, 2000, COMPUT VIS IMAGE UND, V77, P211, DOI 10.1006/cviu.1999.0816
   Pluim JPW, 2000, IEEE T MED IMAGING, V19, P809, DOI 10.1109/42.876307
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Pluim JPW, 2004, IEEE T MED IMAGING, V23, P1508, DOI 10.1109/TMI.2004.836872
   Rajwade A, 2009, IEEE T PATTERN ANAL, V31, P475, DOI 10.1109/TPAMI.2008.97
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sobottka K., 1997, Pattern Recognition and Image Analysis, V7, P124
   Sossa H., 1992, COMP VIS PATT REC P, P811
   Studholme C, 1997, MEASURES 3D MED IMAG
   Sural S., 2002, P IEEE INT C IM PROC, DOI DOI 10.1109/ICIP.2002.1040019
   Thévenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976
   UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778
   Vretos N., 2006, P INT C MULT EXP ICM
   Yang J, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P142, DOI 10.1109/ACV.1996.572043
   [No title captured]
NR 34
TC 21
Z9 22
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2011
VL 29
IS 10
BP 693
EP 705
DI 10.1016/j.imavis.2011.07.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 848YP
UT WOS:000297091300005
DA 2024-07-18
ER

PT J
AU Michel, D
   Oikonomidis, I
   Argyros, A
AF Michel, Damien
   Oikonomidis, Iasonas
   Argyros, Antonis
TI Scale invariant and deformation tolerant partial shape matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Partial shape matching; 2D shape descriptors; Dynamic programming
ID REPRESENTATION
AB We present a novel approach to the problem of establishing the best match between an open contour and a part of a closed contour. At the heart of the proposed scheme lies a novel shape descriptor that also permits the quantification of local scale. Shape descriptors are computed along open or closed contours in a spatially non-uniform manner. The resulting ordered collections of shape descriptors constitute the global shape representation. A variant of an existing Dynamic Time Warping (DTW) matching technique is proposed to handle the matching of shape representations. Due to the properties of the employed shape descriptor, sampling scheme and matching procedure, the proposed approach performs partial shape matching that is invariant to Euclidean transformations, starting point as well as to considerable shape deformations. Additionally, the problem of matching closed-to-closed contours is naturally treated as a special case. Extensive experiments on benchmark datasets but also in the context of specific applications, demonstrate that the proposed scheme outperforms existing methods for the problem of partial shape matching and performs comparably to methods for full shape matching. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Michel, Damien; Oikonomidis, Iasonas; Argyros, Antonis] FORTH, Inst Comp Sci, Iraklion, Crete, Greece.
   [Oikonomidis, Iasonas; Argyros, Antonis] Univ Crete, Dept Comp Sci, Iraklion, Greece.
C3 Foundation for Research & Technology - Hellas (FORTH); University of
   Crete
RP Argyros, A (corresponding author), N Plastira 100, GR-70013 Iraklion, Crete, Greece.
EM argyros@ics.forth.gr
RI Argyros, Antonis/AAD-9251-2019; Argyros, Antonis/GPK-4775-2022
OI Argyros, Antonis/0000-0001-8230-3192
FU GRASP [IST-FP7-IP-215821]
FX This work was partially supported by the IST-FP7-IP-215821 project
   GRASP.
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2003, KDD
   Arica N, 2002, INT C PATT RECOG, P375, DOI 10.1109/ICPR.2002.1047923
   Backes AR, 2009, PATTERN RECOGN, V42, P54, DOI 10.1016/j.patcog.2008.07.006
   Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1
   Belongie S, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P20, DOI 10.1109/IVL.2000.853834
   Cui M, 2009, PATTERN RECOGN LETT, V30, P1, DOI 10.1016/j.patrec.2008.08.013
   Ebrahim Y, 2009, PATTERN RECOGN LETT, V30, P348, DOI 10.1016/j.patrec.2008.09.013
   Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Latecki LJ, 2007, PATTERN RECOGN, V40, P3069, DOI 10.1016/j.patcog.2007.03.004
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6
   Sakoe H., 1971, P 7 INT C AC BUD
   Schmidt FR, 2007, IEEE I CONF COMP VIS, P1479
   Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602
   Torres RD, 2007, IMAGE VISION COMPUT, V25, P3, DOI 10.1016/j.imavis.2005.12.010
   Torres RD, 2004, PATTERN RECOGN, V37, P1163, DOI 10.1016/j.patcog.2003.10.007
   Wu A, 2009, APPL SOFT COMPUT, V9, P282, DOI 10.1016/j.asoc.2007.10.027
   Yang XW, 2008, LECT NOTES COMPUT SC, V5305, P788, DOI 10.1007/978-3-540-88693-8_58
NR 22
TC 26
Z9 30
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2011
VL 29
IS 7
BP 459
EP 469
DI 10.1016/j.imavis.2011.01.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 786YW
UT WOS:000292344800003
DA 2024-07-18
ER

PT J
AU Audigier, R
   Lotufo, RD
AF Audigier, Romaric
   Lotufo, Roberto de Alencar
TI Relationships between some watershed definitions and their tie-zone
   transforms
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 8th International Symposium on Mathematical Morphology
CY OCT 10-13, 2007
CL Rio de Janeiro, BRAZIL
DE Image segmentation; Watershed transform; Graph theory; Minimum spanning
   forest; Shortest-path forest
ID IMAGE; ALGORITHMS
AB To better understand the numerous solutions related to watershed transform (WT), this paper shows the relationships between some discrete definitions of the WT, especially those based on image foresting transform (IFT) with/without lexicographic cost function, topographic distance (TD). local condition (LC), flooding (F). and minimum spanning forest (MSF). Some of these paradigms allow multiple solutions. The tie-zone (TZ) transform returns a unique solution from a set of multiple solutions of a given WT. We demonstrate that the TZ transform applied to the IFT-WT includes all the solutions predicted by the other paradigms. More precisely, the watershed line of TD-WT and F-WT are contained in the TZ of the IFT-WT, while the catchment basins of TD-WT or F-WT contain the basins of the TZ-IFT-WT. In addition, the TD-WT can be seen as the tie-zone transform of the LC-WT. Furthermore, any solution of LC-WT or MSF-WT is also solution of the IFT-WT. Finally, MSF-WT and IFT-WT have the same tie-zone transform. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Audigier, Romaric] MINES Paristech, Ctr Morphol Math Math & Syst, F-77305 Fontainebleau, France.
   [Lotufo, Roberto de Alencar] Univ Estadual Campinas, UNICAMP, Fac Engn Eletr & Computacao, BR-13083852 Campinas, SP, Brazil.
C3 Universite PSL; MINES ParisTech; Universidade Estadual de Campinas
RP Audigier, R (corresponding author), MINES Paristech, Ctr Morphol Math Math & Syst, 35 Rue St Honore, F-77305 Fontainebleau, France.
EM audigier@cmm.ensmp.fr
RI Audigier, Romaric/ADS-8946-2022; Lotufo, Roberto/C-1496-2009
OI Audigier, Romaric/0000-0002-4757-2052; Lotufo,
   Roberto/0000-0002-5652-0852
CR [Anonymous], 1979, P INT WORKSHOP IMAGE
   Audigier R, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P55
   AUDIGIER R, 2005, P IEEE INT C IM PROC, V2, P654
   AUDIGIER R, 2007, P 8 INT S MATH MORPH
   Audigier R, 2007, J MATH IMAGING VIS, V27, P157, DOI 10.1007/s10851-007-0780-4
   Audigier R, 2006, SIBGRAPI, P53
   Beucher S., 1993, MATH MORPHOLOGY IMAG, P433, DOI [10.1201/9781482277234-12, DOI 10.1201/9781482277234-12]
   Bieniek A, 1998, COMP IMAG VIS, V12, P215
   Bieniek A, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P237
   Couprie M, 1997, P SOC PHOTO-OPT INS, V3168, P136, DOI 10.1117/12.292778
   Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076
   Falcao AX, 2001, PROC SPIE, V4322, P468, DOI 10.1117/12.431120
   GONDRAN M, 1984, GRAPHS ALGORITHMS, P129
   Lin YC, 2006, IEEE T IMAGE PROCESS, V15, P632, DOI 10.1109/TIP.2005.860996
   Lotufo R, 2000, COMPUT IMAGING VIS, V18, P341
   Lotufo RA, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P146, DOI 10.1109/SIBGRA.2002.1167137
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   Meyer F, 1994, COMP IMAG VIS, V2, P77
   NAJMAN L, 1994, SIGNAL PROCESS, V38, P99, DOI 10.1016/0165-1684(94)90059-0
   Osma-Ruiz V, 2007, PATTERN RECOGN, V40, P1078, DOI 10.1016/j.patcog.2006.06.025
   PRETEUX F, 1993, MATH MORPHOLOGY IMAG, P323
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Udupa JK, 2002, IEEE T PATTERN ANAL, V24, P1485, DOI 10.1109/TPAMI.2002.1046162
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
NR 24
TC 7
Z9 7
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2010
VL 28
IS 10
SI SI
BP 1472
EP 1482
DI 10.1016/j.imavis.2009.11.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 638YK
UT WOS:000280936300006
DA 2024-07-18
ER

PT J
AU Lee, CF
   Chen, HL
   Lai, SH
AF Lee, Chin-Feng
   Chen, Hsing-Ling
   Lai, Shu-Hua
TI An adaptive data hiding scheme with high embedding capacity and visual
   image quality based on SMVQ prediction through classification codebooks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Data hiding; Image quality of stego-image; Embedding capacity;
   Side-match vector quantization; SMVQ prediction
ID SIDE-MATCH; VECTOR; ALGORITHM
AB This study exploits the characteristics of image blocks to develop an adaptive data hiding scheme that is based on SMVQ prediction. Since human beings' eyes are highly sensitive to smooth images, changes in smooth cause great distortion and attract the attention of interceptors. Hence, this study proposes a data embedding scheme for embedding secret data into edge blocks and non-sufficiently smooth blocks. The experimental results show that the proposed scheme improves the quality of the stego-image and the embedding capacity. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Lee, Chin-Feng; Lai, Shu-Hua] Chaoyang Univ Technol, Dept Informat Management, Wufong Township 41349, Taichung County, Taiwan.
   [Chen, Hsing-Ling] Chaoyang Univ Technol, Doctoral Program, Grad Inst Informat, Wufong Township 41349, Taichung County, Taiwan.
C3 Chaoyang University of Technology; Chaoyang University of Technology
RP Lee, CF (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifong E Rd, Wufong Township 41349, Taichung County, Taiwan.
EM lcf@cyut.edu.tw; hsingling@cyut.edu.tw; s9514618@cyut.edu.tw
CR Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Chang CC, 2005, IEICE T INF SYST, VE88D, P2159, DOI 10.1093/ietisy/e88-d.9.2159
   CHANG CC, 2000, IMAGING SCI J, V48, P43
   Chang CC, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P541
   De Natale FGB, 2000, IEEE J SEL AREA COMM, V18, P1111, DOI 10.1109/49.848260
   Du WC, 2003, IEE P-VIS IMAGE SIGN, V150, P233, DOI 10.1049/ip-vis:20030525
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Kii H, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P895, DOI 10.1109/MMCS.1999.779321
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P813, DOI 10.1109/83.923277
   Lin SD, 2000, IEICE T INF SYST, VE83D, P1671
   Lin YC, 1998, IEEE T CIRCUITS-II, V45, P432, DOI 10.1109/82.664257
   Lin YC, 1999, NATL COMPUTER S, P76
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Shie SC, 2006, IEICE T INF SYST, VE89D, P358, DOI 10.1093/ietisy/e89-d.1.358
   Tai SC, 1996, IEEE T COMMUN, V44, P1623, DOI 10.1109/26.545888
   Tsai JC, 2000, IEEE T IMAGE PROCESS, V9, P1825, DOI 10.1109/83.877206
   Wu MN, 2008, J SYST SOFTWARE, V81, P1505, DOI 10.1016/j.jss.2007.09.017
NR 19
TC 26
Z9 26
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1293
EP 1302
DI 10.1016/j.imavis.2010.01.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400011
DA 2024-07-18
ER

PT J
AU Kristan, M
   Skocaj, D
   Leonardis, A
AF Kristan, M.
   Skocaj, D.
   Leonardis, A.
TI Online kernel density estimation for interactive learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Online learning; Kernel density estimation; Mixture models; Unlearning;
   Compression; Hellinger distance; Unscented transform
ID SELECTION
AB In this paper we propose a Gaussian-kernel-based online kernel density estimation which can be used for applications of online probability density estimation and online learning. Our approach generates a Gaussian mixture model of the observed data and allows online adaptation from positive examples as well as from the negative examples. The adaptation from the negative examples is realized by a novel concept of unlearning in mixture models. Low complexity of the mixtures is maintained through a novel compression algorithm. In contrast to the existing approaches, our approach does not require fine-tuning parameters for a specific application, we do not assume specific forms of the target distributions and temporal constraints are not assumed on the observed data. The strength of the proposed approach is demonstrated with examples of online estimation of complex distributions, an example of unlearning, and with an interactive learning of basic visual concepts. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Kristan, M.; Skocaj, D.; Leonardis, A.] Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia.
   [Kristan, M.] Univ Ljubljana, Fac Elect Engn, Ljubljana 1000, Slovenia.
C3 University of Ljubljana; University of Ljubljana
RP Kristan, M (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, Ljubljana 1000, Slovenia.
EM matej.kristan@fri.uni-lj.si
FU EU [FP6-004250-IP, FP7-ICT-215181-IP];  [P2-0214 (RS)]
FX This research has been supported in part by: Research Program P2-0214
   (RS), EU FP6-004250-IP project CoSy and EU FP7-ICT-215181-IP project
   CogX.
CR [Anonymous], 2009, MATLAB LANGUAGE TECH
   ARANDJELOVIC O, 2005, BRIT MACH VIS C, P759
   ARDIZZONE E, 1992, J INTELLIGENT SYSTEM, V1, P273
   Arsenio AM, 2004, IEEE IJCNN, P3167
   Bischof H, 2001, IMAGE VISION COMPUT, V19, P619, DOI 10.1016/S0262-8856(01)00043-9
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550
   Corduneanu C. Bishop, 2001, ARTIF INTELL, V18, P27
   DECLERCQ A, 2008, INT C COMP VIS IM CO, P605
   *EF PROJ, 2008, COGX COGN SYST SELF
   *EF PROJ, 2004, COSY COGN SYST COGN
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   GALES WF, 2004, COMPUT SPEECH LANG, V20, P22
   Girolami M, 2003, IEEE T PATTERN ANAL, V25, P1253, DOI 10.1109/TPAMI.2003.1233899
   GOLDBERGER J, 2005, NEUR INF P SYST, P505
   Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771
   Holub A, 2008, PROC CVPR IEEE, P885
   Jones MC, 1996, J AM STAT ASSOC, V91, P401, DOI 10.2307/2291420
   Julier S.J., 1996, GEN METHOD APPROXIMA
   KIRSTEIN S, 2005, 27 PATT REC S DAGM, P301
   Leonardis A, 1998, NEURAL NETWORKS, V11, P963, DOI 10.1016/S0893-6080(98)00051-3
   McGrory CA, 2007, COMPUT STAT DATA AN, V51, P5352, DOI 10.1016/j.csda.2006.07.020
   McLachlan G. J., 1997, The EM Algorithm and Extensions, V473, P486
   Pollard D., 2002, A User's Guide to Measure Theoretic Probability
   Press W. H, 1992, NUMERICAL RECIPES C
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Scott DW, 2001, TECHNOMETRICS, V43, P323, DOI 10.1198/004017001316975916
   SKOCAJ D, 2008, INT C COMP VIS THEOR
   Song MZ, 2005, PROC SPIE, V5803, P174, DOI 10.1117/12.601724
   SZEWCZYK WF, 2005, TIME EVOLVING ADAPTI
   Veach E., 1995, P 22 ANN C COMP GRAP, P419, DOI [DOI 10.1145/218380.218498, 10.1145/218380.218498]
   Wand M.P., 1994, KERNEL SMOOTHING
   ZHANG K, 2006, NEUR INF P SYST
   ZIYKOVIC Z, 2004, IEEE T PATTERN ANAL, V26, P651
   2007, ONL LEARN CLASS WORK
   2008, ONL LEARN CLASS WORK
NR 36
TC 24
Z9 29
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2010
VL 28
IS 7
SI SI
BP 1106
EP 1116
DI 10.1016/j.imavis.2009.09.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 603UP
UT WOS:000278233900005
DA 2024-07-18
ER

PT J
AU Ding, LY
   Martinez, AM
AF Ding, Liya
   Martinez, Aleix M.
TI Modelling and recognition of the linguistic components in American Sign
   Language
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE American Sign Language; Handshape; Motion reconstruction; Multiple cue
   recognition; Computer vision
ID EXTRACTION
AB The manual signs in sign languages are generated and interpreted using three basic building blocks: handshape, motion, and place of articulation. When combined, these three components (together with palm orientation) uniquely determine the meaning of the manual sign. This means that the use of pattern recognition techniques that only employ a subset of these components is inappropriate for interpreting the sign or to build automatic recognizers of the language. In this paper, we define an algorithm to model these three basic components form a single video sequence of two-dimensional pictures of a sign. Recognition of these three components are then combined to determine the class of the signs in the videos. Experiments are performed on a database of (isolated) American Sign Language (ASL) signs. The results demonstrate that, using semi-automatic detection, all three components can be reliably recovered from two-dimensional video sequences, allowing for an accurate representation and recognition of the signs. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Ding, Liya; Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Ding, LY (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, 2015 Neil Ave, Columbus, OH 43210 USA.
EM dingl@ece.osu.edu; aleix@ece.osu.edu
RI Martinez, Aleix M/A-2380-2008; Ding, Liya/HHZ-3407-2022
OI Ding, Liya/0000-0002-1209-875X
FU National Institutes of Health [R01-DC-005241]; National Science
   Foundation [IIS-07-13055]
FX This research was supported in part by a grant from the National
   Institutes of Health and a grant from the National Science Foundation.;
   We are grateful to Ronnie Wilbur for her wonderful descriptions of the
   inner-workings of ASL. This research was supported in part by Grant
   R01-DC-005241 from the National Institutes of Health and Grant
   IIS-07-13055 from the National Science Foundation.
CR [Anonymous], THESIS U PENNSYLVANI
   ARAN O, 2006, ENTERFACE WORKSH
   ARULAMPALAM MS, 2002, P IEEE COMP VIS PATT, V50
   BRASHEAR H, 2006, P C ACM SIGACCESS CO
   BRENTARI D, 2000, PROSODIC MODEL SIGN
   Cui Y, 2000, COMPUT VIS IMAGE UND, V78, P157, DOI 10.1006/cviu.2000.0837
   Dennis John., 1987, Numerical Methods for Unconstrained Optimization and Nonlinear Equations, V16
   DING L, 2006, P 2 IEEE WORKSH VIS
   DING L, 2008, P IEEE COMP VIS PATT
   EMMOREY K, 1999, LANGUAGE GESTURE SPA
   FANG G, 2002, P IEEE AUT FAC GEST
   GORCE ML, 2008, P IEEE COMP VIS PATT
   Grunert JA., 1841, Grunerts Archiv fur Mathematik und Physik, V1, P238
   HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   HERNANDEZREBOLL.JL, 2004, P IEEE AUT FAC GEST
   Imagawa K, 2000, INT C PATT RECOG, P849, DOI 10.1109/ICPR.2000.903050
   Jacobs DW, 2001, COMPUT VIS IMAGE UND, V82, P57, DOI 10.1006/cviu.2001.0906
   Jia HJ, 2009, IEEE T PATTERN ANAL, V31, P841, DOI 10.1109/TPAMI.2008.122
   Kuhn NS, 2006, SIGN LANG LINGUIST, V9, P33, DOI 10.1075/sll.9.1-2.05kuh
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Martínez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250
   MARTINEZ AM, 2002, P IEEE MULT INT PITT
   MESSING MS, 1999, GESTURE SPEECH SIGN
   Nayak S, 2009, IEEE T PATTERN ANAL, V31, P795, DOI 10.1109/TPAMI.2008.80
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   STOKE WC, 2005, J DEAF STUDIES DEAF, V10
   Stoke WC, 1976, DICT AM SIGN LANGUAG
   Su MC, 2000, IEEE T SYST MAN CY C, V30, P276, DOI 10.1109/5326.868448
   TAMURA S, 1988, PATTERN RECOGN, V21, P343, DOI 10.1016/0031-3203(88)90048-9
   Tanibata N., 2002, PROC INT C VISION IN, P391
   Vamplew S, 2007, NEUROPSYCHOL TRENDS, P31
   Von Agris Ulrich, 2006, C COMP VIS PATT REC, P159, DOI DOI 10.1109/CVPRW.2006.165
   Wang JB, 2008, IEEE T PATTERN ANAL, V30, P477, DOI 10.1109/TPAMI.2007.1178
   Wilbur R.B., 1979, AM SIGN LANGUAGE SIG
   WILBUR RB, 2002, PHYS CORRELATES PROS, V38
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   YANG R, 2007, P IEEE C COMP VIS PA
   YE J, 2004, P IEEE INT C IM GRAP
   Zhu ML, 2008, IEEE T NEURAL NETWOR, V19, P148, DOI 10.1109/TNN.2007.904040
NR 42
TC 42
Z9 49
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2009
VL 27
IS 12
SI SI
BP 1826
EP 1844
DI 10.1016/j.imavis.2009.02.005
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 513PL
UT WOS:000271335000009
PM 20161003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Ong, EJ
   Ellis, L
   Bowden, R
AF Ong, Eng-Jon
   Ellis, Liam
   Bowden, Richard
TI Problem solving through imitation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cognitive system; Complexity Chain; Learning from imitation; Problem
   solving
AB This paper presents an approach to problem solving through imitation. It introduces the Statistical and Temporal Percept Action Coupling (ST-PAC) System which statistically models the dependency between the perceptual state of the world and the resulting actions that this state should elicit. The ST-PAC system stores a sparse set of experiences provided by a teacher. These memories are stored to allow efficient recall and generalisation over novel systems states. Random exploration is also used as a fall-back "brute-force" mechanism should a recalled experience fail to solve a scenario. Statistical models are used to couple groups of percepts with similar actions and incremental learning used to incorporate new experiences into the system. The system is demonstrated within the problem domain of a children's shape sorter puzzle. The ST-PAC system provides an emergent architecture where competence is implicitly encoded within the system. in order to train and evaluate such emergent architectures, the concept of the Complexity Chain is proposed. The Complexity Chain allows efficient structured learning in a similar fashion to that used in biological system and can also be used as a method for evaluating a cognitive system's performance. Tests demonstrating the Complexity Chain in learning are shown in both simulated and live environments. Experimental results show that the proposed methods allowed for good generalisation and concept refinement from an initial set of sparse examples provided by a tutor. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Ong, Eng-Jon; Ellis, Liam; Bowden, Richard] Univ Surrey, Sch Elect & Phys Sci, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
C3 University of Surrey
RP Ong, EJ (corresponding author), Univ Surrey, Sch Elect & Phys Sci, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
EM e.ong@surrey.ac.uk; l.ellis@surrey.ac.uk; r.bowden@surrey.ac.uk
RI Bowden, Richard/AAF-8283-2019
OI Bowden, Richard/0000-0003-3285-8020
CR [Anonymous], 2006, MOTOR COGNITION WHAT
   [Anonymous], 2007, INT J ADV ROBOT SYST
   [Anonymous], 1995, Mind as Motion: Explorations in the Dynamics of Cognition
   Buccino G, 2004, BRAIN LANG, V89, P370, DOI 10.1016/S0093-934X(03)00356-0
   Dichter-Blancher TB, 1997, INFANT BEHAV DEV, V20, P545, DOI 10.1016/S0163-6383(97)90043-6
   ELLIS L, 2007, P 5 INT C COMP VIS S
   Felsberg M, 2006, IEEE T PATTERN ANAL, V28, P209, DOI 10.1109/TPAMI.2006.29
   FELSBERG M, 2005, AAAI FALL S REACT AN, P65
   Felsberg M, 2007, LECT NOTES COMPUT SC, V4522, P908
   FITZPATRICK P, THESIS MIT
   FORSSEN PE, 2006, 3 CAN C COMP ROB VIS
   Granlund GH, 1999, SIGNAL PROCESS, V74, P101, DOI 10.1016/S0165-1684(98)00204-7
   HOPPE F, 2007, THESIS C ALBRECHTS U
   Hoppe F, 2006, INT C PATT RECOG, P1208
   LARSSON F, 2007, ROBOMAT
   Nehaniv CL, 2007, IMITATION AND SOCIAL LEARNING IN ROBOTS, HUMANS AND ANIMALS: BEHAVIOURAL, SOCIAL AND COMMUNICATIVE DIMENSIONS, P1, DOI 10.1017/CBO9780511489808
   Rizzolatti G, 2001, NAT REV NEUROSCI, V2, P661, DOI 10.1038/35090060
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0
   Saunders J, 2008, 2008 ECSIS SYMPOSIUM ON LEARNING AND ADAPTIVE BEHAVIORS FOR ROBOTIC SYSTEMS - LAB-RS 2008, PROCEEDINGS, P9, DOI 10.1109/LAB-RS.2008.23
   Siskind JM, 2003, ARTIF INTELL, V151, P91, DOI 10.1016/S0004-3702(03)00112-7
   Thelen E., 1994, A Dynamic Systems Approach to the Development of Cognition and Action
   Vernon D, 2007, IEEE T EVOLUT COMPUT, V11, P151, DOI 10.1109/TEVC.2006.890274
   YOUNG D, 2000, P EUR C VIS PERC GRO
NR 23
TC 1
Z9 1
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 2
PY 2009
VL 27
IS 11
SI SI
BP 1715
EP 1728
DI 10.1016/j.imavis.2009.04.016
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 498HJ
UT WOS:000270127800008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Novo, J
   Penedo, MG
   Santos, J
AF Novo, J.
   Penedo, M. G.
   Santos, J.
TI Localisation of the optic disc by means of GA-optimised Topological
   Active Nets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Topological Active Nets; Genetic algorithms; Optic disc
ID NERVE HEAD; SEGMENTATION; BOUNDARY; IMAGES; MODEL
AB In this paper we propose a new approach to the optic disc localisation process in digital retinal images by means of Topological Active Nets (TAN). This is a deformable model used for image segmentation that integrates features of region-based and edge-based segmentation techniques, being able to fit the edges of the objects and model their inner topology. In this paper the active nets incorporate new energy terms for the optic disc localisation and their optimisation is performed with a genetic algorithm, with adapted or new ad hoc genetic operators. There is no need of any pre-processing of the images, which allows a quasi automatic localisation of the optic disc. This process also provides a simultaneous segmentation of the disc. We present representative results of optic disc localisations showing the advantages of the approach, with images focusing on the optic disc or on the macula, and with images with different levels of noise and lesion areas. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Novo, J.; Penedo, M. G.; Santos, J.] Univ A Coruna, Dept Comp Sci, La Coruna 15071, Spain.
C3 Universidade da Coruna
RP Novo, J (corresponding author), Univ A Coruna, Dept Comp Sci, Campus Elvina S-N, La Coruna 15071, Spain.
EM jnovo@udc.es; mgpenedo@udc.es; santos@udc.es
RI Santos, José/IAP-5866-2023; Buján, Jorge Novo/N-3366-2014; Santos,
   Jose/H-8569-2014; Penedo, Manuel/N-7767-2015
OI Buján, Jorge Novo/0000-0002-0125-3064; Santos, Jose/0000-0002-4212-1367;
   Penedo, Manuel/0000-0002-6881-0865
FU Xunta de Galicia [PGIDIT06TIC10502PR]
FX This paper has been partly funded by the Xunta de Galicia through the
   Grant contract PGIDIT06TIC10502PR.
CR ABDELGHAFAR RA, 2007, INFORM HLTH SOCIAL C, V32, P19, DOI DOI 10.1080/14639230601095865
   [Anonymous], PATTERN RECOGN IMAGE
   Ballerini L, 1999, PROC SPIE, V3812, P13, DOI 10.1117/12.367691
   Carmona EJ, 2008, ARTIF INTELL MED, V43, P243, DOI 10.1016/j.artmed.2008.04.005
   Chanwimaluang T, 2003, IEEE IMAGE PROC, P1093
   Chrastek R, 2002, BILDVERARBEITUNG MED, P263
   *DRIVE, DIG RET IM VESS EXTR
   Fan Y, 2002, IEEE T MED IMAGING, V21, P904, DOI 10.1109/TMI.2002.803126
   Foracchia M, 2004, IEEE T MED IMAGING, V23, P1189, DOI 10.1109/TMI.2004.829331
   Hoover A, 2003, IEEE T MED IMAGING, V22, P951, DOI 10.1109/TMI.2003.815900
   Ibáñez O, 2006, LECT NOTES COMPUT SC, V4141, P272
   Jelinek H., 2005, P IM VIS COMP C NZ
   Lalonde M, 2001, IEEE T MED IMAGING, V20, P1193, DOI 10.1109/42.963823
   Li HQ, 2003, PATTERN RECOGN, V36, P2093, DOI 10.1016/S0031-3203(03)00052-9
   Li HQ, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P837, DOI 10.1109/ICIP.2001.958624
   Lowell J, 2004, IEEE T MED IMAGING, V23, P256, DOI 10.1109/TMI.2003.823261
   Mendels F., 1999, P IRISH MACHINE VISI, P103
   Niemeijer M, 2007, IEEE T MED IMAGING, V26, P116, DOI 10.1109/TMI.2006.885336
   OSAREH A, 2002, 6 MED IM UND AN C, P21
   Tobin KW, 2007, IEEE T MED IMAGING, V26, P1729, DOI 10.1109/TMI.2007.902801
   Tsumiyama K., 1989, IPSJ SIG notes, V89, P1
   *VARIA, 2008, VARPA RET IM AUTH
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu J, 2005, P ANN INT IEEE EMBS, P6516, DOI 10.1109/IEMBS.2005.1615992
   Xu J, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1
NR 25
TC 24
Z9 26
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1572
EP 1584
DI 10.1016/j.imavis.2009.02.011
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800014
DA 2024-07-18
ER

PT J
AU Uematsu, Y
   Saito, H
AF Uematsu, Yuko
   Saito, Hideo
TI Multiple planes based registration using 3D Projective Space for
   Augmented Reality
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Augmented Reality; Mixed Reality; Vision-based registration; Multiple
   planes; Projective Space
AB We propose a vision-based registration method for Augmented Reality (AR) that uses real scenes containing multiple planar structures. Our method provides users with an enhanced view of a real scene by overlaying computer-generated virtual objects onto images captured with a movable camera. The virtual objects are associated with a 3D planar structure and appeared to move with that structure. To align the coordinates of the virtual objects with the coordinates of the images captured with the camera, the camera's motion should be estimated for every frame by tracking and integrating the multiple planes. In contrast with related work, the proposed method does not require a priori knowledge about the geometrical relationships among the multiple planes because the geometrical relationship is automatically estimated by "Projective Space". This space is 3D and is defined by projective reconstruction of two reference images. Automatic estimation using the Projective Space can eliminate the time-consuming task of measuring the planes and the constraints of plane arrangement, e.g. only vertical or co-planar. Therefore, the proposed method can be applied even to complicated multi-planar scenes. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Uematsu, Yuko; Saito, Hideo] Keio Univ, Sch Sci & Technol, Kohoku Ku, Yokohama, Kanagawa 2238522, Japan.
C3 Keio University
RP Uematsu, Y (corresponding author), Keio Univ, Sch Sci & Technol, Kohoku Ku, 3-14-1 Hiyoshi, Yokohama, Kanagawa 2238522, Japan.
EM yu-ko@ozawa.ics.keio.ac.jp; saito@ozawa.ics.-keio.ac.jp
RI Saito, Hideo/D-6223-2014
OI Saito, Hideo/0000-0002-2421-9862
CR Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Billinghurst M., 2000, P SIGGRAPH 2000, P87
   Chia KW, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P305, DOI 10.1109/ISMAR.2002.1115123
   Comport AI, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P36, DOI 10.1109/ISMAR.2003.1240686
   DRUMMOND T, 1999, P BMVC, P574
   Genc Y, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P295, DOI 10.1109/ISMAR.2002.1115122
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Henrysson A., 2005, Proc. 2005 Int. Conf. Augment. tele-existence - ICAT '05, P164, DOI [DOI 10.1145/1152399.1152430, 10.1145/1152399.1152430]
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   KLEIN K, 2004, P ISMAR, P38
   Satoh K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P46, DOI 10.1109/ISMAR.2003.1240687
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Simon G, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P285, DOI 10.1109/ISMAR.2002.1115118
   Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935
   SIMON G, 2002, P BMVC, P567
   Uematsu Y., 2005, Proc. of the 2005 international conference on Augmented Tele-existence, P48
   UEMATSU Y, 2006, P ACM SIGCHI INT C A, P48
   WAGNER D, 2006, P ACM SIGCHI INT C A
NR 19
TC 7
Z9 7
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1484
EP 1496
DI 10.1016/j.imavis.2009.01.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800007
DA 2024-07-18
ER

PT J
AU Farshidi, F
   Sirouspour, S
   Kirubarajan, T
AF Farshidi, F.
   Sirouspour, S.
   Kirubarajan, T.
TI Robust sequential view planning for object recognition using multiple
   cameras
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active object recognition; Pose estimation; View planning; Occlusion;
   Sensor fusion; Machine vision; Cramer-Rao lower bound; Mutual
   information
ID CRAMER-RAO BOUNDS; APPEARANCE; ALGORITHM; SELECTION
AB While prior relevant research in active object recognition/pose estimation has mostly focused on single-camera systems, we propose two multi-camera solutions to this problem that can enhance object recognition rate, particularly in the presence of occlusion. In the proposed methods, multiple cameras simultaneously acquire images from different view angles of an unknown, randomly occluded object belonging to a set of a priori known objects. By processing the available information within a recursive Bayesian framework at each step, the recognition algorithms attempt to classify the object, if its identity/pose can be determined with a high confidence level. Otherwise, the algorithms would compute the next most informative camera positions for capturing more images. The principle component analysis (PCA) is used to produce a measurement vector based on the acquired images. Occlusions in the images are handled by a novel probabilistic modelling approach that can increase the robustness of the recognition process with respect to structured noise. The camera positions at each recognition step are selected based on two statistical metrics quantifying the quality of the observations, namely the mutual information (MI) and the Cramer-Rao lower bound (CRLB). While the former has also been used in a prior relevant work, the latter is new in the context of object recognition. Extensive Monte Carlo experiments conducted with a two-camera system demonstrate the effectiveness of the proposed approaches. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Farshidi, F.; Sirouspour, S.; Kirubarajan, T.] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4K1, Canada.
C3 McMaster University
RP Sirouspour, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4K1, Canada.
EM farshif@mcmaster.ca; sirouspour@ece.mcmaster.ca; kiruba@mcmaster.ca
CR [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   [Anonymous], 2002, Numerical Recipes in C++: The Art of Scientific Computing
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2001, Estimation, Tracking and Navigation: Theory, Algorithms and Software
   ARBEL T, 1994, INT C PATT RECOG, P470, DOI 10.1109/ICPR.1994.576328
   Arbel T, 2001, INT J COMPUT VISION, V43, P205, DOI 10.1023/A:1011187530616
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Borotschnig H, 1999, COMPUTING, V62, P293, DOI 10.1007/s006070050026
   Borotschnig H, 2000, IMAGE VISION COMPUT, V18, P715, DOI 10.1016/S0262-8856(99)00075-X
   Callari FG, 1996, PROC CVPR IEEE, P701, DOI 10.1109/CVPR.1996.517149
   Chandrasekaran S, 1997, GRAPH MODEL IM PROC, V59, P321, DOI 10.1006/gmip.1997.0425
   CHEN S, 2002, P IEEE INT C ROB AUT, V3, P2545
   COOTES TF, 1992, IMAGE VISION COMPUT, V10, P289, DOI 10.1016/0262-8856(92)90044-4
   Denzler J, 2002, IEEE T PATTERN ANAL, V24, P145, DOI 10.1109/34.982896
   DENZLER J, 2000, OPTIMAL SELECTION CA
   Dickinson S. J., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P257, DOI 10.1109/ICCV.1990.139528
   Dickinson SJ, 1997, COMPUT VIS IMAGE UND, V67, P239, DOI 10.1006/cviu.1997.0532
   Frieden B. R., 1998, PHYS FISHER INFORM U
   Hernandez M, 2004, IEEE T SIGNAL PROCES, V52, P2361, DOI 10.1109/TSP.2004.831906
   Laporte C, 2004, INT C PATT RECOG, P91, DOI 10.1109/ICPR.2004.1334476
   Laporte C, 2006, INT J COMPUT VISION, V68, P267, DOI 10.1007/s11263-005-4436-9
   LEIBOWICZ L, 2000, P 3 INT C INF FUS PA
   Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830
   LEPAGE GP, 1978, J COMPUT PHYS, V27, P192
   LI X, 2004, P 7 INT C INF FUS ST, P243
   Matas J, 2002, COMPUT VIS IMAGE UND, V88, P1, DOI 10.1006/cviu.2002.0965
   Murase H., 1993, Proceedings of IEEE Workshop on Qualitative Vision (Cat. No.93TH0521-5), P39, DOI 10.1109/WQV.1993.262951
   MURASE H, 1995, IEEE T IMAGE PROCESS, V4, P620, DOI 10.1109/83.382496
   NELSON B, 1994, IEEE INT CONF ROBOT, P1351, DOI 10.1109/ROBOT.1994.351300
   Paletta L, 2000, ROBOT AUTON SYST, V31, P71, DOI 10.1016/S0921-8890(99)00079-2
   Paulus D, 2000, 5TH INTERNATIONAL WORKSHOP ON COMPUTER ARCHITECTURES FOR MACHINE PERCEPTION, PROCEEDINGS, P18, DOI 10.1109/CAMP.2000.875955
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660
   Reinhold MP, 2005, PATTERN RECOGN, V38, P739, DOI 10.1016/j.patcog.2004.10.008
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Rothganger F, 2007, IEEE T PATTERN ANAL, V29, P477, DOI 10.1109/TPAMI.2007.57
   Roy SD, 2004, PATTERN RECOGN, V37, P429, DOI 10.1016/j.patcog.2003.01.002
   Schiele B., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P50, DOI 10.1109/ICPR.1996.546722
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502
   Selinger A, 2001, PROC CVPR IEEE, P905
   Tichavsky P, 1998, IEEE T SIGNAL PROCES, V46, P1386, DOI 10.1109/78.668800
NR 41
TC 7
Z9 7
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1072
EP 1082
DI 10.1016/j.imavis.2008.09.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000009
OA Green Published
DA 2024-07-18
ER

PT J
AU Martín-Fernández, MA
   Cárdenes, R
   Muñoz-Moreno, E
   de Luis-García, R
   Martín-Fernández, M
   Alberola-López, C
AF Martin-Fernandez, Miguel A.
   Cardenes, Ruben
   Munoz-Moreno, Emma
   de Luis-Garcia, Rodrigo
   Martin-Fernandez, Marcos
   Alberola-Lopez, Carlos
TI Automatic articulated registration of hand radiographs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Elastic registration; Bone age assessment; Landmarks detection;
   Segmentation; Deformable geometry; Anatomical structures
ID BONE-AGE ASSESSMENT; SKELETAL MATURITY; INFORMATION; LANDMARK; CHILDREN
AB In this paper, we propose a methodology to automatically carry out registration of hands out of conventional X-ray images. The registration method we describe here will be referred to as "articulated registration"; the method is a landmark-based elastic registration procedure in which individual bones are affinely registered and soft tissues are elastically registered so that long skeletal structures are maintained straight while a continuous and smooth transformation is obtained all over the image. In order for the method to be fully automatic, the landmarks used for the registration are detected using a number of image processing algorithms. An optimization step for the refinement of the landmarks locations is included within the registration algorithm; the algorithm is based on an iterative procedure to maximize a local similarity measure. A final procedure to correct bone width has also been performed. We show that the articulated registration described here is robust and outperforms alternatives based on the thin-plate splines (TPS) algorithm. The algorithm for automatic landmark position finding has been tested using registered images with landmarks manually selected by an expert. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Martin-Fernandez, Miguel A.; Cardenes, Ruben; Munoz-Moreno, Emma; de Luis-Garcia, Rodrigo; Martin-Fernandez, Marcos; Alberola-Lopez, Carlos] Univ Valladolid, ETSIT, Lab Image Proc, E-47011 Valladolid, Spain.
C3 Universidad de Valladolid
RP Martín-Fernández, MA (corresponding author), Univ Valladolid, ETSIT, Lab Image Proc, Campus Miguel Delibes S-N, E-47011 Valladolid, Spain.
EM migmar@tel.uva.es; ruben@lpi.tel.uva.es; emunmor@lpi.tel.uva.es;
   rodlui@tel.uva.es; marcma@tel.uva.es; caralb@tel.uva.es
RI Muñoz-Moreno, Emma/ABD-6424-2021; Martín-Fernández, Miguel/M-1549-2014;
   Martin-Fernandez, Marcos/L-8366-2014; de Luis-García,
   Rodrigo/ABG-8045-2020; de Luis Garcia, Rodrigo/L-2468-2017;
   Alberola-Lopez, Carlos/M-1582-2014
OI Muñoz-Moreno, Emma/0000-0003-2104-7265; Martín-Fernández,
   Miguel/0000-0002-6313-9443; Martin-Fernandez,
   Marcos/0000-0001-9342-9989; de Luis Garcia, Rodrigo/0000-0001-5023-6490;
   Alberola-Lopez, Carlos/0000-0003-3684-0055
FU Spanish CICYT [TEC2004-06647-CO3-01, TEC 2007-67073/TCM]
FX The authors acknowledge the Spanish CICYT for research grants
   TEC2004-06647-CO3-01 and TEC 2007-67073/TCM. Thanks also go to Dr.
   Andres de Llano and Dr. B. Vinuela from Hospital Rio Carrion, Palencia,
   Spain, and Dr. S. Alberola, Centro de Salud Jardinillos, Palencia,
   Spain, for their valuable comments of the medical aspects of this work,
   and for the radiographs collected in the Radiology Department of the
   above mentioned hospital for research purposes.
CR Aja-Fernández S, 2004, J BIOMED INFORM, V37, P99, DOI 10.1016/j.jbi.2004.01.002
   [Anonymous], 2005, The ITK software guide
   ARSIGNY V, 2006, LNCS, P120
   ARSIGNY V, 2003, LNCS, P829
   Baiker M, 2007, I S BIOMED IMAGING, P728, DOI 10.1109/ISBI.2007.356955
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bocchi L, 2003, IEEE IMAGE PROC, P1077, DOI 10.1109/ICIP.2003.1247153
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Christensen GE, 2001, IEEE T MED IMAGING, V20, P568, DOI 10.1109/42.932742
   d'Aische AD, 2007, BIOMED SIGNAL PROCES, V2, P16, DOI 10.1016/j.bspc.2007.03.002
   Davis MH, 1997, IEEE T MED IMAGING, V16, P317, DOI 10.1109/42.585766
   de Luis-Garcia R., 2002, Proceedings of the IASTED International Conference Signal Processing, Pattern Recognition, and Application, P161
   DELUISGARCIA R, 2003, INT C IM PROC BARC S, V3, P421
   EFFORD ND, 1994, 9431 U LEEDS SCH COM
   FISHER B, 2003, MED IMAGING 2003 IMA, P1037
   Fitzpatrick JM, 2000, HDB MED IMAGING, V2, P447, DOI DOI 10.1117/3.831079.CH8
   Fletcher R., 1987, Practical Methods of Optimization, DOI [DOI 10.1002/9781118723203, 10.1002/9781118723203]
   Gertych A, 2007, COMPUT MED IMAG GRAP, V31, P322, DOI 10.1016/j.compmedimag.2007.02.012
   Greulich W.W., 1971, RADIOGRAPHIC ATLAS S
   GROSS GW, 1995, IEEE T MED IMAGING, V14, P689
   Hsieh CW, 2007, MED BIOL ENG COMPUT, V45, P283, DOI 10.1007/s11517-006-0155-9
   Jaccard P., 1901, B SOC VAUD SCI NAT, V37, P547, DOI DOI 10.5169/SEALS-266450
   Johnson HJ, 2002, IEEE T MED IMAGING, V21, P450, DOI 10.1109/TMI.2002.1009381
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   LI X, 2006, 3 INT WORKSH BIOM IM, P18
   Little JA, 1997, COMPUT VIS IMAGE UND, V66, P223, DOI 10.1006/cviu.1997.0608
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Martín-Fernández MA, 2005, PROC SPIE, V5747, P182, DOI 10.1117/12.595133
   Mattes D, 2001, PROC SPIE, V4322, P1609, DOI 10.1117/12.431046
   MORENO EM, 2005, WSEAS T COMPUT, V4, P1596
   PAPADEMETRIS X, 2005, LNCS, P919
   PATHAK A, 1986, IEEE T SYST MAN CYB, V16, P657, DOI 10.1109/TSMC.1986.289310
   PIETKA E, 1995, COMPUT MED IMAG GRAP, V19, P251, DOI 10.1016/0895-6111(95)00005-B
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Rohr K, 2001, IEEE T MED IMAGING, V20, P526, DOI 10.1109/42.929618
   Rosner B., 2010, FUNDAMENTALS BIOSTAT
   Tanner JM, 1983, Assessment of Skeletal Maturity and Prediction of Adult Height (TW2 Method), V2nd
   Thompson P, 1996, IEEE T MED IMAGING, V15, P402, DOI 10.1109/42.511745
   Tristán A, 2005, MACHINE LEARN SIGN P, P221, DOI 10.1109/MLSP.2005.1532903
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Warfield Simon., 1999, Brain Warping, P67
   Wells W M 3rd, 1996, Med Image Anal, V1, P35
   Zhang AF, 2007, COMPUT MED IMAG GRAP, V31, P299, DOI 10.1016/j.compmedimag.2007.02.008
NR 45
TC 15
Z9 17
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1207
EP 1222
DI 10.1016/j.imavis.2008.11.001
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000020
DA 2024-07-18
ER

PT J
AU Drew, MS
   Lee, TK
   Rova, A
AF Drew, Mark S.
   Lee, Tim K.
   Rova, Andrew
TI Shape retrieval with eigen-CSS search
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape; 2D contour; Scale-space; Matching; Retrieval; Curvature; CSS;
   Eigen-analysis
ID RECOGNITION
AB Shape retrieval programs are comprised of two components: shape representation and matching algorithm. Building the representation on scale space filtering and the curvature function of a closed boundary curve, curvature scale space (CSS) has been demonstrated to be a robust 2D shape representation. The adoption of the CSS image as the default in the MPEG-7 standard, using a matching algorithm utilizing maxima of the CSS image contours, makes this feature of interest perforce. In this paper, we propose a framework in two stages for a novel approach to both representing and matching the CSS feature. Our contribution consists of three steps, each of which effects a profound speedup on CSS image matching. Each step is a well-known technique in other domains, but the proposed concatenation of steps leads to a novel approach to this subject which captures shape information more efficiently and decreases distracting noise. First, using experience derived from medical imaging, we define a set of marginal-sum features summarizing the CSS image. Second, the standard algorithm using CSS maxima involves a complicated and time-consuming search, since the zero of arc length is not known in any new contour. Here, we obviate this search via a phase normalization transform in the spatial dimension of the reduced marginal-CSS feature. Remarkably, this step also makes the method rotation- and reflection-invariant. Finally, the resulting feature space is amenable to dimension reduction via subspace projection methods, with a dramatic speedup in time, and as well orders of magnitude reduction in space. The first stage of the resultant program, using a general-purpose eigenspace, has class-categorization accuracy compatible with the original contour maxima program. In a second stage, we generate specialized eigenspaces for each shape category, with little extra runtime complexity because search can still be carried out in reduced dimensionality. In a leave-one-out categorization using the MPEG-7 contour database, a classification success rate of 94.1% over 1400 objects in 70 classes is achieved with very fast matching, and 98.6% in the top-2 classes. A leave-all-in test achieves 99.8% correct categorization. The method is rotation invariant, and is simple, fast, and effective. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Drew, Mark S.; Lee, Tim K.; Rova, Andrew] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
   [Lee, Tim K.] British Columbia Canc Res Ctr, Vancouver, BC V5Z 1L3, Canada.
C3 Simon Fraser University; British Columbia Cancer Agency
RP Drew, MS (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
EM mark@cs.sfu.ca; tlee@bccancer.bc.ca; arova@cs.sfu.ca
CR Abbasi S, 2001, IEEE T IMAGE PROCESS, V10, P131, DOI 10.1109/83.892449
   [Anonymous], COMP VIS PATT REC 20
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Drew MS, 2002, PATTERN RECOGN, V35, P1687, DOI 10.1016/S0031-3203(01)00163-7
   DREW MS, 1998, ICCV 98, P533
   DREW MS, 2005, 20057 CSS TR S FRAS
   Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163
   KUNTTU I, 2001, ICCV20001, P755
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   LEE T, 2007, 1 INT C SCAL SPAC ME, P883
   Mokhatarian F., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P269, DOI 10.1109/ICCV.1993.378207
   MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   MURASE H, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P836
   MURASE H, 1994, CVPR94, P31
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Stiene S, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P168
   SUN KB, 2005, CVPR, P727
NR 19
TC 12
Z9 13
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 748
EP 755
DI 10.1016/j.imavis.2008.07.011
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, H
   Liu, YH
   Li, LZ
   Wei, BG
AF Zhou, Hong
   Liu, Yonghuai
   Li, Longzhuang
   Wei, Baogang
TI A clustering approach to free form surface reconstruction from
   multi-view range images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Free form surface reconstruction; Range images; Principal component
   analysis; Hierarchical segmentation; Tensor analysis; Surface
   classification; K Means clustering; Fuzzy c means clustering
ID REGISTRATION; INTEGRATION; ERROR
AB 3D modelling finds a wide range of applications in robot vision and reverse engineering. However due to the presence of surface scanning noise, accumulative registration errors, and improper data fusion, the reconstructed surfaces from multiple registered range images are often non-smooth and distorted with thick patches, false connections and blurred features. These shortcomings will limit the wide applications of 3D modelling using the latest laser scanning systems. In this paper, the clustering approach, surface segmentation and classification are employed to fuse registered range images to reduce the adverse effect of large accumulative registration errors and heavy scanning noise, minimize the dissimilarity of the fused surface with respect to the original overlapping Surfaces, and produce smooth and detailed 3D object computer models. For initialization of the clustering approach, an automatic method is developed, shifting possible corresponding points from different viewpoints toward each other and thus, making sure that the initialization of the cluster centroids are in between the two data sets so that more efficient and effective integration of data can be obtained. Then the principal component analysis (PCA) is employed to segment these centroids into different areas for the representation of the initially fused surface and then the tensor analysis is applied to classify these areas into featured and non-featured ones. In the integration process, the K means and fuzzy c means clustering approaches from the pattern recognition and machine learning literatures are employed to integrate non-featured areas for a smooth fused surface and featured areas for keeping the geometric details. By controlling a parameter, the final integrated surface can be traded off between smoothness and geometric details. Finally the fused point set is triangulated using an improved Delaunay method, guaranteeing a watertight surface. The new method is theoretically guaranteed to converge and minimize the dissimilarity between the final fused surface and original surfaces. A comparative study based on real images shows that the proposed algorithm desirably retains geometric details, produces smooth surface and minimizes the integration error. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Zhou, Hong; Liu, Yonghuai] Aberystwyth Univ, Dept Comp Sci, Ceredigion SY23 3DB, Wales.
   [Li, Longzhuang] Texas A&M Univ, Dept Comp Sci, Corpus Christi, TX 78412 USA.
   [Wei, Baogang] Zhejiang Univ, Sch Comp Sci, Hangzhou 310027, Peoples R China.
C3 Aberystwyth University; Texas A&M University System; Zhejiang University
RP Liu, YH (corresponding author), Aberystwyth Univ, Dept Comp Sci, Ceredigion SY23 3DB, Wales.
EM yyl@aber.ac.uk
RI Liu, Yonghuai/ABF-3794-2020; cai, bo/G-1491-2010
CR [Anonymous], 1991, IEEE ICRA
   [Anonymous], ELECT BASEL
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Dey TK, 2003, J COMPUTING INFORMAT, V13, P302
   DOMINGO A, 2000, P ICPR, P546
   Dorai C, 1998, IEEE T PATTERN ANAL, V20, P83, DOI 10.1109/34.655652
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Heckel B, 2001, COMP SUPPL, V14, P199
   Hilton A, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P381, DOI 10.1109/ICIP.1996.560840
   Hilton A, 2000, MACH VISION APPL, V12, P44, DOI 10.1007/s001380050123
   Hoppe Hugues, 1992, P SIGGRAPH 92, P71, DOI DOI 10.1145/133994.134011
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888
   Jackson J. E., 2005, USERS GUIDE PRINCIPA
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   JONATHAN C, 1996, P SIGGRAPH, P119
   LEE CK, 1994, COMPUT STRUCT, V52, P847, DOI 10.1016/0045-7949(94)90070-1
   Liu Y, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P4
   LIU Y, 2004, P ICRA, P2285
   Manly B. F., 2016, MULTIVARIATE STAT ME
   Park SY, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P276
   Pulli K., 1999, Proc.3DIM, P160
   Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012
   Sharp GC, 2004, IEEE T PATTERN ANAL, V26, P1037, DOI 10.1109/TPAMI.2004.49
   Sun YY, 2003, INTEGR COMPUT-AID E, V10, P37
   Tang CK, 2002, IEEE T PATTERN ANAL, V24, P858, DOI 10.1109/TPAMI.2002.1008395
   Tang CK, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P818, DOI 10.1109/ICCV.1998.710812
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   Wang WP, 2006, ACM T GRAPHIC, V25, P214, DOI 10.1145/1138450.1138453
   Westin CF, 1999, LECT NOTES COMPUT SC, V1679, P441
   Zaiane Osmar R., 1999, PRINCIPLES KNOWLEDGE
   Zhou H, 2005, IEEE IND ELEC, P468
   Zhou H, 2006, LECT NOTES COMPUT SC, V3851, P958
NR 34
TC 11
Z9 11
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 725
EP 747
DI 10.1016/j.imavis.2008.07.009
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000013
DA 2024-07-18
ER

PT J
AU Stein, AN
   Hebert, M
AF Stein, Andrew N.
   Hebert, Martial
TI Local detection of occlusion boundaries in video
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 17th Annual British Machine Vision Conference
CY SEP, 2006
CL British Machine Vis Assoc, Edinburgh, SCOTLAND
HO British Machine Vis Assoc
DE Occlusion boundaries; Edge detection; Contours; Motion analysis;
   Occlusion detection
ID PLANE IMAGE-ANALYSIS; TRACKING
AB Occlusion boundaries are notoriously difficult for many patch-based computer vision algorithms, but they also provide potentially useful information about scene structure and shape. Using short video clips, we present a novel method for scoring the degree to which occlusion is visible at detected edges. We first utilise a spatio-temporal edge detector which estimates edge strength, Orientation, and normal motion. By then extracting patches from either side of each detected (possibly moving) edge pixel, we can estimate and compare motion to determine if occlusion is present. In experiments on synthetic and natural images, we demonstrate our ability to differentiate occlusion boundary pixels from simple edge pixels by using motion information. In terms of precision versus recall, our occlusion scoring metric outperforms a rank-based motion inconsistency measure from the literature. The completely local, bottom-up approach described here is intended to provide powerful low-level information for use by higher-level reasoning methods. (C) 2008 FIsevier B.V. All rights reserved.
C1 [Stein, Andrew N.; Hebert, Martial] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Stein, AN (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM anstein@cmu.edu; hebert@ri.cmu.edu
CR ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], BMVC
   Apostoloff N, 2005, PROC CVPR IEEE, P553
   BAKER HH, 1989, INT J COMPUT VISION, V3, P33, DOI 10.1007/BF00054837
   Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933
   BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525
   BOUTHEMY P, 1989, IEEE T PATTERN ANAL, V11, P499, DOI 10.1109/34.24782
   Brostow G. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P8, DOI 10.1109/ICCV.1999.791190
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Derpanis KG, 2005, IEEE IMAGE PROC, P2777
   Fleet D.J., 2002, EXPLORING ARTIFICIAL, P139
   Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HEEGER DJ, 1988, INT J COMPUT VISION, V1, P270
   HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841
   Hirschmüller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Ke QF, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P37, DOI 10.1109/MOTION.2002.1182211
   Kumar MP, 2005, IEEE I CONF COMP VIS, P33
   Levina E, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P251, DOI 10.1109/ICCV.2001.937632
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   MALLOWS CL, 1972, ANN MATH STAT, V43, P508, DOI 10.1214/aoms/1177692631
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Nestares O, 2001, PROC CVPR IEEE, P358
   SCOTT DW, 1979, BIOMETRIKA, V66, P605, DOI 10.1093/biomet/66.3.605
   Shechtman E, 2005, PROC CVPR IEEE, P405
   Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861
   Smith P, 2004, IEEE T PATTERN ANAL, V26, P479, DOI 10.1109/TPAMI.2004.1265863
   Stein A, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P37
   STEIN AN, 2006, PATCH WORKSH IEEE C, P19
   STEIN AN, 2006, BRIT MACH VIS C BMVC, P407
   Tomasi C, 1991, DETECTION TRACKING P
   Wand MP, 1997, AM STAT, V51, P59, DOI 10.2307/2684697
   Wolf L, 2006, LECT NOTES COMPUT SC, V3952, P481
NR 37
TC 9
Z9 15
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 2
PY 2009
VL 27
IS 5
SI SI
BP 514
EP 522
DI 10.1016/j.imavis.2008.04.017
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 437WD
UT WOS:000265516700003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lucet, Y
AF Lucet, Yves
TI New sequential exact Euclidean distance transform algorithms based on
   convex analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Distance transform; Euclidean distance; Feature transform; Fast Legendre
   transform; Legendre-Fenchel transform; Fenchel conjugate; Moreau
   envelope; Moreau-Yosida approximate; Computational convex analysis
AB We present several sequential exact Euclidean distance transform algorithms. The algorithms are based on fundamental transforms of convex analysis: The Legendre Conjugate or Legendre-Fenchel transform, and the Moreau envelope or Moreau-Yosida approximate. They combine the separability of the Euclidean distance with convex properties to achieve an optimal linear-time complexity. We compare them with a Parabolic Envelope distance transform, and provide several extensions. All the algorithms presented perform equally well in higher dimensions. They can naturally handle grayscale images, and their principles are generic enough to apply to other transforms. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ British Columbia Okanagan, IK Barber Sch Arts & Sci, Kelowna, BC V1V 1V7, Canada.
C3 University of British Columbia; University of British Columbia Okanagan
RP Lucet, Y (corresponding author), Univ British Columbia Okanagan, IK Barber Sch Arts & Sci, 3333 Univ Way, Kelowna, BC V1V 1V7, Canada.
EM yves.lucet@ubc.ca
CR [Anonymous], COMPUTER SCI TECHNIC
   [Anonymous], 2004, THEOR COMPUT
   [Anonymous], 1995, Classics in Mathematics
   Bailey DG, 2004, LECT NOTES COMPUT SC, V3322, P394
   Bec J, 2000, J FLUID MECH, V416, P239, DOI 10.1017/S0022112000001051
   BORGEFORS G, 1989, PATTERN RECOGN LETT, V9, P97, DOI 10.1016/0167-8655(89)90042-1
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   BRENIER Y, 1989, CR ACAD SCI I-MATH, V308, P587
   BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389
   CHEN L, 1994, INFORM PROCESS LETT, V51, P25, DOI 10.1016/0020-0190(94)00062-X
   Corrias L, 1996, SIAM J NUMER ANAL, V33, P1534, DOI 10.1137/S0036142993260208
   CUISENAIRE O, 1999, P IEEE INT C AC SPEE, V6, P3293
   Cuisenaire O., 1999, DISTANCE TRANSFORMAT
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   DENIAU L, 1995, FRACTAL ANAL HAUSDOR
   FABBRI R, 2005, SCILAB IMAGE PROCESS
   Frisch U., 2001, NATO Advanced Study Institute. Les Houches Session LXXIV. New Trends in Turbulence. Turbulence: Nouveaux Aspects, P341
   Frisch U, 2001, PHYSICA D, V152, P620, DOI 10.1016/S0167-2789(01)00195-6
   HELLUY P, 2005, THESIS I SCI INGENIE
   HESSELINK W, 2005, LINEAR TIME ALGORITH
   Hiriart-Urruty J. -B, 1993, GRUNDLEHREN MATH WIS, V305
   HIRIARTURRUTY JB, 1993, FUNDAMENTALS, V1
   HIRIARTURRUTY JB, 1993, ADV THEORY BUNDLE ME, V2
   HISAKADO T, 2003, P IEEE INT S CIRC SY, V3, P738
   KOOPEN B, 2002, THESIS U AMSTERDAM
   Legras B, 2005, ATMOS CHEM PHYS, V5, P1605, DOI 10.5194/acp-5-1605-2005
   Lucet Y, 1997, NUMER ALGORITHMS, V16, P171, DOI 10.1023/A:1019191114493
   Lucet Y., 1996, Computational Optimization and Applications, V6, P27, DOI 10.1007/BF00248008
   LUCET Y, 2005, FAST MOREAU ENVELOPE, V1
   LUCET Y, 2005, P 2 CAN C COMP ROB V
   Mauch Sean, 2000, A Fast Algorithm for Computing the Closest Point and Distance Transform., DOI DOI 10.1007/978-3-319-15090-1_15
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156
   Moreau J.-J., 1966, Functional Analysis and Optimization, P145
   Moreau Jean-Jacques, 1965, B SOC MATH FRANCE, V93, P273, DOI DOI 10.24033/BSMF.1625
   MOREAU JJ, 1963, CR HEBD ACAD SCI, V256, P1069
   Noullez A., 1994, Journal of Scientific Computing, V9, P259, DOI 10.1007/BF01575032
   NOULLEZ A, 2004, NLINCD0409022 ARIXVO
   Prohaska S, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P29, DOI 10.1109/VISUAL.2002.1183753
   Rockafellar R. T., 1998, VARIATIONAL ANAL
   Rockafellar R. T., 2015, CONVEX ANAL, DOI DOI 10.1515/9781400873173
   ROSENFEL.A, 1966, J ACM, V13, P471
   SHE ZS, 1992, COMMUN MATH PHYS, V148, P623, DOI 10.1007/BF02096551
   Shih FY, 2004, COMPUT VIS IMAGE UND, V93, P195, DOI 10.1016/j.cviu.2003.09.004
   SIGG C, 2003, P IEEE VIS 03 ETH ZU
   TORIWAKI J, 2001, LECT NOTES COMPUTER, P412
NR 45
TC 17
Z9 21
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 37
EP 44
DI 10.1016/j.imavis.2006.10.011
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700005
DA 2024-07-18
ER

PT J
AU Lee, CF
   Chang, CC
   Wang, KH
AF Lee, Chin-Feng
   Chang, Chin-Chen
   Wang, Kuo-Hua
TI An improvement of EMD embedding method for large payloads by pixel
   segmentation strategy
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Covert communication; Digit steganography; Data hiding; Embedding
   capacity
ID LSB STEGANOGRAPHY; IMAGES; STEGANALYSIS
AB In this paper, a novel data hiding method by using pixel segmentation strategy is proposed. The proposed paper keeps (16 - p(m)) MSBs of a pixel-pair unchanged and alters p(m) LSBs to indicate the virtual modifications on an m-dimensional pseudo-random vectors for carrying the secret data, where m = 2(Pm-1) - 1. The embedding rate of proposed method is R = (log(2)(2m + 1))/2, which is greater than that of the EMD embedding method proposed by Zhang and Wang [X. Zhang, S. Wang, Efficient steganographic embedding by exploiting modification direction, IEEE Communication Letters 10 (2006) (113), pp.781-783], because the embedding rate of EMD embedding method is R = (log(2)(2n + 1))/n, when m > 2 and n >= 2. The experimental results show that the proposed method increases the number of embedded secret bits more than 1.7 times compared with the EMD embedding method. Even with such high embedding capacity, the average PSNR of 44.3 dB shows that the visual quality does not decline to an unacceptable degree. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Lee, Chin-Feng] Chaoyang Univ Technol, Dept Informat Management, Wufong Township 41349, Taichung County, Taiwan.
   [Chang, Chin-Chen; Wang, Kuo-Hua] Feng Chia Univ, Dept Comp Sci & Informat Engn, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 62107, Taiwan.
C3 Chaoyang University of Technology; Feng Chia University; National Chung
   Cheng University
RP Lee, CF (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifong E Rd, Wufong Township 41349, Taichung County, Taiwan.
EM lcf@cyut.edu.tw; ccc@cs.ccu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR [Anonymous], 2000, Digital Watermarking
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Ker AD, 2004, PROC SPIE, V5306, P83, DOI 10.1117/12.526720
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   HIDE SEEK
NR 11
TC 45
Z9 47
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1670
EP 1676
DI 10.1016/j.imavis.2008.05.005
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500010
DA 2024-07-18
ER

PT J
AU Michael, GKO
   Connie, T
   Teoh, ABJ
AF Michael, Goh Kah Ong
   Connie, Tee
   Teoh, Andrew Beng Jin
TI Touch-less palm print biometrics: Novel design and implementation
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Palm print recognition; Touch-less biometrics; Local binary pattern
   (LBP); Gradient operator; Probabilistic neural networks (PNN)
ID PALMPRINT
AB In this paper, we propose an innovative touch-less palm print recognition system. This project is motivated by the public's demand for non-invasive and hygienic biometric technology. For various reasons, users are concerned about touching the biometric scanners. Therefore, we propose to use a low-resolution web camera to capture the user's hand at a distance for recognition. The users do not need to touch any device for their palm print to be acquired. A novel hand tracking and palm print region of interest (ROI) extraction technique are used to track and capture the user's palm in real-time video stream. The discriminative palm print features are extracted based on a new method that applies local binary pattern (LBP) texture descriptor on the palm print directional gradient responses. Experiments show promising result using the proposed method. Performance can be further improved when a modified probabilistic neural network (PNN) is used for feature matching. Verification can be performed in less than one second in the proposed system. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Michael, Goh Kah Ong; Connie, Tee] Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
   [Teoh, Andrew Beng Jin] Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul 120749, South Korea.
C3 Multimedia University; Yonsei University
RP Connie, T (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
EM michael.goh@mmu.edu.my; tee.connie@mmu.edu.my; bjteoh@yonsei.ac.kr
RI Tee, Connie/F-8478-2012; Goh, Kah Ong Michael/F-8404-2012; Teoh, Andrew
   Beng Jin/F-4422-2010
OI Tee, Connie/0000-0002-0901-3831; Goh, Kah Ong
   Michael/0000-0002-9217-6390; Teoh, Andrew Beng Jin/0000-0001-5063-9484
CR AHONEN T, 2004, P 8 EUR C COMP VIS, P145
   ANDREW T, 2006, INFORM PROCESSING LE, V100, P145
   CHANG H, 2000, FACE DETECTION
   Connie T, 2005, IMAGE VISION COMPUT, V23, P501, DOI 10.1016/j.imavis.2005.01.002
   Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9
   Funada J, 1998, INT C PATT RECOG, P1849, DOI 10.1109/ICPR.1998.712091
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   HAROLD C, 1943, FINGER PRINTS PALMS
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   LU G, 2003, PATTERN RECOGN, V24, P1473
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
   Zhang L, 2004, IEEE T SYST MAN CY B, V34, P1335, DOI 10.1109/TSMCB.2004.824521
NR 17
TC 125
Z9 143
U1 2
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1551
EP 1560
DI 10.1016/j.imavis.2008.06.010
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500001
DA 2024-07-18
ER

PT J
AU Zhao, H
   Li, Q
   Feng, HJ
AF Zhao, Hui
   Li, Qi
   Feng, Huajun
TI Multi-focus color image fusion in the HSI space using the
   sum-modified-laplacian and a coarse edge map
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE HSI; SML; multi-focus; focus measure; coarse-edge map; region-filling
AB This paper presented a simple algorithm for fusion of multi-focus color images. The algorithm was developed in HSI space where the intensity component was not very sensitive to noise. First, an initial decision map was generated by computing the classical SML (sum-modified-laplacian) as the pixels' focus measure using the intensity component; second, by subtracting one of multi-focus images from another, a coarse edge map was obtained to refine the initial decision map: third, a fast region-filling method was used to build the final decision map; fourth, a soft fusion strategy was applied to the transition zone between focused and clefocused regions and a nice-looking fused image was generated. Experiments showed that the algorithm was effective and the results were acceptable. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Zhao, Hui; Li, Qi; Feng, Huajun] Zhejiang Univ, Dept Opt Engn, State Key Lab Modern Opt Instrumentat, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhao, H (corresponding author), Zhejiang Univ, Dept Opt Engn, State Key Lab Modern Opt Instrumentat, Hangzhou 310027, Peoples R China.
EM zhaohui@zj139.com; fenghj@zju.edu.cn
RI ZHAO, HUANYU/JFD-8853-2023
CR [Anonymous], P 3 INT C INF FUS
   CONZALEZ RC, 1992, DIGITAL IMAGE PROCES
   ELTOUKHY HA, 2003, P SPIE IS T EL IM
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   KIM C, 2005, IEEE T IMAGE PROCESS, V14
   LI H, 1994, IEEE IMAGE PROC, P51, DOI 10.1109/ICIP.1994.413273
   Li S, 2001, Information Fusion, V2, P169, DOI DOI 10.1016/S1566-2535(01)00038-0
   Li ST, 2002, PATTERN RECOGN LETT, V23, P985, DOI 10.1016/S0167-8655(02)00029-6
   Maik V, 2005, LECT NOTES COMPUT SC, V3691, P677
   Nayar S.K., 1994, IEEE Transactions on Pattern Analysis and Machine Intelligence, V16, p824 831
   RIOUL O, 1992, IEEE T INFORM THEORY, V38, P569, DOI 10.1109/18.119724
   SUBBARAO M, 1995, IEEE T PATTERN ANAL, V17, P266, DOI 10.1109/34.368191
   TSATSANIS MK, 1992, IEEE T PATTERN ANAL, V14, P733, DOI 10.1109/34.142910
   Tyan J. K., 1997, THESIS STATE U NEW Y
   Weeks AR, 1997, P SOC PHOTO-OPT INS, V3026, P143, DOI 10.1117/12.271117
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
NR 16
TC 45
Z9 55
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1285
EP 1295
DI 10.1016/j.imavis.2008.03.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300011
DA 2024-07-18
ER

PT J
AU Tseng, CC
   Hsieh, JG
   Jeng, JH
AF Tseng, Chun-Chieh
   Hsieh, Jer-Guang
   Jeng, Jyh-Horng
TI Fractal image compression using visual-based particle swarm optimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fractal image compression; particle swarm optimization; edge-type
   classification
ID GENETIC ALGORITHM
AB Fractal image compression is promising both theoretically and practically. The encoding speed of the traditional full search method is a key factor rendering the fractal image compression unsuitable for real-time applications. In this papey, particle swarm optimization (PSO) method by utilizing the visual information of the edge property is proposed, which can speedup the encoder and preserve the image quality. Instead of the full search, a direction map is built according to the edge-type of image blocks, which directs the particles in the swarm to regions consisting of candidates of higher similarity. Therefore, the searching space is reduced and the speedup can be achieved. Also, since the strategy is performed according to the edge property, better visual effect can be preserved. Experimental results show that the visual-based particle swarm optimization speeds up the encoder 125 times faster with only 0.89 dB decay of image quality in comparison to the full search method. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Tseng, Chun-Chieh; Hsieh, Jer-Guang] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 804, Taiwan.
   [Jeng, Jyh-Horng] I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
C3 National Sun Yat Sen University; I Shou University
RP Tseng, CC (corresponding author), Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 804, Taiwan.
EM d9131809@student.nsysu.edu.tw
CR [Anonymous], 1991, FRACTALS FUNDAMENTAL
   [Anonymous], FRACTALS CHAOS
   BARNSLEY MF, 1985, P ROY SOC LOND A MAT, V399, P243, DOI 10.1098/rspa.1985.0057
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   Fisher Y., 1994, Fractal Image Compression
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Mitra SK, 1998, IEEE T IMAGE PROCESS, V7, P586, DOI 10.1109/83.663505
   Polvere M, 2000, IEEE T IMAGE PROCESS, V9, P1002, DOI 10.1109/83.846243
   Truong TK, 2000, IEEE T IMAGE PROCESS, V9, P529, DOI 10.1109/83.841930
   VENCES L, 1997, P COMPUTACION VISUAL, P35
   Wang Z, 2000, SIGNAL PROCESS-IMAGE, V15, P767, DOI 10.1016/S0923-5965(99)00018-1
   Wu MS, 2007, ENG APPL ARTIF INTEL, V20, P531, DOI 10.1016/j.engappai.2006.08.005
   Wu MS, 2006, CHAOS SOLITON FRACT, V28, P497, DOI 10.1016/j.chaos.2005.07.004
   Zhang CL, 2000, IEEE SYS MAN CYBERN, P2487, DOI 10.1109/ICSMC.2000.884366
NR 16
TC 38
Z9 44
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1154
EP 1162
DI 10.1016/j.imavis.2008.01.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300009
DA 2024-07-18
ER

PT J
AU Wensch, J
   Gerisch, A
   Posch, S
AF Wensch, J.
   Gerisch, A.
   Posch, S.
TI Optimised coupling of hierarchies in image registration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE elastic registration; image hierarchies; transformation hierarchies;
   coupling of hierarchies; dynamic programming; 2D-PAGE images
ID ELECTROPHORESIS
AB Image registration algorithms rely on multilevel strategies in order to improve efficiency and robustness. Hierarchies in image resolution, the underlying grids for spline-based transformations, as well as the regularisation parameters are used. This paper deals with the optimisation of the coupling of these hierarchies.
   An image registration procedure - suitable for 2D polyacrylamide gel electrophoresis images - using piecewise bilinear transformations and an intensity based objective function with a regularisation term based on the elastic deformation energy is described. The resulting nonlinear least squares problem is solved by the Gauss-Newton method.
   Techniques reminiscent of dynamic programming are used to optimise the coupling of hierarchies in image and transformation resolution. Besides using these techniques to devise an advantageous fixed coupling of both hierarchies, we favour incorporating the dynamic programming ideas into the final registration algorithm. This leads to an adaptive and streamlined approach.
   Numerical experiments on 2D-PAGE images show that the adaptive registration algorithm is much more reliable than the same algorithm with a fixed coupling of hierarchies. The proposed optimisation procedure for the coupling of hierarchies presents a valuable tool to optimise other registration algorithms. (c) 2008 Published by Elsevier B.V.
C1 [Wensch, J.] Tech Univ Dresden, Inst Wissensch Rechnen, D-01062 Dresden, Germany.
   [Gerisch, A.] Univ Halle Wittenberg, Inst Math, D-06099 Halle, Saale, Germany.
   [Posch, S.] Univ Halle Wittenberg, Inst Informat, D-06099 Halle, Saale, Germany.
C3 Technische Universitat Dresden; Martin Luther University Halle
   Wittenberg; Martin Luther University Halle Wittenberg
RP Wensch, J (corresponding author), Tech Univ Dresden, Inst Wissensch Rechnen, D-01062 Dresden, Germany.
EM joerg.wensch@tu-dresden.de; gerisch@mathematik.uni-halle.de;
   posch@informatik.uni-halle.de
RI Gerisch, Alf/B-4744-2015
OI Gerisch, Alf/0000-0002-8049-7795
CR BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Clarenz U., 2006, Math. Models Reg. Appl. Med. Imaging, P81
   Fischer B., 2003, PAMM, V3, P32, DOI [10.1002/pamm.200310309, DOI 10.1002/PAMM.200310309]
   Gustafsson JS, 2002, ELECTROPHORESIS, V23, P1731, DOI 10.1002/1522-2683(200206)23:11<1731::AID-ELPS1731>3.0.CO;2-#
   Haber E, 2006, SIAM J SCI COMPUT, V27, P1594, DOI 10.1137/040608106
   Henn S, 2005, MULTISCALE MODEL SIM, V4, P584, DOI 10.1137/040604194
   Roth U, 2006, J EXP BOT, V57, P4003, DOI 10.1093/jxb/erl170
   Salmi J, 2002, PROTEOMICS, V2, P1504, DOI 10.1002/1615-9861(200211)2:11<1504::AID-PROT1504>3.0.CO;2-B
   Smilansky Z, 2001, ELECTROPHORESIS, V22, P1616, DOI 10.1002/1522-2683(200105)22:9<1616::AID-ELPS1616>3.0.CO;2-Z
   Sorzano COS, 2005, IEEE T BIO-MED ENG, V52, P652, DOI 10.1109/TBME.2005.844030
   Veeser S, 2001, PROTEOMICS, V1, P856
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
   [No title captured]
NR 13
TC 5
Z9 6
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 1000
EP 1011
DI 10.1016/j.imavis.2007.11.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800013
DA 2024-07-18
ER

PT J
AU Alsultanny, YA
AF Alsultanny, Yas Abbas
TI Random-bit sequence generation from image data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image encryption; randomness bit generation; CBC model; ECB mode
AB The random number generated is very important in constructing encryption keys together with the other algorithm parameters. A new approach is proposed to generate a random-bit sequence with a high level of randomness. The five statistical test, Frequency, Serial, Poker, Runs and Autocorrelation are used to test the proposed algorithm, the results showed that 79% of the generated sequences can pass all of the five statistical tests together, and 94% of the generated sequences pass at least four of the statistical tests, which means the proposed algorithm can generate bit sequence with a high degree of randomness. The degree of encryption increased as the randomness level increased.
   Three hypotheses are suggested and tested in this paper. One of these hypotheses proved that by using CBC mode of encryption, the randomness level of the key have no significant effect on the degree of encryption. By using ECB mode, the encryption level has significant effect by using different levels of randomness key, the minimum key length gave good degree of encryption is 32 bit, which proved that the mode of image encryption determined the degree of image encryption, and some modes such as ECB of encryption depends on the level of randomness of the key, and this was proved by testing tens of images rated from simple images to complex images, such as the satellite image processed in this paper. (C) 2007 Elsevier B.V. All rights reserved.
C1 Arabian Gulf Univ, Technol Management Programme, Coll Grad Studies, Manama, Bahrain.
C3 Arabian Gulf University
RP Alsultanny, YA (corresponding author), Arabian Gulf Univ, Technol Management Programme, Coll Grad Studies, POB 26671, Manama, Bahrain.
EM alsultanny@yahoo.com
RI Alsultanny, Yas A./ABC-9737-2021
OI Alsultanny, Yas A./0000-0002-6211-7074
CR Alfred J.Menezes., 1997, Handbook of Applied Cryptography
   Alsultanny Y., 2005, JORDAN J APPL SCI
   ALSULTANNY Y, 2007, INT J INN COMP INF C, V1
   ALSULTANNY Y, 2004, EMB SIGN PROC C GSPX
   ALSULTANNY Y, 2004, P 1 INT C TECHN INF, P49
   Douglas R.S., 1995, CRYPTOGRAPHY THEORY
   JOHN E, 2003, CRYPTOGRAPHY DEMYSTI
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Stallings W., 2003, CRYPTOGRAPHY NETWORK
NR 9
TC 4
Z9 4
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 592
EP 601
DI 10.1016/j.imavis.2007.07.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100011
DA 2024-07-18
ER

PT J
AU Crosby, F
AF Crosby, Frank
TI Comparison of directly measured to derived polarization imagery using an
   adaptive signature detection algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE polarization; ATR; maximum likelihood test; CFAR
ID FIELD
AB Directly measured linear polarization images are shown to be more effective in target detection compared with derived imagery using a constant false alarm rate (CFAR) detection algorithm. The CFAR algorithm is derived from a maximum likelihood ratio test and is used to compare two pairs of inputs. One pair is directly measured imagery: an image with reflectivity/emissivity and a linear polarization and another with reflectivity/emissivity and a linear polarization perpendicular to the first image. The other pair is the first two Stokes images (SO, S-1): a linear polarization image and a reflectivity/emissivity image. Detection using the directly measured pair is shown to be consistent with detection using the derived pair. Furthermore, using the directly measured pair is computationally simpler, and for target detection on natural backgrounds, does not increase the false alarm rate. (c) 2007 Elsevier B.V. All rights reserved.
C1 USN, Ctr Surface Warfare, Dahlgren Div, Panama City, FL 32407 USA.
C3 United States Department of Defense; United States Navy; US Navy Naval
   Sea Systems Command
RP Crosby, F (corresponding author), USN, Ctr Surface Warfare, Dahlgren Div, Code HS-13,110 Vernon Ave, Panama City, FL 32407 USA.
EM frank.crosby@navy.mil
CR CAMPANA SB, 1993, INFRARED ELECT OPTIC, V5
   CRAIB A, 1996, INT C MIN CLEAR TECH
   Crosby F, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1995710
   de Jong W, 2000, P SOC PHOTO-OPT INS, V4038, P241, DOI 10.1117/12.396250
   Forssell G, 2003, P SOC PHOTO-OPT INS, V5089, P547, DOI 10.1117/12.487163
   HOLMES QA, 1995, P SOC PHOTO-OPT INS, V2496, P421, DOI 10.1117/12.211339
   Johnson JR, 1998, REMOTE SENS ENVIRON, V64, P34, DOI 10.1016/S0034-4257(97)00166-1
   MILES BH, 1992, P SOC PHOTO-OPT INS, V1747, P239, DOI 10.1117/12.138831
   MUISE R, 1996, P SPIE DET REM TECHN
   Shurcliff W.A., 1964, POLARIZED LIGHT
   Taylor JS, 2001, P SOC PHOTO-OPT INS, V4394, P1247, DOI 10.1117/12.445453
   Williams JW, 2001, P SOC PHOTO-OPT INS, V4394, P139, DOI 10.1117/12.445466
NR 12
TC 0
Z9 0
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1759
EP 1766
DI 10.1016/j.imavis.2007.01.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900006
DA 2024-07-18
ER

PT J
AU Ikonen, L
AF Ikonen, Leena
TI Priority pixel queue algorithm for geodesic distance transforms
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE distance transforms; gray-level distance transforms; nearest neighbor
   transforms; minimal geodesics; pixel queue algorithms
ID SURFACES; IMAGES
AB The sequential mask operations for calculating distance transforms may have to be iterated several times in the case of geodesic distances. This article presents an efficient propagation algorithm for the Distance Transform on Curved Space (DTOCS). It is based on a best-first pixel queue, and is applicable also for other gray-level distance transforms. It eliminates repetition of local distance calculations, and performs in near-linear time. A nearest neighbor transform based on distances along the surface, and a propagation direction image for tracing the shortest paths, can be produced simultaneously with the distance map. (c) 2006 Elsevier B.V. All rights reserved.
C1 Lappeenranta Univ Technol, Lab Informat Proc, Dept Informat Technol, FIN-53851 Lappeenranta, Finland.
C3 Lappeenranta-Lahti University of Technology LUT
RP Ikonen, L (corresponding author), Lappeenranta Univ Technol, Lab Informat Proc, Dept Informat Technol, POB 20, FIN-53851 Lappeenranta, Finland.
EM leena.ikonen@lut.fi
CR BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   BORGEFORS G, 1990, SIGNAL PROCESS, V21, P61, DOI 10.1016/0165-1684(90)90027-V
   Ikonen L., 2005, Pattern Recognition and Image Analysis, V15, P195
   Ikonen L, 2005, LECT NOTES COMPUT SC, V3708, P308
   Ikonen L, 2005, IMAGE VISION COMPUT, V23, P133, DOI 10.1016/j.imavis.2004.06.010
   Ikonen L, 2005, LECT NOTES COMPUT SC, V3429, P228
   Kapoutsis CA, 1999, IEEE T IMAGE PROCESS, V8, P1644, DOI 10.1109/83.799892
   KIRYATI N, 1993, PATTERN RECOGN, V26, P1623, DOI 10.1016/0031-3203(93)90018-R
   LEVI G, 1970, INFORM CONTROL, V17, P62, DOI 10.1016/S0019-9958(70)80006-7
   PIPER J, 1987, PATTERN RECOGN, V20, P599, DOI 10.1016/0031-3203(87)90030-6
   RAGNEMALM I, 1992, CVGIP-IMAG UNDERSTAN, V56, P399, DOI 10.1016/1049-9660(92)90050-D
   RAGNEMALM I, 1989, INT C IM AN PROC IT, P204
   ROSENFEL.A, 1966, J ACM, V13, P471
   Rosenfeld A., 1982, Digital Picture Processing, VII
   Sethian J., 1999, LEVEL SET METHODS FA
   Silvela J, 2001, IEEE T IMAGE PROCESS, V10, P1194, DOI 10.1109/83.935035
   SOILLE P, 1994, PATTERN RECOGN LETT, V15, P1235, DOI 10.1016/0167-8655(94)90113-9
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Toivanen PJ, 1996, PATTERN RECOGN LETT, V17, P437, DOI 10.1016/0167-8655(96)00010-4
   Verwer B. J. H., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1287, DOI 10.1142/S0218001493000637
   VERWER BJH, 1989, IEEE T PATTERN ANAL, V11, P425, DOI 10.1109/34.19041
   VINCENT L, 1991, P SOC PHOTO-OPT INS, V1451, P158, DOI 10.1117/12.44323
NR 22
TC 11
Z9 11
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1520
EP 1529
DI 10.1016/j.imavis.2006.06.016
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200002
DA 2024-07-18
ER

PT J
AU Tsai, CY
   Song, KT
AF Tsai, Chi-Yi
   Song, Kai-Tai
TI A new edge-adaptive demosaicing algorithm for color filter arrays
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image representation; color reproduction; CFA demosaicing; adaptive
   filtering; color artifacts
ID PLANE INTERPOLATION
AB A novel edge-adaptive demosaicing algorithm (EADA) is proposed in this paper to effectively reduce color artifacts in demosaiced images from a color filter array (CFA). The proposed algorithm aims to reduce the aliasing error in red and blue channels by exploiting high-frequency information of the green channel. To achieve this, color-difference based edge-adaptive filtering and post-processing schemes are designed to reproduce the color values by exploiting the green channel information. For green channel interpolation, any of the existing image interpolation methods can be used and combined with the proposed algorithm. Moreover, a new adaptive interpolation method is presented for reconstructing the green channel from CFA samples. We have compared this technique with two recently proposed demosaicing techniques: Gunturk's and Lu's methods. The experimental results show that EADA outperforms both of them in both PSNR values and CIELAB Delta E*(ab) measures. (C) 2007 Elsevier B.V. All rights reserved.
C1 Natl Chiao Tung Univ, Dept Elect & Control Engn, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Song, KT (corresponding author), Natl Chiao Tung Univ, Dept Elect & Control Engn, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM chiyi.ece91g@nctu.edu.tw; ktsong@mail.nctu.edu.tw
RI Tsai, Chi-Yi/AFJ-8560-2022; Tsai, Chi-Yi/AAT-2837-2021
OI Tsai, Chi-Yi/0000-0001-9872-4338; Tsai, Chi-Yi/0000-0001-9872-4338
CR ADAMS JE, 1995, P SOC PHOTO-OPT INS, V2416, P144
   ADAMS JR, 1997, P SPIE REAL TIME IMA, V2, P117
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Chang E, 1999, P SOC PHOTO-OPT INS, V3650, P36, DOI 10.1117/12.342861
   Chang LL, 2004, IEEE T CONSUM ELECTR, V50, P355, DOI 10.1109/TCE.2004.1277885
   Cok D. R., 1987, US Patent, Patent No. [4,642,678, 4642678]
   COK DR, 1994, P IS T ANN C ICPS, P380
   Freeman W. T., 1988, U.S. Patent, Patent No. [4,774,565, 4774565]
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   Hamilton Jr J. F., 1997, US Patent, Patent No. [5,629,734, 5629734]
   HIBBARD H, 1996, Patent No. 5382976
   HIRAKAWA K, 2003, P IEEE INT C IM PROC, V1, P669
   Kimmel R, 1999, IEEE T IMAGE PROCESS, V8, P1221, DOI 10.1109/83.784434
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lu WM, 2003, IEEE T IMAGE PROCESS, V12, P1194, DOI 10.1109/TIP.2003.816004
   MAHNY M, 1994, COLOR RES APPL, V19, P105
   Muresan DD, 2004, IEEE T IMAGE PROCESS, V13, P690, DOI 10.1109/TIP.2004.826097
   MURESAN DD, 2001, P IEEE INT C IM PROC, V3, P848
NR 19
TC 25
Z9 29
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1495
EP 1508
DI 10.1016/j.imavis.2006.12.018
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000010
OA Green Published
DA 2024-07-18
ER

PT J
AU Bertrand, G
AF Bertrand, Gilles
TI On the dynamics
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE mathematical morphology; dynamics; graph; watershed; minimum spanning
   tree; component tree
ID WATERSHEDS; ALGORITHMS; IMAGE; TREE
AB We show several properties of the ordered dynamics. In particular, we give necessary and sufficient conditions which indicate when a transformation preserves the dynamics of the regional maxima. We also establish a link between the dynamics, minimum spanning trees, and component trees. At last, we propose a linear time algorithm for computing, given the component tree of a function, the dynamics of all its maxima. (c) 2006 Elsevier B.V. All rights reserved.
C1 ESIEE, Inst Gaspard Monge, Lab A2SI, F-93162 Noisy Le Grand, France.
C3 Universite Gustave-Eiffel; ESIEE Paris
RP Bertrand, G (corresponding author), ESIEE, Inst Gaspard Monge, Lab A2SI, BP 99, F-93162 Noisy Le Grand, France.
EM g.bertrand@esiee.fr
OI Bertrand, Gilles/0009-0004-7294-7081
CR [Anonymous], 1984, Graphs and Algorithms
   Bertrand G, 2005, COMP IMAG VIS, V30, P197
   Bertrand G, 2005, J MATH IMAGING VIS, V22, P217, DOI 10.1007/s10851-005-4891-5
   Bertrand G, 2004, P SOC PHOTO-OPT INS, V5300, P127, DOI 10.1117/12.526740
   CACHIER C, 1995, THESIS ECOLE MINES P
   Couprie M, 2005, J MATH IMAGING VIS, V22, P231, DOI 10.1007/s10851-005-4892-4
   Couprie M, 1997, P SOC PHOTO-OPT INS, V3168, P136, DOI 10.1117/12.292778
   Grimaud M., 1992, Image Algebra and Morphological Image Processing III, V1769, P292
   GRIMAUD M, 1991, THESIS ECOLE MINES P
   HEIJMANS HJAM, 1991, IEEE T PATTERN ANAL, V13, P568, DOI 10.1109/34.87343
   Mattes J, 1999, LECT NOTES COMPUT SC, V1568, P298
   Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556
   Meyer F, 1996, COMPUT IMAGING VIS, P329
   Najman L, 2005, DISCRETE APPL MATH, V147, P301, DOI 10.1016/j.dam.2004.09.017
   Najman L, 2004, P SOC PHOTO-OPT INS, V5300, P98, DOI 10.1117/12.526592
   ROSENFELD A, 1979, INFORM CONTROL, V40, P76, DOI 10.1016/S0019-9958(79)90353-X
   Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500
   Serra J., 2000, Fundamenta Informaticae, V41, P147
   Serra J., 1988, IMAGE ANAL MATH MORP
   WENDT PD, 1986, IEEE T ACOUST SPEECH, V34, P898, DOI 10.1109/TASSP.1986.1164871
NR 20
TC 17
Z9 17
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 447
EP 454
DI 10.1016/j.imavis.2006.04.017
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600007
DA 2024-07-18
ER

PT J
AU Zhang, R
   Vogler, C
   Metaxas, D
AF Zhang, Rong
   Vogler, Christian
   Metaxas, Dimitris
TI Human gait recognition at sagittal plane
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE gait recognition; biometrics; human motion analysis; human
   identification; hidden Markov model
ID BIOLOGICAL MOTION
AB The reliable extraction of characteristic gait features from image sequences and their recognition are two important issues in gait recognition. In this paper, we propose a novel two-step, model-based approach to gait recognition by employing a five-link biped locomotion human model. We first extract the gait features from image sequences using the Metropolis-Hasting method. Hidden Markov Models are then trained based on the frequencies of these feature trajectories, from which recognition is performed. As it is entirely based on human gait, our approach is robust to different type of clothes the subjects wear. The model-based gait feature extraction step is insensitive to noise, cluttered background or even moving background. Furthermore, this approach also minimizes the size of the data required for recognition compared to model-free algorithms. We applied our method to both the USF Gait Challenge data set and CMU MoBo data set, and achieved recognition rate of 61 and 96%, respectively. We further studied the relationship between number of subjects within data set and the recognition rate. The results suggest that the recognition rate is significantly limited by the distance of the subject to the camera. (c) 2006 Published by Elsevier B.V.
C1 Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
   Gallaudet Univ, Gallaudet Res Inst, Washington, DC 20002 USA.
C3 Rutgers University System; Rutgers University New Brunswick
RP Zhang, R (corresponding author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.
EM roni@cs.rutgers.edu
CR [Anonymous], INT C IM PROC
   [Anonymous], 2001, Cmu Ri Tr 01-18
   AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859
   BENABDELKADER C, 2001, P INT C AUD VID BAS
   Borghese NA, 1996, J PHYSIOL-LONDON, V494, P863, DOI 10.1113/jphysiol.1996.sp021539
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   COLLINS RT, 2002, INT C AUT FAC GEST
   CUNADO D, 1997, 1 INT C AUD VID BAS
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   ELGAMMAL A, 2000, 6 EUR C COMP VIS
   FOSTER JP, 2001, PATTERN RECOGN, V24, P2489
   Hayfron-Acquah JB, 2003, PATTERN RECOGN LETT, V24, P2175, DOI 10.1016/S0167-8655(03)00086-2
   HORN RKP, 1986, ROBOT VISION
   Huang PS, 1999, IEE P-VIS IMAGE SIGN, V146, P93, DOI 10.1049/ip-vis:19990187
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   KALE A, 2003, P 3 INT C AUD VID BA
   KALE A, 2002, FACE GESTURE RECOGNI
   Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9
   LEE CS, 2004, 6 INT C AUT FAC GEST
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   LEE L, 2003, INT C COMP VIS PATT
   LITTLE L, 1996, VIDERE, V1, P1
   Murase H, 1996, PATTERN RECOGN LETT, V17, P155, DOI 10.1016/0167-8655(95)00109-3
   MURRAY MP, 1964, J BONE JOINT SURG AM, V46, P335, DOI 10.2106/00004623-196446020-00009
   NIYOGI SA, 1994, IEEE C COMP VIS PATT
   PHILLIPS PJ, 2002, INT C PATT REC
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   SMINCHISESCU C, 2001, IEEE INT C COMP VIS
   Stevenage SV, 1999, APPL COGNITIVE PSYCH, V13, P513, DOI 10.1002/(SICI)1099-0720(199912)13:6<513::AID-ACP616>3.0.CO;2-8
   SUN H, THESIS U PENNSYLVANI
   TANAWONGSUWAN R, 2001, COMPUTER VISION PATT, V2, P726
   Tilley A., 1993, MEASURE MAN WOMAN HU
   Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2
   Yam CY, 2002, INT C PATT RECOG, P287, DOI 10.1109/ICPR.2002.1044691
   Yoo JH, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P35, DOI 10.1109/IAI.2002.999885
NR 35
TC 62
Z9 77
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 321
EP 330
DI 10.1016/j.imavis.2005.10.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100008
DA 2024-07-18
ER

PT J
AU Tagliasacchi, M
AF Tagliasacchi, Marco
TI A genetic algorithm for optical flow estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE optical flow; genetic algorithms; motion estimation
ID COMPUTATION; MOTION
AB This paper illustrates a new optical flow estimation technique that builds upon a genetic algorithm (GA). First, the current frame is segmented into generic shape regions, using only luminance and color information. For each region, a two-parameter motion model is estimated using a GA. The fittest individuals identified at the end of this step are used to initialize the population of the second step of the algorithm, which estimates a six-parameter affine motion model, again using a GA. The proposed method is compared with a multi-resolution version of the well-known Lucas-Kanade differential algorithm. Our simulations demonstrate that, with respect to Lucas-Kanade, it significantly reduces the energy of the motion-compensated residual error. (c) 2006 Elsevier B.V. All rights reserved.
C1 Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, MI, Italy.
C3 Polytechnic University of Milan
RP Tagliasacchi, M (corresponding author), Politecn Milan, Dipartimento Elettron & Informaz, Piazza Leonardo da Vinci 32, I-20133 Milan, MI, Italy.
EM marco.tagliasacchi@polimi.it
CR ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   [Anonymous], 1987, Proceedings of the 2nd International Conference on Genetic Algorithms, DOI DOI 10.1007/S10489-006-0018-Y
   [Anonymous], 1988, International journal of computer vision
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Black MJ, 1996, IEEE T PATTERN ANAL, V18, P972, DOI 10.1109/34.541407
   Booker L., 1987, Improving search in genetic algorithms. Genetic Algorithms and Simulated Annealing, P61
   CHIPPERFIELD A, GENETIC ALGORITHM TO
   DIXON EL, 1997, IEEE T CONSUMER ELEC, V43
   FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772
   GONG M, 2002, PATTERN RECOGN, V1, P644
   HORN B, 1985, ARTIF INTELL, V17, P185
   LI S, 1999, P INT C IM PROC KOB
   Lucas B. D., 1981, P IJCAI, P674
   NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5
   SIMONCELLI EHA, 1991, P IEEE COMP SOC C CO
   VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781
   Wang DM, 1997, PATTERN RECOGN, V30, P2043, DOI 10.1016/S0031-3203(97)00015-0
   ZAIM M, 2001, VIS INT ANN C OTT CA
NR 19
TC 17
Z9 24
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 141
EP 147
DI 10.1016/j.imavis.2006.01.021
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700002
DA 2024-07-18
ER

PT J
AU Zavidovique, B
   Di Gesú, V
AF Zavidovique, Bertrand
   Di Gesu, Vito
TI Pyramid symmetry transforms:: From local to global symmetry
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE soft computing; pyramid computation; symmetry computation; visual
   attention; visual perception
ID IMAGES
AB Pyramid computation is a natural paradigm of computation in planning strategies and multi-resolution image analysis. This paper introduces a new paradigm that is based on the concept of soft-hierarchical operators implemented in pyramid architecture to retrieve global versus local symmetries. The concept of symmetry is mathematically well defined in geometry whenever patterns are crisp images (two levels). Necessity for a soft approach occurs with multi-levels images and whenever the separation between object and background is subjective or not well defined. The paper describes two new pyramid operators to detect symmetries based on previously introduced conventional operators. For sake of applications, experiments in the detection of point of interest are shown to support the hierarchical scheme. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Palermo, Dipartimento Matemat & Applicaz, I-90123 Palermo, Italy.
   Univ Paris 11, IEF, Orsay, France.
C3 University of Palermo; Universite Paris Saclay
RP Di Gesú, V (corresponding author), Univ Palermo, Dipartimento Matemat & Applicaz, Via Archirafi 34, I-90123 Palermo, Italy.
EM zavido@ief.u-psud.fr; digesu@math.unipa.it
CR Blake A., 1998, ACTIVE CONTOURS
   Cantoni V., 1991, Journal of VLSI Signal Processing, V2, P195, DOI 10.1007/BF00925466
   DIGESU V, 1997, ADV COMPUTER VISION
   DIGESU V, 1998, DMAIR0598 U PAL
   DIGESU V, 1996, VISTAS ASTRON, V40, P461
   GAUCH JM, 1993, IEEE T PATTERN ANAL, V15, P753, DOI 10.1109/34.236253
   KELLY MF, 1994, TRCIM9412 MCGILL U
   Kiryati N, 1998, INT J COMPUT VISION, V29, P29, DOI 10.1023/A:1008034529558
   KROPATSCH WG, 1985, PRIPTR35 TU WIEN DEP, V7
   LOY G, 2002, P EUR C COMP VIS ECC
   MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119
   Merigot A., 1992, International Journal of Pattern Recognition and Artificial Intelligence, V6, P387, DOI 10.1142/S0218001492000230
   MILGRAM DL, 1979, CGIP, V1, P1
   NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3
   PAVLIDIS TA, 1975, COMPUTER GRAPHICS IM, V4
   POMERANZT JR, 1975, PERCEPTION PSYCOPHYS, V8, P460
   UHR L, 1972, IEEE T COMPUT, pC21
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   ZADEH LA, 1994, COMMUN ACM, V37, P77, DOI 10.1145/175247.175255
NR 19
TC 4
Z9 4
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 220
EP 229
DI 10.1016/j.imavis.2006.01.030
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700011
DA 2024-07-18
ER

PT J
AU Nayak, A
   Chaudhuri, S
AF Nayak, Arvind
   Chaudhuri, Subhasis
TI Automatic illumination correction for scene enhancement and object
   tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE illumination correction; skin color; contrast transfer; neural network;
   condensation tracker; fuzzy c-means clustering
ID COLOR CONSTANCY ALGORITHMS; REAL-TIME TRACKING
AB An important challenge for any vision system is to accommodate varying illumination conditions. We device an automatic correction scheme that transforms images under some unknown illumination to match an illumination model learnt for a known illumination. We test the scheme on both color and gray level imaging scenarios. Skin color based hand tracking is our reference problem for testing the scheme in color imaging scenario. An automatically extracted palm region from initial frames in the sequence serves as an observed skin color palette. During training phase a feed-forward neural network learns the weights that map the observed palette to a pre-stored (target) skin color palette. The pre-stored palette represents ideal illumination conditions where the tracker gives reliable results. The look up table so generated then enhances skin regions in successive frames of the image sequence, thus improving the performance of the tracker. This approach enables a reliable tracking of hand in image sequences with wide variations in illumination. In order to defining correspondence between source and target palettes, a fuzzy c-means clustering scheme is used to segment images into regions. The histograms of matching clusters are used to transfer the contrast in poorly illuminated images to enhance the contrast. (c) 2006 Elsevier B.V. All rights reserved.
C1 Heriot Watt Univ, Vis Image & Signal Proc Res Grp, EECE EPS, Edinburgh EH14 4AS, Midlothian, Scotland.
   Indian Inst Technol, Dept Elect Engn, Bombay 400076, Maharashtra, India.
C3 Heriot Watt University; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Bombay
RP Nayak, A (corresponding author), Heriot Watt Univ, Vis Image & Signal Proc Res Grp, EECE EPS, Edinburgh EH14 4AS, Midlothian, Scotland.
EM amn1@hw.ac.uk; sc@ee.iitb.ac.in
RI Nayak, Arvind/B-7746-2009
CR Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   CARDEI V, 2000, THESIS S FRASER U BU
   Chen HT, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P717, DOI 10.1109/ICCV.2001.937697
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   FUNT B, 1998, 5 EUR C COMP VIS, P445
   GONCALVES L, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P764, DOI 10.1109/ICCV.1995.466861
   GUPTA N, 2002, P 3 IND C COMP VIS G
   Heap T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P344, DOI 10.1109/ICCV.1998.710741
   HSU R, 1999, IEEE T CIRCUITS SYST, V9, P551
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   JENNINGS C, 1999, INT WORKSH REC AN TR, P152
   JONES MJ, TECHNICAL REPORT SER
   Kjeldsen R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P312, DOI 10.1109/AFGR.1996.557283
   Mammen JP, 2002, IETE J RES, V48, P245, DOI 10.1080/03772063.2002.11416283
   Mammen JP, 2001, P BRIT MACH VIS C BM
   Martinkauppi JB, 2001, PROC SPIE, V4301, P102, DOI 10.1117/12.420902
   MCKENNA S, 1998, IMAGE VISION COMPUT, P225
   Oliver N, 1997, PROC CVPR IEEE, P123, DOI 10.1109/CVPR.1997.609309
   PEREZ P, 2002, EUR C COMP VIS, P661
   Peterfreund N, 1999, IEEE T PATTERN ANAL, V21, P564, DOI 10.1109/34.771328
   REHG JM, 1994, P EUR C COMP VIS, V2, P35
   Sigal L, 2000, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2000.854764
   Socolinsky DA, 2001, PROC CVPR IEEE, P527
   Soriano M, 2003, PATTERN RECOGN, V36, P681, DOI 10.1016/S0031-3203(02)00089-4
   STORRING M., 1999, P 7 S INTELLIGENT RO, P187
   Terzopoulos D., 1992, Active Vision, P3
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   WU Y, 2000, P AS C COMP VIS TAIW
   YANG J, CMUCS97146
NR 31
TC 8
Z9 14
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 949
EP 959
DI 10.1016/j.imavis.2006.02.017
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200004
DA 2024-07-18
ER

PT J
AU Mishra, A
   Dutta, PK
   Ghosh, MK
AF Mishra, A.
   Dutta, P. K.
   Ghosh, M. K.
TI Fuzzy shape based motion evaluation of left ventricle using genetic
   algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fuzzy shape properties; genetic algorithm; left ventricular motion; MRI
   and echocardiography images
ID BOUNDARY DETECTION; IDENTIFICATION; BORDERS; MODEL
AB A shape based non-rigid cardiac motion study is presented using simple fuzzy shape descriptors. The objective of this work is to evaluate the detail point wise motion trajectories from sequential contours. The shape correspondence on endocardial contour has been performed in multiple stages with well-defined, level specific curvature information. We incorporate non-uniform expansion and contraction of shape matched templates to optimize the correspondence in each level. However, final flow field evaluation is a constrained optimization problem, which results into a smooth mapping of contours. Constrained non-linear optimization with genetic algorithm has shown considerable promise in solving this problem. The results are quite consistent when correlated with the movement of implanted markers in an experimental set-up. Even though tracking contours in the reverse direction is irrelevant from a practical standpoint a good correlation between motions in either direction is observed. The algorithm has been tested over sets of 2D images to quantify the motion of left ventricle (LV) using two different imaging modalities. (C) 2006 Elsevier B.V. All rights reserved.
C1 Vanderbilt Univ, Nashville, TN 37240 USA.
   Indian Inst Technol Kharagpur, Dept Elect Engn, Kharagpur, W Bengal, India.
C3 Vanderbilt University; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Mishra, A (corresponding author), Vanderbilt Univ, Nashville, TN 37240 USA.
EM arimishra@rediffmail.com
CR ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   BHANDARKAR SM, 1994, PATTERN RECOGN, V27, P1159, DOI 10.1016/0031-3203(94)90003-5
   BHANU B, IEEE T SYST MAN CYBE, P1043
   Chai JX, 1998, PATTERN RECOGN LETT, V19, P829, DOI 10.1016/S0167-8655(98)00032-4
   Chalana V, 1996, IEEE T MED IMAGING, V15, P290, DOI 10.1109/42.500138
   CHU CH, 1988, IEEE T MED IMAGING, V7, P81, DOI 10.1109/42.3932
   COHEN I, 1992, LECT NOTES COMP SCI, V588
   DEMI M, 1990, COMPUT CARDIOL, P30
   DETMER PR, 1990, IEEE T MED IMAGING, V9, P396, DOI 10.1109/42.61755
   DUNCAN JS, 1991, IEEE T MED IMAGING, V10, P307, DOI 10.1109/42.97580
   FLEAGLE SR, 1991, INVEST RADIOL, V26, P295, DOI 10.1097/00004424-199104000-00002
   Geiser E A, 1990, J Am Soc Echocardiogr, V3, P79
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   JOHN C, 1997, IEEE T MED IMAGING, V16
   KRISHNAKUMAR K, 1995, GENETIC ALGORITHM EN
   LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733
   Mishra A, 2003, IMAGE VISION COMPUT, V21, P967, DOI 10.1016/S0262-8856(03)00121-5
   Mishra A, 2001, IMAGE VISION COMPUT, V19, P929, DOI 10.1016/S0262-8856(01)00053-1
   MISHRA A, 2000, ICCCD 2000, V2, P467
   MISHRA A, 2000, P JOINT INT C SCI 20
   RANGANATH S, 1995, IEEE T MED IMAGING, V14, P328, DOI 10.1109/42.387714
   RANGANATH S, 1992, P 2 INT C AUT ROB CO
   Shi P., 1995, Computer Vision, Virtual Reality and Robotics in Medicine. First International Conference, CVRMed '95. Proceedings, P327, DOI 10.1007/BFb0034968
   SHI P, 2000, IEEE T MED IMAGING, V19
   SLAGER CJ, 1986, J AM COLL CARDIOL, V7, P317, DOI 10.1016/S0735-1097(86)80498-3
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   Suh D. Y., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P149, DOI 10.1109/VBC.1990.109314
   Wang HY, 2000, IEEE T IMAGE PROCESS, V9, P302, DOI 10.1109/83.821748
   ZERHOUNI EA, 1988, RADIOLOGY, V169, P59, DOI 10.1148/radiology.169.1.3420283
NR 30
TC 4
Z9 4
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 436
EP 446
DI 10.1016/j.imavis.2006.01.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600004
DA 2024-07-18
ER

PT J
AU Zhang, HM
   Gao, W
   Chen, XL
   Zhao, DB
AF Zhang, Hongming
   Gao, Wen
   Chen, Xilin
   Zhao, Debin
TI Object detection using spatial histogram features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object detection; spatial histogram features; feature selection;
   histogram matching; support vector machine
ID INVARIANT TEXTURE CLASSIFICATION; SUPPORT VECTOR MACHINES;
   FEATURE-SELECTION; FACE DETECTION; IMAGES; SCALE
AB In this paper, we propose an object detection approach using spatial histogram features. As spatial histograms consist of marginal distributions of an image over local patches, they can preserve texture and shape information of an object simultaneously. We employ Fisher criterion and mutual information to measure discriminability and features correlation of spatial histogram features. We further train a hierarchical classifier by combining cascade histogram matching and support vector machine. The cascade histogram matching is trained via automatically selected discriminative features. A forward sequential selection method is presented to construct uncorrelated and discriminative feature sets for support vector machine classification. We evaluate the proposed approach on two different kinds of objects: car and video text. Experimental results show that the proposed approach is efficient and robust in object detection. (c) 2006 Elsevier B.V. All rights reserved.
C1 Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150001, Peoples R China.
   Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
C3 Harbin Institute of Technology; Chinese Academy of Sciences; Institute
   of Computing Technology, CAS
RP Zhang, HM (corresponding author), Harbin Inst Technol, Dept Comp Sci & Technol, 92,W Da Zhi St, Harbin 150001, Peoples R China.
EM hmzhang@jdl.ac.cn; wgao@jdl.ac.cn; xlchen@jdl.ac.cn; dbzhao@jdl.ac.cn
RI Zhao, Debin/JEP-0204-2023
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111
   [Anonymous], 2000, P 4 IEEE INT C AUT F
   [Anonymous], 1998, STAT LEARNING THEORY
   BERNHARD F, 2001, P 3 INT C AUD VID BA, P78
   Chang C.-C., 2004, Libsvm: a library for support vector machines, software
   Chen XR, 2004, PROC CVPR IEEE, P366
   Chow TWS, 2005, IEEE T NEURAL NETWOR, V16, P213, DOI 10.1109/TNN.2004.841414
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   FERGUS R, 1908, P 9 INT C COMP VIS P, V2, P264
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Hadid A, 2004, PROC CVPR IEEE, P797
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538
   Hua XS, 2001, PROC INT CONF DOC, P545, DOI 10.1109/ICDAR.2001.953848
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861
   Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145
   LEIBE B, 2004, ECCV2004 WORKSH STAT
   LI FF, 2004 C COMP VIS PATT
   Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   Lin YY, 2005, PROC CVPR IEEE, P680
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MENSER B, 1999, P 7 INT C IM PROC IT, P13
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   NAQUEST MV, 2003, P 9 INT C COMP VIS, P281
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   PAPAGEPRGIOU CP, 1999, 180 MIT AI
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Rao C, 1973, LINEAR STAT INFERENC
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   SCHIELE B, 1997, THESIS INP GRENOBLE
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Torralba A, 2004, PROC CVPR IEEE, P762
   Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu YM, 2004, PROC CVPR IEEE, P251
   Zhang HM, 2004, LECT NOTES COMPUT SC, V3331, P377
NR 43
TC 64
Z9 84
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2006
VL 24
IS 4
BP 327
EP 341
DI 10.1016/j.imavis.2005.11.010
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 049US
UT WOS:000238043500002
DA 2024-07-18
ER

PT J
AU Sminchisescu, C
   Triggs, B
AF Sminchisescu, C
   Triggs, B
TI Fast mixing hyperdynamic sampling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE hyperdynamics; Markov chain Monte-Carlo; importance sampling;
   global-optimization; human tracking
ID MOLECULAR-DYNAMICS; SIMULATION
AB Sequential random sampling ('Markov Chain Monte-Carlo') is a popular strategy for many vision problems involving multi-modal distributions over high-dimensional parameter spaces. It applies both to importance sampling (where one wants to sample points according to their 'importance' for some calculation, but otherwise fairly) and to global-optimization (where one wants to find good minima, or at least good starting points for local minimization, regardless of fairness). Unfortunately, most sequential samplers are very prone to becoming trapped for long periods in unrepresentative local minima, which leads to biased or highly variable estimates. We present a general strategy for reducing MCMC trapping that generalizes Voter's 'hyperdynamic sampling' from computational chemistry. The local gradient and curvature of the input distribution are used to construct an adaptive importance sampler that focuses samples on negative curvature regions that are likely to contain low cost transition states' (codimension-1 saddle points representing 'mountain passes' connecting adjacent cost basins). This substantially accelerates inter-basin transition rates while still preserving correct relative transition probabilities. Experimental tests on the difficult problem of 3D articulated human pose estimation from monocular images show significantly enhanced minimum exploration. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Toronto, Dept Comp Sci, Artificial Intelligence Lab, Toronto, ON M5S 3G4, Canada.
   INRIA, CNRS, GRAVIR, F-38330 Montbonnot St Martin, France.
C3 University of Toronto; Inria; Centre National de la Recherche
   Scientifique (CNRS)
RP Univ Toronto, Dept Comp Sci, Artificial Intelligence Lab, 6 Kings Coll Rd,Part Bldg, Toronto, ON M5S 3G4, Canada.
EM crismin@cs.toronto.edu; bill.triggs@inrialpes.fr
CR [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 1983, SCIENCE
   BARR AH, 1984, COMPUTER GRAPHICS, V18
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   CHAM T, 1999, IEEE INT C COMP VIS, V2, P239
   Choo K., 2001, IEEE INT C COMP VIS
   DEUTSCHER J, 1999, ICCV, P1144
   Deutscher J., 2000, IEEE INT C COMP VIS
   DUANE S, 1987, PHYS LETT B, V195, P216, DOI 10.1016/0370-2693(87)91197-X
   Forsyth DA, 2001, INT J COMPUT VISION, V41, P109, DOI 10.1023/A:1011165200654
   Gilks WR, 1998, J AM STAT ASSOC, V93, P1045, DOI 10.1080/01621459.1998.10473766
   Heap T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P344, DOI 10.1109/ICCV.1998.710741
   JARZYNSKI C, 2001, LAUR012157
   KING O, 2000, ECCV, P695
   LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5
   MacCormick J., 2000, IEEE European Conference on Computer Vision, P3, DOI DOI 10.1007/3-540-45053-X1
   MARINARI E, 1992, EUROPHYSICS LETT, V19
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   MILLER M, 2000, J CHEM PHYSICS, V113
   Morris DD, 1998, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.1998.698622
   NEAL R, 1993, CRGTR911 U TOR
   NEAL R, 1998, CRGTR931 U TOR
   NEAL R, 1998, 9805 U TOR DEP STAT
   Neal RM, 1996, STAT COMPUT, V6, P353, DOI 10.1007/BF00143556
   Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028
   SENDEROWITZ H, 1995, J AM CHEM SOC, P117
   SEVICK EM, 1993, J CHEM PHYSICS, V98
   Sidenbladh H., 2000, EUR C COMP VIS
   Sminchisescu C, 2004, PROC CVPR IEEE, P608
   Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003
   Sminchisescu C, 2003, PROC CVPR IEEE, P69
   Sminchisescu C, 2002, LECT NOTES COMPUT SC, V2350, P769
   Sminchisescu C, 2002, LECT NOTES COMPUT SC, V2350, P566
   Sminchisescu C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P27, DOI 10.1109/AFGR.2002.1004125
   Sminchisescu C., 2004, Proc. 21st International Conference on Machine Learning, P96
   SMINCHISESCU C, 2003, UNPUB MACHINE LEARNI
   Sorensen MR, 2000, J CHEM PHYS, V112, P9599, DOI 10.1063/1.481576
   Strauch B, 2000, J RECONSTR MICROSURG, V16, P1
   Taylor CJ, 2000, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2000.855885
   VINEYARD GH, 1957, J PHYS CHEM SOLIDS, V3, P121, DOI 10.1016/0022-3697(57)90059-8
   VOTER A, 1985, J CHEM PHYSICS, V82
   Voter AF, 1997, PHYS REV LETT, V78, P3908, DOI 10.1103/PhysRevLett.78.3908
   Voter AF, 1997, J CHEM PHYS, V106, P4665, DOI 10.1063/1.473503
NR 43
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2006
VL 24
IS 3
BP 279
EP 289
DI 10.1016/j.imavis.2005.07.022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 031PI
UT WOS:000236716100007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jedynak, B
   Zheng, HC
   Daoudi, M
AF Jedynak, B
   Zheng, HC
   Daoudi, M
TI Skin detection using pairwise models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE maximum entropy models; skin detection; Markov random field
ID EQUIVALENCE; ENSEMBLES; FRAME
AB We consider a sequence of three models for skin detection built from a large collection of labeled images. Each model is a maximum entropy model with respect to constraints concerning marginal distributions. Our models are nested. The first model, called the baseline model is well known from practitioners. Pixels are considered independent. Performance, measured by the ROC curve on the Compaq Database is impressive for such a simple model. However, single image examination reveals very irregular results. The second model is a Hidden Markov model, which includes constraints that force smoothness of the solution. The ROC curve obtained shows better performance than the baseline model. Finally, color gradient is included. Thanks to, Bethe tree approximation, we obtain a simple analytical expression for the coefficients of the associated maximum entropy model. Performance, compared with previous model is once more improved. (C) 2005 Elsevier Ltd All rights reserved.
C1 USTL, Lab Math Paul Painleve, F-59655 Villeneuve Dascq, France.
   ENIC Telecom Lille 1, CNRS,UMR 8022, INT LIFL, MIIRE Grp, F-59655 Villeneuve Dascq, France.
C3 Universite de Lille; Centre National de la Recherche Scientifique
   (CNRS); Universite de Lille
RP Johns Hopkins Univ, Ctr Imaging Sci, Clarck 302b, Baltimore, MD 21218 USA.
EM bruno.jedynak@jhu.edu; zheng@enic.fr; daoudi@enic.fr
RI jedynak, bruno m/A-8198-2009; Daoudi, Mohammed/H-5935-2013
OI Daoudi, Mohammed/0000-0003-4219-7860
CR [Anonymous], SCAND J STAT
   [Anonymous], ELEMENTS INFORM THEO
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Celeux G, 2003, PATTERN RECOGN, V36, P131, DOI 10.1016/S0031-3203(02)00027-4
   CHELLAPA R, 1996, MARKOV RANDOM FIELDS
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   JAYNES E, PROBABILITY THEORY L, pCH11
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   JONES MJ, 1998, 9811 CRL COMP
   MARTINLOF A, 1979, J STAT PHYS, V20, P557, DOI 10.1007/BF01012899
   Pearl J., 1988, PROBABILISTIC REASON
   Terrillon JC, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P112, DOI 10.1109/AFGR.1998.670934
   TERRILLON JC, 1920, 4 INT C AUT FAC GEST, P54
   Wang JZ, 1998, COMPUT COMMUN, V21, P1355, DOI 10.1016/S0140-3664(98)00203-5
   WANG JZ, 1998, NOTES COMPUTER SCI, V21, P113
   Winkler G., 1995, IMAGE ANAL RANDOM FI
   WU CH, 1995, IEEE T PATTERN ANAL, V17, P391, DOI 10.1109/34.385979
   Wu YN, 2000, INT J COMPUT VISION, V38, P247, DOI 10.1023/A:1008199424771
   YEDIDA JS, 2002, TR200122 MITS RES LA
   YOUNES L, 1998, ANN I H POINCARE B, V24, P269
   ZHANG J, 1992, IEEE T SIGNAL PROCES, V40, P2570, DOI 10.1109/78.157297
   Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420
NR 23
TC 11
Z9 15
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1122
EP 1130
DI 10.1016/j.imavis.2005.06.010
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500002
DA 2024-07-18
ER

PT J
AU Bevilacqua, A
AF Bevilacqua, A
TI Optimizing parameters of a motion detection system by means of a
   distributed genetic algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE motion detection; parameter optimization; traffic monitoring; visual
   surveillance; distributed genetic algorithm
ID SEGMENTATION; OPTIMIZATION; EXAMPLE
AB The main task of traffic monitoring applications is to identify moving targets. Usually, these applications require that a large number of parameters is tuned in order to work properly. In the motion detection system we have developed, about thirty parameters have been required to be optimized.
   This paper shows how a distributed implementation of a Genetic Algorithm (GA) over a network of workstations can successfully accomplish the parameter optimization task within a reduced amount of time. Accurate experiments accomplished on a challenging training sequence yield optimal parameter values. Four more test sequences allow us to assess the generality of the results previously attained. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Bologna, DEIS, ARCES, Dept Elect Comp Sci & Syst, I-40136 Bologna, Italy.
C3 University of Bologna
RP Bevilacqua, A (corresponding author), Univ Bologna, DEIS, ARCES, Dept Elect Comp Sci & Syst, Viale Risorgimento 2, I-40136 Bologna, Italy.
EM abevilacqua@deis.unibo.it
RI Bevilacqua, Alessandro/B-7851-2013
OI Bevilacqua, Alessandro/0000-0003-2938-5058
CR [Anonymous], 2002, P IAPR WORKSH MACH V
   Bevilacqua A, 2003, WSCG'2003, VOL 11, NO 1, CONFERENCE PROCEEDINGS, P57
   Bevilacqua A, 2001, LECT NOTES COMPUT SC, V2037, P278
   Bevilacqua A., 1999, Informatica, V23, P49
   Bevilacqua A, 2001, INT J MOD PHYS C, V12, P55, DOI 10.1142/S0129183101001523
   BEVILACQUA A, 2003, P IEEE INT WORKSH CO
   BEVILACQUA A, 2002, P 3 IND C COMP VIS G, P125
   BEVILACQUA A, 2003, P 11 INT C CENTR EUR, P25
   BEVILACQUA A, 2002, THESIS U BOLOGNA ITA
   Geist A., 1994, PVM: Parallel Virtual Machine
   Hwang SW, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICIP.2001.958508
   Kim EY, 2000, ELECTRON LETT, V36, P946, DOI 10.1049/el:20000690
   Kim EY, 2002, PATTERN RECOGN LETT, V23, P843, DOI 10.1016/S0167-8655(01)00160-X
   Kim EY, 2001, PATTERN RECOGN, V34, P2063, DOI 10.1016/S0031-3203(00)00129-1
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   MOSCHENI F, 1995, P 15 C TRAIT SIGN IM, V1, P825
   SHIRVAIKAR MV, 1995, IEEE T NEURAL NETWOR, V6, P252, DOI 10.1109/72.363430
   Swisher JR, 2000, PROCEEDINGS OF THE 2000 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P119, DOI 10.1109/WSC.2000.899706
   Voudouris C, 1998, BT TECHNOL J, V16, P46, DOI 10.1023/A:1009665513140
   ZHANG M, 2000, THESIS RMIT U MELBOU
   [No title captured]
NR 21
TC 7
Z9 7
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2005
VL 23
IS 9
BP 815
EP 829
DI 10.1016/j.imavis.2005.04.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VF
UT WOS:000231400700006
DA 2024-07-18
ER

PT J
AU Benabdelkader, C
   Griffin, PA
AF Benabdelkader, C
   Griffin, PA
TI Comparing and combining depth and texture cues for face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; 3D acquisition; biometrics; modality fusion
AB Depth and texture play complementary roles in the coding of faces. While most existing face recognition methods are based on texture cues from intensity images due to their ease of acquisition, more accurate face recognition can be achieved by exploiting both modalities. To evaluate this claim, we have designed a pattern classifier for three different inputs: (1) depth map, (2) texture map, and (3) both depth and texture maps of the facial surface. Two existing face recognition methods are considered for this task, FaceIt technology and FisherFaces. Recognition performance is evaluated based on face data of 185 subjects, captured with the structured-light-based Rainbow250 3D camera. (C) 2004 Elsevier B.V. All rights reserved.
C1 Amer Univ Beirut, Dept Comp Sci, Beirut, Lebanon.
   Identix Inc, Jersey City, NJ USA.
C3 American University of Beirut
RP Benabdelkader, C (corresponding author), Amer Univ Beirut, Dept Comp Sci, 104C Bliss Hall, Beirut, Lebanon.
EM cb07@aub.edu.lb
CR ACHERMANN B, 1997, INT C VIRT SYST MULT
   Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   [Anonymous], 1961, Adaptive control processes: a guided tour, DOI DOI 10.1515/9781400874668
   [Anonymous], 1999, Biometrics: Personal Identification in Networked Society
   Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9
   BEUMIER C, 2000, PORT C PATT REC
   Bowyer KevinW., 2004, Technical Report TR 2004-22
   BRONSTEIN A, 2003, AUDIO VIDEO BASED BI
   Chang K., 2003, WORKSH MULT US AUTH
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   COX I, 1994, P COMP VIS PATT REC
   Duda R. O., 2000, PATTERN CLASSIFICATI
   ETEMAD K, J OPTICAL SOC AM, V14
   Foley J. D., 1994, Introduction to Computer Graphics", V55
   GORDON GG, 1992, P COMP VIS PATT REC
   GORDON GG, P SPIE GEOM METH COM, V1570
   Hallinan P., 1999, Two and Three-dimensional Patterns of the Face
   HSU R, 2002, IEEE C MULT EXP
   KIRBY M, 1987, J OPT SOC AM, V4, P519
   LANITIS A, 1994, BRIT MACH VIS C
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   MORENO A, 2003, IR MACH VIS IM PROC
   Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002
   PHILLIPS P, 2003, 6965 IR NIST
   PHILLIPS PJ, PAMI, V22
   RATHA N, 1908, INT C ADV PATT REC
   RUSINKIEWICZ S, 2002, ACM SPECIAL INTEREST
   SRIVASTAVA A, UNPUB IMAGE VISION C
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   TSALAKANIDOU F, PATTERN RECOGNITION, V24
   TURK M, COGNITIVE NEUROSCIEN, V3
   WANG Y, 2003, PATTERN RECOGN, V23, P1191
   ZHAO ARW, 2002, CSTR4167R UMCP
NR 35
TC 36
Z9 38
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2005
VL 23
IS 3
BP 339
EP 352
DI 10.1016/j.imavis.2004.09.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NO
UT WOS:000227221800006
DA 2024-07-18
ER

PT J
AU Damiand, G
   Dexet-Guiard, M
   Lienhardt, P
   Andres, E
AF Damiand, G
   Dexet-Guiard, M
   Lienhardt, P
   Andres, E
TI Removal and contraction operations to define combinatorial pyramids:
   application to the design of a spatial modeler
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE removal; contraction; irregular pyramids; n-G-map; modeler; discrete
   reconstruction
ID SPECIFICATION; TOPOLOGY
AB Removal and contraction are basic operations for several methods conceived in order to handle irregular image pyramids, for multi-level image analysis for instance. We give the definitions of removal and contraction operations in the generalized maps framework. We propose a first experimentation of irregular pyramid as a basis for a discrete geometrical modeler that can handle both discrete and continuous representations of geometrical objects. This modeler is based on a pyramidal kernel with four coexisting level between the discrete and the Euclidean representations. We describe how this pyramid can be constructed and updated. (C) 2004 Elsevier B.V. All rights reserved.
C1 SIC, IRCOM, F-86962 Chasseneuil, France.
C3 Universite de Poitiers
RP SIC, IRCOM, Bat SP2M1,BP 30179, F-86962 Chasseneuil, France.
EM damiand@sic.univ-poitiers.fr; dexet@sic.univ-poitiers.fr;
   lienhardt@sic.univ-poitiers.fr; andres@sic.univ-poitiers.fr
RI Damiand, Guillaume/AAJ-2151-2020; Damiand, Guillaume/IAM-8662-2023
OI Damiand, Guillaume/0000-0003-1580-5517; 
CR Alexandroff P., 1937, DISKRETE RAUME MAT S, V2, P501
   Andres E, 2003, GRAPH MODELS, V65, P92, DOI 10.1016/S1524-0703(03)00004-3
   ANDRES E, 2001, LNCS, V2243, P91
   ANDRES E, 2000, THESIS U POITIERS FR
   AUBRY S, 1989, IEEE INT C ROB AUT S, V1, P196
   Bertrand Y, 2000, LECT NOTES COMPUT SC, V1953, P311
   BERTRAND Y, 1994, CVGIP-GRAPH MODEL IM, V56, P29, DOI 10.1006/cgip.1994.1005
   BERTRAND Y, 1992, THESIS U LOUIS PASTE
   Bonneau GP, 1998, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P59, DOI 10.1109/CGI.1998.694250
   BRAQUELAIRE JP, 2001, WORKSH GRAPH BAS REP, P32
   BRAQUELAIRE JP, 1999, WORKSH GRAPH BAS REP, P193
   Breton R, 2003, LECT NOTES COMPUT SC, V2886, P246
   BRISSON E, 1993, DISCRETE COMPUT GEOM, V9, P387, DOI 10.1007/BF02189330
   BRUN L, 1999, 57 U TECHN I COMP AI
   BRUN L, 1999, WORKSH GRAPH BAS REP, P145
   BRUN L, 2001, WORKSH GRAPH BAS REP, P12
   BRUN L, 2000, 63 VIENN U TECHN I C
   BURN L, 1996, THESIS U BORDEAUX 1
   BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619
   Cori R., 1973, THESIS U PARIS 7
   Damiand G, 2003, LECT NOTES COMPUT SC, V2886, P408
   Damiand G., 2001, THESIS U MONTPELLIER
   DEFLORIANI L, 1988, ACM T GRAPHIC, V7, P42, DOI 10.1145/42188.46164
   Dufourd JF, 2000, COMP GEOM-THEOR APPL, V16, P129, DOI 10.1016/S0925-7721(00)00004-3
   Edmonds J. R., 1960, NOT AM MATH SOC, V7
   ELTER H, 1994, THESIS U LOUIS PASTE
   Fiorio C., 1995, THESIS U MONTPELLIER
   Jacques A., 1970, COMBINATORIAL THEORY, V2, P657
   JOLION JM, 1992, CVGIP-IMAG UNDERSTAN, V55, P339, DOI 10.1016/1049-9660(92)90031-W
   Khalimsky E., 1990, J. Appl. Math. Stochastic Anal, V3, P27
   KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5
   Kropatsch WG, 1995, IEE P-VIS IMAGE SIGN, V142, P366, DOI 10.1049/ip-vis:19952115
   KROPATSCH WG, 2002, LNCS, V2301, P1
   KROPATSCH WG, 1994, PRIPTR35 TU VIENN I
   LIENHARDT P, 1991, COMPUT AIDED DESIGN, V23, P59, DOI 10.1016/0010-4485(91)90082-8
   Lienhardt P, 1994, INT J COMPUT GEOM AP, V4, P275, DOI 10.1142/S0218195994000173
   MEER P, 1989, COMPUT VISION GRAPH, V45, P269, DOI 10.1016/0734-189X(89)90084-4
   MOUTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307
   VIDIL F, 2001, DEV MODELEUR GEOMETR
   [No title captured]
NR 40
TC 7
Z9 7
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 259
EP 269
DI 10.1016/j.imavis.2004.06.016
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Egnal, G
   Mintz, M
   Wildes, RP
AF Egnal, G
   Mintz, M
   Wildes, RP
TI A stereo confidence metric using single view imagery with comparison to
   five alternative approaches
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE stereo matching; confidence metrics; empirical evaluations
AB Although stereo vision research has progressed remarkably, stereo systems still need a fast, accurate way to estimate confidence in their output. In the current paper, we explore using stereo performance on two different images from a single view as a confidence measure for a binocular stereo system incorporating that single view. Although it seems counterintuitive to search for correspondence in two different images taken in quick succession from the same view, such a search gives us precise quantitative performance data. Correspondences significantly far from the same location are erroneous because there is little to no displacement between the two images. Using hand-generated ground truth, we quantitatively compare this new confidence metric with five commonly used confidence metrics. We explore the performance characteristics of each metric under a variety of conditions. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA.
   York Univ, Ctr Vis Res, N York, ON M3J 1P3, Canada.
C3 University of Pennsylvania; York University - Canada
RP 11600 Sunrise Valley Dr,Suite 290, Reston, VA USA.
EM gegnal@gradient.cis.upenn.edu; mintz@grasp.cis.upenn.edu;
   wildes@cs.yorku.ca
CR ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   Anandan P., 1984, SPIE INTEL ROBOTS CO, V521, P184
   [Anonymous], INT S ROB RES
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   BLOSTEIN SD, 1987, IEEE T PATTERN ANAL, V9, P752, DOI 10.1109/TPAMI.1987.4767982
   Bolles R.C., 1993, IUW, P263
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chang C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P722, DOI 10.1109/CVPR.1991.139799
   DAS S, 1995, IEEE T PATTERN ANAL, V17, P1213, DOI 10.1109/34.476513
   Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808
   Faugeras O., 1992, ROBUST COMPUTER VISI, P1
   GRIMSON WEL, 1981, PHILOS T ROY SOC B, V292, P217, DOI 10.1098/rstb.1981.0031
   HANNAH M, 1982, DARPA IM UND WORKSH, P283
   HANNAH MJ, 1974, THESIS STANFORD U
   Kamberova G., 1998, Empirical Evaluation Techniques in Computer Vision, P96
   LECLERC Y, 1998, DARPA IM UND WORKSH, P793
   LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839
   LITTLE J, 1990, P EUR C COMP VIS, P336
   Liu XF, 1996, IMAGE UNDERSTANDING WORKSHOP, 1996 PROCEEDINGS, VOLS I AND II, P1533
   LUO A, 1995, INT J COMPUT VISION, V15, P171, DOI 10.1007/BF01451740
   MANDELBAUM R, 1998, P INT C COMP VIS
   MATTHIES L, 1992, INT J COMPUT VISION, V8, P71, DOI 10.1007/BF00126401
   MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1
   MULLIGAN J, 2001, P INT C COMP VIS
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763
   Samaras D, 2000, PROC CVPR IEEE, P480, DOI 10.1109/CVPR.2000.855858
   SATOH K, 1996, P INT C PATT REC
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 1997, THESIS CORNELL U
   SMITLEY T, 1984, P INT JOINT C PATT R, P405
   Szeliski R., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P781, DOI 10.1109/ICCV.1999.790301
   TRAPP R, 1998, P ECCV, P17
   WENG J, 1988, P INT C COMP VIS, P64
   XIONG Y, 1997, P C COMP VIS PATT RE
NR 35
TC 61
Z9 67
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 943
EP 957
DI 10.1016/j.imavis.2004.03.018
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800003
DA 2024-07-18
ER

PT J
AU Haddadnia, J
   Ahmadi, M
AF Haddadnia, J
   Ahmadi, M
TI N-feature neural network human face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE face recognition; RBF neural network; clustering technique; shape
   information
ID DESIGN
AB This paper introduces an efficient method for human face recognition system, which is called the hybrid N-feature neural network (HNFNN) human face recognition system. The HNFNN employs a set of different kind of features from face images with radial basis function (RBF) neural networks, which are fused together through the majority rule. The proposed method improves the performance of the system by combining RBF neural networks, training with different learning algorithms, in committees. This article also evaluates how the performance can be improved by disregarding irrelevant data from the face images by defining the efficient parameters. Experimental results on the ORL and Yale face databases confirm that the proposed method lends itself to higher classification accuracy relative to existing techniques. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
   Tarbiat Moallem Univ Sabzevar, Dept Engn, Khorasan 397, Iran.
C3 University of Windsor
RP Univ Windsor, Dept Elect & Comp Engn, 401 Sunset Ave, Windsor, ON N9B 3P4, Canada.
EM ahmadi@uwindsor.ca
RI Haddadnia, Javad/S-1485-2018
OI Haddadnia, Javad/0000-0003-4736-455X
CR Behloul F, 2002, PATTERN RECOGN, V35, P659, DOI 10.1016/S0031-3203(01)00033-4
   Bezdek James C., 1981, PATTERN RECOGN
   Chen LF, 2001, PATTERN RECOGN, V34, P1393, DOI 10.1016/S0031-3203(00)00078-9
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   EMBREE PM, 1991, LANGUAGE ALGORITHM D
   Giacinto G, 2000, IEEE IJCNN, P155, DOI 10.1109/IJCNN.2000.861297
   Grudin MA, 2000, PATTERN RECOGN, V33, P1161, DOI 10.1016/S0031-3203(99)00104-1
   GUTTA S, 2002, IEEE T NEURAL NETWOR, V11, P949
   Haddadnia J, 2003, IEICE T INF SYST, VE86D, P316
   Haddadnia J, 2001, IEEE IMAGE PROC, P1018, DOI 10.1109/ICIP.2001.959221
   Haddadnia J, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P330, DOI 10.1109/AFGR.2002.1004175
   Haddadnia J, 2002, IEEE IJCNN, P11, DOI 10.1109/IJCNN.2002.1005434
   HADDADNIA J, 2000, 5 INT FALL WORKSH VI, P113
   HARA Y, 1994, IEEE T GEOSCI REMOTE, V32, P100, DOI 10.1109/36.285193
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   JANG JSR, 1993, IEEE T NEURAL NETWOR, V4, P156, DOI 10.1109/72.182710
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575
   Lu Y, 1996, APPL INTELL, V6, P75, DOI 10.1007/BF00117809
   Tan T, 1999, INT CONF ACOUST SPEE, P3537, DOI 10.1109/ICASSP.1999.757606
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Thomaz CE, 1998, VTH BRAZILIAN SYMPOSIUM ON NEURAL NETWORKS, PROCEEDINGS, P118, DOI 10.1109/SBRN.1998.731006
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang JG, 2000, PATTERN RECOGN LETT, V21, P463, DOI 10.1016/S0167-8655(00)00008-8
   YUNG MH, 2002, IEEE T PATTERN ANAL, V34, P34
   Zhou WY, 1999, IEEE T GEOSCI REMOTE, V37, P771, DOI 10.1109/36.752193
NR 28
TC 27
Z9 29
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 1071
EP 1082
DI 10.1016/j.imavis.2004.03.011
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800012
DA 2024-07-18
ER

PT J
AU Ryan, N
   Heneghan, C
   de Chazal, P
AF Ryan, N
   Heneghan, C
   de Chazal, P
TI Registration of digital retinal images using landmark correspondence by
   expectation maximization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image registration; vector mapping; affine transformation; EM algorithm;
   retina
ID ALGORITHM; RETINOPATHY
AB A method for registering pairs of digital images of the retina is presented, using a small set of intrinsic control points whose matching is not known. Control point matching is then achieved by calculating similarity transformation (ST) coefficients for all possible combinations of control point pairs. The cluster of coefficients associated with the matched control point pairs is identified by calculating the Euclidean distance between each set of ST coefficients and its Rth nearest neighbour, followed by use of the Expectation-Maximization (EM) algorithm. Registration is then achieved using linear regression to optimize similarity, bilinear or second order polynomial transformations for the matching control point pairs. Results are presented of (a) the cross-modal image registration of an optical image and a fluorescein angiogram, (b) temporal registration of two images of an infant eye, and (c) mono-modal registration of a set of seven standard field optical photographs. For cross-modal registration, using a set of independent matched control points, points are mapped with an estimated accuracy of 2.9 pixels for 575 x 480 pixel images. Bilinear and second-order polynomial transformation models all prove to be appropriate for the final registration transform. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Coll Dublin, Dept Elect & Elect Engn, Dublin 4, Ireland.
C3 University College Dublin
RP Heneghan, C (corresponding author), Univ Coll Dublin, Dept Elect & Elect Engn, Dublin 4, Ireland.
EM conor.heneghan@ucd.ie
OI de Chazal, Philip/0000-0002-2091-207X
CR ALDINGTON SJ, 1995, DIABETOLOGIA, V38, P437, DOI 10.1007/s001250050303
   [Anonymous], 1991, Ophthalmology, V98, P823
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Can A, 2002, IEEE T PATTERN ANAL, V24, P347, DOI 10.1109/34.990136
   Can A, 2002, IEEE T PATTERN ANAL, V24, P412, DOI 10.1109/34.990145
   Can A, 2000, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2000.854924
   CAN A, 1999, P IEEE C COMP VIS PA, P286
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   GOSHTASBY A, 1986, PATTERN RECOGN, V19, P459, DOI 10.1016/0031-3203(86)90044-0
   Harris, 2001, RETINA, P2068
   HART WE, 1994, IEEE IMAGE PROC, P576, DOI 10.1109/ICIP.1994.413740
   HATKENS T, 2002, COMPUTER VISION IMAG, V86, P118
   Heneghan C, 2002, MED IMAGE ANAL, V6, P407, DOI 10.1016/S1361-8415(02)00058-0
   JAGOE R, 1993, INVEST OPHTH VIS SCI, V34, P2881
   Lloret D, 2000, INT C PATT RECOG, P203, DOI 10.1109/ICPR.2000.903521
   MAGUIRE P, 2003, THESIS U COLL DUBLIN
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   MARKOW MS, 1993, IEEE T BIO-MED ENG, V40, P1269, DOI 10.1109/10.250583
   Matsopoulos G K, 1999, IEEE Trans Inf Technol Biomed, V3, P47, DOI 10.1109/4233.748975
   NAGIN P, 1985, OPHTHALMOLOGY, V92, P547
   NANJIANI M., 1991, FLUORESCEIN ANGIOGRA
   PELI E, 1987, IEEE T MED IMAGING, V6, P272, DOI 10.1109/TMI.1987.4307837
   Pinz A, 1998, IEEE T MED IMAGING, V17, P606, DOI 10.1109/42.730405
   Ritter N, 1999, IEEE T MED IMAGING, V18, P404, DOI 10.1109/42.774168
   SANE PJ, 1997, OPHTHALMIC PHOTOGRAP
   Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589
   Wolberg G., 1992, DIGITAL IMAGE WARPIN
   Xu L, 1996, NEURAL COMPUT, V8, P129, DOI 10.1162/neco.1996.8.1.129
   Zana F, 1999, IEEE T MED IMAGING, V18, P419, DOI 10.1109/42.774169
   Zana F, 1999, IEE CONF PUBL, P479, DOI 10.1049/cp:19990368
NR 30
TC 61
Z9 66
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2004
VL 22
IS 11
BP 883
EP 898
DI 10.1016/j.imavis.2004.04.004
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 847MJ
UT WOS:000223396600003
DA 2024-07-18
ER

PT J
AU Jin, ATB
   Ling, DNC
   Song, OT
AF Jin, ATB
   Ling, DNC
   Song, OT
TI An efficient fingerprint verification system using integrated wavelet
   and <i>Fourier-Mellin</i> invariant transform
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fingerprint verification; wavelet transform; Fourier-Mellin transform;
   invariant features
ID RECOGNITION
AB Today, minutiae-based and image-based are the two major approaches for the purpose of fingerprint authentication. Image based approach offers much higher computation efficiency with minimum pre-processing and proves also effective even when the image quality is too low to allow a reliable minutia extraction. However, this approach is vulnerable to shape distortions as well as variation in position, scale and orientation an-le. In this paper, a novel method of image based fingerprint matching based on the features extracted from the integrated Wavelet and the Fourier-Mellin Transform (WFMT) framework is proposed to remedy these problems. Wavelet transform, with its energy compacted feature is used to preserve the local edges and reduce noise in the low frequency domain after image decomposition, and hence making the fingerprint images less sensitive to shape distortion. The Fourier-Mellin transform (FMT) served to produce a translation, rotation and scale invariant feature. Multiple WFMT features can be used to form a reference invariant feature through the linearity property of FMT and hence reduce the variability of the input fingerprint images. Based on this integrated framework, a fingerprint verification system is designed. The experiments show the verification accuracy is 5.66 and 1.01% of equal error rate is achieved when multiple WFMT features are used. (C) 2003 Elsevier B.V. All rights reserved.
C1 Multimedia Univ, Fac Informat Sci & Technol, Melaka 75450, Malaysia.
C3 Multimedia University
RP Multimedia Univ, Fac Informat Sci & Technol, Melaka 75450, Malaysia.
EM bjteoh@mmu.edu.my
RI Ngo, David C. L./E-3307-2012; Teoh, Andrew Beng Jin/F-4422-2010; Ong,
   Thian Song/Q-6932-2018
OI Teoh, Andrew Beng Jin/0000-0001-5063-9484; Ong, Thian
   Song/0000-0002-5867-9517
CR [Anonymous], 2008, A wavelet tour of signal processing: The sparse way
   [Anonymous], 2003, Handbook of fingerprint recognition
   [Anonymous], P IEEE INT S CIRC SY
   BAZEN AM, 2000, P PRORISC
   Bracewell R. N, 1986, FOURIER TRANSFORM IT, V3rd
   GRACE AE, 1991, PATTERN RECOGN LETT, V12, P635, DOI 10.1016/0167-8655(91)90018-H
   HENRY ER, 1990, CLASSIFICATION US FI
   Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674
   Lee CJ, 1999, ELECTRON LETT, V35, P288, DOI 10.1049/el:19990213
   MAIO D, 2002, P INT C PATT REC QUE
   Prabhakar S, 2000, INT C PATT RECOG, P25, DOI 10.1109/ICPR.2000.905269
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   ROBERGE D, 1998, SPIE, V3386
   Schalkoff R. J., 1989, DIGITAL IMAGE PROCES, P279
   TEOH ATS, 2003, 16 AUST JOINT C ART, V2903, P633
   Wood J, 1996, PATTERN RECOGN, V29, P1, DOI 10.1016/0031-3203(95)00069-0
   ZHAO F, 2002, P INT C INF SEC JUL
   ZHAO F, 2002, INT C IMAGING SCI SY
NR 18
TC 61
Z9 70
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2004
VL 22
IS 6
BP 503
EP 513
DI 10.1016/j.imavis.2003.12.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 817HB
UT WOS:000221167500006
DA 2024-07-18
ER

PT J
AU Park, U
   Udpa, L
   Stockman, GC
AF Park, U
   Udpa, L
   Stockman, GC
TI Motion-based filtering of magneto-optic imagers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE magneto-optic imager; serpentine pattern noise; motion-based filtering
AB The magneto-optic imager (MOI) is a powerful device for the nondestructive inspection (NDI) of aging aircraft. MOI produces analog images of magnetic flux leakage associated with eddy current distribution around surface and subsurface structures. The main advantages of using MOI are its fast inspection speed and easy interpretation compared with conventional Eddy Current NDI instruments. However, due to the magnetic domain wall structures of the sensor, the MOI images are corrupted by noise, which lowers the MOI inspection capabilities. The domain walls produce serpentine pattern noise, which can be reduced by improving the sensor or by use of image processing methods. This paper introduces a motion-based image processing method to reduce the background noise. Initial results of implementing the algorithm on real field data are presented. (C) 2003 Elsevier B.V. All rights reserved.
C1 Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
   Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48824 USA.
C3 Michigan State University; Michigan State University
RP Park, U (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3208 Engn Bldg, E Lansing, MI 48824 USA.
EM parkunsa@egr.msu.edu; udpal@egr.msu.edu; stockman@cse.msu.edu
CR Bright DS, 1998, J MICROSC-OXFORD, V189, P25, DOI 10.1046/j.1365-2818.1998.00249.x
   Fitzpatrick G., 1993, MAGNETO OPTIC EDDY C, P1402
   FITZPATRICK GL, 1996, REV PROGR QUANTITATI, pV15
   FITZPATRICK GL, Patent No. 4625167
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   JAEIN L, 2001, REV PROGR QUANTITATI, V20, P611
   LEMISTRE M, 2001, P INT C QUAL CONTR A, P65
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   SHAPIRO LG, 2001, COMP VISION
NR 9
TC 18
Z9 20
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2004
VL 22
IS 3
BP 243
EP 249
DI 10.1016/j.imavis.2003.10.001
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 776RH
UT WOS:000189130100007
DA 2024-07-18
ER

PT J
AU Magee, DR
AF Magee, DR
TI Tracking multiple vehicles using foreground, background and motion
   models
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Statistical Methods in Video Processing
CY JUN 01-02, 2002
CL COPENHAGEN, DENMARK
DE vehicle tracking; background model; Gaussian mixture model
AB In this paper a vehicle tracking algorithm is presented based on the combination of a novel per-pixel (Gaussian Mixture Based) background model and a set of foreground models of object size, position, velocity, and colour distribution. Each pixel in the scene is 'explained' as either background, belonging to a foreground object, or as noise. A projective ground-plane transform is used within the foreground model to strengthen object size and velocity consistency assumptions. A learned model of typical road travel direction and speed is used to provide a prior estimate of object velocity, which is used to initialise the velocity model for each of the foreground objects. The system runs at near video framerate (>20 fps) on modest hardware and is robust assuming sufficient image resolution is available and vehicle sizes do not greatly exceed the priors on object size used in object initialisation. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
C3 University of Leeds
RP Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
EM drm@comp.leeds.ac.uk
CR Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371
   Cootes T.F., 1998, COMPUTER VISION ECCV, V1407, P484, DOI [DOI 10.1007/BFB0054760, DOI 10.1109/34.927467]
   FERRIER N, 1994, IEEE WORKSH APPL COM, P81
   Ferryman JM, 2000, INT J COMPUT VISION, V37, P187, DOI 10.1023/A:1008155721192
   Galata A, 2002, FRONT ARTIF INTEL AP, V77, P741
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Harville M, 2002, LECT NOTES COMPUT SC, V2352, P543
   HEAP A, 1997, P BRIT MACH VIS C, V1, P80
   ISARD M, 1914, P IEEE INT C COMP VI, P34
   Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8
   Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   Koller D., 1994, PROC EUROPEAN C COMP, P186
   McKenna S. J., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P348, DOI 10.1109/AFGR.2000.840658
   McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8
   Ridder C., 1995, PROC INT C RECENT AD, P193
   Silverman, 2018, DENSITY ESTIMATION S, DOI 10.1201/9781315140919
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   SULLIVAN G, REAL TIME COMPUTER V
   Tao Hai., 1999, P ICCV 99 WORKSHOP V, P53
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 22
TC 122
Z9 174
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2004
VL 22
IS 2
BP 143
EP 155
DI 10.1016/S0262-8856(03)00145-8
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 769DW
UT WOS:000188612000007
DA 2024-07-18
ER

PT J
AU Sebe, N
   Tian, Q
   Loupias, E
   Lew, MS
   Huang, TS
AF Sebe, N
   Tian, Q
   Loupias, E
   Lew, MS
   Huang, TS
TI Evaluation of salient point techniques
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE salient points; wavelet transform; information content; repeatability
   rate
AB In image retrieval, global features related to color or texture are commonly used to describe the image content. The problem with this approach is that these global features cannot capture all parts of the image having different characteristics. Therefore, local computation of image information is necessary. By using salient points to represent local information, more discriminative features can be computed. In this paper, we compare a wavelet-based salient point extraction algorithm with two corner detectors using the criteria: repeatability rate and information content. We also show that extracting color and texture information in the locations given by our salient points provides significantly improved results in terms of retrieval accuracy, computational complexity, and storage space of feature vectors as compared to global feature approaches. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Amsterdam, Fac Sci, Amsterdam, Netherlands.
   Univ Texas, Dept Comp Sci, San Antonio, TX 78285 USA.
   INSA Lyon, Lab Reconnaissance Formes & Vis, Lyon, France.
   Leiden Univ, LIACS Media Lab, Leiden, Netherlands.
   Univ Illinois, Beckman Inst, Urbana, IL 61801 USA.
C3 University of Amsterdam; University of Texas System; University of Texas
   Health Science Center at San Antonio; Institut National des Sciences
   Appliquees de Lyon - INSA Lyon; Leiden University - Excl LUMC; Leiden
   University; University of Illinois System; University of Illinois
   Urbana-Champaign
RP Univ Amsterdam, Fac Sci, Kruislaan 403, Amsterdam, Netherlands.
EM nicu@science.uva.nl; qitian@cs.utsa.edu; loupias@rfv.insa-lyon.fr;
   mlew@liacs.nl; huang@ifp.uiuc.edu
RI Sebe, Niculae/KEC-2000-2024
OI Sebe, Niculae/0000-0002-6597-7248
CR [Anonymous], BRIT MACH VIS C
   BECK J, 1987, COMPUT VISION GRAPH, V37, P299, DOI 10.1016/S0734-189X(87)80006-3
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   Haralick R.M., 1993, COMPUTER ROBOT VISIO, V2
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   LOUPIAS E, 2000, INT C ADV VIS INF SY, P223
   Ma W.Y., 1995, Image Processing, 1995. Proceedings., V2, P256, DOI DOI 10.1109/ICIP.1995.537463
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Sebe N, 2002, LECT NOTES COMPUT SC, V2383, P367
   Sebe N, 2003, PATTERN RECOGN LETT, V24, P89, DOI 10.1016/S0167-8655(02)00192-7
   Sebe N, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P15, DOI 10.1109/IVL.2000.853833
   SMITH JR, 1994, IEEE IMAGE PROC, P407, DOI 10.1109/ICIP.1994.413817
   STRICKER A, 1995, SPIE STORAGE RETRIEV, V3, P381
   Tian Q, 2001, J ELECTRON IMAGING, V10, P835, DOI 10.1117/1.1406945
NR 17
TC 38
Z9 44
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1087
EP 1095
DI 10.1016/j.imavis.2003.08.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100003
DA 2024-07-18
ER

PT J
AU Thodberg, HH
   Rosholm, A
AF Thodberg, HH
   Rosholm, A
TI Application of the active shape model in a commercial medical device for
   bone densitometry
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE active shape model; active appearance model; medical image analysis;
   osteoporosis
AB Osteoporosis is a common disorder characterised mainly by low bone mineral density (BMD), and leading to an increased risk of fracture. We have developed a new device that estimates BMD from ordinary hand radiographs. A crucial element of this method is the reconstruction of the metacarpals. This paper describes how this was solved using the active shape model (ASM). Standard ASM is unable to locate the metacarpal shafts in the direction along the bones. Therefore ASM was extended with a translation operator, which solved the problem. A hierarchical filtering method was used to construct a sufficient list of initial guesses for the ASM. The performance of ASM and the experience with the integration of ASM in a commercial medical device is reported. The ASM achieves 99.5% reconstruction success and is able to validate its own reconstruction in 97% of the cases. The system (Pronosco X-posure system, version 2.0) has been approved by the FDA, and more than 100 units have been sold.
   The concept of the translation operator is generalised to the more active shape model (MASM), which also allows a natural integration with the active appearance model. (C) 2003 Elsevier B.V. All rights reserved.
C1 Tech Univ Denmark, DK-2800 Lyngby, Denmark.
   Sectra Pronosco A S, Herlev, Denmark.
C3 Technical University of Denmark
RP Thodberg, HH (corresponding author), Tech Univ Denmark, Richard Petersens Plads, DK-2800 Lyngby, Denmark.
CR Cootes T., 1992, P BRIT MACH VIS C, P266
   COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   COOTES TF, 2000, DETAILED REPORT ACTI
   EFFORD ND, 1994, 9431 U LEEDS
   Rosholm A, 2001, OSTEOPOROSIS INT, V12, P961, DOI 10.1007/s001980170026
   Smyth PP, 1999, RADIOLOGY, V211, P571, DOI 10.1148/radiology.211.2.r99ma40571
NR 7
TC 17
Z9 18
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1155
EP 1161
DI 10.1016/j.imavis.2003.09.002
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100010
DA 2024-07-18
ER

PT J
AU Huber, DF
   Hebert, M
AF Huber, DF
   Hebert, M
TI Fully automatic registration of multiple 3D data sets
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT IEEE Workshop in Computer Vision Beyond the Visible Spectrum
CY DEC 14, 2001
CL KAUAI, HI
SP IEEE
DE three dimensional modeling; object modeling; surface matching;
   visibility consistency; model graph; registration
ID OBJECT; REPRESENTATION; RECOGNITION
AB This paper presents a method for automatically registering multiple rigid three dimensional (3D) data sets, a process we call multi-view surface matching. Previous approaches required manual registration or relied on specialized hardware to record the sensor position. In contrast, our method does not require any pose measuring hardware or manual intervention. We do not assume any knowledge of initial poses or which data sets overlap. Our multi-view surface matching algorithm begins by converting the input data into surface meshes, which are pair-wise registered using a surface matching engine. The resulting matches are tested for surface consistency, but some incorrect matches may be indistinguishable from correct ones at this local level. A global optimization process searches a graph constructed from the pair-wise matches for a connected sub-graph containing only correct matches, employing a global consistency measure to eliminate incorrect, but locally consistent, matches. From this sub-graph, the rigid-body transforms that register all the views can be computed directly. We apply our algorithm to the problem of 3D digital reconstruction of real-world objects and show results for a collection of automatically digitized objects. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM dhuber@ri.cmu.edu; hebert@ri.cmu.edu
CR Allen P, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P357, DOI 10.1109/IM.2001.924477
   [Anonymous], ACM SIGGRAPH 2000 C
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   [Anonymous], P EUR C COMP VIS FRE
   [Anonymous], P IM UND WORKSH MONT
   [Anonymous], 1997, THESIS CARNEGIE MELL
   Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   CARMICHAEL O, 1999, P 2 INT C 3D DIG IM, P358, DOI DOI 10.1109/IM.1999.805366
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   Cormen T.H., 1990, Introduction to Algorithms
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Eggert DW, 1998, COMPUT VIS IMAGE UND, V69, P253, DOI 10.1006/cviu.1998.0667
   ElHakim SF, 1997, P SOC PHOTO-OPT INS, V3174, P21, DOI 10.1117/12.279791
   Ferrie F. P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P117
   Foley James D., 1987, COMPUTER GRAPHICS PR, V2nd
   Garland M., 1997, P 24 ANN C COMP GRAP, V1997, P209, DOI DOI 10.1145/258734.258849
   Goldberger J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P730, DOI 10.1109/ICCV.1999.790294
   HIGUCHI K, 1995, GRAPH MODEL IM PROC, V57, P315, DOI 10.1006/gmip.1995.1028
   HUBER DF, 2001, IEEE COMP SOC WORKSH
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733
   Neugebauer P. J., 1997, International Journal of Shape Modeling, V3, P71, DOI 10.1142/S0218654397000070
   Nishino K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P454
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982
   STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785
   Stoddart A. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P40, DOI 10.1109/ICPR.1996.546720
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   Wyngaerd J. V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P301, DOI 10.1109/ICCV.1999.791234
   ZHANG D, 1999, P IEEE COMP SOC C CO, V2, P524
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 43
TC 217
Z9 258
U1 0
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2003
VL 21
IS 7
BP 637
EP 650
DI 10.1016/S0262-8856(03)00060-X
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 706FR
UT WOS:000184443400007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, Y
   Zhang, D
AF Yang, Y
   Zhang, D
TI A novel line scan clustering algorithm for identifying connected
   components in digital images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image processing; connected components labeling; connectivity; one-pass;
   parallel processing
AB In this paper, the Line-Scan Clustering (LSC) algorithm, a novel one-pass algorithm for labeling arbitrarily connected components is presented. In currently available connected components labeling approaches, only 4 or 8 connected components can be labeled. We overcome this limitation by introducing the new notion n-ED-neighbors. In designing the algorithm, we fully considered the particular properties of a connected component in an image and employed two data structures, the LSC algorithm turns to be highly efficient. On top of this, it has three more favorable features. First, as its capability to be processed block by block means that it is suitable for parallel processing, improving the speed when multiple processors are used. Second, its applicability is extended from working on binary images only to directly work on gray images, implying an efficiency gain in time spent on image binarization. Moreover, the LSC algorithm provides a more convenient way to employ the labeling result for conducting processing in later stages. Finally we compare LSC with an efficient connected labeling algorithm that is recently published, demonstrating how the LSC algorithm is faster. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Hong Kong Polytech Univ, Ctr Multimedia Signal Proc, Dept Comp, Kowloon, Hong Kong, Peoples R China.
   Singapore Operat Private Ltd, Agilent Technol, Singapore 768923, Singapore.
C3 Hong Kong Polytechnic University; Agilent Technologies
RP Hong Kong Polytech Univ, Ctr Multimedia Signal Proc, Dept Comp, Kowloon, Hong Kong, Peoples R China.
EM csdzhang@comp.polyu.edu.hk
RI Zhang, Hao/HHM-1940-2022; Zhang, David D/O-9396-2016
OI Zhang, David D/0000-0002-5027-5286
CR Di Stefano L., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P322, DOI 10.1109/ICIAP.1999.797615
   DILLENCOURT MB, 1992, J ACM, V39, P253, DOI 10.1145/128749.128750
   Gonzales R., 1992, DIGITAL IMAGE PROCES, P42
   Haralick R., 1992, COMPUTER ROBOT VISIO, V1, P33
   Jain R, 1995, MACHINE VISION, P44
   KLETTE R, 1996, HDB IMAGR PROCESSING, P314
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   ROSENFEL.A, 1966, J ACM, V13, P471
   Rosenfeld A., 1982, DIGITAL PICTURE PROC, V2, P241
   Samet H., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P312
   TARJAN RE, 1984, J ACM, V31, P245, DOI 10.1145/62.2160
   TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884
   YANG XD, 1992, CVIP
   YANG Y, 2000, VISION INTERFACE, P187
   ZUNIGA RLO, 1983, COMPUTERS VISION GRA, V22, P287
NR 15
TC 12
Z9 18
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2003
VL 21
IS 5
BP 459
EP 472
DI 10.1016/S0262-8856(03)00015-5
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 676DA
UT WOS:000182735600005
DA 2024-07-18
ER

PT J
AU François, ARJ
   Medioni, GG
   Waupotitsch, R
AF François, ARJ
   Medioni, GG
   Waupotitsch, R
TI Mirror symmetry ⇒ 2-view stereo geometry
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE mirror symmetry; stereo; 3D modeling
ID RECONSTRUCTION; SHAPE
AB We address the problem of 3D reconstruction from a single perspective view of a mirror symmetric scene. We establish the fundamental result that it is geometrically equivalent to observing the scene with two cameras, the cameras being symmetrical with respect to the unknown 3D symmetry plane. All traditional tools of classical 2-view stereo can then be applied, and the concepts of fundamental/essential matrix, epipolar geometry, rectification and disparity hold. However, the problems are greatly simplified here, as the rectification process and the computation of epipolar geometry can be easily performed from the original view only. If the camera is calibrated, we show how to synthesize the symmetric image generated by the same physical camera. A Euclidean reconstruction of the scene can then be computed from the resulting stereo pair. To validate this novel formulation, we have processed many real images, and show examples of 3D reconstruction. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ So Calif, Sch Engn, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.
   Geometrix Inc, San Jose, CA 95126 USA.
C3 University of Southern California
EM afrancoi@iris.usc.edu; gerardm@geometrix.com; romanw@geometrix.com
CR *EOS SYST, PHOT PRO 4 0
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   François ARJ, 2001, IMAGE VISION COMPUT, V19, P317, DOI 10.1016/S0262-8856(00)00081-0
   GROSS AD, 1994, INT J COMPUT VISION, V13, P91, DOI 10.1007/BF01420797
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Huynh D. Q., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P476, DOI 10.1109/ICCV.1999.791259
   KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X
   MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352
   NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842
   Rothwell C. A., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P573, DOI 10.1109/ICCV.1993.378159
   Shimshoni I, 2000, INT J COMPUT VISION, V39, P97, DOI 10.1023/A:1008118909580
   TAN TN, 1996, P BRIT MACH VIS C SE
   ULUPINAR F, 1991, CVGIP-IMAG UNDERSTAN, V53, P88, DOI 10.1016/1049-9660(91)90007-C
   Zhang ZY, 1998, INT C PATT RECOG, P1174, DOI 10.1109/ICPR.1998.711905
NR 14
TC 35
Z9 43
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 10
PY 2003
VL 21
IS 2
BP 137
EP 143
AR PII S0262-8856(02)00149-X
DI 10.1016/S0262-8856(02)00149-X
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 655CP
UT WOS:000181534000001
DA 2024-07-18
ER

PT J
AU Valaeys, S
   Menegaz, G
   Ziliani, F
   Reichel, J
AF Valaeys, S
   Menegaz, G
   Ziliani, F
   Reichel, J
TI Modeling of 2D+1 texture movies for video coding
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE model-based coding; dynamic textures; dynamic coding
ID WAVELET TRANSFORMS; STATISTICS; MAP
AB We propose a novel model-based coding system for video. Model-based coding aims at improving compression gain by replacing the non-informative image elements with some perceptually equivalent models. Images enclosing large textured regions are ideal candidates. Texture movies are obtained by filming a static texture with a moving camera. The integration of the motion information within the generative texture process allows to replace the 'real' texture with a 'visually equivalent' synthetic one, while preserving the correct motion perception. Global motion estimation is used to determine the movement of the camera and to identify the overlapping region between two successive frames. Such an information is then exploited for the generation of the texture movies. The proposed method for synthesizing 2D + 1 texture movies is able to emulate any piece-wise linear trajectory. The compression performance is very encouraging. On this kind of video sequences, the proposed method improves the compression rate of an MPEG4 state-of-the-art video coder of an order of magnitude while providing a sensibly better perceptual quality. Importantly, the current implementation is real-time on Intel PIII processors. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Swiss Fed Inst Technol, Audio Visual Commun Lab, CH-1015 Lausanne, Switzerland.
   VisioWave SA, CH-1024 Ecublens, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Swiss Fed Inst Technol, Audio Visual Commun Lab, CH-1015 Lausanne, Switzerland.
EM gloria@ieee.org; ziliani@visiowave.com; julien.reichel@visiowave.com
RI Menegaz, Gloria/D-3365-2013
OI Menegaz, Gloria/0000-0002-6889-3461
CR AACH T, 1993, SIGNAL PROCESS, V31, P165, DOI 10.1016/0165-1684(93)90063-G
   [Anonymous], P SIGGRAPHS, DOI DOI 10.1145/218380.218446
   [Anonymous], S INT 3D GRAPH
   BARJOSEPH Z, 2001, P IEEE VIS, P403
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   DEBONET JS, 1997, COMPUTER GRAPHICS, P361
   DEBONET JS, 1997, ADV NEURAL INFORMATI, V10
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   EFROS AA, 1999, P INT C COMP VIS
   *ISO IEC JTC 1 SC, 1999, N3156 ISO IEC JTC 1S
   KUNT M, 1995, P IEEE, V73
   Landy M.S., 1996, Encyclopedia of Neuroscience
   Landy MS, 2001, J OPT SOC AM A, V18, P2307, DOI 10.1364/JOSAA.18.002307
   LI Z, 2001, J VISION, V1
   Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9
   Menegaz G, 2001, IEEE IMAGE PROC, P173, DOI 10.1109/ICIP.2001.958981
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   REICHEL J, 2001, THESIS SWISS FEDERAL
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   SOATTO S, 2001, P INT C COMP VIS
   SZUMMER M, 1996, P INT C IM PROC
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Wolfson SS, 1998, VISION RES, V38, P439, DOI 10.1016/S0042-6989(97)00153-3
   Xu Y., 2000, Technical Report MSR-TR-2000-32
   ZHU S, 1996, P IEEE C COMP VIS PA
NR 28
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 49
EP 59
AR PII S0262-8856(02)00132-4
DI 10.1016/S0262-8856(02)00132-4
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yao, HB
   Wang, LP
   Cai, CT
   Sun, YX
   Zhang, Z
   Luo, YK
AF Yao, Haibo
   Wang, Lipeng
   Cai, Chengtao
   Sun, Yuxin
   Zhang, Zhi
   Luo, Yongkang
TI Multi-modal spatial relational attention networks for visual question
   answering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual question answering; Spatial relation; Attention mechanism; Pre
   -training strategy
AB Visual Question Answering (VQA) is a task that requires VQA model to fully understand the visual information of the image and the language information of the question, and then combine both to provide an answer. Recently, a large amount of VQA approaches focus on modeling intra- and inter-modal interactions with respect to vision and language using a deep modular co-attention network, which can achieve a good performance. Despite their benefits, they also have their limitations. First, the question representation is obtained through Glove word embeddings and Recurrent Neural Network, which may not be sufficient to capture the intricate semantics of the question features. Second, they mostly use visual appearance features extracted by Faster R-CNN to interact with language features, and they ignore important spatial relations between objects in images, resulting in incomplete use of image information. To overcome the limitations of previous methods, we propose a novel Multi-modal Spatial Relation Attention Network (MSRAN) for VQA, which can introduce spatial relationships between objects to fully utilize the image information, thus improving the performance of VQA. In order to achieve the above, we design two types of spatial relational attention modules to comprehensively explore the attention schemes: (i) Self-Attention based on Explicit Spatial Relation (SA-ESR) module that explores geometric relationships between objects explicitly; and (ii) Self-Attention based on Implicit Spatial Relation (SA-ISR) module that can capture the hidden dynamic relationships between objects by using spatial relationship. Moreover, the pre-training model BERT, which replaces Glove word embeddings and Recurrent Neural Network, is applied to MSRAN in order to obtain the better question representation. Extensive experiments on two large benchmark datasets, VQA 2.0 and GQA, demonstrate that our proposed model achieves the state-of-the-art performance.
C1 [Yao, Haibo; Wang, Lipeng; Cai, Chengtao; Sun, Yuxin; Zhang, Zhi] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
   [Luo, Yongkang] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Harbin Engineering University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Wang, LP (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
EM yhb1667662807@hrbeu.edu.cn; wanglipeng@hrbeu.edu.cn;
   caichengtao@hrbeu.edu.cn; heu_syx@hrbeu.edu.cn;
   zhangzhi1981@hrbeu.edu.cn; yongkang.luo@ia.ac.cn
RI ren, jing/JXN-8411-2024; Sun, Yuxin/ISA-5582-2023; Wang,
   Lipeng/ABG-2247-2021
OI Sun, Yuxin/0000-0002-6391-9714; Wang, Lipeng/0000-0002-7987-5947
FU National Natural Science Foundation of China [62173103, 62303129];
   Fundamental Research Funds for the Central Universities of China
   [3072022JC0402, 3072022JC0403]; Natural Science Foundation of
   Heilongjiang Province of China [LH2023F022]; National Key Research and
   Development Program of China [2019YFE0105400]; Project of Intelligent
   Situation Awareness System for Smart Ship [MC-201920-X01]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62173103 and 62303129, in part by the
   Fundamental Research Funds for the Central Universities of China under
   Grant 3072022JC0402 and 3072022JC0403, in part by the Natural Science
   Foundation of Heilongjiang Province of China under Grant LH2023F022, in
   part by the National Key Research and Development Program of China under
   Grant 2019YFE0105400, and in part by the Project of Intelligent
   Situation Awareness System for Smart Ship under Grant MC-201920-X01.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2011, P 14 INT C ART INT S
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bao H., 2022, ADV NEURAL INFORM PR
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Cao JJ, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3135655
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Clark K, 2020, INFORM SYST RES, DOI 10.48550/arXiv.2003.10555
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Farazi MR, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.103985
   Feng JF, 2022, DISPLAYS, V75, DOI 10.1016/j.displa.2022.102329
   Gao P, 2019, IEEE I CONF COMP VIS, P5824, DOI 10.1109/ICCV.2019.00592
   Gao P, 2019, PROC CVPR IEEE, P6632, DOI 10.1109/CVPR.2019.00680
   Goyal P, 2018, Arxiv, DOI arXiv:1706.02677
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Guo WY, 2020, AAAI CONF ARTIF INTE, V34, P91
   Guo ZH, 2023, APPL INTELL, V53, P586, DOI 10.1007/s10489-022-03559-4
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu RH, 2019, IEEE I CONF COMP VIS, P10293, DOI 10.1109/ICCV.2019.01039
   Hudson D.A., 2018, INT C LEARN REPR ICL
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Iandola F.N., 2020, arXiv
   Jiang TL, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104316
   Jing CC, 2022, PROC CVPR IEEE, P5089, DOI 10.1109/CVPR52688.2022.00504
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kim JH, 2018, ADV NEUR IN, V31
   Kingma D. P., 2015, INT C LEARNING REPRE
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kuo CW, 2022, PROC CVPR IEEE, P17948, DOI 10.1109/CVPR52688.2022.01744
   Lample G., 2019, NEURIPS
   Lan Z., 2019, ARXIV190911942, DOI DOI 10.48550/ARXIV.1909.11942
   Lee J, 2023, IEEE WINT CONF APPL, P1114, DOI 10.1109/WACV56688.2023.00117
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu AA, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104281
   Liu C, 2023, MULTIMEDIA SYST, V29, P2527, DOI 10.1007/s00530-023-01125-7
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu JS, 2019, ADV NEUR IN, V32
   Lu JS, 2016, ADV NEUR IN, V29
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Manmadhan S, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104291
   Narayanan A, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104328
   Peng L, 2022, IEEE T KNOWL DATA EN, V34, P1644, DOI 10.1109/TKDE.2020.2998805
   Peng L, 2022, IEEE T PATTERN ANAL, V44, P318, DOI 10.1109/TPAMI.2020.3004830
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Riquelme F, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103968
   Sharma H, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104165
   Shi JX, 2019, PROC CVPR IEEE, P8368, DOI 10.1109/CVPR.2019.00857
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song K., 2020, ADV NEURAL INFORM PR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1793, DOI 10.1109/ICCV48922.2021.00183
   Wu CF, 2018, ADV NEUR IN, V31
   Wu J., 2019, Advances in neural information processing systems
   Xu YSY, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0287557
   Yan F, 2024, MULTIMED TOOLS APPL, V83, P7085, DOI 10.1007/s11042-023-15418-6
   Yang L, 2022, PROC CVPR IEEE, P9489, DOI 10.1109/CVPR52688.2022.00928
   Yang ZY, 2019, IEEE I CONF COMP VIS, P4682, DOI 10.1109/ICCV.2019.00478
   Yang ZQ, 2020, IEEE IMAGE PROC, P1411, DOI 10.1109/ICIP40778.2020.9190771
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhan YB, 2020, INT J COMPUT VISION, V128, P2146, DOI 10.1007/s11263-020-01353-8
   Zhang K, 2022, PROC CVPR IEEE, P15640, DOI 10.1109/CVPR52688.2022.01521
   Zhang Yang, 2019, INT C LEARN REPR
   Zhou YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2054, DOI 10.1109/ICCV48922.2021.00208
NR 75
TC 1
Z9 1
U1 14
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104840
DI 10.1016/j.imavis.2023.104840
EA OCT 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Y0KY4
UT WOS:001102256600001
DA 2024-07-18
ER

PT J
AU Luo, JM
   Tang, YZ
   Wang, J
   Lu, HT
AF Luo, Jiaming
   Tang, Yongzhe
   Wang, Jie
   Lu, Hongtao
TI USMLP: U-shaped Sparse-MLP network for mass segmentation in mammograms
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Breast mass segmentation; Multi-layer perceptron; U -Net
ID COMPUTER-AIDED DIAGNOSIS
AB Convolutional neural networks (CNN) are widely used in computer-aided diagnosis (CAD). However, there are several limitations of this structure for mass segmentation in mammograms, which may lead to incorrect segmentation results. Recently, multi-layer perceptron (MLP) based methods introduce a new way to solve computer vision (CV) problems. In this paper we propose U-shaped Sparse-MLP (USMLP), which is a MLP-based segmentation model with U-shaped architecture. Our proposed method consists of CNN layers and sparse MLP (sMLP) blocks. Detailed experiments on two public datasets show that our method achieves state-of-the-art performance while remaining efficiency, compared with other benchmarks. We hope the investigation of new network architecture can be beneficial to mass segmentation tasks as well as CAD systems.
C1 [Luo, Jiaming; Lu, Hongtao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Tang, Yongzhe; Wang, Jie] Shanghai Jiao Tong Univ, Int Peace Maternal & Child Hlth Hosp, Sch Med, Shanghai 200030, Peoples R China.
   [Wang, Jie] Shanghai Key Lab Embryo Original Dis, Shanghai 200030, Peoples R China.
   [Luo, Jiaming; Lu, Hongtao] Shanghai Jiao Tong Univ, AI Inst, MOE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai
   Jiao Tong University
RP Lu, HT (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.; Wang, J (corresponding author), Shanghai Jiao Tong Univ, Int Peace Maternal & Child Hlth Hosp, Sch Med, Shanghai 200030, Peoples R China.; Wang, J (corresponding author), Shanghai Key Lab Embryo Original Dis, Shanghai 200030, Peoples R China.; Lu, HT (corresponding author), Shanghai Jiao Tong Univ, AI Inst, MOE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.
EM leojm2017@sjtu.edu.cn; yiishui@163.com; jiewang76@hotmail.com;
   htlu@sjtu.edu.cn
FU SJTU [YG2019QNA09]
FX The study is supported by SJTU funding (YG2019QNA09) .
CR Cao H., 2021, arXiv
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Heath M, 1998, COMP IMAG VIS, V13, P457
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Imran S, 2021, IEEE ACCESS, V9, P99327, DOI 10.1109/ACCESS.2021.3094768
   Kingma D. P., 2014, arXiv
   Singh VK, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112855
   Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177
   Li HY, 2018, Arxiv, DOI arXiv:1808.08885
   Li HY, 2022, IEEE T MED IMAGING, V41, P3, DOI 10.1109/TMI.2021.3102622
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lou M, 2022, MULTIMED TOOLS APPL, V81, P13335, DOI 10.1007/s11042-021-10940-x
   Melas-Kyriazi L, 2021, Arxiv, DOI arXiv:2105.02723
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Paszke A, 2019, ADV NEUR IN, V32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sharma S, 2015, J DIGIT IMAGING, V28, P77, DOI 10.1007/s10278-014-9719-7
   Sun H, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab5745
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tang CX, 2022, AAAI CONF ARTIF INTE, P2344
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Touvron H, 2023, IEEE T PATTERN ANAL, V45, P5314, DOI 10.1109/TPAMI.2022.3206148
   Trockman A, 2022, Arxiv, DOI [arXiv:2201.09792, DOI 10.48550/ARXIV.2201.09792,09792]
   Valanarasu JMJ, 2022, LECT NOTES COMPUT SC, V13435, P23, DOI 10.1007/978-3-031-16443-9_3
   Valanarasu JMJ, 2021, LECT NOTES COMPUT SC, V12901, P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Wang RS, 2022, IET IMAGE PROCESS, V16, P1243, DOI 10.1049/ipr2.12419
   Wang RZ, 2019, NEUROCOMPUTING, V363, P313, DOI 10.1016/j.neucom.2019.06.045
   Wang XW, 2012, J DIGIT IMAGING, V25, P570, DOI 10.1007/s10278-012-9451-0
   Xie B, 2022, Arxiv, DOI arXiv:2207.08265
   Xu CB, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103178
   Yu Q., 2021, arXiv
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 34
TC 2
Z9 2
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104761
DI 10.1016/j.imavis.2023.104761
EA JUL 2023
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P2UI8
UT WOS:001049237600001
DA 2024-07-18
ER

PT J
AU Ghimire, D
   Lee, K
   Kim, SH
AF Ghimire, Deepak
   Lee, Kilho
   Kim, Seong-heum
TI Loss-aware automatic selection of structured pruning criteria for deep
   neural network acceleration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep neural networks; Structured pruning; Pruning criteria
AB Structured pruning is a well-established technique for compressing neural networks, making them suitable for deployment in resource-limited edge devices. This study presents an efficient loss-aware automatic selection of structured pruning (LAASP) criteria for slimming and accelerating deep neural networks. The majority of pruning methods employ a sequential process consisting of three stages, 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed pruning technique adopts a pruning-while-training approach that eliminates the first stage and integrates the second and third stages into a single cycle. The automatic selection of magnitude or similarity-based filter pruning criteria from a specified pool of criteria and the specific pruning layer at each pruning iteration is guided by the network's overall loss on a small subset of training data. To mitigate the abrupt accuracy drop due to pruning, the network is retrained briefly after each reduction of a predefined number of floating-point operations (FLOPs). The optimal pruning rates for each layer in the network are automatically determined, eliminating the need for manual allocation of fixed or variable pruning rates for each layer. Experiments on the VGGNet, ResNet, and MobileNet models on the CIFAR-10 and ImageNet benchmark datasets demonstrate the effectiveness of the proposed method. In particular, the ResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the top-1 accuracy compared to state-of-the-art methods while reducing the network FLOPs by 52%. Furthermore, pruning the ResNet50 model on the ImageNet dataset reduces FLOPs by more than 42% with a negligible 0.33% drop in the top-5 accuracy. The source code of this study is publicly available on GitHub: https://github.com/ghimiredhikura/laasp.
C1 [Ghimire, Deepak; Lee, Kilho; Kim, Seong-heum] Soongsil Univ, Coll Informat Technol, Sch AI Convergence, Seoul, South Korea.
C3 Soongsil University
RP Kim, SH (corresponding author), Soongsil Univ, Coll Informat Technol, Sch AI Convergence, Seoul, South Korea.
EM seongheum@ssu.ac.kr
RI Ghimire, Deepak/W-2826-2019
OI Ghimire, Deepak/0000-0001-8940-8739
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
FX This work was supported by a National Research Foundation of Korea (NRF)
   grant funded by the Korean government(MSIT) (No. NRF- 2021R1A4A1032252).
CR Bailin Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P639, DOI 10.1007/978-3-030-58536-5_38
   Banner R, 2019, ADV NEUR IN, V32
   Cha S, 2023, Arxiv, DOI arXiv:2204.03916
   Chen T., 2021, ARXIV
   Chen TY, 2023, Arxiv, DOI arXiv:2303.06862
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Ding Xiaohan, 2019, ADV NEUR IN, V32
   Fang GF, 2023, Arxiv, DOI arXiv:2301.12900
   Frankle J., 2018, arXiv
   Frankle J., 2021, INT C LEARNING REPRE
   Frankle Jonathan, 2020, INT C MACHINE LEARNI, P3259
   Gao SQ, 2021, PROC CVPR IEEE, P9266, DOI 10.1109/CVPR46437.2021.00915
   Ghimire D, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13010316
   Ghimire D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060945
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Han S, 2015, ADV NEUR IN, V28
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   He Y, 2020, PROC CVPR IEEE, P2006, DOI 10.1109/CVPR42600.2020.00208
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   He Yang, 2022, IEEE Transactions on Neural Networks and Learning Systems
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Heo S, 2020, IEEE REAL TIME, P174, DOI 10.1109/RTAS48715.2020.000-8
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Ji M, 2021, PROC CVPR IEEE, P10659, DOI 10.1109/CVPR46437.2021.01052
   Ji Y, 2018, ADV NEUR IN, V31
   Jiang Y., 2022, PROC INT JOINT C ART, P3107
   Jung S, 2019, PROC CVPR IEEE, P4345, DOI 10.1109/CVPR.2019.00448
   Kim T, 2022, IEEE ACCESS, V10, P22547, DOI 10.1109/ACCESS.2022.3153025
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lee NM, 2019, Arxiv, DOI arXiv:1810.02340
   Lee S, 2020, IEEE REAL TIME, P15, DOI 10.1109/RTAS48715.2020.00-20
   Li D, 2019, IEEE I CONF COMP VIS, P3315, DOI 10.1109/ICCV.2019.00341
   Li GL, 2022, J SYST ARCHITECT, V124, DOI 10.1016/j.sysarc.2022.102431
   Li GL, 2020, IEEE T COMPUT AID D, V39, P3614, DOI 10.1109/TCAD.2020.3013050
   Li H, 2017, Arxiv, DOI arXiv:1608.08710
   Lin M, 2022, IEEE Trans. Neural Netw. Learn. Syst.
   Lin MB, 2023, IEEE T PATTERN ANAL, V45, P3999, DOI 10.1109/TPAMI.2022.3195774
   Lin MB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P673
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Liu LY, 2021, PR MACH LEARN RES, V139
   Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339, 10.1109/ICCV.2019.00339D\]
   Liu Z, 2019, Arxiv, DOI arXiv:1810.05270
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Lym S, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356156
   Mondal M, 2022, COMPUT VIS IMAGE UND, V222, DOI 10.1016/j.cviu.2022.103511
   Nigade V, 2022, REAL TIM SYST SYMP P, P277, DOI 10.1109/RTSS55097.2022.00032
   Oyedotun OK, 2020, IEEE WINT CONF APPL, P2266, DOI [10.1109/WACV45572.2020.9093377, 10.1109/wacv45572.2020.9093377]
   Paszke A., 2017, NIPS W
   Polino A, 2018, Arxiv, DOI arXiv:1802.05668
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen M., 2022, P IEEECVF C COMPUTER, P12247
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P, 2020, IEEE WINT CONF APPL, P824, DOI [10.13140/rg.2.2.28674.94402, 10.1109/WACV45572.2020.9093331]
   Singh P, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103857
   Yang HR, 2020, IEEE COMPUT SOC CONF, P2899, DOI 10.1109/CVPRW50498.2020.00347
   Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18
   Ye HC, 2023, IEEE T PATTERN ANAL, V45, P10267, DOI 10.1109/TPAMI.2023.3260903
   Yin M, 2021, PROC CVPR IEEE, P10669, DOI 10.1109/CVPR46437.2021.01053
   Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zhang Y., 2022, Advances in Neural Information Processing Systems
   Zhang Yuxin, 2022, IEEE T NEUR NET LEAR
   Zhou Aojun, 2021, INT C LEARNING REPRE
   Zuo YD, 2020, IEEE ACCESS, V8, P90924, DOI 10.1109/ACCESS.2020.2993932
NR 68
TC 1
Z9 1
U1 8
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104745
DI 10.1016/j.imavis.2023.104745
EA JUL 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA O0NC8
UT WOS:001040865000001
DA 2024-07-18
ER

PT J
AU Bukhari, M
   Yasmin, S
   Naz, S
   Maqsood, M
   Rew, J
   Rho, S
AF Bukhari, Maryam
   Yasmin, Sadaf
   Naz, Sheneela
   Maqsood, Muazzam
   Rew, Jehyeok
   Rho, Seungmin
TI Language and vision based person re-identification for surveillance
   systems using deep learning with LIP layers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Surveillance; Language and vision based Re
   -ID; Deep learning
ID RECOGNITION; BIOMETRICS; ATTENTION; TRACKING; NETWORK
AB Real-time surveillance systems have become a necessity of today's life owing to their relevance in the contempo-rary era for security reasons to ensure a secure and safe environment. Presently, Person re-identification (Re-ID)-based surveillance systems are becoming increasingly more prevalent and sophisticated since they do not require human intervention and are more reliable to deploy in public spaces leveraging multi-camera networks. How-ever, one of the major problems in Person ReID is the visual appearance i-e the appearance of a person in an image is greatly affected by different camera views. As a result, the discriminative set of features must be learned in a deep learning model in order to re-identify persons from opposing camera viewpoints. To address this chal-lenge, we propose an image/text-retrieval-based Person ReId method in which both visual and text-based fea-tures are exploited to carry out person re-identification. More precisely, the textual descriptions of the images are taken into account as text features with Glove Word Embedding followed by 1D-MAPCNN and fused with image-level features extracted using the GoogLeNet model. In addition, the feature discriminability is enhanced using local importance-based pooling (LIP) layers in which adaptive significance weights are learned during downsampling. Moreover, from two different modalities, feature refinement is done during training with the help of attention mechanisms using the Convolutional Block Attention module (CBAM) and the proposed shared attention neural network. It is observed that LIP layers along with both vision and textual features are playing a key role in acquiring discriminative features even if the visual appearance of the same person is greatly affected due to camera pose conditions. The proposed method is validated on the CUHK-PADES dataset and has 15.34% and 24.39% rank-1 improvement in text and image-based retrievals. (c) 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Bukhari, Maryam; Yasmin, Sadaf; Maqsood, Muazzam] COMSATS Univ Islamabad, Dept Comp Sci, Attock Campus, Attock 43600, Pakistan.
   [Naz, Sheneela] COMSATS Univ Islamabad, Dept Comp Sci, Islamabad 45550, Pakistan.
   [Rew, Jehyeok] Duksung Womens Univ, Coll Sci & Technol, Digital Software Engn, Seoul 01369, South Korea.
   [Rho, Seungmin] Chung Ang Univ, Dept Ind Secur, Seoul 06974, South Korea.
C3 COMSATS University Islamabad (CUI); COMSATS University Islamabad (CUI);
   Duksung Women's University; Chung Ang University
RP Rho, S (corresponding author), Chung Ang Univ, Dept Ind Secur, Seoul 06974, South Korea.
EM smrho@cau.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2022R1F1A1063134]; MSIT (Ministry of Science and ICT) , Korea, under
   the ITRC (Information Technology Research Center)
   [IITP-2022-2018-0-01799]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No. 2022R1F1A1063134)
   and also the MSIT (Ministry of Science and ICT) , Korea, under the ITRC
   (Information Technology Research Center) support program
   (IITP-2022-2018-0-01799) supervised by the IITP (Institute for
   Information and communications Technology Planning and Evaluation) .
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Ahmed I, 2021, J REAL-TIME IMAGE PR, V18, P1803, DOI 10.1007/s11554-021-01144-5
   Almasawa MO, 2019, IEEE ACCESS, V7, P175228, DOI 10.1109/ACCESS.2019.2957336
   [Anonymous], 2013, 2013 7 INT C DISTR S
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Balas V.E., 2019, Handbook of deep learning applications, V136
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Boles A, 2017, 2017 12TH SYSTEM OF SYSTEMS ENGINEERING CONFERENCE (SOSE)
   Bouchrika I., 2017, DEV NEXT GENERATION, P140
   Bukhari M, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/2801227
   Bukhari M, 2021, IEEE ACCESS, V9, P6465, DOI 10.1109/ACCESS.2020.3047266
   Chen M, 2018, IEEE ACCESS, V6, P68089, DOI 10.1109/ACCESS.2018.2879490
   Chen TL, 2018, IEEE WINT CONF APPL, P1879, DOI 10.1109/WACV.2018.00208
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Feng GH, 2019, NEURAL PROCESS LETT, V50, P2087, DOI 10.1007/s11063-019-10000-4
   Gao ZT, 2023, INT J COMPUT VISION, V131, P363, DOI [10.1109/ICCV.2019.00345, 10.1007/s11263-022-01707-4]
   Genç A, 2019, MULTIMED TOOLS APPL, V78, P5843, DOI 10.1007/s11042-018-6409-3
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Iguernaissi R, 2019, MULTIMED TOOLS APPL, V78, P10773, DOI 10.1007/s11042-018-6638-5
   Imani Z, 2019, NATL ACAD SCI LETT, V42, P233, DOI 10.1007/s40009-018-0736-9
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jabeen F, 2019, PEER PEER NETW APPL, V12, P1263, DOI 10.1007/s12083-019-00733-3
   Jelodar H, 2020, IEEE J BIOMED HEALTH, V24, P2733, DOI 10.1109/JBHI.2020.3001216
   Jungling Kai., 2011, COMPUTER VISION PATT, P55, DOI 10.1109/CVPRW.2011.5981771
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Kuzu RS, 2020, IEEE T INF FOREN SEC, V15, P2641, DOI 10.1109/TIFS.2020.2971144
   Larochelle Hugo, 2010, ADV NEURAL INFORM PR, V23
   Lavi B, 2018, Arxiv, DOI arXiv:1807.05284
   Layne R, 2012, LECT NOTES COMPUT SC, V7583, P402, DOI 10.1007/978-3-642-33863-2_40
   Li S., P IEEE C COMP VIS PA, P1970
   Li S., P IEEE INT C COMP VI, P1890
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Ling HF, 2019, NEUROCOMPUTING, V347, P109, DOI 10.1016/j.neucom.2019.01.027
   Liu Y, 2017, IEEE I CONF COMP VIS, P4127, DOI 10.1109/ICCV.2017.442
   Lyon D, 2008, BIOETHICS, V22, P499, DOI 10.1111/j.1467-8519.2008.00697.x
   Ma TH, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104168
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Nawaz H, 2021, MULTIMED TOOLS APPL, V80, P35789, DOI 10.1007/s11042-020-09087-y
   Peng YQ, 2022, MULTIMED TOOLS APPL, V81, P11221, DOI 10.1007/s11042-022-12124-7
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pham V.-H., 2019, INT J MACH LEARN COM, V9, P465
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Saghafi MA, 2014, IET COMPUT VIS, V8, P455, DOI 10.1049/iet-cvi.2013.0180
   Schumann A, 2017, IEEE COMPUT SOC CONF, P1435, DOI 10.1109/CVPRW.2017.186
   Shengcai Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P456, DOI 10.1007/978-3-030-58621-8_27
   Specker A., 2020, PROC SPIE, P98
   Tobji R, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102042
   Tome P, 2014, IEEE T INF FOREN SEC, V9, P464, DOI 10.1109/TIFS.2014.2299975
   Wang GZ, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P192, DOI 10.1145/3007669.3007741
   Wang K, 2020, INT J INTELL SYST, V35, P1881, DOI 10.1002/int.22276
   Wang KJ, 2018, CAAI T INTELL TECHNO, V3, P219, DOI 10.1049/trit.2018.1001
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang SQ, 2020, J REAL-TIME IMAGE PR, V17, P73, DOI 10.1007/s11554-019-00908-4
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang ZJ, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.4.043028
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Wu DM, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116257
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu Q, 2016, ACSR ADV COMPUT, V54, P826
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zhang Y., 2018, P EUR C COMP VIS ECC, P686
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
NR 68
TC 3
Z9 3
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2023
VL 132
AR 104658
DI 10.1016/j.imavis.2023.104658
EA MAR 2023
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA A6SL8
UT WOS:000956399700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Gu, SQ
   Lian, ZC
AF Gu, Siqi
   Lian, Zhichao
TI A unified RGB-T crowd counting learning framework
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Crowd counting; RGB-T; Multimodal fusion; End-to-end training
ID VISIBLE IMAGE FUSION; NETWORK; NEST
AB In this paper, a novel Unified RGB-T Crowd Counting Learning Framework (UCCF) is proposed, which utilizes an image fusion network architecture and a crowd counting network architecture to estimate the density map and count results simultaneously. Since there are few deep learning methods for the RGB-T crowd counting task, cur-rent research lacks unified learning frameworks to solve the image fusion and crowd counting problems synchro-nously. To fill this gap, our framework aims to fuse two modalities, visible and thermal infrared images, that exploit the complementary information to accurately count the dense population and construct the end-to -end training process. To this end, we first propose the unified RGB-T crowd counting learning framework to com-plete the image fusion and crowd counting tasks simultaneously by redesigning the unified training loss function. Also, to further narrow the gap between the two models and simplify the end-to-end training process, we design the Assisted Learning Module (ALM) by merging the density map feature into the image fusion encoding process. Meanwhile, we propose an Extensive Context Extraction Module (ECEM) and apply the Multi-domain Attention Block (MAB) to further improve the counting accuracy. The experimental results show that our method outper-forms all single-modal input methods (26.9% improvements over the best RGB-input approaches and 3% im-provements over the best thermal infrared input methods for MAE) and is at the forefront of multi-modal input methods, which demonstrates the robustness and effectiveness of our framework.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Gu, Siqi] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Lian, Zhichao] Nanjing Univ Sci & Technol, Sch Cyberspace Secur, Wuxi 214443, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology
RP Lian, ZC (corresponding author), Nanjing Univ Sci & Technol, Sch Cyberspace Secur, Wuxi 214443, Peoples R China.
EM sikygu@126.com; lzcts@163.com
RI Lian, Zhichao/E-7660-2012; Gu, Siqi/HTM-4004-2023
OI Gu, Siqi/0000-0001-5514-6734
CR Bai HY, 2022, Arxiv, DOI arXiv:2012.15685
   Cao JX, 2020, Arxiv, DOI [arXiv:2005.11475, DOI 10.48550/ARXIV.2005.11475]
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chenyu Gao, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11858), P582, DOI 10.1007/978-3-030-31723-2_50
   Gao JY, 2019, NEUROCOMPUTING, V363, P1, DOI 10.1016/j.neucom.2019.08.018
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Kang D, 2019, IEEE T CIRC SYST VID, V29, P1408, DOI 10.1109/TCSVT.2018.2837153
   Li H, 2021, INFORM FUSION, V73, P72, DOI 10.1016/j.inffus.2021.02.023
   Li H, 2020, IEEE T INSTRUM MEAS, V69, P9645, DOI 10.1109/TIM.2020.3005230
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liang D., 2022, ARXIV
   Liu LB, 2021, PROC CVPR IEEE, P4821, DOI 10.1109/CVPR46437.2021.00479
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Mnih V, 2014, ADV NEUR IN, V27
   Parmar N, 2018, Arxiv, DOI arXiv:1802.05751
   Paszke Adam, 2017, Pytorch
   Patil U., 2011, P 2011 INT C IM INF, P1, DOI DOI 10.1109/ICIIP.2011.6108966
   Peng T., 2020, P AS C COMP VIS ACCV, DOI DOI 10.1007/978-3-030-69544-6_30
   Rong LZ, 2021, IEEE WINT CONF APPL, P3674, DOI 10.1109/WACV48630.2021.00372
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Sheng BY, 2018, IEEE T CIRC SYST VID, V28, P1788, DOI 10.1109/TCSVT.2016.2637379
   Song Q., 2021, AAAI
   Tang H., 2022, ARXIV
   Wan J., 2020, P ADV NEUR INF PROC, P3386
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Yang S., 2022, P INT JOINT C ART IN, P1545
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang YJ, 2022, Arxiv, DOI arXiv:2210.10392
   Zhao ZX, 2021, Arxiv, DOI arXiv:2003.09210
   Zhou OETY, 2022, IEEE T PATTERN ANAL, V44, P3602, DOI 10.1109/TPAMI.2021.3056518
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zong JJ, 2017, BIOMED SIGNAL PROCES, V34, P195, DOI 10.1016/j.bspc.2017.02.005
   Zou ZK, 2018, IEEE ACCESS, V6, P60745, DOI 10.1109/ACCESS.2018.2875495
NR 43
TC 2
Z9 2
U1 7
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2023
VL 131
AR 104631
DI 10.1016/j.imavis.2023.104631
EA FEB 2023
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 9Q3AC
UT WOS:000944840200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Han, TT
   Wang, K
   Yu, J
   Fan, JP
AF Han, Tingting
   Wang, Kai
   Yu, Jun
   Fan, Jianping
TI Weakly supervised moment localization with natural language based on
   semantic reconstruction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross -modal moment localization; Weakly supervised temporal grounding;
   Semantic reconstruction
AB The goal of cross-modal moment localization is to find the temporal moment in the untrimmed video that semantically corresponds to the natural language query. The majority of current approaches learn the cross -modal moment localization models from fine-grained temporal annotations in the video, which are extremely time-consuming and labor-intensive to obtain. In this paper, we offer a novel framework for weakly supervised cross-modal moment localization that incorporates a proposal generation module and a semantic reconstruction module. The proposal generation module uses a two-dimensional temporal feature map to model cross-modal video representations and can encode the moment-by-moment temporal relationships of moment candidates. The semantic reconstruction module, which is based on the generated proposals, assesses a proposal's capacity to restore the text query and provides weak supervision for network training. Besides, a punishment loss is also proposed to further eliminate the effect of the invalid area. Extensive experimental results show that the proposed method achieves state-of-the-art performance, demonstrating its effectiveness for weakly supervised moment localization with natural language. (c) 2022 Published by Elsevier B.V.
C1 [Han, Tingting; Wang, Kai; Yu, Jun; Fan, Jianping] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Fan, Jianping] AI Lab Lenovo Res, Beijing, Peoples R China.
C3 Hangzhou Dianzi University
RP Fan, JP (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.; Fan, JP (corresponding author), AI Lab Lenovo Res, Beijing, Peoples R China.
EM ttinghan@hdu.edu.cn; kgwalker@hdu.edu.cn; yujun@hdu.edu.cn;
   fanjianping@hdu.edu.cn
RI HAN, TINGTING/GQZ-8692-2022; jun, yu/ABD-5776-2021
FU Zhejiang Province Natural Science Foundation [LQ21F020014]; National
   Natural Science Foundation of China [62002091]
FX This work is partly supported by the Zhejiang Province Natural Science
   Foundation under Project No. LQ21F020014 and the National Natural
   Science Foundation of China under Project No. 62002091.
CR Chen JY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P162
   Chen Z.C., arXiv
   Duan X, 2018, ARXIV
   Gao JY, 2017, IEEE I CONF COMP VIS, P5277, DOI 10.1109/ICCV.2017.563
   Gao M., 2019, arXiv
   He DL, 2019, AAAI CONF ARTIF INTE, P8393
   He XN, 2018, ACM/SIGIR PROCEEDINGS 2018, P355, DOI 10.1145/3209978.3209981
   Hendricks LA, 2017, IEEE I CONF COMP VIS, P5804, DOI 10.1109/ICCV.2017.618
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R., 2015, ADV NEURAL INFORM PR, P3294, DOI DOI 10.48550/ARXIV.1506.06726
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Lin ZJ, 2020, AAAI CONF ARTIF INTE, V34, P11539
   Liu M, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P843, DOI 10.1145/3240508.3240549
   Liu M, 2018, ACM/SIGIR PROCEEDINGS 2018, P15, DOI 10.1145/3209978.3210003
   Liu ZY, 2019, IEEE I CONF COMP VIS, P3898, DOI 10.1109/ICCV.2019.00400
   Minuk Ma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P156, DOI 10.1007/978-3-030-58604-1_10
   Mithun NC, 2019, PROC CVPR IEEE, P11584, DOI 10.1109/CVPR.2019.01186
   Peng B, 2022, IEEE J BIOMED HEALTH, V26, P27, DOI 10.1109/JBHI.2021.3082541
   Peng B, 2021, NEUROCOMPUTING, V456, P519, DOI 10.1016/j.neucom.2020.05.123
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706
   Song Y., arXiv
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P515, DOI 10.1145/3077136.3080786
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wang WN, 2019, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2019.00042
   Wang YX, 2023, IEEE T MULTIMEDIA, V25, P3921, DOI 10.1109/TMM.2022.3168424
   Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029
   Xu H., 2018, ARXIV PREPRINT ARXIV, V2, P7
   Xu HJ, 2019, AAAI CONF ARTIF INTE, P9062
   Yu C., 2022, IEEE T GEOSCI ELECT, V60, P1
   Yuan Y., 2019, arXiv
   Yuan YT, 2019, AAAI CONF ARTIF INTE, P9159
   Zhang D, 2019, PROC CVPR IEEE, P1247, DOI 10.1109/CVPR.2019.00134
   Zhang SY, 2020, AAAI CONF ARTIF INTE, V34, P12870
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
NR 38
TC 2
Z9 2
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104532
DI 10.1016/j.imavis.2022.104532
EA AUG 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3Y7GB
UT WOS:000843888700001
DA 2024-07-18
ER

PT J
AU Zhu, JW
   Li, ZX
   Wei, JH
   Zeng, YF
   Ma, HF
AF Zhu, Jianwei
   Li, Zhixin
   Wei, Jiahui
   Zeng, Yufei
   Ma, Huifang
TI Fine-grained bidirectional attentional generation and knowledge-assisted
   networks for cross-modal retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross-modal retrieval; Graph convolutional network; Knowledge embedding;
   Cross-attention; Attentional generative network
AB Generally, most existing cross-modal retrieval methods only consider global or local semantic embeddings, lacking fine-grained dependencies between objects. At the same time, it is usually ignored that the mutual transformation between modalities also facilitates the embedding of modalities. Given these problems, we propose a method called BiKA (Bidirectional Knowledge-assisted embedding and Attention-based generation). The model uses a bidirectional graph convolutional neural network to establish dependencies between objects. In addition, it employs a bidirectional attention-based generative network to achieve the mutual transformation between modalities. Specifically, the knowledge graph is used for local matching to constrain the local expression of the modalities, in which the generative network is used for mutual transformation to constrain the global expression of the modalities. In addition, we also propose a new position relation embedding network to embed position relation information between objects. The experiments on two public datasets show that the performance of our method has been dramatically improved compared to many state-of-the-art models.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhu, Jianwei; Li, Zhixin; Wei, Jiahui; Zeng, Yufei] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Ma, Huifang] Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Peoples R China.
C3 Guangxi Normal University; Northwest Normal University - China
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM zhujw@stu.gxnu.edu.cn; lizx@gxnu.edu.cn; weijh@stu.gxnu.edu.cn;
   zengyf@stu.gxnu.edu.cn; mahuifang@nwnu.edu.cn
RI Li, Zhixin/ABI-9264-2022; Ma, Huifang/JTV-4982-2023
OI Li, Zhixin/0000-0002-5313-6134; Ma, Huifang/0000-0002-5104-8982
FU National Natural Science Foundation of China [61966004, 61866004];
   Guangxi Natural Science Foundation [2019GXNSFDA245018]; Innovation
   Project of Guangxi Graduate Education [XYCBZ2021002]; Guangxi "Bagui
   Scholar" Teams for Innovation and Research Project, Guangxi Talent
   Highland Project of Big Data Intelligence and Application; Guangxi
   Collaborative Innovation Center of Multi-source Information Integration
   and Intelligent Processing
FX This work is supported by National Natural Science Foundation of China
   (Nos. 61966004, 61866004) , Guangxi Natural Science Foundation (No.
   2019GXNSFDA245018) , Innovation Project of Guangxi Graduate Education
   (No.XYCBZ2021002) , Guangxi "Bagui Scholar" Teams for Innovation and
   Research Project, Guangxi Talent Highland Project of Big Data
   Intelligence and Application, and Guangxi Collaborative Innovation
   Center of Multi-source Information Integration and Intelligent
   Processing.
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:160902907
   [Anonymous], ARXIV14112539
   Chen K., ARXIV210606509
   Chen SJ, 2020, IEEE DATA MINING, P52, DOI 10.1109/ICDM50108.2020.00014
   Chen SJ, 2020, IEEE SIGNAL PROC LET, V27, P1680, DOI 10.1109/LSP.2020.3025128
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Cheng H., ARXIV 150501809
   Dosovitskiy A., ARXIV PREPRINT ARXIV
   Faghri F., ARXIV170705612
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652
   Herdade S., ARXIV PREPRINT ARXIV
   Hou CW, 2022, APPL INTELL, V52, P7670, DOI 10.1007/s10489-021-02804-6
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Huang FC, 2020, MACH LEARN, V109, P2313, DOI 10.1007/s10994-020-05919-y
   Huang Y, 2017, PROC CVPR IEEE, P7254, DOI 10.1109/CVPR.2017.767
   Hui Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12652, DOI 10.1109/CVPR42600.2020.01267
   Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257, DOI 10.1109/89.568732
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Klein E, 2015, PROC CVPR IEEE, P4437, DOI 10.1109/CVPR.2015.7299073
   Lan Z., ARXIV PREPRINT ARXIV
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Li Z., ENG APPL ARTIF INTEL, V106
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P3, DOI 10.1145/3343031.3350869
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Vendrov I., ARXIV151106361
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang SJ, 2020, IEEE WINT CONF APPL, P1497, DOI 10.1109/WACV45572.2020.9093614
   Wang Y., ARXIV PREPRINT
   Wang ZH, 2019, IEEE I CONF COMP VIS, P5763, DOI 10.1109/ICCV.2019.00586
   Xu B., ARXIV150500853
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Young P., 2014, T ASSOC COMPUT LING, V2, P67, DOI [DOI 10.1162/TACL_A_00166, 10.1162/tacl_a_00166]
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhu JJ, 2021, PHOSPHORUS SULFUR, V196, P948, DOI 10.1080/10426507.2021.1946063
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 46
TC 3
Z9 4
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104507
DI 10.1016/j.imavis.2022.104507
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800006
DA 2024-07-18
ER

PT J
AU Dede, MA
   Genc, Y
AF Dede, Muhammet Ali
   Genc, Yakup
TI Object aspect classification and 6DoF pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Object pose estimation; Aspect graph; Deep learning
AB We present a novel approach to the problem of estimating a given object's 6DoF pose from a single RGB image. Recent works focus on a multi-stage approach, which first detects key-points followed by perspective -n-point pose estimation algorithm and a pose refinement procedure. We show that adding a classifier block estimating the predefined aspects of the objects improves the multi-stage process. This is due to the fact that the additional classifier acts as a constraint simplifying the required neural network and at the same time yielding better keypoint selection. We reduce the search space for the key-point selection and exclude false-positives by mapping the appearance of an object to an aspect. The simplified neural network allows faster inference and a smaller footprint. Our experiments show that our hypothesis performs similar to the state-of-the-art on three different datasets. We also show that an off-the-shelf refinement process can further improve our results to surpass state-of-the-art on several objects. Another advantage is, the proposed pipeline can run efficiently on real-time due to the smaller neural network backbone used. The code to replicate this research will be publicly available at https://github.com/greymad/6DoFPoseAspects
C1 [Dede, Muhammet Ali; Genc, Yakup] Gebze Tech Univ, Dept Comp Engn, Kocaeli, Turkey.
C3 Gebze Technical University
RP Dede, MA (corresponding author), Gebze Tech Univ, Dept Comp Engn, Kocaeli, Turkey.
EM madede@example.com
RI Genc, Yakup/AAG-4668-2019
OI Genc, Yakup/0000-0002-6952-6735
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Akgul O, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P47, DOI 10.1109/SITIS.2016.17
   [Anonymous], 2012, ACCV
   [Anonymous], 2018, CVPR, DOI DOI 10.1109/CVPR.2018.00474
   [Anonymous], 2016, 4 INT C LEARN REPR I
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Brynte L., 2020, ARXIV
   Choi J, 2019, IEEE I CONF COMP VIS, P502, DOI 10.1109/ICCV.2019.00059
   Doumanoglou A, 2016, PROC CVPR IEEE, P3583, DOI 10.1109/CVPR.2016.390
   Drost B, 2010, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2010.5540108
   Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146
   FAUGERAS O, 1992, CVGIP-IMAG UNDERSTAN, V55, P212, DOI 10.1016/1049-9660(92)90018-X
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gupta K, 2019, IEEE INT CONF COMP V, P2758, DOI 10.1109/ICCVW.2019.00337
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hess R., 2010, P ACM MULT MM
   Hinterstoisser E., 2014, LECT NOTES COMPUTER, V8690
   Hodan T, 2018, LECT NOTES COMPUT SC, V11214, P19, DOI 10.1007/978-3-030-01249-6_2
   Hodan T, 2017, IEEE WINT CONF APPL, P880, DOI 10.1109/WACV.2017.103
   Hodan T, 2015, IEEE INT C INT ROBOT, P4421, DOI 10.1109/IROS.2015.7354005
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Kehl W, 2016, LECT NOTES COMPUT SC, V9907, P205, DOI 10.1007/978-3-319-46487-9_13
   Kingma D. P., 2015, P INT C LEARN REPR, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Li Y, 2018, LECT NOTES COMPUT SC, V11210, P695, DOI [10.1007/s11263-019-01250-9, 10.1007/978-3-030-01231-1_42]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez M, 2010, IEEE INT CONF ROBOT, P2043, DOI 10.1109/ROBOT.2010.5509801
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Persson M., 2018, P EUROPEAN C COMPUTE, P318
   Plantinga W., 1986, ANN S FDN COMP SCI P
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Vidal J, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P405, DOI 10.1109/ICCAR.2018.8384709
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xiang Yu, 2017, ARXIV171100199
   Zakharov S, 2019, IEEE I CONF COMP VIS, P1941, DOI 10.1109/ICCV.2019.00203
   Zhu ML, 2014, IEEE INT CONF ROBOT, P3936, DOI 10.1109/ICRA.2014.6907430
NR 40
TC 4
Z9 4
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104495
DI 10.1016/j.imavis.2022.104495
EA JUN 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800003
DA 2024-07-18
ER

PT J
AU Mohamed, AA
   Alqahtani, F
   Shalaby, A
   Tolba, A
AF Mohamed, Abdallah A.
   Alqahtani, Fayez
   Shalaby, Ahmed
   Tolba, Amr
TI Texture classification-based feature processing for violence-based
   anomaly detection in crowded environments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Anomaly detection; Deep learning; Feature processing; Textural analysis;
   Video surveillance
AB Anomaly detection from video surveillance inputs helps to improve security in crowded places and outdoors. The captured image is analyzed to identify human faces, objects, and abnormal events through computer-aided analytics. This article proposes a Texture-Classification-based Feature Processing (TCFP) technique for distinguishing anomalies in captured video inputs. The anomalies are identified as events from the sequence frames wherein the dynamic inputs are distinguished using their features. Deep learning is employed for temporal training features based on frame characteristics in this distinguishing process. The input frame is segregated using textural boundaries separated using non-dimensional features. The learning process trains dimensional and non-dimensional features for identifying anomalies and maximizing detection accuracy. The textural boundaries are defined using the non-dimensional vectors present in the frame series in the different face classifications. Therefore, the errors are confined within selective boundaries without impacting the preceding feature. This improves the F1score with less processing time.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Mohamed, Abdallah A.] Menoufia Univ, Fac Sci, Math & Comp Sci Dept, Shibin Al Kawm 32511, Egypt.
   [Alqahtani, Fayez] King Saud Univ, Coll Comp & Informat Sci, Software Engn Dept, Riyadh 12372, Saudi Arabia.
   [Shalaby, Ahmed] Univ Louisville, Speed Sch Engn, Bioengn Dept, Louisville, KY 40292 USA.
   [Tolba, Amr] King Saud Univ, Community Coll, Comp Sci Dept, Riyadh 11437, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; King Saud University;
   University of Louisville; King Saud University
RP Mohamed, AA (corresponding author), Menoufia Univ, Fac Sci, Math & Comp Sci Dept, Shibin Al Kawm 32511, Egypt.
EM abdmoham@science.menofia.edu.eg; fhalqahtani@ksu.edu.sa;
   ahmed.shalaby@louisville.edu; atolba@ksu.edu.sa
RI Tolba, Amr/O-8464-2016; Mohamed, Abdallah A./IVS-2806-2023
OI Tolba, Amr/0000-0003-3439-6413; 
FU King Saud University, Riyadh, Saudi Arabia [RSP2022R509]
FX Acknowledgement This work was funded by the Researchers Supporting
   Project No. (RSP2022R509) King Saud University, Riyadh, Saudi Arabia
CR Bilecen A.E., 2021, SIVIP, P1
   Bouhlel F, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114656
   Chriki A, 2021, MULTIMED TOOLS APPL, V80, P2599, DOI 10.1007/s11042-020-09774-w
   de Carvalho GHF, 2019, MULTIDIM SYST SIGN P, V30, P311, DOI 10.1007/s11045-018-0558-4
   Deepak K, 2020, ICT EXPRESS, V6, P155, DOI 10.1016/j.icte.2020.04.014
   Redondo RPD, 2020, FUTURE GENER COMP SY, V109, P83, DOI 10.1016/j.future.2020.03.038
   Ganokratanaa T, 2022, PATTERN RECOGN LETT, V155, P143, DOI 10.1016/j.patrec.2021.11.001
   Hao Y, 2019, INT J AUTOM COMPUT, V16, P27, DOI 10.1007/s11633-018-1141-z
   Ilyas Z., MULTIMED TOOLS APPL, P1
   Jia DY, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01167-9
   Khan MUK, 2019, IEEE T INF FOREN SEC, V14, P541, DOI 10.1109/TIFS.2018.2856189
   Kong XJ, 2018, WORLD WIDE WEB, V21, P825, DOI 10.1007/s11280-017-0487-4
   Li A, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107355
   Li H, 2020, COMPUT VIS IMAGE UND, V201, DOI 10.1016/j.cviu.2020.103065
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Li T, 2021, NEUROCOMPUTING, V439, P256, DOI 10.1016/j.neucom.2021.01.097
   Lu BY, 2022, ADV ENG INFORM, V51, DOI 10.1016/j.aei.2021.101471
   Torres DM, 2019, IMAGE VISION COMPUT, V89, P197, DOI 10.1016/j.imavis.2019.07.006
   Mehmood A, 2021, IEEE ACCESS, V9, P138283, DOI 10.1109/ACCESS.2021.3118009
   Rahim A, 2018, PERVASIVE MOB COMPUT, V51, P43, DOI 10.1016/j.pmcj.2018.09.006
   Sharma V, 2021, IEEE ACCESS, V9, P139489, DOI 10.1109/ACCESS.2021.3118541
   Singh K, 2020, NEUROCOMPUTING, V371, P188, DOI 10.1016/j.neucom.2019.08.059
   Song W, 2019, IEEE ACCESS, V7, P39172, DOI 10.1109/ACCESS.2019.2906275
   Wang J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092451
   Wang J, 2022, J AMB INTEL HUM COMP, V13, P1293, DOI 10.1007/s12652-020-02574-y
   Wang T, 2019, IEEE T INF FOREN SEC, V14, P1390, DOI 10.1109/TIFS.2018.2878538
   Yu SY, 2020, FRONT INFORM TECH EL, V21, P1626, DOI 10.1631/FITEE.1900481
   Zhang Q, 2022, MULTIMED TOOLS APPL, P1
   Zhang XG, 2019, PHYSICA A, V525, P935, DOI 10.1016/j.physa.2019.04.033
   US
NR 30
TC 9
Z9 9
U1 2
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104488
DI 10.1016/j.imavis.2022.104488
EA MAY 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800005
DA 2024-07-18
ER

PT J
AU Valem, LP
   Pedronette, DCG
AF Valem, Lucas Pascotti
   Pedronette, Daniel Carlos Guimaraes
TI Person Re-ID through unsupervised hypergraph rank selection and fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person Re-ID; Unsupervised; Hypergraph; Rank; Selection; Fusion
ID IMAGE RETRIEVAL; REIDENTIFICATION; SIMILARITY; NETWORK
AB Person Re-ID has been gaining a lot of attention and nowadays is of fundamental importance in many camera sur-veillance applications. The task consists of identifying individuals across multiple cameras that have no overlap-ping views. Most of the approaches require labeled data, which is not always available, given the huge amount of demanded data and the difficulty of manually assigning a class for each individual. Recently, studies have shown that re-ranking methods are capable of achieving significant gains, especially in the absence of labeled data. Be-sides that, the fusion of feature extractors and multiple-source training is another promising research direction not extensively exploited. We aim to fill this gap through a manifold rank aggregation approach capable of exploiting the complementarity of different person Re-ID rankers. In this work, we perform a completely unsu-pervised selection and fusion of diverse ranked lists obtained from multiple and diverse feature extractors. Among the contributions, this work proposes a query performance prediction measure that models the relation-ship among images considering a hypergraph structure and does not require the use of any labeled data. Expres-sive gains were obtained in four datasets commonly used for person Re-ID. We achieved results competitive to the state-of-the-art in most of the scenarios.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Valem, Lucas Pascotti; Pedronette, Daniel Carlos Guimaraes] Sao Paulo State Univ UNESP, Dept Stat Appl Math & Comp DEMAC, Rio Claro, Brazil.
C3 Universidade Estadual Paulista
RP Valem, LP (corresponding author), Sao Paulo State Univ UNESP, Dept Stat Appl Math & Comp DEMAC, Rio Claro, Brazil.
EM lucas.valem@unesp.br; daniel.pedronette@unesp.br
FU Sao Paulo Research Foundation-FAPESP [2018/15597-6, 2017/25908-6];
   Brazilian National Council for Scientic and Technological
   Development-CNPq [309439/2020-5, 422667/2021-8]; Microsoft Research;
   Petrobras [2017/00285-6]
FX The authors are grateful to the Sao Paulo Research Foundation-FAPESP
   (grants #2018/15597-6 and #2017/25908-6) , Brazilian National Council
   for Scientic and Technological Development-CNPq (grants #309439/2020-5
   and #422667/2021-8) , Microsoft Research, and Petrobras (grant
   #2017/00285-6) .
CR An L, 2017, IEEE T NEUR NET LEAR, V28, P2763, DOI 10.1109/TNNLS.2016.2602082
   [Anonymous], 2008, P 14 ACM SIGKDD INT
   Bai ZC, 2021, PROC CVPR IEEE, P12909, DOI 10.1109/CVPR46437.2021.01272
   Bretto A., 2013, HYPERGRAPH THEORY IN, DOI DOI 10.1007/978-3-319-00080-0
   Camps O, 2017, IEEE T CIRC SYST VID, V27, P540, DOI 10.1109/TCSVT.2016.2556538
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Cristani M., 2018, Academic Press Library in Signal Processing, V6, P365
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Figueira D, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P111, DOI 10.1109/AVSS.2013.6636625
   García J, 2017, IEEE T IMAGE PROCESS, V26, P1650, DOI 10.1109/TIP.2017.2652725
   García J, 2016, J VIS COMMUN IMAGE R, V38, P115, DOI 10.1016/j.jvcir.2016.02.009
   García J, 2015, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2015.154
   Ge W., 2021, CROSS CAMERA FEATURE, P3644, DOI DOI 10.1145/3474085.3475382
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Pedronette DCG, 2019, IEEE T IMAGE PROCESS, V28, P5824, DOI 10.1109/TIP.2019.2920526
   Guo RP, 2018, INT C PATT RECOG, P982, DOI 10.1109/ICPR.2018.8545619
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X., 2005, P ADV NEURAL INFORM, V18, P507
   Huang H., 2022, ARXIV PREPRINT ARXIV
   Huang Y, 2020, AAAI C ART INT
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   Jing-Yan Wang, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P2053, DOI 10.1109/ICMLC.2010.5580505
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar D., ABS190712016 CORR
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li D., 2019, UNSUPERVISED CROSS D, P1222, DOI DOI 10.1109/ICIP.2019.8804418
   Li M., 2018, PROC EUR C COMPUT, P737
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2012, IEEE IMAGE PROC, P1621, DOI 10.1109/ICIP.2012.6467186
   Li Y., 2014, REAL WORLD RE IDENTI, P1, DOI DOI 10.1145/2659021.2659039
   Li YJ, 2018, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2018.00054
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Lin YT, 2020, IEEE T IMAGE PROCESS, V29, P5481, DOI 10.1109/TIP.2020.2982826
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu H., ABS190512830 CORR
   Liu J., 2019, IEEE C COMPUTER VISI
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Ma AJ, 2015, LECT NOTES COMPUT SC, V9007, P397, DOI 10.1007/978-3-319-16814-2_26
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Mang Ye, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P105, DOI 10.1007/978-3-319-14445-0_10
   Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Meng JK, 2019, PROC CVPR IEEE, P760, DOI 10.1109/CVPR.2019.00085
   Oliveira A, 2019, J VIS COMMUN IMAGE R, V60, P236, DOI 10.1016/j.jvcir.2019.02.019
   Piras L, 2017, INFORM FUSION, V37, P50, DOI 10.1016/j.inffus.2017.01.003
   Ren C., ABS190505382 CORR
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shtok A, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2926790
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tang HT, 2019, IEEE COMPUT SOC CONF, P1536, DOI 10.1109/CVPRW.2019.00195
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Valem LP, 2020, NEUROCOMPUTING, V377, P182, DOI 10.1016/j.neucom.2019.09.065
   Valem LP, 2018, PATTERN RECOGN LETT, V114, P41, DOI 10.1016/j.patrec.2017.10.013
   Nguyen VH, 2013, 2013 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P304, DOI 10.1109/SOCPAR.2013.7054148
   Wang G., ARXIV190403845, V2020
   Wang HX, 2016, IEEE IMAGE PROC, P769, DOI 10.1109/ICIP.2016.7532461
   Webber W, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852106
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xian YQ, 2018, IET COMPUT VIS, V12, P1219, DOI 10.1049/iet-cvi.2018.5103
   Xin XM, 2019, PATTERN RECOGN, V88, P285, DOI 10.1016/j.patcog.2018.11.025
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Yun Zhou, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P543, DOI 10.1145/1277741.1277835
   Zeng QX, 2019, ELECTRON LETT, V55, P186, DOI 10.1049/el.2018.7791
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151, DOI DOI 10.1145/1273496.1273641
   Zheng L., ABS161002984 CORR
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhou D., 2006, ADV NEURAL INFORM PR, P1601, DOI DOI 10.7551/MITPRESS/7503.003.0205
   Zhou K., 2022, ARXIV PREPRINT ARXIV
   Zhou K., 2019, ARXIV191010093
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhou Y., 2006, CIKM, P567
   Zhu XP, 2021, INT J COMPUT VISION, V129, P1580, DOI 10.1007/s11263-021-01440-4
   Zhu XP, 2019, IEEE INT CONF COMP V, P1079, DOI 10.1109/ICCVW.2019.00138
NR 92
TC 3
Z9 5
U1 2
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104473
DI 10.1016/j.imavis.2022.104473
EA MAY 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J5IS
UT WOS:000815691000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, CH
   Meng, GF
   Su, B
   Xiang, SM
   Pan, CH
AF Zhang, Chenghao
   Meng, Gaofeng
   Su, Bing
   Xiang, Shiming
   Pan, Chunhong
TI Monocular contextual constraint for stereo matching with adaptive
   weights assignment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Stereo matching; Monocular contextual constraint;
   Adaptive weights assignment
AB Matching-based stereo disparity estimation has difficulty in dealing with occlusion, weak and repetitive textures in binocular vision. By contrast, monocular vision, estimating depth from a single image, is not subject to these challenges. Inspired by this, in this study, we propose an adaptive co-learning framework with monocular and stereo branches named CLStereo to improve stereo performance. This framework introduces a monocular branch as contextual constraints to transfer the prior knowledge learned from the monocular branch to the stereo branch. An adaptive weights assignment is further proposed to balance the co-learning of both branches without mutually tuning. CLStereo can be seamlessly embedded into many existing deep stereo models to boost their performance, especially in occluded, weak, and repetitive texture areas. Extensive experiments demonstrate that we achieve the state-of-the-art performance on the Scene Flow dataset and improve deep stereo models by at least 4% on KITTI 2012 and 2015 benchmarks. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhang, Chenghao; Meng, Gaofeng; Xiang, Shiming; Pan, Chunhong] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   [Zhang, Chenghao; Meng, Gaofeng; Xiang, Shiming] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
   [Meng, Gaofeng] Chinese Acad Sci, HK Inst Sci & Innovat, Ctr Artificial Intelligence & Robot, Hong Kong 999077, Peoples R China.
   [Su, Bing] Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing 100872, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences; Renmin University of China
RP Meng, GF (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM chenghao.zhang@nlpr.ia.ac.cn; gfmeng@nlpr.ia.ac.cn; bingsu@ruc.edu.cn;
   smxiang@nlpr.ia.ac.cn; chpan@nlpr.ia.ac.cn
RI Su, Bing/ABC-4813-2020
OI Su, Bing/0000-0001-8560-1910
FU National Key Research and De-velopment Program of China
   [2020AAA0109702]; National Natural Science Foundation of China
   [61976208, 61802407, 62071466]
FX Acknowledgments This research was supported by the National Key Research
   and De-velopment Program of China under Grant No. 2020AAA0109702, and
   the National Natural Science Foundation of China under Grants 61976208,
   61802407, and 62071466.
CR Aleotti Filippo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P614, DOI 10.1007/978-3-030-58621-8_36
   [Anonymous], 2018, P EUR C COMP VIS ECC
   Badki A, 2020, PROC CVPR IEEE, P1597, DOI 10.1109/CVPR42600.2020.00167
   Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Duggal S, 2019, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2019.00448
   Eigen D, NEURIPS 2014, P2366
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   Guo XY, 2018, LECT NOTES COMPUT SC, V11215, P506, DOI 10.1007/978-3-030-01252-6_30
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee JH, 2019, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR.2019.00996
   Li J, 2017, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2017.365
   Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Ranjan A, 2019, PROC CVPR IEEE, P12232, DOI 10.1109/CVPR.2019.01252
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Schöps T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272
   Song X., 2020, IJCV
   Tosi F, 2019, PROC CVPR IEEE, P9791, DOI 10.1109/CVPR.2019.01003
   Wang L., ECCV 2020, P316
   Watson Jamie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P722, DOI 10.1007/978-3-030-58452-8_42
   Xu HF, 2020, PROC CVPR IEEE, P1956, DOI 10.1109/CVPR42600.2020.00203
   Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39
   Yin ZC, 2019, PROC CVPR IEEE, P6037, DOI 10.1109/CVPR.2019.00620
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 41
TC 5
Z9 5
U1 1
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104424
DI 10.1016/j.imavis.2022.104424
EA MAR 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0N8RO
UT WOS:000783099100003
DA 2024-07-18
ER

PT J
AU Vu, AKN
   Nguyen, ND
   Nguyen, KD
   Nguyen, VT
   Ngo, TD
   Do, TT
   Nguyen, TV
AF Vu, Anh-Khoa Nguyen
   Nguyen, Nhat-Duy
   Nguyen, Khanh-Duy
   Nguyen, Vinh-Tiep
   Ngo, Thanh Duc
   Do, Thanh-Toan
   Nguyen, Tam V.
TI Few-shot object detection via baby learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Few-shot object detection; Few-shot learning; Baby learning
AB Few-shot learning is proposed to overcome the problem of scarce training data in novel classes. Recently, few-shot learning has been well adopted in various computer vision tasks such as object recognition and object detection. However, the state-of-the-art (SOTA) methods have less attention to effectively reuse the information from previous stages. In this paper, we propose a new framework of few-shot learning for object detection. In particular, we adopt Baby Learning mechanism along with the multiple receptive fields to effectively utilize the former knowledge in novel domain. The propoed framework imitates the learning process of a baby through visual cues. The extensive experiments demonstrate the superiority of the proposed method over the SOTA methods on the benchmarks (improve average 7.0% on PASCAL VOC and 1.6% on MS COCO).(c) 2022 Elsevier B.V. All rights reserved.
C1 [Vu, Anh-Khoa Nguyen; Nguyen, Nhat-Duy; Nguyen, Khanh-Duy; Nguyen, Vinh-Tiep; Ngo, Thanh Duc] Univ Informat Technol, Ho Chi Minh City, Vietnam.
   [Vu, Anh-Khoa Nguyen; Nguyen, Nhat-Duy; Nguyen, Khanh-Duy; Nguyen, Vinh-Tiep; Ngo, Thanh Duc] Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
   [Do, Thanh-Toan] Monash Univ, Clayton, Vic 3800, Australia.
   [Nguyen, Tam V.] Univ Dayton, Dayton, OH 45469 USA.
C3 Vietnam National University Hochiminh City; Monash University;
   University System of Ohio; University of Dayton
RP Nguyen, ND (corresponding author), Univ Informat Technol, Ho Chi Minh City, Vietnam.; Nguyen, ND (corresponding author), Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
EM duynn@uit.edu.vn
RI Nguyen, Tam/AAU-6504-2020; Nguyen Vu, Anh-Khoa/KIG-2033-2024
OI Nguyen, Tam/0000-0003-0236-7992; Nguyen Vu, Anh-Khoa/0000-0003-3133-0259
FU National Science Foundation (NSF) [2025234]; Division Of Computer and
   Network Systems; Direct For Computer & Info Scie & Enginr [2025234]
   Funding Source: National Science Foundation
FX Acknowledgements This research is funded by National Science Foundation
   (NSF) under Grant No. 2025234.
CR Artacho B, 2020, PROC CVPR IEEE, P7033, DOI 10.1109/CVPR42600.2020.00706
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cheng Xu, 2020, CVPR
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan Q, 2020, PROC CVPR IEEE, P4012, DOI 10.1109/CVPR42600.2020.00407
   Fan Z., P IEEE CVF C COMP VI, P4527
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gomez J, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03166-3
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Kang BY, 2019, IEEE I CONF COMP VIS, P8419, DOI 10.1109/ICCV.2019.00851
   Karlinsky L, 2019, PROC CVPR IEEE, P5192, DOI 10.1109/CVPR.2019.00534
   Li B., 2021, CVPR
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Qiao L., 2021, PROC IEEECVF INT C C, P8681
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Redmon J., 2018, P IEEE C COMP VIS PA
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shafto CL, 2012, INFANCY, V17, P247, DOI 10.1111/j.1532-7078.2011.00085.x
   Tan M., 2020, CVPR
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang X., 2020, ICML, p2020b
   Wang Y.X., 2009, ICCV
   Wu Y., 2019, DETECTRON2
   Yan XP, 2019, IEEE I CONF COMP VIS, P9576, DOI 10.1109/ICCV.2019.00967
   Zhang G., 2021, META DETR IMAGE LEV
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou K, 2016, DESTECH TRANS COMP
   Zhu X., 2020, DEFORMERS DETR DEFRO
NR 33
TC 11
Z9 12
U1 9
U2 84
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104398
DI 10.1016/j.imavis.2022.104398
EA FEB 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500001
OA Bronze
DA 2024-07-18
ER

PT J
AU Masson, JEN
   Petry, MR
   Coutinho, DF
   Honório, LD
AF Masson, Juliano Emir Nunes
   Petry, Marcelo Roberto
   Coutinho, Daniel Ferreira
   Honorio, Leonardo de Mello
TI Deformable convolutions in multi-view stereo
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-view stereo; Depth map; Deep learning
ID PHOTOGRAMMETRY
AB The Multi-View Stereo (MVS) is a key process in the photogrammetry workflow. It is responsible for taking the camera's views and finding the maximum number of matches between the images yielding a dense point cloud of the observed scene. Since this process is based on the matching between images it greatly depends on the abil-ity of features matching throughout different images. To improve the matching performance several researchers have proposed the use of Convolutional Neural Networks (CNNs) to solve the MVS problem. Despite the progress in the MVS problem with the usage of CNNs, the Video RAM (VRAM) consumption within these approaches is usually far greater than classical methods, that rely more on RAM, which is cheaper to expand than VRAM. This work then follows the progress made in CasMVSNet in the reduction of GPU memory usage, and further study the changes in the feature extraction process. The Average Group-wise Correlation is used in the cost vol-ume generation, to reduce the number of channels in the cost volume, yielding a reduction in GPU memory usage without noticeable penalties in the result. The deformable convolutions are applied in the feature extraction net -work to augment the spatial sampling locations with learning offsets, without additional supervision, to further improve the network's ability to model transformations. The impact of these changes is measured using quanti-tative and qualitative tests using the DTU and the Tanks and Temples datasets. The modifications reduced the GPU memory usage by 32% and improved the completeness by 9% with a penalty of 6.6% in accuracy on the DTU dataset.(c) 2021 Published by Elsevier B.V.
C1 [Masson, Juliano Emir Nunes; Coutinho, Daniel Ferreira] Univ Fed Santa Catarina, Dept Automat & Syst, Florianopolis, SC, Brazil.
   [Petry, Marcelo Roberto] Inst Syst & Comp Engn Technol & Sci INESC TEC, Porto, Portugal.
   [Masson, Juliano Emir Nunes; Honorio, Leonardo de Mello] Univ Fed Juiz de Fora, Dept Elect Energy, Juiz De Fora, Brazil.
C3 Universidade Federal de Santa Catarina (UFSC); INESC TEC; Universidade
   Federal de Juiz de Fora
RP Masson, JEN (corresponding author), Univ Fed Santa Catarina, Dept Automat & Syst, Florianopolis, SC, Brazil.; Masson, JEN (corresponding author), Univ Fed Juiz de Fora, Dept Elect Energy, Juiz De Fora, Brazil.
EM juliano.masson@posgrad.ufsc.br
RI Petry, Marcelo R./G-6328-2010; Coutinho, Daniel Ferreira/M-6790-2013; de
   Mello Honório, Leonardo/A-6180-2016
OI Petry, Marcelo R./0000-0002-7023-8562; Coutinho, Daniel
   Ferreira/0000-0002-4249-1288; de Mello Honório,
   Leonardo/0000-0003-2735-4792
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001.
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Campbell NDF, 2008, LECT NOTES COMPUT SC, V5302, P766, DOI 10.1007/978-3-540-88682-2_58
   Chen PH, 2020, IEEE T IMAGE PROCESS, V29, P7261, DOI 10.1109/TIP.2020.3000611
   Chen R, 2019, IEEE I CONF COMP VIS, P1538, DOI 10.1109/ICCV.2019.00162
   Cheng S, 2020, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR42600.2020.00260
   Choi S., P IEEE C COMP VIS PA, P276
   Comba L, 2018, COMPUT ELECTRON AGR, V155, P84, DOI 10.1016/j.compag.2018.10.005
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai YC, 2019, INT CONF 3D VISION, P1, DOI 10.1109/3DV.2019.00010
   Furukawa Y., 2015, TRENDS COMPUT GRAPH, V9, P1, DOI DOI 10.1561/0600000052
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Galliani S, 2015, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2015.106
   Gallup David, 2007, CVPR
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Guerra W, 2019, IEEE INT C INT ROBOT, P6941, DOI [10.1109/iros40897.2019.8968116, 10.1109/IROS40897.2019.8968116]
   Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298
   Im Sunghoon, 2019, P INT C LEARN REPR
   Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59
   Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Kruglov A. V., 2016, PROC INT C DIGIT IMA, P1, DOI [10.1109/DICTA.2016.7797088, DOI 10.1109/DICTA.2016.7797088]
   Liu J, 2020, PROC CVPR IEEE, P6049, DOI 10.1109/CVPR42600.2020.00609
   Loredo Conde AJ, 2020, J CIV ENG MANAG, V26, P513, DOI 10.3846/jcem.2020.12611
   Luo KY, 2020, PROC CVPR IEEE, P1587, DOI 10.1109/CVPR42600.2020.00166
   Luo KY, 2019, IEEE I CONF COMP VIS, P10451, DOI 10.1109/ICCV.2019.01055
   Melo AG, 2020, IEEE ACCESS, V8, P177823, DOI 10.1109/ACCESS.2020.3027205
   Monteiro JG, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80612-7
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Smith MW, 2015, EARTH SURF PROC LAND, V40, P1656, DOI 10.1002/esp.3747
   Sulaiman MZ, 2020, P INT C INN MED VIS, P221, DOI DOI 10.2991/ASSEHR.K.201202.079
   Tao F, 2019, IEEE T IND INFORM, V15, P2405, DOI 10.1109/TII.2018.2873186
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   Tsouros DC, 2019, INFORMATION, V10, DOI 10.3390/info10110349
   Xu HF, 2020, PROC CVPR IEEE, P1956, DOI 10.1109/CVPR42600.2020.00203
   Xu Q., 2019, ARXIV191211746
   Xue YZ, 2019, IEEE I CONF COMP VIS, P4311, DOI 10.1109/ICCV.2019.00441
   Yang JY, 2020, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR42600.2020.00493
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yao Y, 2020, PROC CVPR IEEE, P1787, DOI 10.1109/CVPR42600.2020.00186
   Yao Y, 2019, PROC CVPR IEEE, P5520, DOI 10.1109/CVPR.2019.00567
   Ying XY, 2020, IEEE SIGNAL PROC LET, V27, P1500, DOI 10.1109/LSP.2020.3013518
   Yu ZH, 2020, PROC CVPR IEEE, P1946, DOI 10.1109/CVPR42600.2020.00202
NR 42
TC 3
Z9 4
U1 3
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2022
VL 118
AR 104369
DI 10.1016/j.imavis.2021.104369
EA JAN 2022
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0F3OZ
UT WOS:000777273700004
DA 2024-07-18
ER

PT J
AU Gutoski, M
   Lazzaretti, AE
   Lopes, HS
AF Gutoski, Matheus
   Lazzaretti, Andre Eugenio
   Lopes, Heitor Silverio
TI Incremental human action recognition with dual memory
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Incremental learning; Human Action Recognition; Metric Learning; Triplet
   Networks; Dual-memory Extreme Value Machine
AB Incremental learning is a topic of great interest in the current state of machine learning research. Real-world problems often require a classifier to incorporate new knowledge while preserving what was learned before. One of the most challenging problems in computer vision is Human Action Recognition (HAR) in videos. How-ever, most of the existing works approach HAR from a non-incremental point of view. This work proposes a framework for performing HAR in the incremental learning scenario called Incremental Human Action Recogni-tion with Dual Memory (IHAR-DM). IHAR-DM contains three main components: a 3D convolutional neural net-work for capturing Spatio-temporal features; a Triplet Network to perform metric learning; and the dual -memory Extreme Value Machine, which is introduced in this work. The proposed method is compared with 10 other state-of-the-art incremental learning models. We propose five experimental settings containing different numbers of tasks and classes using two widely known HAR datasets: UCF-101 and HMDB51. Our results show superior performance in terms of Normalized Mutual Information (NMI) and Inter-task Intransigence (ITI), which is a new metric proposed in this work. Overall results show the feasibility of the proposal for real HAR problems, which mostly present the requirements imposed by incremental learning. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Gutoski, Matheus; Lazzaretti, Andre Eugenio; Lopes, Heitor Silverio] Univ Tecnol Fed Parana, Av Sete Setembro 3165, BR-80230901 Curitiba, Parana, Brazil.
C3 Universidade Federal do Parana; Pontificia Universidade Catolica do
   Parana; Universidade Tecnologica Federal do Parana
RP Gutoski, M (corresponding author), Univ Tecnol Fed Parana, Av Sete Setembro 3165, BR-80230901 Curitiba, Parana, Brazil.
EM matheusgutoski@alunos.utfpr.edu.br
RI Lazzaretti, Andre Eugenio/ABE-4474-2021; Lazzaretti, Andre
   Eugenio/T-7227-2019
OI Lazzaretti, Andre Eugenio/0000-0003-1861-3369; gutoski,
   matheus/0000-0001-7679-0588
CR Aljundi R, 2018, LECT NOTES COMPUT SC, V11207, P144, DOI 10.1007/978-3-030-01219-9_9
   Aljundi R, 2017, PROC CVPR IEEE, P7120, DOI 10.1109/CVPR.2017.753
   Belouadah E, 2019, IEEE I CONF COMP VIS, P583, DOI 10.1109/ICCV.2019.00067
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Castro FM, 2018, LECT NOTES COMPUT SC, V11216, P241, DOI 10.1007/978-3-030-01258-8_15
   Chaudhry A, 2018, LECT NOTES COMPUT SC, V11215, P556, DOI 10.1007/978-3-030-01252-6_33
   De Lange M, 2022, IEEE T PATTERN ANAL, V44, P3366, DOI 10.1109/TPAMI.2021.3057446
   De Rosa R, 2014, P BRIT MACH VIS C, P1
   Desjardins G., 2016, ARXIV160604671
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Gepperth Alexander, 2019, INT C LEARN REPR ICL
   Glorot X., 2010, P INT C ART INT STAT, P249
   Gutoski M, 2021, NEURAL COMPUT APPL, V33, P1207, DOI 10.1007/s00521-020-05009-z
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hou SH, 2019, PROC CVPR IEEE, P831, DOI 10.1109/CVPR.2019.00092
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Lu YY, 2014, NEUROCOMPUTING, V126, P132, DOI 10.1016/j.neucom.2012.08.071
   Mallya A, 2018, LECT NOTES COMPUT SC, V11208, P72, DOI 10.1007/978-3-030-01225-0_5
   Masana Marc, 2020, ARXIV200108714
   Masana Marc, 2020, ARXIV201015277
   Min EX, 2018, IEEE ACCESS, V6, P39501, DOI 10.1109/ACCESS.2018.2855437
   Minhas R, 2012, IEEE T CIRC SYST VID, V22, P1529, DOI 10.1109/TCSVT.2011.2177182
   Pinto M.F., 2020, LEARN NONLINEAR MODE, V18, P4
   Rajasegaran J., 2020, IEEE C COMPUT VIS PA, P13588
   Rebuffi SA, 2017, PROC CVPR IEEE, P5533, DOI 10.1109/CVPR.2017.587
   Reddy KK, 2009, IEEE I CONF COMP VIS, P1010, DOI 10.1109/ICCV.2009.5459374
   Rudd EM, 2018, IEEE T PATTERN ANAL, V40, P762, DOI 10.1109/TPAMI.2017.2707495
   Schwarz J, 2018, PR MACH LEARN RES, V80
   Soomro K., 2012, ARXIV12120402CS
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Tang C, 2018, INFORM SCIENCES, V467, P219, DOI 10.1016/j.ins.2018.08.003
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Wong S.-F., 2007, IEEE COMPUTER SOC C, P1
   Wu XX, 2010, PATTERN RECOGN, V43, P4190, DOI 10.1016/j.patcog.2010.07.012
   Wu Y, 2019, PROC CVPR IEEE, P374, DOI 10.1109/CVPR.2019.00046
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yuanyuan Shi, 2018, 2018 IEEE Power & Energy Society General Meeting (PESGM), DOI 10.1109/PESGM.2018.8586227
   Zenke F, 2017, PR MACH LEARN RES, V70
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
NR 44
TC 2
Z9 2
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104313
DI 10.1016/j.imavis.2021.104313
EA OCT 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WL9GT
UT WOS:000710706800002
DA 2024-07-18
ER

PT J
AU Aziz, L
   Salam, MSBHFC
   Ayub, S
AF Aziz, Lubna
   Salam, Md. Sah Bin Haji F. C.
   Ayub, Sara
TI Multi-level refinement enriched feature pyramid network for object
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CNN; Object detection; Chained parallel pooling; Computer vision;
   Feature pyramid
AB Class Imbalance and scales imbalance are common in object detection. A class imbalance occurs due to insufficient inequality between the number of instances with respect to different classes, while an imbalance in scale occurs when object have different scales and a different number of examples of different scales. In order to solve the problem of scale variance (scale imbalance) and class imbalance together, we propose a simple and effective feature enhancement scheme that explicitly uses all information of a multi-level structure to generate a multilevel contextual features pyramid with multiple scales. We also introduce a cascaded refinement scheme that incorporates multi-scale contextual features into the Single Shot Detector (SSD) predictive layers to improve their distinctiveness for multi-scale detection. A stack of multi-scale contextual feature modules is used in a feature enhancement scheme to merge the multi-level and multi-scale features. Then we collect the equivalent scale features over the Multi-layer Feature Fusion (MLFF) unit to construct a feature pyramid in which each feature map is made up of layers from multiple levels. More robustness and contextual information are integrated into the pyramid through chain parallel pooling operation. To improve classification and regression, a cascaded refinement scheme is proposed that effectively captures a large amount of contextual information and refines the anchors to solve the class imbalance problem. The experiments are carried out on two benchmarks datasets: MS COCO and PASCAL VOC 07/12. Our proposed approach achieves state-of-the-art accuracy with an AP of 40.6 in the case of multi-scale inference on MS COCO Test-dev (input size 320 x 320). For 512 x 512 input on the MS COCO Test-dev, our approach leads in an absolute gain in precision of 1.8% compared to the best reported results of single-stage detector (AP: 45.7). (c) 2021 Elsevier B.V. All rights reserved.
C1 [Aziz, Lubna; Salam, Md. Sah Bin Haji F. C.] Univ Teknol Malaysia, Sch Comp, Div Artificial Intelligence, Fac Engn, Skudai 81310, Johor, Malaysia.
   [Aziz, Lubna] FICT BUITEMS, Dept Comp Engn, Lahore, Pakistan.
   [Ayub, Sara] Univ Teknol Malaysia, Dept Elect Engn, Fac Engn, Skudai 81310, Johor, Malaysia.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia
RP Aziz, L (corresponding author), Univ Teknol Malaysia, Sch Comp, Div Artificial Intelligence, Fac Engn, Skudai 81310, Johor, Malaysia.
EM azizlubna@graduate.utm.my
RI Aziz, Lubna/ABF-8547-2021
OI Aziz, Lubna/0000-0002-8280-7523
CR [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2016, INT C LEARNING REPRE
   Aziz L, 2020, IEEE ACCESS, V8, P170461, DOI 10.1109/ACCESS.2020.3021508
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cao JL, 2019, PROC CVPR IEEE, P7384, DOI 10.1109/CVPR.2019.00757
   Chen Jiaqi, 2019, ARXIV PREPRINT ARXIV
   Chen Xiangyi, 2018, ARXIV180802941
   Dai JF, 2016, ADV NEUR IN, V29
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai XY, 2021, PROC CVPR IEEE, P7369, DOI 10.1109/CVPR46437.2021.00729
   Dong Q, 2017, IEEE I CONF COMP VIS, P1869, DOI 10.1109/ICCV.2017.205
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Lin M., 2014, NETW NETW INT C LEAR
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Pang YW, 2019, PROC CVPR IEEE, P7328, DOI 10.1109/CVPR.2019.00751
   Pang YW, 2019, IEEE T CIRC SYST VID, V29, P3211, DOI 10.1109/TCSVT.2018.2880223
   Quang TN, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060746
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K., 2014, CORR
   Singh B, 2018, 32 C NEURAL INFORM P
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tychsen-Smith L, 2018, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR.2018.00719
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xinjiang Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13356, DOI 10.1109/CVPR42600.2020.01337
   Yazhao Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13346, DOI 10.1109/CVPR42600.2020.01336
   Yu F., 2015, ARXIV
   Yuhang Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11580, DOI 10.1109/CVPR42600.2020.01160
   Zhang SF, 2021, IEEE T CIRC SYST VID, V31, P674, DOI 10.1109/TCSVT.2020.2986402
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
NR 53
TC 13
Z9 13
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104287
DI 10.1016/j.imavis.2021.104287
EA SEP 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WC6NH
UT WOS:000704372400005
DA 2024-07-18
ER

PT J
AU Biswas, R
   González-Castro, V
   Fidalgo, E
   Alegre, E
AF Biswas, Rubel
   Gonzalez-Castro, Victor
   Fidalgo, Eduardo
   Alegre, Enrique
TI A new perceptual hashing method for verification and identity
   classification of occluded faces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face verification; Face classification; Adversarial attack eye region
   occlusion; Perceptual hashing; Discrete cosine transform (DCT); OSF-DNS
ID RECOGNITION; AUTOENCODERS; OCCLUSION; FUSION; MODEL
AB Recently, research communities on Computer Vision and biometrics have shown a lot of interest in face verification and classification methods. Fighting against Child Sexual Exploitation Material (CSEM) is one of the applications that might benefit most from these advances. In CSEM, discriminative parts of the face, i.e. mostly the eyes, are often occluded to make the victim identification more difficult. Most of the current face recognition methods are not able to handle such kind of occlusions. To overcome this problem, we present One-Shot Frequency Dominant Neighborhood Structure (OSF-DNS), a new perceptual hashing method that shows advantages on two scenarios: (a) occluded face verification, i.e., matching occluded faces with their non-occluded versions, and (b) face classification, i.e., getting the identity of an occluded face by means of a classifier trained with the non-occluded faces using the perceptual hash codes as feature vectors. We have compared the face verification performance of OSF-DNS with three perceptual hashing methods and with the features obtained from five deep learning techniques, using the occluded versions of six different facial datasets. The proposed method achieves accuracies between 69.24% and 99.46% depending on the dataset, and always higher than the compared methods. For the face classification task, we compared the performance of OSF-DNS with the features obtained by four deep learning techniques. Experimental results on LFW and CFPW datasets showed that the proposed hashing method outperformed the results obtained with deep features with an accuracy up to 89.53%. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Biswas, Rubel; Gonzalez-Castro, Victor; Fidalgo, Eduardo; Alegre, Enrique] Univ Leon, Dept Elect Syst & Automat Engn, Leon, Spain.
   [Biswas, Rubel; Gonzalez-Castro, Victor; Fidalgo, Eduardo; Alegre, Enrique] INCIBE Spanish Natl Cybersecur Inst, Leon, Spain.
C3 Universidad de Leon
RP Biswas, R (corresponding author), Univ Leon, Dept Elect Syst & Automat Engn, Leon, Spain.
EM rbis@unileon.es; victor.gonzalez@unileon.es; eduardo.fidalgo@unileon.es;
   enrique.alegre@unileon.es
RI Alegre, Enrique/N-3430-2019; González-Castro, Víctor/L-2744-2017;
   FIDALGO, Eduardo/ABC-1710-2020
OI Alegre, Enrique/0000-0003-2081-774X; González-Castro,
   Víctor/0000-0001-8742-3775; FIDALGO, Eduardo/0000-0003-1202-5232
FU University of Leon; INCIBE Spanish National Cybersecurity Institute
FX This research is supported by the framework agreement between
   theUniversity of Leon and (INCIBE Spanish National Cybersecurity
   Institute) under Addendum 01. We also gratefully acknowledge the support
   of Nvidia Corporation for their kind donation of GPUs (GeForce GTX Titan
   X and K-40) that were used in this work. Finally, we would like to thank
   Professor Zhenjun Tang for sharing with us the implementation of his
   perceptual hashing method Ring Partition and Invariant Vector Distance
   and Professor Chuan Qin for sharing the implementation of his method
   Selective Sampling for Salient Structure Features.
CR Alrjebi MM, 2017, PATTERN RECOGN LETT, V95, P14, DOI 10.1016/j.patrec.2017.05.013
   Andrew P.F., 2011, 7807 NIST
   [Anonymous], 2016, CMU-CS-16-118
   Best-Rowden L, 2014, IEEE T INF FOREN SEC, V9, P2144, DOI 10.1109/TIFS.2014.2359577
   Bharadwaj S, 2016, IEEE T INF FOREN SEC, V11, P1630, DOI 10.1109/TIFS.2016.2538744
   Biswas R., 2020, NEUROCOMPUTING, V27, P778
   Biswas R., 8 INT C IM CRIM DET, P13
   Biswas Rubel, 2019, V Jornadas Nacionales de Investigacion en Ciberseguridad, V1, P344
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Cheng EJ, 2019, PATTERN RECOGN LETT, V125, P71, DOI 10.1016/j.patrec.2019.03.006
   Cho-Ying W., P IEEE INT C MULT EX, P1
   Dagnes N, 2019, INT J INTERACT DES M, V13, P1617, DOI 10.1007/s12008-019-00582-7
   Davarzani R, 2016, MULTIMED TOOLS APPL, V75, P4639, DOI 10.1007/s11042-015-2496-6
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Domingo M., IEEE INT WORKSH INF, P13
   Dong JL, 2019, SIGNAL PROCESS-IMAGE, V76, P81, DOI 10.1016/j.image.2019.04.006
   Duan YQ, 2018, IEEE T INF FOREN SEC, V13, P1823, DOI 10.1109/TIFS.2018.2804919
   Egger HL, 2011, INT J METH PSYCH RES, V20, P145, DOI 10.1002/mpr.343
   Fang W, 2018, NEUROCOMPUTING, V272, P520, DOI 10.1016/j.neucom.2017.07.019
   Fidalgo E, 2019, REV IBEROAM AUTOM IN, V16, P358, DOI [10.4995/riai.2019.10640, 10.4995/riai.2018.10640]
   Gangwar Abhishek, 2017, 8th International Conference on Imaging for Crime Detection and Prevention (ICDP 2017), P37
   Gao GW, 2017, PATTERN RECOGN, V66, P129, DOI 10.1016/j.patcog.2016.12.021
   Gary B.H., 2007, 749 U MASS
   Görgel P, 2019, APPL MATH COMPUT, V355, P325, DOI 10.1016/j.amc.2019.02.071
   Iranmanesh SM, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103861
   Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454
   Khellah FM, 2011, IEEE T IMAGE PROCESS, V20, P3270, DOI 10.1109/TIP.2011.2143422
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Koc M, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01156-4
   Liao SC, 2013, IEEE T PATTERN ANAL, V35, P1193, DOI 10.1109/TPAMI.2012.191
   Lilei Zheng, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163085
   Long Y, 2018, INFORM SCIENCES, V430, P634, DOI 10.1016/j.ins.2017.10.042
   Lu CS, 2005, MULTIMEDIA SYST, V11, P159, DOI 10.1007/s00530-005-0199-y
   Lu T, 2021, MULTIMED TOOLS APPL, V80, P8563, DOI 10.1007/s11042-020-09784-8
   Lu WJ, 2010, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2010.5650613
   Massoli FV, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103927
   Mathai J., 2019, INT CONF BIOMETR, P1, DOI DOI 10.1109/icb45273.2019.8987388
   Andrés AM, 2014, PATTERN RECOGN LETT, V36, P235, DOI 10.1016/j.patrec.2013.08.001
   Ou WH, 2018, PATTERN RECOGN LETT, V107, P41, DOI 10.1016/j.patrec.2017.07.006
   Qin C, 2019, IEEE ACCESS, V7, P45460, DOI 10.1109/ACCESS.2019.2908029
   Qin C, 2016, DISPLAYS, V45, P26, DOI 10.1016/j.displa.2016.09.003
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S, 2016, IEEE WINT CONF APPL
   Sharma S, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P192, DOI 10.1109/ICACCCT.2016.7831628
   Simonyan K, 2015, IEEE INT C ICLR
   Tang ZJ, 2019, MATH BIOSCI ENG, V16, P6103, DOI 10.3934/mbe.2019305
   Tang ZJ, 2018, NEUROCOMPUTING, V308, P147, DOI 10.1016/j.neucom.2018.04.057
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Vakhshiteh F., ABS200711709 ARXIV
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu CY, 2018, PATTERN RECOGN, V80, P256, DOI 10.1016/j.patcog.2018.03.016
   Xie L, 2016, SIGNAL PROCESS, V124, P81, DOI 10.1016/j.sigpro.2015.10.010
   Xu YJ, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106554
   Yu YF, 2017, PATTERN RECOGN, V66, P302, DOI 10.1016/j.patcog.2017.01.021
   Yuan XR, 2021, IEEE ACCESS, V9, P49325, DOI 10.1109/ACCESS.2021.3069045
   Zauner C., 2010, THESIS U APPL SCI HA
   Zeng D, 2019, PATTERN RECOGN LETT, V119, P180, DOI 10.1016/j.patrec.2018.05.024
   Zhang PY, 2016, PATTERN RECOGN, V52, P249, DOI 10.1016/j.patcog.2015.09.024
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao F, 2018, IEEE T IMAGE PROCESS, V27, P778, DOI 10.1109/TIP.2017.2771408
   Zhong YY, 2021, IEEE T IMAGE PROCESS, V30, P2587, DOI 10.1109/TIP.2020.3048632
   Zhou R., 2020, IMAGE VIS COMPUT, V100, P1
NR 63
TC 9
Z9 9
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104245
DI 10.1016/j.imavis.2021.104245
EA JUL 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900007
DA 2024-07-18
ER

PT J
AU Hou, HP
   Zhou, Y
   Zhao, JQ
   Yao, R
   Chen, Y
   Zheng, Y
   El Saddik, A
AF Hou, Haopeng
   Zhou, Yong
   Zhao, Jiaqi
   Yao, Rui
   Chen, Ying
   Zheng, Yi
   El Saddik, Abdulmotaleb
TI Unsupervised cross-domain person re-identification with self-attention
   and joint-flexible optimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Unsupervised domain adaptation; Self-attention
   mechanism
AB Unsupervised domain adaptation (UDA) for person re-identication (ReID) remains a challenging task, as the trained ReID system often fails to adapting to a new dataset. Due to the lack of supervision of real labels, the performance of the UDA models suffers from inefficient feature learning and inevitable pseudo label noise. In this work, we tackle the problems by designing an effective dual-path mutual-learning framework which can capture effective information for better feature learning and mitigate the impact of label noise. Firstly, to reduce the impact of occlusion and viewpoints, we introduce the self-attention mechanism in a two-stage strategy making the models focus on the key areas of identifying people. Secondly, considering that UDA is an open-set task, we leverage density-based spatial clustering of applications with noise (DBSCAN) to avoid manually setting the number of classes of the target domain. Thirdly, for realizing joint and flexible optimization under the supervision of soft pseudo labels and hard pseudo labels, a joint and flexible loss (JFL) is proposed to train the network. Experiments on three large-scale datasets show that our model outperforms the state-of-the-art UDA methods in both mAP and top-1 evaluation protocols by large margins. Especially on task of Duke-to-Market, our method outperforms the state-of-the-art by 6.9% mAP.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Hou, Haopeng; Zhou, Yong; Zhao, Jiaqi; Yao, Rui; Chen, Ying; Zheng, Yi] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Hou, Haopeng; Zhou, Yong; Zhao, Jiaqi; Yao, Rui; Chen, Ying; Zheng, Yi] Engn Res Ctr Mine Digitizat, Minist Educ Peoples Republ China, Xuzhou 221116, Jiangsu, Peoples R China.
   [El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Multimedia Commun Res Lab MCRLab, 800 King Edward, Ottawa, ON K1N 6N5, Canada.
C3 China University of Mining & Technology; University of Ottawa
RP Zhou, Y (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
EM yzhou@cumt.edu.cn
FU National Natural Science Foundation of China [61806206, 61772530];
   Natural Science Foundation of Jiangsu Province [BK20180639, BK20201346];
   Six Talent Peaks Project in Jiangsu Province [2015-DZXX-010,
   2018XYDXX-044]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61806206, 61772530), and the Natural Science Foundation of
   Jiangsu Province (No. BK20180639, BK20201346), the Six Talent Peaks
   Project in Jiangsu Province (No. 2015-DZXX-010, 2018XYDXX-044).
CR [Anonymous], 2020, PROC CVPR IEEE, DOI DOI 10.1109/CVPR42600.2020.00643
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.90
   [Anonymous], 2007, P IEEE INT WORKSH PE
   Bak S, P IEEE C COMP VIS PA, P2990
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bengio Y., 2014, TECHNICAL REPORT
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen D, P EUR C COMP VIS ECC, P734
   Cho YJ, 2018, IEEE T IMAGE PROCESS, V27, P3739, DOI 10.1109/TIP.2018.2815840
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Ge Y., 2020, INT C LEARN REPR
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Huang Y, 2020, AAAI C ART INT
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Khan K, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES (ICADIWT), P232, DOI 10.1109/ICADIWT.2014.6814687
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee KH, 2018, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2018.00571
   Leibe B., 2017, ARXIV170307737CS
   Li YJ, 2019, IEEE I CONF COMP VIS, P7918, DOI 10.1109/ICCV.2019.00801
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048
   Motiian S, 2017, IEEE I CONF COMP VIS, P5716, DOI 10.1109/ICCV.2017.609
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Qi L, 2019, IEEE I CONF COMP VIS, P8079, DOI 10.1109/ICCV.2019.00817
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Zhai Y., P IEEEC VF C COMP VI, P9021
   Zhang XY, 2019, IEEE I CONF COMP VIS, P8221, DOI 10.1109/ICCV.2019.00831
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
NR 48
TC 3
Z9 4
U1 0
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104191
DI 10.1016/j.imavis.2021.104191
EA MAY 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700001
DA 2024-07-18
ER

PT J
AU Charco, JL
   Sappa, AD
   Vintimilla, BX
   Velesaca, HO
AF Charco, Jorge L.
   Sappa, Angel D.
   Vintimilla, Boris X.
   Velesaca, Henry O.
TI Camera pose estimation in multi-view environments: From virtual
   scenarios to the real world
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Relative camera pose estimation; Domain adaptation; Siamese
   architecture; Synthetic data; Multi-view environments
AB This paper presents a domain adaptation strategy to efficiently train network architectures for estimating the relative camera pose in multi-view scenarios. The network architectures are fed by a pair of simultaneously acquired images, hence in order to improve the accuracy of the solutions, and due to the lack of large datasets with pairs of overlapped images, a domain adaptation strategy is proposed. The domain adaptation strategy consists on transferring the knowledge learned from synthetic images to real-world scenarios. For this, the networks are firstly trained using pairs of synthetic images, which are captured at the same time by a pair of cameras in a virtual environment; and then, the learned weights of the networks are transferred to the real-world case, where the networks are retrained with a few real images. Different virtual 3D scenarios are generated to evaluate the relationship between the accuracy on the result and the similarity between virtual and real scenarios & mdash;similarity on both geometry of the objects contained in the scene as well as relative pose between camera and objects in the scene. Experimental results and comparisons are provided showing that the accuracy of all the evaluated networks for estimating the camera pose improves when the proposed domain adaptation strategy is used, highlighting the importance on the similarity between virtual-real scenarios.
   (c) 2021 Published by Elsevier B.V.
C1 [Charco, Jorge L.] Univ Guayaquil, Delta & Kennedy Av,PB EC090514, Guayaquil, Ecuador.
   [Charco, Jorge L.; Sappa, Angel D.; Vintimilla, Boris X.; Velesaca, Henry O.] Escuela Super Politecn Litoral, ESPOL, Campus Gustavo Galindo Km 30-5 Via Perimetral, Guayaquil, Ecuador.
   [Sappa, Angel D.] Comp Vis Ctr, Edifici O,Campus UAB, Barcelona 08193, Spain.
C3 Universidad de Guayaquil; Escuela Superior Politecnica del Litoral;
   Autonomous University of Barcelona; Centre de Visio per Computador (CVC)
RP Charco, JL (corresponding author), Univ Guayaquil, Delta & Kennedy Av,PB EC090514, Guayaquil, Ecuador.
EM jlcharco@espol.edu.ec
RI Sappa, Angel D./A-2072-2009
OI Charco Aguirre, Jorge/0000-0002-0099-0345; Sappa,
   Angel/0000-0003-2468-0031; Vintimilla, Boris/0000-0001-8904-0209
FU ESPOL project EPASI [CIDIS-01-2018]; ESPOL project TICs4CI [FIEC162018];
   Spanish Government [TIN201789723P]; CERCA Programme/Generalitat de
   Catalunya; CYTED Network: "IberoAmerican Thematic Network on ICT
   Applications for Smart Cities" [REF-518RT0559]; Ecuador government under
   a SENESCYT scholarship [CZ050000402018]; NVIDIA Corporation
FX This work has been partially supported by the ESPOL projects EPASI
   (CIDIS-01-2018) and TICs4CI (FIEC162018) ; the Spanish Government under
   Project TIN201789723P; and the "CERCA Programme/Generalitat de
   Catalunya". The authors acknowledge the support of CYTED Network:
   "IberoAmerican Thematic Network on ICT Applications for Smart Cities"
   (REF-518RT0559) and the NVIDIA Corporation for the donation of the Titan
   Xp GPU. The first author has been supported by Ecuador government under
   a SENESCYT scholarship contract CZ050000402018.
CR Aanæs H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Charco JL, 2020, VISAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4: VISAPP, P498, DOI 10.5220/0009167604980505
   Charco JL, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P224, DOI 10.1109/SITIS.2018.00041
   Chu WS, 2013, PROC CVPR IEEE, P3515, DOI 10.1109/CVPR.2013.451
   Clevert D.A, 2015, 4 INT C LEARN REPR I
   Dornaika F, 2011, IEEE T INTELL TRANSP, V12, P954, DOI 10.1109/TITS.2011.2117420
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   En Sovann, 2018, P EUR C COMP VIS
   Gaidon A, 2016, PROC CVPR IEEE, P4340, DOI 10.1109/CVPR.2016.470
   Gebru T, 2017, IEEE I CONF COMP VIS, P1358, DOI 10.1109/ICCV.2017.151
   Gheisari M, 2015, NEUROCOMPUTING, V165, P300, DOI 10.1016/j.neucom.2015.03.020
   Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309
   Hartley R. I., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P471
   Hu JL, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629
   Iyer G, 2018, IEEE INT C INT ROBOT, P1110, DOI 10.1109/IROS.2018.8593693
   Jalal M., 2019, P C COMP VIS PATT RE
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lin YM, 2019, LECT NOTES ARTIF INT, V11671, P454, DOI 10.1007/978-3-030-29911-8_35
   Liu R, 2009, 2009 INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND MECHATRONICS AUTOMATION, VOL I, P352, DOI 10.1109/ICMTMA.2009.338
   Melekhov I, 2017, LECT NOTES COMPUT SC, V10617, P675, DOI 10.1007/978-3-319-70353-4_57
   Moulon P., 2016, OTHERS OPENMVG OPEN
   Onkarappa N, 2015, MULTIMED TOOLS APPL, V74, P3121, DOI 10.1007/s11042-013-1771-7
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Peng XC, 2016, IEEE IMAGE PROC, P3683
   Rivadeneira RE, 2019, LECT NOTES COMPUT SC, V11663, P417, DOI 10.1007/978-3-030-27272-2_37
   Sappa AD, 2006, ELECTRON LETT, V42, P745, DOI 10.1049/el:20061322
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Shalnov E., 2017, INT ARCH PHOTOGRAMME, V42
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wilson K, 2014, LECT NOTES COMPUT SC, V8691, P61, DOI 10.1007/978-3-319-10578-9_5
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhou BL, 2014, ADV NEUR IN, V27
NR 40
TC 7
Z9 7
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104182
DI 10.1016/j.imavis.2021.104182
EA APR 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Afza, F
   Khan, MA
   Sharif, M
   Kadry, S
   Manogaran, G
   Saba, T
   Ashraf, I
   Damasevicius, R
AF Afza, Farhat
   Khan, Muhammad Attique
   Sharif, Muhammad
   Kadry, Seifedine
   Manogaran, Gunasekaran
   Saba, Tanzila
   Ashraf, Imran
   Damasevicius, Robertas
TI A framework of human action recognition using length control features
   fusion and weighted entropy-variances based feature selection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pre-processing; Frames fusion; Features extraction; Features fusion;
   Features selection; Classification
ID DEEP FEATURES
AB In this article, we implement an action recognition technique based on features fusion and best feature selection. In the proposed method, HSI color transformation is performed in the first step to improve the contrast of video frames and then extract their motion features by optical flow algorithm. The frames fusion approach extracts the moving regions that find out by optical flow. After that, extract shape and texture features fused by a new parallel approach name length control features. A new Weighted Entropy-Variances approach is applied to a combined vector and selects the best of them for classification. Finally, features are passed in M-SVM for final features classification into relevant human actions. The experimental process is conducted in four famous action datasets-Weizmann, KTH, UCF Sports, and UCF YouTube, with recognition rate 97.9%, 100%, 99.3%, and 94.5%, respectively. Experimental results show that the proposed scheme performed significantly sound output concerning listed methods. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Afza, Farhat; Sharif, Muhammad] COMSATS Univ, Dept Comp Sci, Wah Cantt, Pakistan.
   [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Pakistan.
   [Kadry, Seifedine] Beirut Arab Univ, Fac Sci, Dept Math & Comp Sci, Beirut, Lebanon.
   [Manogaran, Gunasekaran] Univ Calif Davis, Davis, CA 95616 USA.
   [Manogaran, Gunasekaran] Asia Univ, Coll Informat & Elect Engn, Taichung, Taiwan.
   [Saba, Tanzila] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Ashraf, Imran] HITEC Univ, Dept Comp Engn, Museum Rd, Taxila, Pakistan.
   [Damasevicius, Robertas] Kaunas Univ Technol, Dept Software Engn, Kaunas, Lithuania.
C3 COMSATS University Islamabad (CUI); NITEC University; Beirut Arab
   University; University of California System; University of California
   Davis; Asia University Taiwan; Prince Sultan University; NITEC
   University; Kaunas University of Technology
RP Khan, MA (corresponding author), HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Pakistan.
EM attique@ciitwah.edu.pk
RI Afza, Farhat/ABG-6364-2021; Saba, Tanzila/D-4593-2018; khan,
   sajid/HGE-2406-2022; Damaševičius, Robertas/E-1387-2017; Khan, Dr.
   Muhammad Attique/AAX-2644-2021; ashraf, imran/HJA-5212-2022; Kadry,
   Seifedine/C-7437-2011; Sharif, Muhammad/ACD-2598-2022; Sharif,
   Muhammad/AAB-8376-2022
OI Saba, Tanzila/0000-0003-3138-3801; Damaševičius,
   Robertas/0000-0001-9990-1084; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; ashraf, imran/0000-0003-4480-2489; Kadry,
   Seifedine/0000-0002-1939-4842; Sharif, Muhammad/0000-0002-7258-8400; 
CR Abdelbaky A, 2020, NEURAL COMPUT APPL, V32, P12561, DOI 10.1007/s00521-020-04712-1
   Abdul-Azim HA, 2015, EGYPT INFORM J, V16, P187, DOI 10.1016/j.eij.2015.05.002
   Ahmad Tasweer., 2015, Journal of Image and Graphics, V3, DOI [DOI 10.18178/JOIG.3.2.96-101, 10.18178/joig.3.2.96-101]
   Althloothi S, 2014, PATTERN RECOGN, V47, P1800, DOI 10.1016/j.patcog.2013.11.032
   Arshad H, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12541
   Aslan MF, 2020, NEURAL COMPUT APPL, V32, P8585, DOI 10.1007/s00521-019-04365-9
   Cai LQ, 2020, NONLINEAR DYNAM, V99, P3253, DOI 10.1007/s11071-020-05468-y
   Cai Y., 2018, MULTIMED TOOLS APPL, P1
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Damasevicius R, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/4073584
   Deng, 2017, MULTIMED TOOLS APPL, P1
   John, SEC TECHN ICCST 2016, P1
   Khan FS, 2018, MACH VISION APPL, V29, P55, DOI 10.1007/s00138-017-0871-1
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Khan MA, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105986
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu J., PATT REC ICPR 2010 2, P3744
   Majd M, 2020, NEUROCOMPUTING, V396, P224, DOI 10.1016/j.neucom.2018.10.095
   Naheed N, 2020, CMES-COMP MODEL ENG, V125, P1, DOI 10.32604/cmes.2020.011380
   Nazir S, 2018, PATTERN RECOGN LETT, V103, P39, DOI 10.1016/j.patrec.2017.12.024
   Qazi HA, 2017, INT CONF INF COMMUN, P6, DOI 10.1109/ICICT.2017.8320156
   Rahman SA, 2013, J VIS COMMUN IMAGE R, V24, P217, DOI 10.1016/j.jvcir.2012.12.001
   Rashid M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125037
   Ren ZL, 2021, MULTIMED TOOLS APPL, V80, P16185, DOI 10.1007/s11042-019-08576-z
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Sharif A, 2019, CONTROL ENG APPL INF, V21, P3
   Sharif M, 2020, PATTERN ANAL APPL, V23, P281, DOI 10.1007/s10044-019-00789-0
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Thabet E, 2021, MULTIMED TOOLS APPL, V80, P5287, DOI 10.1007/s11042-020-09903-5
   Vercauteren, IACR CRYPTOLOGY EPRI
   Wang XF, 2016, MACH VISION APPL, V27, P861, DOI 10.1007/s00138-016-0746-x
   Weng ZK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0250-5
   Xiao QK, 2018, MULTIMED TOOLS APPL, V77, P6955, DOI 10.1007/s11042-017-4614-0
   Xiong, MIPPR 2017 PATTERN R
   Yao B, 2015, SOFT COMPUT, V19, P499, DOI 10.1007/s00500-014-1270-4
   Yu JH, 2020, IEEE ACCESS, V8, P43243, DOI 10.1109/ACCESS.2020.2977856
   Zhou LY, 2018, COMPUT ELECTR ENG, V68, P490, DOI 10.1016/j.compeleceng.2018.05.003
NR 41
TC 101
Z9 101
U1 1
U2 80
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104090
DI 10.1016/j.imavis.2020.104090
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700007
DA 2024-07-18
ER

PT J
AU Boutros, F
   Damer, N
   Raja, K
   Ramachandra, R
   Kirchbuchner, F
   Kuijper, A
AF Boutros, Fadi
   Damer, Naser
   Raja, Kiran
   Ramachandra, Raghavendra
   Kirchbuchner, Florian
   Kuijper, Arjan
TI Iris and periocular biometrics for head mounted displays: Segmentation,
   recognition, and synthetic data generation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Head mounted displays; Periocular; Iris; Verification and
   authentication
ID AUGMENTED REALITY; IMAGE; NETWORK
AB Augmented and virtual reality deployment is finding increasing use in novel applications. Some of these emerging and foreseen applications allow the users to access sensitive information and functionalities. Head Mounted Displays (HMD) are used to enable such applications and they typically include eye facing cameras to facilitate advanced user interaction. Such integrated cameras capture iris and partial periocular region during the interaction. This work investigates the possibility of using the captured ocular images from integrated cameras from HMD devices for biometric verification, taking into account the expected limited computational power of such devices. Such an approach can allow user to be verified in a manner that does not require any special and explicit user action. In addition to our comprehensive analyses, we present a light weight, yet accurate, segmentation solution for the ocular region captured from HMD devices. Further, we benchmark a number of well-established iris and periocular verification methods along with an in-depth analysis on the impact of iris sample selection and its effect on iris recognition performance for HMD devices. To the end, we also propose and validate an identity preserving synthetic ocular image generation mechanism that can be used for large scale data generation for training purposes or attack generation purposes. We establish the realistic image quality of generated images with high fidelity and identity preserving capabilities through benchmarking them for iris and periocular verification. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Boutros, Fadi; Damer, Naser; Kirchbuchner, Florian; Kuijper, Arjan] Fraunhofer Inst Comp Graph Res IGD, Fraunhoferstr 5, D-64283 Darmstadt, Germany.
   [Boutros, Fadi; Damer, Naser; Kirchbuchner, Florian; Kuijper, Arjan] Tech Univ Darmstadt, Math & Appl Visual Comp, Darmstadt, Germany.
   [Raja, Kiran] NTNU, Norwegian Colour & Visual Comp Lab, Gjovik, Norway.
   [Raja, Kiran; Ramachandra, Raghavendra] NTNU, Norwegian Biometr Lab, Gjovik, Norway.
C3 Fraunhofer Gesellschaft; Technical University of Darmstadt; Norwegian
   University of Science & Technology (NTNU); Norwegian University of
   Science & Technology (NTNU)
RP Damer, N (corresponding author), Fraunhofer Inst Comp Graph Res IGD, Fraunhoferstr 5, D-64283 Darmstadt, Germany.
EM naser.damer@igd.fraunhofer.de
RI Kirchbuchner, Florian/B-8982-2017
OI Kirchbuchner, Florian/0000-0003-3790-3732
FU German Federal Ministry of Education and Research; Hessen State Ministry
   for Higher Education, Research and the Arts within the National Research
   Center for Applied Cybersecurity ATHENE
FX This researchwork has been funded by the German Federal Ministry of
   Education and Research and the Hessen State Ministry for Higher
   Education, Research and the Arts within their joint support of the
   National Research Center for Applied Cybersecurity ATHENE.
CR AlGashaam F., 2015, P INT C IMAG VIS COM, P1
   Alonso-Fernandez F., 2015, BIOM FOR IWBF 2015 I, P1
   [Anonymous], 2003, Recognition of Human Iris Patterns for Biometric Identification
   [Anonymous], 2017, Seamless and secure VR: Adapting and evaluating established authentication systems for virtual reality
   [Anonymous], 2011, Signal Processing and Communication Systems (ICSPCS), 2011 5th International Conference on, DOI [10.1109/IJCB.2011.6117600, DOI 10.1109/IJCB.2011.6117600]
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Ba L.J., ABS160706450 CORR
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bao JM, 2018, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2018.00702
   Bastias D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P503, DOI 10.1109/BTAS.2017.8272735
   Bazrafkan S, 2018, NEURAL NETWORKS, V106, P79, DOI 10.1016/j.neunet.2018.06.011
   Bin Tomi A, 2011, LECT NOTES COMPUT SC, V7067, P305, DOI 10.1007/978-3-642-25200-6_29
   Boutros Fadi, 2019, IEEE INT C COMP VIS
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Bühler M, 2019, IEEE INT CONF COMP V, P4650, DOI 10.1109/ICCVW.2019.00570
   Chai WL, 2018, IEEE INT CONF AUTOMA, P130, DOI 10.1109/FG.2018.00028
   Chang H., 2018, CVPR 2018
   Chen JX, 2016, IEEE T INF FOREN SEC, V11, P1476, DOI 10.1109/TIFS.2016.2535901
   Chen L.-C., 2018, Pertanika J. Trop. Agric. Sci., P801, DOI [10.1007/978-3-030-01234-2_49, DOI 10.1007/978-3-030-01234-249, DOI 10.1007/978-3-030-01234-2_49]
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Culurciello E., ABS160602147 CORR
   Damer N., 2019, 10 IEEE INT C BIOM T
   Damer N., IEEE INT C COMP VIS
   Damer N, 2018, INT CONF BIOMETR THE
   Das A, 2019, INT CONF BIOMETR, DOI 10.1109/icb45273.2019.8987414
   Das S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P11, DOI 10.1109/CGVIS.2015.7449883
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J., 2004, International Airport Review, V8
   Daugman John., 2015, Encyclopedia of Biometrics, P998
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Garbin S.J., ABS190503702 CORR
   Gentex-Corporation, 2017, GENT INTR BIOM AUTH
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jillela R.R., 2013, HDB IRIS RECOGNITION, P281
   Joshi A, 2014, IEEE IMAGE PROC, P4977, DOI 10.1109/ICIP.2014.7026008
   Juefei-Xu F., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P201, DOI 10.1109/WACV.2012.6163051
   Juefei-Xu F, 2014, IEEE T IMAGE PROCESS, V23, P3490, DOI 10.1109/TIP.2014.2329460
   Kannala J, 2012, INT C PATT RECOG, P1363
   Karras T, 2018, P INT C LEARN REPR I
   Kim S., 2018, INT J ENG TECHNOL, V7
   Kingma D. P., 2014, arXiv
   Kishore Kumar K., 2019, Microelectronics, Electromagnetics and Telecommunications. Proceedings of the Fourth ICMEET 2018. Lecture Notes in Electrical Engineering (LNEE 521), P713, DOI 10.1007/978-981-13-1906-8_72
   Klamkin J, 2018, 2018 IEEE BICMOS AND COMPOUND SEMICONDUCTOR INTEGRATED CIRCUITS AND TECHNOLOGY SYMPOSIUM (BCICTS), P8, DOI 10.1109/BCICTS.2018.8550947
   Ko JG, 2007, ETRI J, V29, P399, DOI 10.4218/etrij.07.0206.0141
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Kupin A, 2019, LECT NOTES COMPUT SC, V11295, P55, DOI 10.1007/978-3-030-05710-7_5
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Li M., 2016, Annual IEEE Systems Conference (SysCon), P1
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lozej J, 2018, 2018 IEEE INT WORK C, P16, DOI [DOI 10.1109/IWOBI.2018.8464213, 10.1109/IWOBI.2018.8464213]
   Lozej J, 2019, I W BIOMETRIC FORENS, DOI 10.1109/iwbf.2019.8739225
   Luo B., 2019, ABS191005283 CORR
   Luo B., 2018, P 2018 IMP COLL COMP, VVolume 66, p7:1, DOI [10.4230/OASIcs.ICCSW.2018.7, DOI 10.4230/OASICS.ICCSW.2018.7]
   Ma DD, 2018, IEEE IMAGE PROC, P2087, DOI 10.1109/ICIP.2018.8451520
   Ma M., 2014, Virtual, Augmented Reality and Serious Games for Healthcare 1, V68, P1, DOI DOI 10.1007/978-3-642-54816-1_1
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Mahalingam G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-36
   Mechrez R, 2018, LECT NOTES COMPUT SC, V11218, P800, DOI 10.1007/978-3-030-01264-9_47
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Miyazawa K, 2008, IEEE T PATTERN ANAL, V30, P1741, DOI 10.1109/TPAMI.2007.70833
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Nee AYC, 2012, CIRP ANN-MANUF TECHN, V61, P657, DOI 10.1016/j.cirp.2012.05.010
   Ng R. Y. F., 2008, EFFECTIVE SEGMENTATI
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Nianfeng Liu, 2016, 2016 International Conference on Biometrics (ICB), DOI 10.1109/ICB.2016.7550055
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Olade I, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P1997, DOI 10.1109/SmartWorld.2018.00334
   Ortega-Garcia J, 2010, IEEE T PATTERN ANAL, V32, P1097, DOI 10.1109/TPAMI.2009.76
   Park M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICUWB 2009), P1, DOI 10.1109/ICUWB.2009.5288737
   Peer Peter., 2005, CVL FACE DATABASE
   Pereira TD, 2015, INT CONF BIOMETR THE
   Poelman R., 2012, P ACM 2012 C COMP SU, P1267, DOI [10.1145/2145204.2145394, DOI 10.1145/2145204.2145394]
   Poudel R. P. K., 2019, ABS190204502 CORR
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Proença H, 2016, ADV COMPUT VIS PATT, P321, DOI 10.1007/978-1-4471-6784-6_15
   Raghavendra R, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P155, DOI 10.1109/ACPR.2013.22
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Rathgeb C, 2010, LECT NOTES COMPUT SC, V6112, P266, DOI 10.1007/978-3-642-13775-4_27
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ross A, 2010, COMPUTER, V43, P30, DOI 10.1109/MC.2010.44
   Ross Arun, 2012, Proceedings of the IEEE 5th International Conference on Biometrics, pag, P446
   Rot P, 2018, 2018 IEEE international work conference on bioinspired intelligence (IWOBI), P1, DOI 10.1109/IWOBI.2018.8464133
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Shah S, 2009, IEEE T INF FOREN SEC, V4, P824, DOI 10.1109/TIFS.2009.2033225
   Shen J., P IEEE INT C COMP VI, P50
   Shen YJ, 2018, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2018.00092
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith B.A., 2013, P 26 ANN ACM S USER, P271, DOI DOI 10.1145/2501988.2501994
   Smolensky P., 1986, Information processing in dynamical systems: Foundations of harmony theory
   Streefkerk Jan Willem, 2013, Virtual, Augmented and Mixed Reality. Systems and Applications. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings, Part II: LNCS 8022, P330, DOI 10.1007/978-3-642-39420-1_35
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   van den Oord A, 2016, PR MACH LEARN RES, V48
   van den Oord Aaron, 2016, ARXIV160605328
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Woodard D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P162, DOI DOI 10.1109/CVPRW.2010.5544621
   Woodard Damon L., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P201, DOI 10.1109/ICPR.2010.58
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
NR 114
TC 29
Z9 29
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104007
DI 10.1016/j.imavis.2020.104007
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800013
DA 2024-07-18
ER

PT J
AU Shen, DH
   Zareapoor, M
   Yang, J
AF Shen, Donghao
   Zareapoor, Masoumeh
   Yang, Jie
TI Infrared and visible image fusion via global variable consensus
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image fusion; Infrared; Consensus; Total variation; ADMM
ID ALGORITHMS; TRANSFORM; COLOR
AB In this paper, we propose an infrared and visible image fusion framework based on the consensus problem. Most current infrared and visible image fusion models aim to transfer only one characteristic of each source domain to the final fusion result. This mechanism limits the performances of fusion algorithms under different conditions. We present a general fusion framework based to solve the global variable consensus optimization problem through altering direction method of multipliers (ADMM). We identified that combination of the local operators allows smooth transfer of superficial characteristics of the source domain into the fusion result. Our modification of ADMM enables us to expand the fusion algorithm's compatibility by tackling various setting including dimensionality, data types and style. The qualitative and quantitative experiment results demonstrate that, compared with other state-of-the-art algorithms, the proposed method can provide competitive performance in transferring features, structures, and information from source images to fusion results. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Shen, Donghao; Zareapoor, Masoumeh; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
EM jieyang@sjtu.edu.cn
RI Yang, Jie/JCD-9867-2023; Zareapoor, Dr. Masoumeh/AAE-6067-2019
OI Zareapoor, Dr. Masoumeh/0000-0002-3991-0584; Zareapoor,
   Masoumeh/0000-0002-7569-9018
FU NSFC, China [61876107, U1803261]; Committee of Science and Technology,
   Shanghai, China [19510711200]
FX This research is partly supported by NSFC, China (No: 61876107,
   U1803261), Committee of Science and Technology, Shanghai, China (No.
   19510711200).
CR [Anonymous], 2015, International Journal of Signal Processing, Image Processing and Pattern Recognition
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen J, 2020, INFORM SCIENCES, V508, P64, DOI 10.1016/j.ins.2019.08.066
   Chipman L. J., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P248, DOI 10.1109/ICIP.1995.537627
   Cvejic N., 2005, INT J SIGNAL PROCESS, V2, P178
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Donoho DL, 2001, NETWORK-COMP NEURAL, V12, P371, DOI 10.1088/0954-898X/12/3/308
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Han J, 2007, PATTERN RECOGN, V40, P1771, DOI 10.1016/j.patcog.2006.11.010
   Kumar P, 2006, LECT NOTES COMPUT SC, V4338, P528
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu CH, 2017, INFRARED PHYS TECHN, V83, P94, DOI 10.1016/j.infrared.2017.04.018
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Nava R., 2007, Proc. SPIE, V34, P94
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Schizas ID, 2008, IEEE T SIGNAL PROCES, V56, P350, DOI 10.1109/TSP.2007.906734
   Simone G., 2002, Information Fusion, V3, P3, DOI 10.1016/S1566-2535(01)00056-2
   Singh R, 2008, PATTERN RECOGN, V41, P880, DOI 10.1016/j.patcog.2007.06.022
   Toet A, 2017, DATA BRIEF, V15, P249, DOI 10.1016/j.dib.2017.09.038
   Wang J, 2014, INFRARED PHYS TECHN, V67, P477, DOI 10.1016/j.infrared.2014.09.019
   Wang KP, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19070306
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
   Zhu H, 2010, IEEE T WIREL COMMUN, V9, P2044, DOI 10.1109/TWC.2010.06.090890
NR 38
TC 4
Z9 4
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104037
DI 10.1016/j.imavis.2020.104037
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800002
DA 2024-07-18
ER

PT J
AU Cao, MW
   Zheng, LP
   Jia, W
   Liu, XP
AF Cao, Mingwei
   Zheng, Liping
   Jia, Wei
   Liu, Xiaoping
TI Constructing big panorama from video sequence based on deep local
   feature
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Panorama; Deep local feature; Feature tracking; Image stitching; Image
   blending
ID IMAGE; WARPS
AB Constructing high-quality panorama is a fundamental task in both computer vision and computer graphics communities, thus, leading to many image stitching approaches for panorama construction. However, panorama constructed by traditional image stitching has a limited angle of view and has an expensively computational cost. To defend the issues, in this paper, we proposed to use video sequence as input for constructing big panorama, resulting in a high-quality panoramic image, the presented method is built on the stabilized video and robust feature tracking method. Specifically, the input video sequences are captured by moving hand cameras which can be any type of consumer-level camera. To mitigate the affections from rolling shutters in videos, a novel video stabilization method is introduced to filter the unstable camera's path, then resulting in a stabilized video for panorama construction. Additionally, a deep local feature-based feature tracking method is proposed to produce feature correspondences between consecutive video frames for camera motion estimation used in both video stabilization and image stitching. Finally, a comprehensive experiment conducted on the benchmarking datasets is presented to demonstrate the effectiveness of the proposed method. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Cao, Mingwei; Zheng, Liping; Jia, Wei; Liu, Xiaoping] Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 230009, Peoples R China.
   [Cao, Mingwei; Zheng, Liping; Jia, Wei; Liu, Xiaoping] Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Peoples R China.
   [Cao, Mingwei; Zheng, Liping; Jia, Wei; Liu, Xiaoping] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Cao, MW (corresponding author), Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 230009, Peoples R China.
EM caomw@hfut.edu.cn; zhenglp@hfut.edu.cn; jiawei@hfut.edu.cn;
   liu@hfut.edu.cn
FU National Natural Science Foundation [61972128,61802103, 61877016,
   61602146, 61673157]; China Postdoctoral Science Foundation [:2018
   M632522]; Fundamental Research Funds for the Central Universities
   [PA2019GDPK0071, JZ2018HGBH0280, PA2018GDQT0014]; Key Research and
   Development Program in Anhui Province [1804a09020036]
FX The authors gratefully acknowledge the support of the National Natural
   Science Foundation (Grant No.: 61972128,61802103, 61877016, 61602146 and
   61673157), China Postdoctoral Science Foundation (Grant No.:2018
   M632522), Fundamental Research Funds for the Central Universities (Grant
   No.: PA2019GDPK0071, JZ2018HGBH0280, and PA2018GDQT0014), and Key
   Research and Development Program in Anhui Province (Grant No.:
   1804a09020036).
CR Agarwala A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239545, 10.1145/1276377.1276495]
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], 2011, PROC CVPR IEEE
   [Anonymous], 2015, ARXIV151008012
   ASSAF Z, 2006, IEEE T IMAGE PROCESS, V15, P969
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brown M, 2005, PROC CVPR IEEE, P510
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Cao MW, 2018, NEURAL COMPUT APPL, V29, P1383, DOI 10.1007/s00521-017-3032-6
   Cao MW, 2018, IEEE ACCESS, V6, P72939, DOI 10.1109/ACCESS.2018.2879337
   Cao MW, 2019, OPT LASER TECHNOL, V110, P120, DOI 10.1016/j.optlastec.2018.05.036
   Cao MW, 2017, MULTIMED TOOLS APPL, V76, P21843, DOI 10.1007/s11042-017-4581-5
   CHANG CH, 2014, PROC CVPR IEEE, P3254, DOI DOI 10.1109/CVPR.2014.422
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Chum O, 2012, INT C PATT RECOG, P3236
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   DeTone Daniel, 2016, ARXIV160603798
   Farbman Z, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024209
   Gao J., 2013, EUROGRAPHICS
   Guo H, 2016, IEEE T IMAGE PROCESS, V25, P5491, DOI 10.1109/TIP.2016.2607419
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Havlena M, 2014, LECT NOTES COMPUT SC, V8691, P46, DOI 10.1007/978-3-319-10578-9_4
   He BT, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010007
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3144455
   Ho T, 2017, INT CONF ACOUST SPEE, P2172, DOI 10.1109/ICASSP.2017.7952541
   JIANGYT, 2015, P 2 INT S MAN INN, P42
   JIAYA J, 2005, 10 IEEE INT C COMP V, V1652, P1651
   Joo K, 2015, IEEE IMAGE PROC, P1175, DOI 10.1109/ICIP.2015.7350985
   Lan RS, 2020, NEURAL COMPUT APPL, V32, P4317, DOI 10.1007/s00521-018-03968-y
   Lan RS, 2020, IEEE T CYBERNETICS, V50, P1498, DOI 10.1109/TCYB.2018.2880290
   Lee J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925983
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Li J, 2018, IEEE T MULTIMEDIA, V20, P1672, DOI 10.1109/TMM.2017.2777461
   Li N, 2018, IEEE T MULTIMEDIA, V20, P1365, DOI 10.1109/TMM.2017.2771566
   Lin CC, 2015, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2015.7298719
   Lin HS, 2019, IEEE T CIRC SYST VID, V29, P915, DOI 10.1109/TCSVT.2018.2818186
   Lin KM, 2016, LECT NOTES COMPUT SC, V9907, P370, DOI 10.1007/978-3-319-46487-9_23
   Liu F., 2008, P 16 ACM INT C MULTI, P329
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowry S, 2018, IEEE INT CONF ROBOT, P7262
   Lv ZH, 2017, NEUROCOMPUTING, V254, P71, DOI 10.1016/j.neucom.2016.07.078
   Lv ZH, 2016, IEEE INTERNET THINGS, V3, P1015, DOI 10.1109/JIOT.2016.2546307
   Mishkin D, 2015, COMPUT VIS IMAGE UND, V141, P81, DOI 10.1016/j.cviu.2015.08.005
   Nie YW, 2018, IEEE T IMAGE PROCESS, V27, P164, DOI 10.1109/TIP.2017.2736603
   Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794
   Perazzi F, 2015, COMPUT GRAPH FORUM, V34, P57, DOI 10.1111/cgf.12541
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zhang GF, 2016, IEEE T IMAGE PROCESS, V25, P3099, DOI 10.1109/TIP.2016.2535225
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhi Q, 2012, IEEE T IMAGE PROCESS, V21, P366, DOI 10.1109/TIP.2011.2162743
   2003, ACM SIGGRAPH 2003 PA, P313
NR 58
TC 1
Z9 1
U1 2
U2 52
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2020
VL 101
AR 103972
DI 10.1016/j.imavis.2020.103972
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NP4HG
UT WOS:000570137900002
DA 2024-07-18
ER

PT J
AU Bu, QR
   Zeng, K
   Wang, R
   Feng, J
AF Bu, Qirong
   Zeng, Kai
   Wang, Rui
   Feng, Jun
TI Multi-depth dilated network for fashion landmark detection with
   batch-level online hard keypoint mining
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fashion landmark detection; Convolutional neural network; Deep learning
AB Deep learning has been applied to fashion landmark detection in recent years, and great progress has been made. However, the detection of hard keypoints, such as those which are occluded or invisible, remains challenging and must be addressed. To tackle this problem, in the feature exaction level a novel Multi-Depth Dilated (MDD) block which is composed of different numbers of dilated convolutions in parallel and a Multi-Depth Dilated Network (MDDNet) constructed by MDD blocks are proposed in this paper, and in the training level a network training method of Batch-level Online Hard Keypoint Mining (B-OHKM) is proposed. During the training of network, each clothing keypoint is one-to-one corresponding to the related loss value calculated at that keypoint. The greater the loss of the keypoint, the more difficult it is for the network to detect that keypoint. In that way, hard keypoints can be effectively mined, so that the network can be trained in a targeted manner to improve the performance of hard keypoints. The results of experiments on two large-scale fashion benchmark datasets demonstrate that the proposed MDDNet that uses the MDD block and B-OHKM method achieves state-of-the-art results. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Bu, Qirong; Zeng, Kai; Wang, Rui; Feng, Jun] Northwest Univ, Dept Comp Sci, Xian, Peoples R China.
C3 Northwest University Xi'an
RP Feng, J (corresponding author), Northwest Univ, Dept Comp Sci, Xian, Peoples R China.
EM fengjun@nwu.edu.cn
FU National Key R&D Program of China [2017YFB1002504]; Shaanxi
   international science and technology cooperation and exchange program of
   China [2017KW-010]
FX This work is supported by the National Key R&D Program of China under
   grant 2017YFB1002504, Shaanxi international science and technology
   cooperation and exchange program of China (2017KW-010).
CR [Anonymous], 2016, P INT C LEARN REPR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2011, P 4 INT C ART INT ST
   [Anonymous], 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00742
   Bossard Lukas, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P321, DOI 10.1007/978-3-642-37447-0_25
   Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44
   Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169
   Han XT, 2017, IEEE I CONF COMP VIS, P1472, DOI 10.1109/ICCV.2017.163
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Kiapour MH, 2014, LECT NOTES COMPUT SC, V8689, P472, DOI 10.1007/978-3-319-10590-1_31
   Kingma D. P., 2014, arXiv
   Li YX, 2019, IEEE INT CON MULTI, P820, DOI 10.1109/ICME.2019.00146
   Liang XD, 2017, IEEE T PATTERN ANAL, V39, P115, DOI 10.1109/TPAMI.2016.2537339
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Liu ZW, 2016, LECT NOTES COMPUT SC, V9906, P229, DOI 10.1007/978-3-319-46475-6_15
   Ma Xindian, 2019, Advances in Neural Information Processing Systems, V32, P1, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Simo-Serra E, 2015, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2015.7298688
   Simonyan K., 2014, 14091556 ARXIV
   Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449
   Wang XM, 2011, J BIOMED BIOTECHNOL, P1, DOI 10.1155/2011/419343
   Yamaguchi K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P773, DOI 10.1145/2647868.2654958
   Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yan SJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P172, DOI 10.1145/3123266.3123276
   Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407
NR 27
TC 3
Z9 3
U1 4
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2020
VL 99
AR 103930
DI 10.1016/j.imavis.2020.103930
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LZ3LW
UT WOS:000541130800005
DA 2024-07-18
ER

PT J
AU Chen, DY
   Wang, PT
   Yue, LY
   Zhang, YX
   Jia, T
AF Chen, Dongyue
   Wang, Pengtao
   Yue, Lingyi
   Zhang, Yuxin
   Jia, Tong
TI Anomaly detection in surveillance video based on bidirectional
   prediction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Anomaly detection; Bidirectional prediction; Sliding window; U-Net
ID ABNORMAL EVENT DETECTION; HISTOGRAMS
AB With the development of information technology and the popularization of monitoring network, how to quickly and automatically detect abnormal behaviors in surveillance video is becoming more and more important for public security and smart city. The emergence of deep learning has greatly promoted the development of anomaly detection and much remarkable work has been presented on this topic. However, the existing approaches for anomaly detection generally encounter problems such as insufficient utilization of motion patterns and instability on different datasets. To improve the performance of anomaly detection in surveillance video, we propose a framework based on bidirectional prediction, which predicts the same target frame by the forward and the backward prediction subnetworks, respectively. Then the loss function is constructed based on the real target frame and its bidirectional prediction frame. Furthermore, we also propose an anomaly score estimation method based on the sliding window scheme which focuses on the foregrounds of the prediction error map. The comparison with the state-of-the-art shows that the proposed model outperforms most competing models on different video surveillance datasets. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Chen, Dongyue; Wang, Pengtao; Yue, Lingyi; Zhang, Yuxin; Jia, Tong] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
   [Chen, Dongyue; Jia, Tong] Northeastern Univ, Minist Educ, Key Lab Data Analyt & Optimizat Smart Ind, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Jia, T (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.; Jia, T (corresponding author), Northeastern Univ, Minist Educ, Key Lab Data Analyt & Optimizat Smart Ind, Shenyang 110819, Liaoning, Peoples R China.
EM jiatong@ise.neu.edu.cn
RI wang, pengtao/D-8289-2016
OI wang, pengtao/0000-0001-8371-5850
FU National Natural Science Foundation of China [U1613214]; National Key
   Research and Development Program of China [2018YFB1404101]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1613214 and the National Key Research
   and Development Program of China under Grant 2018YFB1404101.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   [Anonymous], Deep autoencoding gaussian mixture model for unsupervised anomaly detection. Proceedings of the International Conference on Learning Representations (ICLR); 2018
   [Anonymous], P IEEE C COMP VIS PA
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Chu WQ, 2019, IEEE T MULTIMEDIA, V21, P246, DOI 10.1109/TMM.2018.2846411
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Goodfellow Ian, ADV NEURAL INFORM PR
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jinshu Ji, 2018, Multi-disciplinary Trends in Artificial Intelligence. 12th International Conference, MIWAI 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11248), P69, DOI 10.1007/978-3-030-03014-8_6
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kolarik M, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P643, DOI [10.1109/TSP.2019.8768829, 10.1109/tsp.2019.8768829]
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Smeureanu S, 2017, LECT NOTES COMPUT SC, V10485, P779, DOI 10.1007/978-3-319-68548-9_70
   Sun QR, 2017, PATTERN RECOGN, V64, P187, DOI 10.1016/j.patcog.2016.09.016
   Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003
   Wang L, 2018, IEEE IMAGE PROC, P2276, DOI 10.1109/ICIP.2018.8451070
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xu K., 2018, PROCEEDINGS2018 11 I
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zhang Y, 2016, PATTERN RECOGN, V59, P302, DOI 10.1016/j.patcog.2015.11.018
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
NR 35
TC 53
Z9 56
U1 3
U2 50
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2020
VL 98
AR 103915
DI 10.1016/j.imavis.2020.103915
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR9US
UT WOS:000536040700003
DA 2024-07-18
ER

PT J
AU Aziz, F
   Labbani-Igbida, O
   Radgui, A
   Tamtaoui, A
AF Aziz, Fatima
   Labbani-Igbida, Ouiddad
   Radgui, Amina
   Tamtaoui, Ahmed
TI A Riemannian approach for free-space extraction and path planning using
   catadioptric omnidirectional vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Catadioptric vision; Riemannian metric; Geodesic distance; Free-space
   segmentation; Path planning
AB This paper presents a Riemannian approach for free-space extraction and path planning using color catadioptric vision. The problem is formulated considering color catadioptric images as Riemannian manifolds and solved using the Riemannian Eikonal equation with an anisotropic fast marching numerical scheme. This formulation allows the integration of adapted color and spatial metrics in an incremental process. First, the traversable ground (namely free-space) is delimited using a color structure tensor built on the multidimensional components of the catadioptric image. Then, the Eikonal equation is solved in the image plane incorporating a generic metric tensor for central catadioptric systems. This built Riemannian metric copes with the geometric distortions in the catadioptric image plane introduced by the curved mirror in order to compute the geodesic distance map and the shortest path between image points. We present comparative results using Euclidean and Riemannian distance transforms and show the effectiveness of the Riemannian approach to produce safest path planning. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Aziz, Fatima; Labbani-Igbida, Ouiddad] Univ Limoges, XLIM Inst, UMR CNRS 7252, Parc Ester Technopole,16 Rue Atlantis, F-87068 Limoges, France.
   [Aziz, Fatima; Radgui, Amina; Tamtaoui, Ahmed] Inst Natl Postes & Telecommun, STRS Lab, 2 Ave Allal Fassi, Rabat 10100, Morocco.
C3 Universite de Limoges; Centre National de la Recherche Scientifique
   (CNRS)
RP Labbani-Igbida, O (corresponding author), Univ Limoges, XLIM Inst, UMR CNRS 7252, Parc Ester Technopole,16 Rue Atlantis, F-87068 Limoges, France.
EM fatima.aziz@unilim.fr; ouiddad.labbani-igbida@unilim.fr;
   radgui@inpt.ac.ma; tamtaoui@inpt.ac.ma
CR Ahmed S, 2011, SIAM J SCI COMPUT, V33, P2402, DOI 10.1137/10080258X
   [Anonymous], 2008, OPTIMAL CONTROL VISC
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Aziz F, 2018, COMPUT VIS IMAGE UND, V176, P54, DOI 10.1016/j.cviu.2018.09.002
   Aziz F, 2016, IEEE IMAGE PROC, P1594, DOI 10.1109/ICIP.2016.7532627
   Bagnerini P, 2001, INT SER NUMER MATH, V140, P109
   Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364
   Barreto JP, 2006, COMPUT VIS IMAGE UND, V103, P208, DOI 10.1016/j.cviu.2006.06.003
   Bogdanova I, 2007, IEEE T IMAGE PROCESS, V16, P1888, DOI 10.1109/TIP.2007.899008
   Cai CT, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0240-z
   CRANDALL MG, 1983, T AM MATH SOC, V277, P1, DOI 10.2307/1999343
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Estépar RSJ, 2005, LECT NOTES COMPUT SC, V3804, P613
   Gaspar J, 2000, IEEE T ROBOTIC AUTOM, V16, P890, DOI 10.1109/70.897802
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Geyer C, 2000, EUROPEAN C COMPUTER, V2000, P445
   Hoch P, 2002, SIAM J SCI COMPUT, V23, P2055, DOI 10.1137/S1064827599360182
   Junxian Dong, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P861, DOI 10.1109/ICMA.2018.8484410
   Khomutenko B, 2016, IEEE ROBOT AUTOM LET, V1, P137, DOI 10.1109/LRA.2015.2502921
   Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431
   Ko YJ, 2018, J MATH IMAGING VIS, V60, P503, DOI 10.1007/s10851-017-0770-0
   Krishnamoorthy V, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2761, DOI 10.1109/ICACCI.2016.7732480
   Lee John M, 2006, Riemannian manifolds: an introduction to curvature, V176
   Li FY, 2008, J COMPUT PHYS, V227, P8191, DOI 10.1016/j.jcp.2008.05.018
   Li HY, 2014, ADV SOC SCI EDUC HUM, V9, P127
   Mantegazza C, 2003, APPL MATH OPT, V47, P1, DOI 10.1007/s00245-002-0736-4
   Marie R, 2014, IEEE INT CONF ROBOT, P4451, DOI 10.1109/ICRA.2014.6907508
   Marie R, 2013, 2013 IEEE WORKSHOP ON ROBOT VISION (WORV), P191, DOI 10.1109/WORV.2013.6521937
   Merveilleux P, 2011, IEEE INT CONF ROBOT
   Mukuddem-Petersen J, 2006, PROCEEDINGS OF THE SIXTH IASTED INTERNATIONAL CONFERENCE ON MODELLING, SIMULATION, AND OPTIMIZATION, P171
   Peyré G, 2009, FOUND TRENDS COMPUT, V5, DOI 10.1561/0600000029
   Peyré G, 2009, COMPUT METH APPL SCI, V13, P29
   Plataniotis K. N., 2013, Color image processing and applications
   Puig L, 2011, IEEE I CONF COMP VIS, P1599, DOI 10.1109/ICCV.2011.6126420
   Sethian J.A., 2003, Journal of Computing and Information Technology, V11, P1
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Van de Weijer J, 2006, IEEE T IMAGE PROCESS, V15, P118, DOI 10.1109/TIP.2005.860343
   Ying XG, 2004, LECT NOTES COMPUT SC, V3021, P442
NR 39
TC 2
Z9 2
U1 4
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103872
DI 10.1016/j.imavis.2020.103872
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000002
OA Bronze
DA 2024-07-18
ER

PT J
AU Lin, FQ
   Chou, Y
   Martinez, T
AF Lin, Fanqing
   Chou, Yao
   Martinez, Tony
TI Flow Adaptive Video Object Segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video object segmentation; Optical flow; Online adaptation;
   Semi-supervised; Interactive; Object tracking
AB We tackle the task of semi-supervised video object segmentation, i.e. pixel-level object classification of the images in video sequences using very limited ground truth training data of its corresponding video. We present FLow Adaptive Video Object Segmentation, an efficient pipeline based on a novel online adaptation algorithm that utilizes optical flow, capable of tracking objects effectively throughout videos. Comparing with most of the recent deep learning based approaches that trade efficiency for accuracy, we provide extensive complexity analysis and additionally demonstrate that FLAVOS is natural for real world applications by introducing an interactive pipeline that enables the user to provide feedback for online training. Our method achieves state-of-the-art accuracy on three challenging benchmark datasets and nearly ground-truth level segmentation results with interactive user feedback. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Lin, Fanqing; Chou, Yao; Martinez, Tony] Brigham Young Univ, 3361 TMCB, Provo, UT 84602 USA.
C3 Brigham Young University
RP Lin, FQ (corresponding author), Brigham Young Univ, 3361 TMCB, Provo, UT 84602 USA.
EM flin2@byu.edu; yaochou@byu.edu; martinez@cs.byu.edu
RI Chou, Yao/ABH-5192-2020
CR [Anonymous], 2016, ARXIV161110080
   [Anonymous], CVPR WORKSH
   [Anonymous], CVPR WORKSH
   [Anonymous], CVPR WORKSH
   [Anonymous], CVPR WORKSH
   [Anonymous], ARXIV160506885
   [Anonymous], ARXIV180100269
   [Anonymous], 2017, CVPR WORKSHOPS
   [Anonymous], 2015, P 2015 IEEE C COMPUT
   [Anonymous], 2009, PROC IEEE C COMPUT V
   [Anonymous], P ACM SIGGRAPH
   [Anonymous], 2017, CVPR
   [Anonymous], CVPR WORKSH
   [Anonymous], 2015, ICCV
   [Anonymous], CVPR
   [Anonymous], CVPR WORKSH
   Bao LC, 2018, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2018.00626
   Bertasius G., 2016, CVPR
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Khoreva Anna, 2017, ARXIV170309554
   Kokkinos I., 2016, ICLR
   Krahenbuhl P., 2011, NIPS
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Maninis K.-K., 2018, PAMI
   Oh SeoungWug, 2018, CVPR
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Pont-Tuset J., 2017, ARXIV170400675
   Pont-Tuset J., 2018, ARXIV180300557
   Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065
   Price BL, 2009, IEEE I CONF COMP VIS, P779, DOI 10.1109/ICCV.2009.5459293
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Simonyan K., 2014, 14091556 ARXIV
   Voigtlaender P., 2017, BMVC
   Zagoruyko S., 2016, BMVC, P1
NR 43
TC 14
Z9 14
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103864
DI 10.1016/j.imavis.2019.103864
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900001
DA 2024-07-18
ER

PT J
AU Li, XH
   Grandvalet, Y
   Davoine, F
   Cheng, JC
   Cui, Y
   Zhang, H
   Belongie, S
   Tsai, YH
   Yang, MH
AF Li, Xuhong
   Grandvalet, Yves
   Davoine, Franck
   Cheng, Jingchun
   Cui, Yin
   Zhang, Hang
   Belongie, Serge
   Tsai, Yi-Hsuan
   Yang, Ming-Hsuan
TI Transfer learning in computer vision tasks: Remember where you come from
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Transfer learning; Parameter regularization; Computer vision
AB Fine-tuning pre-trained deep networks is a practical way of benefiting from the representation learned on a large database while having relatively few examples to train a model. This adjustment is nowadays routinely performed so as to benefit of the latest improvements of convolutional neural networks trained on large databases. Fine-tuning requires some form of regularization, which is typically implemented by weight decay that drives the network parameters towards zero. This choice conflicts with the motivation for fine-tuning, as starting from a pre-trained solution aims at taking advantage of the previously acquired knowledge. Hence, regularizers promoting an explicit inductive bias towards the pre-trained model have been recently proposed. This paper demonstrates the versatility of this type of regularizer across transfer learning scenarios. We replicated experiments on three state-of-the-art approaches in image classification, image segmentation, and video analysis to compare the relative merits of regularizers. These tests show systematic improvements compared to weight decay. Our experimental protocol put forward the versatility of a regularizer that is easy to implement and to operate that we eventually recommend as the new baseline for future approaches to transfer learning relying on fine-tuning. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Li, Xuhong; Grandvalet, Yves; Davoine, Franck] Univ Technol Compiegne, Alliance Sorbonne Univ, CNRS, Heudiasyc,UMR, F-7253 Compiegne, France.
   [Cheng, Jingchun] Tsinghua Univ, Beijing, Peoples R China.
   [Cui, Yin; Belongie, Serge] Cornell Univ, Ithaca, NY 14853 USA.
   [Zhang, Hang] Amazon Inc, Seattle, WA USA.
   [Tsai, Yi-Hsuan] NEC Labs Amer, Princeton, NJ USA.
   [Yang, Ming-Hsuan] Univ Calif, Merced, CA USA.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Technologie de Compiegne; Tsinghua University; Cornell University;
   Amazon.com; NEC Corporation; University of California System; University
   of California Merced
RP Li, XH (corresponding author), Univ Technol Compiegne, Alliance Sorbonne Univ, CNRS, Heudiasyc,UMR, F-7253 Compiegne, France.
EM xuhong.li@hds.utc.fr
RI DAVOINE, FRANCK/JRX-3253-2023; Yang, Ming-Hsuan/T-9533-2019; Cheng,
   Jingchun/AEJ-7497-2022
OI Yang, Ming-Hsuan/0000-0003-4848-2304; Belongie,
   Serge/0000-0002-0388-5217; Davoine, Franck/0000-0002-8587-6997
FU China Scholarship Council; PEPS grant through the DESSTOPT project;
   Institute of Information Science and their Interactions (INS2I) of the
   CNRS, France; NVIDIA Corporation
FX This work was carried out with the supports of the China Scholarship
   Council and of a PEPS grant through the DESSTOPT project jointly managed
   by the National Institute of Mathematical Sciences and their
   Interactions (INSMI) and the Institute of Information Science and their
   Interactions (INS2I) of the CNRS, France. It was carried out in the
   framework of SIVALab, a joint laboratory between Renault and Heudiasyc
   (UTC/CNRS). We acknowledge the support of NVIDIA Corporation with the
   donation of GPUs used for this research.
CR [Anonymous], 2015, INT C LEARNING REPRE
   [Anonymous], P BRIT MACHINE VISIO
   [Anonymous], 2010, CALTECH UCSD BIRDS
   [Anonymous], P EUROPEAN C COMPUTE
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], P EUROPEAN C COMPUTE
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81
   Cui Y, 2018, PROC CVPR IEEE, P4109, DOI 10.1109/CVPR.2018.00432
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Ge WF, 2017, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2017.9
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hu HX, 2017, PROC CVPR IEEE, P2280, DOI 10.1109/CVPR.2017.245
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li Xuhong., INT C MACHINE LEARNI
   Li ZZ, 2016, LECT NOTES COMPUT SC, V9908, P614, DOI 10.1007/978-3-319-46493-0_37
   Liao H, 2013, INT CONF ACOUST SPEE, P7947, DOI 10.1109/ICASSP.2013.6639212
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lu Xiaoyi., 2014, High-Performance Interconnects (HOTI), 2014 IEEE 22nd Annual Symposium on, P9
   Luc Pauline, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P593, DOI 10.1007/978-3-030-01240-3_36
   Luo Y, 2018, PROC CVPR IEEE, P155, DOI 10.1109/CVPR.2018.00024
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Miceli-Barone Antonio Valerio, 2017, P 2017 C EMP METH NA, P1489, DOI DOI 10.18653/V1/D17-1156
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042
   Srebro N, 2005, LECT NOTES COMPUT SC, V3559, P545, DOI 10.1007/11503415_37
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914
   Van Horn G, 2015, PROC CVPR IEEE, P595, DOI 10.1109/CVPR.2015.7298658
   Xie D, 2017, PROC CVPR IEEE, P5075, DOI 10.1109/CVPR.2017.539
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
NR 47
TC 45
Z9 47
U1 1
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103853
DI 10.1016/j.imavis.2019.103853
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000001
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Lu, MQ
   Hu, YC
   Lu, XB
AF Lu, Mingqi
   Hu, Yaocong
   Lu, Xiaobo
TI Dilated Light-Head R-CNN using tri-center loss for driving behavior
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Driving behavior; Dilated convolution; Tri-center loss;
   Positive-sensitive Rol alignment
ID TRANSFORM; POSTURES
AB Unsafe driving behavior causes many traffic accidents, resulting in serious casualties and property losses. It is observed that what the driver is doing can be revealed from the clues on the image, such as the hand with a cigarette. However, the existing behavior recognition approaches are not ideal for distinguishing driving behavior with only local differences. In this paper, we recognize driving behavior by detecting the action-specific parts and propose Dilated Light-Head R-CNN (DL-RCNN) approach, which uses dilated convolution to ensure image resolution for critical details. The technical novelty includes: a position-sensitive Rol alignment to improve the perception of small objects, and tri-center loss to enforce similarity between intra-class features and difference between features of distinct classes. We also adopt two strategies including online hard example mining and proper calibration of key parameters. The evaluation results on the public Kaggle-driving data set and self-built data set show that DL-RCNN achieves state-of-the-art performance in recognizing driving behavior. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Lu, Mingqi; Hu, Yaocong; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Lu, Mingqi; Hu, Yaocong; Lu, Xiaobo] Southeast Univ, Key Lab Measurement & Control CSE, Minist Educ, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
FU National Natural Science Foundation of China [61871123]; Jiangsu
   Provincial Key Research and Development Program [BE2016739]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
FX The authors would like to thank the editor and the anonymous reviewers
   for their valuable comments and constructive suggestions. This work was
   supported by the National Natural Science Foundation of China (No.
   61871123), Jiangsu Provincial Key Research and Development Program (No.
   BE2016739) and a Project Funded by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions.
CR [Anonymous], NIPS
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Delaitre Vincent, 2011, NIPS
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2015.284
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hu J, 2017, IEEE T VEH TECHNOL, V66, P6645, DOI 10.1109/TVT.2017.2660497
   Hu YQ, 2018, MULTIVAR BEHAV RES, V53, P925, DOI 10.1080/00273171.2018.1503941
   Khan FS, 2015, IEEE T IMAGE PROCESS, V24, P4422, DOI 10.1109/TIP.2015.2465147
   Koesdwiady A, 2017, LECT NOTES COMPUT SC, V10317, P11, DOI 10.1007/978-3-319-59876-5_2
   Krizhevsky A., 2012, NEURAL INF PROCES SY, V25
   Le THN, 2016, IEEE COMPUT SOC CONF, P46, DOI 10.1109/CVPRW.2016.13
   Li Z, 2017, ARXIV171107264
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma S, 2012, TRAFFIC INJ PREV, V13, P57, DOI 10.1080/15389588.2011.633945
   Qi TQ, 2017, NEUROCOMPUTING, V267, P475, DOI 10.1016/j.neucom.2017.06.041
   Ragab A, 2014, LECT NOTES COMPUT SC, V8814, P256, DOI 10.1007/978-3-319-11758-4_28
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S, 2015, FASTER R CNN REAL TI, P91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yan C., 2014, INT J VEH TECHNOL, V2014, DOI DOI 10.1155/2014/719413
   Yan C, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P680, DOI 10.1109/ICNC.2015.7378072
   Yang YB, 2017, 2016 INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION, BIG DATA & SMART CITY (ICITBS), P18, DOI 10.1109/ICITBS.2016.149
   YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zhao CH, 2012, IET INTELL TRANSP SY, V6, P161, DOI 10.1049/iet-its.2011.0116
   Zhao CH, 2012, ENG APPL ARTIF INTEL, V25, P1677, DOI 10.1016/j.engappai.2012.09.018
   Zhao CHH, 2013, NEURAL COMPUT APPL, V22, pS175, DOI 10.1007/s00521-012-1057-4
   Zhao X, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P926, DOI 10.1109/ICECC.2011.6066413
NR 42
TC 8
Z9 8
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2019
VL 90
AR 103800
DI 10.1016/j.imavis.2019.08.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU0WT
UT WOS:000501400600002
DA 2024-07-18
ER

PT J
AU Navarro, J
   Buades, A
AF Navarro, Julia
   Buades, Antoni
TI Semi-dense and robust image registration by shift adapted weighted
   aggregation and variational completion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image correspondences; Stereo; Optical flow; Block-matching;
   Interpolation
ID STEREO MATCHING ALGORITHM; OPTICAL-FLOW; BELIEF PROPAGATION; EFFICIENT
   STEREO; SEGMENTATION; MULTISCALE; FALDOI; WINDOW
AB This work presents a novel approach for both stereo and optical flow that deals with large displacements, depth/motion discontinuities and occlusions. The proposed method comprises two main steps. First, a novel local stereo matching algorithm is presented, whose main novelty relies in the block-matching aggregation step. We adopt an adaptive support weights approach in which the weight distribution favors pixels that share the same displacement with the reference one. State-of-the-art methods make the weight function depend only on image features. On the contrary, the proposed weight function depends additionally on the tested shift, by giving more importance to those pixels in the block-matching with smaller cost, as these are supposed to have the tested displacement. Moreover, the method is embedded into a pyramidal procedure to locally limit the search range, which helps to reduce ambiguities in the matching process and saves computational time. Second, the non-dense local estimation is filtered and interpolated by means of a new variational formulation making use of intermediate scale estimates of the local procedure. This permits to keep the fine details estimated at full resolution while being robust to noise and untextured areas using estimates at coarser scales. The introduced variational formulation as well as the block-matching algorithm are robust to illumination changes. We test our algorithm for both stereo and optical flow public datasets showing competitive results. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Navarro, Julia; Buades, Antoni] Univ Illes Balears, Cra Valldemossa Km 7-5, Palma De Mallorca, Illes Balears, Spain.
C3 Universitat de les Illes Balears
RP Navarro, J (corresponding author), Univ Illes Balears, Cra Valldemossa Km 7-5, Palma De Mallorca, Illes Balears, Spain.
EM julia.navarro@uib.es; toni.buades@uib.es
RI buades, antoni/K-6110-2014; Navarro, Julia/I-9059-2017
OI Navarro, Julia/0000-0003-3667-7008
FU Ministerio de Economia y Cornpetitividad of the Spanish Government
   [TIN2017-85572-P]
FX Authors were supported by the Ministerio de Economia y Cornpetitividad
   of the Spanish Government under grant TIN2017-85572-P (MINECO/AEI/FEDER,
   UE).
CR [Anonymous], ROB 2018
   [Anonymous], P WINT C APPL COMP V
   [Anonymous], ECCV 2018
   [Anonymous], REMOTE SENS SPAT INF
   [Anonymous], ICME 2019
   [Anonymous], TECH REP
   [Anonymous], 2015, BMVC 2015
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2016, J MACH LEARN RES
   [Anonymous], P IEEE C COMP VIS PA
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Ballester Coloma, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P31, DOI 10.1007/978-3-642-32717-9_4
   Birchfield S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1073, DOI 10.1109/ICCV.1998.710850
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Blanchet G, 2011, J MATH IMAGING VIS, V41, P109, DOI 10.1007/s10851-011-0268-0
   Bleyer M, 2005, ISPRS J PHOTOGRAMM, V59, P128, DOI 10.1016/j.isprsjprs.2005.02.008
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Buades A, 2015, SIAM J IMAGING SCI, V8, P888, DOI 10.1137/140984269
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen DM, 2015, IEEE T CIRC SYST VID, V25, P730, DOI 10.1109/TCSVT.2014.2361422
   Cheng L., 2006, 2006 IEEE COMP SOC C, P2378, DOI DOI 10.1109/CVPR.2006.251
   COCHRAN SD, 1992, IEEE T PATTERN ANAL, V14, P981, DOI 10.1109/34.159902
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430
   Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428
   Gamonal FP, 2019, IMAGE PROCESS ON LIN, V9, P94, DOI 10.5201/ipol.2019.238
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmüller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221
   Hirschmüller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hosni A, 2013, COMPUT VIS IMAGE UND, V117, P620, DOI 10.1016/j.cviu.2013.01.007
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Klaus A, 2006, INT C PATT RECOG, P15
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Kowalczuk J, 2013, IEEE T CIRC SYST VID, V23, P94, DOI 10.1109/TCSVT.2012.2203200
   Li YC, 2019, OPTIK, V178, P1318, DOI 10.1016/j.ijleo.2018.10.126
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manduchi R., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P26, DOI 10.1109/ICIAP.1999.797566
   Meinhardt-Llopis E, 2013, IMAGE PROCESS ON LIN, V3, P151, DOI 10.5201/ipol.2013.20
   Memin E, 1998, IEEE T IMAGE PROCESS, V7, P703, DOI 10.1109/83.668027
   Monzón N, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2526903
   Navarro J, 2017, IEEE IMAGE PROC, P2249, DOI 10.1109/ICIP.2017.8296682
   Navarro J, 2017, IEEE T IMAGE PROCESS, V26, P1873, DOI 10.1109/TIP.2017.2666041
   Palomares RP, 2017, J MATH IMAGING VIS, V58, P27, DOI 10.1007/s10851-016-0688-y
   Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y
   Patricio MNP, 2004, IEEE IMAGE PROC, P1341, DOI 10.1109/ICIP.2004.1419747
   Psota ET, 2015, IEEE I CONF COMP VIS, P2219, DOI 10.1109/ICCV.2015.256
   Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Saad Y, 2003, ITERATIVE METHODS SP, DOI DOI 10.1137/1.9780898718003
   Sand Peter, 2008, International Journal of Computer Vision, V80, P72, DOI 10.1007/s11263-008-0136-6
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Stoll M., 2012, P AS C COMP VIS, P1
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sun J, 2005, PROC CVPR IEEE, P399
   Tombari F, 2008, INT C PATT RECOG, P336
   Valentin J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275041
   Vanaken C, 2006, EUROGR TECH REP SER, P69
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Wang L, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P798
   Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Werlberger M., 2009, P BMVC
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Ye XQ, 2017, IEEE ACCESS, V5, P18745, DOI 10.1109/ACCESS.2017.2754318
   Yoon K.-J., 2007, P IEEE INT C COMPUTE, P1
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
   Zweig S, 2017, PROC CVPR IEEE, P6363, DOI 10.1109/CVPR.2017.674
NR 79
TC 7
Z9 9
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 258
EP 275
DI 10.1016/j.imavis.2019.07.005
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900021
DA 2024-07-18
ER

PT J
AU Pagnutti, G
   Zanuttigh, P
AF Pagnutti, Giampaolo
   Zanuttigh, Pietro
TI Joint segmentation of color and depth data based on splitting and
   merging driven by surface fitting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Segmentation; Depth; Spectral clustering; Kinect; NURBS
ID COMBINING COLOR; IMAGE; INFORMATION; GEOMETRY; FUSION
AB This paper proposes a segmentation scheme based on the joint usage of color and depth data together with a 3D surface estimation scheme. Firstly a set of multi-dimensional vectors is built from color, geometry and surface orientation information. Normalized cuts spectral clustering is then applied in order to recursively segment the scene in two parts thus obtaining an over-segmentation. This procedure is followed by a recursive merging stage where close segments belonging to the same object are joined together. At each step of both procedures a NURBS model is fitted on the computed segments and the accuracy of the fitting is used as a measure of the plausibility that a segment represents a single surface or object. By comparing the accuracy to the one at the previous step, it is possible to determine if each splitting or merging operation leads to a better scene representation and consequently whether to perform it or not. Experimental results show how the proposed method provides an accurate and reliable segmentation. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Pagnutti, Giampaolo; Zanuttigh, Pietro] Univ Padua, Dept Informat Engn, Via Gradenigo 6B, I-35131 Padua, Italy.
C3 University of Padua
RP Zanuttigh, P (corresponding author), Univ Padua, Dept Informat Engn, Via Gradenigo 6B, I-35131 Padua, Italy.
RI Zanuttigh, Pietro/AAB-9555-2019; Pagnutti, Giampaolo/AAI-2868-2021
OI Zanuttigh, Pietro/0000-0002-9502-2389; 
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], INT J COMPUT VIS
   [Anonymous], NANO RES, DOI DOI 10.1093/MP/SSQ042
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bleiweiss A., 2009, P GERM ASS PATT REC
   Calderero F, 2009, INT CONF ACOUST SPEE, P973, DOI 10.1109/ICASSP.2009.4959748
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dahan MJ, 2012, VISUAL COMPUT, V28, P1181, DOI 10.1007/s00371-011-0667-7
   Dal Mutto C, 2012, IEEE J-STSP, V6, P505, DOI 10.1109/JSTSP.2012.2194474
   Deng Z., 2014, Asian Conference on Computer Vision, P423
   Erdogan C., 2012, P C COMP ROB VIS CRV
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185
   Gallego J, 2014, J VIS COMMUN IMAGE R, V25, P184, DOI 10.1016/j.jvcir.2013.03.019
   Harville M., 2001, P IEEE WORKSH DET RE
   Hasnat M.A., 2014, P BRIT MACH VIS C BM
   Hasnat MA, 2016, IEEE T PATTERN ANAL, V38, P2255, DOI 10.1109/TPAMI.2015.2513407
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Holzer S, 2012, IEEE INT C INT ROBOT, P2684, DOI 10.1109/IROS.2012.6385999
   Juang LH, 2015, INT J CONTROL AUTOM, V13, P1286, DOI 10.1007/s12555-014-0313-z
   Khan MR, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P719, DOI 10.1109/ICIEV.2016.7760095
   Kolmogorov V, 2005, PROC CVPR IEEE, P1186
   Ladicky L., 2010, P BRIT MACH VIS C BM
   Lee JE, 2015, IET IMAGE PROCESS, V9, P62, DOI 10.1049/iet-ipr.2014.0044
   Leens J., 2009, COMBINING COLOR DEPT
   Mutto C. Dal, 2010, INT S 3D DAT PROC VI
   Mutto C. Dal, 2011, P JOINT 3DIM 3DPVT C
   Pagnutti G., 2015, P SMART TOOLS APPS C
   Pagnutti G., 2016, P INT JOINT C COMP V
   Pagnutti G, 2014, IEEE IMAGE PROC, P4407, DOI 10.1109/ICIP.2014.7025894
   Piegl L., 1997, The Nurbs Book, Vsecond
   Ren X., 2012, P IEEE C COMP VIS PA
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Srinivasan N., 2014, P IEEE INT C IM PROC
   Stein SC, 2014, PROC CVPR IEEE, P304, DOI 10.1109/CVPR.2014.46
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Taylor Camillo J., 2013, 2012 Robotics: Science and Systems, P401
   Wallenberg Marcus, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P306, DOI 10.1007/978-3-642-23123-0_31
   Yang JY, 2015, IEEE T CYBERNETICS, V45, P913, DOI 10.1109/TCYB.2014.2340032
   Zanuttigh Pietro., 2016, Time-of-flight and structured light depth cameras
NR 42
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2018
VL 70
BP 21
EP 31
DI 10.1016/j.imavis.2017.12.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GA7AR
UT WOS:000428487500003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hernandez, M
AF Hernandez, Monica
TI Primal-dual optimization strategies in Huber-<i>L</i><SUP>1</SUP>
   optical flow with temporal subspace constraints for non-rigid sequence
   registration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convex optimization; Fenchel-Duality; Primal-dual; Preconditioning;
   Optical flow; Non-rigid sequence registration; Temporal consistency;
   Subspace constraints
ID AUGMENTED LAGRANGIAN METHOD; SPLIT BREGMAN ITERATION;
   CONVEX-OPTIMIZATION; IMAGE REGISTRATION; DEFORMATION; ALGORITHM; MOTION;
   ROF
AB This work studies the application of Fenchel-Duality principles to general convex optimization problems and their corresponding relaxed versions in the context of optical flow estimation. We derive the associated primal-dual optimization strategies in the problem of Huber-L1 optical flow with temporal consistency for non-rigid sequence registration. Temporal consistency is imposed using a recently proposed approach that characterizes the optical flow using temporal subspace constraints, yielding solutions in a space spanned by a non-rigid orthogonal trajectory basis. The performance of the resulting optical flow methods has been studied in a framework for non-rigid sequence registration evaluation. In addition, we have compared the solution of the different methods in other challenging datasets. We have found that the strategies with the best outcome are among the ways of applying Fenchel-Duality principles that were not considered in previous works for the optical flow model with temporal subspace constraints. Indeed, our experiments have shown the simplest optimization strategy as the best performing one. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Hernandez, Monica] Univ Zaragoza, Aragon Inst Engn Res I3A, Robot Percept & Real Time Grp, Zaragoza, Spain.
C3 University of Zaragoza
RP Hernandez, M (corresponding author), Univ Zaragoza, Aragon Inst Engn Res I3A, Robot Percept & Real Time Grp, Zaragoza, Spain.
EM mhg@unizar.es
RI Hernandez, Monica/A-9855-2013
OI Hernandez Gimenez, Monica/0000-0003-1270-5852
FU UZ (University of Zaragoza) [2016-TEC03]; DGA (Diputacion General de
   Aragon) [T04-FSE]; MINECO; MICINN Spanish projects [DPI2012-32168,
   DPI2012-31781, TIN2016-80347-R]
FX The author would like to acknowledge the anonymous reviewers for their
   time and interest in the revision of the manuscript. This work was
   partially supported by the regional research grants UZ (University of
   Zaragoza) 2016-TEC03 and DGA (Diputacion General de Aragon) T04-FSE.
   This work was partially supported by MINECO and MICINN Spanish projects
   DPI2012-32168, DPI2012-31781, and TIN2016-80347-R.
CR Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201
   [Anonymous], 2001, P IEEE C COMP VIS PA
   [Anonymous], THESIS
   [Anonymous], 2009, BMVC
   [Anonymous], 2012, THESIS
   [Anonymous], 1980, Mat. Zametki
   Arrow KJ., 1958, Stanford mathematical studies in the social sciences, VII
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa
   Black M., 1991, IEEE COMPUTER SOC C, P292
   Bredies K, 2015, J MATH IMAGING VIS, V52, P317, DOI 10.1007/s10851-015-0564-1
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cachier P, 2003, COMPUT VIS IMAGE UND, V89, P272, DOI 10.1016/S1077-3142(03)00002-X
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan TF, 2006, NUMER ALGORITHMS, V41, P387, DOI 10.1007/s11075-006-9020-z
   De Craene M, 2012, MED IMAGE ANAL, V16, P427, DOI 10.1016/j.media.2011.10.006
   Dosovitskiy A., 2015, FLOWNET LEARNING OPT
   Durrleman S, 2013, INT J COMPUT VISION, V103, P22, DOI 10.1007/s11263-012-0592-x
   Elad M, 1998, J VIS COMMUN IMAGE R, V9, P119, DOI 10.1006/jvci.1998.0382
   Ferstl D., 2013, P 14 IEEE INT C COMP
   Frohn-Schauf C., 2004, Computing and Visualization in Science, V7, P199, DOI 10.1007/s00791-004-0150-3
   Gabay D., 1976, Computers mathematics with applications, V2
   Garg Ravi, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P300, DOI 10.1007/978-3-642-23094-3_22
   Garg R., 2010, P 10 AS C COMP VIS A
   Garg R., 2013, P IEEE C COMP VIS PA
   Garg R, 2013, INT J COMPUT VISION, V104, P286, DOI 10.1007/s11263-012-0607-7
   Glowinski R., 1975, REV FR AUTOMAT INF R, V9
   Goldfarb D, 2005, SIAM J SCI COMPUT, V27, P622, DOI 10.1137/040608982
   Graber G., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P708, DOI 10.1109/ICCVW.2011.6130318
   Hadj-Hamou M, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00236
   Hernandez M., 2015, P BRIT MACH VIS C BM
   Hernandez M, 2017, PHYS MED BIOL, V62, P9067, DOI 10.1088/1361-6560/aa925a
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Ince S, 2008, IEEE T IMAGE PROCESS, V17, P1443, DOI 10.1109/TIP.2008.925381
   Jannik Fritsch, 2013, P INT C INT TRANSP S
   Korpelevich G. M., 1976, EKONOMIKA MATEMATICH, V12, P747
   LIONS PL, 1979, SIAM J NUMER ANAL, V16, P964, DOI 10.1137/0716071
   Lombaert H, 2014, INT J COMPUT VISION, V107, P254, DOI 10.1007/s11263-013-0681-5
   Malls E., 2004, P 2004 IEEE INT C RO
   Miller MI, 2004, NEUROIMAGE, V23, pS19, DOI 10.1016/j.neuroimage.2004.07.021
   Modersitzki J., 2004, NUMER MATH SCI COMP
   MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896
   NAGEL HH, 1990, LECT NOTES COMPUT SC, V427, P139
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Nir T, 2008, INT J COMPUT VISION, V76, P205, DOI 10.1007/s11263-007-0051-2
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Papadakis N., 2007, P 11 IEEE INT C COMP
   Pennec X, 1999, LECT NOTES COMPUT SC, V1679, P597
   Perperidis D, 2005, MED IMAGE ANAL, V9, P441, DOI 10.1016/j.media.2005.05.004
   Pizarro D, 2012, INT J COMPUT VISION, V97, P54, DOI 10.1007/s11263-011-0452-0
   POCK T., 2009, P 12 IEEE INT C COMP
   Pock T., 2011, P 13 IEEE INT C COMP
   Pock T, 2011, LECT NOTES COMPUT SC, V6570, P245, DOI 10.1007/978-3-642-19391-0_18
   Preiswerk F, 2014, LECT NOTES COMPUT SC, V8676, P221, DOI 10.1007/978-3-319-13692-9_21
   Qiu A, 2008, NEUROIMAGE, V40, P68, DOI 10.1016/j.neuroimage.2007.11.041
   Qiu AQ, 2009, NEUROIMAGE, V45, pS51, DOI 10.1016/j.neuroimage.2008.10.039
   Ranftl R, 2014, LECT NOTES COMPUT SC, V8689, P439, DOI 10.1007/978-3-319-10590-1_29
   Revaud J., 2015, EPICFLOW EDGE PRESER, P2
   Rockafellar R. T., 1977, CONVEX ANAL PRINCETO
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Ruijters D, 2012, COMPUT J, V55, P15, DOI 10.1093/comjnl/bxq086
   Salgado A, 2007, LECT NOTES COMPUT SC, V4739, P709
   Salzmann M., 2007, P 11 IEEE INT C COMP
   Sidky EY, 2012, PHYS MED BIOL, V57, P3065, DOI 10.1088/0031-9155/57/10/3065
   Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603
   Steinbrücker F, 2009, IEEE I CONF COMP VIS, P1609, DOI 10.1109/ICCV.2009.5459364
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Tai XC, 2009, LECT NOTES COMPUT SC, V5567, P502
   Taylor Jonathan, 2010, P IEEE C COMP VIS PA
   Valkonen T, 2013, SIAM J IMAGING SCI, V6, P487, DOI 10.1137/120867172
   Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Volz S., 2011, P 13 IEEE INT C COMP
   Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2
   Weickert J, 2001, J MATH IMAGING VIS, V14, P245, DOI 10.1023/A:1011286029287
   Weinzaepfel P., 2013, P 14 IEEE INT C COMP
   White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Zach C., 2007, P 29 ANN S GERM ASS
   Zhang M, 2015, MED IMAGE ANAL, V25, P37, DOI 10.1016/j.media.2015.04.009
   Zhang Z., 2014, MED PHYS
   Zimmer H, 2011, INT J COMPUT VISION, V93, P368, DOI 10.1007/s11263-011-0422-6
NR 86
TC 4
Z9 4
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 44
EP 67
DI 10.1016/j.imavis.2017.11.005
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100005
DA 2024-07-18
ER

PT J
AU López, AM
   Villalonga, G
   Sellart, L
   Ros, G
   Vázquez, D
   Xu, JL
   Marin, J
   Mozafari, A
AF Lopez, Antonio M.
   Villalonga, Gabriel
   Sellart, Laura
   Ros, German
   Vazquez, David
   Xu, Jiaolong
   Marin, Javier
   Mozafari, Azadeh
TI Training my car to see using virtual worlds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE ADAS; Autonomous driving; Computer vision; Object detection; Semantic
   segmentation; Machine learning; Data annotation; Virtual worlds; Domain
   adaptation
ID DRIVER ASSISTANCE; PEDESTRIAN DETECTION; RECOGNITION; ADAPTATION; VIDEO
AB Computer vision technologies are at the core of different advanced driver assistance systems (ADAS) and will play a key role in oncoming autonomous vehicles too. One of the main challenges for such technologies is to perceive the driving environment, i.e. to detect and track relevant driving information in a reliable manner (e.g. pedestrians in the vehicle route, free space to drive through). Nowadays it is clear that machine learning techniques are essential for developing such a visual perception for driving. In particular, the standard working pipeline consists of collecting data (i.e. on-board images), manually annotating the data (e.g. drawing bounding boxes around pedestrians), learning a discriminative data representation taking advantage of such annotations (e.g. a deformable part-based model, a deep convolutional neural network), and then assessing the reliability of such representation with the acquired data. In the last two decades most of the research efforts focused on representation learning (first, designing descriptors and learning classifiers; later doing it end-to-end). Hence, collecting data and, especially, annotating it, is essential for learning good representations. While this has been the case from the very beginning, only after the disruptive appearance of deep convolutional neural networks that it became a serious issue due to their data hungry nature. In this context, the problem is that manual data annotation is a tiresome work prone to errors. Accordingly, in the late 00's we initiated a research line consisting of training visual models using photo-realistic computer graphics, especially focusing on assisted and autonomous driving. In this paper, we summarize such a work and show how it has become a new tendency with increasing acceptance. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Lopez, Antonio M.; Villalonga, Gabriel; Sellart, Laura; Ros, German; Vazquez, David; Xu, Jiaolong; Mozafari, Azadeh] Campus Univ Autonoma Barcelona UAB, CVC, Edifici 0, Barcelona 08193, Spain.
   [Lopez, Antonio M.; Villalonga, Gabriel; Ros, German; Vazquez, David; Xu, Jiaolong] Campus UAB, Escola Engn, DCC, Barcelona 08193, Spain.
   [Marin, Javier] MIT, CSAIL, Cambridge, MA 02139 USA.
C3 Centre de Visio per Computador (CVC); Autonomous University of
   Barcelona; Autonomous University of Barcelona; Massachusetts Institute
   of Technology (MIT)
RP López, AM (corresponding author), Campus Univ Autonoma Barcelona UAB, CVC, Edifici 0, Barcelona 08193, Spain.; López, AM (corresponding author), Campus UAB, Escola Engn, DCC, Barcelona 08193, Spain.
EM antonio@cvc.uab.es
RI López, Antonio M/L-5303-2014; Villalonga, Gabriel/JZU-0544-2024;
   Vázquez, David/P-3306-2019
OI López, Antonio M/0000-0002-6979-5783; Villalonga,
   Gabriel/0000-0002-1155-9374; Vázquez, David/0000-0002-2845-8158; martin,
   Javier/0000-0001-5938-5898; Ros, German/0000-0002-3182-6345
FU Spanish MINECO project [TRA2014-57088-C2-1-R]; Spanish DGT project
   [SPIP2017-02237]; Secretaria d'Universitats i Recerca del Departament
   d'Economia i Coneixement de la Generalitat de Catalunya [2014-SGR-1506];
   CERCA Programme / Generalitat de Catalunya; People Programme (Marie
   Curie Actions) REA grant [600388]; ACCIO; National Natural Science
   Foundation of China [6160011396]; NVIDIA Corporation
FX This work is supported by the Spanish MINECO project
   TRA2014-57088-C2-1-R, by the Spanish DGT project SPIP2017-02237, by the
   Secretaria d'Universitats i Recerca del Departament d'Economia i
   Coneixement de la Generalitat de Catalunya (2014-SGR-1506), by the CERCA
   Programme / Generalitat de Catalunya, by People Programme (Marie Curie
   Actions) FP7/2007-2013 REA grant agreement no. 600388 and ACCIO, and by
   the National Natural Science Foundation of China (project no.
   6160011396). Our research is also kindly supported by NVIDIA Corporation
   in the form of different GPU hardware.
CR [Anonymous], P ACM SIGCHI C HUM F
   [Anonymous], P IEEE INT C INT TRA
   [Anonymous], P IEEE INT C ROB AUT
   [Anonymous], 2016, ARXIV160401545
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P INT C COMP VIS
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2014, P INT C LEARN REPR B
   [Anonymous], ARXIV161102886
   [Anonymous], P AS C COMP VIS HYD
   [Anonymous], P IB C PATT REC IM A
   [Anonymous], P BRIT MACH VIS C NO
   [Anonymous], P EUR C COMP VIS FIR
   [Anonymous], P INT C COMP VIS
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], SMART CIT
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], TECH REP
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P GERM C PATT REC
   [Anonymous], P INT C LEARN REPR
   [Anonymous], P EUR C COMP VIS FIR
   [Anonymous], INTERACTIVE TRAINING
   [Anonymous], P C ADV NEUR INF PRO
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], ROBOT AUTON SYST
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], 2015, ARXIV151201030
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], IEEE INT WORKSH VIS
   [Anonymous], P C ADV CONC INT VIS
   [Anonymous], P INT C COGN SYST ZU
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2014, P EUR C COMP VIS ZUR
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2015, P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P INT C COMP VIS
   [Anonymous], P INT C COMP VIS
   [Anonymous], P INT C COMP VIS
   [Anonymous], P EUR C COMP VIS FIR
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], REAL VERSUS REALISTI
   [Anonymous], P C ADV NEUR INF PRO
   [Anonymous], 2007, CROSS DOMAIN VIDEO C
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], INT C IM VIS COMP NZ
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P GERM C PATT REC SA
   [Anonymous], 2014, P ECCV
   [Anonymous], SPRINGER BRIEFS COMP
   [Anonymous], P EUR NORRK SWED
   [Anonymous], P INT C COMP VIS
   [Anonymous], ARXIV161205424
   [Anonymous], SYNTHETICALLY TRAINE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P BRIT MACH VIS C AB
   [Anonymous], 2012, P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], THESIS
   [Anonymous], 2013, IEEE ICCV WORKSH
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2016, ARXIV160509582
   [Anonymous], 2017, ARXIV170105524
   [Anonymous], 2007, P INT C COMP VIS
   [Anonymous], P INT C MACH LEARN
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P IB C PATT REC IM A
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], 2016, ARXIV151103240
   [Anonymous], P C ADV NEUR INF PRO
   [Anonymous], P C ADV INF PROC SYS
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], 2017, LEARNING SYNTHETIC H
   [Anonymous], TRAINING CONVOLUTION
   [Anonymous], P BRIT MACH VIS C SW
   [Anonymous], ADV COMPUTER VISION
   [Anonymous], 2015, ARXIV151201401
   [Anonymous], 2008, NEURAL INFORM PROCES
   [Anonymous], SPRINGER SERIES ADV
   [Anonymous], P ROB SCI SYST SEATT
   [Anonymous], P INT C COMP VIS
   [Anonymous], P INT C COMP VIS
   [Anonymous], ARXIV160308152
   [Anonymous], 2007, IEEE WORKSH PERF EV
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P INT C COMP VIS
   [Anonymous], P INT C COMP VIS
   [Anonymous], P C COMP VIS PATT RE
   Bala R, 2012, PROC SPIE, V8305, DOI 10.1117/12.912453
   Bar Hillel A, 2014, MACH VISION APPL, V25, P727, DOI 10.1007/s00138-011-0404-2
   Berg TL, 2010, P IEEE, V98, P1434, DOI 10.1109/JPROC.2009.2032355
   Bertozzi M, 2004, IEEE T VEH TECHNOL, V53, P1666, DOI 10.1109/TVT.2004.834878
   Bileschi S., 2007, CBCL StreetScenes Challenge Framework
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Buehler M, 2009, SPRINGER TRAC ADV RO, V56, P1, DOI 10.1007/978-3-642-03991-1
   COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211
   de la Escalera A, 2003, IMAGE VISION COMPUT, V21, P247, DOI 10.1016/S0262-8856(02)00156-7
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Eum S, 2013, IEEE T INTELL TRANSP, V14, P1003, DOI 10.1109/TITS.2012.2233736
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gerónimo D, 2010, COMPUT VIS IMAGE UND, V114, P583, DOI 10.1016/j.cviu.2009.07.008
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Krotosky SJ, 2007, IEEE T INTELL TRANSP, V8, P619, DOI 10.1109/TITS.2007.908722
   Lai K, 2010, INT J ROBOT RES, V29, P1019, DOI 10.1177/0278364910369190
   Larsson F, 2011, IET COMPUT VIS, V5, P244, DOI 10.1049/iet-cvi.2010.0040
   Asensio JML, 2014, EXPERT SYST APPL, V41, P7281, DOI 10.1016/j.eswa.2014.05.004
   López A, 2010, INT J AUTO TECH-KOR, V11, P395, DOI 10.1007/s12239-010-0049-6
   Marín J, 2014, IEEE T CYBERNETICS, V44, P342, DOI 10.1109/TCYB.2013.2255271
   McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Onkarappa N, 2015, MULTIMED TOOLS APPL, V74, P3121, DOI 10.1007/s11042-013-1771-7
   Rozantsev A, 2015, COMPUT VIS IMAGE UND, V137, P24, DOI 10.1016/j.cviu.2014.12.006
   Rubio JC, 2012, IEEE T INTELL TRANSP, V13, P594, DOI 10.1109/TITS.2011.2175219
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Satkin S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.128
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Vázquez D, 2014, IEEE T PATTERN ANAL, V36, P797, DOI 10.1109/TPAMI.2013.163
   Xu JL, 2016, INT J COMPUT VISION, V119, P159, DOI 10.1007/s11263-016-0885-6
   Xu JL, 2014, IEEE T PATTERN ANAL, V36, P2367, DOI 10.1109/TPAMI.2014.2327973
   Xu JL, 2014, IEEE T INTELL TRANSP, V15, P2121, DOI 10.1109/TITS.2014.2310138
   Zitnick CL, 2016, IEEE T PATTERN ANAL, V38, P627, DOI 10.1109/TPAMI.2014.2366143
NR 135
TC 6
Z9 7
U1 1
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2017
VL 68
SI SI
BP 102
EP 118
DI 10.1016/j.imavis.2017.07.007
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FR9UP
UT WOS:000419418900010
DA 2024-07-18
ER

PT J
AU Tao, L
   Ip, HHS
   Zhang, AJ
   Shu, X
AF Tao, Liang
   Ip, Horace H. S.
   Zhang, Aijun
   Shu, Xin
TI Exploring canonical correlation analysis with subspace and structured
   sparsity for web image annotation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Canonical correlation; Image annotation; Subspace learning; Sparsity
ID SPACE
AB Canonical correlation analysis (CCA) has been extensively exploited for modelling Internet multimedia. However, two major challenges are raised for the classical CCA. First, CCA frequently fails to remove noisy and irrelevant features. Second, CCA cannot effectively capture the correlation between semantic labels, which is especially beneficial for annotating web images. In this paper, we propose a new framework that integrates structural sparsity and low-rank shared subspace into the least-squares formulation of CCA. Under this framework, multiple label interactions can be uncovered by the shared common, structure of the input space. Meanwhile, a few highly discriminative features can be decided via the structural sparse norm. Owing to the presence of non-smooth structured sparsity, a new efficient iterative algorithm is derived with guaranteed convergence. The empirical studies over several popular web image data collections consistently deliver the effectiveness of our new formulation in comparison with competing algorithms. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Tao, Liang; Zhang, Aijun] Hong Kong Baptist Univ, Dept Math, Hong Kong, Hong Kong, Peoples R China.
   [Ip, Horace H. S.] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Shu, Xin] Nanjing Agr Univ, Coll Informat Sci & Technol, Nanjing 210095, Jiangsu, Peoples R China.
C3 Hong Kong Baptist University; City University of Hong Kong; Nanjing
   Agricultural University
RP Tao, L (corresponding author), Hong Kong Baptist Univ, Dept Math, Hong Kong, Hong Kong, Peoples R China.
EM liang.tao@my.cityu.edu.hk; cship@cityu.edu.hk; ajzhang@hkbu.edu.hk;
   xinshu@outlook.com
RI Zhang, Aijun/M-5466-2014
OI Zhang, Aijun/0000-0001-9729-9018
FU Hong Kong Innovation and Technology Fund [ITS/268/14FX]; Fundamental
   Research Funds for the Central Universities [6J0126]; Natural Science
   Foundation of Jiangsu Province [BK20160741]
FX This research was supported in part by the Hong Kong Innovation and
   Technology FundITS/268/14FX. Xin Shu was supported by the Fundamental
   Research Funds for the Central Universities (6J0126) and the Natural
   Science Foundation of Jiangsu Province (Grants No. BK20160741).
CR [Anonymous], 2012, ADV NEURAL INF PROCE
   Cai X, 2013, IEEE I CONF COMP VIS, P801, DOI 10.1109/ICCV.2013.104
   Chen B, 2013, IEEE T PATTERN ANAL, V35, P1284, DOI 10.1109/TPAMI.2012.243
   Chen XH, 2012, ADV INTEL SOFT COMPU, V137, P199
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Ji SW, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1754428.1754431
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Shi CJ, 2014, IMAGE VISION COMPUT, V32, P189, DOI 10.1016/j.imavis.2013.12.013
   Sun L., 2013, MULTILABEL DIMENSION
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Wang H, 2010, LECT NOTES COMPUT SC, V6316, P126, DOI 10.1007/978-3-642-15567-3_10
   Wang LP, 2014, COMPUT OPTIM APPL, V58, P409, DOI 10.1007/s10589-014-9648-x
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P289, DOI 10.1109/TMM.2013.2293060
   Wang Shiqiang., 2015, CORR
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang Yi, 2011, Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, P873
   Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495
NR 24
TC 3
Z9 3
U1 0
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2016
VL 54
BP 22
EP 30
DI 10.1016/j.imavis.2016.06.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EB6UG
UT WOS:000387520500003
DA 2024-07-18
ER

PT J
AU Máttyus, G
   Fraundorfer, F
AF Mattyus, Gellert
   Fraundorfer, Friedrich
TI Aerial image sequence geolocalization with road traffic as invariant
   feature
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Geolocalization; Georeferencing; Geotagging; Geometric hashing
ID RECOGNITION
AB The geolocalization of aerial images is important for extracting geospatial information (e.g. the position of buildings, streets, and cars) and for creating maps. The standard is to use an expensive aerial imaging system equipped with an accurate GPS and IMU and/or do laborious ground control point measurements. In this paper we present a novel method to recognize the geolocation of aerial images automatically without any GPS or IMU. We extract road segments in the image sequence by detecting and tracking cars. We search in a database created from a road network map for the best matches between the road database and the extracted road segments. Geometric hashing is used to retrieve a shortlist of matches. The matches in the shortlist are ranked by a verification process. The highest scoring match gives the location and orientation of the images. We show in the experiments that our method can correctly geolocalize the aerial images in various scenes: e.g. urban, suburban, and rural with motorway. Besides the current images only the road map is needed over the search area. We can search an area of 22,500 km(2) containing 32,000 km of streets within minutes on a single cpu. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Mattyus, Gellert; Fraundorfer, Friedrich] German Aerosp Ctr, Remote Sensing Technol Inst, Oberpfaffenhofen, Germany.
   [Fraundorfer, Friedrich] Graz Univ Technol, Inst Comp Graph & Vis, Graz, Austria.
C3 Helmholtz Association; German Aerospace Centre (DLR); Graz University of
   Technology
RP Máttyus, G (corresponding author), German Aerosp Ctr, Remote Sensing Technol Inst, Oberpfaffenhofen, Germany.
EM gellert.mattyus@dlr.de; fraundorfer@icg.tugraz.at
FU Vabene++5 project of the German Aerospace Center (DLR)
FX This work was funded by the Vabene++<SUP>5</SUP> project of the German
   Aerospace Center (DLR).
CR [Anonymous], 2007, Photogrammetry: Geometry from Images and Laser Scans
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2000, ANN STAT
   Baatz G, 2012, LECT NOTES COMPUT SC, V7573, P517, DOI 10.1007/978-3-642-33709-3_37
   Baatz G, 2012, INT J COMPUT VISION, V96, P315, DOI 10.1007/s11263-011-0458-7
   Barrow H. G., 1977, P IMAGE UNDERSTANDIN, P659
   Bergtholdt Martin, 2010, International Journal of Computer Vision, V87, P93, DOI 10.1007/s11263-009-0209-1
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Brubaker MA, 2013, PROC CVPR IEEE, P3057, DOI 10.1109/CVPR.2013.393
   Gros P, 1998, COMPUT VIS IMAGE UND, V69, P135, DOI 10.1006/cviu.1997.0565
   Hornbostel A., 2013, EUR GNSS C
   Kluckner S, 2007, IEEE I CONF COMP VIS, P47
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kozempel K, 2009, 2009 24TH INTERNATIONAL CONFERENCE IMAGE AND VISION COMPUTING NEW ZEALAND (IVCNZ 2009), P237, DOI 10.1109/IVCNZ.2009.5378405
   LI SZ, 1992, LECT NOTES COMPUT SC, V588, P857
   Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2
   Lin Y., 2007, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1
   Mnih V., 2012, P 29 INT C MACH LEAR, P567
   Mossel E., 2012, ARXIV E PRINTS
   MULLER R, 2012, PHOTOGRAMMETRIC ENG, V71, P61
   Nakai T, 2006, LECT NOTES COMPUT SC, V3872, P541
   Stein F., 1990, P 10 INT C PATT REC, V1, P13
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang C., 2007, IM PROC 2007 ICIP 20, V5, pV
   Wegner JD, 2013, PROC CVPR IEEE, P1698, DOI 10.1109/CVPR.2013.222
   WILSON R, 1993, P SOC PHOTO-OPT INS, V2059, P444, DOI 10.1117/12.150248
   Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604
   Wu C., 2008, Proceedings of the International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Beijing, P197
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Xiao JJ, 2010, PROC CVPR IEEE, P679, DOI 10.1109/CVPR.2010.5540151
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 32
TC 10
Z9 11
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 218
EP 229
DI 10.1016/j.imavis.2016.05.014
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400017
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Tu, CT
   Luo, JR
AF Tu, Ching-Ting
   Luo, Jang-Ren
TI Robust face hallucination using ensemble of feature-based regression
   functions and classifiers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Principal component analysis (PCA); Canonical correlation analysis
   (CCA); Eigenfaces; Facial hallucination
ID SUPERRESOLUTION
AB An example-based face hallucination system is proposed, in which given a low-resolution facial image, a corresponding high-resolution image is automatically obtained. In practice, such a problem is extremely challenging since it is often the case that two discriminative high-resolution images may have similar low-resolution inputs. To address this issue, this study proposes an ensemble of image feature representations, including various local patch- or block-based representations, a one-dimensional vector image representation, a two-dimensional matrix image representation, and a global matrix image representation. Notably, some of these representations are designed to preserve the global facial geometry of the low-resolution input, while others are designed to preserve the local detailed texture. For each feature representation, a regression function is constructed to synthesize a high-resolution image from the low-resolution input image. The synthesis process is conducted in a layer-by-layer fashion, with the output from one layer serving as the input to the following layer. Importantly, each regression function is associated with a classifier in order to determine which regression functions are required in the synthesis procedure in accordance with the particular characteristics of the input image. Furthermore, these classifiers can also help to deal with the individual ambiguity of system low-resolution inputs. The experimental results show that the proposed framework is capable of synthesizing high-resolution images from low-resolution input images with a wide variety of facial poses, geometry misalignments and facial expressions even when such images are not included within the original training dataset. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Tu, Ching-Ting; Luo, Jang-Ren] Tamkang Univ, Dept Comp Sci & Informat Engn, New Taipei 25137, Taiwan.
C3 Tamkang University
RP Tu, CT (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, New Taipei 25137, Taiwan.
EM cttu@mail.tku.edu.tw
FU  [103-2221-E-032-027-MY2]
FX This work was supported by grant 103-2221-E-032-027-MY2.
CR Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   An L., 2014, SIGNAL PROCESSING
   An L, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P696, DOI 10.1109/IJCNN.2011.6033289
   [Anonymous], 2008, International Trade Theory, DOI DOI 10.1007/978-3-540-78265-0
   Biswas S, 2013, IEEE T PATTERN ANAL, V35, P3037, DOI 10.1109/TPAMI.2013.68
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen HT, 2005, IEEE I CONF COMP VIS, P1371
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Gao X B, 2012, IEEE T IMAGE PROCESS, V21
   He H, 2011, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2011.5995713
   Hu Y, 2011, IEEE T IMAGE PROCESS, V20, P433, DOI 10.1109/TIP.2010.2063437
   Huang H, 2010, PATTERN RECOGN, V43, P2532, DOI 10.1016/j.patcog.2010.02.007
   Jung CK, 2011, IEEE SIGNAL PROC LET, V18, P367, DOI 10.1109/LSP.2011.2140370
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Li B, 2009, IEEE SIGNAL PROC LET, V16, P957, DOI 10.1109/LSP.2009.2027657
   Li K, 2014, IEEE T MULTIMEDIA, V16, P299, DOI 10.1109/TMM.2013.2293064
   Li YC, 2014, PATTERN RECOGN, V47, P1261, DOI 10.1016/j.patcog.2013.09.012
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu K, 2011, IEEE INT CON MULTI
   Liu W., 2005, IEEE C MULT EXP
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Park JS, 2008, IEEE T IMAGE PROCESS, V17, P1806, DOI 10.1109/TIP.2008.2001394
   Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311
   Robinson MD, 2010, IEEE T IMAGE PROCESS, V19, P2669, DOI 10.1109/TIP.2010.2050107
   Tu C.-T., 2013, P IAPR INT C MACH VI, P149
   Tu CT, 2010, IEEE T SYST MAN CY B, V40, P1158, DOI 10.1109/TSMCB.2009.2035154
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L., 2004, ACM INT C MULT
   Zhuang YT, 2007, PATTERN RECOGN, V40, P3178, DOI 10.1016/j.patcog.2007.03.011
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 38
TC 4
Z9 4
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2015
VL 44
BP 59
EP 72
DI 10.1016/j.imavis.2015.10.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA CZ5EK
UT WOS:000367125100005
DA 2024-07-18
ER

PT J
AU Dehghan, A
   Oreifej, O
   Shah, M
AF Dehghan, Afshin
   Oreifej, Omar
   Shah, Mubarak
TI Complex event recognition using constrained low-rank representation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Complex event recognition; Low-rank optimization; Activity recognition;
   Action concepts
AB Complex event recognition is the problem of recognizing events in long and unconstrained videos. In this extremely challenging task, concepts have recently shown a promising direction where core low-level events (referred to as concepts) are annotated and modeled using a portion of the training data, then each complex event is described using concept scores, which are features representing the occurrence confidence for the concepts in the event. However, because of the complex nature of the videos, both the concept models and the corresponding concept scores are significantly noisy. In order to address this problem, we propose a novel low-rank formulation, which combines the precisely annotated videos used to train the concepts, with the rich concept scores. Our approach finds a new representation for each event, which is not only low-rank, but also constrained to adhere to the concept annotation, thus suppressing the noise, and maintaining a consistent occurrence of the concepts in each event. Extensive experiments on large scale real world dataset TRECVID Multimedia Event Detection 2011 and 2012 demonstrate that our approach consistently improves the discriminativity of the concept scores by a significant margin. (C) 2015 Published by Elsevier B.V.
C1 [Dehghan, Afshin; Shah, Mubarak] Univ Cent Florida, Orlando, FL 32816 USA.
   [Oreifej, Omar] Univ Calif Berkeley, Berkeley, CA 94720 USA.
C3 State University System of Florida; University of Central Florida;
   University of California System; University of California Berkeley
RP Dehghan, A (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.
EM adehghan@cs.ucf.edu; oreifej@eecs.berkeley.edu; shah@eecs.ucf.edu
RI Sahoo, Sarat Kumar/J-8765-2014
OI Sahoo, Sarat Kumar/0000-0001-5734-6844; Shah,
   Mubarak/0000-0001-6172-5572
FU Intelligence Advanced Research Projects Activity (IARPA) via the
   Department of Interior National Business Center [D11PC20066]
FX This work was supported by the Intelligence Advanced Research Projects
   Activity (IARPA) via the Department of Interior National Business Center
   contract number D11PC20066. The U.S. Government is authorized to
   reproduce and distribute reprints for Governmental purposes
   notwithstanding any copyright annotation thereon. Disclaimer: The views
   and conclusions contained herein are those of the authors and should not
   be interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of IARPA, DoI/NBC, or the
   U.S. Government.
CR [Anonymous], 2012, CVPR
   [Anonymous], 2014, PROCEEDINGS OF IEEE
   [Anonymous], 2010, ADV NEURAL INF PROCE
   [Anonymous], 2011, CVPR
   [Anonymous], P NIST TRECVID WORKS
   [Anonymous], ACM MM
   [Anonymous], 2012, CVPR
   [Anonymous], 2011, CVPR
   Bertsekas D. P., 1999, NONLINEAR PROGRAMMIN
   Borzeshi EZ, 2014, IEEE IMAGE PROC, P2373, DOI 10.1109/ICIP.2014.7025481
   Cai J., SIAM J OPTIM
   Candes E.J., 2009, IEEE SENS ARR MULT S
   Cheng H., 2012, P NIST TRECVID WORKS
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Farhadi Ali, 2009, CVPR
   Gleich DavidF., 2011, KDD
   Goldfarb D., 2009, PREPRINT
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Izadinia Haid., 2012, ECCV
   Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849
   Joachims T.F.T., 2009, MACH LEARN J
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Liangliang C., 2012, ECCV
   Lin Z., 2009, AUGMENTED LAGRANGE M
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu X., 2010, IEEE 4 INT C SEM COM
   Loui A., 2007, KODAKS CONSUMER VIDE
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Oreifej O., 2011, CVPR
   Oreifej O., 2013, PAMI
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Tang Kevin., 2012, CVPR, DOI 10.1109/cvpr.2012.6247808 2-s2.0-84866658784
   Tao M., 2011, SIAM J OPTIMIZATION
   Tianzhu Zhang B.G., 2012, ECCV
   van Gernert J. C, 2009, IEEE T PATTERN ANAL
   Wang H., 2009, BMVC
   Yang Y., 2012, ECCV
NR 38
TC 2
Z9 2
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2015
VL 42
BP 13
EP 21
DI 10.1016/j.imavis.2015.06.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CT2BV
UT WOS:000362607900002
DA 2024-07-18
ER

PT J
AU Shi, Y
   Ji, SP
   Shao, XW
   Yang, P
   Wu, WB
   Shi, ZC
   Shibasaki, R
AF Shi, Yun
   Ji, Shunping
   Shao, Xiaowei
   Yang, Peng
   Wu, Wenbin
   Shi, Zhongchao
   Shibasaki, Ryosuke
TI Fusion of a panoramic camera and 2D laser scanner data for constrained
   bundle adjustment in GPS-denied environments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Panoramic camera; Laser; Sensor fusion; Constrained bundle adjustment
ID SIMULTANEOUS LOCALIZATION; PROBABILISTIC LOCALIZATION; VISUAL SLAM;
   MODEL; MAP
AB Pose estimation is a key concern in 3D urban surveying, mapping, and navigation. Although Global Positioning System (GPS) technologies can be used to estimate a robot's or vehicle's pose, there are many urban environments in which GPS functions poorly or not at all. For these situations, we offer a novel approach based on a careful fusion of panoramic camera data and 2D laser scanner input. First, a Constrained Bundle Adjustment (CBA) is introduced to handle scale and loop closure constraints. The fusion of a panoramic image series and laser data then enables an accurate scale to be estimated and loop closures detected. Finally, the two geometric constraints are enforced on the global CBA solution, which in turn produces a robust pose estimate. Experiments show that the proposed method is practicable and more accurate than vision-only methods, with an average error of just 0.2 m in the horizontal plane over a 580 m trajectory. (C). 2015 Elsevier B.V. All rights reserved.
C1 [Shi, Yun; Yang, Peng; Wu, Wenbin] Chinese Acad Agr Sci, Inst Agr Resources & Reg Planning, Beijing 100193, Peoples R China.
   [Ji, Shunping] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China.
   [Shi, Yun; Ji, Shunping; Shibasaki, Ryosuke] Univ Tokyo, Ctr Spatial Informat Sci, Chiba, Japan.
   [Shao, Xiaowei] Univ Tokyo, Earth Observat Data Integrat & Fus Res Initiat, Tokyo 1538505, Japan.
   [Shi, Zhongchao] Tokyo City Univ, Dept Restorat Ecol & Built Environm, Fac Environm Studies, Tuzuki Ku, Yokohama, Kanagawa 2248551, Japan.
C3 Chinese Academy of Agricultural Sciences; Institute of Agricultural
   Resources & Regional Planning, CAAS; Wuhan University; University of
   Tokyo; University of Tokyo; Tokyo City University
RP Ji, SP (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China.
EM shiyun@caas.cn; jishunping@whu.edu.cn; shaoxw@iis.u-tokyo.ac.jp;
   Yangpeng@caas.cn; Wuwenbin@caas.cn; shizc@tcu.ac.jp;
   shiba@csis.u-tokyo.ac.jp
OI Ji, Shunping/0000-0002-3088-1481
FU National Key Basic Research Program of China [2012CB719902]; National
   Natural Science Foundation of China [41301365, 41471288, 61403285];
   National High-Tech R&D Program of China [2015AA124001]
FX This work was jointly supported by the National Key Basic Research
   Program of China (2012CB719902), the National Natural Science Foundation
   of China (41301365, 41471288 and 61403285), and the National High-Tech
   R&D Program of China (2015AA124001).
CR Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9_3
   [Anonymous], 2007 6 IEEE ACM INT
   [Anonymous], IEEE COMP SOC C COMP
   Booij O, 2009, ROBOT AUTON SYST, V57, P1225, DOI 10.1016/j.robot.2009.06.006
   Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366
   Brown M, 2005, PROC CVPR IEEE, P510
   Chiuso A, 2002, IEEE T PATTERN ANAL, V24, P523, DOI 10.1109/34.993559
   Chli M, 2009, ROBOT AUTON SYST, V57, P1173, DOI 10.1016/j.robot.2009.07.010
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768
   Diosi A, 2007, INT J ROBOT RES, V26, P1125, DOI 10.1177/0278364907082042
   Dusha D, 2012, INT J ROBOT RES, V31, P714, DOI 10.1177/0278364911433777
   Ganhua Li, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3854, DOI 10.1109/IROS.2007.4399041
   HAMMER E, 2013, PETERMANNS MITT 1, V59, P261
   Henskin L., 2002, International Archives of Photogrammetry, Remote Sensing and Spatial Information Science, Photogrammetric Computer Vision, ISPRS Comm. Ill, Symposium 2002, Sept. 9-13, Graz, Austrial, P156
   Jae-Han Park, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P5269
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832
   Maddern Will, 2011, IEEE International Conference on Robotics and Automation, P3595
   Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273
   McGlone C., 2004, MANUAL PHOTOGRAMMETR, V5th
   Michot J., 2010, 3DPVT 10, V3025
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Milford MJ, 2004, IEEE INT CONF ROBOT, P403, DOI 10.1109/ROBOT.2004.1307183
   Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483
   Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587
   Ramisa A, 2009, AUTON ROBOT, V27, P373, DOI 10.1007/s10514-009-9136-9
   Shi Y, 2013, SENSORS-BASEL, V13, P119, DOI 10.3390/s130100119
   Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268
   Sim D, 2009, IMAGE VISION COMPUT, V27, P1527, DOI 10.1016/j.imavis.2009.02.009
   Solà J, 2012, INT J COMPUT VISION, V97, P339, DOI 10.1007/s11263-011-0492-5
   Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387
   Vasconcelos F, 2012, IEEE T PATTERN ANAL, V34, P2097, DOI 10.1109/TPAMI.2012.18
NR 35
TC 11
Z9 14
U1 0
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2015
VL 40
BP 28
EP 37
DI 10.1016/j.imavis.2015.06.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CO4YD
UT WOS:000359165900003
DA 2024-07-18
ER

PT J
AU Ploumpis, S
   Amanatiadis, A
   Gasteratos, A
AF Ploumpis, Stylianos
   Amanatiadis, Angelos
   Gasteratos, Antonios
TI A stereo matching approach based on particle filters and scattered
   control landmarks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo matching; Particle filters; Ground control points; Markov chains;
   Plane fitting
ID BELIEF PROPAGATION; ADAPTIVE SUPPORT; VISION; ACCURATE
AB In robot localization, particle filtering can estimate the position of a robot in a known environment with the help of sensor data. In this paper, we present an approach based on particle filtering, for accurate stereo matching. The proposed method consists of three parts. First, we utilize multiple disparity maps in order to acquire a very distinctive set of features called landmarks, and then we use segmentation as a grouping technique. Secondly, we apply scan line particle filtering using the corresponding landmarks as a virtual sensor data to estimate the best disparity value. Lastly, we reduce the computational redundancy of particle filtering in our stereo correspondence with a Markov chain model, given the previous scan line values. More precisely, we assist particle filtering convergence by adding a proportional weight in the predicted disparity value estimated by Markov chains. In addition to this, we optimize our results by applying a plane fitting algorithm along with a histogram technique to refine any outliers. This work provides new insights into stereo matching methodologies by taking advantage of global geometrical and spatial information from distinctive landmarks. Experimental results show that our approach is capable of providing high-quality disparity maps comparable to other well-known contemporary techniques. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Ploumpis, Stylianos; Amanatiadis, Angelos; Gasteratos, Antonios] Democritus Univ Thrace, Sch Engn, GR-67100 Xanthi, Greece.
C3 Democritus University of Thrace
RP Amanatiadis, A (corresponding author), Democritus Univ Thrace, Sch Engn, 12 Vas Sofias Str, GR-67100 Xanthi, Greece.
EM aamanat@ee.duth.gr
RI Gasteratos, Antonios/B-7796-2012; Gasteratos, Antonios/AAI-4740-2021;
   Amanatiadis, Angelos/AAI-9496-2021
OI Gasteratos, Antonios/0000-0002-5421-0332; Amanatiadis,
   Angelos/0000-0002-1595-2683
CR Agrawal M, 2004, PROC CVPR IEEE, P66
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Canny J.F., 1983, 1 MIT
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fusiello A, 2000, INT J PATTERN RECOGN, V14, P1053, DOI 10.1142/S0218001400000696
   Geiger A., 2012, P IEEE CVPR
   Hadfield S, 2011, IEEE I CONF COMP VIS, P2290, DOI 10.1109/ICCV.2011.6126509
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Hirschmüller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407
   Hirschmuller H., 2006, P 2006 IEEE COMPUTER, P2386, DOI DOI 10.1109/CVPR.2006.294
   Humenberger M., P IEEE CVPRW 2010, P77
   Kim JC, 2005, PROC CVPR IEEE, P1075
   Klaus A, 2006, INT C PATT RECOG, P15
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Lewis J.P., 1995, Vision, Interface, V95, P120
   Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810
   Liu TL, 2012, INT C PATT RECOG, P914
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Min DB, 2011, IEEE I CONF COMP VIS, P1567, DOI 10.1109/ICCV.2011.6126416
   Nalpantidis L, 2011, IET IMAGE PROCESS, V5, P481, DOI 10.1049/iet-ipr.2009.0262
   Nalpantidis L, 2008, INT J OPTOMECHATRONI, V2, P435, DOI 10.1080/15599610802438680
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein Daniel., MIDDLEBURY STEREO EV
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562
   Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8
   Tombari F., P IEEE ICPR 2008, P1
   Tombari F., P IEEE CVPR 2008, P1
   Tombari F, 2007, LECT NOTES COMPUT SC, V4872, P427
   Wang L., P IEEE CVPR 2011, P3033
   Welch G., 1995, An introduction to the kalman filter
   Yang QX, 2012, LECT NOTES COMPUT SC, V7572, P399, DOI 10.1007/978-3-642-33718-5_29
   Yang QX, 2010, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2010.5539797
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yang S, 2012, IEEE T CIRC SYST VID, V22, P91, DOI 10.1109/TCSVT.2011.2158339
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
NR 42
TC 17
Z9 21
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2015
VL 38
BP 13
EP 23
DI 10.1016/j.imavis.2015.04.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CK4LX
UT WOS:000356196400002
DA 2024-07-18
ER

PT J
AU Wang, C
   Huang, KQ
AF Wang, Chong
   Huang, Kaiqi
TI How to use Bag-of-Words model better for image classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image classification; Bag-of-Words; Visual vocabulary; Coding; Pooling
AB The Bag-of-Words (BoW) framework is well-known in image classification. In the framework, there are two essential steps: 1) coding, which encodes local features by a visual vocabulary, and 2) pooling, which pools over the response of all features into image representation. Many coding and pooling methods are proposed, and how to apply them better in different conditions has become a practical problem. In this paper, to better use BoW in different applications, we study the relation between many typical coding methods and two popular pooling methods. Specifically, complete combinations of coding and pooling are evaluated based on an extremely large range of vocabulary sizes (16 to 1M) on five primary and popular datasets. Three typical ones are 15 Scenes, Caltech 101 and PASCAL VOC 2007, while the other two large-scale ones are Caltech 256 and ImageNet. Based on the systematic evaluation, some interesting conclusions are drawn. Some conclusions are the extensions of previous viewpoints, while some are different but important to understand BoW model. Based on these conclusions, we provide detailed application criterions by evaluating coding and pooling based on precision, efficiency and memory requirements in different applications. We hope that this study can be helpful to evaluate different coding and pooling methods, the conclusions can be beneficial to better understand BoW, and the application criterions can be valuable to use BoW better indifferent applications. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Wang, Chong; Huang, Kaiqi] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Huang, KQ (corresponding author), Zhong Guan Cun East Rd 95, Beijing, Peoples R China.
EM cwang@nlpr.ia.ac.cn; kqhuang@nlpr.ia.ac.cn
RI 黄, 凯琦/JJC-9384-2023
OI 黄, 凯琦/0000-0001-6834-6604
FU National Basic Research Program of China [2012CB316302]; National
   Natural Science Foundation of China [61322209, 61175007, 2012BAH07B01]
FX This work is supported by the National Basic Research Program of China
   (Grant No. 2012CB316302) and the National Natural Science Foundation of
   China (Grant No. 61322209, Grant No. 61175007, and Grant No.
   2012BAH07B01).
CR [Anonymous], NEURAL INFORM PROCES
   [Anonymous], PASCAL VISUAL OBJECT
   [Anonymous], 1989, P ADV NEURAL INFORM
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], EUR C COMP VIS 2010
   [Anonymous], 2004, ECCV
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], INT C COMP VIS
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], INT C IM PROC
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   [Anonymous], COMPUTER VISION PATT
   Bishop C.M., 2006, J ELECTRON IMAGING, V16, P049901, DOI DOI 10.1117/1.2819119
   Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Coates A., 2011, P 28 INT C MACH LEAR, V28, P921
   Deng Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2905, DOI 10.1109/CVPR.2011.5995390
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fei-Fei Li, 2004, COMP VIS PATT REC WO
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Griffin G., 2007, Technical Report 7694, P1
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Huang YZ, 2011, PROC CVPR IEEE, P1649, DOI 10.1109/CVPR.2011.5995655
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Koenderink JJ, 1999, INT J COMPUT VISION, V31, P159, DOI 10.1023/A:1008065931878
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni N, 2011, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2011.5995701
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Morioka N, 2011, IEEE I CONF COMP VIS, P1639, DOI 10.1109/ICCV.2011.6126425
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nock R, 2006, IEEE T PATTERN ANAL, V28, P1223, DOI 10.1109/TPAMI.2006.168
   Perronnin F., 2007, P IEEE CVPR, P1
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Picard D, 2011, IEEE IMAGE PROC, P669, DOI 10.1109/ICIP.2011.6116641
   Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Serre T, 2005, PROC CVPR IEEE, P994
   Shabou A., 2012, COMPUTER VISION PATT
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Velmurugan T., 2010, Journal of Computer Sciences, V6, P363, DOI 10.3844/jcssp.2010.363.368
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Xu W., 2011, Towards optimal one pass large scale learning with averaged stochastic gradient descent
   Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yu K, 2011, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2011.5995732
   Yu Kai, 2010, ICML, P1215
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 54
TC 27
Z9 31
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2015
VL 38
BP 65
EP 74
DI 10.1016/j.imavis.2014.10.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CK4LX
UT WOS:000356196400006
DA 2024-07-18
ER

PT J
AU Talha, AM
   Junejo, IN
AF Talha, Ayesha M.
   Junejo, Imran N.
TI Dynamic scene understanding using temporal association rules
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Scene understanding; Computer vision; Association rules; Traffic
   surveillance
ID PATTERNS
AB The basic goal of scene understanding is to organize the video into sets of events and to find the associated temporal dependencies. Such systems aim to automatically interpret activities in the scene, as well as detect unusual events that could be of particular interest, such as traffic violations and unauthorized entry. The objective of this work, therefore, is to learn behaviors of multi-agent actions and interactions in a semi-supervised manner. Using tracked object trajectories, we organize similar motion trajectories into clusters using the spectral clustering technique. This set of clusters depicts the different paths/routes, i.e., the distinct events taking place at various locations in the scene. A temporal mining algorithm is used to mine interval-based frequent temporal patterns occurring in the scene. A temporal pattern indicates a set of events that are linked based on their relationship with other events in the set, and we use Allen's interval-based temporal logic to describe these relations. The resulting frequent patterns are used to generate temporal association rules, which convey the semantic information contained in the scene. Our overall aim is to generate rules that govern the dynamics of the scene and perform anomaly detection. We apply the proposed approach on two publicly available complex traffic datasets and demonstrate considerable improvements over the existing techniques. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Talha, Ayesha M.; Junejo, Imran N.] Univ Sharjah, Dept Comp Sci, Sharjah 27272, U Arab Emirates.
C3 University of Sharjah
RP Junejo, IN (corresponding author), Univ Sharjah, Dept Comp Sci, Sharjah 27272, U Arab Emirates.
EM ijunejo@sharjah.ac.ae
RI Junejo, Imran/ABA-2975-2020
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Allen J. E., 1994, Journal of Logic and Computation, V4, P531, DOI 10.1093/logcom/4.5.531
   [Anonymous], 2011, 2011 NAT C COMM NCC
   [Anonymous], 2001, IEEE WORKSH COMP VIS
   [Anonymous], IEEE INT WORKSH VIS
   [Anonymous], UNSUPERVISED LEARNIN
   Atev S, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4851, DOI 10.1109/IROS.2006.282362
   Benezeth Y, 2009, PROC CVPR IEEE, P2450
   Bolei Zhou, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3441, DOI 10.1109/CVPR.2011.5995459
   Brendel W., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3329, DOI 10.1109/CVPR.2011.5995491
   Damen D, 2009, PROC CVPR IEEE, P927, DOI 10.1109/CVPRW.2009.5206636
   Emonet Remi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3233, DOI 10.1109/CVPR.2011.5995572
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Hamid R, 2009, ARTIF INTELL, V173, P1221, DOI 10.1016/j.artint.2009.05.002
   Hervieu A, 2008, IEEE T CIRC SYST VID, V18, P1533, DOI 10.1109/TCSVT.2008.2005609
   Hoppner F., 2001, IJCAI WORKSH LEARN T, P25
   Hospedales T., 2011, IEEE T PATTERN ANAL, V99
   Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342
   Jakkula Vikramaditya, 2007, 3rd IET International Conference on Intelligent Environments, IE 07, P339
   Jouneau E., 2011, PARTICLE BASED TRACK
   Junejo IN, 2008, IMAGE VISION COMPUT, V26, P512, DOI 10.1016/j.imavis.2007.07.006
   Kratz L., 2008, 1 INT WORKSH MACH LE
   Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869
   Laxman S, 2006, SADHANA-ACAD P ENG S, V31, P173, DOI 10.1007/BF02719780
   Li J, 2008, LECT NOTES COMPUT SC, V5305, P383
   Loy C., 2010, AS C COMP VIS, P161
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Morariu V. I., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3289, DOI 10.1109/CVPR.2011.5995386
   Morris B, 2009, PROC CVPR IEEE, P312, DOI 10.1109/CVPRW.2009.5206559
   Patel D., 2008, P 2008 ACM SIGMOD IN, P393, DOI DOI 10.1145/1376616.1376658
   Karthir,, 2010, PROC CVPR IEEE, P1967, DOI 10.1109/CVPR.2010.5539871
   Saleemi I, 2010, PROC CVPR IEEE, P2069, DOI 10.1109/CVPR.2010.5539884
   Shi Y., 2006, Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR), P1631
   SivaSelvan B, 2007, LECT NOTES COMPUT SC, V4509, P250
   Song LB, 2011, MOBILE OPPORTUNISTIC NETWORKS: ARCHITECTURES, PROTOCOLS AND APPLICATIONS, P1, DOI 10.1145/1287791.1287799
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Varadarajan Jagannadan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1338, DOI 10.1109/ICCVW.2009.5457456
   Varadarajan J., 2013, INT J COMPUT VISION, P1
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Winarko E, 2005, LECT NOTES COMPUT SC, V3589, P315, DOI 10.1007/11546849_31
   Yang Y, 2009, IEEE I CONF COMP VIS, P1669, DOI 10.1109/ICCV.2009.5459376
   Zen G., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3225, DOI 10.1109/CVPR.2011.5995578
   Zhang YJ, 2013, INT CONF SERVICE SCI, P64, DOI 10.1109/ICSS.2013.38
   Zhang Z., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1
NR 44
TC 12
Z9 13
U1 0
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1102
EP 1116
DI 10.1016/j.imavis.2014.08.010
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600012
DA 2024-07-18
ER

PT J
AU Zhang, L
   Ma, K
   Nejati, H
   Foo, L
   Sim, T
   Guo, D
AF Zhang, Li
   Ma, KengTeck
   Nejati, Hossein
   Foo, Lewis
   Sim, Terence
   Guo, Dong
TI A talking profile to distinguish identical twins
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Talking profile; Identical twins; Abnormal motions; EMRM
ID ADVANTAGE
AB Identical twins pose a great challenge to face recognition due to high similarities in their appearances. Motivated by the psychological findings that facial motion contains identity signatures and the observation that twins may look alike but behave differently, we develop a talking profile to use the identity signatures in the facial motion to distinguish between identical twins. The talking profile for a subject is defined as a collection of multiple types of usual face motions from the video. Given two talking profiles, we compute the similarities of the same type of face motion in both profiles and then perform the classification based on those similarities. To compute the similarity of each type of face motion, we give higher weights to more abnormal motions which are assumed to carry more identity signature information.
   Our approach, named Exceptional Motion Reporting Model (EMRM), is unrelated with appearance, and can handle realistic facial motion in human subjects, with no restrictions of speed of motion or video frame rate. We first conduct our experiments on a video database containing 39 pairs of twins. The experimental results demonstrate that identical twins can be distinguished better by the talking profiles over the traditional appearance based approach. Moreover, we collected a non-twin YouTube dataset with 99 subjects. The results on this dataset verified that the talking profile can be the potential biometric. We further conducted an experiment to test the robustness of talking profile to the time. Videos from 10 subjects which span across years or even decades in their lives are collected. The results indicated the robustness of talking profile to the aging process. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Zhang, Li; Ma, KengTeck; Foo, Lewis; Sim, Terence; Guo, Dong] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
   [Nejati, Hossein] Facebook Inc, Palo Alto, CA USA.
C3 National University of Singapore; Facebook Inc
RP Zhang, L (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
EM lizhang@comp.nus.edu.sg; ktma@comp.nus.edu.sg; nejati@nus.edu.sg;
   lewis@comp.nus.edu.sg; tsim@comp.nus.edu.sg; dnguo@fb.com
OI Sim, Terence/0000-0002-0198-094X
CR Ahonen T., COMP VIS ECCV 2004, P469
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Daugman J, 2001, P ROY SOC B-BIOL SCI, V268, P1737, DOI 10.1098/rspb.2001.1696
   Deng WH, 2012, PATTERN RECOGN, V45, P4438, DOI 10.1016/j.patcog.2012.06.010
   He X., 2003, ADV NEURAL INFORM PR, P153
   Hill H, 2001, CURR BIOL, V11, P880, DOI 10.1016/S0960-9822(01)00243-3
   Huang G.B., 2008, WORKSH FAC REAL LIF
   Jain AK, 2002, PATTERN RECOGN, V35, P2653, DOI 10.1016/S0031-3203(01)00218-7
   Klare B., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117548
   Kong AWK, 2006, PATTERN RECOGN, V39, P2149, DOI 10.1016/j.patcog.2006.04.035
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Martin JA, 2008, PEDIATRICS, V121, P788, DOI 10.1542/peds.2007-3753
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Ning Y, 2008, INT C PATT RECOG, P2792
   Phillips P.J., 2011, DISTINGUISHING IDENT
   Pilz KS, 2006, EXP BRAIN RES, V171, P436, DOI 10.1007/s00221-005-0283-8
   Sun Z., 2010, P SPIE
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Thornton IM, 2002, PERCEPTION, V31, P113, DOI 10.1068/p3300
   Tulyakov S., 2007, P CVPR
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Unnikrishnan MK, 2009, J THEOR BIOL, V261, P469, DOI 10.1016/j.jtbi.2009.08.011
   Zhang L., 2012, NEW HOPE RECOGNIZING
NR 25
TC 3
Z9 5
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 771
EP 778
DI 10.1016/j.imavis.2013.12.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700014
DA 2024-07-18
ER

PT J
AU Xu, JS
   Wu, Q
   Zhang, J
   Tang, ZM
AF Xu, Jingsong
   Wu, Qiang
   Zhang, Jian
   Tang, Zhenmin
TI Exploiting Universum data in AdaBoost using gradient descent
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ada Boost; Gradient boost; uAdaBoost; Universum; u-SVM
ID MULTILINEAR ANALYSIS; VIEW
AB Recently, Universum data that does not belong to any class of the training data, has been applied for training better classifiers. In this paper, we address a novel boosting algorithm called AdaBoost that can improve the classification performance of AdaBoost with Universum data. uAdaBoost chooses a function by minimizing the loss for labeled data and Universum data. The cost function is minimized by a greedy, stagewise, functional gradient procedure. Each training stage of uAdaBoost is fast and efficient. The standard AdaBoost weights labeled samples during training iterations while uAdaBoost gives an explicit weighting scheme for Universum samples as well. In addition, this paper describes the practical conditions for the effectiveness of Universum learning. These conditions are based on the analysis of the distribution of ensemble predictions over training samples. Experiments on handwritten digits classification and gender classification problems are presented. As exhibited by our experimental results, the proposed method can obtain superior performances over the standard AdaBoost by selecting proper Universum data. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Xu, Jingsong; Tang, Zhenmin] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Wu, Qiang] Univ Technol Sydney, Sch Comp & Commun, Sydney, NSW 2007, Australia.
   [Zhang, Jian] Univ Technol Sydney, Adv Analyt Inst, Sydney, NSW 2007, Australia.
   [Zhang, Jian] Univ Technol Sydney, Sch Software, Sydney, NSW 2007, Australia.
C3 Nanjing University of Science & Technology; University of Technology
   Sydney; University of Technology Sydney; University of Technology Sydney
RP Zhang, J (corresponding author), Univ Technol Sydney, Adv Analyt Inst, Sydney, NSW 2007, Australia.
EM xjsxujingsong@gmail.com; Qiang.Wu@uts.edu.au; jian.Zhang@uts.edu.au;
   tzm.cs@mail.njust.edu.cn
RI Tang, Zhenmin/AAY-6058-2020
OI Tang, Zhenmin/0000-0001-6708-2205; Xu, Jingsong/0000-0002-9102-3616; Wu,
   Qiang/0000-0001-5641-2483; Zhang, Jian/0000-0002-7240-3541
CR [Anonymous], 2006, Estimation of Dependences Based on Empirical Data, DOI DOI 10.2307/2988246
   Bai X, 2008, IEEE IJCNN, P746, DOI 10.1109/IJCNN.2008.4633879
   Bennett K. P., 2002, P 8 ACM SIGKDD INT C, P289
   Chapelle O., 2008, Advances in neural information processing systems, P1369
   Chen S, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1016
   Chen XH, 2012, ELECTRON LETT, V48, P1407, DOI 10.1049/el.2012.2506
   Cherkassky V, 2011, IEEE T NEURAL NETWOR, V22, P1241, DOI 10.1109/TNN.2011.2157522
   d'Alché-Buc F, 2002, ADV NEUR IN, V14, P553
   Dhar S, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P220, DOI 10.1109/ICMLA.2012.45
   Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Hao XK, 2013, LECT NOTES COMPUT SC, V8184, P227, DOI 10.1007/978-3-319-02267-3_29
   Mason L, 2000, ADV NEUR IN, V12, P512
   Peng B, 2009, PATTERN RECOGN LETT, V30, P1289, DOI 10.1016/j.patrec.2009.06.007
   Peng B, 2008, LECT NOTES COMPUT SC, V5359, P581, DOI 10.1007/978-3-540-89646-3_57
   Qi ZQ, 2014, NEURAL COMPUT APPL, V24, P621, DOI 10.1007/s00521-012-1260-3
   Qi ZQ, 2012, NEURAL NETWORKS, V36, P112, DOI 10.1016/j.neunet.2012.09.004
   Rätsch G, 2005, J MACH LEARN RES, V6, P2131
   Shen CH, 2012, IEEE T PATTERN ANAL, V34, P825, DOI 10.1109/TPAMI.2011.240
   Shen CH, 2010, IEEE T PATTERN ANAL, V32, P2216, DOI 10.1109/TPAMI.2010.47
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Weston J., 2006, P 23 INT C MACH LEAR, P1009
   Zhang D., 2008, P 2008 SIAM INT C DA, P323
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P873
NR 24
TC 7
Z9 9
U1 5
U2 32
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 550
EP 557
DI 10.1016/j.imavis.2014.04.009
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600009
OA Green Published
DA 2024-07-18
ER

PT J
AU Werneck, NL
   Costa, AHR
AF Werneck, Nicolau Leal
   Reali Costa, Anna Helena
TI <i>Corisco</i>: Robust edgel-based orientation estimation for generic
   camera models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Grid mask; Edgels; Orientation estimation; Omnidirectional vision;
   Monocular vision; Quaternions
ID CALIBRATION; WORLD
AB The estimation of camera orientation from image lines using the anthropic environment restriction is a well-known problem, but traditional methods to solve it depend on line extraction, a relatively complex procedure that is also incompatible with distorted images. We propose Corisco, a monocular orientation estimation method based on edgels instead of lines. Edgels are points sampled from image edges with their tangential directions, extracted in Corisco using a grid mask. The estimation aligns the measured edgel directions with the predicted directions calculated from the orientation, using a known camera model. Corisco uses the M-estimation technique to define an objective function that is optimized by two algorithms in sequence: RANSAC, which gives robustness and flexibility to Corisco, and FilterSQP, which performs a continuous optimization to refine the initial estimate, using closed formulas for the function derivatives. Corisco is the first edgel-based method able to analyze images with any camera model, and it also allows for a compromise between speed and accuracy, so that its performance can be tuned according to the application requirements. Our experiments demonstrate the effectiveness of Corisco with various camera models, and its performance surpasses similar edgel-based methods. The accuracy displayed a mean error below 2 degrees for execution times above 8 s in a conventional computer, and above 3 degrees for less than 2 s. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Werneck, Nicolau Leal; Reali Costa, Anna Helena] Univ Sao Paulo, LTI, BR-05508900 Sao Paulo, Brazil.
C3 Universidade de Sao Paulo
RP Werneck, NL (corresponding author), Univ Sao Paulo, LTI, Av Prof Luciano Gualberto Trav 3,158, BR-05508900 Sao Paulo, Brazil.
EM nwerneck@gmail.com; anna.reali@usp.br
RI Werneck, Nicolau/H-8012-2012; Costa, Anna Helena Reali/I-2469-2012
OI Werneck, Nicolau/0000-0003-0017-5890; Costa, Anna Helena
   Reali/0000-0001-7309-4528
FU CAPES; FAPESP [2011/19280-8]; CNPq [311058/2011-6]; Fundacao de Amparo a
   Pesquisa do Estado de Sao Paulo (FAPESP) [11/19280-8] Funding Source:
   FAPESP
FX We acknowledge the support provided by CAPES, FAPESP (process
   no.2011/19280-8), and CNPq (process no.311058/2011-6).
CR Ando S, 2000, IEEE T PATTERN ANAL, V22, P252, DOI 10.1109/34.841757
   Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170
   [Anonymous], 2018, Robust Statistics: Theory and Methods (with R)
   Antunes M, 2013, PROC CVPR IEEE, P1336, DOI 10.1109/CVPR.2013.176
   Barreto JP, 2005, IEEE T PATTERN ANAL, V27, P1327, DOI 10.1109/TPAMI.2005.163
   Bazin J.-C., 2012, C COMP VIS PATT REC, DOI DOI 10.1109/CVPR2012.6247731
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   Choi S., 2009, BRIT MACH VIS C BMVA, V24
   Chum O., 2004, Proc. of the Asian Conference on Computer Vision ACCV, V2, P812
   Cipolla R., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P382
   Collins R. T., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P400, DOI 10.1109/ICCV.1990.139560
   Coughlan J.M., 2000, NEURAL INFORM PROCES
   Coughlan JM, 2003, NEURAL COMPUT, V15, P1063, DOI 10.1162/089976603765202668
   Denis P.H., 2008, THESIS YORK U
   Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15
   Deutscher J., 2002, LECT NOTES COMPUTER, V2353, P373, DOI DOI 10.1007/3-540-47979-1
   Eade E, 2009, IMAGE VISION COMPUT, V27, P588, DOI 10.1016/j.imavis.2008.04.012
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fletcher R, 2002, MATH PROGRAM, V91, P239, DOI 10.1007/s101070100244
   Flint A, 2010, PROC CVPR IEEE, P467, DOI 10.1109/CVPR.2010.5540176
   Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241
   Ghosal S, 1997, IEEE T IMAGE PROCESS, V6, P781, DOI 10.1109/83.585230
   Grammatikopoulos L, 2007, ISPRS J PHOTOGRAMM, V62, P64, DOI 10.1016/j.isprsjprs.2007.02.002
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hughes C, 2010, IMAGE VISION COMPUT, V28, P538, DOI 10.1016/j.imavis.2009.09.001
   Ji H, 2006, VISION RES, V46, P3105, DOI 10.1016/j.visres.2006.04.010
   Leal Werneck Nicolau, 2010, International Journal of Natural Computing Research, V1, P56, DOI 10.4018/jncr.2010100106
   LYVERS EP, 1988, IEEE T PATTERN ANAL, V10, P927, DOI 10.1109/34.9114
   Matas J, 2000, COMPUT VIS IMAGE UND, V78, P119, DOI 10.1006/cviu.1999.0831
   Meer P, 2012, IMAGE VISION COMPUT, V30, P472, DOI 10.1016/j.imavis.2011.10.004
   Olson CF, 2001, INT J COMPUT VISION, V45, P39, DOI 10.1023/A:1012317923177
   PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394
   Rosten E., 2009, MACH VISION APPL, V22, P77, DOI DOI 10.1007/S00138-009-0196-9(URL
   Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9
   Schindler G, 2004, PROC CVPR IEEE, P203
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   STEPHENS RS, 1991, IMAGE VISION COMPUT, V9, P66, DOI 10.1016/0262-8856(91)90051-P
   Strand R., 2005, BRIT MACH VIS C BRIT, DOI DOI 10.5244/C.19.9
   Sudipta N., 2010, Proc. of European Conference on Computer Vision Workshop on Reconstruction and Modeling of Large-Scale 3D Virtual Environments, P1
   Swart D., 2011, MATH HORIZ, P14, DOI DOI 10.4169/MATHH0RIZ0NS.19.1.14(SEPTEMBER)
   Tardif JP, 2009, IEEE I CONF COMP VIS, P1250
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Tordoff B, 2004, COMPUT VIS IMAGE UND, V96, P17, DOI 10.1016/j.cviu.2004.06.002
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   Werneck NL, 2011, WSCG 2011: COMMUNICATION PAPERS PROCEEDINGS, P127
NR 48
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2013
VL 31
IS 12
BP 969
EP 981
DI 10.1016/j.imavis.2013.10.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 282DU
UT WOS:000329151300007
DA 2024-07-18
ER

PT J
AU Sellent, A
   Ruhl, K
   Magnor, M
AF Sellent, Anita
   Ruhl, Kai
   Magnor, Marcus
TI A loop-consistency measure for dense correspondences in multi-view video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-view video; Correspondence estimation; Confidence measure; Optical
   flow
ID OPTICAL-FLOW ESTIMATION; CONFIDENCE MEASURE; STEREO; PERFORMANCE
AB Many applications in computer vision and computer graphics require dense correspondences between images of multi-view video streams. Most state-of-the-art algorithms estimate correspondences by considering pairs of images. However, in multi-view videos, several images capture nearly the same scene. In this article we show that this redundancy can be exploited to estimate more robust and consistent correspondence fields. We use the multi-video data structure to establish a confidence measure based on the consistency of the correspondences in a loop of three images. This confidence measure can be applied after flow estimation is terminated to find the pixels for which the estimate is reliable. However, including the measure directly into the estimation process yields dense and highly accurate correspondence fields. Additionally, application of the loop consistency confidence measure allows us to include sparse feature matches directly into the dense optical flow estimation. With the confidence measure, spurious matches can be successfully suppressed during optical flow estimation while correct matches contribute to increase the accuracy of the flow. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Sellent, Anita; Ruhl, Kai; Magnor, Marcus] TU Braunschweig, Inst Computerg, Braunschweig, Germany.
C3 Braunschweig University of Technology
RP Sellent, A (corresponding author), TU Braunschweig, Inst Computerg, Braunschweig, Germany.
EM sellent@cg.tu-bs.de
OI Magnor, Marcus/0000-0003-0579-480X
CR Alvarez L, 2007, INT J COMPUT VISION, V75, P371, DOI 10.1007/s11263-007-0041-4
   [Anonymous], P BMVC
   [Anonymous], JWSCG
   [Anonymous], P ICCV
   [Anonymous], P VMV EUR ASS
   [Anonymous], P ICIP IEEE
   [Anonymous], P CVPR
   Baker Simon, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Basha T, 2010, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2010.5539791
   Berkels B, 2009, LECT NOTES COMPUT SC, V5681, P388, DOI 10.1007/978-3-642-03641-5_29
   Black M. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P296, DOI 10.1109/CVPR.1991.139705
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Brox T, 2009, PROC CVPR IEEE, P41, DOI 10.1109/CVPRW.2009.5206697
   Bruhn A, 2006, COMP IMAG VIS, P283
   Hasler N, 2009, PROC CVPR IEEE, P224, DOI 10.1109/CVPRW.2009.5206859
   Huguet F., 2007, P ICCV, P1
   Kondermann C, 2008, LECT NOTES COMPUT SC, V5304, P290, DOI 10.1007/978-3-540-88690-7_22
   Kondermann C, 2007, LECT NOTES COMPUT SC, V4713, P132
   Leung C, 2004, INT C PATT RECOG, P72, DOI 10.1109/ICPR.2004.1333708
   Lipski C, 2010, COMPUT GRAPH FORUM, V29, P2555, DOI 10.1111/j.1467-8659.2010.01824.x
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matusik W, 2004, ACM T GRAPHIC, V23, P814, DOI 10.1145/1015706.1015805
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Min D, 2006, INT C PATT RECOG, P74
   Sand Peter, 2008, International Journal of Computer Vision, V80, P72, DOI 10.1007/s11263-008-0136-6
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Sizintsev M, 2009, PROC CVPR IEEE, P493, DOI 10.1109/CVPRW.2009.5206728
   Tuytelaars T, 2004, PROC CVPR IEEE, P762
   Wedel A, 2008, LECT NOTES COMPUT SC, V5302, P739, DOI 10.1007/978-3-540-88682-2_56
   Weickert J, 2001, J MATH IMAGING VIS, V14, P245, DOI 10.1023/A:1011286029287
   WERLBERGER M., 2009, BMVC, V1, P3
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211
   Yan Niu, 2009, Proceedings of the 2009 24th International Conference Image and Vision Computing New Zealand (IVCNZ 2009), P12, DOI 10.1109/IVCNZ.2009.5378427
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhou CX, 2003, PROC CVPR IEEE, P351
NR 39
TC 3
Z9 3
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2012
VL 30
IS 9
BP 641
EP 654
DI 10.1016/j.imavis.2012.06.011
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 024EV
UT WOS:000310092600005
DA 2024-07-18
ER

PT J
AU Zheng, W
   Liang, LH
   Chang, H
   Heng, CK
   Shan, SG
   Chen, XL
AF Zheng, Wei
   Liang, Luhong
   Chang, Hong
   Heng, Cher-Keng
   Shan, Shiguang
   Chen, Xilin
TI Boosted translation-tolerable classifiers for fast object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Boosting; Maximal Translation-Tolerable Region (MTTR);
   Granularity-Adaptively-Tunable (GAT)
ID PEDESTRIAN DETECTION
AB Different classifiers show different sensitivities to translation-variance. The translation-insensitive classifiers are capable of accelerating the detection process by searching over a coarse grid as well as guaranteeing the recall rate.
   In this paper, we define a concept of Translation-Tolerable Region (TTR) for a classifier. The TTR is such a region that all the detection windows in it have consistent (stable) results output by the classifier. We use the classifier's Maximal Translation-Tolerable Region (MTTR) to measure its sensitivity to the translation-variance. For object detection, we propose an algorithm for training the discriminative classifiers as well as learning the associated MTTRs. The discriminative classifiers are assembled into a cascaded classifier in descending order of their MTTR sizes. To speed up the detection process, we propose a Granularity-Adaptively-Tunable (GAT) search strategy according to the classifiers' MTTRs. Furthermore, we prove that the recall rate is Probably Approximately Admissible (PAA) in the GAT search, which means that the proposed approach can theoretically guarantee the accuracy while accelerating the detection process. Based on the boosting framework with Histograms of Oriented Gradients (HOG) features, we evaluate the proposed approach on the public datasets containing both rigid and non-rigid object classes. The experimental results show that our approach achieves considerable results with a fast speed. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Zheng, Wei; Liang, Luhong; Chang, Hong; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Zheng, Wei] Chinese Acad Sci, Grad Sch, Beijing 100039, Peoples R China.
   [Heng, Cher-Keng] Panason R&D Ctr, Singapore, Singapore.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Chang, H (corresponding author), 6 Kexueyuan S Rd, Beijing 100190, Peoples R China.
EM wei.zheng@vipl.ict.ac.cn; luhong_liang@yahoo.com.cn;
   hong.chang@vipl.ict.ac.cn; CherKeng.Heng@sg.panasonic.com;
   shiguang.shan@vipl.ict.ac.cn; xilin.chen@vipl.ict.ac.cn
RI Yu, Yang/L-7703-2016
OI Yu, Yang/0000-0001-9592-8191; Shan, Shiguang/0000-0002-8348-392X
FU National Basic Research Program of China (973 Program) [2009CB320902];
   Natural Science Foundation of China [60872124, 60833013, 60832004];
   Beijing Natural Science Foundation (New Technologies and Methods in
   Intelligent Video Surveillance for Public Security) [4111003]
FX This paper is partially supported by National Basic Research Program of
   China (973 Program) under contract 2009CB320902; Natural Science
   Foundation of China under contracts Nos. 60872124, 60833013, and
   60832004; and Beijing Natural Science Foundation (New Technologies and
   Methods in Intelligent Video Surveillance for Public Security) under
   contract No. 4111003.
CR [Anonymous], 2009, ICCV
   [Anonymous], 2010, CVPR
   [Anonymous], 2010, BRIT MACH VIS C AB U
   [Anonymous], CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], 2006, CVPR
   [Anonymous], CVPR
   [Anonymous], THESIS I NATL POLYTE
   [Anonymous], 2008, CVPR
   [Anonymous], 2005, NIPS
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollar P., 2007, CVPR
   Everingham M., 2006, PASCAL VISUAL OBJECT
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584
   Kelly P, 2009, IMAGE VISION COMPUT, V27, P1445, DOI 10.1016/j.imavis.2008.04.006
   Laptev I, 2009, IMAGE VISION COMPUT, V27, P535, DOI 10.1016/j.imavis.2008.08.010
   Lin Z., 2009, CVPR
   Rowley Henry A, 1996, NIPS, P2
   Sahbi Hichem, 2002, ICPR
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Schneiderman H., 2004, CVPR
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Vedaldi A., 2009, ICCV
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]
   Wu B., 2008, CVPR
   Wu B., 2007, ICCV
   Zhang HM, 2006, IMAGE VISION COMPUT, V24, P327, DOI 10.1016/j.imavis.2005.11.010
   Zhang Wei., 2007, ICCV
   Zheng W., 2009, CVPR
NR 31
TC 1
Z9 1
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 480
EP 491
DI 10.1016/j.imavis.2012.04.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100009
DA 2024-07-18
ER

PT J
AU Lui, YM
AF Lui, Yui Man
TI Advances in matrix manifolds for computer vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Lie groups; Stiefel manifolds; Grassmann manifolds; Riemannian manifolds
ID 3D MOTION ESTIMATION; PEDESTRIAN DETECTION; VISUAL TRACKING;
   OPTIMIZATION; RECOGNITION
AB The attention paid to matrix manifolds has grown considerably in the computer vision community in recent years. There are a wide range of important applications including face recognition, action recognition, clustering, visual tracking, and motion grouping and segmentation. The increased popularity of matrix manifolds is due partly to the need to characterize image features in non-Euclidean spaces. Matrix manifolds provide rigorous formulations allowing patterns to be naturally expressed and classified in a particular parameter space. This paper gives an overview of common matrix manifolds employed in computer vision and presents a summary of related applications. Researchers in computer vision should find this survey beneficial due to the overview of matrix manifolds, the discussion as well as the collective references. (c) 2011 Elsevier B.V. All rights reserved.
C1 Colorado State Univ, Dept Comp Sci, Ft Collins, CO 80523 USA.
C3 Colorado State University
RP Lui, YM (corresponding author), Colorado State Univ, Dept Comp Sci, Ft Collins, CO 80523 USA.
EM lui@cs.colostate.edu
CR Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006
   Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P EUR SIGN PROC C
   [Anonymous], INT C PATT REC
   [Anonymous], 2003, Introduction to Smooth manifolds
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Bayro-Corrochano E, 2007, IMAGE VISION COMPUT, V25, P907, DOI 10.1016/j.imavis.2006.07.005
   Begelfor Evgeni, 2006, P IEEE C COMP VIS PA, V2, P2087, DOI DOI 10.1109/CVPR.2006.50
   Belta C, 2002, P I MECH ENG C-J MEC, V216, P47, DOI 10.1243/0954406021524909
   Beveridge JR, 2009, IEEE T PATTERN ANAL, V31, P351, DOI 10.1109/TPAMI.2008.200
   Çetingül HE, 2009, PROC CVPR IEEE, P1896, DOI 10.1109/CVPRW.2009.5206806
   Chang J.-M., 2006, P INT C IMAGE PROCES, P390
   Chang JM, 2007, LECT NOTES COMPUT SC, V4844, P733
   Chaudhry R, 2010, LECT NOTES COMPUT SC, V6312, P735, DOI 10.1007/978-3-642-15552-9_53
   Chikuse Y., 2003, STAT SPECIAL MANIFOL
   Cortez-Cargill P., 2009, INT C CHIL COMP SOC
   da Silva N.P., 2008, IEEE C COMP VIS PATT
   Ding X., 2005, SIGNAL PROCESSING MU
   Drummond T, 2000, INT J COMPUT VISION, V37, P21, DOI 10.1023/A:1008125412549
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   Drummond T., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P652, DOI 10.1109/CVPR.1999.784996
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   Govindu V., 2004, IEEE C COMP VIS PATT
   Gu QQ, 2008, IEEE IMAGE PROC, P1788, DOI 10.1109/ICIP.2008.4712123
   Guo K., 2010, INT C PATT REC IST T
   Guo K., 2010, INT C ADV VID SIGN B
   HAMM J, 2009, ADV NEURAL INFORM PR, P601
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443
   KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kwon J, 2009, PROC CVPR IEEE, P991, DOI 10.1109/CVPRW.2009.5206501
   Kwon J, 2010, INT J ROBOT RES, V29, P198, DOI 10.1177/0278364909345167
   Lebanon G, 2006, IEEE T PATTERN ANAL, V28, P497, DOI 10.1109/TPAMI.2006.77
   Li M, 2010, PROC CVPR IEEE, P1315, DOI 10.1109/CVPR.2010.5539815
   Li R., 2010, EUR C COMP VIS CRETE
   Li RN, 2010, PROC CVPR IEEE, P2038, DOI 10.1109/CVPR.2010.5539880
   Li X, 2008, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2008.4587516
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Lin D., 2005, IEEE Conference on Computer Vision and Pattern Recognition, P386
   Lin DH, 2010, PROC CVPR IEEE, P1783, DOI 10.1109/CVPR.2010.5539848
   Lin DH, 2009, PROC CVPR IEEE, P747, DOI 10.1109/CVPRW.2009.5206660
   Liu XW, 2004, IEEE T PATTERN ANAL, V26, P662, DOI 10.1109/TPAMI.2004.1273986
   Liu Y., 2010, EURASIP J. Adv. Signal Process, V2010, P1
   Lui Y.M., 2011, IEEE INT C AUT FAC G
   Lui Y.M., 2008, IEEE INT C AUT FAC G
   Lui YM, 2008, LECT NOTES COMPUT SC, V5303, P44, DOI 10.1007/978-3-540-88688-4_4
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Lui YM, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P431
   Ma Y, 2001, INT J COMPUT VISION, V44, P219, DOI 10.1023/A:1012276232049
   Ma Y, 1998, IEEE DECIS CONTR P, P3751, DOI 10.1109/CDC.1998.761802
   Mégret R, 2010, IEEE T IMAGE PROCESS, V19, P2369, DOI 10.1109/TIP.2010.2048406
   Moakher M, 2002, SIAM J MATRIX ANAL A, V24, P1, DOI 10.1137/S0895479801383877
   OHARA S, 2011, IEEE INT C AUT FAC G
   Paisitkriangkcrai S, 2008, IEEE T CIRC SYST VID, V18, P1140, DOI 10.1109/TCSVT.2008.928213
   Palaio H, 2008, INT C PATT RECOG, P245
   Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108
   Park S.W., 2011, IEEE INT C AUT FAC G
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Peterson P., 2000, SPRINGER GRADUATE TE
   Pham DS, 2008, PROC CVPR IEEE, P510
   Porikli F., 2009, IEEE INT C ADV VID S
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Rentmeesters Q, 2010, INT CONF ACOUST SPEE, P3838, DOI 10.1109/ICASSP.2010.5495828
   Rossmann W., 2002, Oxford Graduate Text in Mathematics
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scholz Erhard., 1999, History of Topology, P25
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   Sirvalingam R., 2009, IEEE INT C DISTR SMA
   Sirvalingam R., 2010, EUR C COMP VIS CRETE
   Subbarao R., 2006, IEEE C COMP VIS PATT
   Subbarao R., 2006, EUR C COMP VIS
   Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8
   Taheri S., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P306, DOI 10.1109/FG.2011.5771415
   TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tosato D., 2010, EUR C COMP VIS CRET
   Tron R., 2008, WORKSH OMN VIS MARS
   Turaga P., 2011, IND C COMP VIS GRAPH
   Turaga P., IEEE T PATT IN PRESS
   Turaga P., 2010, IEEE INT C AC SPEECH
   Turaga P., 2008, 2008 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2008.4587733, DOI 10.1109/CVPR.2008.4587733]
   Turaga P, 2009, PROC CVPR IEEE, P2427
   Tuzel O, 2005, IEEE I CONF COMP VIS, P18
   Tuzel O, 2008, PROC CVPR IEEE, P1389
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Van S., 2006, EUR C COMP VIS GRAZ
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143
   Wang G., 2009, INT C INT COMP TECHN
   Wang RP, 2008, PROC CVPR IEEE, P2940
   Wang TS, 2008, INT CONF ACOUST SPEE, P969
   Wang TS, 2009, PATTERN RECOGN LETT, V30, P1161, DOI 10.1016/j.patrec.2009.06.002
   Watanabe S., 2009, ALGEBRAIC GEOMETRY S, V25
   Wu Y, 2008, INT C PATT RECOG, P229
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
   Yu D., 2009, INT C FUZZ SYST KNOW
   Zhao DL, 2008, PROC CVPR IEEE, P39
NR 100
TC 84
Z9 93
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2012
VL 30
IS 6-7
SI SI
BP 380
EP 388
DI 10.1016/j.imavis.2011.08.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 977BA
UT WOS:000306630100002
DA 2024-07-18
ER

PT J
AU Han, YB
   Chen, RS
AF Han, Yubing
   Chen, Rushan
TI Efficient video denoising based on dynamic nonlocal means
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video denoising; Nonlocal means; Kalman filtering; Linear minimum
   variance fusion
ID WAVELET-DOMAIN; QUALITY ASSESSMENT; IMAGE; FILTER
AB A video denoising algorithm, which is based on dynamic nonlocal means (DNLM), is developed. Firstly, the standard nonlocal means and Kalman filtering are reviewed briefly. Then, using the idea of nonlocal means and linear minimum variance fusion, a weighted translational motion model without the explicit motion estimation and a weighted translational observation model are proposed to modify the state transition and observation equations. Finally, the overall dynamic denoising algorithm under the Kalman filter framework is presented. The main contribution of our work is a dynamic nonlocal means algorithm that is developed for video denoising under the Kalman filtering framework. In this algorithm, all computations are pixel-wise and it is easy to realize an efficient recursive algorithm for real-time processing. Experimental results for different test videos demonstrate the power of proposed method based on peak signal-to-noise-ratio (PSNR), structural similarity (SSIM) and motion-based video integrity evaluation index (MOVIE). The proposed method performs better than SNLM with the average PSNR gain of 2.33 dB, and outperforms SEQWT, 3DWTF and IFSM with the average SSIM gains of 0.033, 0.0087 and 0.049. It has competitive performance with STA, WRSTF and 3DSWDCT, but needs lower computational cost. Though the proposed DNLM is not competitive with several state-of-the-art video denoising algorithms such as VBM3D, K-SVD, 3D-Patch, and ST-GSM, it may be anyway valuable to readers working in this field as a source of inspiration for their further researches. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Han, Yubing; Chen, Rushan] Nanjing Univ Sci & Technol, Sch Elect Engn & Optoelect Tech, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Han, YB (corresponding author), Nanjing Univ Sci & Technol, Sch Elect Engn & Optoelect Tech, Nanjing 210094, Jiangsu, Peoples R China.
EM hanyb@mail.njust.edu.cn
OI Han, Yubing/0000-0002-2705-3546
CR Batlle J, 2002, REAL-TIME IMAGING, V8, P345, DOI 10.1006/rtim.2001.0273
   Boulanger J, 2007, IEEE T PATTERN ANAL, V29, P1096, DOI 10.1109/TPAMI.2007.1064
   BRAILEAN JC, 1995, P IEEE, V83, P1272, DOI 10.1109/5.406412
   Buades A, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P70
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Dabov Kostadin, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P145
   Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gal Y, 2010, IEEE T MED IMAGING, V29, P302, DOI 10.1109/TMI.2009.2026575
   Jin F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P349
   Jovanov L, 2009, IEEE T CIRC SYST VID, V19, P417, DOI 10.1109/TCSVT.2009.2013491
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Kim J, 1997, IEEE T IMAGE PROCESS, V6, P414, DOI 10.1109/83.557351
   Li X, 2009, IEEE T CIRC SYST VID, V19, P27, DOI 10.1109/TCSVT.2008.2005805
   Luisier F, 2010, IEEE T CIRC SYST VID, V20, P913, DOI 10.1109/TCSVT.2010.2045819
   Özkan MK, 1993, IEEE T CIRC SYST VID, V3, P277, DOI 10.1109/76.257217
   Pizurica A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P334, DOI 10.1109/AVSS.2003.1217940
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P1899, DOI 10.1109/TIP.2009.2022440
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Rahman SMM, 2007, IEEE T CIRC SYST VID, V17, P187, DOI 10.1109/TCSVT.2006.887079
   Rusanovskyy D, 2005, LECT NOTES COMPUT SC, V3708, P618
   Selesnick IW, 2003, PROC SPIE, V5207, P607, DOI 10.1117/12.504896
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Varghese G, 2010, IEEE T CIRC SYST VID, V20, P1032, DOI 10.1109/TCSVT.2010.2051366
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yin HB, 2007, IEEE T CIRC SYST VID, V17, P1714, DOI 10.1109/TCSVT.2007.904590
   Zlokolica V, 2006, IEEE T CIRC SYST VID, V16, P993, DOI 10.1109/TCSVT.2006.879994
NR 29
TC 22
Z9 26
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2012
VL 30
IS 2
BP 78
EP 85
DI 10.1016/j.imavis.2012.01.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 934ZJ
UT WOS:000303486200002
DA 2024-07-18
ER

PT J
AU Castle, RO
   Murray, DW
AF Castle, R. O.
   Murray, D. W.
TI Keyframe-based recognition and localization during video-rate parallel
   tracking and mapping
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Wearable vision; Augmented reality; Object recognition; Structure from
   motion
AB Generating situational awareness by augmenting live imagery with collocated scene information has applications from game-playing to military command and control. We propose a method of object recognition, reconstruction, and localization using triangulation of SIFT features from keyframe camera poses in a 3D map. The map and keyframe poses themselves are recovered at video-rate by bundle adjustment of FAST image features in the parallel tracking and mapping algorithm. Detected objects are automatically labeled on the user's display using predefined annotations. Experimental results are given for laboratory scenes, and in more realistic applications. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Castle, R. O.; Murray, D. W.] Univ Oxford, Dept Engn Sci, Act Vis Lab, Oxford OX1 3PJ, England.
C3 University of Oxford
RP Murray, DW (corresponding author), Univ Oxford, Dept Engn Sci, Act Vis Lab, Parks Rd, Oxford OX1 3PJ, England.
EM bob@robots.ox.ac.uk; dwm@robots.ox.ac.uk
FU UK Engineering and Physical Science Research Council [EP/D037077]
FX This work was supported by the Platform Grant Virtual Oxford from UK
   Engineering and Physical Science Research Council (Grant EP/D037077).
   The authors thank the Director of the Ashmolean Museum of Art and
   Archaeology for permission to experiment within its galleries.
CR [Anonymous], P 9 EUR C COMP VIS
   [Anonymous], P 12 IEEE INT S WEAR
   [Anonymous], THESIS U OXFORD
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], P 18 BRIT MACH VIS C
   [Anonymous], NONLINEAR LEAST SQUA
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393
   Castle RO, 2010, IMAGE VISION COMPUT, V28, P1548, DOI 10.1016/j.imavis.2010.03.009
   Castle RO, 2009, INT SYM MIX AUGMENT, P179, DOI 10.1109/ISMAR.2009.5336477
   Choi M.J., 2010, P 28 IEEE C COMP VIS
   Collins C.A., 1850, CONVENT THOUGHTS W A
   Davison AJ, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P18, DOI 10.1109/ISMAR.2003.1240684
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   Faugeras O.D., 1983, P 8 INT JOINT C ARTI, V2, P996
   Fergus R, 2003, PROC CVPR IEEE, P264
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon A. W., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P311, DOI 10.1007/BFb0055675
   GENNERY DB, 1992, INT J COMPUT VISION, V7, P243, DOI 10.1007/BF00126395
   Gordon I, 2006, LECT NOTES COMPUT SC, V4170, P67
   Holmes S.A., 2009, P 2009 IEEE INT C RO
   HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127
   Klein G., 2007, 6 IEEE ACM INT S MIX
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Mayol W.W., 2003, INT S ROB RES SIEN I, P325
   McGlone C., 2004, MANUAL PHOTOGRAMMETR, V5th
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   NISTER D, 2001, THESIS ROYAL I TECHN
   Nistér D, 2006, J FIELD ROBOT, V23, P3, DOI 10.1002/rob.20103
   Opelt A, 2008, INT J COMPUT VISION, V80, P16, DOI 10.1007/s11263-008-0139-3
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Sinha SN, 2011, MACH VISION APPL, V22, P207, DOI 10.1007/s00138-007-0105-z
   Stennett C., 1990, P BMVC, P1
   Strasdat H., 2010, P 2010 IEEE INT C RO
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   Wagner D., 2008, Proceedings of the 7th IEEE and ACM intl. symposium on mixed and augmented reality (ISMAR'08), Cambridge
   Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2
NR 45
TC 13
Z9 15
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2011
VL 29
IS 8
BP 524
EP 532
DI 10.1016/j.imavis.2011.05.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 822RB
UT WOS:000295066200003
DA 2024-07-18
ER

PT J
AU Dinh, CV
   Leitner, R
   Paclik, P
   Loog, M
   Duin, RPW
AF Dinh, Cuong V.
   Leitner, Raimund
   Paclik, Pavel
   Loog, Marco
   Duin, Robert P. W.
TI SEDMI: Saliency based edge detection in multispectral images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multispectral image analysis; Edge detection; Saliency; Ensemble
   clustering
AB Detecting edges in multispectral images is difficult because different spectral bands may contain different edges. Existing approaches calculate the edge strength of a pixel locally, based on the variation in intensity between this pixel and its neighbors. Thus, they often fail to detect the edges of objects embedded in background clutter or objects which appear in only some of the bands.
   We propose SEDMI, a method that aims to overcome this problem by considering the salient properties of edges in an image. Based on the observation that edges are rare events in the image, we recast the problem of edge detection into the problem of detecting events that have a small probability in a newly defined feature space. The feature space is constructed by the spatial gradient magnitude in all spectral channels. As edges are often confined to small, isolated clusters in this feature space, the edge strength of a pixel, or the confidence value that this pixel is an event with a small probability, can be calculated based on the size of the cluster to which it belongs.
   Experimental results on a number of multispectral data sets and a comparison with other methods demonstrate the robustness of the proposed method in detecting objects embedded in background clutter or appearing only in a few bands. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Dinh, Cuong V.; Loog, Marco; Duin, Robert P. W.] Delft Univ Technol, Pattern Recognit Lab, Delft, Netherlands.
   [Paclik, Pavel] PR Sys Design, Delft, Netherlands.
   [Dinh, Cuong V.; Leitner, Raimund] Carinthian Tech Res AG, Villach, Austria.
C3 Delft University of Technology; Carinthian Tech Research AG (CTR)
RP Dinh, CV (corresponding author), Delft Univ Technol, Pattern Recognit Lab, Delft, Netherlands.
EM v.c.dinh@tudelft.nl
RI cai, bo/G-1491-2010
OI Leitner, Raimund/0000-0001-9808-2320
FU Carinthian Tech Research AG, Austria
FX The authors would like to thank Sergey Verzakov, David Tax and Yan Li
   for useful discussions. We thank the anonymous reviewers for fruitful
   comments and stimulating questions which greatly improved the revised
   manuscript. This research is supported by Carinthian Tech Research AG,
   Austria through the Austrian COMET funding program.
CR [Anonymous], HYPERSPECTRAL IMAGES
   [Anonymous], 1988, Proceedings of International Conference ofComputer Vision (ICCV'88), DOI [10.1109/CCV.1988.590008, DOI 10.1109/CCV.1988.590008]
   BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CARRON T, 1994, IEEE IMAGE PROC, P977, DOI 10.1109/ICIP.1994.413699
   Chapron M., 2000, IEEE INT C IM PROC, V2
   CUMANI A, 1991, CVGIP-GRAPH MODEL IM, V53, P40, DOI 10.1016/1049-9652(91)90018-F
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Duin R., 2015, Prtools, a matlab toolbox for pattern recognition
   Eskin E., 2002, GEOMETRIC FRAMEWORK
   Evans AN, 2006, IEEE T IMAGE PROCESS, V15, P1454, DOI 10.1109/TIP.2005.864164
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113
   Green D., 1988, CVGIP-GRAPH MODEL IM
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   He ZY, 2003, PATTERN RECOGN LETT, V24, P1641, DOI 10.1016/S0167-8655(03)00003-5
   Hedley M., 1992, Journal of Electronic Imaging, V1, P374, DOI 10.1117/12.61158
   Kanade T., 1987, Image Understanding Workshop Proceedings, P32
   Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946
   Koschan A, 2005, IEEE SIGNAL PROC MAG, V22, P64, DOI 10.1109/MSP.2005.1407716
   Krzanowski WJ, 2009, MONOGR STAT APPL PRO, V111, P1
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Lisin D, 2003, LECT NOTES COMPUT SC, V2626, P481
   Loog M, 2010, IEEE T PATTERN ANAL, V32, P1141, DOI 10.1109/TPAMI.2010.53
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Moore A. W., 1990, EFFICIENT MEMORY BAS
   Nascimento SMC, 2002, J OPT SOC AM A, V19, P1484, DOI 10.1364/JOSAA.19.001484
   Paclik P., 2005, J IMAGE VISION COMPU, V21, P473
   Papari G, 2008, IEEE T IMAGE PROCESS, V17, P1950, DOI 10.1109/TIP.2008.2002306
   Piater J.H., 2001, THESIS UMASS AMHERST
   ROBINSON GS, 1977, OPT ENG, V16, P479, DOI 10.1117/12.7972120
   ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519
   ROSIN PL, 1995, INT GEOSCI REMOTE SE, P93, DOI 10.1109/IGARSS.1995.519657
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Toivanen PJ, 2003, PATTERN RECOGN LETT, V24, P2987, DOI 10.1016/S0167-8655(03)00159-4
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P259, DOI 10.1109/83.217230
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   Walker K. N., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P557
NR 40
TC 7
Z9 10
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2011
VL 29
IS 8
BP 546
EP 556
DI 10.1016/j.imavis.2011.06.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 822RB
UT WOS:000295066200005
DA 2024-07-18
ER

PT J
AU Hernández, J
   Marcotegui, B
AF Hernandez, Jorge
   Marcotegui, Beatriz
TI Shape ultimate attribute opening
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ultimate opening; Attribute opening; Mathematical morphology; Shape
   information; Image segmentation; Facade analysis; Scene-text detection;
   Cell segmentation
ID CONNECTED OPERATORS; APPROXIMATIONS; ALGORITHMS; SPECTRUM; IMAGE
AB The ultimate opening (UO) is a powerful segmentation operator recently introduced by Beucher [1]. It automatically selects the most contrasted regions of an image. However, in the presence of nested structures (e.g. text in a signboard or windows in a contrasted facade), interesting structures may be masked by the containing region. In this paper we focus on ultimate attribute openings and we propose a method that improves the results by favoring regions with a predefined shape via a similarity function. An efficient implementation using a max-tree representation of the image is proposed. The method is validated in the framework of three applications: facade analysis, scene-text detection and cell segmentation. Experimental results show that the proposed method yields better segmentation results than UO. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Hernandez, Jorge; Marcotegui, Beatriz] Mines ParisTech, CMM, Ctr Morphol Math Math & Syst, F-77305 Fontainebleau, France.
C3 Universite PSL; MINES ParisTech
RP Marcotegui, B (corresponding author), Mines ParisTech, CMM, Ctr Morphol Math Math & Syst, 35 Rue St Honore, F-77305 Fontainebleau, France.
EM jorge.hernandez@mines-paristech.fr;
   beatriz.marcotegui@mines-paristech.fr
CR [Anonymous], 1994, Digital Image Processing Methods
   Benner J., 2005, 1 INT WORKSH NEXT GE
   Beucher S, 2007, IMAGE VISION COMPUT, V25, P405, DOI 10.1016/j.imavis.2006.07.020
   Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x
   Fabrizio J, 2009, LECT NOTES COMPUT SC, V5720, P272, DOI 10.1007/978-3-642-03613-2_25
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Hamarneh G, 2009, IMAGE VISION COMPUT, V27, P59, DOI 10.1016/j.imavis.2006.10.009
   Hanbury A., 2001, P BMVC 2001, V2, P451
   Hernandez J., 2009, DOCUMENT IMAGE BINAR
   Hernández J, 2009, LECT NOTES COMPUT SC, V5720, P205, DOI 10.1007/978-3-642-03613-2_19
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Korc F., 2009, etrims image database for interpreting images of man-made scenes
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   Matheron G., 1975, Random sets and integral geometry
   Mayer H, 2005, COMP MED SY, P55, DOI 10.1109/CBMS.2005.25
   Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556
   Meyer F, 2001, INT J PATTERN RECOGN, V15, P1089, DOI 10.1142/S0218001401001337
   Müller P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276484, 10.1145/1239451.1239536]
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nguyen HT, 2003, IEEE T PATTERN ANAL, V25, P330, DOI 10.1109/TPAMI.2003.1182096
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Outal S., 2006, THESIS CMM
   Park J, 2001, IEEE T PATTERN ANAL, V23, P1201, DOI 10.1109/34.954609
   Retornaz T., 2007, THESIS ECOLE MINES P
   SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422
   Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500
   SCHONFELD D, 1990, INT CONF ACOUST SPEE, P2065, DOI 10.1109/ICASSP.1990.115934
   SHIH FY, 1992, PATTERN RECOGN, V25, P921, DOI 10.1016/0031-3203(92)90058-Q
   Tushabe F, 2007, WCECS 2007: WORLD CONGRESS ON ENGINEERING AND COMPUTER SCIENCE, P999
   Urbach ER, 2005, COMPUT IMAGING VIS, V30, P95
   Urbach ER, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P305
   Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28
   Veltkamp R.C., 1999, STATE OF THE ART SHA
   Veltkamp RC, 2000, LECT NOTES COMPUT SC, V1929, P467
   Vincent Luc, 1994, SHAPE IN PICTURE, P197, DOI [10.1007/978-3-662-03039-4_13, DOI 10.1007/978-3-662-03039-4_13]
   Wilkinson MHF, 2000, COMP IMAG VIS, V18, P311
   Wilkinson MichaelH. F., 2001, Proc. Medical Image Computing and Computer-Assisted Intervention (MICCAI 01), P770, DOI DOI 10.1007/3-540-45468-3_92
   Yin Z, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-264
NR 41
TC 14
Z9 14
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2011
VL 29
IS 8
BP 533
EP 545
DI 10.1016/j.imavis.2011.05.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 822RB
UT WOS:000295066200004
DA 2024-07-18
ER

PT J
AU Kang, B
   Jeon, C
   Han, DK
   Ko, H
AF Kang, Bonghyup
   Jeon, Changwon
   Han, David K.
   Ko, Hanseok
TI Adaptive height-modified histogram equalization and chroma correction in
   YCbCr color space for fast backlight image compensation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Backlight compensation; Image enhancement; Contrast enhancement;
   Histogram equalization; Saturation
AB Automatic exposure controls in commercially available cameras often encounter difficulties in capturing scenes with backlight luminance which dominates the entire image. An Adaptive Height-Modified Histogram Equalization (AHMHE) algorithm is proposed as a compensation technique for backlight images. It simultaneously enhances contrast in both the dark and the bright areas without creating regions of degraded local contrast. Moreover AHMHE is an adaptive algorithm: thus it requires minimal user input, and its reduced computational requirement makes it suitable for real-time application. In addition to AHMHE, a chroma correction technique was applied to chroma components in the YCbCr color space to produce more vivid color images. A series of subjective and index evaluations were conducted to measure the resultant image quality improvements by the AHMHE and the chroma correction algorithms. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Jeon, Changwon; Ko, Hanseok] Korea Univ, Seoul, South Korea.
   [Kang, Bonghyup] Samsung, Songnam, South Korea.
   [Han, David K.] Off Naval Res, Ballston, VA USA.
C3 Korea University
RP Ko, H (corresponding author), Korea Univ, Seoul, South Korea.
EM bh47.kang@samsung.com; cwjeon@ispl.korea.ac.kr; ctmkhan@gmail.com;
   hsko@korea.ac.kr
OI Ko, Hanseok/0000-0002-8744-4514
FU Samsung Techwin RD Joint Lab; Korea University
FX This research was supported in part by Samsung Techwin R&D Joint Lab
   fund and partially by a Korea University grant.
CR Eramian M, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P397, DOI 10.1109/CRV.2005.47
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Gonazlez R.C., 1981, REAL TIME DIGITAL IM
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   JI TL, 1994, IEEE T MED IMAGING, V13, P573, DOI 10.1109/42.363111
   Jobson D.J., 2006, VIS INF PROC, VXV, P6246
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   MacDonald L.W., 1998, COLOR IMAGING VISION, P363
   Munteanu C., 2004, IEEE T SYST, V34
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Su MC, 2002, IEEE IJCNN, P1396, DOI 10.1109/IJCNN.2002.1007720
   Yang S, 2003, IEEE IMAGE PROC, P881
NR 14
TC 18
Z9 19
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2011
VL 29
IS 8
BP 557
EP 568
DI 10.1016/j.imavis.2011.06.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 822RB
UT WOS:000295066200006
DA 2024-07-18
ER

PT J
AU Pang, ZF
   Yang, YF
AF Pang, Zhi-Feng
   Yang, Yu-Fei
TI A projected gradient algorithm based on the augmented Lagrangian
   strategy for image restoration and texture extraction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Augmented Lagrangian strategy; Image restoration; Texture extraction;
   Projected gradient method; Total variation; High-order PDEs
ID TOTAL VARIATION MINIMIZATION
AB Based on the augmented Lagrangian strategy, we construct a projected gradient algorithm for image restoration and texture extraction. The proposed algorithm is established on the basis of a mixed model which combines the Rudin-Osher-Fatemi (ROF) model with the Lysaker-Lundevold-Tai (LLT) model to reduce the staircase effect and blur phenomenons. The proof of the convergence of the proposed algorithm is provided. Moreover, we show that the dual methods based on convex analysis which have been proposed in some papers can be actually deduced from the augmented Lagrangian strategy. Some numerical examples are supplied to illustrate the efficiency of the proposed algorithm. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Pang, Zhi-Feng] Henan Univ, Coll Math & Informat Sci, Kaifeng 475004, Peoples R China.
   [Yang, Yu-Fei] Hunan Univ, Coll Math & Econometr, Changsha 410082, Hunan, Peoples R China.
C3 Henan University; Hunan University
RP Pang, ZF (corresponding author), Henan Univ, Coll Math & Informat Sci, Kaifeng 475004, Peoples R China.
EM zhifengpang@163.com; yfyang@hnu.cn
RI Yang, Yufei/JXX-6325-2024; Yang, yufei/KHW-2735-2024; ,
   zhifengpang/AAE-6852-2020
OI Pang, Zhi-Feng/0000-0001-6824-3509
FU NNSF of China [60872129, 60835004]; Science and Technology Project of
   Hunan Province [2009SK3027]
FX The research was supported in part by the NNSF of China (No. 60872129,
   60835004) and the Science and Technology Project of Hunan Province (No.
   2009SK3027). The authors also thank the referees very much for their
   valuable comments and suggestions.
CR [Anonymous], 1984, MINIMAL SURFACES FUN
   [Anonymous], 1983, Infinite-dimensional optimization and convexity
   Aujol JF, 2009, J MATH IMAGING VIS, V34, P307, DOI 10.1007/s10851-009-0149-y
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chambolle A, 2005, LECT NOTES COMPUT SC, V3757, P136, DOI 10.1007/11585978_10
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan T.F., 2006, IMS LECT NOTES
   Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767
   Chan TF, 2007, J VIS COMMUN IMAGE R, V18, P464, DOI 10.1016/j.jvcir.2006.12.004
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Chen HZ, 2009, ADV COMPUT MATH, V31, P115, DOI 10.1007/s10444-008-9097-0
   Ito K, 2000, NONLINEAR ANAL-THEOR, V41, P591, DOI 10.1016/S0362-546X(98)00299-5
   Ito K., 1999, ESAIM-MATH MODEL NUM, V33, P909
   Li F, 2007, J VIS COMMUN IMAGE R, V18, P322, DOI 10.1016/j.jvcir.2007.04.005
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Nikolova M, 2004, J MATH IMAGING VIS, V21, P155, DOI 10.1023/B:JMIV.0000035180.40477.bd
   PAZY A, 1979, PITMAN RES NOTES MAT, V30
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Scherzer O, 1998, COMPUTING, V60, P1, DOI 10.1007/BF02684327
   Setzer S., 2008, APPROXIMATION, P360
   Steidl G, 2006, COMPUTING, V76, P135, DOI 10.1007/s00607-005-0129-z
   Tai XC, 2009, LECT NOTES COMPUT SC, V5567, P502
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   ZHU M, COMPUTATIONAL OPTIMI
NR 27
TC 12
Z9 16
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2011
VL 29
IS 2-3
BP 117
EP 126
DI 10.1016/j.imavis.2010.08.012
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 707NV
UT WOS:000286294200003
DA 2024-07-18
ER

PT J
AU Lo, EHS
   Pickering, MR
   Frater, MR
   Arnold, JF
AF Lo, Edward H. S.
   Pickering, Mark R.
   Frater, Michael R.
   Arnold, John F.
TI Image segmentation from scale and rotation invariant texture features
   from the double dyadic dual-tree complex wavelet transform
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE DT CWT; (DT)-T-3 CWT; Image segmentation; Scale and rotation invariant
   texture features
ID RETRIEVAL; COLOR
AB A goal of Image segmentation is to divide an image into regions that have some semantic meaning Because regions of semantic meaning often include variations in colour and intensity various segmentation algorithms that use multi pixel textures have been developed A challenge for these algorithms is to Incorporate invariance to rotation and changes in scale In this paper we propose a new scale and rotation invariant texture based segmentation algorithm that performs feature extraction using the Dual-Tree Complex Wavelet Transform (DT-CWT) The DT-CWT is used to analyse a signal at and between dyadic scales The performance of image segmentation using this new method is compared with existing techniques over different imagery databases with operator produced ground truth data Compared with previous algorithms our segmentation results show that the new texture feature is capable of performing well over general images and particularly well over images containing objects with scaled and rotated textures (C) 2010 Elsevier B V All rights reserved
C1 [Lo, Edward H. S.; Pickering, Mark R.; Frater, Michael R.; Arnold, John F.] Australian Def Force Acad, Univ New S Wales, Sch Engn & Informat Technol, Canberra, ACT, Australia.
C3 Australian Defense Force Academy; University of New South Wales Sydney
RP Lo, EHS (corresponding author), Australian Def Force Acad, Univ New S Wales, Sch Engn & Informat Technol, Canberra, ACT, Australia.
RI cai, bo/G-1491-2010
CR [Anonymous], P INT C IM VID RETR
   [Anonymous], P INT C IM PROC IEEE
   [Anonymous], P INT C IM PROC IEEE, DOI DOI 10.1109/ICIP.1995.537578
   [Anonymous], P 8 INT C COMP VIS
   [Anonymous], THESIS NATL U SINGAP
   [Anonymous], MARTINEZ EXPLORATORY
   [Anonymous], P 2 INT WORKSH TEXT
   [Anonymous], THESIS U CAMBRIDGE C
   [Anonymous], P INT C IM PROC IEEE
   [Anonymous], P INT C IM PROC IEEE
   [Anonymous], P COMP VIS THEOR APP
   [Anonymous], P INT C AC SPEECH SI
   [Anonymous], P INT C IM PROC IEEE
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], THESIS U CAMBRIDGE C
   [Anonymous], 2004, Understanding Digital Signal Processing
   Chabrier S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/96306
   Comaniciu D, 1999, PATTERN ANAL APPL, V2, P22, DOI 10.1007/s100440050011
   Dong JY, 2005, INT J COMPUT VISION, V62, P177, DOI 10.1007/s11263-005-4641-6
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gibson J.J., 1950, PERCEPTION VISUAL WO
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kam AH, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P91, DOI 10.1109/IVL.2000.853846
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kingsbury N, 1999, PHILOS T R SOC A, V357, P2543, DOI 10.1098/rsta.1999.0447
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mirmehdi M, 2000, IEEE T PATTERN ANAL, V22, P142, DOI 10.1109/34.825753
   RANDEN T, 1994, OPT ENG, V33, P2617, DOI 10.1117/12.177115
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   UNSER M, 1990, IEEE T SYST MAN CYB, V20, P804, DOI 10.1109/21.105080
   Zhang N., 1998, PROC ASIAN C COMPUTE, P17
   Zhang X., 1997, Journal of the Society for Information Display, V5, P61, DOI 10.1889/1.1985127
NR 40
TC 18
Z9 18
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2011
VL 29
IS 1
BP 15
EP 28
DI 10.1016/j.imavis.2010.08.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 679BP
UT WOS:000284134700002
DA 2024-07-18
ER

PT J
AU Chow, CK
   Yuen, SY
AF Chow, Chi Kin
   Yuen, Shiu Yin
TI A solution to illumination direction estimation of a shaded image:
   Genetic algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Illumination direction estimation; Shape from shading; Fast marching
   method; Genetic algorithm
ID SHAPE; FORMULATION
AB In oblique shape from shading (SfS), the illumination direction is essential for recovering the 3D surface of a shaded image. On the other hand, fast marching methods (FMM) are SfS algorithms that use the mechanism of wave propagation to reconstruct the surface. In this paper, the estimation of illumination direction is addressed and we model it as an optimization problem. The idea is to minimize the inconsistency of wave propagation of FMM during the reconstruction. As the consistency of wave propagation is a multi-modal function of illumination direction, genetic algorithm (GA) is utilized. The proposed algorithm is examined on four synthetic models and a real world object. The experimental results show that the proposed algorithm is superior to benchmark methods. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Chow, Chi Kin; Yuen, Shiu Yin] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Yuen, SY (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM kelviny.ee@cityu.edu.hk
RI Yuen, Shiu Yin/B-7569-2008
OI YUEN, Shiu Yin Kelvin/0000-0002-5889-8808
FU Research Grant Council of the Hong Kong Special Administrative Region,
   China [124409]
FX The work described in this paper was supported by a grant from the
   Research Grant Council of the Hong Kong Special Administrative Region,
   China [Project No. CityU 124409].
CR [Anonymous], 1995, Tech. Rep. TR-95-012
   [Anonymous], 1989, Shape from shading
   Belhumeur PN, 1996, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.1996.517085
   Cho SY, 2001, IEEE T NEURAL NETWOR, V12, P1204, DOI 10.1109/72.950148
   Chow CK, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P7
   Chow CK, 2009, INT J COMPUT VISION, V85, P58, DOI 10.1007/s11263-009-0240-2
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Dupuis P, 1994, ANN APPL PROBAB, V4, P287, DOI 10.1214/aoap/1177005063
   Hansen N., 2007, CMA EVOLUTIONARY STR
   Ikeda O, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/92456
   Kimmel R, 2001, J MATH IMAGING VIS, V14, P237, DOI 10.1023/A:1011234012449
   Leclerc Y. G., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P552, DOI 10.1109/CVPR.1991.139752
   Samaras D, 2003, IEEE T PATTERN ANAL, V25, P247, DOI 10.1109/TPAMI.2003.1177155
   Tankus A, 2005, INT J COMPUT VISION, V63, P21, DOI 10.1007/s11263-005-4945-6
   VERBEEK PW, 1990, PATTERN RECOGN LETT, V11, P681, DOI 10.1016/0167-8655(90)90102-8
   Yuen SY, 2007, PATTERN RECOGN LETT, V28, P806, DOI 10.1016/j.patrec.2006.11.008
   ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658
NR 17
TC 6
Z9 6
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1717
EP 1730
DI 10.1016/j.imavis.2010.06.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300012
DA 2024-07-18
ER

PT J
AU Castle, RO
   Klein, G
   Murray, DW
AF Castle, R. O.
   Klein, G.
   Murray, D. W.
TI Combining monoSLAM with object recognition for scene augmentation using
   a wearable camera
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Wearable vision; Augmented reality; Object recognition; Simultaneous
   localization and mapping
ID GPS
AB In wearable visual computing, maintaining a time-evolving representation of the 3D environment along with the pose of the camera provides the geometrical foundation on which person-centred processing can be built. In this paper, an established method for the recognition of feature clusters is used on live imagery to identify and locate planar objects around the wearer. Objects' locations are incorporated as additional 3D measurements into a monocular simultaneous localization and mapping process, which routinely uses 2D image measurements to acquire and maintain a map of the surroundings, irrespective of whether objects are present or not. Augmenting the 3D maps with automatically recognized objects enables useful annotations of the surroundings to be presented to the wearer. After demonstrating the geometrical integrity of the method, experiments show its use in two augmented reality applications. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Castle, R. O.; Klein, G.; Murray, D. W.] Univ Oxford, Dept Engn Sci, Act Vis Lab, Oxford OX1 3PJ, England.
C3 University of Oxford
RP Murray, DW (corresponding author), Univ Oxford, Dept Engn Sci, Act Vis Lab, Parks Rd, Oxford OX1 3PJ, England.
EM bob@robots.ox.ac.uk; gk@robots.ox.ac.uk; dwm@robots.ox.ac.uk
FU UK's Engineering and Physical Science Research Council [GR/S97774,
   EP/D037077]
FX This work was supported by grants GR/S97774 and EP/D037077 from the UK's
   Engineering and Physical Science Research Council. The authors are
   grateful for discussion with David Lowe during his sabbatical visit to
   Oxford, and to colleagues Brian Williams and Ian Reid for the use of
   their camera recovery code.
CR [Anonymous], P ROB SCI SYST
   [Anonymous], 1990, Autonomous Robot Vehicles, DOI 10.1007/978-1-4613-8997-2{}14
   Ashbrook D, 2003, PERS UBIQUIT COMPUT, V7, P275, DOI 10.1007/s00779-003-0240-0
   Bar-Shalom Y., 1988, MATH SCI ENG, V179
   Bunnun P, 2008, INT SYM MIX AUGMENT, P61, DOI 10.1109/ISMAR.2008.4637325
   CASTLE RO, 2009, THESIS U OXFORD
   Castle RO, 2009, INT SYM MIX AUGMENT, P179, DOI 10.1109/ISMAR.2009.5336477
   Civera J, 2007, LECT NOTES COMPUT SC, V4478, P412
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   DAVISON KJ, 1998, LNCS, V1407, P809
   FITZGIBBON A, 1998, LECT NOTES COMPUTER, V1406, P311
   Foxlin EM, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P527, DOI 10.1109/IRDS.2002.1041444
   Gordon I, 2006, LECT NOTES COMPUT SC, V4170, P67
   Hariharan R, 2004, LECT NOTES COMPUT SC, V3234, P106
   Klein George, 2007, P1
   KNIGHT J, 2001, P IEEE RSJ INT C INT, P406
   Kourogi M, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P107, DOI 10.1109/ISWC.2001.962109
   Leonard J., 2003, P INT JOINT C ARTIFI, P1143
   Leonard JJ, 2001, LECT NOTES CONTR INF, V271, P533
   LEONARD JJ, 1992, INT J ROBOT RES, V11, P286, DOI 10.1177/027836499201100402
   LEONARD JJ, 1992, DURRANT WHYTE DIRECT
   Liao L, 2007, INT J ROBOT RES, V26, P119, DOI 10.1177/0278364907073775
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mayol WW, 2002, PERS UBIQUIT COMPUT, V6, P37, DOI 10.1007/s007790200004
   Mayol WW, 2005, SPRINGER TRAC ADV RO, V15, P325
   MOURAGNON E, 2006, P 24 IEEE C COMP VIS, P363
   NISTER D, 2001, THESIS ROYAL I TECHN
   Nister D., 2006, J FIELD ROBOTICS, V23
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   POSNER HI, 2006, P 10 INT S EXP ROB, P85
   Reitmayr G., 2007, P IEEEACM INT S MIXE, P67
   Rottmann A., 2005, Conference on Artificial Intelligence AAAI, P1306
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479
   Thrun S, 2004, IEEE T ROBOTIC AUTOM, V20, P433, DOI 10.1109/TRA.2004.825520
   Thrun S., 2005, PROBABILISTIC ROBOTI
   van den Hengel A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239537, 10.1145/1276377.1276485]
   Vidal-Calleja T, 2006, IEEE INT CONF ROBOT, P1930, DOI 10.1109/ROBOT.2006.1641988
   Williams BT, 2007, ROUTL STUD LITERACY, V3, P1
NR 42
TC 49
Z9 57
U1 1
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2010
VL 28
IS 11
BP 1548
EP 1556
DI 10.1016/j.imavis.2010.03.009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 639KD
UT WOS:000280972800005
DA 2024-07-18
ER

PT J
AU Tsapanos, N
   Tefas, A
   Pitas, I
AF Tsapanos, Nikolaos
   Tefas, Anastasios
   Pitas, Ioannis
TI Online shape learning using binary search trees
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Incremental learning techniques; Online pattern recognition; Binary
   search trees
ID DISTANCE; IMAGES
AB In this paper we propose an online shape learning algorithm based on the self-balancing binary search tree data structure for the storage and retrieval of shape templates. This structure can also be used for classification purposes. We introduce a similarity measure with which we can make decisions on how to traverse the tree and even backtrack through the search path to find more candidate matches. Then we describe every basic operation a binary search tree can perform adapted to such a tree of shapes. Note that as a property of binary search trees, all operations can be performed in O(logn) time and are very efficient. Finally, we present experimental data evaluating the performance of the proposed algorithm and demonstrating the suitability of this data structure for the purpose it was designed to serve. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Tsapanos, Nikolaos; Tefas, Anastasios; Pitas, Ioannis] Aristotle Univ Thessaloniki, Dept Informat, GR-54124 Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Tsapanos, N (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Box 451, GR-54124 Thessaloniki, Greece.
EM niktsap@aiia.csd.auth.gr
RI Tefas, Anastasios/ABA-2328-2020; Tefas, Anastasios/F-1899-2010
OI Tefas, Anastasios/0000-0003-1288-3667
FU European Community [FP7/2007-2013, 211471]
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme (FP7/2007-2013) under
   Grant agreement No. 211471 (i3DPost).
CR ADELSONVELSKII GM, 1962, DOKL AKAD NAUK SSSR+, V146, P263
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 1998, The art of computer programming: Sorting and searching
   [Anonymous], P 12 INT C PATT REC, DOI DOI 10.1109/ICPR.1994.576361
   [Anonymous], 2006, Advances in neural information processing systems
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Borodin Allan., ONLINE COMPUTATION C
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   RUCKLIDGE WJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P457, DOI 10.1109/ICCV.1995.466904
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   [No title captured]
   [No title captured]
NR 15
TC 3
Z9 3
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2010
VL 28
IS 7
SI SI
BP 1146
EP 1154
DI 10.1016/j.imavis.2009.10.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 603UP
UT WOS:000278233900008
DA 2024-07-18
ER

PT J
AU Perina, A
   Cristani, M
   Murino, V
AF Perina, Alessandro
   Cristani, Marco
   Murino, Vittorio
TI Learning natural scene categories by selective multi-scale feature
   extraction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image representation; Image classification; Generative modeling
ID IMAGE RETRIEVAL; WORDS
AB Natural scene categorization from images represents a very useful task for automatic image analysis systems. In the literature, several methods have been proposed facing this issue with excellent results. Typically, features of several types are clustered so as to generate a vocabulary able to describe in a multifaceted way the considered image collection. This vocabulary is formed by a discrete set of visual codewords whose co-occurrence and/or composition allows to classify the scene category. A common drawback of these methods is that features are usually extracted from the whole image, actually disregarding whether they derive properly from the natural scene to be classified or from foreground objects, possibly present in it, which are not peculiar for the scene. As quoted by perceptual studies, objects present in an image are not useful to natural scene categorization, indeed bringing an important source of clutter, in dependence of their size.
   In this paper, a novel, multi-scale, statistical approach for image representation aimed at scene categorization is presented. The method is able to select, at different levels, sets of features that represent exclusively the scene disregarding other non-characteristic, clutter, elements. The proposed procedure, based on a generative model, is then able to produce a robust representation scheme, useful for image classification. The obtained results are very convincing and prove the goodness of the approach even by just considering simple features like local color image histograms. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Perina, Alessandro; Cristani, Marco; Murino, Vittorio] Univ Verona, Dipartimento Informat, I-37134 Verona, Italy.
   [Cristani, Marco; Murino, Vittorio] IIT, I-16163 Genoa, Italy.
C3 University of Verona; Istituto Italiano di Tecnologia - IIT
RP Perina, A (corresponding author), Univ Verona, Dipartimento Informat, Str Grazie 15, I-37134 Verona, Italy.
EM alessandro.perina@univr.it; marco.cristani@univr.it;
   vittorio.murino@univr.it
RI Murino, Vittorio/A-5570-2011; Cristani, Marco/I-5275-2012
OI Murino, Vittorio/0000-0002-8645-2328
CR [Anonymous], 2006, 2006 C COMP VIS PATT
   [Anonymous], P 7 EUR C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   BOSCH A, 2006, P ECCV, P517, DOI DOI 10.1007/11744085_40
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Figueiredo M. A. T., 1999, Energy Minimization Methods in Computer Vision and Pattern Recognition. Second International Workshop, EMMCVPR'99. Proceedings (Lecture Notes in Computer Science Vol.1654), P54
   Frey BJ, 2005, IEEE T PATTERN ANAL, V27, P1392, DOI 10.1109/TPAMI.2005.169
   Geusebroek JM, 2005, INT J COMPUT VISION, V62, P7, DOI 10.1007/s11263-005-4632-7
   GHAHRAMANI Z, 1997, CRGTR971
   Hadjidemetriou E, 2004, IEEE T PATTERN ANAL, V26, P831, DOI 10.1109/TPAMI.2004.32
   Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4
   Henderson JM, 2005, VIS COGN, V12, P849, DOI 10.1080/13506280444000544
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Jojic N, 2001, PROC CVPR IEEE, P199
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666
   LI F, 2005, P IEEE C COMP VIS PA, V1, P524
   LIU D, 2006, P IEEE CVPR WORKSH P, P16
   Liu D, 2007, IEEE I CONF COMP VIS, P191
   Liu D, 2006, INT C PATT RECOG, P468
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mojsilovic A, 2004, INT J COMPUT VISION, V56, P79, DOI 10.1023/B:VISI.0000004833.39906.33
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051
   ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9
   Rosch E., 1978, COGNITION CATEGORIZA, P27, DOI DOI 10.1016/B978-1-4832-1446-7.50028-5
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Russell B.C., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1605, DOI DOI 10.1109/CVPR.2006.326
   Salton G, 1986, Introduction to Modern Information Retrieval
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
   TVERSKY B, 1983, COGNITIVE PSYCHOL, V15, P121, DOI 10.1016/0010-0285(83)90006-3
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Veltkamp RC, 1999, STATE OF THE ART CON, P97, DOI [10.1007/978-94-015-9664-0_5, DOI 10.1007/978-94-015-9664-0_5]
   Vogel J, 2004, LECT NOTES COMPUT SC, V3175, P195
   Vogel J., 2006, P 3 S APPL PERCEPTIO, V153, P33
   VOGEL J, 2004, SELECTED READINGS VI, V33
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   2004, WASHINGTON GROUND TR
NR 52
TC 10
Z9 12
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 927
EP 939
DI 10.1016/j.imavis.2009.11.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200008
DA 2024-07-18
ER

PT J
AU Sen, D
   Pal, SK
AF Sen, Debashis
   Pal, Sankar K.
TI Gradient histogram: Thresholding in a region of interest for edge
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Edge detection; Gradient operators; Random process; Gradient histogram;
   Skewness and kurtosis; Threshold determination; Non-maximum suppression;
   Hysteresis thresholding
ID GAUSSIAN-MARKOV; SELECTION; COLOR
AB Selecting a threshold from the gradient histogram, a histogram of gradient magnitudes, of an image plays a crucial role in a gradient based edge detection system. This paper presents a methodology to determine the threshold from a gradient histogram generated using any kind of linear gradient operator on an image. We consider the image as a random process with dependent samples, model the gradient histogram using theories of random process and random input to a system, and determine a region of interest in the gradient histogram using certain properties of a probability density function. Standard histogram thresholding techniques are then used within the region of interest to get the threshold value. To obtain the edges, this threshold value is then used as the upper threshold of the hysteresis thresholding technique that follows the non-maximum Suppression operation applied on the gradient magnitude image. The proposed methodology of determining a threshold in a gradient histogram is deduced through rigorous analysis and hence it helps in achieving consistently appreciable edge detection performance. Experimental results using different real-life and benchmark images are shown to demonstrate the effectiveness of the proposed technique. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Sen, Debashis; Pal, Sankar K.] Indian Stat Inst, Ctr Soft Comp Res, Kolkata 700108, W Bengal, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Sen, D (corresponding author), Indian Stat Inst, Ctr Soft Comp Res, 203 BT Rd, Kolkata 700108, W Bengal, India.
EM dsen_t@isical.ac.in; sankar@isical.ac.in
RI Pal, Sankar/G-2243-2010; Sen, Debashis/R-3236-2016; cai, bo/G-1491-2010
OI Sen, Debashis/0000-0002-9756-1191; 
FU Government of India
FX D. Sen thanks Mr. Suman Saha for his comments and suggestions. S.K. Pal
   thanks the Government of India for the J.C. Bose National Fellowship.
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Alkaabi S, 2003, ELECTRON LETT, V39, P1174, DOI 10.1049/el:20030777
   [Anonymous], 1983, Finding Edges and Lines in Images
   [Anonymous], 2022, Testing Statistical Hypotheses, DOI DOI 10.1007/978-3-030-70578-7
   [Anonymous], 2001, Probability, Random Variables and Stochastic Processes
   [Anonymous], 2006, Speckle Phenomena in Optics, Theory and Applications
   [Anonymous], 1994, Communication systems
   Basu M, 2002, IEEE T SYST MAN CY C, V32, P252, DOI 10.1109/TSMCC.2002.804448
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHOSH K, 2005, BIOL CYBERN, V93, P1
   Descombes X, 1999, IEEE T IMAGE PROCESS, V8, P490, DOI 10.1109/83.753737
   DESOUZA P, 1983, COMPUT VISION GRAPH, V23, P1, DOI 10.1016/0734-189X(83)90051-8
   Dong Y, 2003, INT J REMOTE SENS, V24, P711, DOI 10.1080/0143116021000013322
   Duda R., 1973, Pattern Classification and Scene Analysis
   Elmabrouk A, 1998, ELECTRON LETT, V34, P1216, DOI 10.1049/el:19980851
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HADDON JF, 1988, PATTERN RECOGN, V21, P195, DOI 10.1016/0031-3203(88)90054-4
   Han JH, 2002, FUZZY SET SYST, V126, P311, DOI 10.1016/S0165-0114(01)00037-9
   Hancock E. R., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P196, DOI 10.1109/CVPR.1991.139687
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heath M, 1996, PROC CVPR IEEE, P143, DOI 10.1109/CVPR.1996.517066
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   Henstock PV, 1996, IEEE T IMAGE PROCESS, V5, P784, DOI 10.1109/83.499917
   JUNG GS, 1988, ELECTRON LETT, V24, P711, DOI 10.1049/el:19880480
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Koschan A, 2005, IEEE SIGNAL PROC MAG, V22, P64, DOI 10.1109/MSP.2005.1407716
   KUNDU MK, 1986, PATTERN RECOGN LETT, V4, P433, DOI 10.1016/0167-8655(86)90041-3
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL SK, 1983, IEEE T PATTERN ANAL, V5, P69, DOI 10.1109/TPAMI.1983.4767347
   PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047
   QIU P, 1996, PATTERN RECOGN, V17, P849
   Rakesh RR, 2004, IEEE T IMAGE PROCESS, V13, P927, DOI 10.1109/TIP.2004.828404
   RICE SO, 1945, AT&T TECH J, V24, P46, DOI 10.1002/j.1538-7305.1945.tb00453.x
   Rosin PL, 2001, PATTERN RECOGN, V34, P2083, DOI 10.1016/S0031-3203(00)00136-9
   ROSIN PL, 1997, MACH VIS APPL, V9
   SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275
   Sen D, 2006, IEE P-VIS IMAGE SIGN, V153, P521, DOI 10.1049/ip-vis:20050289
   Sen D, 2007, FUND INFORM, V75, P483
   SHEN J, 1992, CVGIP-GRAPH MODEL IM, V54, P112, DOI 10.1016/1049-9652(92)90060-B
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Sobel I., 1970, THESIS STANDFORD U
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Zayezdny A., 1989, ENG APPL STOCHASTIC
   ZUNIGA OA, 1988, PATTERN RECOGN, V21, P493, DOI 10.1016/0031-3203(88)90008-8
NR 50
TC 40
Z9 49
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 677
EP 695
DI 10.1016/j.imavis.2009.10.010
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600013
DA 2024-07-18
ER

PT J
AU Hughes, C
   McFeely, R
   Denny, P
   Glavin, M
   Jones, E
AF Hughes, Ciaran
   McFeely, Robert
   Denny, Patrick
   Glavin, Martin
   Jones, Edward
TI Equidistant (<i>f</i>θ) fish-eye perspective with application in
   distortion centre estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fish-eye; Perspective; Equidistant projection; Camera calibration;
   Distortion centre
ID AUTOMATIC CALIBRATION; CAMERA; REMOVAL; SCENES; LINES
AB Radial distortion in an image is a geometric distortion that causes a non-linear variation in resolution across the image, with a higher spatial resolution in the central areas of the image, and lower resolution in the peripheral areas of the image. This is particularly evident in fish-eye cameras, with very wide fields-of-view. Equidistant fish-eye cameras are designed such that the distance between a projected point and the distortion centre of the image is proportional to the incident angle of the projected ray, scaled only by the focal length. The perspective of the projection of a given scene in an equidistant fish-eye camera differs greatly from the projection of the same scene in a rectilinear pin-hole camera. For example, while the field-of-view is significantly larger for a fish-eye camera, the non-linear radial distortion of the scene results in straight lines mapping to curves of a particular shape in the equidistant fish-eye image.
   In this paper, we describe equidistant fish-eye perspective in terms of the projection of sets of parallel lines to the equidistant fish-eye plane, and derive an equation that describes the projection of a straight line. We also demonstrate how the shape of a projected straight line can be accurately described by arcs of circles on the distorted image plane. We also describe an application of the equidistant perspective properties, by showing that the distortion centre of an equidistant fish-eye camera can be estimated by the extraction of the vanishing points. Additionally, we examine the accuracy of this estimation procedure on a large set of synthetically created images and a smaller set of real images from fish-eye cameras. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Hughes, Ciaran; McFeely, Robert; Glavin, Martin; Jones, Edward] Natl Univ Ireland, Dept Elect Engn, Connaught Automot Res Grp, Galway, Ireland.
   [Denny, Patrick] Valeo Vis Syst, Tuam, County Galway, Ireland.
C3 Ollscoil na Gaillimhe-University of Galway; Valeo SA
RP Hughes, C (corresponding author), Natl Univ Ireland, Dept Elect Engn, Connaught Automot Res Grp, Univ Rd, Galway, Ireland.
EM ciaran.hughes@nuigalway.ie
RI Eising, Ciarán/GON-7585-2022; Denny, Patrick/ISU-4497-2023; Glavin,
   Martin/GRX-8748-2022
OI Eising, Ciarán/0000-0001-8383-2635; Denny, Patrick/0000-0001-7494-8513;
   Jones, Edward/0000-0003-1521-4442; Glavin, Martin/0000-0003-1477-4835
FU Enterprise Ireland and Valeo Vision Systems
FX This research is funded by Enterprise Ireland and Valeo Vision Systems
   (formerly Connaught Electronics Ltd.) under the Enterprise Ireland
   Innovation Partnerships Scheme.
CR Ahmed M, 2005, IEEE T IMAGE PROCESS, V14, P1215, DOI 10.1109/TIP.2005.846025
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Avinash N, 2008, J MATH IMAGING VIS, V30, P221, DOI 10.1007/s10851-007-0052-3
   Ballard D.H., 1982, Computer Vision
   Barreto JP, 2006, COMPUT VIS IMAGE UND, V101, P151, DOI 10.1016/j.cviu.2005.07.002
   Barreto JP, 2005, IEEE T PATTERN ANAL, V27, P1327, DOI 10.1109/TPAMI.2005.163
   Barreto JP, 2005, IEEE I CONF COMP VIS, P625
   BARRETO JP, 2002, P EUR C COMP VIS, P237
   BASU A, 1995, PATTERN RECOGN LETT, V16, P433, DOI 10.1016/0167-8655(94)00115-J
   Bräuer-Burchardt C, 2001, IEEE IMAGE PROC, P225, DOI 10.1109/ICIP.2001.958994
   Brauer-Burchardt C., 2000, MUSTERERKENNUNG 2000, P187, DOI DOI 10.1007/978-3-642-59802-9_24
   CIPOLLA R, 1999, P BRIT MACH VIS C, V2, P382
   Clarke TA, 1998, PHOTOGRAMM REC, V16, P293, DOI 10.1111/0031-868X.00127
   Claus D, 2005, PROC CVPR IEEE, P213
   CLAUS D, 2005, P BRIT MACH VIS C
   Daniilidis K, 1996, PATTERN RECOGN LETT, V17, P1179, DOI 10.1016/0167-8655(96)00073-6
   DEVERNAY F, 1995, P SOC PHOTO-OPT INS, V2567, P62, DOI 10.1117/12.218487
   Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269
   Fitzgibbon A. W., 1995, P BRIT MACH VIS C
   Fitzgibbon AW, 2001, PROC CVPR IEEE, P125
   Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241
   Hartley R.I., 1997, PROC DARPA IMAGE UND, P649
   Hartley R, 2007, IEEE T PATTERN ANAL, V29, P1309, DOI 10.1109/TPAMI.2007.1147
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   MIYAMOTO K, 1964, J OPT SOC AM, V54, P1060, DOI 10.1364/JOSA.54.001060
   Pers J., 2002, P COMP VIS WINT WORK, V1, P286, DOI DOI 10.1002/HEP.26980
   RAJAN S, 2006, IEEE CAN C EL COMP E, P1043
   Schaffalitzky F, 2000, IMAGE VISION COMPUT, V18, P647, DOI 10.1016/S0262-8856(99)00069-4
   Slama C.C., 1980, MANUAL PHOTOGRAMMETR, Vfourth
   Strand R., 2005, P BRIT MACH VIS C
   TARDIF JP, 2006, P 9 EUR C COMP VIS, V4, P186
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Wang GH, 2008, PATTERN RECOGN LETT, V29, P977, DOI 10.1016/j.patrec.2008.01.017
   Waynant RW, 2000, ELECTROOPTICS HDB
   Wu YH, 2008, INT J COMPUT VISION, V79, P209, DOI 10.1007/s11263-007-0114-4
   YING X, 2004, P EUR C COMP VIS ECC, V1, P442
   YING X, 2006, P AS C COMP VIS, V2, P61
   ZHENG JY, 2006, P AS C COMP VIS
NR 38
TC 40
Z9 50
U1 1
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 538
EP 551
DI 10.1016/j.imavis.2009.09.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300023
DA 2024-07-18
ER

PT J
AU Li, PH
   Liu, XM
   Xiao, LJ
   Song, Q
AF Li, Peihua
   Liu, Xiaomin
   Xiao, Lijuan
   Song, Qi
TI Robust and accurate iris segmentation in very noisy iris images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris segmentation; Integro-differential operator; K-Means clustering;
   RANSAC algorithm
ID LOCALIZATION; RECOGNITION
AB Iris segmentation plays an important role in an accurate iris recognition system. In less constrained environments where iris images are captured at-a-distance and on-the-move, iris segmentation becomes much more difficult due to the effects of significant variation of eye position and size, eyebrows, eyelashes, glasses and contact lenses, and hair, together with illumination changes and varying focus condition. This paper contributes to robust and accurate iris segmentation in very noisy images. Our main contributions are as follows: (1) we propose a limbic boundary localization algorithm that combines K-Means clustering based on the gray-level co-occurrence histogram and an improved Hough transform, and, in possible failures, a complementary method that uses skin information; the best localization between this and the former is selected. (2) An upper eyelid detection approach is presented, which combines a parabolic integro-differential operator and a RANSAC (RANdom SAmple Consensus)-like technique that utilizes edgels detected by a one-dimensional edge detector. (3) A segmentation approach is presented that exploits various techniques and different image information, following the idea of focus of attention, which progressively detects the eye, localizes the limbic and then pupillary boundaries, locates the eyelids and removes the specular highlight.
   The proposed method was evaluated in the UBIRIS.v2 testing database by the NICE.I organizing committee. We were ranked #4 among all participants according to the evaluation results. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Li, Peihua; Liu, Xiaomin; Xiao, Lijuan; Song, Qi] Heilongjiang Univ, Sch Comp Sci & Technol, Harbin 150080, Hei Long Jiang, Peoples R China.
C3 Heilongjiang University
RP Li, PH (corresponding author), Heilongjiang Univ, Sch Comp Sci & Technol, Xue Fu St 74, Harbin 150080, Hei Long Jiang, Peoples R China.
EM peihualj@hotmail.com
FU National Natural Science Foundation of China [60673110]; Program for New
   Century Excellent Talents of Heilongjiang Province [1153-NCET-002];
   Science and Technology Project of Educational Bureau of Heilongjiang
   Province [1151G033]; Scientific Research Foundation; State Education
   Ministry and Ministry of Personnel; Harbin Science and Technology Bureau
   [2006RFLXG030]
FX This work was supported by the National Natural Science Foundation of
   China (No. 60673110), supported in part by the Program for New Century
   Excellent Talents of Heilongjiang Province (1153-NCET-002), the Science
   and Technology Project of Educational Bureau of Heilongjiang Province
   (1151G033), the Scientific Research Foundation for the Returned Overseas
   Chinese Scholars, State Education Ministry and Ministry of Personnel,
   the Science and Technology Innovation Research Project (2006RFLXG030) of
   Harbin Science and Technology Bureau.
CR Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   He ZF, 2006, INT C PATT RECOG, P366
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jang YK, 2008, PATTERN RECOGN LETT, V29, P1698, DOI 10.1016/j.patrec.2008.05.001
   Liu XM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P118
   Proença H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   PROENCA H, 2007, P IEEE 1 INT C BIOM, P27
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
NR 12
TC 77
Z9 88
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2010
VL 28
IS 2
SI SI
BP 246
EP 253
DI 10.1016/j.imavis.2009.04.010
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 538GR
UT WOS:000273173100006
DA 2024-07-18
ER

PT J
AU Gonzàlez, J
   Rowe, D
   Varona, J
   Roca, FX
AF Gonzalez, Jordi
   Rowe, Daniel
   Varona, Javier
   Xavier Roca, F.
TI Understanding dynamic scenes based on human sequence evaluation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image Sequence Evaluation; High-level processing of monitored scenes;
   Segmentation and tracking in complex scenes; Event recognition in
   dynamic scenes; Human motion understanding; Human behaviour
   interpretation; Natural-language text generation; Realistic
   demonstrators
ID REAL-TIME TRACKING; HUMAN MOVEMENT; RECOGNITION; MODELS
AB In this paper, a Cognitive Vision System (CVS) is presented, which explains the human behaviour of monitored scenes using natural-language texts. This cognitive analysis of human movements recorded in image sequences is here referred to as Human Sequence Evaluation (HSE) which defines a set of transformation modules involved in the automatic generation of semantic descriptions from pixel values. In essence, the trajectories of human agents are obtained to generate textual interpretations of their motion, and also to infer the conceptual relationships of each agent w.r.t. its environment. For this purpose, a human behaviour model based on Situation Graph Trees (SGTs) is considered, which permits both bottom-up (hypothesis generation) and top-down (hypothesis refinement) analysis of dynamic scenes. The resulting system prototype interprets different kinds of behaviour and reports textual descriptions in multiple languages. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Gonzalez, Jordi] CSIC, UPC, Inst Robot & Informat Ind, Barcelona, Catalonia, Spain.
   [Rowe, Daniel; Xavier Roca, F.] UAB, Comp Vision Ctr, Barcelona, Catalonia, Spain.
   [Rowe, Daniel; Xavier Roca, F.] UAB, Dept Comp Sci, Barcelona, Catalonia, Spain.
   [Varona, Javier] UIB, Unitat Graf & Visio Ordinador, Palma de Mallorca, Spain.
C3 Universitat Politecnica de Catalunya; Consejo Superior de
   Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i
   Informatica Industrial (IRII); Centre de Visio per Computador (CVC);
   Autonomous University of Barcelona; Autonomous University of Barcelona;
   Universitat de les Illes Balears
RP Gonzàlez, J (corresponding author), CSIC, UPC, Inst Robot & Informat Ind, Edifici U,Parc Tecnol Barcelona, Barcelona, Catalonia, Spain.
EM poal@cvc.uab.es
RI Gonzàlez, Jordi/I-1812-2015; Roca Marva, F. Xavier/I-2013-2015; Varona,
   Javier/X-5831-2018
OI Gonzàlez, Jordi/0000-0001-8033-0306; Roca Marva, F.
   Xavier/0000-0002-7043-7334; Varona, Javier/0000-0002-0287-0486
FU EC [IST-027110, IST-045547]; Spanish MEC [TIN2006-14606];
   CONSOLIDER-INGENIO 2010 [CSD2007-00018]
FX This work is supported by EC grants IST-027110 for the HERMES project
   and IST-045547 for the VIDI-video project, and by the Spanish MEC under
   projects TIN2006-14606 and CONSOLIDER-INGENIO 2010 (CSD2007-00018).
   Jordi Gonzalez and Javier Varona also acknowledges the support of a Juan
   de la Cierva and a Ramon y Cajal Postdoctoral fellowships from the
   Spanish MEC, respectively.
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], 2007, IBPRIA 07 P 3 IB C P
   Arens M, 2002, FRONT ARTIF INTEL AP, V77, P455
   ARENS M, 2003, SGTEDITOR V1 0 RFERE
   Bar-Shalom Y., 1988, TRACKING DATA ASS
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bullock DJ, 2004, IMAGE VISION COMPUT, V22, P1083, DOI 10.1016/j.imavis.2004.03.024
   Buxton H, 2003, IMAGE VISION COMPUT, V21, P125, DOI 10.1016/S0262-8856(02)00127-0
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   GERBER R, 1998, ECCV, P255
   GONZALEZ J, 2004, THESIS UAB SPAIN
   Haag M, 2000, IMAGE VISION COMPUT, V18, P137, DOI 10.1016/S0262-8856(99)00021-9
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896
   Kamp H., 1993, From Discourse to Logic: Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory
   KANADE T, 1978, 4TH P INT JOINT C PA, P95
   Karaman M, 2005, PROC SPIE, V5960, P2140, DOI 10.1117/12.633437
   Karaulova IA, 2002, IMAGE VISION COMPUT, V20, P691, DOI 10.1016/S0262-8856(02)00059-8
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   Ma MH, 2004, ARTIF INTELL REV, V21, P293, DOI 10.1023/B:AIRE.0000036260.50412.a8
   MATSUYAMA T, 1984, 9 INT JOINT C ART IN, V2, P908
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Morris RJ, 2000, INT J COMPUT VISION, V37, P209, DOI 10.1023/A:1008159822101
   Nagel HH, 2004, AI MAG, V25, P31
   NAGEL HH, 1988, IMAGE VISION COMPUT, V6, P59, DOI 10.1016/0262-8856(88)90001-7
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   PEREZ P, 2002, EUR C COMP VIS, P661
   Porikli F, 2006, J REAL-TIME IMAGE PR, V1, P33, DOI 10.1007/s11554-006-0011-z
   Reiter E., 2000, Building natural language generation systems
   Remagnino P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P857, DOI 10.1109/ICCV.1998.710817
   Remagnino P, 2005, IEEE T SYST MAN CY A, V35, P1, DOI 10.1109/TSMCA.2004.838456
   ROWE D, 2006, 28 DAGM, P505
   ROWE D, 2007, 15 SCIA, P502
   SAGERER G, 1997, SEMANTIC NETWORKS UN
   Schafer K, 1996, J SYMB COMPUT, V22, P725
   Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   THONNAT M, 1999, P 3 INT WORKSH COOP, P51
   Tsotsos JK, 2001, INT J COMPUT VISION, V45, P265, DOI 10.1023/A:1013666302043
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 44
TC 17
Z9 17
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1433
EP 1444
DI 10.1016/j.imavis.2008.02.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800003
OA Green Published
DA 2024-07-18
ER

PT J
AU Mills, A
   Dudek, G
AF Mills, Alec
   Dudek, Gregory
TI Image stitching with dynamic elements
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image stitching; Mosaic; Blending; Computer vision; SIFT; Optimal seam
   selection; Panorama; Parallax
AB This paper presents a new combination of techniques to create pleasing and physically consistent image mosaics despite the presence of moving objects in the scene. The technique uses heuristic seam selection in the intensity and gradient-domains to choose which pixels to use from each image and then blends them smoothly to create the final mosaic.
   We demonstrate illustrative results obtained by comparing and contrasting our output with that obtained from four representative existing image mosaic systems. One of these is documented in the academic research literature and three are commercially available products. The present algorithm gives comparable or superior results in all examples. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Mills, Alec; Dudek, Gregory] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.
C3 McGill University
RP Mills, A (corresponding author), McGill Univ, Ctr Intelligent Machines, 3480 Univ St, Montreal, PQ H3A 2A7, Canada.
EM alec@cim.mcgill.ca
RI Dudek, Gregory L/H-3567-2012; cai, bo/G-1491-2010
CR Afek Y, 1998, PHOTOGRAMM ENG REM S, V64, P115
   AGARWALA A, 2007, INT C COMP GRAPH INT
   Agarwala A., 2004, ITERACTIVE DIGITAL P, P294
   Aguiar PMQ, 2006, IEEE IMAGE PROC, P361
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 1981, P 7 INT JOINT C ART
   BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Davis J, 1998, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.1998.698630
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Irani M, 1996, SIGNAL PROCESS-IMAGE, V8, P327, DOI 10.1016/0923-5965(95)00055-0
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Long Jeremy, 2007, Proceedings Graphics Interface 2007, P257, DOI 10.1145/1268517.1268559
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   MILGRAM DL, 1975, IEEE T COMPUT, V24, P1113, DOI 10.1109/T-C.1975.224142
   PELEG S, 1981, C PATT REC IM PROC D, P426
   Porter T., 1984, Proceedings of the 11th annual conference on Computer graphics and interactive techniques, P253, DOI 10.1145/800031.808606
   Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169
   Soille P, 2006, IEEE T PATTERN ANAL, V28, P673, DOI 10.1109/TPAMI.2006.99
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   UYTTENDAELE M, 2001, P IEEE C COMP VIS PA, V2
   Wood D. N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P243, DOI 10.1145/258734.258859
   Xiong YL, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P69, DOI 10.1109/ACV.1998.732860
NR 28
TC 68
Z9 80
U1 1
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1593
EP 1602
DI 10.1016/j.imavis.2009.03.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800016
DA 2024-07-18
ER

PT J
AU Chen, JC
   Lien, JJJ
AF Chen, Ju-Chin
   Lien, Jenn-Jier James
TI A view-based statistical system for multi-view face detection and pose
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face detection; Pose estimation
ID RECOGNITION; OBJECTS; IMAGES
AB This study develops a novel statistical system for automatic multi-view face detection and pose estimation. The five-module detection system is based on significant local facial features (or subregions) rather than the entire face. The low- and high-frequency feature information of each subregion of the facial image are extracted and projected onto the eigenspace and residual independent basis space in order to create the corresponding PCA (principal component analysis) projection weight vector and ICA (independent component analysis) coefficient vector, respectively. Therefore, the proposed system has an improved tolerance toward different facial expressions, wide viewing angles, partial occlusions and lighting conditions. Furthermore, either projection weight vectors or coefficient vectors in the PCA or ICA space have divergent distributions and are therefore modeled by using the weighted Gaussian mixture model (GMM) rather than a single Gaussian model. The GMM weights and parameters of the GMM are estimated iteratively using the Expectation-Maximization (EM) algorithm. Face detection is then performed by conducting a likelihood evaluation process based on the estimated joint probability of the weight and coefficient vectors and the corresponding geometric positions of the subregions. The use of subregion position information can reduce the risk of false acceptances. Moreover, simple cascaded rejecter module is employed to exclude 85% of the non-face images in order to enhance the overall system performance. The computational overhead is further reduced by eliminating the requirement for a residual image reconstruction process in the ICA process. Finally, the performance of the proposed system is evaluated using challenging databases. The results not only demonstrate the ability of the system to automatically identify facial images with a high degree of accuracy, but also verify its ability to estimate the fine pose angles with 5 degrees precision and an over 90% accuracy rate. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Chen, Ju-Chin; Lien, Jenn-Jier James] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
C3 National Cheng Kung University
RP Chen, JC (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
EM joan@csie.ncku.edu.tw
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   [Anonymous], 2003, TR200396 MITS EL RES
   Bae H, 2005, IMAGE VISION COMPUT, V23, P1181, DOI 10.1016/j.imavis.2005.07.017
   Barlow HB, 1989, NEURAL COMPUT, V1, P295, DOI 10.1162/neco.1989.1.3.295
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FERAUD J, 2000, P IEEE INT C AUT FAC, P77
   Gong SG, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P265, DOI 10.1109/AFGR.1996.557275
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Heisele B, 2001, PROC CVPR IEEE, P657
   Huang C, 2005, IEEE I CONF COMP VIS, P446
   Huang J, 1998, INT C PATT RECOG, P154, DOI 10.1109/ICPR.1998.711102
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Kato T, 2002, IEEE T INTELL TRANSP, V3, P252, DOI 10.1109/TITS.2002.804752
   Kim HC, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P605
   Kim TK, 2004, PATTERN RECOGN, V37, P1873, DOI 10.1016/j.patcog.2004.01.019
   Küblbeck C, 2006, IMAGE VISION COMPUT, V24, P564, DOI 10.1016/j.imavis.2005.08.005
   LEUNG B, 2004, THESIS DEP ELECT ENG
   LEUNG TK, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P637, DOI 10.1109/ICCV.1995.466878
   Levi K, 2004, PROC CVPR IEEE, P53
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Li SZ, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P107, DOI 10.1109/AFGR.2002.1004140
   Li SZ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P674, DOI 10.1109/ICCV.2001.937691
   Li YM, 2004, IMAGE VISION COMPUT, V22, P413, DOI 10.1016/j.imavis.2003.12.005
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   MIKAMI T, 2003, C SOC INSTR CONTR EN
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Ng J., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P14, DOI 10.1109/RATFG.1999.799218
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Phimoltares S, 2007, IMAGE VISION COMPUT, V25, P741, DOI 10.1016/j.imavis.2006.05.017
   RAJAGOPALAN AN, 1999, P 7 IEEE INT C COMP, V2, P1204
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Schneiderman H, 2004, PROC CVPR IEEE, P29
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Srinivasan S, 2002, INT C PATT RECOG, P302, DOI 10.1109/ICPR.2002.1047456
   Sun ZH, 2004, PATTERN RECOGN, V37, P2165, DOI 10.1016/j.patcog.2004.03.013
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   WANG L, 2000, M6001 ISOMPEG
   Waring CA, 2005, IEEE T SYST MAN CY B, V35, P467, DOI 10.1109/TSMCB.2005.846655
   Wei YC, 2002, IEEE IMAGE PROC, P281
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79
   Xiao R, 2004, IEEE T CIRC SYST VID, V14, P31, DOI 10.1109/TCSVT.2003.818351
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
NR 50
TC 9
Z9 13
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1252
EP 1271
DI 10.1016/j.imavis.2008.11.004
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200003
DA 2024-07-18
ER

PT J
AU Dornaika, F
   Sappa, AD
AF Dornaika, Fadi
   Sappa, Angel D.
TI A featureless and stochastic approach to on-board stereo vision system
   pose
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE On-board stereo vision system; Pose estimation; Featureless approach;
   Particle filtering; Image warping
ID PEDESTRIAN DETECTION
AB This paper presents a direct and stochastic technique for real-time estimation of on-board stereo head's position and orientation. Unlike existing works which rely on feature extraction either in the image domain or in 3D space, our proposed approach directly estimates the unknown parameters from the stream of stereo pairs' brightness. The pose parameters are tracked using the particle filtering framework which implicitly enforces the smoothness constraints on the estimated parameters. The proposed technique can be used with a driver assistance applications as well as with augmented reality applications. Extended experiments on urban environments with different road geometries are presented. Comparisons with a 3D data-based approach are presented. Moreover, we provide a performance study aiming at evaluating the accuracy of the proposed approach. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Dornaika, Fadi] Univ Basque Country, San Sebastian 20018, Spain.
   [Sappa, Angel D.] Comp Vis Ctr, Barcelona 08193, Spain.
C3 University of Basque Country; Centre de Visio per Computador (CVC)
RP Dornaika, F (corresponding author), Univ Basque Country, San Sebastian 20018, Spain.
EM dornaika@cvc.uab.es; sappa@cvc.uab.es
RI Sappa, Angel D./A-2072-2009
OI Sappa, Angel/0000-0003-2468-0031
FU Government of Spain [TRA2007-62526/AUT]; Consolider Ingenio 2010: MIPRCV
   [CSD2007-00018]
FX This work was partially supported by the Government of Spain under MEC
   project TRA2007-62526/AUT and research programme Consolider Ingenio
   2010: MIPRCV (CSD2007-00018).
CR AIRES KRT, 2008, ALV VIS C
   Alvarez JM, 2008, IEEE INT VEH SYM, P952
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   Bertozzi M, 2004, IEEE T VEH TECHNOL, V53, P1666, DOI 10.1109/TVT.2004.834878
   Bertozzi M, 2003, 2003 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, VOLS. 1 & 2, P328
   BERTOZZI M, 2005, P COMP VIS PATT REC
   Blake Andrew., 2000, Active Contours
   Boufama BS, 2003, INT J PATTERN RECOGN, V17, P1127, DOI 10.1142/S0218001403002794
   Broggi A, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P410, DOI 10.1109/IVS.2003.1212946
   Broggi A, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P215, DOI 10.1109/IVS.2000.898344
   Collado JM, 2006, LECT NOTES COMPUT SC, V4179, P1151
   Coulombeau P, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P619
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Hautiere N, 2006, IEEE T INTELL TRANSP, V7, P201, DOI 10.1109/TITS.2006.874682
   Hu ZC, 2005, 2005 IEEE Intelligent Vehicles Symposium Proceedings, P48
   Labayrade R, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P646
   Labayrade R, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P31, DOI 10.1109/IVS.2003.1212878
   Labayrade R., 2003, P 1 INT WORKSH IN VE, P13
   Lefée D, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P768
   LERTRUSDACHAKUL T, 2005, INT C ADV PATT REC
   Liang YM, 2003, 2003 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, VOLS. 1 & 2, P90
   Liu X, 2004, IEEE T VEH TECHNOL, V53, P1657, DOI 10.1109/TVT.2004.834876
   Micusík B, 2008, IEEE INT CONF ROBOT, P999, DOI 10.1109/ROBOT.2008.4543335
   Ponsa D, 2005, 2005 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE (ITSC), P1096
   SAPPA A, 2008, IEEE T INTELL TRANSP, V9, P475
   STEIN G, 2000, IEEE INT VEH S
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   SUZUKI T, 1999, IEEE INT VEH S
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   ZHANG T, 1999, IEEE C COMP VIS PATT
NR 34
TC 9
Z9 9
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1382
EP 1393
DI 10.1016/j.imavis.2008.12.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200014
DA 2024-07-18
ER

PT J
AU Di Ruberto, C
   Cinque, L
AF Di Ruberto, Cecilia
   Cinque, Luigi
TI Decomposition of two-dimensional shapes for efficient retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape decomposition; Morphological skeleton; Shape representation; Shape
   retrieval; Shape matching; Object recognition
ID IMAGE RETRIEVAL; PERFORMANCE GRAPHS; SIMILARITY; ALGORITHM
AB This paper presents a novel approach to address the problem of generic 2D shape recognition. We propose a morphological method to decompose a binary shape into entities in correspondence with their protrusions. Each entity is associated with a set of perceptual features that can be used in indexing into image databases. The matching process, based on the softassign algorithm, has produced encouraging results, showing the potential of the developed method in a variety of computer vision and pattern recognition domains. The results demonstrate its robustness in the presence of scale, reflection and rotation transformations and prove the ability to handle noise and articulated structures. In order to increase efficiency, the retrieval process is applied after a coarse scale grouping of objects, without sacrificing effectiveness and allowing indexing into large shape databases. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Di Ruberto, Cecilia] Univ Cagliari, Dept Math & Comp Sci, I-09124 Cagliari, Italy.
   [Cinque, Luigi] Univ Roma La Sapienza, Dept Comp Sci, Rome, Italy.
C3 University of Cagliari; Sapienza University Rome
RP Di Ruberto, C (corresponding author), Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.
EM dirubert@unica.it
RI Di Ruberto, Cecilia/G-6915-2014
OI Di Ruberto, Cecilia/0000-0003-4641-0307
CR [Anonymous], 1987, Visual Reconstruction
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 1997, Image Databases and Multi-Media Search, DOI DOI 10.1142/9789812797988_
   [Anonymous], IMAGE ANAL MATH MORP
   [Anonymous], 1997, MODERN DIFFERENTIAL
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058
   BOAZ JS, 2003, SPIE C INT ROB COMP, V21, P228
   Bridle J., 1989, P 2 INT C NEURAL INF, V2, P211
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   Di Ruberto C, 2002, ELECTRON LETT, V38, P1018, DOI 10.1049/el:20020724
   Di Ruberto C, 2001, ELECTRON LETT, V37, P1325, DOI 10.1049/el:20010925
   Di Ruberto C., 2002, P WORKSH PERC VIS MA
   DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788
   FALOUTSOS C, 1993, 9453 ALM RES CTR IBM
   Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Gold S, 1996, PROC CVPR IEEE, P239, DOI 10.1109/CVPR.1996.517080
   Goldstein Robert D, 1996, William Mary Bill Rights J, V4, P787
   Huijsmans DP, 2005, IEEE T PATTERN ANAL, V27, P245, DOI 10.1109/TPAMI.2005.30
   Huijsmans DP, 2001, PROC CVPR IEEE, P26
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   JANG BK, 1990, IEEE T PATTERN ANAL, V12, P541, DOI 10.1109/34.56190
   JOSHI S, 2004, LECT NOTES COMPUTER
   KIMIA BB, 2004, P WORKSH GEN OBJ REC
   KOSOWSKY JJ, 1994, NEURAL NETWORKS, V7, P477, DOI 10.1016/0893-6080(94)90081-7
   Kreyszig E., 1991, Differential Geometry. Differential Geometry
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Lin Ping, 2004, Proceedings of the CSEE, V24, P118
   Milios E, 2000, IEEE T IMAGE PROCESS, V9, P141, DOI 10.1109/83.817606
   Mjolsness E, 1989, NEURAL COMPUT, V1, P218, DOI 10.1162/neco.1989.1.2.218
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Rangarajan A, 1996, IEEE T NEURAL NETWOR, V7, P1365, DOI 10.1109/72.548165
   Reinhardt JM, 1996, IEEE T IMAGE PROCESS, V5, P89, DOI 10.1109/83.481673
   Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602
   Serratosa F, 2000, INT C PATT RECOG, P867, DOI 10.1109/ICPR.2000.906212
   SHOJI K, 1992, SPIE P IM ALG MORP 3, V1769, P404
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591
   Super BJ, 2004, PATTERN RECOGN LETT, V25, P217, DOI 10.1016/j.patrec.2003.10.003
   Super BJ, 2002, COMPUT VIS IMAGE UND, V85, P1, DOI 10.1006/cviu.2002.0959
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vitulano S, 1998, INT J PATTERN RECOGN, V12, P677, DOI 10.1142/S0218001498000397
   1967, MODELS PERCEPTION SP
   [No title captured]
NR 47
TC 12
Z9 12
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1097
EP 1107
DI 10.1016/j.imavis.2008.10.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000011
DA 2024-07-18
ER

PT J
AU Kim, S
   Kweon, IS
AF Kim, Sungho
   Kweon, In So
TI Simultaneous place and object recognition using collaborative context
   information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Place recognition; Object recognition; Bidirectional context;
   Disambiguation
ID CLASSIFICATION
AB In this paper, we present a practical place and object recognition method for guiding visitors in building environments. Due to motion blur or camera noise, places or objects can be ambiguous. The first key contribution of this work is the modeling of bidirectional interaction between places and objects for simultaneous reinforcement. The second key contribution is the unification of visual context, including scene context, object context, and temporal context. The last key contribution is a practical demonstration of the proposed system for visitors in a large scale building environment. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Kim, Sungho; Kweon, In So] Korea Adv Inst Sci & Technol, Dept EECS, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Kim, S (corresponding author), Korea Adv Inst Sci & Technol, Dept EECS, 373-1 Guseong Dong, Taejon 305701, South Korea.
EM shkim@rcv.kaist.ac.kr; iskweon@kaist.ac.kr
RI Kweon, In So/C-2023-2011
FU Korean Ministry of Science and Technology for National Research
   Laboratory Program [M1-0302-00-0064]
FX This research has been supported by the Korean Ministry of Science and
   Technology for National Research Laboratory Program (Grant No.
   M1-0302-00-0064).
CR Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476
   CSURKA JG, 2004, WORKSH STAT LEARN CO
   Jordan Michael Irwin, 1999, LEARNING GRAPHICAL M
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   KIM S, 2006, IEEE CVPR WORKSH PER
   Kim S, 2008, PATTERN RECOGN, V41, P754, DOI 10.1016/j.patcog.2007.03.018
   Kim S, 2006, INT C PATT RECOG, P650
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Murphy K., 2004, NIPS
   MURPHYCHUTORIAN E, 2005, SHARED FEATURES SCAL, P16
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Ristic N.G.B., 2004, KALMAN FILTER PARTIC
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Yedidia J.S., 2003, EXPLORING ARTIFICIAL, P239, DOI DOI 10.5555/779343.779352
NR 18
TC 3
Z9 3
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 824
EP 833
DI 10.1016/j.imavis.2008.07.010
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000021
DA 2024-07-18
ER

PT J
AU Larlus, D
   Jurie, F
AF Larlus, Diane
   Jurie, Frederic
TI Latent mixture vocabularies for object categorization and segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 17th Annual British Machine Vision Conference
CY SEP, 2006
CL British Machine Vis Assoc, Edinburgh, SCOTLAND
HO British Machine Vis Assoc
DE Object categorization; Object segmentation; Visual vocabulary creation
ID IMAGE
AB The visual vocabulary is an intermediate level representation which has been proved to be very powerful for addressing object categorization problems. It is generally built by vector quantizing a set of local image descriptors, independently of the object model used for categorizing images. We propose here to embed the visual vocabulary creation within the object model construction, allowing to make it more suited for object class discrimination and therefore for object categorization. We also show that the model can be adapted to perform object level segmentation task, without needing any shape model, making the approach very adapted to high intra-class varying objects. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Larlus, Diane; Jurie, Frederic] INRIA Rhone Alpes, F-38334 Montbonnot St Martin, St Ismier, France.
RP Larlus, D (corresponding author), INRIA Rhone Alpes, 655 Ave Europe, F-38334 Montbonnot St Martin, St Ismier, France.
EM diane.larlus@inrialpes.fr; frederic.jurie@inrialpes.fr
CR [Anonymous], BMVC
   [Anonymous], ICCV
   [Anonymous], 2005, ICCV
   [Anonymous], 2005, MLCW 2005, DOI DOI 10.1007/11736790_8
   [Anonymous], ICCV
   [Anonymous], 2005, CVPR
   [Anonymous], ECCV
   [Anonymous], 2006, COMPUTER VISION PATT
   [Anonymous], 2004, Advances in Neural Information Processing Systems (NIPS)
   [Anonymous], 2005, ICCV
   Blei D.M., 2002, NIPS
   Blei D.M., 2003, SIGIR
   BORENSTEIN E, 2004, P CVPR WORKSH
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   FERGUS R, 2005, ICCV, V101, P5228
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Fritz M., 2005, ICCV
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Kumar M.P., 2005, CVPR
   Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9
   Leibe B., 2003, BMVC
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Quelhas P., 2005, ICCV
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   SUDDERTH E, 2006, NIPS
NR 27
TC 23
Z9 25
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 2
PY 2009
VL 27
IS 5
SI SI
BP 523
EP 534
DI 10.1016/j.imavis.2008.04.022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 437WD
UT WOS:000265516700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Saúde, AV
   Couprie, M
   Lotufo, RA
AF Saude, Andre V.
   Couprie, Michel
   Lotufo, Roberto A.
TI Discrete 2D and 3D euclidean medial axis in higher resolution
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Medial axis; Skeleton; Euclidean distance
ID DISTANCE TRANSFORMATION; ALGORITHMS; SKELETON
AB The notion of skeleton plays a major role in shape analysis. Some usually desirable characteristics of a skeleton are: centered, thin, homotopic, and sufficient for the reconstruction of the original object. The Euclidean medial axis presents all these characteristics in a continuous framework. In the discrete case, the exact Euclidean medial axis (MA) is also sufficient for reconstruction and centered. It no longer preserves homotopy but it can be combined with a homotopic thinning to generate homotopic skeletons. The thinness of the MA, however, may be discussed. In this paper, we present the definition of the exact Euclidean medial axis in higher resolution, which has the same properties as the MA but with a better thinness characteristic, against the price of rising resolution. We provide and prove an efficient algorithm to compute it. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Saude, Andre V.] Univ Fed Lavras, Dept Comp Sci, DCC UFLA, BR-37200000 Lavras, MG, Brazil.
   [Couprie, Michel] Univ Paris Est, IGM, ESIEE, Dept Informat, F-93162 Noisy Le Grand, France.
   [Lotufo, Roberto A.] Univ Estadual Campinas, Sch Elect & Comp Engn, DCA, FEEC,UNICAMP, BR-13081970 Campinas, SP, Brazil.
C3 Universidade Federal de Lavras; Universite Gustave-Eiffel; ESIEE Paris;
   Universidade Estadual de Campinas
RP Saúde, AV (corresponding author), Univ Fed Lavras, Dept Comp Sci, DCC UFLA, Caixa Postal 3037, BR-37200000 Lavras, MG, Brazil.
EM saude@dcc.ufla.br; coupriem@esiee.fr; lotufo@unicamp.br
RI Lotufo, Roberto/C-1496-2009; Saúde, André V/D-7219-2017
OI Lotufo, Roberto/0000-0002-5652-0852; Saúde, André V/0000-0001-5233-1379
FU FAPESP; CAPES, Brazil; CNRS, France
FX This work has been partially supported by FAPESP and CAPES, Brazil, and
   by CNRS, France.
CR Bertrand G, 1999, LECT NOTES COMPUT SC, V1568, P218
   Bertrand G., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P326
   BERTRAND G, 2006, LNCS
   Blum H., 1962, BIOL PROTOTYPES SYNT, P244
   Borgefors G., 1991, P 7 SCAND C IM AN, V2, P974
   Coeurjolly D, 2003, LECT NOTES COMPUT SC, V2886, P327
   Coeurjolly D, 2007, IEEE T PATTERN ANAL, V29, P437, DOI 10.1109/TPAMI.2007.54
   Couprie M, 2006, SIBGRAPI, P307
   Couprie M, 2007, IMAGE VISION COMPUT, V25, P1543, DOI 10.1016/j.imavis.2006.06.020
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   DAVIES ER, 1981, PATTERN RECOGN, V14, P53, DOI 10.1016/0031-3203(81)90045-5
   HARDY GH, 1978, INTRO THEORY NUMBERS
   Hirata T, 1996, INFORM PROCESS LETT, V58, P129, DOI 10.1016/0020-0190(96)00049-X
   KHALIMSKY E, 1990, TOPOL APPL, V36, P1, DOI 10.1016/0166-8641(90)90031-V
   KONG TY, 1991, AM MATH MON, V98, P901, DOI 10.2307/2324147
   KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5
   Meijster A, 2000, COMP IMAG VIS, V18, P331
   MEYER F, 1979, THESIS ECOLE NATL MI
   PFALTZ JL, 1967, COMMUN ACM, V10, P119, DOI 10.1145/363067.363120
   Remy E, 2005, IMAGE VISION COMPUT, V23, P167, DOI 10.1016/j.imavis.2004.06.007
   Remy E, 2003, LECT NOTES COMPUT SC, V2886, P224
   SAITO T, 1994, PATTERN RECOGN, V27, P1551, DOI 10.1016/0031-3203(94)90133-3
   Saúde AV, 2006, LECT NOTES COMPUT SC, V4245, P605
   TALBOT H, 1992, VISUAL COMMUNICATION, V1818, P862
NR 24
TC 8
Z9 8
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 354
EP 363
DI 10.1016/j.imavis.2008.05.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600005
DA 2024-07-18
ER

PT J
AU Zuliani, M
   Bertelli, L
   Kenney, CS
   Chandrasekaran, S
   Manjunath, BS
AF Zuliani, M.
   Bertelli, L.
   Kenney, C. S.
   Chandrasekaran, S.
   Manjunath, B. S.
TI Drums, curve descriptors and affine invariant region matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE curve descriptors; curve matching; Helmoholtz equation; affine
   invariance
ID SHAPE; RECOGNITION; HEAR
AB In this paper we present a new physically motivated curve/region descriptor based on the solution of Helmholtz's equation. The descriptor we propose satisfies the six principles set by MPEG-7: it has a good retrieval accuracy, it is compact, it can be applied in general contests, it has a reasonable computational complexity, it is rotation and scale invariant and provides an hierarchical representation of the curve from coarse to fine. In addition to these properties, the descriptor can be generalized in order to take into account also the intensity content of the image region defined by the curve. The construction of the descriptor can be coupled with a preprocessing step that enables us to describe a curve in an affine invariant fashion. The performance of our approach has been tested in the contest of affine invariant curve and region matching, both within a controlled experimental setup and also using real images. The experiments show that the proposed approach compares favorably to the state of the art curve/region descriptors. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Zuliani, M.; Bertelli, L.; Kenney, C. S.; Chandrasekaran, S.; Manjunath, B. S.] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
C3 University of California System; University of California Santa Barbara
RP Zuliani, M (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM zuliani@ece.ucsb.edu; lbertelli@ece.ucs-b.edu; kenney@ece.ucsb.edu;
   shiv@ece.ucsb.edu; manj@ece.ucsb.edu
RI Manjunath, B S/AAM-8190-2020
OI Manjunath, B S/0000-0003-2804-3611
CR [Anonymous], 1999, MATRIX ANAL
   ASTROM K, THESIS LUND U SWEDEN
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Buser P, 1994, Int. Math. Res. Not., P391
   CARRIER GF, 1988, PARTIAL DIFFERTIAL E
   Driscoll TA, 1997, SIAM REV, V39, P1, DOI 10.1137/S0036144595285069
   Eidenberger H, 2004, MULTIMEDIA SYST, V10, P84, DOI 10.1007/s00530-004-0141-8
   EVANS LC, 1998, GRADUATE STUDIES MAT, V91
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Fox L., 1967, SIAM J. Numer. Anal., V4, P89
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   GORDON C, 1992, B AM MATH SOC, V27, P134, DOI 10.1090/S0273-0979-1992-00289-6
   Gorelick L, 2004, PROC CVPR IEEE, P61
   GUIDOTTI P, 2005, UNPUB EIGENVALUE CHA
   Höllig K, 2005, ADV COMPUT MATH, V23, P215, DOI 10.1007/s10444-004-1811-y
   KAC M, 1966, AM MATH MON, V73, P1, DOI 10.2307/2313748
   Kato T., 1976, Grundlehren der Mathematischen Wissenschaften
   Lisani JL, 2003, MULTISCALE MODEL SIM, V1, P1, DOI 10.1137/S1540345902410846
   Meyer C. D, 2001, SIAM
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   MORSE BS, 1994, THESIS U N CAROLINA
   Ngo K. V., 2005, Applied Numerical Analysis and Computational Mathematics, V2, P108, DOI 10.1002/anac.200410028
   NOLL A, 1999, JOURNEES EQUATION DE, P1
   SAITO N, 2005, P IEEE STAT SIGN PRO
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   SINCLAIR D, 1994, IEEE T PATTERN ANAL, V16, P769, DOI 10.1109/34.308471
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   WEINBERGER HF, 1965, FIRTS COURSE PARTIAL
   Yang C., 1997, ARPACK Users' Guide: Solution of Large Scale Eigenvalue Problems by Implicitly Restarted Arnoldi Methods
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
   Zhang DS, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P425, DOI 10.1109/ICME.2002.1035809
   Zhang SG, 2001, NETWORKS, V37, P102, DOI 10.1002/1097-0037(200103)37:2<102::AID-NET5>3.0.CO;2-S
   ZULIANI M, 2004, BRIT MACH VIS C SEPT
   ZULIANI M, 2004, IEEE INT C IM PROC O
NR 35
TC 8
Z9 16
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 347
EP 360
DI 10.1016/j.imavis.2006.12.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500004
DA 2024-07-18
ER

PT J
AU Schmitt, O
   Bethke, S
   Sobe, P
   Prehn, S
   Maehle, E
AF Schmitt, Oliver
   Bethke, Sven
   Sobe, Peter
   Prehn, Steffen
   Maehle, Erik
TI Parallelized segmentation of a serially sectioned whole human brain
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE segmentation; adaptive fuzzy c-means; human brain; paraffin sections;
   histologic sections; block-face; episcopic images
ID ADAPTIVE FUZZY SEGMENTATION; RANDOM-FIELD MODEL; IMAGE SEGMENTATION;
   ALGORITHM; MRI
AB Building a digital three dimensional representation of a human brain is a challenging task. Such a model provides insights into the microstructure of cortical layering and columns. The presented work is based on a complete dissected and preserved human brain that has been serially sectioned at a coronal resolution that is suitable for single cell detection. More than 6000 sections have been generated and exist as digital images. To obtain a valuable three dimensional representation, morphology preserving affine linear and nonlinear registration schemes are necessary steps. To rebuild a serially sectioned brain, reference images derived from a non deformed object, e.g., MRI or block face images, are necessary for a faithful affine linear and nonlinear registration. In the case of block face images the brain regions must be separated from highly variable background regions to obtain a suitable stack of segmentation images. Among the image segmentation algorithms we found fuzzy c-means techniques as a promising starting point for a sophisticated segmentation framework of either gray level or color images within 2- and 3-dimensions.
   With respect to algorithmic complexity and computation cost, two fuzzy c-means algorithms were implemented. A proper image preprocessing strategy turned out to be necessary for accurate and robust segmentation results. Primarily, the algorithms work in a parametric resp. supervised mode. Additionally, an automatic mode helps to explore the parameter space within a reasonable range and to compare the segmentation result with an optimal one, provided by an expert. By minimizing the differences we can set up parameters that are used for series of adjacent images. So, it is possible to obtain optimal segmentations independent of illumination disturbances, artifacts and defocusing.
   We present a complete high resolution and accurate segmentation of the first complete human brain that was sectioned, photographed and digitized at histologic resolution. Based on these images, a succeeding 3D representation is presented. Finally, a segmented and spatially correct straightened data set is available now for coregistration tasks together with the high resolution histologic data set. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Schmitt, Oliver] Inst Anat, D-18055 Rostock, Germany.
   [Bethke, Sven; Sobe, Peter; Prehn, Steffen; Maehle, Erik] Inst Comp Engn, D-23538 Lubeck, Germany.
RP Schmitt, O (corresponding author), Inst Anat, Gertrudenstr 9, D-18055 Rostock, Germany.
EM schmitt@med.uni-rostock.de; syb28975@gsk.com; sobe@iti.uni-luebeck.de;
   prehn@iti.uni-luebeck.de; maehle@iti.uni-luebeck.de
CR Alirezaie J, 1997, IEEE T NUCL SCI, V44, P194, DOI 10.1109/23.568805
   Amato U, 2003, J NEUROSCI METH, V131, P65, DOI 10.1016/S0165-0270(03)00237-1
   Atkins MS, 1998, IEEE T MED IMAGING, V17, P98, DOI 10.1109/42.668699
   Barash D, 2004, IMAGE VISION COMPUT, V22, P73, DOI 10.1016/j.imavis.2003.08.005
   Bardinet É, 2002, LECT NOTES COMPUT SC, V2488, P548
   Barker SA, 1997, LECT NOTES COMPUT SC, V1223, P165
   BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000
   BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964
   BOCK S, 2002, SEGMENTIERUNG DEAGGL
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   COLCHESTER A, 2001, LNCS, V2208, P957
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Fan Y, 2002, IEEE T MED IMAGING, V21, P904, DOI 10.1109/TMI.2002.803126
   Forbes F, 2003, IEEE T PATTERN ANAL, V25, P1089, DOI 10.1109/TPAMI.2003.1227985
   GLASBEY CA, 1993, CVGIP-GRAPH MODEL IM, V55, P532, DOI 10.1006/cgip.1993.1040
   Gonzales R.C., 1993, Digital Image Processing
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   Hochbaum DS, 2001, J ACM, V48, P686, DOI 10.1145/502090.502093
   Kapur T., 1996, Med Image Anal, V1, P109127
   Lindeberg T, 1999, HUM BRAIN MAPP, V7, P166, DOI 10.1002/(SICI)1097-0193(1999)7:3<166::AID-HBM3>3.0.CO;2-I
   MacKenzie-Graham A, 2004, J ANAT, V204, P93, DOI 10.1111/j.1469-7580.2004.00264.x
   Matsui K., 1999, Systems and Computers in Japan, V30, P69, DOI 10.1002/(SICI)1520-684X(19990630)30:7<69::AID-SCJ8>3.0.CO;2-U
   Modersitzki J., 2004, NUMER MATH SCI COMP
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ourselin S, 2001, IMAGE VISION COMPUT, V19, P25, DOI 10.1016/S0262-8856(00)00052-4
   OURSELIN S, 2001, LNCS, V2208, P743
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pham DL, 1999, PATTERN RECOGN LETT, V20, P57, DOI 10.1016/S0167-8655(98)00121-4
   Pham DL, 2001, COMP MED SY, P127, DOI 10.1109/CBMS.2001.941709
   Pham DL, 1999, LECT NOTES COMPUT SC, V1613, P140
   Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752
   Pitiot A, 2002, IEEE T MED IMAGING, V21, P910, DOI 10.1109/TMI.2002.803124
   Polzehl J, 2000, J R STAT SOC B, V62, P335, DOI 10.1111/1467-9868.00235
   PREWITT JMS, 1966, ANN NY ACAD SCI, V128, P1035
   RANADE S, 1980, ICPR, P561
   ROSENFELD A, 1982, KAKDIGITAL PICTURE P, V2
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   SANGWINE S, 1998, HORNETHE COLOUR IMAG
   SCHMITT O, 2001, MULTIMODALE ARCHITEK, V1
   SIERACKI ME, 1989, APPL ENVIRON MICROB, V55, P2762, DOI 10.1128/AEM.55.11.2762-2772.1989
   SOMBOONKAEW A, 1999, P 20 AS C REM SENS A, P20
   STAUDACHER J, 2002, THESIS TU MUNCHEN
   SZEGIN M, 2004, J ELECTRON IMAGING, V13, P146
   Szirányi T, 2000, REAL-TIME IMAGING, V6, P195, DOI 10.1006/rtim.1998.0159
   TOGA AW, 1994, J NEUROSCI METH, V54, P239, DOI 10.1016/0165-0270(94)90196-1
   VANDENBOOMGAARD R, 2002, P INT S MATH MORPH, V6, P283
   Veenman CJ, 2003, IEEE T IMAGE PROCESS, V12, P304, DOI 10.1109/TIP.2002.806256
   Wang Y, 1998, IEEE T IMAGE PROCESS, V7, P1165, DOI 10.1109/83.704309
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8
   Wilson R, 2003, IEEE T PATTERN ANAL, V25, P42, DOI 10.1109/TPAMI.2003.1159945
   Zhang YJ, 1997, PATTERN RECOGN LETT, V18, P963, DOI 10.1016/S0167-8655(97)00083-4
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
NR 53
TC 3
Z9 4
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 289
EP 301
DI 10.1016/j.imavis.2007.06.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500012
DA 2024-07-18
ER

PT J
AU Zhang, J
   Ge, Y
   Ong, SH
   Chui, CK
   Teoh, SH
   Yan, CH
AF Zhang, J.
   Ge, Y.
   Ong, S. H.
   Chui, C. K.
   Teoh, S. H.
   Yan, C. H.
TI Rapid surface registration of 3D volumes using a neural network approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE surface registration; neural network; surface modelling; medical images
ID IMAGE REGISTRATION; 3-DIMENSIONAL REGISTRATION; 2-D-3-D REGISTRATION;
   CT; ALGORITHM; BRAIN; PET
AB An automatic surface-based rigid registration system using a neural network representation is proposed. The system has been applied to register human bone structures for image-guided surgery. A multilayer perceptron neural network is used to construct a patient-specific surface model from pre-operative images. A surface representation function derived from the resultant neural network model is then employed for intra-operative registration. The optimal transformation parameters are obtained via an optimization process. This segmentation/registration system achieves sub-voxel accuracy comparable to that of conventional techniques, and is significantly faster. These advantages are demonstrated using image datasets of the calcaneus and vertebrae. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Zhang, J.; Ge, Y.; Ong, S. H.; Yan, C. H.] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
   [Zhang, J.; Chui, C. K.; Teoh, S. H.] Natl Univ Singapore, Dept Mech Engn, Singapore 117576, Singapore.
   [Ong, S. H.] Natl Univ Singapore, Div Bioengn, Singapore 117576, Singapore.
C3 National University of Singapore; National University of Singapore;
   National University of Singapore
RP Ong, SH (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Block E4-05-48,4 Engn Dr 3, Singapore 117576, Singapore.
EM eleongsh@nus.edu.sg
RI Ong, Sim-Heng/R-9244-2019
OI Ong, Sim-Heng/0000-0003-2766-8150
CR ALPERT NM, 1990, J NUCL MED, V31, P1717
   Barrow H. G., 1977, P IMAGE UNDERSTANDIN, P659
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Chen HM, 2003, IEEE T MED IMAGING, V22, P1111, DOI 10.1109/TMI.2003.816949
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023
   Ghafoor A, 2003, 4 EURASIP C FOC VID, P155
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Hellier P, 2003, IEEE T MED IMAGING, V22, P217, DOI 10.1109/TMI.2002.808365
   Hezel S, 2002, ANN IEEE SYM FIELD P, P89, DOI 10.1109/FPGA.2002.1106664
   Hipwell JH, 2003, IEEE T MED IMAGING, V22, P1417, DOI 10.1109/TMI.2003.819283
   Jan ML, 2005, IEEE T MED IMAGING, V24, P886, DOI 10.1109/TMI.2005.848617
   Liu YH, 2004, PATTERN RECOGN, V37, P211, DOI 10.1016/S0031-3203(03)00239-5
   McLaughlin RA, 2005, IEEE T MED IMAGING, V24, P1058, DOI 10.1109/TMI.2005.852067
   OURSELIN S, 2002, ROBUST REGISTRATION
   PELIZZARI CA, 1989, J COMPUT ASSIST TOMO, V13, P20, DOI 10.1097/00004728-198901000-00004
   Quek FKH, 2003, IEEE T SYST MAN CY B, V33, P758, DOI 10.1109/TSMCB.2003.816919
   Ryan N, 2004, IMAGE VISION COMPUT, V22, P883, DOI 10.1016/j.imavis.2004.04.004
   Shang LF, 2006, NEUROCOMPUTING, V69, P1717, DOI 10.1016/j.neucom.2006.01.007
   SONTAG ED, 1992, IEEE T NEURAL NETWOR, V3, P981, DOI 10.1109/72.165599
   Srikanchana R, 2004, J VLSI SIG PROC SYST, V37, P237, DOI 10.1023/B:VLSI.0000027488.23703.ba
   Yan CH, 1998, MED PHYS, V25, P121, DOI 10.1118/1.598166
   YAN CH, 2004, IEEE INT WORKSH BIOM
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 24
TC 25
Z9 28
U1 2
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 201
EP 210
DI 10.1016/j.imavis.2007.04.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500005
DA 2024-07-18
ER

PT J
AU Brimkov, VE
   Dantchev, S
AF Brimkov, Valentin E.
   Dantchev, Stefan
TI Digital hyperplane recognition in arbitrary fixed dimension within an
   algebraic computation model
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE digital hyperplane; digital plane recognition; integer programming;
   Euclidean algorithm
ID PLANES; COMPLEXITY; ALGORITHMS; NAIVE; TIME
AB In this paper we present an algorithm for the integer linear programming (ILP) problem within an algebraic model of computation 1 2 and use it to solve the following digital plane segment recognition problem: Given a set of points M = {p(1),p(2), . . . , p(m)} subset of R-n, decide whether M is a portion of a digital hyperplane and, if so, determine its analytical representation. In our setting p(1), P-2,...,p(m) may be arbitrary points (possibly, with rational and/or irrational coefficients) and the dimension n may be any arbitrary fixed integer. We reduce this last problem to an ILP to which our general integer programming algorithm applies. It performs 0(m log D) arithmetic operations, where D is a bound on the norm of the domain elements. For the special case of problem dimension two, we propose an elementary algorithm that takes advantage of the specific geometry of the problem and appears to be optimal. It implies an efficient algorithm for digital line segment recognition. (c) 2006 Elsevier B.V. All rights reserved.
C1 SUNY Coll Buffalo, Dept Math, Buffalo, NY 14222 USA.
   Univ Durham, Sci Labs, Dept Comp Sci, Durham DH1 3LE, England.
C3 State University of New York (SUNY) System; Buffalo State College;
   Durham University
RP Brimkov, VE (corresponding author), SUNY Coll Buffalo, Dept Math, 1300 Elmwood Ave, Buffalo, NY 14222 USA.
EM brimkove@buffalostate.edu; s.s.dantchev@durham.ac.uk
CR Andres E, 1997, GRAPH MODEL IM PROC, V59, P302, DOI 10.1006/gmip.1997.0427
   ANDRES E, 2001, THESIS U POITIERS PO
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   BLUM L, 1989, B AM MATH SOC, V21, P1, DOI 10.1090/S0273-0979-1989-15750-9
   BLUM L, 1995, COMPLEXITY REAL COMP
   Brimkov V, 2007, DISCRETE APPL MATH, V155, P468, DOI 10.1016/j.dam.2006.08.004
   Brimkov VE, 1999, CALCOLO, V36, P123, DOI 10.1007/s100920050026
   Brimkov VE, 1997, J COMPLEXITY, V13, P279, DOI 10.1006/jcom.1997.0446
   Brimkov VE, 2005, LECT NOTES COMPUT SC, V3429, P287
   Brimkov VE, 2002, PATTERN RECOGN LETT, V23, P623, DOI 10.1016/S0167-8655(01)00139-8
   BRIMKOV VE, 2000, EL C COMP COMPL
   BRIMKOV VE, 2000, LNCS, V1872, P286
   Buzer L, 2003, GRAPH MODELS, V65, P61, DOI 10.1016/S1524-0703(03)00008-0
   Buzer L., 2002, Discrete Geometry for Computer Imagery. 10th International Conference, DGCI 2002. Proceedings (Lecture Notes in Computer Science Vol.2301), P372
   Cary M., 2002, LATTICE BASIS REDUCT
   Case J, 2001, J ACM, V48, P110, DOI 10.1145/363647.363688
   Coeurjolly D, 2006, LECT NOTES COMPUT SC, V4040, P291
   Coppersmith D, 1996, LECT NOTES COMPUT SC, V1070, P178
   COPPERSMITH D, 1997, LECT NOTES COMPUTER, V1233, P52
   DEBLEDRENNESSON I, 1994, SPIE, V2356, P12
   FEIT SD, 1984, J ACM, V31, P99, DOI 10.1145/2422.322417
   FRANKEL E, 1976, SOC STUD SCI, V6, P141, DOI 10.1177/030631277600600201
   Frankovich J, 2001, BIOL BLOOD MARROW TR, V7, P49, DOI 10.1053/bbmt.2001.v7.pm11215699
   Garey M.R., 1979, COMPUTERS INTRACTABI
   HASTAD J, 1989, SIAM J COMPUT, V18, P859, DOI 10.1137/0218059
   Herman GT, 2003, P IEEE, V91, P1612, DOI 10.1109/JPROC.2003.817871
   KALAI G, 1992, 24 ANN ACM S THEOR C, P472
   KANNAN R, 1979, SIAM J COMPUT, V8, P499, DOI 10.1137/0208040
   KIM CE, 1991, PATTERN RECOGN LETT, V12, P665, DOI 10.1016/0167-8655(91)90003-5
   KIM CE, 1984, IEEE T PATTERN ANAL, V6, P639, DOI 10.1109/TPAMI.1984.4767578
   Klette R., 2001, Visual Form 2001. 4th International Workshop on Visual Form IWVF4. Proceedings (Lecture Notes in Computer Science Vol.2059), P356
   Klette R, 1996, GRAPH MODEL IM PROC, V58, P295, DOI 10.1006/gmip.1996.0024
   LENSTRA AK, 1982, MATH ANN, V261, P515, DOI 10.1007/BF01457454
   LENSTRA HW, 1983, MATH OPER RES, V8, P538, DOI 10.1287/moor.8.4.538
   MEGIDDO N, 1984, J ACM, V31, P114, DOI 10.1145/2422.322418
   Niederreiter H., 1973, Diophantine Approximation and Its Applications, P129
   NOVAK E, 1995, J COMPLEXITY, V11, P57, DOI 10.1006/jcom.1995.1002
   OSGOOD CF, 1973, DIOPHANTINE APPROXIM
   REVEILLES JP, 1991, GEOMETRIE DISCRETE C
   REVEILLES JP, 1995, SPIE, V2573, P2334
   ROSENFELD A, 2001, ELECT NOTES THEORETI, P46
   Schrijver A., 1998, THEORY LINEAR INTEGE
   Stojmenovic I., 1991, CONTEMPORANE MATH, V119, P197
   Strassen V., 1990, Handbook of theoretical computer science, VA, P633
   VEELAERT P, 1994, IEEE T PATTERN ANAL, V16, P647, DOI 10.1109/34.295909
   Vittone J, 2000, LECT NOTES COMPUT SC, V1953, P296
   1998, INT WORKSH GRAND CHA
NR 47
TC 3
Z9 3
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1631
EP 1643
DI 10.1016/j.imavis.2006.06.013
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200011
DA 2024-07-18
ER

PT J
AU Dana, KJ
   Cula, OG
   Wang, J
AF Dana, Kristin J.
   Cula, Oana G.
   Wang, Jing
TI Surface detail in computer models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE surface models; texture; reflectance; illumination; BRDF; BTF;
   image-based models; appearance-based models
ID BIDIRECTIONAL TEXTURE FUNCTIONS; REFLECTANCE
AB Quantitative characterization of surface appearance is an important but difficult task. Surfaces of real world objects are detailed landscapes, with complex geometry and local optical properties. Surface appearance is strongly affected by the direction from which it is viewed and illuminated. Computational modeling of surface texture has potential uses in many applications including realistic rendering for computer graphics and robust recognition for computer vision. For recognition, the overall structure of the object is important, but fine-scale details can assist the recognition problem greatly. We develop models of surface texture and demonstrate their use in recognition tasks. We also describe a texture camera for capturing fine-scale surface details. Specifically, the texture camera measures reflectance and surface height variation using curved mirrors. We discuss why measurements and models of fine scale detail are important in modem industrial applications. (C) 2006 Elsevier B.V. All rights reserved.
C1 Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
   Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
C3 Rutgers University System; Rutgers University New Brunswick; Rutgers
   University System; Rutgers University New Brunswick
RP Dana, KJ (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, 94 Brett Rd, Piscataway, NJ 08854 USA.
EM kdana@ece.rutgers.edu
CR CARTER RR, 1999, Patent No. 5912741
   Cula OG, 2005, INT J COMPUT VISION, V62, P97, DOI 10.1007/s11263-005-4637-2
   Cula OG, 2004, INT J COMPUT VISION, V59, P33, DOI 10.1023/B:VISI.0000020670.05764.55
   Cula OG, 2001, PROC CVPR IEEE, P1041
   Cula OG, 2001, PROC SPIE, V4299, P209, DOI 10.1117/12.429492
   Cula OG, 2002, P TEXT 2002 2 INT WO, P35
   Dana K. J., 1999, IEEE Workshop on the Integration of Appearance and Geometric Methods in Object Recognition, P46
   Dana KJ, 1998, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.1998.698669
   Dana KJ, 1997, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.1997.609313
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Dana KJ, 2004, J OPT SOC AM A, V21, P1, DOI 10.1364/JOSAA.21.000001
   Davis K.J., 1997, United States Patent, Patent No. 5637873
   Han JY, 2003, ACM T GRAPHIC, V22, P741, DOI 10.1145/882262.882341
   Koenderink JJ, 1999, INT J COMPUT VISION, V31, P129, DOI 10.1023/A:1008061730969
   Koudelka ML, 2003, 3 INT WORKSHOP TEXTU, P59
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   LEUNG T, 1999, INT C COMP VIS, V2, P1010
   Liu XG, 2001, COMP GRAPH, P97
   MATTISON PR, 1998, P SPIE INT SOC OPT E, P240
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   NENE SA, 1994, P ARPA IM UND WORKSH
   PENIRSCHKE A, 2002, P TEXT 2002 2 INT WO, P103
   Suen PH, 1998, PROC CVPR IEEE, P753, DOI 10.1109/CVPR.1998.698688
   Suykens F, 2003, COMPUT GRAPH FORUM, V22, P463, DOI 10.1111/1467-8659.00694
   Tong X, 2002, ACM T GRAPHIC, V21, P665, DOI 10.1145/566570.566634
   van Ginneken B, 1998, APPL OPTICS, V37, P130, DOI 10.1364/AO.37.000130
   Varma M, 2004, PROC CVPR IEEE, P179
   Varma M, 2003, PROC CVPR IEEE, P691
   VASILESCU MAO, 2003, ACM SIGGRAPH
   WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078
   YIZHOU Y, 2002, P EUR C COMP VIS MAY, P31
NR 31
TC 5
Z9 12
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1037
EP 1049
DI 10.1016/j.imavis.2006.04.022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300002
DA 2024-07-18
ER

PT J
AU Burgeth, B
   Bruhn, A
   Didas, S
   Weickert, J
   Welk, M
AF Burgeth, Bernhard
   Bruhn, Andres
   Didas, Stephan
   Weickert, Joachim
   Welk, Martin
TI Morphology for matrix data: Ordering versus PDE-based approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE mathematical morphology; dilation; erosion; matrix-valued images;
   diffusion tensor MRI; Loewner ordering; nonlinear partial differential
   equation
ID TENSOR; TEXTURE; COLOR
AB Matrix fields are becoming increasingly important in digital imaging. In order to perform shape analysis, enhancement or segmentation of such matrix fields, appropriate image processing tools must be developed. This paper extends fundamental morphological operations to the setting of matrices, in the literature sometimes referred to as tensors despite the fact that matrices are only rank two tensors. The goal of this paper is to introduce and explore two approaches to mathematical morphology for matrix-valued data: one is based on a partial ordering, the other utilises nonlinear partial differential equations (PDEs). We start by presenting definitions for the maximum and minimum of a set of symmetric matrices since these notions are the cornerstones of the morphological operations. Our first approach is based on the Loewner ordering for symmetric matrices, and is in contrast to the unsatisfactory component-wise techniques. The notions of maximum and minimum deduced from the Loewner ordering satisfy desirable properties such as rotation invariance, preservation of positive semidefiniteness, and continuous dependence on the input data. These properties are also shared by the dilation and erosion processes governed by a novel nonlinear system of PDEs we are proposing for our second approach to morphology on matrix data. These PDEs are a suitable counterpart of the nonlinear equations known from scalar continuous-scale morphology. Both approaches incorporate information simultaneously from all matrix channels rather than treating them independently. In experiments on artificial and real medical positive semidefinite matrix-valued images we contrast the resulting notions of erosion, dilation, opening, closing, top hats, morphological derivatives, and shock filters stemming from these two alternatives. Using a ball shaped structuring element we illustrate the properties and performance of our orderingor PDE-driven morphological operators for matrix-valued data. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Saarland, Math Image Anal Grp, Fac Math & Comp Sci, D-66041 Saarbrucken, Germany.
C3 Saarland University
RP Burgeth, B (corresponding author), Univ Saarland, Math Image Anal Grp, Fac Math & Comp Sci, Bldg 27, D-66041 Saarbrucken, Germany.
EM burgeth@mia.uni-saarland.de; bruhn@mia.uni-saarland.de;
   didas@mia.uni-saarland.de; weickert@mia.uni-saarland.de;
   welk@mia.uni-saarland.de
OI Welk, Martin/0000-0002-6268-7050
CR Alexander DC, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P83, DOI 10.1007/3-540-31272-2_5
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   [Anonymous], 1994, Morphological Image Operators
   [Anonymous], VISUALIZATION PROCES
   Barvinok A.I., 2002, A course in convexity, Graduate Studies in Mathematics, V54
   BASSER PJ, 1994, BIOPHYS J, V66, P259, DOI 10.1016/S0006-3495(94)80775-1
   Basser PJ, 1995, NMR BIOMED, V8, P333, DOI 10.1002/nbm.1940080707
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Brox T, 2003, LECT NOTES COMPUT SC, V2756, P353
   BROX T, 2002, LECT NOTES COMPUTER, V2449, P446
   Burgeth B, 2005, COMPUT IMAGING VIS, V30, P407
   Burgeth B, 2004, LECT NOTES COMPUT SC, V2034, P155
   COULON O, 2001, LECT NOTES COMPUTER, V2082, P92
   FEDDERN C, 2004, 104 SAARL U DEP MATH
   GOUTSIAS J, 1995, COMPUT VIS IMAGE UND, V62, P326, DOI 10.1006/cviu.1995.1058
   Goutsias J., 2000, MATH MORPHOLOGY ITS
   GRANDLUND GH, 1995, SIGNAL PROCESSING CO
   HAHN K, 2001, LECT NOTES COMPUTER, V2208, P195
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Heijmans H. J., 1998, MATH MORPHOLOGY ITS, V12
   Hiriart-Urruty J.-B., 2001, FUNDAMENTALS CONVEX
   Horn Roger A, 1990, Matrix Analysis
   KRAMER HP, 1975, PATTERN RECOGN, V7, P53, DOI 10.1016/0031-3203(75)90013-8
   Louverdis G, 2002, PATTERN RECOGN, V35, P1733, DOI 10.1016/S0031-3203(01)00166-2
   Matheron G., 1975, Random sets and integral geometry
   MATHERON G, 1967, ELEMENTS 1 THEORIE M
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Parker GJM, 2000, J MAGN RESON IMAGING, V11, P702, DOI 10.1002/1522-2586(200006)11:6<702::AID-JMRI18>3.0.CO;2-A
   Pierpaoli C, 1996, RADIOLOGY, V201, P637, DOI 10.1148/radiology.201.3.8939209
   RAO AR, 1991, CVGIP-GRAPH MODEL IM, V53, P157, DOI 10.1016/1049-9652(91)90059-S
   Rousson M, 2003, PROC CVPR IEEE, P699
   SAPIRO G, 1993, PATTERN RECOGN, V26, P1363, DOI 10.1016/0031-3203(93)90142-J
   Sapiro G., 2001, Geometric Partial Differential Equations and Image Analysis
   SERRA J, 1967, THESIS U NANCY FRANC
   TALBOT H, 2002, P 6 INT S MATH MORPH
   Tschumperlé D, 2001, PROC CVPR IEEE, P948
   VANVLIET LJ, 1989, COMPUT VISION GRAPH, V45, P167, DOI 10.1016/0734-189X(89)90131-X
   Weickert J., 2002, CONT MATH, P251
   Welk M, 2003, LECT NOTES COMPUT SC, V2781, P17
   Westin CF, 1999, LECT NOTES COMPUT SC, V1679, P441
   1988, J SERRAIMAGE ANAL MA, V2
   1982, J SERRAIMAGE ANAL MA, V1
NR 43
TC 24
Z9 27
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 496
EP 511
DI 10.1016/j.imavis.2006.06.002
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jung, CR
AF Jung, Claudio Rosito
TI Combining wavelets and watersheds for robust multiscale image
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE segmentation; watersheds; wavelets; multiresolution; denoising; region
   merging
ID MATHEMATICAL MORPHOLOGY; ALGORITHM; SCALE
AB This paper proposes a new segmentation technique that combines multiresolution wavelet decompositions with the watershed transform. The wavelet transform is applied to the intensity image, producing detail and approximation coefficients. Gradient magnitudes of the approximation image at the coarsest resolution are computed, and an adaptive threshold is used to remove small gradient magnitudes. The watershed transform is then applied, and the segmented image is projected up to higher resolutions using inverse wavelet transforms. Typically, if a low resolution is chosen for the initial segmentation, large relevant objects will be captured; on the other hand, a higher initial resolution will lead to smaller (and more detailed) segmented objects. The low-pass filtering involved in the wavelet decomposition provides robust segmentation results for noisy images, even when the amount of noise is very large. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Vale Rio dos Sinos, PIPCA, Grad Sch Appl Comp, BR-93022000 Sao Leopoldo, RS, Brazil.
C3 Universidade do Vale do Rio dos Sinos (Unisinos)
RP Jung, CR (corresponding author), Univ Vale Rio dos Sinos, PIPCA, Grad Sch Appl Comp, Av UNISINOS 950, BR-93022000 Sao Leopoldo, RS, Brazil.
EM crjung@unisinos.br
RI Jung, Claudio R/G-2439-2012
CR Bieniek A, 2000, PATTERN RECOGN, V33, P907, DOI 10.1016/S0031-3203(99)00154-5
   Bleau A, 2000, COMPUT VIS IMAGE UND, V77, P317, DOI 10.1006/cviu.2000.0822
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   DONOHO DL, PROGR WAVELET ANAL A
   Gauch JM, 1999, IEEE T IMAGE PROCESS, V8, P69, DOI 10.1109/83.736688
   Gies V, 2004, IEEE IMAGE PROC, P1863
   HANSEN MW, 1994, IEEE IMAGE PROC, P460, DOI 10.1109/ICIP.1994.413764
   Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380
   Henstock PV, 1996, IEEE T IMAGE PROCESS, V5, P784, DOI 10.1109/83.499917
   JACKWAY P, 1995, 9 SCAND C IM AN
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jung CR, 2005, IMAGE VISION COMPUT, V23, P661, DOI 10.1016/j.imavis.2005.03.001
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim JB, 2003, PATTERN RECOGN LETT, V24, P473, DOI 10.1016/S0167-8655(02)00270-2
   Kim JB, 2002, INT C PATT RECOG, P505, DOI 10.1109/ICPR.2002.1047987
   Larson H.J., 1979, Probabilistic Models in Engineering Sciences, V1
   LIFSHITZ LM, 1987, THESIS U N CAROLINA
   Lindeberg T., 1991, Discrete Scale-Space Theory and the Scale-Space Primal Sketch
   Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433
   MA WY, 1997, IEEE C COMP VIS PATT, P744
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Meyer F, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P28, DOI 10.1109/SIBGRA.1998.722729
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Mukhopadhyay S, 2003, IEEE T IMAGE PROCESS, V12, P533, DOI 10.1109/TIP.2003.810757
   Nguyen HT, 2003, IEEE T PATTERN ANAL, V25, P330, DOI 10.1109/TPAMI.2003.1182096
   Ogor B, 1995, P SOC PHOTO-OPT INS, V2579, P375, DOI 10.1117/12.226855
   Patino L, 2005, PATTERN RECOGN LETT, V26, P819, DOI 10.1016/j.patrec.2004.09.036
   PETERS RA, 1995, IEEE T IMAGE PROCESS, V4, P554, DOI 10.1109/83.382491
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Scharcanski J, 2002, IEEE T IMAGE PROCESS, V11, P1092, DOI 10.1109/TIP.2002.802528
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Simoncelli E.P., 1996, P IEEE INT C IMAGE P, V1, P279
   Strang G., 1996, Wavelets and Filter Banks
   Vanhamel I, 2003, IEEE T IMAGE PROCESS, V12, P617, DOI 10.1109/TIP.2003.811490
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Weickert J, 2001, PATTERN RECOGN, V34, P1813, DOI 10.1016/S0031-3203(00)00109-6
   Wu HH, 2000, IEEE T IMAGE PROCESS, V9, P1983, DOI 10.1109/83.877221
NR 38
TC 28
Z9 41
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 24
EP 33
DI 10.1016/j.imavis.2006.01.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600004
DA 2024-07-18
ER

PT J
AU Shen, L
   Makedon, F
AF Shen, Li
   Makedon, Fillia
TI Spherical mapping for processing of 3D closed surfaces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE spherical parameterization; shape analysis; surface modeling
ID MEDICAL IMAGES; MEDIAL MODELS; SHAPE; PARAMETERIZATION; PARAMETRIZATION;
   SEGMENTATION; REGISTRATION
AB The spherical harmonic (SPHARM) description is a powerful surface modeling technique used by many applications in biomedical imaging, However, earlier SPHARM studies employ a spherical parameterization procedure that can be applied only to voxel surfaces. This paper presents CALD, a new spherical parameterization algorithm that makes the SPHARM model applicable to general triangle meshes. The CALD algorithm starts from an initial mapping and performs novel local and global smoothing methods alternately until a solution is approached. This new algorithm can also be used for processing of 3D closed surfaces in many different areas, including medical image analysis, computer vision, and computer graphics. (c) 2006 Elsevier B.V. All rights reserved.
C1 SE Massachusetts Univ, N Dartmouth, MA 02747 USA.
   Dartmouth Coll, Dartmouth Expt Visualizat Lab, Sudikoff Lab 6211, Hanover, NH 03062 USA.
C3 Dartmouth College
RP Shen, L (corresponding author), SE Massachusetts Univ, 285 Old Westport Rd, N Dartmouth, MA 02747 USA.
EM lshen@umassd.edu; makedon@cs.dartmouth.edu
RI Shen, Li/AAB-6870-2021
OI Shen, Li/0000-0002-5443-0503
CR Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575
   Anderson E., 1999, LAPACK USERSGUIDE, Vthird
   ANKERST M, 1999, ADV SPATIAL DATABASE, V18, P700
   Ballard D.H., 1982, Computer Vision
   Bookstein FL, 1997, COMPUT VIS IMAGE UND, V66, P97, DOI 10.1006/cviu.1997.0607
   BRECHBUHLER C, 1995, COMPUT VIS IMAGE UND, V61, P154, DOI 10.1006/cviu.1995.1013
   Brown L.G., 1992, ACM COMPUT SURV, V24, P325, DOI DOI 10.1145/146370.146374
   CANNAN S, 1998, P 7 INT MESH ROUNDT, P497
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Csernansky JG, 1998, P NATL ACAD SCI USA, V95, P11406, DOI 10.1073/pnas.95.19.11406
   Floater M.S., 2004, Multiresolution in Geometric Modelling
   FREITAG L, 1997, ASME, V220, P37
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gerig G, 2001, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P171, DOI 10.1109/MMBIA.2001.991731
   Gerig G., 2001, Lecture Notes in Computer Science, V2208, P24
   GU X, 2001, P 29 ANN C COMP GRAP, P355
   Gu X., 2002, Commun. Inf. Syst., V2, P121, DOI DOI 10.4310/CIS.2002.V2.N2.A2
   Haker S, 2000, IEEE T VIS COMPUT GR, V6, P181, DOI 10.1109/2945.856998
   Huang H, 2005, LECT NOTES COMPUT SC, V3749, P67
   Joshi SC, 1997, INT J PATTERN RECOGN, V11, P1317, DOI 10.1142/S0218001497000615
   Kazhdan M, 2004, ALGORITHMICA, V38, P201, DOI 10.1007/s00453-003-1050-5
   KAZHDAN M, 2003, THESIS PRINCETON U N
   KAZHDAN M, 2004, THESIS PRINCETON U N
   Kelemen A, 1999, IEEE T MED IMAGING, V18, P828, DOI 10.1109/42.811260
   LORENSEN WE, 1987, P 14 ANN C COMP GRAP, P163, DOI DOI 10.1145/3740137422
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   MEYERS D, 1992, ACM T GRAPHIC, V11, P228, DOI 10.1145/130881.131213
   ONeill B., 1966, Elementary Differential Geometry
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Periaswamy S, 2003, IEEE T MED IMAGING, V22, P865, DOI 10.1109/TMI.2003.815069
   Pizer SM, 1999, IEEE T MED IMAGING, V18, P851, DOI 10.1109/42.811263
   Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274
   QUICKEN M, 2000, IEEE COMP SOC C COMP, V1, P354
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   Schruder P., 1995, Proc. 22nd Ann. Conf. Comput. Graphics Interactive Techniques (SIGGRAPH'95), P161
   Sheffer A, 2004, COMPUTING, V72, P185, DOI 10.1007/s00607-004-0056-9
   Shen L, 2003, LECT NOTES COMPUT SC, V2879, P513
   SHEN L, 2005, CVPRIP 2005 6 INT C, P699
   Shen L, 2004, INTELL DATA ANAL, V8, P519, DOI DOI 10.3233/IDA-2004-8602
   Staib LH, 1996, IEEE T MED IMAGING, V15, P720, DOI 10.1109/42.538949
   Styner M, 2003, MED IMAGE ANAL, V7, P207, DOI 10.1016/S1361-8415(02)00110-X
   Styner M, 2003, INT J COMPUT VISION, V55, P107, DOI 10.1023/A:1026378916288
   VRANIC D, 2001, P DAGM, P392
   Weisstein E.W., Spherical Harmonic. MathWorld: A Wolfram Web Resource
   WEISSTEIN EW, BARYCENTRIC COORINAT
   WEISSTEIN EW, TRIANGLE AREA MATHWO
   WEISSTEIN EW, GENUS MATHWORLD A WO
NR 47
TC 108
Z9 129
U1 3
U2 25
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 743
EP 761
DI 10.1016/j.imavis.2006.01.011
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400009
DA 2024-07-18
ER

PT J
AU Pinho, AJ
   Neves, AJR
AF Pinho, Armando J.
   Neves, Antonio J. R.
TI On the relation between Memon's and the modified Zeng's palette
   reordering methods
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE color-indexed images; palette recording; lossless image compression;
   JPEG-LS; JPEG2000
ID COMPRESSION
AB Palette reordering has been shown to be a very effective approach for improving the compression of color-indexed images by general purpose continuous-tone image coding techniques. In this paper, we provide a comparison, both theoretical and experimental, of two of these methods: the pairwise merging heuristic proposed by Memon et al. and the recently proposed modification of Zeng's method. This analysis shows how several parts of the algorithms relate and how their performance is affected by some modifications. Moreover, we show that Memon's method can be viewed as an extension of the modified version of Zeng's technique and, therefore, that the modified Zeng's method can be obtained through some simplifications of Menton's method. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Aveiro, Signal Proc Lab, DET IEETA, P-3810193 Aveiro, Portugal.
C3 Universidade de Aveiro
RP Pinho, AJ (corresponding author), Univ Aveiro, Signal Proc Lab, DET IEETA, Campus Univ Santiago, P-3810193 Aveiro, Portugal.
EM ap@det.ua.pt; an@ieeta.pt
RI Pinho, Armando J/A-2309-2012; Neves, Antonio J. R./AAF-9857-2019
OI Neves, Antonio J. R./0000-0001-5433-6667; Pinho,
   Armando/0000-0002-9164-0016
CR Ausbeck PJ, 2000, P IEEE, V88, P1779, DOI 10.1109/5.892713
   Chen X, 2002, IEEE T CIRC SYST VID, V12, P904, DOI 10.1109/TCSVT.2002.804896
   Memon ND, 1996, IEEE T IMAGE PROCESS, V5, P1522, DOI 10.1109/83.541422
   Pinho AJ, 2004, IEEE T IMAGE PROCESS, V13, P1411, DOI 10.1109/TIP.2004.836168
   Pinho AJ, 2004, IEEE SIGNAL PROC LET, V11, P232, DOI 10.1109/LSP.2003.821758
   RATNAKAR V, 1998, P 32 AS C SIGN SYST, V2, P1251
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Taubman D.S., 2002, JPEG 2000: Image Compression Fundamentals, Standards and Practice, DOI 10.1007/978-1-4615-0799-4
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   YOO Y, 1999, P 6 IEEE INT C IM PR, V1, P477
   Zeng WJ, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P476, DOI 10.1109/ICIP.2000.899448
NR 11
TC 7
Z9 7
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 534
EP 540
DI 10.1016/j.imavis.2006.02.005
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600012
DA 2024-07-18
ER

PT J
AU Yu, WW
   Teng, XL
   Liu, CQ
AF Yu, WW
   Teng, XL
   Liu, CQ
TI Face recognition using discriminant locality preserving projections
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; difference model; locality preserving projections;
   discriminant locality preserving projections
ID REPRESENTATION
AB Locality Preserving Projections (LPP) is a linear projective rnap that arises by solving a variational problem that optimally preserves the neighborhood structure of the data set. Though LPP has been applied in many domains, it has limits to solve recognition problem. Thus, Discriminant Locality Preserving Projections (DLPP) is presented in this paper. The improvement of DLPP algorithm over LPP method benefits mostly from two aspects: One aspect is that DLPP tries to find the subspace that best discriminates different face classes by maximizing the between-class distance, while minimizing the within-class distanced The other aspect is that DLPP reduces the energy of noise and transformation difference as much as possible without sacrificing much of intrinsic difference. In the experiments. DLPP achieves better face recognition performance than LPP. (c) 2005 Elsevier B.V. All rights reserved.
C1 Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University
RP Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Room 502,Bldg 45,2438 Jinshajiang Rd, Shanghai 200030, Peoples R China.
EM yww@sjtu.edu.cn
CR [Anonymous], 2003, NIPS
   [Anonymous], P 3 WORKSH EMP EV ME
   [Anonymous], 2001, MULTIDIMENSIONAL SCA
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M., 2001, P C ADV NEUR INF PRO, V15
   Benavente R, 1998, 24 COMP VIS CTR
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Koren Y, 2004, IEEE T VIS COMPUT GR, V10, P459, DOI 10.1109/TVCG.2004.17
   LIU Q, 2002, P 5 INT C AUT FAC GE
   Martinez A.M., 1998, AR FACE DATABASE
   Roweis S., 2000, SCIENCE, P290
   Roweis SamT., 2003, J MACHINE LEARNING R, V4, P119
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Turk M, 2001, IEICE T INF SYST, VE84D, P1586
   Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   YANG MH, 2002, P 5 INT C AUT FAC GE
   Yuen PC, 2002, PATTERN RECOGN, V35, P1247, DOI 10.1016/S0031-3203(01)00101-7
   ZHAO WY, 2000, CARTR948 U MAR COLL
NR 21
TC 230
Z9 284
U1 2
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2006
VL 24
IS 3
BP 239
EP 248
DI 10.1016/j.imavis.2005.11.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 031PI
UT WOS:000236716100003
DA 2024-07-18
ER

PT J
AU Brox, T
   Weickert, J
   Burgeth, B
   Mrázek, P
AF Brox, T
   Weickert, J
   Burgeth, B
   Mrázek, P
TI Nonlinear structure tensors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE structure tensor; PDEs; diffusion; orientation estimation; optic flow;
   corner detection
ID TOTAL VARIATION FLOW; DIFFUSION; EDGE; TEXTURE; REGULARIZATION;
   FRAMEWORK; PDES
AB In this article, we introduce nonlinear versions of the popular structure tensor, also known as second moment matrix. These nonlinear structure tensors replace the Gaussian smoothing of the classical structure tensor by discontinuity-preserving nonlinear diffusions. While nonlinear diffusion is a well-established tool for scalar and vector-valued data, it has not often been used for tensor images so far. Two types of nonlinear diffusion processes for tensor data are studied: an isotropic one with a scalar-valued diffusivity, and its anisotropic counterpart with a diffusion tensor. We prove that these schemes preserve the positive semidefiniteness of a matrix field and are, therefore, appropriate for smoothing structure tensor fields. The use of diffusivity functions of total variation (TV) type allows us to construct nonlinear structure tensors without specifying additional parameters compared to the conventional structure tensor. The performance of nonlinear structure tensors is demonstrated in three fields where the classic structure tensor is frequently used: orientation estimation, optic flow computation, and corner detection. In all these cases, the nonlinear structure tensors demonstrate their superiority over the classical linear one. Our experiments also show that for corner detection based on nonlinear structure tensors, anisotropic nonlinear tensors give the most precise localisation. (C) 2005 Elsevier B.V. All rights reserved.
C1 Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, D-66041 Saarbrucken, Germany.
   UPEK Prague R&D Ctr, Prague 13000 3, Czech Republic.
C3 Saarland University
RP Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, Bldg 27, D-66041 Saarbrucken, Germany.
EM brox@mia.uni-saarland.de; weickert@mia.uni-saarland.de;
   burgeth@mia.uni-saarland.de; mrazek@mia.uni-saarland.de
CR ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   Andreu F, 2002, J FUNCT ANAL, V188, P516, DOI 10.1006/jfan.2001.3829
   Andreu F., 2001, DIFFERENTIAL INTEGRA, V14, P321
   [Anonymous], LECT NOT COMPUT SCI
   [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], 1962, Bulletin of the Electrotechnical Laboratory
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bellettini G, 2002, J DIFFER EQUATIONS, V184, P475, DOI 10.1006/jdeq.2001.4150
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433
   Brox T, 2003, LECT NOTES COMPUT SC, V2756, P353
   Brox T, 2003, LECT NOTES COMPUT SC, V2695, P86
   BROX T, 2002, LECT NOTES COMPUTER, V2449, P446
   BROX T, IN PRESS VISUALIZATI
   ChefD'Hotel C, 2004, J MATH IMAGING VIS, V20, P147, DOI 10.1023/B:JMIV.0000011324.14508.fb
   DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733
   Dibos F, 2000, SIAM J NUMER ANAL, V37, P646, DOI 10.1137/S0036142998334838
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Feng XB, 2003, ESAIM-MATH MODEL NUM, V37, P533, DOI 10.1051/m2an:2003041
   Forstner W., 1986, International Archives of the Photogrammetry, V26, P150
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jahne B, 1993, LECT NOTES COMPUTER, V751
   Keeling SL, 2002, INVERSE PROBL, V18, P175, DOI 10.1088/0266-5611/18/1/312
   Köthe U, 2003, LECT NOTES COMPUT SC, V2781, P25
   Lindeberg T., 1994, SCALE SPACE THEORY C
   LU T, 1991, APPL MATH LETT, V4, P25, DOI 10.1016/0893-9659(91)90161-N
   Lucas B. D., 1981, P IJCAI, P674
   Middendorf M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P178, DOI 10.1109/ICCV.2001.937515
   MIDDENDORF M, 2002, LECT NOTES COMPUTER, V2449, P66
   MRAZEK P, 2004, SERIES SPP U BREMEN
   OTTE M, 1995, ARTIF INTELL, V78, P5, DOI 10.1016/0004-3702(95)00033-X
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RAO AR, 1991, CVGIP-GRAPH MODEL IM, V53, P157, DOI 10.1016/1049-9652(91)90059-S
   Rohr K., 1994, Journal of Mathematical Imaging and Vision, V4, P139, DOI 10.1007/BF01249893
   ROHR K, 1992, IMAGE VISION COMPUT, V10, P66, DOI 10.1016/0262-8856(92)90001-J
   Rousson M, 2003, PROC CVPR IEEE, P699
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Sporring J., 1997, Computational Imaging and Vision, V8
   THOMAS I, 1999, F11 U HAMB I APPL MA
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Tschumperlé D, 2002, INT J COMPUT VISION, V50, P237, DOI 10.1023/A:1020870207168
   Tsurkov VI, 2000, J COMPUT SYS SC INT+, V39, P437
   VANDENBOOMGAARD R, 2002, P 2 INT WORKSH TEXT
   Wang ZZ, 2004, IEEE T MED IMAGING, V23, P930, DOI 10.1109/TMI.2004.831218
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973
   Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131
   WEICKERT J., 1999, HDB COMPUTER VISION, P423
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Weickert J., 2002, CONT MATH, P251
NR 54
TC 170
Z9 208
U1 2
U2 45
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 41
EP 55
DI 10.1016/j.imavis.2005.09.010
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Saykol, E
   Güdükbay, U
   Ulusoy, Ö
AF Saykol, E
   Güdükbay, U
   Ulusoy, Ö
TI A histogram-based approach for object-based query-by-shape-and-color in
   image and video databases
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE histogram-based approach; object-based querying; query-by-shape;
   query-by-color; distance histogram; angle histogram; distance-weighted;
   color histogram
ID RETRIEVAL; BILVIDEO
AB Considering the fact that querying by low-level object features is essential in image and video data, an efficient approach for querying and retrieval by shape and color is proposed. The approach employs three specialized histograms, (i.e. distance, angle, and color histograms) to store feature-based information that is extracted from objects. The objects can be extracted from images or video frames. The proposed histogram-based approach is used as a component in the query-by-feature subsystem of a video database management system. The color and shape information is handled together to enrich the querying capabilities for content-based retrieval. The evaluation of the retrieval effectiveness and the robustness of the proposed approach is presented via performance experiments. (C) 2005 Elsevier Ltd All rights reserved.
C1 Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM ediz@cs.bilkent.edu.tr
RI Gudukbay, Ugur/F-1012-2011; Saykol, Ediz/AAF-6251-2020; Ulusoy,
   Ozgur/KVY-4530-2024; Rohlf, F J/A-8710-2008
OI Gudukbay, Ugur/0000-0003-2462-6959; Saykol, Ediz/0000-0002-8950-5114;
   Ulusoy, Ozgur/0000-0002-6887-3778; 
CR ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509
   Boujemaa N., 2001, P INT C IM SIGN PROC, P404
   Buser P., 1992, Vision
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carson C., 1999, LECT NOTES COMPUTER, V1614, P509, DOI DOI 10.1007/3-540-48762-X_63
   Catarci T, 2003, IEEE MULTIMEDIA, V10, P66, DOI 10.1109/MMUL.2003.1167924
   Chang SF, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P313, DOI 10.1145/266180.266382
   Dönderler ME, 2005, MULTIMED TOOLS APPL, V27, P79, DOI 10.1007/s11042-005-2715-7
   Dönderler ME, 2002, INFORM SCIENCES, V143, P13, DOI 10.1016/S0020-0255(02)00172-X
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   Gunsel B, 1998, PATTERN RECOGN, V31, P931, DOI 10.1016/S0031-3203(97)00076-9
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   JONES KS, 1981, INFORMATION RETRIEVA
   Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7
   Lu GJ, 1999, MULTIMEDIA SYST, V7, P165, DOI 10.1007/s005300050119
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Safar M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P141, DOI 10.1109/ICME.2000.869564
   Saykol E, 2004, IEEE T IMAGE PROCESS, V13, P314, DOI 10.1109/TIP.2003.821114
   Saykol E, 2002, LECT NOTES COMPUT SC, V2457, P186
   SAYKOL E, 2001, P 7 WORKSH MULT INF, P11
   SCASSELLATI B, 1994, P SOC PHOTO-OPT INS, V2185, P2, DOI 10.1117/12.171777
   Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   SMITH JR, 1996, IS T SPIE P, V2670, P426
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Taubin G., 1992, OBJECT RECOGNITION B, P375
   *U CAL IM LIB, COR
   VELTKAMP RC, 2001, UUCS200103
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhang DS, 2002, INT CONF ACOUST SPEE, P3668
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
   ZLOOF M, IBM SYSTEM J, V16
NR 35
TC 55
Z9 62
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1170
EP 1180
DI 10.1016/j.imavis.2005.07.015
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500006
DA 2024-07-18
ER

PT J
AU Wang, YJ
   Chua, CS
AF Wang, YJ
   Chua, CS
TI Face recognition from 2D and 3D images using 3D Gabor filters
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D Gabor filter; 3D spherical gabor filter; rotation-invariant; Least
   Trimmed Square Hausdorff Distance
ID MODEL
AB To recognize faces with different facial expressions or varying views from only one stored prototype per person is challenging. This paper presents such a system based on both 3D range data as well as the corresponding 2D gray-level facial images. The traditional 3D Gabor filter (3D TGF) is explored in the face recognition domain to extract expression-invariant features. To extract view-invariant features, a rotation-invariant 3D spherical Gabor filter (3D SGF) is proposed. Furthermore, a two-dimensional (2D) Gabor histogram is employed to represent the Gabor responses of the 3D SGF for solving the missing-point problem caused by self-occlusions under large rotation angles. The choice of 3D Gabor filter parameters for face recognition is examined as well. To match a given test face with each model face, the Least Trimmed Square Hausdorff Distance (LTS-HD) is employed to tackle the possible partial-matching problem. Experimental results based on our face database involving 80 persons have demonstrated that our approach outperforms the standard Eigenface approach and the approach using the 2D Gabor-wavelets representation. (c) 2005 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Elect & Elect Engn, Nanyang Ave, Singapore 639798, Singapore.
EM ecschua@ntu.edu.sg
CR [Anonymous], 2001, Medical image registration
   Ayinde O, 2002, PATTERN RECOGN, V35, P1275, DOI 10.1016/S0031-3203(01)00120-0
   BEYMER D, 1993, AIM1461 MIT ART INT
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Feng GC, 2000, IEEE T SYST MAN CY A, V30, P871, DOI 10.1109/3468.895926
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gao Y, 2001, IEE P-VIS IMAGE SIGN, V148, P248, DOI 10.1049/ip-vis:20010377
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   MAURER T, 1995, P INT WORKSH AUT FAC, P248
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   REED TR, 1996, P 30 ANN AS C SIGN S, P506
   Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3
   Sim DG, 1999, IEEE T IMAGE PROCESS, V8, P425, DOI 10.1109/83.748897
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   WANG YJ, 2002, P 2 IASTED INT C VIS, V447
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
NR 20
TC 58
Z9 62
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2005
VL 23
IS 11
BP 1018
EP 1028
DI 10.1016/j.imavis.2005.07.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 973KF
UT WOS:000232520600008
DA 2024-07-18
ER

PT J
AU Gan, XC
   Liew, AWC
   Yan, H
AF Gan, XC
   Liew, AWC
   Yan, H
TI A smoothness constraint set based on local statistics of BDCT
   coefficients for image postprocessing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE projection onto convex sets; postprocessing methods; BDCT
ID BLOCKING ARTIFACTS; TRANSFORM; PROJECTION; RECONSTRUCTION; REDUCTION
AB In blocking artifacts reduction based on the projection onto convex sets (POCS) technique, good constraint sets are very important. Until recently, smoothness constraint sets (SCS) are often formulated in the image domain, whereas quantization constraint set is defined in the block-based discrete cosine transform (BDCT) domain. Thus, frequent BDCT transform is inevitable in alternative projections. In this paper, based on signal and quantization noise statistics, we proposed a novel smoothness constraint set in the BDCT transform domain via the Wiener filtering concept. Experiments show that POCS using this smoothness constraint set not only has good convergence but also has better objective and subjective performance. Moreover, this set can be used as extra constraint set to improve most existing POCS-based image postprocessing methods. (c) 2005 Elsevier B.V. All rights reserved.
C1 City Univ Hong Kong, Dept Comp Engn & Informat Technol, Kowloon, Hong Kong, Peoples R China.
   Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
C3 City University of Hong Kong; Chinese University of Hong Kong;
   University of Sydney
RP City Univ Hong Kong, Dept Comp Engn & Informat Technol, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
EM gan.xiangchao@student.cityu.edu.hk
RI Liew, Alan Wee-Chung/F-6988-2011
OI Liew, Alan Wee-Chung/0000-0001-6718-7584; YAN, Hong/0000-0001-9661-3095
CR CHEN T, 2000, IEEE T CIRCUIT SYST, V10, P617
   CHITPRASERT B, 1990, IEEE T COMMUN, V38, P1040, DOI 10.1109/26.57501
   Choy SSO, 1997, IEEE SIGNAL PROC LET, V4, P5, DOI 10.1109/97.551686
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Jeong Y, 2000, IEEE T CIRC SYST VID, V10, P617, DOI 10.1109/76.845007
   Kim Y, 2003, ELECTRON LETT, V39, P1583, DOI 10.1049/el:20031025
   LAGENDIJK RL, 1988, IEEE T ACOUST SPEECH, V36, P1874, DOI 10.1109/29.9032
   Lim J S., 1990, Two-Dimensional Signal and Image Processing, P536
   NGAN KN, 1989, IEEE T ACOUST SPEECH, V37, P1743, DOI 10.1109/29.46556
   Paek H, 1998, IEEE T CIRC SYST VID, V8, P358, DOI 10.1109/76.678636
   Park SH, 1999, IEEE T IMAGE PROCESS, V8, P1361, DOI 10.1109/83.791962
   PENNEBAKER WB, 1993, JPET STILL IMAGE DAT
   Reeves SJ, 1993, IEEE T CIRC SYST VID, V3, P439, DOI 10.1109/76.260202
   ROSENBERG K, 1992, IFIP TRANS C, V2, P91
   Stark Henry, 1998, WILEY S TEL
   Yang YY, 1993, IEEE T CIRC SYST VID, V3, P421, DOI 10.1109/76.260198
   YANG YY, 1995, IEEE T IMAGE PROCESS, V4, P896, DOI 10.1109/83.392332
NR 17
TC 6
Z9 8
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2005
VL 23
IS 8
BP 731
EP 737
DI 10.1016/j.imavis.2005.05.001
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VD
UT WOS:000231400500005
DA 2024-07-18
ER

PT J
AU Jung, CR
   Scharcanski, J
AF Jung, CR
   Scharcanski, J
TI Robust watershed segmentation using wavelets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image de-noising; image enhancement; watersheds segmentation; wavelets
ID EFFICIENT IMAGE SEGMENTATION; ALGORITHM; MORPHOLOGY
AB The use of watersheds in image segmentation relies mostly on a good estimation of image gradients. However, background noise tends to produce spurious gradients, causing over-segmentation and degrading the result of the watershed transform. Also, low-contrast edges generate small magnitude gradients, causing distinct regions to be erroneously merged. In this paper, a new technique is presented to improve the robustness of the segmentation using watersheds, which attenuates the over-segmentation problem. A redundant wavelet transform is used to de-noise the image, enhance edges in multiple resolutions, and obtain an enhanced version of image gradients. Then, the watershed transform is applied to the obtained gradient image, and the segmented regions that do not satisfy specific criteria are removed or merged. Applications of our segmentation approach to noisy and/or blurred images are discussed, emphasizing a case study in fingerprint segmentation. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Fed Rio Grande do Sul, Inst Informat, BR-91501970 Porto Alegre, RS, Brazil.
   Univ Vale Rio dos Sinos, BR-93022000 Sao Leopoldo, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul; Universidade do Vale do Rio
   dos Sinos (Unisinos)
RP Univ Fed Rio Grande do Sul, Inst Informat, Av Bento Goncalves,9500, BR-91501970 Porto Alegre, RS, Brazil.
EM crjung@exatas.unisinos.br; jacobs@inf.ufrgs.br
RI Jung, Claudio R/G-2439-2012; Scharcanski, Jacob/AAA-4799-2021
OI Scharcanski, Jacob/0000-0002-9223-4693
CR [Anonymous], PRORISC 2001 WORKSH
   Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618
   BEUCHER S, 1979, P IEEE INT WORKSH IM
   Bieniek A, 2000, PATTERN RECOGN, V33, P907, DOI 10.1016/S0031-3203(99)00154-5
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kim JB, 2003, PATTERN RECOGN LETT, V24, P473, DOI 10.1016/S0167-8655(02)00270-2
   Kim JB, 2002, INT C PATT RECOG, P505, DOI 10.1109/ICPR.2002.1047987
   MA WY, 1997, IEEE C COMP VIS PATT, P744
   MAIO D, 2002, INT C PATT REC QUEB
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   Meyer F, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P28, DOI 10.1109/SIBGRA.1998.722729
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Nguyen HT, 2003, IEEE T PATTERN ANAL, V25, P330, DOI 10.1109/TPAMI.2003.1182096
   PETERS RA, 1995, IEEE T IMAGE PROCESS, V4, P554, DOI 10.1109/83.382491
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3
   Scharcanski J, 2002, IEEE T IMAGE PROCESS, V11, P1092, DOI 10.1109/TIP.2002.802528
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Weickert J, 2001, PATTERN RECOGN, V34, P1813, DOI 10.1016/S0031-3203(00)00109-6
NR 22
TC 41
Z9 47
U1 0
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2005
VL 23
IS 7
BP 661
EP 669
DI 10.1016/j.imavis.2005.03.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 940LX
UT WOS:000230147100005
DA 2024-07-18
ER

PT J
AU Nagaty, KA
AF Nagaty, KA
TI An adaptive hybrid energy-based fingerprint matching technique
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fingerprints; minutiae matching; proportion ranks; adaptive matching;
   energy minimization
ID ALGORITHM
AB In this paper we present a new adaptive hybrid energy-based fingerprint matching system, which combines both minutiae information available in a fingerprint with the information of the local ridges in their vicinity. A more continuous representation of fingerprints can be obtained by using an energy-based rectangular tessellation with non-overlapped squared cells. However, a fixed tessellation is not efficient in handling non-linear deformations in fingerprints for which we propose an adaptive matching technique that uses dynamic rectangular tessellation to handle them. Each time a match is not found the dynamic tessellation increases its cell size until there is a match or cell size is greater than image size where the fingerprint is rejected. The basic idea of this system is to divide the fingerprint-matching problem into several small sub-problems that involve the use of cell energy minimization for which an iterative schema is devised. At each minimization step this schema optimizes its local energy according to the previous estimate and the observed image features. Minutiae and local ridges in their vicinity, produce different amounts of energy which form the energy vectors of the fingerprint image. In this work, we focus on the difficult problem of recognizing known fingerprints while rejecting unknown ones. Our system was tested on FVC2000 benchmark database of fingerprints and showed promising results. We show that matching performance can be improved by using energy vectors and adaptive matching, where adaptive matching reduces the effect of intra-class variations between different impressions of the same fingerprint image and energy vectors can efficiently represent fingerprints by using both information extracted from the minutiae and their local surrounding ridges. (c) 2005 Elsevier B.V. All rights reserved.
C1 Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University
RP Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.
EM knagaty@asunet.shams.edu.eg
CR ALMANSA A, 2000, FINGERPRINT IMAGE MA, P35
   [Anonymous], 1999, Biometrics: Personal Identification in Networked Society
   [Anonymous], 2003, Handbook of fingerprint recognition
   Bhowmick P., 2002, P ICVGIP, P463
   Eshera M., 1984, P 7 INT C PATT REC M
   Federal Bureau of Investigation, 1984, SCI FING CLASS US
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   HRECHAK AK, 1990, PATTERN RECOGN, V23, P893, DOI 10.1016/0031-3203(90)90134-7
   ISENOR DK, 1986, PATTERN RECOGN, V19, P113, DOI 10.1016/0031-3203(86)90017-8
   Jain A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P282, DOI 10.1109/ICIP.2001.958106
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674
   Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531
   Lee H.C., 1991, ADV FINGERPRINT TECH
   Mehtre B. M., 1993, Machine Vision and Applications, V6, P124, DOI 10.1007/BF01211936
   Nagaty KA, 2001, NEURAL NETWORKS, V14, P1293, DOI 10.1016/S0893-6080(01)00086-7
   RAMADE A, 1993, PATTERN RECOGN, V12, P269
   RATHA NK, 2000, ROBUST FINGERPRINT A, P29, DOI 10.1109/WACV.2000.895399
   ROSEBUSH J, 1985, IEEE COMPUT GRAPH, V5, P14
   TON JC, 1989, IEEE T GEOSCI REMOTE, V27, P642, DOI 10.1109/TGRS.1989.35948
   Wegstein J.H., 1982, AUTOMATED FINGERPRIN, P500
   Xiao Q., 1991, Pattern recognition, V29, P335
NR 23
TC 6
Z9 6
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2005
VL 23
IS 5
BP 491
EP 500
DI 10.1016/j.imavis.2004.12.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 917XA
UT WOS:000228501300004
DA 2024-07-18
ER

PT J
AU Latecki, LJ
   Lakaemper, R
   Wolter, D
AF Latecki, LJ
   Lakaemper, R
   Wolter, D
TI Optimal partial shape similarity
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE shape similarity; visual parts; shape representation; object recognition
ID VISUAL FORM
AB Humans are able to recognize objects in the presence of significant amounts of occlusion and changes in the view angle. In human and robot vision, these conditions are normal situations and not exceptions. In digital images one more problem occurs due to unstable outcomes of the segmentation algorithms. Thus, a normal case is that a given shape is only partially visible, and the visible part is distorted. To our knowledge there does not exist a shape representation and similarity approach that could work under these conditions. However, such an approach is necessary to solve the object recognition problem. The main contribution of this paper is the definition of an optimal partial shape similarity measure that works under these conditions. In particular, the presented novel approach to shape-based object recognition works even if only a small part of a given object is visible and the visible part is significantly distorted, assuming the visible part is distinctive. (C) 2004 Elsevier B.V. All rights reserved.
C1 Temple Univ, Dept Informat & Comp Sci, Philadelphia, PA 19122 USA.
   Univ Bremen, FB Cognit Syst 3, Bremen, Germany.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple
   University; University of Bremen
RP Temple Univ, Dept Informat & Comp Sci, Philadelphia, PA 19122 USA.
EM latecki@temp.edu; lakamper@tem-ple.edu; dwolter@informatik.uni-bremen.de
OI Latecki, Longin Jan/0000-0002-5102-8244
CR [Anonymous], 1971, IEEE C SYST CONTR
   ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509
   ATTALLA E, 2004, THESIS WAYNE STATE U
   Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7
   BOBER M, 1999, JTC1SC29WG11MPEG99M4
   BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X
   BURL MC, 1996, RECOGNITION PLANA OB
   CYR CM, 2001, 3D OBJECT RECOGNITIO
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   LAKAEMPER R, SHAPE SEARCH ENGINE
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   LATECKI LJ, 2002, SPECIAL ISSUES SHAPE, V35
   LATECKI LJ, 2003, SHAPE SIMILARITY VIS
   LATECKI LJ, 2000, SHAPE DESCRIPTORS NO, P424
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   MUELLER K, 2000, ISOIECJTC1SC29WG11
   PENTLAND A, 1987, RECOGNITION PARTS, P612
   Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951
   SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189
   Siddiqi K, 1996, PERCEPTION, V25, P399, DOI 10.1068/p250399
   WEBER M, 2000, UNSUPERVISED LEARNIN, P18
   WEBER M, 2000, AUTOMATIC DISCOVERY, P101
NR 28
TC 44
Z9 51
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 227
EP 236
DI 10.1016/j.imavis.2004.06.015
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800013
OA Green Published
DA 2024-07-18
ER

PT J
AU González-Velasco, HM
   García-Orellana, CJ
   Macías-Macías, M
   López-Aligué, FJ
   Acevedo-Sotoca, MI
AF González-Velasco, HM
   García-Orellana, CJ
   Macías-Macías, M
   López-Aligué, FJ
   Acevedo-Sotoca, MI
TI Neural-networks-based edges selector for boundary extraction problems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE edge detection; edge selection; boundary extraction; neural networks
ID MODELS
AB In the present work, a neural-networks-based system is presented that makes it possible to reduce, when generating edge maps to be used in an object boundary detection problem, the number of edges that are not due to the object itself, but to the background. Starting from a conventional edge detection, the selection is carried out by a neural-networks-based classifier, which is trained using examples. As a test for the system, the application to bovine livestock images (from which we want to extract the boundary of the animal) is presented. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Extremadura, Dept Elect & Electromech Engn, E-06071 Badajoz, Spain.
C3 Universidad de Extremadura
RP Univ Extremadura, Dept Elect & Electromech Engn, E-06071 Badajoz, Spain.
EM horacio@nemet.unex.es
RI Macias, Miguel/F-7640-2016; Gonzalez Velasco, Horacio M./A-4368-2012;
   Garcia-Orellana, Carlos J./E-5265-2016
OI Macias, Miguel/0000-0002-2013-4204; Gonzalez Velasco, Horacio
   M./0000-0002-4459-4811; Garcia-Orellana, Carlos J./0000-0001-6089-1499
CR COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4
   *DEP EL EL ENG, APPL GA DEF MOD TECH
   GONZALEZ HM, 2003, INT J PATTERN RECOGN, V17, P601
   GONZALEZ HM, 2001, LECT NOTES COMPUTER, V2084, P482
   HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Parker J.R., 1996, Algorithms for Image Processing and Computer Vision
   RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623
   SRINIVASAN V, 1994, PATTERN RECOGN, V27, P1653, DOI 10.1016/0031-3203(94)90084-1
   SUZUKI K, 2001, LECT NOTES COMPUTER, V2085, P303
   TOET A, 1995, PATTERN RECOGN LETT, V16, P849, DOI 10.1016/0167-8655(95)00015-9
   TOET A, 1994, TARGET DETECTION REC
   Wong HS, 2000, PATTERN RECOGN, V33, P427, DOI 10.1016/S0031-3203(99)00088-6
NR 14
TC 5
Z9 5
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2004
VL 22
IS 13
BP 1129
EP 1135
DI 10.1016/j.imavis.2004.05.005
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 862LY
UT WOS:000224493600004
DA 2024-07-18
ER

PT J
AU Oskarsson, M
   Zisserman, A
   Åström, K
AF Oskarsson, M
   Zisserman, A
   Åström, K
TI Minimal projective reconstruction for combinations of points and lines
   in three views
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE projective reconstruction; points and lines; conics
ID UNCALIBRATED IMAGES; TRIFOCAL TENSOR; CORRESPONDENCES; MOTION;
   INVARIANTS
AB In this article we address the problem of projective reconstruction of structure and motion given only image data. In particular we investigate three novel minimal combinations of points and lines over three views, and give complete solutions and reconstruction methods for two of these cases: 'four points and three lines in three views', and 'two points and six lines in three views'. We show that in general there are three and seven solutions, respectively, to these cases. The reconstruction methods are tested on real and simulated data. We also give tentative results for the case of nine lines in correspondence over three views, where experiments indicate that there may be up to 36 complex solutions. (C) 2004 Elsevier B.V. All rights reserved.
C1 Lund Univ, Ctr Math Sci, SE-22100 Lund, Sweden.
   Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England.
C3 Lund University; University of Oxford
RP Lund Univ, Ctr Math Sci, POB 118, SE-22100 Lund, Sweden.
EM magnuso@maths.lth.se; az@robots.ox.ac.uk; kalle@maths.lth.se
RI Astrom, Kalle/AAT-9538-2020
OI Astrom, Kalle/0000-0002-8689-7810; Oskarsson, Magnus/0000-0002-1789-8094
CR [Anonymous], 1998, USING ALGEBRAIC GEOM, DOI DOI 10.1007/978-1-4757-6911-1
   ASTROM K, 1999, P 7 INT C COMP VIS K
   BUCHANAN T, 1992, P 2 EUR C COMP VIS S, P730
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley R. I., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), P903, DOI 10.1109/CVPR.1994.323922
   Hartley R.I., 1994, P ARPA IM UND WORKSH
   HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005
   Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022
   Heyden Anders, 1995, THESIS LUND I TECHNO
   Holt RJ, 1996, J VIS COMMUN IMAGE R, V7, P126, DOI 10.1006/jvci.1996.0012
   Holt RJ, 1997, INT J IMAG SYST TECH, V8, P301, DOI 10.1002/(SICI)1098-1098(1997)8:3<301::AID-IMA8>3.0.CO;2-E
   Kahl F., 2001, P C COMP VIS PATT RE
   MAYBANK SJ, 1995, APPL ALGEBR ENG COMM, V6, P89, DOI 10.1007/BF01225646
   QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34
   Quan L, 1997, IEEE T PATTERN ANAL, V19, P834, DOI 10.1109/34.608285
   SPETSAKIS ME, 1990, INT J COMPUT VISION, V4, P171, DOI 10.1007/BF00054994
   Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3
   Triggs B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P278, DOI 10.1109/ICCV.1999.791231
   TRIGGS W, 2000, LNCS
   Verschelde J, 1999, ACM T MATH SOFTWARE, V25, P251, DOI 10.1145/317275.317286
   Vieville T., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P517, DOI 10.1109/ICCV.1990.139585
   WENG J, 1988, P IEEE C COMP VIS PA, P387
   WENG JY, 1992, IEEE T PATTERN ANAL, V14
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 25
TC 10
Z9 14
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 777
EP 785
DI 10.1016/j.imavis.2004.02.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300005
DA 2024-07-18
ER

PT J
AU Benlamri, R
   Al-Marzooqi, Y
AF Benlamri, R
   Al-Marzooqi, Y
TI Free-form object segmentation and representation from registered range
   and color images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE free-form object modeling; range image segmentation; 3D surface
   representation; image registration; hermite interpolation
ID RECOGNITION; CURVES; SURFACES
AB This paper describes a new technique to 3D surface segmentation and representation of free-form objects from registered range and color images. The proposed approach combines edge and region information to derive a surface description using algebraic implicit surfaces. This is done by propagating and blending Piecewise Hermite Interpolation Surfaces. The proposed technique, not only reduces the number of used patches, but also preserves surface-depth and orientation continuity. It can also be used to generate partial surface models for CAD-based vision and object recognition purposes. Realistic partial models are obtained by mapping texture extracted from a registered color image onto the generated surfaces. Experimental results show that the system can produce reliable surface segmentation as well as realistic 3D surface models of free-form objects. (C) 2004 Elsevier B.V. All rights reserved.
C1 Etisalat Coll Engn, Dept Comp Engn, Sharjah 980, U Arab Emirates.
C3 Khalifa University of Science & Technology
RP Benlamri, R (corresponding author), Etisalat Coll Engn, Dept Comp Engn, POB 980, Sharjah 980, U Arab Emirates.
EM benlamri@ece.ac.ae
CR ALBOUL L, 1997, MATH SURFACES, V7, P309
   ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255
   AYONGCHEE N, 1996, OBJECT REPRESENTATIO, V2, P321
   BACCAR L, 1996, PATTERN RECOGNIT OCT, P1673
   BAJAJ C, 1992, DIRECTIONS GEOMETRIC, P1
   Bajaj Chandrajit., 1997, Introduction to implicit surfaces
   BAJAJ CL, 1995, ACM T GRAPHIC, V14, P103, DOI 10.1145/221659.221662
   Benlamri R, 2000, PATTERN RECOGN LETT, V21, P1051, DOI 10.1016/S0167-8655(00)00062-3
   Benlamri R, 2002, GEOMETRIC MODELING AND PROCESSING: THEORY AND APPLICATIONS, PROCEEDINGS, P197, DOI 10.1109/GMAP.2002.1027511
   BESL L, 1998, PATTERN RECOGNIT FEB, P121
   Besl P.J., 1990, Machine Vision for Three-Dimensional Scenes, P25, DOI [10.1016/B978-0-12-266722-0.50006-3, DOI 10.1016/B978-0-12-266722-0.50006-3]
   Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760
   BROWN CM, 1981, IEEE T PATTERN ANAL, V3, P444, DOI 10.1109/TPAMI.1981.4767129
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   DAHMEN W, 1993, COMPUT AIDED GEOM D, V10, P89, DOI 10.1016/0167-8396(93)90013-S
   Dierckx P., 1993, Curve and Surface Fitting with Splines
   Ernest M. S., 1992, IEEE T PATTERN ANAL, V14, P833
   FAN TJ, 1990, DESCRIPTION RECOGNIZ
   Farin G., 1997, Curves and surfaces for cagd: a pratical guide, V4th
   Figueiredo MAT, 2000, IEEE T IMAGE PROCESS, V9, P1075, DOI 10.1109/83.846249
   GAO X, 2002, P 2 INT C GEOM MOD P
   Hartmann E, 2001, COMPUT AIDED GEOM D, V18, P267, DOI 10.1016/S0167-8396(01)00030-9
   LEAONARDIS A, 1995, INT J COMPUTER V APR, P253
   Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940
   Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433
   Marshall D, 2001, IEEE T PATTERN ANAL, V23, P304, DOI 10.1109/34.910883
   MONGA O, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P852, DOI 10.1109/CVPR.1994.323912
   Nishida H, 1997, PATTERN RECOGN, V30, P45, DOI 10.1016/S0031-3203(96)00062-3
   RAJA NS, 1992, IMAGE VISION COMPUT, V10, P179, DOI 10.1016/0262-8856(92)90069-F
   Subrahmonia J, 1996, IEEE T PATTERN ANAL, V18, P505, DOI 10.1109/34.494640
   Tasdizen T, 2000, IEEE T IMAGE PROCESS, V9, P405, DOI 10.1109/83.826778
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   WARREN J, 1989, ACM T GRAPHIC, V8, P263, DOI 10.1145/77269.77270
   Zariski O., 1958, Commutative algebra, V1
   Zariski O, 1958, Commutative Algebra, VII
   ZHAN SM, 1994, COMPUTER VISION GRAP, V9, P346
   Zhang YJ, 1997, PATTERN RECOGN LETT, V18, P963, DOI 10.1016/S0167-8655(97)00083-4
NR 37
TC 6
Z9 7
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 20
PY 2004
VL 22
IS 9
BP 703
EP 717
DI 10.1016/j.imavis.2004.03.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 834WE
UT WOS:000222440800003
DA 2024-07-18
ER

PT J
AU Babu, RV
   Ramakrishnan, KR
AF Babu, RV
   Ramakrishnan, KR
TI Recognition of human actions using motion history information extracted
   from the compressed video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE action recognition; compressed domain; content-based retrieval; feature
   extraction; motion history; video indexing
ID HUMAN MOVEMENT; REPRESENTATION; BEHAVIOR; SYSTEM
AB Human motion analysis is a recent topic of interest among the computer vision and video processing community. Research in this area is motivated by its wide range of applications such as surveillance and monitoring systems. In this paper we describe a system for recognition of various human actions from compressed video based on motion history information. We introduce the notion of quantifying the motion involved, through what we call Motion Flow History (MFH). The encoded motion information readily available in the compressed MPEG stream is used to construct the coarse Motion History Image (MHI) and the corresponding MFH. The features extracted from the static MHI and MFH compactly characterize the spatio-temporal and motion vector information of the action. Since the features are extracted from the partially decoded sparse motion data, the computational load is minimized to a great extent. The extracted features are used to train the KNN, Neural network, SVM and the Bayes classifiers for recognizing a set of seven human actions. The performance of each feature set with respect to various classifiers are analyzed. (C) 2003 Elsevier B.V. All rights reserved.
C1 Norwegian Univ Sci & Technol, Ctr Quantifiable Qual Serv Commun Syst, N-7491 Trondheim, Norway.
   Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.
C3 Norwegian University of Science & Technology (NTNU); Indian Institute of
   Science (IISC) - Bangalore
RP Norwegian Univ Sci & Technol, Ctr Quantifiable Qual Serv Commun Syst, OS Bragstads Plass 2E, N-7491 Trondheim, Norway.
EM venkat@q2s.ntnu.no; krr@ee.isc.ernet.in
RI Radhakrishnan, Venkatesh Babu/D-5313-2009
OI Radhakrishnan, Venkatesh Babu/0000-0002-1926-1804
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Ayers D, 2001, IMAGE VISION COMPUT, V19, P833, DOI 10.1016/S0262-8856(01)00047-6
   Babu RV, 2002, PATTERN RECOGN LETT, V23, P1203, DOI 10.1016/S0167-8655(02)00067-3
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892
   BOEHM K, 1994, P SOC PHOTO-OPT INS, V2177, P336, DOI 10.1117/12.173889
   Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382
   Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109
   Davis JW, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P39, DOI 10.1109/EVENT.2001.938864
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Fleet DJ, 2000, INT J COMPUT VISION, V36, P171, DOI 10.1023/A:1008156202475
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Haykin S., 1998, NEURAL NETWORKS COMP
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   MADABHUSHI A, 1999, 2 IEEE WORKSH VIS SU
   Mitchell J.L., 1996, MPEG VIDEO COMPRESSI
   *MPEGI ISO IEC, 1996, 11172 MPEGI ISO IEC
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   POLANA R, 1994, WORKSH MOT NONR ART, P77
   Psarrou A, 2002, IMAGE VISION COMPUT, V20, P349, DOI 10.1016/S0262-8856(02)00007-0
   Rittscher J, 2002, IMAGE VISION COMPUT, V20, P905, DOI 10.1016/S0262-8856(02)00099-9
   ROSALES R, 98020 BU
   SHAH M, 1997, MOTION BASED RECOGIN
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   STARNER T, 1995, TR375 MIT MED LAB
   SU M, 1998, P IEEE WORLD C COMP
   SUN XD, 2002, IEEE INT C IM PROC S, V2, P813
   Umeda M., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P793
   Vapnik V., 1999, NATURE STAT LEARNING
   VENKATESH R, 2003, IEEE INT C AC SPEECH, V3, P41
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
NR 35
TC 59
Z9 68
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2004
VL 22
IS 8
BP 597
EP 607
DI 10.1016/j.imavis.2003.11.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RV
UT WOS:000221481200002
DA 2024-07-18
ER

PT J
AU Barash, D
   Comaniciu, D
AF Barash, D
   Comaniciu, D
TI A common framework for nonlinear diffusion, adaptive smoothing,
   bilateral filtering and mean shift
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE nonlinear diffusion; adaptive smoothing; bilateral filtering; mean shift
   procedure
ID SCALE-SPACE
AB In this paper, a common framework is outlined for nonlinear diffusion, adaptive smoothing, bilateral filtering and mean shift procedure. Previously, the relationship between bilateral filtering and the nonlinear diffusion equation was explored by using a consistent adaptive smoothing formulation. However, both nonlinear diffusion and adaptive smoothing were treated as local processes applying a 3 X 3 window at each iteration. Here, these two approaches are extended to an arbitrary window, showing their equivalence and stressing the importance of using large windows for edge-preserving smoothing. Subsequently, it follows that bilateral filtering is a particular choice of weights in the extended diffusion process that is obtained from geometrical considerations. We then show that kernel density estimation applied in the joint spatial-range domain yields a powerful processing paradigm-the mean shift procedure, related to bilateral filtering but having additional flexibility. This establishes an attractive relationship between the theory of statistics and that of diffusion and energy minimization. We experimentally compare the discussed methods and give insights on their performance. (C) 2003 Elsevier B.V. All rights reserved.
C1 NYU, Dept Chem, New York, NY 10003 USA.
   NYU, Courant Inst Math Sci, New York, NY 10003 USA.
   Howard Hughes Med Inst, New York, NY 10003 USA.
   Siement Corp Res, Real Time Vis & Modeling Dept, Princeton, NJ 08540 USA.
C3 New York University; New York University; Howard Hughes Medical
   Institute
RP Univ Haifa, Inst Evolut, Genome Divers Ctr, IL-31905 Har Hakarmel, Israel.
EM dbarash@research.haifa.ac.il; comanici@scr.siemens.com
OI Comaniciu, Dorin/0000-0002-5238-8647
CR Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390
   BARASH D, 2000, HPL200018R1
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   BOULT T, 1993, P SOC PHOTO-OPT INS, V2060, P96, DOI 10.1117/12.165007
   Caselles V, 2000, J MATH IMAGING VIS, V12, P109, DOI 10.1023/A:1008310305351
   Chan T, 2000, SIAM J APPL MATH, V61, P1338, DOI 10.1137/S003613999935799X
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P231, DOI 10.1109/83.902288
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P281, DOI 10.1109/TPAMI.2003.1177159
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   DURAND F, 2002, P ACM SIGGRAPH 2002
   Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126
   Fischl B, 1999, IEEE T PATTERN ANAL, V21, P42, DOI 10.1109/34.745732
   GUICHARD F, 2000, IN PRESS IMAGE ITERA
   KIMMEL R, 1997, P IEEE COMP SOC C CO
   Koenderink JJ, 1999, INT J COMPUT VISION, V31, P159, DOI 10.1023/A:1008065931878
   Maragos P, 1999, LECT NOTES COMPUT SC, V1682, P363
   Nielsen M, 1997, J MATH IMAGING VIS, V7, P291, DOI 10.1023/A:1008282127190
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339
   Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181
   Sochen N, 2001, J MATH IMAGING VIS, V14, P195, DOI 10.1023/A:1011277827470
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   van de Weijer J, 2001, PROC CVPR IEEE, P428
   VANDENBOOMGAARD R, 1994, IEEE T PATTERN ANAL, V16, P1101, DOI 10.1109/34.334389
   WEICKERT J, 2000, 42000 TR U MANNH DEP
   WEICKERT J, 1998, ANISOTROPIC DIFFUSIO, P3
   Yezzi A, 1998, IEEE T IMAGE PROCESS, V7, P345, DOI 10.1109/83.661184
NR 29
TC 159
Z9 188
U1 1
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2004
VL 22
IS 1
BP 73
EP 81
DI 10.1016/j.imavis.2003.08.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 763BB
UT WOS:000188048400007
DA 2024-07-18
ER

PT J
AU Mishra, A
   Dutta, PK
   Ghosh, MK
AF Mishra, A
   Dutta, PK
   Ghosh, MK
TI A GA based approach for boundary detection of left ventricle with
   echocardiographic image sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE genetic algorithm; ultrasound images and snake
AB In this paper automatic detection of the boundary of left ventricle (LV) in a sequence of cardiac images has been proposed. The contour detection algorithm is formulated as a constrained optimization problem based on active contour model. The optimization problem has been solved using Genetic Algorithm (GA). The result obtained by the proposed GA based approach is compared with conventional nonlinear programming methods. Validation of the computer-generated boundaries is done after comparing them with manually outlined contours by expert observers. The performance of the algorithm is comparable to inter-observer anomalies. (C) 2003 Elsevier B.V. All rights reserved.
C1 Indian Inst Technol, Dept Elect Engn, Kharagpur 721302, W Bengal, India.
   IGIT, Dept Elect Engn, Sarang 759146, India.
   Indian Inst Technol, Dept Elect Engn, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indira Gandhi Institute of Technology
   Sarang; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Kharagpur
RP Indian Inst Technol, Dept Elect Engn, Kharagpur 721302, W Bengal, India.
EM pkd@ee.iitkgp.ernet.in
CR AMINI AA, 1988, P 2 INT C COMP VIS, P95
   [Anonymous], 1983, Mathematical Programming The State of the Art, DOI DOI 10.1175/BAMS-84-9-1205
   BHANDARKAR SM, 1994, PATTERN RECOGN, V27, P1159, DOI 10.1016/0031-3203(94)90003-5
   BHANU B, 1995, IEEE T SYST MAN CYB, P1043
   Chalana V, 1996, IEEE T MED IMAGING, V15, P290, DOI 10.1109/42.500138
   CHU CH, 1988, IEEE T MED IMAGING, V7, P81, DOI 10.1109/42.3932
   Corsi C, 2002, IEEE T MED IMAGING, V21, P1202, DOI 10.1109/TMI.2002.804418
   FLEAGLE SR, 1991, INVEST RADIOL, V26, P295, DOI 10.1097/00004424-199104000-00002
   Geiser E A, 1990, J Am Soc Echocardiogr, V3, P79
   GOLDBERG DE, 1994, COMMUN ACM, V37, P30
   GOLDBERG SJ, 1984, ULTRASOUND MED BIOL, V10, P797, DOI 10.1016/0301-5629(84)90238-2
   HAN SP, 1977, J OPTIMIZ THEORY APP, V22, P297, DOI 10.1007/BF00932858
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KRISHNAKUMAR K, 1994, J GUID CONTROL DYNAM, V17, P1374, DOI 10.2514/3.21362
   KRISHNAKUMAR K, 1995, GENETIC ALGORITHM EN
   LILLY P, 1989, IEEE T MED IMAGING, V8, P173, DOI 10.1109/42.24866
   MISHRA A, 2000, P JOINT INT C SCI 20
   Nastar C., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P275, DOI 10.1109/ICCV.1993.378206
   POWELL MJD, 1978, NUMERICAL ANAL, P63
   RANGANATH S, 1995, IEEE T MED IMAGING, V14, P328, DOI 10.1109/42.387714
   RANGANATH S, 1992, P 2 INT C AUT ROB CO
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   Suh D. Y., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P149, DOI 10.1109/VBC.1990.109314
   Terzopoulos D., 1987, TECHNICAL DIGEST SER, V12, P164
   THOMAS JG, 1991, IEEE T MED IMAGING, V10, P180, DOI 10.1109/42.79476
   Wang HY, 2000, IEEE T IMAGE PROCESS, V9, P302, DOI 10.1109/83.821748
   Zhu Y, 1997, IEEE T MED IMAGING, V16, P55, DOI 10.1109/42.552055
NR 29
TC 54
Z9 65
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2003
VL 21
IS 11
BP 967
EP 976
DI 10.1016/S0262-8856(03)00121-5
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 731CP
UT WOS:000185867200003
DA 2024-07-18
ER

PT J
AU Malamas, EN
   Petrakis, EGM
   Zervakis, M
   Petit, L
   Legat, JD
AF Malamas, EN
   Petrakis, EGM
   Zervakis, M
   Petit, L
   Legat, JD
TI A survey on industrial vision systems, applications and tools
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE machine vision; automated visual inspection; image processing; image
   analysis
ID AUTOMATED VISUAL INSPECTION; COMPUTER VISION; NEURAL-NETWORK; MACHINE
   VISION; GENETIC ALGORITHMS; CLASSIFYING IMAGES; QUALITY-CONTROL;
   DYNAMIC-RANGE; WOOD VENEER; CLASSIFICATION
AB The state of the art in machine vision inspection and a critical overview of real-world applications are presented in this paper. Two independent ways to classify applications are proposed, one according to the inspected features of the industrial product or process and the other according to the inspection independent characteristics of the inspected product or process. The most contemporary software and hardware tools for developing industrial vision systems are reviewed. Finally, under the light of recent advances in image sensors, software and hardware technology, important issues and directions for designing and developing industrial vision systems are identified and discussed. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Tech Univ Crete, Dept Elect & Comp Engn, Khania 73100, Crete, Greece.
   Univ Catholique Louvain, Microelect Lab, B-1348 Louvain, Belgium.
C3 Technical University of Crete; Universite Catholique Louvain
RP Petrakis, EGM (corresponding author), Tech Univ Crete, Dept Elect & Comp Engn, Khania 73100, Crete, Greece.
RI Petrakis, Euripides G.M./F-6741-2018
OI Petrakis, Euripides G.M./0000-0001-7436-5852
CR ANARD S, 1999, J MANUF SYST, V18, P396
   Andrey P, 1999, IMAGE VISION COMPUT, V17, P175, DOI 10.1016/S0262-8856(98)00095-X
   Baglietto P, 1996, P IEEE, V84, P917, DOI 10.1109/5.503295
   Bahlmann C, 1999, PATTERN RECOGN, V32, P1049, DOI 10.1016/S0031-3203(98)00128-9
   Barni M, 1997, IMAGE VISION COMPUT, V15, P549, DOI 10.1016/S0262-8856(97)01138-4
   Bezdek J., 1999, FUZZY MODELS ALGORIT
   Bhandarkar SM, 1997, IEEE T PARALL DISTR, V8, P292, DOI 10.1109/71.584095
   Bhandarkar SM, 1999, MACH VISION APPL, V11, P171, DOI 10.1007/s001380050100
   Bose N.K., 1996, Neural Network Fundamentals with Graphs, Algorithms, and Applications
   Boyer KL, 2001, MACH VISION APPL, V12, P291, DOI 10.1007/s001380050147
   Braggins D., 1996, Sensor Review, V16, P16, DOI 10.1108/02602289610123512
   Braggins D., 1995, Sensor Review, V15, P11, DOI 10.1108/02602289510085534
   Carpenter Gail A., 1992, IEEE T NEURAL NETWOR, V3
   Chang SH, 1997, IEEE T NEURAL NETWOR, V8, P964, DOI 10.1109/72.595897
   CHEN YH, 1995, OPT LASER ENG, V22, P181, DOI 10.1016/0143-8166(94)00045-C
   CHIN RT, 1988, COMPUT VISION GRAPH, V41, P346, DOI 10.1016/0734-189X(88)90108-9
   CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309
   Chung Y., 1997, INT C SIGNAL PROCESS
   Cootes TF, 1996, IMAGE VISION COMPUT, V14, P533, DOI 10.1016/0262-8856(96)01098-0
   Cucchiara R, 1998, MACH VISION APPL, V11, P1, DOI 10.1007/s001380050084
   Davies E.R., 1998, Automated Visual Inspection, Machine Vision, VSecond, P471
   DECHOW DL, 1997, VISION SHOW
   DELP EJ, 1997, IEEE SIGNAL PROCESSI, V15, P8
   Drake PR, 1998, INT J ADV MANUF TECH, V14, P280, DOI 10.1007/BF01199883
   EDUARDO BC, 1993, SPIE INTELLIGENT ROB, V2055, P159
   EDUARDO BC, 1993, SPIE INTELLIGENT ROB, V2055, P128
   FATHNAM S, 1998, IEEE SIGNAL PROCESSI, V15, P108
   Fossum ER, 1997, IEEE T ELECTRON DEV, V44, P1689, DOI 10.1109/16.628824
   Golberg D.E., 1999, GENETIC ALGORITHMS S
   Goulermas JY, 1998, IMAGE VISION COMPUT, V16, P615, DOI 10.1016/S0262-8856(98)00075-4
   Hammerstrom DW, 1996, P IEEE, V84, P1005, DOI 10.1109/5.503300
   HAUSCHILD R, 1999, EUR SOL STAT CIRC C
   Haykin S., 1999, NEURAL NETWORK COMPR
   Hou TH, 1999, INT J ADV MANUF TECH, V15, P843, DOI 10.1007/s001700050141
   HUNSICKER RJ, 1994, J MANUF SYST, V13, P370, DOI 10.1016/0278-6125(94)P2586-4
   HUNTER JJ, 1995, IMAGE VISION COMPUT, V13, P623, DOI 10.1016/0262-8856(95)97287-V
   JAGANNATHAN S, 1992, J MANUF SYST, V11, P137, DOI 10.1016/0278-6125(92)90044-G
   JANANNATHAN S, 1997, J MANUF SYST, V16, P389
   JANG JS, 1993, IEEE T SYST MAN CYB, V23, P63
   Jeng JY, 2000, INT J ADV MANUF TECH, V16, P212, DOI 10.1007/s001700050029
   Jiang BC, 1998, J MANUF SYST, V17, P159, DOI 10.1016/S0278-6125(98)80058-7
   Jiménez A, 1999, PATTERN RECOGN, V32, P1719, DOI 10.1016/S0031-3203(98)00170-8
   Jiménez AR, 2000, MACH VISION APPL, V11, P321, DOI 10.1007/s001380050117
   Kavoussanos M, 1998, INT J ADV MANUF TECH, V14, P358, DOI 10.1007/BF01178915
   Ker J., 1990, VIS 90 C
   Khandogin I, 1998, INT C SIGN PROC APPL
   KHANDOGIN I, 1997, INT C SIGN PROC APPL
   Kim KH, 1998, INT C SIGN PROC APPL
   Kim TH, 1999, PATTERN RECOGN, V32, P565, DOI 10.1016/S0031-3203(98)00103-4
   Komuro T, 1999, ADV ROBOTICS, V12, P619, DOI 10.1163/156855399X00036
   Kopardekar P., 1993, Integrated Manufacturing Systems, V4, P18, DOI 10.1108/09576069310023838
   Kuo YH, 1996, J INTELL FUZZY SYST, V4, P257
   Lacey AJ, 1998, IMAGE VISION COMPUT, V16, P373, DOI 10.1016/S0262-8856(97)00068-1
   Li H., 1994, IEEE Transactions on Industry Applications, V30, P1530
   Lin C.-.T., 1996, Neural Fuzzy Systems: A Neuro-Fuzzy Synergism to Intelligent Systems
   LITWILLER D, 2001, CMOS FACTS FICTION
   Loinaz M., 1999, Sensor Review, V19, P19, DOI 10.1108/02602289910255522
   MAGEE M, 1995, J MANUF SYST, V14, P169, DOI 10.1016/0278-6125(95)98885-A
   MCKROY J, 1995, SENSOR REV, V15, P8
   MILLER W, 1996, INT C SIGN PROC APPL
   Mital A., 1998, Integrated Manufacturing Systems, V9, P344, DOI 10.1108/09576069810238709
   Moganti M, 1996, COMPUT VIS IMAGE UND, V63, P287, DOI 10.1006/cviu.1996.0020
   Moreira M, 1999, J INTELL FUZZY SYST, V7, P151
   NEWMAN TS, 1995, COMPUT VIS IMAGE UND, V61, P231, DOI 10.1006/cviu.1995.1017
   Novini A. R., 1990, VIS 90 C
   Oyeleye O, 1998, J MANUF SYST, V17, P251, DOI 10.1016/S0278-6125(98)80073-3
   Packianather MS, 2000, INT J ADV MANUF TECH, V16, P424, DOI 10.1007/s001700050174
   Pal S.K., 1999, NEURO FUZZY PATTERN
   Purcell S, 1998, IEEE SIGNAL PROC MAG, V15, P102, DOI 10.1109/79.664703
   Sanches J. M. R., 1997, INT C SIGN PROC APPL
   SANZ JLC, 1988, IEEE T PATTERN ANAL, V10, P830, DOI 10.1109/34.9106
   SarkodieGyan T, 1997, MECHATRONICS, V7, P185, DOI 10.1016/S0957-4158(96)00049-9
   SCHANZ M, 1997, P EUR SOL STAT CIRC
   SEIBOLD C, 2002, COMP CMOS CCD IMAGE
   Shafarenko L, 1997, IEEE T IMAGE PROCESS, V6, P1530, DOI 10.1109/83.641413
   Shiau YR, 1999, J MANUF SYST, V18, P22, DOI 10.1016/S0278-6125(99)80010-7
   Smith ML, 1999, IMAGE VISION COMPUT, V17, P321, DOI 10.1016/S0262-8856(98)00136-X
   TAYLOR CJ, 1988, PHILOS T R SOC A, V324, P457, DOI 10.1098/rsta.1988.0033
   Tonshoff HK, 1997, ROBOT CIM-INT MANUF, V13, P1, DOI 10.1016/S0736-5845(96)00031-2
   Torres F, 1998, IMAGE VISION COMPUT, V16, P947, DOI 10.1016/S0262-8856(98)00059-6
   TRETTER D, 1995, IEEE T IMAGE PROCESS, V4, P1641, DOI 10.1109/83.475514
   Tsai DM, 1998, INT J ADV MANUF TECH, V14, P412, DOI 10.1007/BF01304620
   Tsai DM, 1999, INT J ADV MANUF TECH, V15, P217, DOI 10.1007/s001700050059
   Tsai DM, 1999, IMAGE VISION COMPUT, V18, P49, DOI 10.1016/S0262-8856(99)00009-8
   Tucker J., 1989, P VIS 89 C
   VELTEN J, 1999, INT C SIGN PROC APPL
   *VLSI VIS INC, 2000, VV55006500 MULT FORM
   Wang CL, 1996, P IEEE, V84, P931, DOI 10.1109/5.503296
   Yamada K, 1997, ELECTR ENG JPN, V120, P34, DOI 10.1002/(SICI)1520-6416(19970730)120:2<34::AID-EEJ5>3.0.CO;2-U
   Yamada K, 1998, IEEE T VEH TECHNOL, V47, P332, DOI 10.1109/25.661058
   Zikidis KC, 1996, FUZZY SET SYST, V83, P63, DOI 10.1016/0165-0114(95)00296-0
   2000, RACIC 810811 RANDOM
   2001, CMOS VS CCD FUTURE I
   2000, MOTION VISION CAMERA
NR 94
TC 527
Z9 613
U1 5
U2 129
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 10
PY 2003
VL 21
IS 2
BP 171
EP 188
AR PII S0262-8856(02)00152-X
DI 10.1016/S0262-8856(02)00152-X
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 655CP
UT WOS:000181534000004
DA 2024-07-18
ER

PT J
AU Li, CZ
   Wang, GH
   Long, Q
   Zhou, ZS
AF Li, Chunzheng
   Wang, Gaihua
   Long, Qian
   Zhou, Zhengshu
TI SGF3D: Similarity-guided fusion network for 3D object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE LiDAR; 3D object detection; Multi-modal; Point cloud features
AB The representation of pseudo point cloud can significantly improve the precision of 3D object detection. How-ever, existing pseudo point cloud-based methods typically fuse the processed features through coarse concate-nation, which ignores the consistency between the point cloud and pseudo point cloud features. The inconsistency of features in different modal data can lead to detection bias. In this paper, we propose a novel pseudo point cloud-based network called SGF3D, which utilizes a cross-modal attention module cross-modal attention fusion (CMAF) to fuse point cloud and pseudo point cloud features. It can better learn the cross-modal similarity of output features, enabling the detection box to fit better with the target. We also designed a region of interest (RoI) head similarity attention head (SAH) to utilize the overlooked similarity to optimize training without increasing the complexity of the network. By using CMAF and SAH, the proposed method can obtain more accurate bounding boxes. Extensive experiments on KITTI dataset demonstrate that the proposed method can achieve competitive results. Training code and well trained weights are available at https://github.com/ChunZheng2022/SGF3D.
C1 [Li, Chunzheng] Hubei Univ Technol, Sch Elect & Elect Engn, Nanli Rd 28, Wuhan 430068, Peoples R China.
   [Wang, Gaihua; Long, Qian; Zhou, Zhengshu] Tianjin Univ Sci & Technol, Coll Artificial Intelligence, Dagu South Rd 1038, Tianjin 300457, Peoples R China.
C3 Hubei University of Technology; Tianjin University Science & Technology
RP Wang, GH (corresponding author), Tianjin Univ Sci & Technol, Coll Artificial Intelligence, Dagu South Rd 1038, Tianjin 300457, Peoples R China.
EM wanggh@tust.edu.cn
OI Chunzheng, Li/0009-0004-0729-0669
CR Alaba SY, 2023, IEEE SENS J, V23, P3378, DOI 10.1109/JSEN.2023.3235830
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen YK, 2022, PROC CVPR IEEE, P5418, DOI 10.1109/CVPR52688.2022.00535
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Deng JJ, 2021, AAAI CONF ARTIF INTE, V35, P1201
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Imran S, 2021, PROC CVPR IEEE, P2583, DOI 10.1109/CVPR46437.2021.00261
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Kumar A., 2014, Seisan Kenkyu, V66, P101
   Kumar A., 2013, Seisan Kenkyu, V65, P91
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Li X, 2023, PROC CVPR IEEE, P17524, DOI 10.1109/CVPR52729.2023.01681
   Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Liu Z, 2023, IEEE T PATTERN ANAL, V45, P8324, DOI 10.1109/TPAMI.2022.3228806
   Mahmoud A, 2023, IEEE WINT CONF APPL, P663, DOI 10.1109/WACV56688.2023.00073
   OD Team, 2020, Openpcdet: An open-source toolbox for 3d object detection from point clouds
   Pang S, 2020, IEEE INT C INT ROBOT, P10386, DOI 10.1109/IROS45743.2020.9341791
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Sheng HL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2723, DOI 10.1109/ICCV48922.2021.00274
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tengteng Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P35, DOI 10.1007/978-3-030-58555-6_3
   Vora S, 2020, PROC CVPR IEEE, P4603, DOI 10.1109/CVPR42600.2020.00466
   Wang D., 2022, P 31 INT JOINT C ART, P3508, DOI DOI 10.24963/IJCAI.2022/487
   Wang DX, 2021, IEEE WCNC, DOI [10.1109/WCNC49053.2021.9417492, 10.1109/ICME51207.2021.9428187]
   Wang D, 2023, INFORM FUSION, V98, DOI 10.1016/j.inffus.2023.101828
   Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826
   Wang ZX, 2019, IEEE INT C INT ROBOT, P1742, DOI [10.1109/IROS40897.2019.8968513, 10.1109/iros40897.2019.8968513]
   Wu H, 2023, Arxiv, DOI arXiv:2303.02314
   Wu H, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3203163
   Wu XP, 2022, PROC CVPR IEEE, P5408, DOI 10.1109/CVPR52688.2022.00534
   Xu SQ, 2021, IEEE INT C INTELL TR, P3047, DOI 10.1109/ITSC48978.2021.9564951
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang HH, 2022, LECT NOTES COMPUT SC, V13668, P662, DOI 10.1007/978-3-031-20074-8_38
   Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161
   Yoo JH, 2020, SELECTED PAPERS FROM THE NINETEENTH BIENNIAL IEEE CONFERENCE ON ELECTROMAGNETIC FIELD COMPUTATION (IEEE CEFC 2020), DOI [10.1109/CEFC46938.2020.9451336, 10.1007/978-3-030-58583-9_43]
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zhang YF, 2023, Arxiv, DOI arXiv:2301.09077
   Zhang YF, 2022, PROC CVPR IEEE, P18931, DOI 10.1109/CVPR52688.2022.01838
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 48
TC 0
Z9 0
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2024
VL 142
AR 104895
DI 10.1016/j.imavis.2023.104895
EA DEC 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IJ5B0
UT WOS:001165959400001
DA 2024-07-18
ER

PT J
AU Shetab-Bushehri, M
   Aranda, M
   Özgüer, E
   Mezouar, Y
   Bartoli, A
AF Shetab-Bushehri, Mohammadreza
   Aranda, Miguel
   Ozgur, Erol
   Mezouar, Youcef
   Bartoli, Adrien
TI ROBUSfT: Robust real-time shape-from-template, a C plus plus library
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Monocular non-rigid reconstruction; Mismatch removal; SfT; Validation
   procedure; C plus plus library
ID SURFACE DETECTION; RECONSTRUCTION; REGISTRATION
AB Tracking the 3D shape of a deforming object using only monocular 2D vision is a challenging problem. This is because one should (i) infer the 3D shape from a 2D image, which is a severely underconstrained problem, and (ii) implement the whole solution pipeline in real time. The pipeline typically requires feature detection and matching, mismatch filtering, 3D shape inference and feature tracking algorithms. We propose ROBUSfT, a conventional pipeline based on a template containing the object's rest shape, texture map and deformation law. ROBUSfT is ready-to-use, wide-baseline, capable of handling large deformations, fast up to 30 fps, free of training, and robust against partial occlusions and discontinuities. It outperforms the state-of-the-art methods in challenging video datasets. ROBUSfT is implemented as a publicly available C++ library. We provide the code, a tutorial on how to use it, and a supplementary video of our experiments at https://github.com/mrsh etab/ROBUSfT.
C1 [Shetab-Bushehri, Mohammadreza; Ozgur, Erol; Mezouar, Youcef; Bartoli, Adrien] Univ Clermont Auvergne, Inst Pascal, CNRS, Clermont Auvergne INP, F-63000 Clermont Ferrand, France.
   [Aranda, Miguel] Univ Zaragoza, Inst Invest Ingn Aragon I3A, E-50018 Zaragoza, Spain.
C3 Universite Clermont Auvergne (UCA); Polytechnic Institute of Clermont
   Auvergne; Centre National de la Recherche Scientifique (CNRS);
   University of Zaragoza
RP Shetab-Bushehri, M (corresponding author), Univ Clermont Auvergne, Inst Pascal, CNRS, Clermont Auvergne INP, F-63000 Clermont Ferrand, France.
EM m.r.shetab@gmail.com
RI Aranda, Miguel/AAV-1773-2021
OI Aranda, Miguel/0000-0002-4556-7209
FU European Union [869855]; Maria Zambrano fellowship - Spanish Ministry of
   Universities; European Union-NextGenerationEU
FX This work was supported by project SOFTMANBOT, which received funding
   from the European Union's Horizon 2020 research and innovation programme
   under grant agreement No 869855. This work was also supported via a
   Maria Zambrano fellowship funded by the Spanish Ministry of Universities
   and by the European Union-NextGenerationEU.
CR Agarwal A, 2023, IEEE WINT CONF APPL, P5850, DOI 10.1109/WACV56688.2023.00581
   Agisoft, 2023, AGISOFT PHOTOSCAN
   Alexa, 2007, AS RIGID AS POSSIBLE
   [Anonymous], 2018, arXiv
   Aranda M, 2020, IEEE INT C INT ROBOT, P7542, DOI 10.1109/IROS45743.2020.9341646
   Bartoli A, 2015, IEEE T PATTERN ANAL, V37, P2099, DOI 10.1109/TPAMI.2015.2392759
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Brunet F, 2014, COMPUT VIS IMAGE UND, V125, P138, DOI 10.1016/j.cviu.2014.04.003
   Chhatkuli A, 2017, IEEE T PATTERN ANAL, V39, P833, DOI 10.1109/TPAMI.2016.2562622
   Chhatkuli A, 2014, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.2014.96
   Collins T., 2011, MED IM UND AN C
   Collins T., 2016, INT C MED IM COMP CO
   Collins T, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P116, DOI 10.1109/ISMAR.2015.35
   Collins T, 2014, LECT NOTES COMPUT SC, V8695, P138, DOI 10.1007/978-3-319-10584-0_10
   Ngo DT, 2016, IEEE T PATTERN ANAL, V38, P172, DOI 10.1109/TPAMI.2015.2435739
   Famouri M, 2018, MACH VISION APPL, V29, P73, DOI 10.1007/s00138-017-0876-9
   Frank B, 2014, ROBOT AUTON SYST, V62, P1153, DOI 10.1016/j.robot.2014.04.005
   Fuentes-Jimenez D, 2022, IMAGE VISION COMPUT, V127, DOI 10.1016/j.imavis.2022.104531
   Fuentes-Jimenez D, 2021, IEEE ACCESS, V9, P75211, DOI 10.1109/ACCESS.2021.3082011
   Golyanik V, 2018, LECT NOTES COMPUT SC, V11162, P51, DOI 10.1007/978-3-030-01790-3_4
   Griwodz C, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P415, DOI 10.1145/3204949.3208136
   Haouchine N, 2014, INT SYM MIX AUGMENT, P229, DOI 10.1109/ISMAR.2014.6948432
   Hu MX, 2009, LECT NOTES COMPUT SC, V5761, P34
   Kairanda N., 2022, IEEECVF C COMPUTER V
   Lamarca J, 2021, IEEE T ROBOT, V37, P291, DOI 10.1109/TRO.2020.3020739
   Lee J, 2019, PR MACH LEARN RES, V97
   Li YX, 2014, IEEE INT C INT ROBOT, P1046, DOI 10.1109/IROS.2014.6942687
   Liu C., 2023, IEEECVF C COMPUTER V
   Liu-Yin Q., 2017, ARXIV
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malti A., 2012, INT C INF PROC COMP
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Östlund J, 2012, LECT NOTES COMPUT SC, V7574, P412, DOI 10.1007/978-3-642-33712-3_30
   Özgür E, 2017, INT J COMPUT VISION, V123, P184, DOI 10.1007/s11263-016-0968-4
   Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8
   Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9
   Pizarro D, 2012, INT J COMPUT VISION, V97, P54, DOI 10.1007/s11263-011-0452-0
   Pumarola A, 2018, PROC CVPR IEEE, P4681, DOI 10.1109/CVPR.2018.00492
   Tran QH, 2012, LECT NOTES COMPUT SC, V7575, P274, DOI 10.1007/978-3-642-33765-9_20
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Salzmann M., 2008, EUROPEAN C COMPUTER
   Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158
   Salzmann M, 2009, PROC CVPR IEEE, P1054, DOI 10.1109/CVPRW.2009.5206759
   Shetab-Bushehri M, 2022, IEEE ROBOT AUTOM LET, V7, P3898, DOI 10.1109/LRA.2022.3145960
   Shimada S, 2019, IEEE COMPUT SOC CONF, P2876, DOI 10.1109/CVPRW.2019.00347
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tretschk E, 2023, COMPUT GRAPH FORUM, V42, P485, DOI 10.1111/cgf.14774
   Varol A, 2012, IEEE T PATTERN ANAL, V34, P1118, DOI 10.1109/TPAMI.2011.196
   Yuan WH, 2022, PROC CVPR IEEE, P3906, DOI 10.1109/CVPR52688.2022.00389
NR 50
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104867
DI 10.1016/j.imavis.2023.104867
EA DEC 2023
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CX8W9
UT WOS:001128633800001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Feng, HT
   Zhang, L
   Zhang, SQ
   Wang, D
   Yang, X
   Liu, ZY
AF Feng, Hangtao
   Zhang, Lu
   Zhang, Siqi
   Wang, Dong
   Yang, Xu
   Liu, Zhiyong
TI RTDOD: A large-scale RGB-thermal domain-incremental object detection
   dataset for UAVs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Domain -incremental object detection; Dataset; RGB-T dataset; Object
   detection dataset; UAVs dataset; Object detection
AB Recently, visual understanding using unmanned aerial vehicles (UAVs) has gained significant attention due to its wide range of applications, including delivery, security investigation and surveillance. However, most existing UAV-based datasets only capture color images under ideal illumination and weather conditions, typically sunny days. This limitation fails to account for the complexity of real-world scenarios, such as cloudy or foggy weather, and nighttime conditions. Deep learning methods trained on color images with good lighting and weather conditions struggle to adapt to the complex visual scenes in these scenarios. Moreover, color images may not provide sufficient visual information under the complex visual scenes. To bridge this gap and meet the demands of real-world applications, we propose a large-scale RGB-Thermal Domain-incremental Object Detection (RTDOD) dataset in this paper. Our dataset includes RGB and thermal videos synchronously captured using calibrated color thermal cameras mounted on UAVs. It covers various weather conditions, from sunny to foggy to rainy, and spans from day to night. We sample and obtain approximately 16,200 pairs of images, and manually label dense annotations, including object bounding boxes and object categories. With the proposed dataset, we introduce a challenging domain-incremental object detection task. We also present a baseline approach that uses task-related gates to filter features for knowledge distillation to reduce forgetting. Experimental results on the RTDOD dataset demonstrate the effectiveness of our proposed method in domain-incremental object detection. To facilitate future research and development in domain-incremental object detection tasks on aerial images, the RTDOD dataset and our baseline model are made available at https://github.com/fenght96/RTDOD. ARTICLE INFO.
C1 [Feng, Hangtao; Zhang, Lu; Zhang, Siqi; Yang, Xu; Liu, Zhiyong] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Feng, Hangtao; Zhang, Lu; Zhang, Siqi; Yang, Xu; Liu, Zhiyong] Chinese Acad Sci, Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing, Peoples R China.
   [Wang, Dong] Army Engn Univ PLA, Nanjing, Peoples R China.
   [Liu, Zhiyong] Nanjing Artificial Intelligence Res IA, Nanjing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Automation, CAS; Army
   Engineering University of PLA
RP Liu, ZY (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing, Peoples R China.
EM zhiyong.liu@ia.ac.cn
FU National Key Research and Development Plan of China [2020AAA0108902];
   Strategic Priority Research Program of Chinese Academy of Science
   [XDB32050100]
FX This work was supported in part by the National Key Research and
   Development Plan of China under Grant 2020AAA0108902 and in part by the
   Strategic Priority Research Program of Chinese Academy of Science under
   Grant XDB32050100.
CR Acharya M, 2020, Arxiv, DOI arXiv:2008.06439
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Busto PP, 2020, IEEE T PATTERN ANAL, V42, P413, DOI 10.1109/TPAMI.2018.2880750
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533
   Cui B, 2023, APPL INTELL, V53, P8864, DOI 10.1007/s10489-022-03509-0
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hao Y, 2019, IEEE INT CON MULTI, P1, DOI 10.1109/ICME.2019.00009
   Hinton G., 2015, COMPUT SCI, V2
   Hsieh MR, 2017, IEEE I CONF COMP VIS, P4165, DOI 10.1109/ICCV.2017.446
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu H., 2023, Image Vis. Comput, V130
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Otsu K, 2016, IEEE ROBOT AUTOM LET, V1, P814, DOI 10.1109/LRA.2016.2525040
   Peng C, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103229
   Radford A, 2021, PR MACH LEARN RES, V139
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rozantsev A, 2017, IEEE T PATTERN ANAL, V39, P879, DOI 10.1109/TPAMI.2016.2564408
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tong K, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104471
   Wang X, 2023, IMAGE VISION COMPUT, V135, DOI 10.1016/j.imavis.2023.104697
   Wei WY, 2023, IMAGE VISION COMPUT, V138, DOI 10.1016/j.imavis.2023.104792
   Wu Y., 2019, DETECTRON2
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Yang DB, 2020, Arxiv, DOI arXiv:2007.13428
   Yang DB, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472393
   Zhao ZP, 2023, IMAGE VISION COMPUT, V136, DOI 10.1016/j.imavis.2023.104715
   Zhu PF, 2018, Arxiv, DOI [arXiv:1804.07437, DOI 10.48550/ARXIV.1804.07437]
NR 39
TC 3
Z9 3
U1 6
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104856
DI 10.1016/j.imavis.2023.104856
EA NOV 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Y9XE4
UT WOS:001108709000001
DA 2024-07-18
ER

PT J
AU Al Jowair, H
   Alsulaiman, M
   Muhammad, G
AF Al Jowair, Hamdan
   Alsulaiman, Mansour
   Muhammad, Ghulam
TI Multi parallel U-net encoder network for effective polyp image
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Polyp; Medical image segmentation; Deep learning; Multi encoders; Skip
   connections
AB Automating polyps' detection and segmentation is very helpful in achieving early detection and potentially effective treatment of colon cancer. Because of the constant rise in processing power at a reasonable cost and the availability of training data, deep learning more than ever is becoming very powerful and increasingly wide-spread in many domains, including computer vision and medical image processing and segmentation. In this paper, we propose a novel method for polyp image segmentation using convolutional neural networks (CNNs) and utilizing multi-parallel U-Net encoder architecture. The proposed method uses multiple encoders that utilize pre-trained CNNs to enrich the extracted features. Skip connections from these parallel encoders are concate-nated and propagated to the decoder in partially and fully meshed fashions allowing for data from shallow to deeper layers in the network to be exchanged and vice versa. We trained and tested the method on five publicly available datasets: Kvasir, CVC-Clinic DB, CVC-Colon DB, CVC-T, and ETIS-Larib, which are well-known benchmark datasets for polyp image segmentation. We tested the performance of the method on these five datasets using multiple testing scenarios including the effect of using attention, vision transformers, and multiple decoders. Experimental results showed that the proposed method outperforms other state-of-the-art methods on two of the used benchmark datasets and ranked second on a third.
C1 [Al Jowair, Hamdan; Alsulaiman, Mansour; Muhammad, Ghulam] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh, Saudi Arabia.
C3 King Saud University
RP Alsulaiman, M; Muhammad, G (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh, Saudi Arabia.
EM msuliman@ksu.edu.sa; ghulam@ksu.edu.sa
RI Muhammad, Ghulam/H-5884-2011
FU King Saud University, Riyadh, Saudi Arabia [RSP2023R34]
FX The authors extend their appreciation to Researchers Supporting Project
   number (RSP2023R34) , King Saud University, Riyadh, Saudi Arabia.
CR Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Czipczer V, 2022, NEUROCOMPUTING, V505, P388, DOI 10.1016/j.neucom.2022.07.024
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Fang Y, 2019, INT C MEDICAL IMAGE
   Fitzgerald K, 2023, Arxiv, DOI arXiv:2302.01027
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gu WC, 2022, IMAGE VISION COMPUT, V120, DOI 10.1016/j.imavis.2022.104401
   Guo YB, 2020, J IMAGING, V6, DOI 10.3390/jimaging6070069
   Hatamizadeh A, 2022, IEEE WINT CONF APPL, P1748, DOI 10.1109/WACV51458.2022.00181
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Higgins WE, 2022, Arxiv, DOI arXiv:2207.07759
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C.-H., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2101.07172
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jha D., 2020 IEEE 33 INT S C
   Jha D., 2019, INT C MULTIMEDIA MOD
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Johansen D., 2020, IEEE 33 INT S COMPUT
   Lan P.N, 2021, INT S VISUAL COMPUTI
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Lou AE, 2022, Arxiv, DOI arXiv:2108.07368
   Moradi M, 2022, BIOMED OPT EXPRESS, V13, P2728, DOI 10.1364/BOE.449942
   An NS, 2022, IEEE ACCESS, V10, P43669, DOI 10.1109/ACCESS.2022.3168693
   Duc NT, 2022, IEEE ACCESS, V10, P80575, DOI 10.1109/ACCESS.2022.3195241
   Ronneberger O., 2015, 18 INT C
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava A, 2022, IEEE J BIOMED HEALTH, V26, P2252, DOI 10.1109/JBHI.2021.3138024
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang Y., 2021, arXiv, DOI DOI 10.48550/ARXIV.2111.14791
   Tomar N.K., 2021, INT WORKSHOP CHALLEN
   Vázquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Sang DV, 2022, Arxiv, DOI [arXiv:2105.00402, 10.48550/arXiv.2105.00402, DOI 10.48550/ARXIV.2105.00402]
   Woo S, 2018, Arxiv, DOI [arXiv:1807.06521, DOI 10.48550/ARXIV.1807.06521]
   Yan XY, 2022, IEEE WINT CONF APPL, P3270, DOI 10.1109/WACV51458.2022.00333
   Yang MQ, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.894970
   Yu Q., 2021, arXiv
   Zhang YF, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104042
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zoph B, 2018, Arxiv, DOI arXiv:1707.07012
NR 48
TC 8
Z9 8
U1 8
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104767
DI 10.1016/j.imavis.2023.104767
EA JUL 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P2GR2
UT WOS:001048880500001
DA 2024-07-18
ER

PT J
AU Raza, MA
   Chen, LF
   Nanbo, L
   Fisher, RB
AF Raza, Muhammad Ahmed
   Chen, Longfei
   Nanbo, Li
   Fisher, Robert B.
TI EatSense: Human centric, action recognition and localization dataset for
   understanding eating behaviors and quality of motion assessment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE EatSense; Eating vision dataset; Atomic -action recognition; Change in
   movement detection
ID CHALLENGES
AB Current datasets for computer vision-based action recognition and localization cover a wide range of classes and challenging scenarios. However, these datasets don't cater to healthcare applications that involve long-term monitoring, tracking minor changes in movements over time for healthcare purposes, or completely modeling a specific human behavior that includes multiple sub-actions. Specifically, there are no existing datasets for research on either health monitoring on atomic-action-based eating behavior or for a full range of eating subactions that fully segment the main action. Addressing these gaps is valuable for extending research on the health monitoring of elderly people and is needed for creating richer and more complete descriptions of actions. This paper introduces a new benchmark dataset named EatSense that targets both the computer vision and healthcare communities and fills in the aforementioned gaps. EatSense is recorded while a person eats in an uncontrolled dining setting. The key features of EatSense are the introduction of challenging atomic actions for action recognition, the significantly diverse durations of actions that make it difficult for current temporal action localization frameworks to localize, the capability to model comprehensive eating behavior in terms of a sequence of action-based behaviors, and the simulation of minor variations in motion or performance. We conduct extensive experiments on EatSense with baseline deep learning-based approaches for benchmarking and hand-crafted feature-based approaches for explainable applications. We believe this dataset will benefit future researchers in building robust temporal action localization networks, behavior recognition, and performance assessment models for eating.
C1 [Raza, Muhammad Ahmed; Chen, Longfei; Nanbo, Li; Fisher, Robert B.] Univ Edinburgh, Sch Informat, Edinburgh EH8 9AB, Scotland.
C3 University of Edinburgh
RP Raza, MA (corresponding author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9AB, Scotland.
EM m.a.raza@ed.ac.uk; lchen11@ed.ac.uk; nanbo.li@ed.ac.uk; rbf@inf.ed.ac.uk
OI Raza, Muhammad Ahmed/0000-0003-4477-7375
CR Alwassel Humam, 2020, TSP TEMPORALLY SENSI
   [Anonymous], 2016, INT C MULT MOD
   Bertasius G, 2017, IEEE I CONF COMP VIS, P2196, DOI 10.1109/ICCV.2017.239
   Bi SJ, 2022, IEEE INT CONF HEALT, P60, DOI 10.1109/ICHI54592.2022.00021
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carreira J, 2019, Arxiv, DOI arXiv:1907.06987
   Chen YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13339, DOI 10.1109/ICCV48922.2021.01311
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Curto E, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197378
   Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44
   Duan HD, 2022, PROC CVPR IEEE, P2959, DOI 10.1109/CVPR52688.2022.00298
   Dutta A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2276, DOI 10.1145/3343031.3350535
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   Gul MA, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9121993
   Hoover A., DATA DESCRIPTION CLE
   Iosifidis A., 2015, Journal of Information Hiding and Multimedia Signal Processing, V6, P254
   Ishikawa S, 2013, 2013 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P300, DOI 10.1109/SII.2013.6776731
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Ke GL, 2017, ADV NEUR IN, V30
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kyritsis K, 2019, IEEE J BIOMED HEALTH, V23, P2325, DOI 10.1109/JBHI.2019.2892011
   Lei Z, 2022, IEEE ROBOT AUTOM LET, V7, P8893, DOI 10.1109/LRA.2022.3189151
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Liu CH, 2017, Arxiv, DOI arXiv:1703.07475
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13688, DOI 10.1109/ICCV48922.2021.01345
   Makihara Yasushi, 2020, COMPUTER VISION REFE, P1, DOI DOI 10.1007/978-3-030-03243-2_883-1
   Men QH, 2019, WORLD WIDE WEB, V22, P1343, DOI 10.1007/s11280-018-0567-0
   Merck C.A., 2016, P PERV CANC MEX 1619, P130, DOI [DOI 10.4108/EAI.16-5-2016.2263281, 10.4108/eai.16-5-2016.2263281]
   Moro M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22052011
   Neves PA, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176443
   Onofri L, 2016, EXPERT SYST APPL, V63, P97, DOI 10.1016/j.eswa.2016.06.011
   Ortells J, 2018, MED BIOL ENG COMPUT, V56, P1553, DOI 10.1007/s11517-018-1795-2
   Paiement Adeline., 2014, British Machine Vision Conference, P153
   Rondinelli RD, 1997, ARCH PHYS MED REHAB, V78, P1358, DOI 10.1016/S0003-9993(97)90310-5
   Rouast PV, 2020, IEEE ACCESS, V8, P181955, DOI 10.1109/ACCESS.2020.3026965
   Sethi D, 2022, ARTIF INTELL MED, V129, DOI 10.1016/j.artmed.2022.102314
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shaikh MB, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124246
   Shao D, 2020, PROC CVPR IEEE, P2613, DOI 10.1109/CVPR42600.2020.00269
   Sharma S, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9020070
   Shen YR, 2017, IEEE J BIOMED HEALTH, V21, P599, DOI 10.1109/JBHI.2016.2612580
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sun Y, 2018, IET COMPUT VIS, V12, P686, DOI 10.1049/iet-cvi.2017.0429
   Sun ZH, 2023, IEEE T PATTERN ANAL, V45, P3200, DOI 10.1109/TPAMI.2022.3183112
   Tang ZY, 2022, INT C PATT RECOG, P4399, DOI 10.1109/ICPR56361.2022.9956550
   Tao L, 2015, 2015 17TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATION & SERVICES (HEALTHCOM), P644, DOI 10.1109/HealthCom.2015.7454583
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Nguyen TN, 2018, IEEE ACCESS, V6, P38106, DOI 10.1109/ACCESS.2018.2854262
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang LA, 2010, IEEE T SYST MAN CY B, V40, P982, DOI 10.1109/TSMCB.2010.2046351
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Woznowski PR, 2016, IOTBD: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND BIG DATA, P369, DOI 10.5220/0005932503690377
   Xu JL, 2022, PROC CVPR IEEE, P2939, DOI 10.1109/CVPR52688.2022.00296
   Xu LM, 2021, PROC CVPR IEEE, P16067, DOI 10.1109/CVPR46437.2021.01581
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   Zhang CL, 2022, LECT NOTES COMPUT SC, V13664, P492, DOI 10.1007/978-3-031-19772-7_29
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
NR 69
TC 1
Z9 1
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104762
DI 10.1016/j.imavis.2023.104762
EA JUL 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P2SE0
UT WOS:001049180800001
OA Green Published, Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Niu, T
   Teng, YL
   Jin, L
   Zou, PP
   Liu, YD
AF Niu, Tao
   Teng, Yinglei
   Jin, Lei
   Zou, Panpan
   Liu, Yiding
TI Pruning-and-distillation: One-stage joint compression framework for CNNs
   via clustering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Filter pruning; Clustering; Knowledge distillation; Deep neural networks
ID NEURAL-NETWORKS
AB Network pruning and knowledge distillation, as two effective network compression techniques, have drawn extensive attention due to their success in reducing model complexity. However, previous works regard them as two independent methods and combine them in an isolated manner rather than joint, leading to a sub-optimal optimization. In this paper, we propose a collaborative compression scheme named Pruningand-Distillation via Clustering (PDC), which integrates pruning and distillation into an end-to-end single-stage framework that takes both advantages of them. Specifically, instead of directly deleting or zeroing out unimportant filters within each layer, we reconstruct them based on clustering, which preserves the learned features as much as possible. The guidance from the teacher is integrated into the pruning process to further improve the generalization of pruned model, which alleviates the randomness caused by reconstruction to some extent. After convergence, we can equivalently remove reconstructed filters within each cluster through the proposed channel addition operation. Benefiting from such equivalence, we no longer require the time-consuming finetuning step to regain accuracy. Extensive experiments on CIFAR-10/100 and ImageNet datasets show that our method achieves the best trade-off between performance and complexity compared with other state-of-theart algorithms. For example, for ResNet-110, we achieve a 61.5% FLOPs reduction with even 0.14% top-1 accuracy increase on CIFAR-10 and remove 55.2% FLOPs with only 0.32% accuracy drop on CIFAR-100. & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Niu, Tao; Teng, Yinglei; Jin, Lei; Zou, Panpan; Liu, Yiding] Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Teng, YL (corresponding author), Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
EM lilytengtt@gmail.com
FU National Key Ramp;D Program of China [2021YFB3300100]; National Natural
   Science Foundation of China [62171062]
FX * This work was supported in part by the National Key R&D Program of
   China (No. 2021YFB3300100) and the National Natural Science Foundation
   of China (No. 62171062) .
CR Aflalo Y, 2020, Arxiv, DOI arXiv:2002.08258
   Ba LJ, 2014, ADV NEUR IN, V27
   Cai LH, 2021, INT C PATT RECOG, P224, DOI 10.1109/ICPR48806.2021.9412993
   Cai Linhang, 2021, 2021 INT JOINT C NEU, P1
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen Liyang, 2021, Complex & Intelligent Systems, P1
   Chen PG, 2021, PROC CVPR IEEE, P5006, DOI 10.1109/CVPR46437.2021.00497
   Chen Y., 2015, THESIS
   Chu Y, 2022, APPL INTELL, V52, P16246, DOI 10.1007/s10489-022-03293-x
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Courbariaux M, 2015, ADV NEUR IN, V28
   Denton E, 2014, Arxiv, DOI arXiv:1404.0736
   Ding XH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4490, DOI 10.1109/ICCV48922.2021.00447
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Guo Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5219, DOI 10.1109/ICCV48922.2021.00519
   Han  S., 2015, ARXIV151000149
   Han S, 2015, Arxiv, DOI arXiv:1506.02626
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, arXiv
   He Y, 2020, PROC CVPR IEEE, P2006, DOI 10.1109/CVPR42600.2020.00208
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   He Y, 2020, IEEE T CYBERNETICS, V50, P3594, DOI 10.1109/TCYB.2019.2933477
   He Yang, 2022, IEEE Transactions on Neural Networks and Learning Systems
   Heo B, 2019, AAAI CONF ARTIF INTE, P3779
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Hu HY, 2016, Arxiv, DOI arXiv:1607.03250
   Huang ZH, 2018, LECT NOTES COMPUT SC, V11220, P317, DOI 10.1007/978-3-030-01270-0_19
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Ji M, 2021, AAAI CONF ARTIF INTE, V35, P7945
   Jia FW, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104192
   Jia FW, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104143
   Kim YD, 2016, Arxiv, DOI [arXiv:1511.06530, 10.48550/arXiv.1511.06530]
   Krizhevsky A., 2009, Tech. Rep.
   Kumar A, 2021, APPL INTELL, V51, P1152, DOI 10.1007/s10489-020-01894-y
   LeCun Y., 1989, ADV NEURAL INFORM PR, VVolume 2
   Li CX, 2018, INT C PATT RECOG, P2785, DOI 10.1109/ICPR.2018.8545028
   Li H, 2017, Arxiv, DOI arXiv:1608.08710
   Li Yawei, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, P8018
   Li YC, 2021, PROC CVPR IEEE, P6434, DOI 10.1109/CVPR46437.2021.00637
   Lin MB, 2020, Arxiv, DOI arXiv:2001.08565
   Lin MB, 2022, IEEE T NEUR NET LEAR, V33, P7091, DOI 10.1109/TNNLS.2021.3084206
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Lin SH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2425
   Lin SH, 2019, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR.2019.00290
   Lin TY, 2015, Arxiv, DOI [arXiv:1405.0312, DOI 10.48550/ARXIV.1405.0312]
   Liu J, 2022, IEEE T PATTERN ANAL, V44, P4035, DOI 10.1109/TPAMI.2021.3066410
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339, 10.1109/ICCV.2019.00339D\]
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   MacQueen J, 1967, P 5 BERKELEY S MATH, V1
   Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191
   Molchanov Pavlo, 2017, ARXIV
   Nonnenmacher M, 2022, Arxiv, DOI arXiv:2110.11395
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romero A, 2015, Arxiv, DOI arXiv:1412.6550
   Rong JT, 2020, IEEE IND ELEC, P5343, DOI [10.1109/iecon43393.2020.9254493, 10.1109/IECON43393.2020.9254493]
   RoyChowdhury Aruni, 2018, REDUCING DUPLICATE F
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabih M, 2022, PROCEEDINGS OF THE 2022 2ND EUROPEAN WORKSHOP ON MACHINE LEARNING AND SYSTEMS (EUROMLSYS '22), P109, DOI 10.1145/3517207.3526982
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.15751
   Singh P, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103857
   Sui Yang, 2021, Advances in Neural Information Processing Systems, V34
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tang YH, 2021, Arxiv, DOI arXiv:2010.10732
   Tian Y., 2019, ARXIV
   Tung F, 2019, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2019.00145
   Wang Zhenyu, 2022, IEEE Transactions on Circuits and Systems for Video Technology
   Wen W, 2016, Arxiv, DOI arXiv:1608.03665
   Xiao X, 2019, ADV NEUR IN, V32
   Yawei Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8015, DOI 10.1109/CVPR42600.2020.00804
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1612.03928
   Zhang GQ, 2022, APPL INTELL, V52, P9274, DOI 10.1007/s10489-021-02907-0
   Zhang Yuyao, 2023, IEEE Transactions on Neural Networks and Learning Systems
   Zhao CL, 2019, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2019.00289
   Zhuang Tao, 2020, Neural Information Processing Systems
   Zhuang ZW, 2018, ADV NEUR IN, V31
NR 78
TC 1
Z9 1
U1 9
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104743
DI 10.1016/j.imavis.2023.104743
EA JUL 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N8FI8
UT WOS:001039304700001
DA 2024-07-18
ER

PT J
AU Pu, YN
   Sun, J
   Tang, NS
   Xu, ZB
AF Pu, Yannan
   Sun, Jian
   Tang, Niansheng
   Xu, Zongben
TI Deep expectation-maximization network for unsupervised image
   segmentation and clustering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep clustering; EM algorithm; Image clustering; Representation
   learning; Unsupervised image segmentation
ID ALGORITHM; MODEL
AB Unsupervised learning, such as unsupervised image segmentation and clustering, are fundamental tasks in image representation learning. In this paper, we design a deep expectation-maximization (DEM) network for unsuper-vised image segmentation and clustering. It is based on the statistical modeling of image in its latent feature space by Gaussian mixture model (GMM), implemented in a novel deep learning framework. Specifically, in the unsu-pervised setting, we design an auto-encoder network and an EM module over the image latent features, for jointly learning the image latent features and GMM model of the latent features in a single framework. To con-struct the EM-module, we unfold the iterative operations of EM algorithm and the online EM algorithm in fixed steps to be differentiable network blocks, plugged into the network to estimate the GMM parameters of the image latent features. The proposed network parameters can be end-to-end optimized using losses based on log-likelihood of GMM, entropy of Gaussian component assignment probabilities and image reconstruction error. Extensive experiments confirm that our proposed networks achieve favorable results compared with sev-eral state-of-the-art methods in unsupervised image segmentation and clustering.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Pu, Yannan; Tang, Niansheng] Key Lab Stat Modeling & Data Anal Yunnan Prov, Kunming, Peoples R China.
   [Sun, Jian; Xu, Zongben] Xi An Jiao Tong Univ, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Sun, J (corresponding author), Xi An Jiao Tong Univ, Xian, Peoples R China.
EM puyannan123@mail.ynu.edu.cn; jiansun@xjtu.edu.cn; nstang@ynu.edu.cn;
   zbxu@xjtu.edu.cn
FU National Natural Science Foundation of China [U20B2075, 12271472,
   12125104, 61721002]
FX This research was supported by the National Natural Science Foundation
   of China (U20B2075, 12271472, 12125104, 61721002) .
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Cai J., 2022, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P1
   Cai JY, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108386
   Cappé O, 2009, J ROY STAT SOC B, V71, P593, DOI 10.1111/j.1467-9868.2009.00698.x
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen X., 2011, 25 AAAI C ART INT, P1010
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cho Jae Won, 2021, P IEEE CVF C COMP VI
   Coates Adam, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P561, DOI 10.1007/978-3-642-35289-8_30
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dizaji KG, 2017, IEEE I CONF COMP VIS, P5747, DOI 10.1109/ICCV.2017.612
   Do K., 2021, P IEEECVF INT C COMP, P9928
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Foggia P, 2009, IMAGE VISION COMPUT, V27, P979, DOI 10.1016/j.imavis.2008.05.002
   Guo XF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1753
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2020, IEEE T GEOSCI REMOTE, V58, P3791, DOI 10.1109/TGRS.2019.2957251
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Huang J., 2020, P IEEE CVF C COMP VI, P8849, DOI DOI 10.1109/CVPR42600.2020.00887
   ISPRS, ISPRS 2D semantic labeling contest-potsdam
   Jabi M, 2021, IEEE T PATTERN ANAL, V43, P1887, DOI 10.1109/TPAMI.2019.2962683
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Ji X, 2019, IEEE I CONF COMP VIS, P9864, DOI 10.1109/ICCV.2019.00996
   Jiang ZX, 2017, Arxiv, DOI arXiv:1611.05148
   Kanezaki A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1543, DOI 10.1109/ICASSP.2018.8462533
   KASS RE, 1995, J AM STAT ASSOC, V90, P928, DOI 10.2307/2291327
   Khan Z, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2020.103871
   Kim B, 2020, IEEE T IMAGE PROCESS, V29, P1856, DOI 10.1109/TIP.2019.2941265
   Kim W, 2020, IEEE T IMAGE PROCESS, V29, P8055, DOI 10.1109/TIP.2020.3011269
   Kingma D. P., 2014, arXiv
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma ZY, 2019, IEEE T NEUR NET LEAR, V30, P449, DOI 10.1109/TNNLS.2018.2844399
   Meila M., 2005, P 22 INT C MACH LEAR, P577, DOI DOI 10.1145/1102351.1102424
   Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Pelleg D., 2000, P 17 INT C MACH LEAR, DOI DOI 10.1007/3-540-44491-2_3
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tang C, 2022, IEEE T KNOWL DATA EN, V34, P4705, DOI 10.1109/TKDE.2020.3048678
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Theis L, 2017, Arxiv, DOI [arXiv:1703.00395, DOI 10.48550/ARXIV.1703.00395]
   Tian F, 2014, AAAI CONF ARTIF INTE, P1293
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Gansbeke Wouter, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P268, DOI 10.1007/978-3-030-58607-2_16
   Wilder B., 2019, NEURAL INFORM PROCES
   Wu JL, 2019, IEEE I CONF COMP VIS, P8149, DOI 10.1109/ICCV.2019.00824
   Wu X, 2023, IEEE T IMAGE PROCESS, V32, P364, DOI 10.1109/TIP.2022.3228497
   Xia XD, 2017, Arxiv, DOI arXiv:1711.08506
   Xie JY, 2016, PR MACH LEARN RES, V48
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Xu ZB, 2018, NATL SCI REV, V5, P22, DOI 10.1093/nsr/nwx099
   Yang B, 2017, PR MACH LEARN RES, V70
   Yang X, 2019, PROC CVPR IEEE, P4061, DOI 10.1109/CVPR.2019.00419
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zhou Q, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104137
NR 61
TC 3
Z9 3
U1 8
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104717
DI 10.1016/j.imavis.2023.104717
EA JUN 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA K1AZ7
UT WOS:001013853900001
DA 2024-07-18
ER

PT J
AU Ta, N
   Chen, HP
   Lyu, Y
   Wang, X
   Shi, ZA
   Liu, ZH
AF Ta, Na
   Chen, Haipeng
   Lyu, Yingda
   Wang, Xue
   Shi, Zenan
   Liu, Zhehao
TI A complementary and contrastive network for stimulus segmentation and
   generalization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Complementary feature; Contrastive feature; Mutual attention; Synthetic
   data augmentation; Medical image segmentation
ID ATTENTION; CONTEXT
AB Existing convolutional neural networks (CNNs) have achieved remarkable performance in medical image segmentation tasks. However, they still fail to generalize well to unseen datasets due to the limited size and diversity of training data as well as distribution shifts. Meanwhile, CNN-based methods have inherent limi-tations in capturing global contexts and suffer semantic dilution issues in the decoder stage, which leads to sub-optimal predictions especially under low inter-class discrepancy and complex backgrounds. In this paper, we propose a novel framework named CCNet that learns complementary and contrastive features for accurate seg-mentation. Firstly, a novel complementary feature extraction module is formulated to learn global-local features by coordinating Transformer and CNN-style parallel branches. Secondly, a global context refinement module is constructed to adaptively generate a set of layer-specific global maps, so as to remedy semantic dilution. Thirdly, a mutual attentive module is designed to alleviate background confusion, in which contrastive cues are mutually captured from the foreground and background view by cascaded dual attention blocks. Moreover, we implement synthetic data augmentation to deal with training data scarcity and distribution shifts, thereby improving the out-of-distribution generalization of our model. Extensive experiments demonstrate that our CCNet achieves outstanding performance in polyp, skin lesion, and nuclei segmentation tasks, outperforming the state-of-the-arts. & COPY; 2023 Published by Elsevier B.V.
C1 [Ta, Na; Chen, Haipeng; Wang, Xue; Shi, Zenan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Ta, Na] Hulunbuir Univ, Coll Comp, Hulunbuir 021008, Peoples R China.
   [Ta, Na; Chen, Haipeng; Wang, Xue; Shi, Zenan] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Lyu, Yingda] Jilin Univ, Publ Comp Educ & Res Ctr, Changchun 130012, Peoples R China.
   [Liu, Zhehao] Jilin Univ, Software Coll, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University
RP Lyu, Y (corresponding author), Jilin Univ, Publ Comp Educ & Res Ctr, Changchun 130012, Peoples R China.
EM ydlv@jlu.edu.cn
FU National Natural Science Foundation of China [62276112]; National
   Natural Science Foundation of China Regional Joint Fund of NSFC
   [U19A2057]; Jilin University "Interdisciplinary Integration and
   Innovation " Young Scholars Free Exploration Project [2020FDZC01];
   Science and Technology Research Project of Hulunbuir University
   [202110183229]; National Innovation and Entrepreneurship Training
   Project for University [GXXT-2021 -008]; Anhui University Collaborative
   Innovation Project Subproject;  [JLUXKJC2021QZ01]
FX This research is supported by the National Natural Science Foundation of
   China (62276112) , the National Natural Science Foundation of China
   Regional Joint Fund of NSFC (U19A2057) , Anhui University Collaborative
   Innovation Project Subproject (GXXT-2021 -008) , Jilin University
   "Interdisciplinary Integration and Innovation " Young Scholars Free
   Exploration Project (JLUXKJC2021QZ01) , Science and Technology Research
   Project of Hulunbuir University (2020FDZC01) , and National Innovation
   and Entrepreneurship Training Project for University (202110183229) .
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   Azad R, 2019, IEEE INT CONF COMP V, P406, DOI 10.1109/ICCVW.2019.00052
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bissoto A, 2021, IEEE COMPUT SOC CONF, P1847, DOI 10.1109/CVPRW53098.2021.00204
   Caicedo JC, 2019, NAT METHODS, V16, P1247, DOI 10.1038/s41592-019-0612-7
   Changqian Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12413, DOI 10.1109/CVPR42600.2020.01243
   Chen C, 2022, LECT NOTES COMPUT SC, V13435, P151, DOI 10.1007/978-3-031-16443-9_15
   Codella N., 2018 IEEE 15 INT S B
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Duy Khang Nguyen, 2020, 2020 5th International Conference on Green Technology and Sustainable Development (GTSD), P366, DOI 10.1109/GTSD50082.2020.9303084
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gao SY, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1495, DOI 10.1109/ICASSP39728.2021.9413702
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hu HG, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108452
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Li YY, 2023, VISUAL COMPUT, V39, P2223, DOI 10.1007/s00371-021-02328-7
   Li Z, 2021, IEEE T IMAGE PROCESS, V30, P4587, DOI 10.1109/TIP.2021.3072811
   Liang YH, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104352
   Liu B., 2020, INT C LEARNING REPRE
   Liu NA, 2020, IEEE T IMAGE PROCESS, V29, P6438, DOI 10.1109/TIP.2020.2988568
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ning ZY, 2022, IEEE T MED IMAGING, V41, P476, DOI 10.1109/TMI.2021.3116087
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/CRV52889.2021.00032, 10.1109/crv52889.2021.00032]
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Shang XD, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P279, DOI 10.1145/3323873.3325056
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Srivastava A, 2022, IEEE J BIOMED HEALTH, V26, P2252, DOI 10.1109/JBHI.2021.3138024
   Sun Jesse, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P797, DOI 10.1007/978-3-030-59719-1_77
   Ta N, 2023, MULTIMEDIA SYST, V29, P3041, DOI 10.1007/s00530-022-00900-2
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Nguyen TC, 2021, LECT NOTES COMPUT SC, V12901, P633, DOI 10.1007/978-3-030-87193-2_60
   Tang Q, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104309
   Tomar NK, 2023, IEEE T NEUR NET LEAR, V34, P9375, DOI 10.1109/TNNLS.2022.3159394
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Valanarasu Jeya Maria Jose, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P363, DOI 10.1007/978-3-030-59719-1_36
   Vázquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang K, 2021, LECT NOTES COMPUT SC, V12901, P471, DOI 10.1007/978-3-030-87193-2_45
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Xupeng, 2021, NEUROCOMPUTING
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu HS, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102327
   Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39
   Xu Xuanang, 2020, Med Image Comput Comput Assist Interv, V12264, P470, DOI 10.1007/978-3-030-59719-1_46
   Yang X, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1939, DOI 10.1145/3394171.3413610
   Yin ZJ, 2022, Arxiv, DOI arXiv:2103.06725
   Yu Q., 2021, arXiv
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 67
TC 0
Z9 0
U1 7
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104694
DI 10.1016/j.imavis.2023.104694
EA MAY 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA K2LN5
UT WOS:001014807400001
DA 2024-07-18
ER

PT J
AU Zheng, ZW
   Hu, ZX
   Qin, H
   Liu, J
AF Zheng, Zhiwei
   Hu, Zhongxu
   Qin, Hui
   Liu, Jie
TI Stacked graph bone region U-net with bone representation for hand pose
   estimation and semi-supervised training
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D hand pose estimation; 2D-to-3D; Deep learning; Graph convolution;
   Semi -supervised training
AB 3D hand estimation from 2D joint information is an essential task in human-machine interaction, which has achieved great progress as an application of deep learning. However, regression-based methods do not perform well because the structural information is not effectively exploited, and the joint coordinates are variable. To ad-dress these issues, the hand pose is represented with bone vectors instead of joint coordinates in this study, which are stabler to learn and allow for easier encoding of the hand geometric structure and joint dependency. A novel graph bone region U-Net is specifically designed for bone representation to learn multiscale structural features, where the proposed novel elements (graph convolution, pooling and unpooling) incorporate hand structural knowledge. Under the introduced "finger-to-hand" framework, the network gradually decreases the scale from bone to finger to hand for learning more meaningful multiscale features. Moreover, the unit network is stacked repeatedly to extract multilevel features. Based on the above network, a simple but effective semi -supervised approach is introduced to address the lack of 3D hand pose labels. Many experiments are conducted to evaluate the proposed approach on two challenging datasets. The experimental results show that the proposed supervised approach outperforms the state-of-the-art methods, and the proposed semi-supervised approach can still achieve favorable performance when the labeled data are scarce.(c) 2023 Published by Elsevier B.V.
C1 [Zheng, Zhiwei] Huazhong Univ Sci & Technol, Sch Arti fi cial Itelligence & Automation, Wuhan, Peoples R China.
   [Hu, Zhongxu] Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore, Singapore.
   [Qin, Hui; Liu, Jie] Huazhong Univ Sci & Technol, Sch Civil & Hydraul Engn, Wuhan, Peoples R China.
C3 Huazhong University of Science & Technology; Nanyang Technological
   University; Huazhong University of Science & Technology
RP Qin, H (corresponding author), Huazhong Univ Sci & Technol, Sch Civil & Hydraul Engn, Wuhan, Peoples R China.
EM zhiweizheng@hust.edu.cn; zhongxu.hu@ntu.edu.sg; hqin@hust.edu.cn;
   jie_liu@hust.edu.cn
RI zheng, zhiwei/KCJ-9060-2024; Hu, Zhongxu/AAH-3982-2020
OI Hu, Zhongxu/0000-0001-8236-7903
FU National Key Research and Develop- ment Program of China
   [2021YFC3200303]; National Natural Sci- ence Foundation of China
   [51979113, 52039004, U1865202]
FX This work is supported by the National Key Research and Develop- ment
   Program of China (2021YFC3200303) and National Natural Sci- ence
   Foundation of China (No. 51979113, 52039004, U1865202) , and special
   thanks are given to the anonymous reviewers and editors for their
   constructive comments.
CR Atwood J, 2016, ADV NEUR IN, V29
   Baek S, 2020, PROC CVPR IEEE, P6120, DOI 10.1109/CVPR42600.2020.00616
   Bresson X, 2018, Arxiv, DOI [arXiv:1711.07553, DOI 10.48550/ARXIV.1711.07553]
   Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236
   Chen L., P IEEE CVF WINT C AP, P411
   Ci H, 2019, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2019.00235
   Defferrard M, 2016, ADV NEUR IN, V29
   Doosti B, 2020, PROC CVPR IEEE, P6607, DOI 10.1109/CVPR42600.2020.00664
   Drover D, 2019, LECT NOTES COMPUT SC, V11132, P78, DOI 10.1007/978-3-030-11018-5_7
   Duvenaudt D, 2015, ADV NEUR IN, V28
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Gao HY, 2019, PR MACH LEARN RES, V97
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Ge LH, 2019, PROC CVPR IEEE, P10825, DOI 10.1109/CVPR.2019.01109
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Iqbal U, 2018, LECT NOTES COMPUT SC, V11215, P125, DOI 10.1007/978-3-030-01252-6_8
   Khaleghi L., 2022, Learning sequential contexts using transformer for 3d hand pose estimation
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Levie R, 2019, IEEE T SIGNAL PROCES, V67, P97, DOI 10.1109/TSP.2018.2879624
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li MR, 2021, AAAI CONF ARTIF INTE, V35, P1921
   Li RY, 2018, AAAI CONF ARTIF INTE, P3546
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Panteleris P, 2018, IEEE WINT CONF APPL, P436, DOI 10.1109/WACV.2018.00054
   Park S, 2016, LECT NOTES COMPUT SC, V9915, P156, DOI 10.1007/978-3-319-49409-8_15
   Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Spurr A, 2018, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2018.00017
   Tekin B., P IEEE CVF C COMP VI, P4511
   Theodoridis T., P IEEE CVF C COMP VI, P960
   Tung HYF, 2017, IEEE I CONF COMP VIS, P4364, DOI 10.1109/ICCV.2017.467
   Wandt Bastian, 2018, P EUR C COMP VIS ECC, P0
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang John, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P122, DOI 10.1007/978-3-030-58610-2_8
   Yang LL, 2019, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2019.00242
   Yang LL, 2019, PROC CVPR IEEE, P9869, DOI 10.1109/CVPR.2019.01011
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Zhang JW, 2016, Arxiv, DOI arXiv:1610.07214
   Zhang JW, 2017, IEEE IMAGE PROC, P982, DOI 10.1109/ICIP.2017.8296428
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zhao W., 2022, P IEEECVF C COMPUTER, P20438
   Zhuang N., P 2021 INT C MULT RE, P420
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 49
TC 0
Z9 0
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2023
VL 134
AR 104673
DI 10.1016/j.imavis.2023.104673
EA APR 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA G5SW0
UT WOS:000989762800001
DA 2024-07-18
ER

PT J
AU Zhang, JW
   Wang, JC
   Zhang, HL
   Miao, ME
   Zhang, J
   Wu, D
AF Zhang, Jianwei
   Wang, Jingchao
   Zhang, Huanlong
   Miao, Mengen
   Zhang, Jie
   Wu, Di
TI Exploiting spatial and temporal context for online tracking with
   improved transformer
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Classification and regression network; Spatial and
   temporal context; Transformer
ID VISUAL TRACKING
AB At present, the transformer is becoming more and more popular in computer vision tasks due to its ability to capture long-range dependencies via self-attention. In this paper, we propose a transformer-based classification regression network TrCAR utilizing the transformer to exploit deeper spatial and temporal context. Different from the classic architecture of the transformer, we introduce convolution operation into the transformer and change the calculation of features to make it suitable for the tracking task. After that, the improved transformer encoder is introduced into the regression branch of TrCAR and combined with the feature pyramid to complete multi-layer feature fusion, which is conducive to obtaining a high-quality target representation. To further enable the target model to adapt to the change of the target appearance, we bring the gradient descent to the regression branch so that it can be updated online to produce a more precise bounding box. Meanwhile, the new transformer is integrated into the classification branch of TrCAR, which as much as possible extracts the essential feature of the target across historical frames via the global computing capability, and uses it to emphasize the target position of the current frame via cross-attention. Which helps the classifier to more easily identify the correct target. Experimental results on OTB, LaSOT, VOT2018, NFS, GOT-10k, and TrackingNet benchmarks show that our TrCAR achieves comparable performance to the popular trackers.
C1 [Zhang, Jianwei; Wang, Jingchao; Miao, Mengen] Zhengzhou Univ Light Ind, Coll Software Engn, Zhengzhou 475000, Peoples R China.
   [Zhang, Huanlong; Zhang, Jie] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Zhengzhou 475000, Peoples R China.
   [Wu, Di] Yellow River Engn Consulting Co Ltd, Zhengzhou 450003, Peoples R China.
C3 Zhengzhou University of Light Industry; Zhengzhou University of Light
   Industry; Yellow River Engineering Consulting Co., Ltd.
RP Zhang, HL (corresponding author), Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Zhengzhou 475000, Peoples R China.
EM zzuli407@163.com
FU National Natural Science Foundation of China [62072416, 61873246,
   62102373]; Program for Science & Technology Innovation Talents in
   Universities of Henan Province [21HASTIT028]; Zhongyuan Science and
   Technology Innovation Leader- ship Program [214200510026]; Natural
   Science Foundation of Henan Province [202300410495]; Ministry of Public
   Security Technology Research Project of China [2019JSYJC25]
FX This work is supported by the National Natural Science Foundation of
   China (62072416, 61873246, 62102373) , Program for Science & Technology
   Innovation Talents in Universities of Henan Province (21HASTIT028) ,
   Zhongyuan Science and Technology Innovation Leader- ship Program
   (214200510026) , Natural Science Foundation of Henan Province
   (202300410495) and Ministry of Public Security Technology Research
   Project of China (No. 2019JSYJC25) .
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P205, DOI 10.1007/978-3-030-58592-1_13
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Cui Y., 2020, arXiv
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fu ZH, 2021, PROC CVPR IEEE, P13769, DOI 10.1109/CVPR46437.2021.01356
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Guo DY, 2021, PROC CVPR IEEE, P9538, DOI 10.1109/CVPR46437.2021.00942
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Han WC, 2021, PROC CVPR IEEE, P16565, DOI 10.1109/CVPR46437.2021.01630
   Han ZJ, 2020, IEEE T CIRC SYST VID, V30, P155, DOI 10.1109/TCSVT.2018.2888492
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kristan M., 2018, P EUR C COMP VIS ECC, P0
   Li B, 2019, IEEE T IMAGE PROCESS, V28, P3624, DOI 10.1109/TIP.2019.2900577
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lukezic A, 2020, PROC CVPR IEEE, P7131, DOI 10.1109/CVPR42600.2020.00716
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Nousi P, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103933
   Radford A., 2019, LANGUAGE MODELS ARE
   Shen JB, 2022, IEEE T PATTERN ANAL, V44, P8896, DOI 10.1109/TPAMI.2021.3127492
   Synnaeve G, 2020, Arxiv, DOI arXiv:1911.08460
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang HS, 2021, OPTOELECTRON LETT, V17, P241, DOI 10.1007/s11801-021-0073-y
   Wang N, 2021, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR46437.2021.00162
   Wu HP, 2021, Arxiv, DOI [arXiv:2103.15808, DOI 10.48550/ARXIV.2103.15808]
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xingping Dong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P378, DOI 10.1007/978-3-030-58565-5_23
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yan B, 2021, Arxiv, DOI arXiv:2103.17154
   Yan B, 2021, PROC CVPR IEEE, P15175, DOI 10.1109/CVPR46437.2021.01493
   Yang TY, 2020, PROC CVPR IEEE, P6717, DOI 10.1109/CVPR42600.2020.00675
   Yu L, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104181
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhao MJ, 2021, Arxiv, DOI arXiv:2105.03817
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhu M, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104002
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 61
TC 0
Z9 0
U1 3
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2023
VL 133
AR 104672
DI 10.1016/j.imavis.2023.104672
EA APR 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA F3CJ9
UT WOS:000981156100001
DA 2024-07-18
ER

PT J
AU Raj, SS
   Prasad, MVNK
   Balakrishnan, R
AF Raj, S. Sridhar
   Prasad, Munaga V. N. K.
   Balakrishnan, Ramadoss
TI Generative Segment-pose Representation based Augmentation (GSRA) for
   unsupervised person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised person re -identi fication; Clustering; Generative
   adversarial networks; Deep learning; Computer vision
ID NETWORK; ADAPTATION; GAN
AB Person re-identification matches the images of a person captured in multiple cameras in a smart surveillance environment. The process of matching the images captured from multiple viewing angles is challenging due to the variations caused by illumination, occlusion, dynamic pose change, etc., To tackle such challenges, large number of samples are required to identify the unique features of a person. In real-world crowded surveillance environment, it is highly difficult to capture the sufficient number of images to build a deep model. This scarcity in samples can be resolved by generating images using generative networks. The existing literature lacks robust discriminators and validation techniques to validate the generative network in an unsupervised person re -identification setup. Thus, we propose an unsupervised adversarial segment-pose distance threshold representa-tion to validate the generated images in addition to the conventional discriminator. The images are generated and cross-validated with the determined segment-pose distance threshold. Labelling process is performed by matching the unoccluded segment with its appropriate ground truth parent cluster based on the segment -pose distance threshold. We have performed experiments on the benchmark person re-ID datasets like DukeMTMC re-ID, Market1501, CUHK03 and MSMT17. The effectiveness of the proposed unsupervised genera-tive model is proved by reporting a +2.6% highest ranking accuracy over the state-of-the-art methods.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Raj, S. Sridhar] Vellore Inst Technol, Vellore, India.
   [Prasad, Munaga V. N. K.] Inst Dev & Res Banking Technol, Hyderabad, India.
   [Balakrishnan, Ramadoss] Natl Inst Technol, Trichy, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; National Institute
   of Technology (NIT System); National Institute of Technology
   Tiruchirappalli
RP Raj, SS (corresponding author), Vellore Inst Technol, Vellore, India.
EM sridharselva394@gmail.com; mvnkprasad@idrbt.ac.in; brama@nitt.edu
OI Balakrishnan, Ramadoss/0000-0003-3817-1510; Raj S, Dr.
   Sridhar/0000-0002-7609-4176
CR Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Chang XY, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107569
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Feng H, 2021, IEEE T IMAGE PROCESS, V30, P2898, DOI 10.1109/TIP.2021.3056212
   Ge YX, 2018, Arxiv, DOI arXiv:1810.02936
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li HF, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107414
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li XH, 2021, ISPRS J PHOTOGRAMM, V179, P14, DOI 10.1016/j.isprsjprs.2021.07.007
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Lu J, 2019, IEEE SIGNAL PROC LET, V26, P933, DOI 10.1109/LSP.2019.2913020
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Raj SS, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114502
   Raj SS, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103956
   Raj S, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108287
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201
   Wu Q, 2021, SIGNAL IMAGE VIDEO P, V15, P655, DOI 10.1007/s11760-019-01523-3
   Xian YQ, 2018, IET COMPUT VIS, V12, P1219, DOI 10.1049/iet-cvi.2018.5103
   Xiong F, 2018, Arxiv, DOI arXiv:1807.11042
   Ye M, 2021, Arxiv, DOI arXiv:2001.04193
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang Z., 2019, IEEE T FUZZY SYST, V14, P1063
   Zhao YR, 2020, NEUROCOMPUTING, V388, P246, DOI 10.1016/j.neucom.2019.12.115
   Zhao YB, 2019, IET IMAGE PROCESS, V13, P2897, DOI 10.1049/iet-ipr.2019.0699
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 33
TC 1
Z9 1
U1 3
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2023
VL 131
AR 104632
DI 10.1016/j.imavis.2023.104632
EA FEB 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 9O5QE
UT WOS:000943655500001
DA 2024-07-18
ER

PT J
AU Xiao, WP
   Li, XM
   Liu, C
   Gao, JT
   Luo, J
   Peng, Y
   Zhou, Y
AF Xiao, Weiping
   Li, Xiaomao
   Liu, Chang
   Gao, Jiantao
   Luo, Jun
   Peng, Yan
   Zhou, Yang
TI 3D-VDNet: Exploiting the vertical distribution characteristics of point
   clouds for 3D object detection and augmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D object detection; Vertical distribution characteristics; Object
   augmentation; LiDAR point cloud
AB Accurate 3D object detection is limited by the sparsity of LiDAR-based point clouds. The vertical distribution char-acteristics (VDCs) of point clouds in pillars are robust to point-sparsity and provide informative semantic infor-mation on objects. Based on this, we propose a novel 3D object detection framework where the VDCs of point clouds are exploited to optimize feature extraction and object augmentation. More specifically, a Spatial Feature Aggregation module is proposed to perform robust feature extraction by decorating pillars with the VDCs. To spa-tially enhance semantic embeddings, we employ VDCs to construct a voxelized semantic map, acting as an addi-tional input stream. Moreover, we develop an Adaptive Object Augmentation (AOA) paradigm, which adopts the VDC searching of suitable ground regions to "paste" virtual objects, thus avoiding conflicts with new scenes. Ex-tensive experiments on the KITTI dataset demonstrate that our framework can significantly outperform the base-line, achieving 3.74%/1.59% moderate AP improvements on the Car 3D/BEV benchmarks with 38 FPS inference speed. Furthermore, we prove the stable performance of our AOA module across different detectors.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Xiao, Weiping; Li, Xiaomao; Liu, Chang; Gao, Jiantao; Luo, Jun; Peng, Yan; Zhou, Yang] Shanghai Univ, Shanghai, Peoples R China.
   [Xiao, Weiping; Li, Xiaomao; Liu, Chang; Gao, Jiantao; Luo, Jun; Peng, Yan; Zhou, Yang] Minist Educ, Engn Res Ctr Unmanned Intelligent Marine Equipment, Shanghai, Peoples R China.
C3 Shanghai University
RP Zhou, Y (corresponding author), Shanghai Univ, Shanghai, Peoples R China.
EM saber_mio@shu.edu.cn
RI Yang, Bo/JTS-4309-2023; Wang, Tianqi/JJD-7473-2023; XU,
   nan/KDP-0628-2024; wu, p/JDW-5015-2023; zhang, yuyang/IVV-5089-2023; qi,
   li/JFE-7167-2023; Liu, Yujie/IWU-6535-2023; LIU, HAO/JBI-9623-2023;
   fang, yu/KCK-2014-2024; zhang, yue/JAC-3705-2023; li, bo/JJC-2664-2023;
   Wang, YUJIE/JXY-8442-2024; liu, junyang/IXD-1201-2023; liu,
   xinyu/IWD-6630-2023; peng, yan/JCO-1763-2023; LI, XIAO/IQV-9318-2023;
   cheng, shu/IZE-4788-2023; wang, yue/ISA-4119-2023; zhou,
   you/KBC-3567-2024; Wang, Luyao/JLL-2001-2023; zhang,
   yimeng/JLL-7337-2023; wu, jun/ISB-8607-2023; Wang, lili/IXD-9828-2023;
   Li, Xiaoli/JVZ-4089-2024; Li, Li/IAQ-0885-2023; Zhang,
   Wenxiao/KCK-3295-2024; liu, junyang/IXD-1252-2023; yang,
   peng/JEZ-8452-2023; LI, XIAO/JCE-6169-2023; Chen, Xupeng/KFA-5959-2024;
   li, yang/IQV-3559-2023; ZHAO, S/IWV-4219-2023; Li, Tao/IWU-9607-2023;
   Liu, Han/HMD-9231-2023; Lu, Xiaomei/IUQ-2139-2023; yang,
   yun/IZE-1092-2023; LI, Xiang/JBJ-8387-2023; Gu, Bingxin/JNS-4761-2023;
   zhang, yu/HNS-5948-2023; Zhang, Lijun/JEZ-7925-2023; Luo,
   Jun/IQU-6231-2023; Zhang, Can/JUU-9511-2023; Yang, Mei/JNS-2225-2023;
   Zhang, Xiaofeng/JMC-6060-2023; liang, YU/IYT-4334-2023
OI Liu, Yujie/0000-0002-1153-6156; Liu, Han/0000-0002-5269-8477; Gu,
   Bingxin/0009-0005-5667-1430; Luo, Jun/0000-0002-6998-4453; Zhang,
   Xiaofeng/0000-0003-2738-3286; Liu, Chang/0000-0001-5012-7921; liang,
   YU/0009-0007-3922-3454
FU National Key Research and Development Program of China [2020YFC1521700];
   Joint Founds of National Natural Science Foundation of China [U1813217];
   National Natural Science Foundation of China [51904181]
FX This work was supported by the National Key Research and Development
   Program of China [Grant No. 2020YFC1521700] , the Joint Founds of
   National Natural Science Foundation of China [Grant No. U1813217] , and
   the National Natural Science Foundation of China [Grant No. 51904181] .
CR Arnold E, 2019, IEEE T INTELL TRANSP, V20, P3782, DOI 10.1109/TITS.2019.2892405
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen XZ, 2015, ADV NEUR IN, V28
   Chen YL, 2019, IEEE I CONF COMP VIS, P9774, DOI [10.1109/iccv.2019.00987, 10.1109/ICCV.2019.00987]
   Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hong DS, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103955
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Peiyun Hu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10998, DOI 10.1109/CVPR42600.2020.01101
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Simon M, 2019, LECT NOTES COMPUT SC, V11129, P197, DOI 10.1007/978-3-030-11009-3_11
   Smith LN, 2019, PROC SPIE, V11006, DOI 10.1117/12.2520589
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Wang D.Z., 2015, ROBOT SCI SYST
   Wang ZX, 2019, IEEE INT C INT ROBOT, P1742, DOI [10.1109/IROS40897.2019.8968513, 10.1109/iros40897.2019.8968513]
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Yang Z., 2018, ARXIV
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Ye YY, 2020, NEUROCOMPUTING, V379, P53, DOI 10.1016/j.neucom.2019.09.086
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 35
TC 3
Z9 3
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104557
DI 10.1016/j.imavis.2022.104557
EA OCT 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300007
DA 2024-07-18
ER

PT J
AU Chong, Z
   Mo, LF
AF Chong, Zheng
   Mo, Lingfei
TI ST-VTON: Self-supervised vision transformer for image-based virtual
   try-on
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Self-supervised; Vision transformer; Virtual try-on; Masked image
   modeling
AB Virtual try-on techniques are in the spotlight due to the promise of enhancing the user experience of online shop-ping in the apparel industry. Among these technologies, image-based virtual try-on methods have received more attention due to their efficiency and low cost. These methods commonly warp the specific clothing item to the desired shape and then fuse it with the target person image. However, existing approaches demand the laborious paired dataset of clothes and persons. While recent works alleviate the dependence on paired datasets by trans-ferring clothing from one person to another, the pose information is still a rigid demand to guide the synthesis. To solve the above-mentioned problems, we propose ST-VTON, a two-stage self-supervised try-on approach that can synthesize photo-realistic try-on results with only person images and a standard ViT structure. Specifically, we first utilize massive person and clothing images to pre-train a powerful ViT encoder following the MAE approach to enhance the generalization ability and accelerate model training. Secondly, we propose the Clothing Recovery Module (CRM) to reconstruct in-shop clothes from person images and use the paired generated cloth-ing and corresponding person images to train a new ViT decoder while optimizing the pre-trained encoder. Noted that, the CRM, as an independent module, can be used to effectively expand existing paired try-on datasets and enhance other try-on approaches in terms of training data. Extensive experiments conducted on the VITON dataset and UnPaired virtual Try-on (UPT) dataset with both paired and unpaired approaches demonstrate that try-on results rendered by our model can match or even outperform supervised methods.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Chong, Zheng; Mo, Lingfei] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Mo, LF (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM lfmo@seu.edu.cn
RI mo, lingfei/ACV-6434-2022
OI mo, lingfei/0000-0002-8561-9122
FU Blue Project for the university of Jiangsu Province;  [2021]
FX Acknowledgement This work is sponsored by the Blue Project for the
   university of Jiangsu Province 2021. Sincere gratitude should also go to
   Prof. Xiaodan Liang and Dr. Zhenyu Xie of Sun Yat-sen University for the
   help in exper-iment data and code debugging.
CR Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Choi S, 2021, PROC CVPR IEEE, P14126, DOI 10.1109/CVPR46437.2021.01391
   Cui A., 2021, P IEEE CVF INT C COM, P14638
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fele B, 2022, IEEE WINT CONF APPL, P2203, DOI 10.1109/WACV51458.2022.00226
   Ge YY, 2021, PROC CVPR IEEE, P8481, DOI 10.1109/CVPR46437.2021.00838
   Gidaris S, 2018, Arxiv, DOI arXiv:1803.07728
   Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   He K., 2022, ARXIV, P16000, DOI DOI 10.48550/ARXIV.2111.06377
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kingma D. P., 2014, arXiv
   Liang Youwei, 2022, arXiv
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Loshchilov Ilya, 2016, arXiv
   Men YF, 2020, PROC CVPR IEEE, P5083, DOI 10.1109/CVPR42600.2020.00513
   Minar M. R., 2020, CVPR WORKSH
   Mir A, 2020, PROC CVPR IEEE, P7021, DOI 10.1109/CVPR42600.2020.00705
   Neuberger A, 2020, PROC CVPR IEEE, P5183, DOI 10.1109/CVPR42600.2020.00523
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Paszke A, 2019, ADV NEUR IN, V32
   Patel Chaitanya, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7363, DOI 10.1109/CVPR42600.2020.00739
   Ren B, 2021, Arxiv, DOI arXiv:2104.05519
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salimans T, 2016, ADV NEUR IN, V29
   Sarkar K., 2021, arXiv
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song L.., 2021, Advances in Neural Information Processing Systems, P5770
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang BC, 2018, LECT NOTES COMPUT SC, V11217, P607, DOI 10.1007/978-3-030-01261-8_36
   Wang HY, 2021, PROC CVPR IEEE, P5459, DOI 10.1109/CVPR46437.2021.00542
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xic Z., 2021, Advances in Neural Information Processing Systems, V34, P2598
   Xie Z., 2022, arXiv
   Xie ZD, 2022, PROC CVPR IEEE, P9643, DOI 10.1109/CVPR52688.2022.00943
   Yang H., P IEEE CVF C COMP VI, P7850
   Yu RY, 2019, IEEE I CONF COMP VIS, P10510, DOI 10.1109/ICCV.2019.01061
   Zhang Q., 2022, arXiv
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou JH, 2022, Arxiv, DOI arXiv:2111.07832
NR 51
TC 2
Z9 2
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104568
DI 10.1016/j.imavis.2022.104568
EA OCT 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300010
DA 2024-07-18
ER

PT J
AU Qin, WC
   Huang, BJ
   Qin, PZ
   Huang, ZY
   Zhong, DD
AF Qin, Wencheng
   Huang, Baojin
   Qin, Pinzhong
   Huang, Zhiyong
   Zhong, Daidi
TI Learning diverse and deep clues for person reidentification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Attention network; convolutional neural net; work; Grouped pyramid;
   Global feature; Local features; Person re -identification
AB Extracting robust features has been the core of person re-identification(ReID). The existing convolutional neural network-based methods pay more attention to local features rather than the connection between local features. Given that human bodies possess certain structural information, it is absolutely necessary to strengthen the con-nection of local features for the ReID task. This paper proposes a two-stage attention network termed Width and Depth Channel Attention Network (WDC-Net) for ReID. Unlike conventional attention-based methods, which only focus on the single local features, our network exploits diverse feature representations to alleviate the miss-ing information problem caused by occlusion. Precisely, for the first stage, it splits the local associations of the fea-ture map through a multi-scale perspective to extract relatively independent multi-level local features of the human body. For the second stage, the correlation of multi-level local features is reconstructed through grouped pyramid structure to obtain a more robust global feature representation. We also propose an adaptive margin weight adjustment strategy to enhance the adaptability of the attention weights. Large-scale ReID datasets are tested to evaluate our method. On Market1501 and DukeMTMC, the proposed method achieves 90.7 % /96.4% mAP/R-1 and 81.8 % /90.8% mAP/R-1, respectively. It is worth highlighting that the proposed method also achieves 55.3 % /65.3% mAP/R-1 on the challenging Occluded-Duke dataset. Extensive experimental results dem-onstrate the superiority of our method, which achieves state-of-the-art performance on ReID.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Qin, Wencheng; Huang, Baojin; Qin, Pinzhong; Huang, Zhiyong] Chongqing Univ, Sch Microelect & Commun Engn, Chongqing 400044, Peoples R China.
   [Zhong, Daidi] Chongqing Univ, Sch Bioengn, Chongqing 400044, Peoples R China.
C3 Chongqing University; Chongqing University
RP Huang, ZY (corresponding author), Chongqing Univ, Sch Microelect & Commun Engn, Chongqing 400044, Peoples R China.
EM qwc@cqu.edu.cn; baojinhuang@cqu.edu.cn; pinzhongq@cqu.edu.cn;
   zyhuang@cqu.edu.cn; daidi.zhong@cqu.edu.cn
OI Zhong, Daidi/0000-0002-9879-4915
FU National Key R&D Program of China;  [2021YFC2009200]
FX This work was supported by grants from the National Key R&D Program of
   China (No. 2021YFC2009200) .
CR Alemu LT, 2019, IEEE I CONF COMP VIS, P9854, DOI 10.1109/ICCV.2019.00995
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Ge Y., 2018, Advances in Neural Information Processing Systems
   Gu HY, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108432
   Guo J., P IEEECVF INT C COMP, P3642
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2018, Arxiv, DOI arXiv:1810.07399
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Huang ZY, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03473-6
   Kiran M, 2021, IMAGE VISION COMPUT, V113, DOI 10.1016/j.imavis.2021.104246
   Kuan Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P346, DOI 10.1007/978-3-030-58580-8_21
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Rama Varior R., ARXIV
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Shizhen Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P647, DOI 10.1007/978-3-030-58539-6_39
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2020, IEEE T IMAGE PROCESS, V29, P6096, DOI 10.1109/TIP.2020.2986878
   Wang H.-F., 2022, ARXIV
   Wang P., 2022, IEEE Transactions on Multimedia
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yang L., 2022, PATTERN RECOGN
   Zang XH, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104330
   Zhang G., 2021, P 29 ACM INT C MULT, P516
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao Y, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107938
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhu H., 2022, P IEEECVF C COMPUTER, P4692
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 53
TC 4
Z9 4
U1 1
U2 39
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104551
DI 10.1016/j.imavis.2022.104551
EA SEP 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5Q3YO
UT WOS:000873771400002
DA 2024-07-18
ER

PT J
AU Tong, XY
   Sun, SL
   Fu, MX
AF Tong, Xiaoyun
   Sun, Songlin
   Fu, Meixia
TI Adaptive weight based on overlapping blocks network for facial
   expression recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Feature map block; Adaptive weight; Deep
   learning
ID FACE RECOGNITION; FEATURES; IMAGE
AB Facial expressions which contain rich behavioral information are the primary vehicle to express emotions. It is important to analyze people's emotions with computer to achieve human-computer interaction. Feature extraction is the most important factor affecting the recognition effect. However, the existing deep learning for expression recognition is mainly based on global feature extraction. Local feature extraction provides more fine-grained information than global features. To strengthen the local discrimination of the image and pay more attention to the small targets in the local region, we propose an innovative Adaptive Weight Based on Overlapping Blocks Network (AWOBNet) for learning feature representation. First, we spatially overlay the feature maps to obtain the local features of the face. Considering the correlation and proportion between different features, we model the correlation between feature channels after overlapping blocks. Moreover, a new adaptive weighting method is developed to enhance significant features. We evaluate the proposed network on two public datasets, including the Real-World Affective Faces Database (RAFDB) and the Static Facial Expressions in the Wild (SFEW), and show the performance using the visualization method. The accuracy rates of our method obtain 89.863% on RAFDB and 62.410% on SFEW, which is significantly higher than the existing technical level.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Tong, Xiaoyun; Sun, Songlin; Fu, Meixia] Beijing Univ Posts & Telecommun, Informat & Commun Engn, Key Lab Trustworthy Distributed Comp & Serv BUPT, 10 Xi Tu Cheng Rd, Beijing 100876, Peoples R China.
   [Fu, Meixia] Univ Sci & Technol Beijing, Sch Automat & Elect Engn, 30 Xue Yuan Rd, Beijing 100083, Peoples R China.
C3 Beijing University of Posts & Telecommunications; University of Science
   & Technology Beijing
RP Tong, XY (corresponding author), Beijing Univ Posts & Telecommun, Informat & Commun Engn, Key Lab Trustworthy Distributed Comp & Serv BUPT, 10 Xi Tu Cheng Rd, Beijing 100876, Peoples R China.
EM xiaoyun_t@bupt.edu.cn
FU National Natural Science Foundation of China [Project61471066,
   201600017]; National Key Laboratory of Electromagnetic Environment,
   China
FX This work is supported by National Natural Science Foundation of China
   (Project61471066) and the open project fund (No. 201600017) of the
   National Key Laboratory of Electromagnetic Environment, China.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2007, COMPUTER ENG DESIGN
   [Anonymous], 2016, INFORMATION
   Bellamkonda S, 2020, INT J AMBIENT COMPUT, V11, P48, DOI 10.4018/IJACI.2020010103
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Connie Tee, 2017, Multi-disciplinary Trends in Artificial Intelligence. 11th International Workshop, MIWAI 2017. Proceedings: LNAI 10607, P139, DOI 10.1007/978-3-319-69456-6_12
   Cubuk Ekin D, 2018, ARXIV180509501
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhall A., 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Farzaneh AH, 2021, IEEE WINT CONF APPL, P2401, DOI 10.1109/WACV48630.2021.00245
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hernandez-Matamoros A, 2016, KNOWL-BASED SYST, V110, P1, DOI 10.1016/j.knosys.2016.07.011
   Huang G., P IEEE C COMP VIS PA, P4700
   Huang YX, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101189
   Iqbal M.T.B., 2020, IN PRESS, DOI [10.1109/TAFFC.2020.2995432, DOI 10.1109/TAFFC.2020.2995432]
   Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174
   Khan SA, 2018, MULTIMED TOOLS APPL, V77, P1133, DOI 10.1007/s11042-016-4324-z
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lajevardi S.M., EUR SIGN PROC C, P60
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Li S, IEEE T AFFECT COMPUT, P1
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Liang DD, 2020, VISUAL COMPUT, V36, P499, DOI 10.1007/s00371-019-01636-3
   Liao S, 2006, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2006.312418
   Liu P, 2022, IEEE T CYBERNETICS, V52, P12649, DOI 10.1109/TCYB.2021.3085744
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Otberdout Naima, 2018, ARXIV180503869
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan XY, 2005, IEEE T NEURAL NETWOR, V16, P875, DOI 10.1109/TNN.2005.849817
   Tong XY, 2019, IEEE ACCESS, V7, P86821, DOI 10.1109/ACCESS.2019.2923530
   Uddin M, 2016, KSII T INTERNET INF, V10
   Uddin MZ, 2014, ARAB J SCI ENG, V39, P7885, DOI 10.1007/s13369-014-1396-9
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang S., CHIN C PATT REC 2019, P670
   Wang Wei, 2008, Optics and Precision Engineering, V16, P696
   Wang Yun-Hong, 2005, Chinese Journal of Computers, V28, P1657
   Yang HY, 2017, INT CONF AFFECT, P556, DOI 10.1109/ACII.2017.8273654
   [曾岳 Zeng Yue], 2011, [计算机科学, Computer Science], V38, P252
   Zhang FF, 2022, IEEE T MULTIMEDIA, V24, P1800, DOI 10.1109/TMM.2021.3072786
   Zhang HF, 2020, IEEE ACCESS, V8, P37976, DOI 10.1109/ACCESS.2020.2975913
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 50
TC 4
Z9 4
U1 3
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104399
DI 10.1016/j.imavis.2022.104399
EA FEB 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500007
DA 2024-07-18
ER

PT J
AU Yang, XW
   Feng, ZG
   Zhao, Y
   Zhang, GY
   He, L
AF Yang, Xiaowei
   Feng, Zhiguo
   Zhao, Yong
   Zhang, Guiying
   He, Lin
TI Edge supervision and multi-scale cost volume for stereo matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo matching; Geometric constraints; Multi-scale cost volume;
   Disparity refinement network
AB Recently, methods based on Convolutional Neural Network have achieved huge progress in stereo matching. However, it is still difficult to find accurate matching points in inherently ill-posed regions (e.g., weak texture areas and around object edges), in which the accuracy of disparity estimate can be improved by the corresponding geometric constraints. To tackle this problem, we innovatively generate the depth ground-truth boundary dataset by mining the instance segmentation and semantic segmentation datasets and propose RDNet, which incorporates edge cues into stereo matching. The network learns geometric information through a separate processing branch edge stream, which can process feature information in parallel with the stereo stream. The edge stream removes noise and only focuses on processing the relevant boundary information. Besides, we introduce a multi-scale cost volume in hierarchical cost aggregation to enlarge the receptive fields and capture structural and global representations that can significantly improve the ability of scene understanding and disparity estimation accuracy. Moreover, a disparity refinement network with several dilated convolutions is applied to further improve the accuracy of the final disparity estimation. The proposed method is evaluated on Sceneflow, KITTI 2015 and KITTI 2012 benchmark datasets, and the qualitative and quantitative results demonstrate that the proposed RDNet significantly achieves the state-of-the-art stereo matching performance. (c) 2021 Published by Elsevier B.V.
C1 [Yang, Xiaowei; Feng, Zhiguo; He, Lin] Guizhou Univ, Sch Mech Engn, Guiyang 550025, Peoples R China.
   [Yang, Xiaowei] Guizhou Acad Agr Sci, Guizhou Tea Res Inst, Guiyang 550006, Peoples R China.
   [Zhao, Yong] Peking Univ, Sch Elect & Comp Engn, Shenzhen Grad Sch, Shenzhen 518055, Peoples R China.
   [Zhang, Guiying] Guangzhou Med Univ, Sch Basic Med Sci, Guangzhou 511436, Peoples R China.
   [He, Lin] Liupanshui Normal Coll, Liupanshui 553004, Peoples R China.
C3 Guizhou University; Guizhou Academy of Agricultural Sciences; Peking
   University; Guangzhou Medical University
RP Feng, ZG; He, L (corresponding author), Guizhou Univ, Sch Mech Engn, Guiyang 550025, Peoples R China.
EM Yangxiaowei_GZU@163.com; zgfeng@gzu.edu.cn; yongzhao@pku.edu.cn;
   guiyingzh@126.com; helin6568@163.com
RI feng, zhiguo/N-4227-2013; Xiao, Yang/AAE-6715-2019
OI Xiao, Yang/0000-0001-8549-6794
FU Science and TechnologyMajor Project of Guizhou Province (Qiankehe Major
   Projects) [ZNWLQC [2019]3012]; Science and Technology Project of Guizhou
   Province Department of Transportation [2021-322-021]; Natural Science
   Foundation of Guangdong Province [2020A1515110501]; Science and
   Technology Planning Project of Shenzhen [JCYJ20180503182133411]
FX This study is supported in part by the Science and TechnologyMajor
   Project of Guizhou Province (Qiankehe Major Projects No. ZNWLQC
   [2019]3012), the Science and Technology Project of Guizhou Province
   Department of Transportation (2021-322-021), the Natural Science
   Foundation of Guangdong Province Grant No. 2020A1515110501 and the
   Science and Technology Planning Project of Shenzhen No.
   JCYJ20180503182133411.
CR Chabra R, 2019, PROC CVPR IEEE, P11778, DOI 10.1109/CVPR.2019.01206
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen C., Proceedings of the IEEE International Conference on Computer Vision, P2722
   Chen QY, 2017, IEEE INT CONF COMP V, P99, DOI 10.1109/ICCVW.2017.20
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Duggal S, 2019, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2019.00448
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   He JZ, 2019, PROC CVPR IEEE, P3823, DOI 10.1109/CVPR.2019.00395
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jie ZQ, 2018, PROC CVPR IEEE, P3838, DOI 10.1109/CVPR.2018.00404
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Khamis S, 2018, LECT NOTES COMPUT SC, V11219, P596, DOI 10.1007/978-3-030-01267-0_35
   Liang Z., 2017, arXiv:1712.01039
   Liu Y, 2017, PROC CVPR IEEE, P5872, DOI 10.1109/CVPR.2017.622
   Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108
   Paszke A, 2019, ADV NEUR IN, V32
   Rao ZB, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/ATSIP.2020.16
   Schmid K, 2013, IEEE INT C INT ROBOT, P3955, DOI 10.1109/IROS.2013.6696922
   Shen SH, 2013, IEEE T IMAGE PROCESS, V22, P1901, DOI 10.1109/TIP.2013.2237921
   Shen ZL, 2021, PROC CVPR IEEE, P13901, DOI 10.1109/CVPR46437.2021.01369
   Song X, 2020, INT J COMPUT VISION, V128, P910, DOI 10.1007/s11263-019-01287-w
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Tankovich V, 2021, PROC CVPR IEEE, P14357, DOI 10.1109/CVPR46437.2021.01413
   Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028
   Wu ZY, 2019, IEEE I CONF COMP VIS, P7483, DOI 10.1109/ICCV.2019.00758
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu D., 2017, ADV NEURAL INFORM PR, P3691
   Xu HF, 2020, PROC CVPR IEEE, P1956, DOI 10.1109/CVPR42600.2020.00203
   Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39
   Yang XW, 2020, IEEE ACCESS, V8, P113371, DOI 10.1109/ACCESS.2020.3003375
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yin ZC, 2019, PROC CVPR IEEE, P6037, DOI 10.1109/CVPR.2019.00620
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
   Zhang YD, 2018, LECT NOTES COMPUT SC, V11212, P802, DOI 10.1007/978-3-030-01237-3_48
   Zhu ZD, 2019, C IND ELECT APPL, P1789, DOI [10.1109/iciea.2019.8834193, 10.1109/ICIEA.2019.8834193]
NR 41
TC 12
Z9 12
U1 2
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104336
DI 10.1016/j.imavis.2021.104336
EA NOV 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA XF7PZ
UT WOS:000724261200002
DA 2024-07-18
ER

PT J
AU Kogashi, K
   Wu, Y
   Nobuhara, S
   Nishino, K
AF Kogashi, Kaen
   Wu, Yang
   Nobuhara, Shohei
   Nishino, Ko
TI Human-object interaction detection with missing objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Keyword; Human-object interaction
AB Human-object interaction (HOI) detection is an important vision task that requires the detection of individual object instances and reasoning of their relations. Despite encouraging advancement in recent years, past methods are still limited to relatively simple images where the human and object instances can be detected without difficulties. HOI in the wild should work even when the objects that a person is interacting with are not visible or hard to detect in the image. In this paper, we formulate HOI with missing objects (HOI-MO) as a research problem, and show that it is indeed critical as many such instances can be found even in the commonly-used public HOI detection datasets. We label these to compose new test sets for the proposed method. To our knowledge, we introduce the first method for such challenging HOI detection that incorporates global scene information. The effectiveness and superiority of the proposed method are demonstrated through extensive experiments and comparisons. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Kogashi, Kaen; Wu, Yang; Nobuhara, Shohei; Nishino, Ko] Kyoto Univ, Kyoto, Japan.
C3 Kyoto University
RP Kogashi, K (corresponding author), Kyoto Univ, Kyoto, Japan.
EM kkogashi@vision.ist.i.kyoto-u.ac.jp; wuyang0321@gmail.com;
   nob@i.kyoto-u.ac.jp; nishino.ko.5a@kyoto-u.ac.jp
RI Nobuhara, Shohei/HWS-3289-2023
OI Nishino, Ko/0000-0002-3534-3447; Nobuhara, Shohei/0000-0002-3204-8696
FU JSPS [20H05951, 21H04893]; JST [JPMJCR20G7]; Grants-in-Aid for
   Scientific Research [21H04893, 20H05951] Funding Source: KAKEN
FX This work was in part supported by JSPS 20H05951, JSPS 21H04893, and JST
   JPMJCR20G7.
CR Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chen XL, 2017, IEEE I CONF COMP VIS, P4106, DOI 10.1109/ICCV.2017.440
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Gao C., BRIT MACH VIS C, P1
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Google, 2013, WORD2VEC GOOGL NEWS
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Gupta Saurabh, 2015, ARXIV150504474, P5
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Kaen Kogashi, 2021, INT C MACH VIS APPL
   Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656
   Kolesnikov A., INT C COMP VIS WORKS, P1749
   Li YL, 2019, PROC CVPR IEEE, P3580, DOI 10.1109/CVPR.2019.00370
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2018, PROC CVPR IEEE, P6985, DOI 10.1109/CVPR.2018.00730
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Oytun Ulutan A.S.M., 2020, ARXIV200305541
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Wan B, 2019, IEEE I CONF COMP VIS, P9468, DOI 10.1109/ICCV.2019.00956
   Wang TC, 2019, IEEE I CONF COMP VIS, P5693, DOI 10.1109/ICCV.2019.00579
   Wu Yuxin, 2019, DETECTRON2
   Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235
   Zhi Hou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P584, DOI 10.1007/978-3-030-58555-6_35
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 29
TC 0
Z9 0
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104262
DI 10.1016/j.imavis.2021.104262
EA AUG 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900010
OA hybrid
DA 2024-07-18
ER

PT J
AU Raju, PM
   Mishra, D
   Mukherjee, P
AF Raju, Priya Mariam
   Mishra, Deepak
   Mukherjee, Prerana
TI DA-SACOT: Domain adaptive-segmentation guided attention for correlation
   based object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual object tracking; Object segmentation; Online learning; Domain
   adaptation; Correlation filter based tracker
AB Object tracking relies on a recursive search technique around the previous target location, concurrently learning the target appearance in each frame. A failure in any frame causes a drift from its optimal target path. Thus, obtaining highly confident search regions is essential in each frame. Motivated by the strong localization property of segmented object masks, the proposed method introduces instance segmentation as an attention mechanism in object tracking framework. The core contribution of this paper is threefold: (i) a region proposal module (RPM) based on instance segmentation to focus on search proposals having a high probability of being the target, (ii) a target localization module (TLM) to localize the final target using a correlation filter and (iii) a domain adaptation technique in both RPM and TLM modules to incorporate target specific knowledge and strong discrimination ability. Extensive experimental evaluation on three benchmark datasets demonstrate a significant average gain of 2.47% in precision, 2.55% in AUC score and 2.15% in overlap score in comparison with recent competing trackers. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Raju, Priya Mariam; Mishra, Deepak] Indian Inst Space Sci & Technol, Trivandrum, Kerala, India.
   [Mukherjee, Prerana] JNU, Sch Engn, Delhi, India.
C3 Department of Space (DoS), Government of India; Indian Institute of
   Space Science & Technology; Jawaharlal Nehru University, New Delhi
RP Mukherjee, P (corresponding author), JNU, Sch Engn, Delhi, India.
EM deepak.mishra@iist.ac.in; prerana@jnu.ac.in
RI MISHRA, DEEPAK/AER-1076-2022
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Ali A, 2016, FRONT COMPUT SCI-CHI, V10, P167, DOI 10.1007/s11704-015-4246-3
   Belagiannis V, 2012, LECT NOTES COMPUT SC, V7575, P842, DOI 10.1007/978-3-642-33765-9_60
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Cai ZW, 2014, IEEE T IMAGE PROCESS, V23, P5497, DOI 10.1109/TIP.2014.2364919
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Gedas Bertasius., P IEEE CVF C COMP VI, P9739
   Gkioxari G., 2017, ICCV, P2961
   Gladh S, 2016, INT C PATT RECOG, P1243, DOI 10.1109/ICPR.2016.7899807
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Keuper M, 2020, IEEE T PATTERN ANAL, V42, P140, DOI 10.1109/TPAMI.2018.2876253
   KristanMatej Alan Lukezic, 2020, NEW VOT2020 SHORT TE
   Laurense VA, 2017, P AMER CONTR CONF, P5586, DOI 10.23919/ACC.2017.7963824
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Matej Kristan, P IEEE INT C COMP VI, P1396
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Sean Walker, 2017, U.S. Patent, Patent No. [9,629,595, 9629595]
   Severson J., 2017, US Patent, Patent No. [9,713,444, 9713444]
   Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934
   Tian B, 2011, IEEE INT C INTELL TR, P1103, DOI 10.1109/ITSC.2011.6083125
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wang D., 2019, CVPR
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wang Y, 2019, KNOWL-BASED SYST, V175, P62, DOI 10.1016/j.knosys.2019.03.012
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang B, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00505-7
   Yang Linjie., P IEEE INT C COMP VI, P5188
   Yang TY, 2020, PROC CVPR IEEE, P6717, DOI 10.1109/CVPR42600.2020.00675
   Yao R, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3391743
   Yao R, 2019, IEEE T CIRC SYST VID, V29, P1687, DOI 10.1109/TCSVT.2018.2848358
   Yeo D, 2017, PROC CVPR IEEE, P511, DOI 10.1109/CVPR.2017.62
   Zgaren Ahmed., INT S VIS COMP, P517
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 54
TC 5
Z9 5
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104215
DI 10.1016/j.imavis.2021.104215
EA JUN 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100012
DA 2024-07-18
ER

PT J
AU Aspandi, D
   Martinez, O
   Sukno, F
   Binefa, X
AF Aspandi, Decky
   Martinez, Oriol
   Sukno, Federico
   Binefa, Xavier
TI Composite recurrent network with internal denoising for facial alignment
   in still and video images in the wild
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial alignment; Facial tracking; Temporal modeling; Internal denoising
ID RECOGNITION; TRACKING; MODELS
AB Facial alignment is an essential task for many higher level facial analysis applications, such as animation, human activity recognition and human -computer interaction. Although the recent availability of big datasets and powerful deep-learning approaches have enabled major improvements on the state of the art accuracy, the performance of current approaches can severely deteriorate when dealing with images in highly unconstrained conditions, which limits the real-life applicability of such models. In this paper, we propose a composite recurrent tracker with internal denoising that jointly address both single image facial alignment and deformable facial tracking in the wild. Specifically, we incorporate multilayer LSTMs to model temporal dependencies with variable length and introduce an internal denoiser which selectively enhances the input images to improve the robustness of our overall model. We achieve this by combining 4 different sub-networks that specialize in each of the key tasks that are required, namely face detection, bounding-box tracking, facial region validation and facial alignment with internal denoising. These blocks are endowed with novel algorithms resulting in a facial tracker that is both accurate, robust to in-the-wild settings and resilient against drifting. We demonstrate this by testing our model on 300-W and Menpo datasets for single image facial alignment, and 300-VW dataset for deformable facial tracking. Comparison against 20 other state of the art methods demonstrates the excellent performance of the proposed approach. (c) 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Aspandi, Decky; Martinez, Oriol; Sukno, Federico; Binefa, Xavier] Pompeu Fabra Univ, Dept Informat & Commun Technol, Barcelona, Spain.
C3 Pompeu Fabra University
RP Aspandi, D (corresponding author), Pompeu Fabra Univ, Dept Informat & Commun Technol, Barcelona, Spain.
EM decky.aspandilatif@upf.edu
RI Aspandi, Decky/ABD-9477-2021; Sukno, Federico/AAM-4440-2021
OI Aspandi, Decky/0000-0002-6653-3470; Sukno, Federico/0000-0002-2029-1576
FU Spanish Ministry of Economy and Competitiveness [TIN2017-90124-P]; Ramon
   y Cajal Programme; Maria de Maeztu Units of Excellence Programme
   [MDM-2015-0502]
FX This work is partly supported by the Spanish Ministry of Economy and
   Competitiveness under project grant TIN2017-90124-P, the Ramon y Cajal
   Programme, the Maria de Maeztu Units of Excellence Programme
   (MDM-2015-0502) and the donation bahi2018-19 to the CMTech at the UPF.
CR Afifi M, 2019, J VIS COMMUN IMAGE R, V62, P77, DOI 10.1016/j.jvcir.2019.05.001
   [Anonymous], 2018, INT J COMPUT VISION
   Aspandi D, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 4: VISAPP, P172, DOI 10.5220/0010332001720181
   Aspandi D, 2019, IEEE INT CONF AUTOMA, P730
   Aspandi D, 2020, IEEE INT CONF AUTOMA, P606, DOI 10.1109/FG47880.2020.00053
   Aspandi D, 2019, IEEE INT CONF AUTOMA, P115
   Aspandi D, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P143, DOI 10.1109/CRV.2019.00027
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Baltrusaitis Tadas, 2018, 2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018), P59, DOI 10.1109/FG.2018.00019
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Biau G, 2019, SANKHYA SER A, V81, P347, DOI 10.1007/s13171-018-0133-y
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Chrysos GG, 2019, INT J COMPUT VISION, V127, P801, DOI 10.1007/s11263-018-1138-7
   Chrysos GG, 2018, INT J COMPUT VISION, V126, P198, DOI 10.1007/s11263-017-0999-5
   Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dong XY, 2018, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2018.00047
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gordon D, 2018, IEEE ROBOT AUTOM LET, V3, P788, DOI 10.1109/LRA.2018.2792152
   Goswami G, 2018, AAAI CONF ARTIF INTE, P6829
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Gu JW, 2017, PROC CVPR IEEE, P1531, DOI 10.1109/CVPR.2017.167
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kazemi V, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.27
   Kingma D. P., 2014, arXiv
   Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393
   Mao XJ, 2016, ADV NEUR IN, V29
   Nada H, 2018, INT CONF BIOMETR THE
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Naturel X., 2018, RFIAP, P1
   Peng X, 2018, INT J COMPUT VISION, V126, P1103, DOI 10.1007/s11263-018-1095-1
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Qu CC, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301348
   Rajamanoharan G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P971, DOI 10.1109/ICCVW.2015.128
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Sun G., IEEE CVPR 2018, P7132
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Uricár M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P963, DOI 10.1109/ICCVW.2015.127
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Wu Y, 2017, PROC CVPR IEEE, P5719, DOI 10.1109/CVPR.2017.606
   Wu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P979, DOI 10.1109/ICCVW.2015.129
   Xiao ST, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P986, DOI 10.1109/ICCVW.2015.130
   Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51
   Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882
   Yang J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P994, DOI 10.1109/ICCVW.2015.131
   Yi Dong, 2014, ARXIV14117923
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zadeh A, 2017, IEEE INT CONF COMP V, P2519, DOI 10.1109/ICCVW.2017.296
   Zafeiriou S, 2017, IEEE INT CONF COMP V, P2503, DOI 10.1109/ICCVW.2017.16
   Zafeiriou S, 2017, IEEE COMPUT SOC CONF, P2116, DOI 10.1109/CVPRW.2017.263
   Zhang HW, 2018, IEEE T INF FOREN SEC, V13, P2409, DOI 10.1109/TIFS.2018.2800901
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203
   Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286
   Zheng S., 2013 10 IEEE INT C A, P1, DOI [10.1109/FG.2013.6553701, DOI 10.1109/FG.2013.6553701]
   Zhou YQ, 2018, IEEE INT CONF AUTOMA, P769, DOI 10.1109/FG.2018.00121
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 68
TC 9
Z9 9
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104189
DI 10.1016/j.imavis.2021.104189
EA MAY 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700009
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Chen, YS
   Guo, B
   Shen, Y
   Wang, W
   Lu, WC
   Suo, XH
AF Chen, Yaosen
   Guo, Bing
   Shen, Yan
   Wang, Wei
   Lu, Weichen
   Suo, Xinhua
TI Boundary graph convolutional network for temporal action detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Temporal action detection; Graph convolutional network; Temproal action
   proposals; Video features
AB Temporal action proposal generation is a fundamental yet challenging to locate the temporal action in untrimmed videos. Although current proposal generation methods can generate the precise boundary of actions, few focus on considering the relation of proposals. In this paper, we propose a unified framework to generate the temporal boundary proposals with a graph convolution network based on the boundary proposals' feature named Boundary Graph Convolutional Network (BGCN). BGCN draws inspiration from boundary methods and uses edge graph convolution relay on the boundary proposals' feature. First, we use a base layer to fusion the two-stream video features to get two-branches of base features. Then the two-branches of base features enter into the same structure of Proposal Features Graph Convolutional Network (PFGCN): Action PFGCN to extract the action classification score and Boundary PFGCN to extract the ending score and staring score. In proposal features graph convolutional network, we first densely sampled the proposals' feature from the video features. We construct a proposal feature graph, where each proposal feature as a node and their relations between proposals' features as an edge with edge convolution for graph convolution. After that, map the relations into a 2D map score. Experiments on popular benchmarks THUMOS14 demonstrate the superiority of BGCN over (44.8% versus 42.8% at tIoU 0.5) the state-of-the-art proposal generator (e.g., G-TAD, TAL-Net, and BMN) at any of tIoU thresholds from 0.3 to 0.7. On ActivityNet1.3, BGCN also got better results. Moreover, BGCN has high efficiency for action detection with less than 2 MB model size and fast inference time.
   GCN based on boundary generation for densely produce the action proposals Efficient and novel BGCN model has a great capability to learn the proposal features Has a lower model size for temporal action proposals generation Has fast inference time for temporal action proposals generation.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Chen, Yaosen; Guo, Bing; Wang, Wei; Suo, Xinhua] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
   [Chen, Yaosen; Wang, Wei; Lu, Weichen] ChengDu Sobey Digital Technol Co Ltd, Chengdu 610041, Sichuan, Peoples R China.
   [Shen, Yan] Chengdu Univ Informat Technol, Sch Comp Sci, Chengdu 610225, Sichuan, Peoples R China.
   [Wang, Wei] Peng Cheng Lab, Shenzhen 518055, Peoples R China.
C3 Sichuan University; Chengdu University of Information Technology; Peng
   Cheng Laboratory
RP Guo, B (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
EM chenyaosen@stu.scu.edu.cn; guobing@scu.edu.cn; sheny@cuit.edu.cn;
   wangwei@sobey.com; luweichen@sobey.com
OI Chen, Yaosen/0000-0002-7212-1755
FU National Natural Science Foundation of China [61772352]; Science and
   Technology Planning Project of Sichuan Province [2019YFG0400,
   2018GZDZX0031, 2018GZDZX0004, 2017GZDZX0003,
   2018JY0182,19ZDYF1286,2020YFG0322]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 61772352; the Science and Technology
   Planning Project of Sichuan Province under Grant No. 2019YFG0400,
   2018GZDZX0031, 2018GZDZX0004, 2017GZDZX0003,
   2018JY0182,19ZDYF1286,2020YFG0322.
CR [Anonymous], 2018, P IEEE CVF C COMP VI
   [Anonymous], 2016, CUHK & ETHZ & SIAT submission to ActivityNet challenge 2016
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Buch S., 2017, BMVC
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Chen M, 2011, INT CONF CLOUD COMPU, P316, DOI 10.1109/CCIS.2011.6045082
   Chen Y, 2021, SURF ENG, V37, P926, DOI 10.1080/02670844.2020.1800346
   Chuang Gan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5589, DOI 10.1109/CVPR.2018.00586
   Dai J., 2021, ICLR
   Dai XY, 2017, IEEE I CONF COMP VIS, P5727, DOI 10.1109/ICCV.2017.610
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan X., 2018, ADV NEURAL INFORM PR, P3059
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Fan LL, 2018, CARDIOL YOUNG, V28, P1410, DOI 10.1017/S1047951118001403
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Feichtenhofer Christoph, 2018, ARXIV181203982, V34, P11948
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Gao Z., 2017, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.31.92
   Gkioxari G, 2019, IEEE I CONF COMP VIS, P9784, DOI 10.1109/ICCV.2019.00988
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Kipf Thomas N, 2017, 5 INT C LEARN REPR I, P3
   Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P4626
   Lin CRN, 2020, AAAI CONF ARTIF INTE, V34, P11499
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Liu XY, 2019, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2019.00440
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Roheda S, 2020, AAAI CONF ARTIF INTE, V34, P11948
   Rong Yu, 2019, 8 INT C LEARNING REP
   Shou Zheng, 2017, P IEEE C COMP VIS PA
   Shou Zheng, 2017, P IEEE C COMP VIS PA, P5734, DOI DOI 10.48550/ARXIV.1703.01515
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Singh Gurkirt, 2016, ACTIVITYNET LARGE SC, V6
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan MK, 2015, PROC CVPR IEEE, P4100, DOI 10.1109/CVPR.2015.7299037
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Xie ZY, 2020, NEUROCOMPUTING, V402, P245, DOI 10.1016/j.neucom.2020.03.086
   Xiong Yuanjun, 2017, P IEEE C COMP VIS PA, P6
   Xu HZ, 2017, PROC CVPR IEEE, P3530, DOI 10.1109/CVPR.2017.376
   Xu M., 2020, CVPR, P10156
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zheng S, 2016, PROC CVPR IEEE, P4480, DOI 10.1109/CVPR.2016.485
NR 57
TC 9
Z9 9
U1 1
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104144
DI 10.1016/j.imavis.2021.104144
EA MAR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600007
DA 2024-07-18
ER

PT J
AU Jiang, ZH
   Wang, X
   Huang, X
   Li, H
AF Jiang, Zhihong
   Wang, Xin
   Huang, Xiao
   Li, Hui
TI Triangulate geometric constraint combined with visual-flow fusion
   network for accurate 6DoF pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 6D object pose estimation; Iterative translation refinement; Triangulate
   geometric constraint; Visual-flow feature fusion
ID SYSTEM
AB Estimating the 6D object pose based on a monocular RGB image is a challenging task in computer vision, which produces false positives under the influence of occlusion or cluttered environments. In addition, the prediction of translation is affected by changes of the image size. In this work, we present a novel two-stage method TGCPose6D for robust 6DoF object pose estimation which is composed of 2D keypoint detection and translation refinement. In the first stage, the 2D keypoint regression space is constrained by triangulate geometric feature vectors, and the low-quality prediction is suppressed by the center-heatmap weighted loss function, thereby the performance of keypoint detection is significantly improved. In the second stage, the Visual-Flow Fusion network (VFFNet) is used to extract the visual feature and optical flow feature of the rendered image and the observed image, and to predict the relative translation based on the difference of features. Specifically, the VFFNet is trained iteratively to gain the ability to predict the relative translation deviation. Extensive experiments are conducted to demonstrate the effectiveness of the proposed TGCPose6D method. Our overall pose estimation pipeline outperforms state-of-the-art object pose estimation methods on several benchmarks.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Jiang, Zhihong; Wang, Xin; Huang, Xiao; Li, Hui] Beijing Inst Technol, Sch Mechatron Engn, Beijing, Peoples R China.
   [Jiang, Zhihong; Wang, Xin; Huang, Xiao; Li, Hui] Adv Innovat Ctr Intelligent Robots & Syst, Beijing, Peoples R China.
   [Jiang, Zhihong; Wang, Xin; Huang, Xiao; Li, Hui] Key Lab Biomimet Robots & Syst Chinese Minist Edu, Beijing, Peoples R China.
C3 Beijing Institute of Technology
RP Huang, X; Li, H (corresponding author), Beijing Inst Technol, Sch Mechatron Engn, Beijing, Peoples R China.
EM 7520200120@bit.edu.cn; lihui2011@bit.edu.cn
RI Zhang, Y J/HLG-1022-2023
FU National Key Research and Development Program of China [2018YFB1305300];
   National Natural Science Foundation of China [61733001, 61873039,
   U1713215, U1913211, U2013602]; China Postdoctoral Science Foundation
   [2020TQ0039]
FX This research was partially supported by the National Key Research and
   Development Program of China (2018YFB1305300), the National Natural
   Science Foundation of China (61733001, 61873039, U1713215, U1913211,
   U2013602), and the China Postdoctoral Science Foundation under Grant
   (2020TQ0039).
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Bui M, 2018, IEEE INT CONF ROBOT, P6140, DOI 10.1109/ICRA.2018.8460654
   Calli B., 2015, 2015 INT C ADV ROB I
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Cheng LS, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102638
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Ferrari V., 2018, LECT NOTES COMPUTER, P125, DOI [10.1007/978-3-030-01267-0, DOI 10.1007/978-3-030-01267-0]
   Fu ML, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051032
   Gu CH, 2010, LECT NOTES COMPUT SC, V6315, P408
   Gupta Kartik, 2019, P IEEE INT C COMP VI
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Hu Y., 2020, 2019 IEEE CVF C COMP
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Li YY, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.10.005
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Manhardt F, 2018, LECT NOTES COMPUT SC, V11218, P833, DOI 10.1007/978-3-030-01264-9_49
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Pavlakos G, 2017, LAW PRACT REASON, P113
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Tulsiani S, 2015, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2015.7298758
   Wang LS, 2018, IEEE ACCESS, V6, P50683, DOI 10.1109/ACCESS.2018.2869325
   Xiang Yu, 2017, ARXIV171100199
   Xu XX, 2008, INT HIGH LEVEL DESIG, P3, DOI 10.1109/HLDVT.2008.4695865
   Zhao WQ, 2020, NEUROCOMPUTING, V389, P9, DOI 10.1016/j.neucom.2019.12.108
   Zhu ML, 2014, IEEE INT CONF ROBOT, P3936, DOI 10.1109/ICRA.2014.6907430
NR 35
TC 7
Z9 7
U1 2
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104127
DI 10.1016/j.imavis.2021.104127
EA FEB 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600013
DA 2024-07-18
ER

PT J
AU Schutera, M
   Hafner, FM
   Abhau, J
   Hagenmeyer, V
   Mikut, R
   Reischl, M
AF Schutera, Mark
   Hafner, Frank M.
   Abhau, Jochen
   Hagenmeyer, Veit
   Mikut, Ralf
   Reischl, Markus
TI Cuepervision: self-supervised learning for continuous domain adaptation
   without catastrophic forgetting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Domain adaptation; Self-supervised learning; Unsupervised learning;
   Continuous transfer learning; Catastrophic forgetting; MNIST dataset
AB Perception systems, to a large extent, rely on neural networks. Commonly, the training of neural networks uses a finite amount of data. The usual assumption is that an appropriate training dataset is available, which covers all relevant domains. This abstract will follow the example of different lighting conditions in autonomous driving scenarios. In real-world datasets, a single source domain, such as day images, often dominates the dataset composition. This poses a risk to overfit on specific source domain features within the dataset, and implicitly breaches the assumption of full or relevant domain coverage. While applying the model to data outside of the source domain, the performance drops, posing a significant challenge for data-driven methods. A common approach is supervised retraining of the model on additional data. Supervised training requires the laborious acquisition and labeling of an adequate amount of data and often becomes infeasible when data augmentation strategies are not applicable. Furthermore, retraining on additional data often causes a performance drop in the source domain, so-called catastrophic forgetting. In this paper, we present a self-supervised continuous domain adaptation method. A model trained supervised on the source domain (day) is used to generate pseudo labels on the samples of an adjacent target domain (dawn). The pseudo labels and samples enable to fine-tune the existing model, which, as a result, is adapted into the intermediate domain. By iteratively repeating these steps, the model reaches the target domain (night). The results, of the novel method, on the MNIST dataset and its modification, the continuous rotatedMNIST dataset demonstrate a domain adaptation of 86.2%, and a catastrophic forgetting of only 1.6% in the target domain. The work contributes a hyperparameter ablation study, analysis, and discussion of the new learning strategy. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Schutera, Mark; Hagenmeyer, Veit; Mikut, Ralf; Reischl, Markus] Karlsruhe Inst Technol, Inst Automat & Appl Informat, Karlsruhe, Germany.
   [Schutera, Mark; Hafner, Frank M.; Abhau, Jochen] ZF, Res & Dev, Friedrichshafen, AG, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Schutera, M (corresponding author), Karlsruhe Inst Technol, Inst Automat & Appl Informat, Karlsruhe, Germany.; Schutera, M (corresponding author), ZF, Res & Dev, Friedrichshafen, AG, Germany.
EM mark.schutera@kit.edu; frank.hafner@zf.com; jochen.abhau@zf.com;
   veit.hagenmeyer@kit.edu; ralf.mikut@kit.edu; markus.reischl@kit.edu
RI Reischl, Markus/H-6970-2013; Mikut, Ralf/A-5949-2013
OI Reischl, Markus/0000-0002-7780-6374; Mikut, Ralf/0000-0001-9100-5496
FU Federal Ministry for Economic Affairs and Energy
FX The research leading to these results is funded by the Federal Ministry
   for Economic Affairs and Energy within the project "AI Delta Learning -
   Development of methods and tools for the efficient expansion and
   transformation of existing AI modules of autonomous vehicles to new
   domains". The authors would like to thank the consortium for the
   successful cooperation. We want to thank our fellow researchers at
   Karlsruhe Institute of Technology and our colleagues at ZF
   Friedrichshafen AG.
CR Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bobu A., 2018, 6 INT C LEARN REPR W
   Bousmalis K, 2016, ADV NEUR IN, V29
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Cheung B., 2019, P ADV NEURAL INFORM
   Chopra S., 2013, ICML WORKSH CHALL RE, P1
   Ganin Y., 2015, ICML
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hamidi M, 2010, MACH VISION APPL, V21, P969, DOI 10.1007/s00138-009-0216-9
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jing L., 2019, ARXIV PREPRINT, DOI 10.1109/TPAMI.2020.2992393
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma D. P., 2014, arXiv
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kumar A., ARXIV200211361
   Lee D.H, WORKSH CHALL REPR LE, P2
   Li D, 2016, LECT NOTES COMPUT SC, V9908, P678, DOI 10.1007/978-3-319-46493-0_41
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI [10.1016/S0079-7421(08)60536-8, DOI 10.1016/S0079-7421(08)60536-8]
   Noroozi M, 2018, PROC CVPR IEEE, P9359, DOI 10.1109/CVPR.2018.00975
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29
   Rusu A.A, 2016, arXiv preprint, P1
   Schutera M, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909858
   Schutera M, 2019, AT-AUTOM, V67, P545, DOI 10.1515/auto-2018-0124
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wulfmeier M, 2018, IEEE INT CONF ROBOT, P4489
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Yu F., 2018, arXiv preprint arXiv:1805.04687
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 39
TC 5
Z9 5
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104079
DI 10.1016/j.imavis.2020.104079
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700011
DA 2024-07-18
ER

PT J
AU Mittal, P
   Singh, R
   Sharma, A
AF Mittal, Payal
   Singh, Raman
   Sharma, Akashdeep
TI Deep learning-based object detection in low-altitude UAV datasets: A
   survey
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Object detection; Unmanned aerial vehicles; Computer
   vision; Low-altitude aerial datasets
ID VEHICLE DETECTION; COMPUTER VISION; AERIAL
AB Deep learning-based object detection solutions emerged from computer vision has captivated full attention in recent years. The growing UAV market trends and interest in potential applications such as surveillance, visual navigation, object detection, and sensors-based obstacle avoidance planning have been holding good promises in the area of deep learning. Object detection algorithms implemented in deep learning framework have rapidly became a method for processing of moving images captured from drones. The primary objective of the paper is to provide a comprehensive review of the state of the art deep learning based object detection algorithms and analyze recent contributions of these algorithms to low altitude UAV datasets. The core focus of the studies is low-altitude UAV datasets because relatively less contribution was seen in the literature when compared with standard or remote-sensing based datasets. The paper discusses the following algorithms: Faster RCNN, Cascade RCNN, R-FCN etc. into two-stage, YOLO and its variants, SSD, RetinaNet into one-stage and CornerNet, Objects as Point etc. under advanced stages in deep learning based detectors. Further, one-two and advanced stages of detectors are studied in detail focusing on low-altitude UAV datasets. The paper provides a broad summary of low altitude datasets along with their respective literature in detection algorithms for the potential use of researchers. Various research gaps and challenges for object detection and classification in UAV datasets that need to deal with for improving the performance are also listed. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Mittal, Payal; Sharma, Akashdeep] Panjab Univ, UIET, Chandigarh, India.
   [Singh, Raman] Thapar Inst Engn & Technol, CSED, Patiala, Punjab, India.
C3 Panjab University; Thapar Institute of Engineering & Technology
RP Sharma, A (corresponding author), Panjab Univ, UIET, Chandigarh, India.
EM payalmittal6792@gmail.com; raman.singh@thapar.edu; akashdeep@pu.ac.in
RI Sharma, Akashdeep/GLU-0641-2022
OI mittal, payal/0000-0001-6187-7509; Singh, Raman/0000-0002-6839-5454
CR Adams S.M., 2011, 9 INT WORKSHOP REMOT, P8
   Agarwal S., 2018, ARXIV180903193, P1
   Aker C, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2017.8078539
   Al-Kaff A., 2017, EXPERT SYST APPL
   Andriluka M, 2010, IEEE INT C INT ROBOT, P1740, DOI 10.1109/IROS.2010.5649223
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2014, INTERACT ANAL NEW VE
   Barekatain M, 2017, IEEE COMPUT SOC CONF, P2153, DOI 10.1109/CVPRW.2017.267
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bondi Elizabeth., 2018, Proceedings of the 1st ACM SIGCAS Conference on Computing and Sustainable Societies, page, P40
   Brunetti A, 2018, NEUROCOMPUTING, V300, P17, DOI 10.1016/j.neucom.2018.01.092
   Campbell S, 2012, ANNU REV CONTROL, V36, P267, DOI 10.1016/j.arcontrol.2012.09.008
   Chen JJ, 2017, CHIN AUTOM CONGR, P2109, DOI 10.1109/CAC.2017.8243120
   Chen KQ, 2018, IEEE GEOSCI REMOTE S, V15, P173, DOI 10.1109/LGRS.2017.2778181
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Cohn P., 2017, Commercial drones are here: the future of unmanned aerial systems
   Colomina I, 2014, ISPRS J PHOTOGRAMM, V92, P79, DOI 10.1016/j.isprsjprs.2014.02.013
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dipert Brian, 2017, VISION PROCESSING OP
   Dollar K.H.G.G.P., 2017, MASK R CNN
   Du Terrail JO, 2017, IEEE IMAGE PROC, P4212, DOI 10.1109/ICIP.2017.8297076
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Gaszczak A, 2011, PROC SPIE, V7878, DOI 10.1117/12.876663
   George Eobin Alex, 2013, 2013 IEEE Global Humanitarian Technology Conference: South Asia Satellite (GHTC-SAS), P270, DOI 10.1109/GHTC-SAS.2013.6629929
   Ghiasi G, 2018, ADV NEUR IN, V31
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gusikhin O., 2008, INFORM CONTROL AUTOM, P3, DOI DOI 10.1007/978-3-540-79142-3_1
   Haye K., 2019, DRONES REPORTING WOR
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Hsieh ML, 2017, TAIDA J ART HIST, P1, DOI 10.6541/TJAH.2017.03.42.01
   Hsu H.-J., 2015, P 1 WORKSHOP MICROAE, P39, DOI DOI 10.1145/2750675.2750679
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C, 2017, IEEE INT C INT ROBOT, P1725, DOI 10.1109/IROS.2017.8205985
   Hung HT, 2019, ASIAPAC SIGN INFO PR, P339, DOI [10.1109/APSIPAASC47483.2019.9023224, 10.1109/apsipaasc47483.2019.9023224]
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Iuga C, 2018, IFAC PAPERSONLINE, V51, P199, DOI 10.1016/j.ifacol.2018.06.262
   Jin R., 2019, IEEE GEOSCI REMOTE S
   Kanellakis C, 2017, J INTELL ROBOT SYST, V87, P141, DOI 10.1007/s10846-017-0483-z
   Kaster J, 2017, PROC NAECON IEEE NAT, P149, DOI 10.1109/NAECON.2017.8268760
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar, 2019, ARXIV190600786
   Kyrkou C, 2018, DES AUT TEST EUROPE, P967, DOI 10.23919/DATE.2018.8342149
   Law H., 2019, Cornernet-lite: Efficient keypoint based object detection
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   LeCun Y., 2015, Lenet-5, convolutional neural networks
   Li CC, 2020, NEURAL COMPUT APPL, V32, P16795, DOI 10.1007/s00521-018-3909-z
   Li Q, 2018, APPL ENVIRON MICROB, V84, DOI 10.1128/AEM.02680-17
   Li Suhao, 2018, Procedia Computer Science, V131, P564, DOI 10.1016/j.procs.2018.04.281
   Li ZB, 2016, REMOTE SENS ENVIRON, V187, P76, DOI 10.1016/j.rse.2016.10.008
   LI ZY, 2017, ARXIV171107264, V105, P1289, DOI DOI 10.1109/JPROC.2017.2685558
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ling H., 2018, Vision Meets Drones: A Challenge
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   McNeal G.S., 2014, Drones and Aerial Surveillance: Considerations for Legislators
   Meier D, 2015, IEEE INT C INT ROBOT, P2473, DOI 10.1109/IROS.2015.7353713
   Miller A, 2008, LECT NOTES COMPUT SC, V4625, P215
   Moranduzzo T, 2014, IEEE T GEOSCI REMOTE, V52, P1635, DOI 10.1109/TGRS.2013.2253108
   Müller R, 2019, ADV NEUR IN, V32
   Nguyen H. B., 2018, MEMET COMPUT, P1
   Oh S., 2011, P CVPR, P3153, DOI DOI 10.1109/CVPR.2011.5995586
   Olsson PM, 2010, I C CONT AUTOMAT ROB, P1070, DOI 10.1109/ICARCV.2010.5707968
   Ouyang W., 2014, P IEEE C COMP VIS PA, P346
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Pailla D. R., 2019, P IEEECVF INT C COMP
   Park J, 2017, INT C CONTR AUTOMAT, P696, DOI 10.23919/ICCAS.2017.8204318
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Puri A., 2005, Ph.D. dissertation, P1
   Qu T, 2017, MULTIMED TOOLS APPL, V76, P21651, DOI 10.1007/s11042-016-4043-5
   Rathinam S, 2007, P AMER CONTR CONF, P2035
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ruth L., 2019, REGULATION DRONES CO
   Semsch E, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P82
   Seo C.-J., 2016, INDIAN J SCI TECHNOL, V9
   Soleimani A, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1005, DOI 10.23919/ICIF.2018.8455494
   Su A, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.096063
   Sugimura D, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550090
   Sun SH, 2013, IEEE J-STARS, V6, P1440, DOI 10.1109/JSTARS.2013.2251457
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang TY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020336
   Tang ZY, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abbf9e
   Teutsch M, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P265, DOI 10.1109/AVSS.2014.6918679
   Thornton S., 2008, P 1 WORKSH HUM DET M
   Todorovic S, 2004, IEEE T VEH TECHNOL, V53, P1713, DOI 10.1109/TVT.2004.834880
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tzelepi M, 2017, EUR SIGNAL PR CONF, P743, DOI 10.23919/EUSIPCO.2017.8081306
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang F, 2019, MICRO NANO TECHNOL, P1, DOI 10.1016/B978-0-12-813647-8.00001-1
   Wang HY, 2017, I S INTELL SIG PROC, P713, DOI 10.1109/ISPACS.2017.8266569
   Wang JW, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P439, DOI 10.23919/ICIF.2018.8455565
   Wang S., 2011, INT C COMP INF TECHN, P171
   Wang XP, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/8696910
   Wu X, 2022, NEURAL COMPUT APPL, V34, P11491, DOI 10.1007/s00521-020-04873-z
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xianbin Cao, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2421, DOI 10.1109/ICIP.2011.6116132
   Xu BW, 2017, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION AND INFORMATION PROCESSING (ICCIP 2017), P484, DOI 10.1145/3162957.3163039
   Xu YZ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081325
   Yang F, 2019, IEEE I CONF COMP VIS, P8310, DOI 10.1109/ICCV.2019.00840
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang J, 2019, IEEE I CONF COMP VIS, P1685, DOI 10.1109/ICCV.2019.00177
   Zhang JS, 2017, INT CONF MACH LEARN, P189
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XD, 2019, IEEE INT CONF COMP V, P118, DOI 10.1109/ICCVW.2019.00020
   Zhao T, 2003, IMAGE VISION COMPUT, V21, P693, DOI 10.1016/S0262-8856(03)00064-7
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou JK, 2019, NEUROCOMPUTING, V366, P305, DOI 10.1016/j.neucom.2019.07.073
   Zhou XZ, 2019, AIP CONF PROC, V2106, DOI 10.1063/1.5109324
   Zhou ZP, 2018, J MANAGE ENG, V34, DOI 10.1061/(ASCE)ME.1943-5479.0000597
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 123
TC 123
Z9 127
U1 14
U2 109
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104046
DI 10.1016/j.imavis.2020.104046
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800001
DA 2024-07-18
ER

PT J
AU Huang, EB
   Su, Z
   Zhou, F
   Wang, RM
AF Huang, Enbo
   Su, Zhuo
   Zhou, Fan
   Wang, Ruomei
TI Learning rebalanced human parsing model from imbalanced datasets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human parsing; Semantic segmentation; Imbalanced datasets
ID SEGMENTATION
AB Research on human parsing methods has attracted increasing attention in a wide range of applications. However, dataset imbalance is still a challenging problem in this task, which directly affects the performance of human parsing. There are different types of dataset imbalance problems. For example, the numbers of samples for various labels in a dataset may differ, the scales of objects identified by different labels may vary considerably, the differences between some heterogeneous label types may be much smaller than other cases, and in some extreme situations, images may be labeled incorrectly. In this paper, we propose a rebalanced model for imbalanced human parsing. Two innovative blocks are included in the model, i.e., a pre-bilateral awareness block and a combined-order statistics awareness block. The function of the former is to leverage the multiscale feature extractors to capture the changing scale information in an efficient way from the spatial space. Meanwhile, the function of the latter is to exploit the information of the feature distributions from the channel space. Furthermore. we propose an imbalance data-drop algorithm to simultaneously solve the mislabeling and small sample label weighting problems. Extensive experiments are conducted on three datasets, and the experimental results demonstrate that our method is able to solve the problem of data imbalance efficiently and obtain better human parsing performance. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Huang, Enbo; Su, Zhuo; Zhou, Fan; Wang, Ruomei] Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, Sch Data & Comp Sci, Guangzhou, Peoples R China.
C3 Sun Yat Sen University
RP Su, Z (corresponding author), Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, Sch Data & Comp Sci, Guangzhou, Peoples R China.
EM huangenb@mail2.sysu.edu.cn; suzhuo3@mail.sysu.edu.cn;
   isszf@mail.sysu.edu.cn; isswrm@mail.sysu.edu.cn
RI Su, Zhuo/AAO-4506-2020; Zhou, fan/KIL-4066-2024
OI Su, Zhuo/0000-0002-6090-0110; 
FU National Natural Science Foundation of China [61872394, 61672547,
   61772140]; Guangzhou science and technology plan project [201902010056]
FX This research is supported by the National Natural Science Foundation of
   China (61872394, 61672547, 61772140) and Guangzhou science and
   technology plan project (201902010056).
CR Agarwal N, 2017, J MACH LEARN RES, V18
   [Anonymous], 2017, ADV NEURAL INFORM PR
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], 2014, P ASIAN C COMP VIS A
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Dong H, 2019, IEEE I CONF COMP VIS, P9025, DOI 10.1109/ICCV.2019.00912
   Dong J, 2016, IEEE T PATTERN ANAL, V38, P88, DOI 10.1109/TPAMI.2015.2420563
   Dong Q, 2017, IEEE I CONF COMP VIS, P1869, DOI 10.1109/ICCV.2017.205
   Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Levina Elizaveta, 2004, Advances in neural information processing systems, V17
   Li H., 2018, ARXIV
   Liang X., 2019, IEEE T PATTERN ANAL, V41
   Liang XD, 2015, IEEE I CONF COMP VIS, P1386, DOI 10.1109/ICCV.2015.163
   Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360
   Lin FQ, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103864
   LIU S, 2015, PROC CVPR IEEE, P1419, DOI DOI 10.1109/CVPR.2015.7298748
   Liu S, 2018, AAAI CONF ARTIF INTE, P7146
   Liu S, 2015, IEEE T MULTIMEDIA, V17, P1347, DOI 10.1109/TMM.2015.2443559
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Luo XH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P654, DOI 10.1145/3240508.3240634
   Luo Y, 2018, 2018 IEEE 4TH INTERNATIONAL CONFERENCE ON CONTROL SCIENCE AND SYSTEMS ENGINEERING (ICCSSE 2018), P417, DOI 10.1109/CCSSE.2018.8724798
   Ly TS, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.10.003
   Matkowski WM, 2019, IMAGE VISION COMPUT, V88, P96, DOI 10.1016/j.imavis.2019.05.005
   Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P519, DOI 10.1007/978-3-030-01228-1_31
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Ruan T, 2019, AAAI CONF ARTIF INTE, P4814
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang TY, 2018, PROC INT C TOOLS ART, P39, DOI 10.1109/ICTAI.2018.00017
   Wu Y, 2018, IMAGE VISION COMPUT, V79, P123, DOI 10.1016/j.imavis.2018.09.010
   Wu ZH, 2019, IMAGE VISION COMPUT, V91, DOI 10.1016/j.imavis.2019.08.005
   Yamaguchi K, 2015, IEEE T PATTERN ANAL, V37, P1028, DOI 10.1109/TPAMI.2014.2353624
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407
   Zhao J, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P792, DOI 10.1145/3240508.3240509
   Zhao J, 2017, IEEE COMPUT SOC CONF, P1595, DOI 10.1109/CVPRW.2017.204
   Zhu BK, 2018, AAAI CONF ARTIF INTE, P7607
NR 40
TC 6
Z9 6
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2020
VL 99
AR 103928
DI 10.1016/j.imavis.2020.103928
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LZ3LW
UT WOS:000541130800004
DA 2024-07-18
ER

PT J
AU Lin, YG
AF Lin, Yigang
TI Automatic recognition of image of abnormal situation in scenic spots
   based on Internet of things
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Internet of things; Scenic spots; Abnormal situations; Image recognition
ID ALGORITHM; TRACKING; MODEL
AB Internet of things is an emerging information-aware technology that combines computer vision and artificial intelligence technology to ensure the safety of personnel and facilities in tourist attractions by discovering real-time alarms of abnormal conditions in the monitoring of tourist attractions. Therefore, this paper proposes an automatic image algorithm for tourism scene anomaly based on Internet of things. The algorithm uses the Internet of things intelligent camera in the image acquisition preprocessing platform to collect the tourist scenic spot image. Based on the traditional image segmentation technology, according to the neighborhood-related characteristics of the Markov random field, the dynamic characteristics of continuous frames are added. Reconstruct the Gibbs energy function. The location of the abnormal situation is determined by coding, and a treatment opinion is given. The experimental results show that the proposed algorithm not only considers the spatial information of each pixel and neighboring points, but also adds the time information of successive frames, accumulates the energy values of all the pixels in the whole image and analyzes the data with the energy curve. It can accurately and efficiently identify the abnormal situation images of tourist attractions. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Lin, Yigang] Sichuan Int Studies Univ, Dept Sociol & Law, Chongqing 400031, Peoples R China.
C3 Sichuan International Studies University
RP Lin, YG (corresponding author), Sichuan Int Studies Univ, Dept Sociol & Law, Chongqing 400031, Peoples R China.
EM xtlyg1019@163.com
CR [Anonymous], 2019, J HARBIN I TECHNOLOG
   Chen Jin Chen Jin, 2018, Transactions of the Chinese Society of Agricultural Engineering, V34, P187
   Chen MC, 2018, ACTA MATH APPL SIN-E, V34, P398, DOI 10.1007/s10255-018-0740-3
   Corker-Marin Q, 2018, IEEE COMPUT GRAPH, V38, P131, DOI 10.1109/MCG.2018.032421660
   Deena S, 2019, IEEE-ACM T AUDIO SPE, V27, P572, DOI 10.1109/TASLP.2018.2888814
   Du XF, 2018, IEEE T MED IMAGING, V37, P1276, DOI 10.1109/TMI.2017.2787672
   Feng L, 2018, ACTA MATER, V142, P121, DOI 10.1016/j.actamat.2017.09.002
   Guan WP, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2841979
   Hellier C, 1997, MON NOT R ASTRON SOC, V292, P397, DOI 10.1093/mnras/292.2.397
   Jin TT, 2019, FRONT INFORM TECH EL, V20, P253, DOI 10.1631/FITEE.1700462
   Li Z., 2018, GEOPHYS J INT, V205, P1326
   Li ZW, 2019, IEEE NETWORK, V33, P96, DOI 10.1109/MNET.2019.1800366
   Lim Kwan Hui, 2017, KNOWL INF SYST, P1
   Lim VF, 2019, SOC SEMIOT, V29, P83, DOI 10.1080/10350330.2017.1412168
   Lin WP, 2018, SUSTAIN CITIES SOC, V37, P541, DOI 10.1016/j.scs.2017.12.003
   Liu B, 2017, TOURISM MANAGE, V58, P132, DOI 10.1016/j.tourman.2016.10.009
   Liu JC, 2013, INT J COMPUT SCI ENG, V8, P324
   Liu WX, 2019, IET POWER ELECTRON, V12, P358, DOI 10.1049/iet-pel.2018.5262
   Liu Z, 2019, IEEE T ULTRASON FERR, V66, P701, DOI 10.1109/TUFFC.2019.2895374
   Mbaiwa JE, 2018, S AFR GEOGR J, V100, P41, DOI 10.1080/03736245.2017.1299639
   Nsengiyumva W, 2018, RENEW SUST ENERG REV, V81, P250, DOI 10.1016/j.rser.2017.06.085
   Oliveira SP, 2017, COMPUT GEOSCI-UK, V103, P80, DOI 10.1016/j.cageo.2017.02.006
   Poblete B, 2018, IEEE T MULTIMEDIA, V20, P2551, DOI 10.1109/TMM.2018.2855107
   Qing CM, 2019, IET IMAGE PROCESS, V13, P235, DOI 10.1049/iet-ipr.2018.5727
   Ramadan A, 2019, IEEE T NEUR SYS REH, V27, P275, DOI 10.1109/TNSRE.2019.2891525
   Sharif A, 2019, IEEE INTERNET THINGS, V6, P3962, DOI 10.1109/JIOT.2019.2893677
   Sun H, 2020, IEEE SENS J, V20, P11753, DOI 10.1109/JSEN.2019.2933200
   Sun YG, 2020, IEEE T IND INFORM, V16, P2629, DOI 10.1109/TII.2019.2938145
   Sun YG, 2019, IEEE T IND ELECTRON, V66, P8589, DOI 10.1109/TIE.2019.2891409
   Wang H., 2018, SENS LETT, V16, P110
   Wu X., 2015, HOUSEHOLD SERVICE RO, V55, P35
   Xie Q., 2018, CEJOR, V26, P1
   Yan RQ, 2019, CLUSTER COMPUT, V22, pS3543, DOI 10.1007/s10586-018-2202-3
   Yang F, 2019, IEEE ACCESS, V7, P15478, DOI 10.1109/ACCESS.2019.2895376
   Zeng F, 2019, IEEE ACCESS, V7, P14523, DOI 10.1109/ACCESS.2019.2893184
   Zhan TM, 2019, IEEE ACCESS, V7, P11868, DOI 10.1109/ACCESS.2019.2891938
   Zhang X, 2018, IEEE GEOSCI REMOTE S, V15, P3, DOI 10.1109/LGRS.2017.2759963
NR 37
TC 6
Z9 6
U1 4
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2020
VL 96
AR 103908
DI 10.1016/j.imavis.2020.103908
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YN
UT WOS:000527905200004
DA 2024-07-18
ER

PT J
AU Hicsonmez, S
   Samet, N
   Akbas, E
   Duygulu, P
AF Hicsonmez, Samet
   Samet, Nermin
   Akbas, Emre
   Duygulu, Pinar
TI GANILLA: Generative adversarial networks for image to illustration
   translation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Generative adversarial networks; Image to image translation;
   Illustrations style transfer
AB In this paper, we explore illustrations in children's books as a new domain in unpaired image-to-image translation. We show that although the current state-of-the-art image-to-image translation models successfully transfer either the style or the content, they fail to transfer both at the sametime. We propose a new generator network to address this issue and show that the resulting network strikes a better balance between style and content. There are no well-defined or agreed-upon evaluation metrics for unpaired image-to-image translation. So far, the success of image translation models has been based on subjective, qualitative visual comparison on a limited number of images. To address this problem, we propose a new framework for the quantitative evaluation of image-to-illustration models, where both content and style are taken into account using separate classifiers. In this new evaluation framework, our proposed model performs better than the current state-of-the-art models on the illustrations dataset. Our code and pretrained models can be found at https://github.com/giddyyupp/ganilla. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Hicsonmez, Samet; Duygulu, Pinar] Hacettepe Univ, Ankara, Turkey.
   [Samet, Nermin; Akbas, Emre] Middle East Tech Univ, Ankara, Turkey.
C3 Hacettepe University; Middle East Technical University
RP Hicsonmez, S (corresponding author), Hacettepe Univ, Ankara, Turkey.
EM samethicsonmez@hacettepe.edu.tr; nermin.samet@metu.edu.tr;
   emre@ceng.metu.edu.tr; pinar@cs.hacettepe.edu.tr
RI Hicsonmez, Samet/ABA-3885-2020; Samet, Nermin/ABA-3888-2020; Akbas,
   Emre/B-6857-2008; A, Sam/GXH-7864-2022
OI Hicsonmez, Samet/0000-0002-4831-4362; Samet, Nermin/0000-0001-9247-2504;
   Akbas, Emre/0000-0002-3760-6722; 
CR Alharbi Y, 2019, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2019.00155
   [Anonymous], ARXIV160601286
   [Anonymous], ARXIV180304469
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], ARXIV150806576
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ABS160708022 CORR
   [Anonymous], INT C LEARN REPR
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIV170108893
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], ABS170305192 CORR
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2019, IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], AUTOMATIC DIFFERENTI
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986
   Cho W, 2019, PROC CVPR IEEE, P10631, DOI 10.1109/CVPR.2019.01089
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Gatys L. A., IEEE C COMP VIS PATT
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hicsonmez S, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P343, DOI 10.1145/3078971.3078982
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Jing Y., ARXIV170504058
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karacan L., 2016, Learning to generate images of outdoor scenes from attributes and semantic layouts. arXiv preprint arXiv:1612.00215
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li SH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1716, DOI 10.1145/3123266.3123425
   Liu F, 2019, PROC CVPR IEEE, P5823, DOI 10.1109/CVPR.2019.00598
   Liu M.-Y., 2019, IEEE INT C COMP VIS
   Liu MY, 2017, ADV NEUR IN, V30
   Radford A., ABS151106434 CORR
   Tomei M, 2019, PROC CVPR IEEE, P5842, DOI 10.1109/CVPR.2019.00600
   Ulyanov D., 2016, P 33 INT C INT C MAC, V48, P1349
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Zhao J., ARXIV160903126
NR 41
TC 32
Z9 38
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103886
DI 10.1016/j.imavis.2020.103886
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Trokielewicz, M
   Czajka, A
   Maciejewicz, P
AF Trokielewicz, Mateusz
   Czajka, Adam
   Maciejewicz, Piotr
TI Post-mortem iris recognition with deep-learning-based image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Iris recognition; Post-mortem; Image segmentation
AB This paper proposes the first known to us iris recognition methodology designed specifically for postmortem samples. We propose to use deep learning-based iris segmentation models to extract highly irregular iris texture areas in post-mortem iris images. We show how to use segmentation masks predicted by neural networks in conventional, Gabor-based iris recognition method, which employs circular approximations of the pupillary and limbic iris boundaries. As a whole, this method allows for a significant improvement in post-mortem iris recognition accuracy over the methods designed only for ante-mortem irises, including the academic OSIRIS and commercial IriCore implementations. The proposed method reaches the EER less than 1% for samples collected up to 10 hours after death, when compared to 16.89% and 5.37% of EER observed for OSIRIS and IriCore, respectively. For samples collected up to 369 h post-mortem, the proposed method achieves the EER 21.45%, while 33.59% and 25.38% are observed for OSIRIS and IriCore, respectively. Additionally, the method is tested on a database of iris images collected from ophthalmology clinic patients, for which it also offers an advantage over the two other algorithms. This work is the first step towards post-mortem-specific iris recognition, which increases the chances of identification of deceased subjects in forensic investigations. The new database of post-mortem iris images acquired from 42 subjects, as well as the deep learning-based segmentation models are made available along with the paper, to ensure all the results presented in this manuscript are reproducible. (C) 2019 The Authors. Published by Elsevier B.V.
C1 [Trokielewicz, Mateusz] Res & Acad Comp Network, Biometr & Machine Intelligence Lab, Kolska 12, PL-01045 Warsaw, Poland.
   [Czajka, Adam] Univ Notre Dame, Dept Comp Sci, Notre Dame, IN 46556 USA.
   [Maciejewicz, Piotr] Med Univ Warsaw, Dept Ophthalmol, Lindleya 4, PL-02005 Warsaw, Poland.
C3 Research & Academic Computer Network (NASK); University of Notre Dame;
   Medical University of Warsaw
RP Trokielewicz, M (corresponding author), Res & Acad Comp Network, Biometr & Machine Intelligence Lab, Kolska 12, PL-01045 Warsaw, Poland.
EM mateusz.trokielewicz@nask.pl
OI Trokielewicz, Mateusz/0000-0002-7363-8385
CR [Anonymous], WARS BIOBASE POSTMOR
   [Anonymous], 2 IEEE INT C CYB CYB
   [Anonymous], EYEB SOL
   [Anonymous], MIT TECHNOLOGY REV
   [Anonymous], BIOMETRIC REFERENCE
   [Anonymous], WARS BIOBASE DIS IR
   [Anonymous], WARS BIOBASE POSTMOR
   [Anonymous], 9 IEEE INT C BIOM TH
   [Anonymous], 2001, BBC NEWS
   [Anonymous], BIOM ACC CONTR CAN I
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bolme D. S., 2016, INT CONF BIOMETR THE
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Hofbauer H, 2019, PATTERN RECOGN LETT, V120, P17, DOI 10.1016/j.patrec.2018.12.021
   IriTech Inc, 2013, IRICORE SOFTW DEV MA
   Kerrigan D, 2019, INT CONF BIOMETR, DOI 10.1109/icb45273.2019.8987299
   Sansola A., 2015, Postmortem iris recognition and its application in human identification
   Saripalle SK, 2015, INT CONF BIOMETR THE
   Sauerwein K, 2017, J FORENSIC SCI, V62, P1599, DOI 10.1111/1556-4029.13484
   Trokielewicz M., 2018, 2018 International Workshop on Biometrics and Forensics (IWBF), P1, DOI [10.1109/IWBF.2018.8401558, DOI 10.1109/IWBF.2018.8401558]
   Trokielewicz M, 2016, INT CONF BIOMETR
   Trokielewicz M, 2019, IEEE T INF FOREN SEC, V14, P1501, DOI 10.1109/TIFS.2018.2881671
   Trokielewicz M, 2016, INT CONF BIOMETR THE
NR 23
TC 37
Z9 41
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103866
DI 10.1016/j.imavis.2019.103866
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900008
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Raj, A
   Gautam, G
   Abdullah, SNHS
   Zaini, AS
   Mukhopadhyay, S
AF Raj, Aditya
   Gautam, Gunjan
   Abdullah, Siti Norul Huda Sheikh
   Zaini, Abbas Salimi
   Mukhopadhyay, Susanta
TI Multi-level thresholding based on differential evolution and Tsallis
   Fuzzy entropy
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multilevel thresholding; Tsallis-Fuzzy entropy; Differential evolution;
   Otsu entropy; Kapur entropy
ID IMAGE; SEGMENTATION; OPTIMIZATION; INTELLIGENCE; TESTS
AB This paper presents a multilevel image thresholding approach which relies on Tsallis entropy using Fuzz partition with a novel threshold selection technique. In order to compute the optimal threshold value Differential Evolution (DE) has been employed. The proposed method can further be exploited in image seg mentation which is considered to be a critical step in image processing. Our proposed threshold selectio technique is based on Tsallis-Fuzzy entropy and the results are compared with Shannon entropy (or fuzz entropy) and Tsallis entropy based existing threshold selection techniques. The experiments are performe on two different sets of images and the results have been compared with that of existing state-of-the-ai methods, namely, Patch Levy Bees' Algorithm (PLBA), Bacterial Foraging optimization (BFO), modified Bacterial Foraging optimization (MBFO) and Bees' Algorithm (BA). Quantitative analysis is carried out based o three image quality metrics viz SSIM, PSNR and SNR. Standard deviation and CPU time for convergence ( the objective function have been calculated for performance evaluation. Furthermore, the statistical significance of our method has been estimated using Friedman test and Wilcoxon test. The experimental result manifest that our method produces results superior to the methods in comparison. (C) 2019 Elsevier B.V. All rights reserved
C1 [Raj, Aditya; Gautam, Gunjan; Mukhopadhyay, Susanta] Indian Inst Technol ISM, Dhanbad 826004, Jharkhand, India.
   [Raj, Aditya; Abdullah, Siti Norul Huda Sheikh; Zaini, Abbas Salimi] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Cyber Secur, Digital Forens Lab, Bangi 43600, Selangor, Malaysia.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; Universiti Kebangsaan
   Malaysia
RP Abdullah, SNHS (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Cyber Secur, Digital Forens Lab, Bangi 43600, Selangor, Malaysia.
EM Aditya13raj@gmail.com; gunjan.2015dr165@cse.ism.ac.in;
   snhsabdullah@ukm.edu.my; abbassalimi@siswa.ukm.edu.my;
   msushanta2001@iitism.ac.in
RI Gautam, Gunjan/AAH-2637-2020; Sheikh Abdullah, Siti Norul
   Huda/J-7949-2015
OI Sheikh Abdullah, Siti Norul Huda/0000-0002-2602-7805
FU Ministry of Higher Education, Malaysia [UKM-AP-2017-005-2]
FX The author would like to thank the Ministry of Higher Education,
   Malaysia for providing facilities and financial support under
   Prototyping Research Grant Scheme No. UKM-AP-2017-005-2 entitled "Using
   STEM data through Smart self-crime prevention at schools for open data
   readiness". Not forgetting research team members at Digital Forensic Lab
   and Medical and Health Informatics Lab at Faculty of Information Science
   and Technology, Universiti Kebangsaan Malaysia.
CR Abdullah SNHS, 2016, APPL ENG AGRIC, V32, P295, DOI 10.13031/aea.32.10868
   Ali A., 2019, INDONES J ELECT ENG, V13, P1199, DOI DOI 10.11591/IJEECS.V13.I3.PP1199-1207
   [Anonymous], THESIS
   Bataineh B, 2011, PATTERN RECOGN LETT, V32, P1805, DOI 10.1016/j.patrec.2011.08.001
   Charansiriphaisan K, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/974024
   Das S, 2011, IEEE T EVOLUT COMPUT, V15, P4, DOI 10.1109/TEVC.2010.2059031
   DELUCA A, 1972, INFORM CONTROL, V20, P301, DOI 10.1016/S0019-9958(72)90199-4
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Gamperle R., 2002, ADV INTELLIGENT SYST, V10, P293
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Ghosh S, 2012, IEEE T SYST MAN CY B, V42, P107, DOI 10.1109/TSMCB.2011.2160625
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hussein WA, 2016, KNOWL-BASED SYST, V101, P114, DOI 10.1016/j.knosys.2016.03.010
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Maszczyk T, 2008, LECT NOTES ARTIF INT, V5097, P643, DOI 10.1007/978-3-540-69731-2_62
   Muppidi M, 2015, INT CONF IMAG PROC, P143, DOI 10.1109/IPTA.2015.7367114
   Nashat S, 2012, PATTERN RECOGN LETT, V33, P1269, DOI 10.1016/j.patrec.2012.03.023
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Saraswat M, 2013, SWARM EVOL COMPUT, V11, P46, DOI 10.1016/j.swevo.2013.02.003
   Sarkar S., 2013, FUZZ SYST FUZZ 2013, P1
   Shannon C. E., 1998, MATH THEORY COMMUNIC
   Shatnawi Nahlah, 2013, Journal of Applied Sciences, V13, P458, DOI 10.3923/jas.2013.458.464
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Tao WB, 2003, PATTERN RECOGN LETT, V24, P3069, DOI 10.1016/S0167-8655(03)00166-1
   Tsallis C, 1998, PHYSICA A, V261, P534, DOI 10.1016/S0378-4371(98)00437-3
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743
NR 27
TC 15
Z9 15
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2019
VL 91
AR 103792
DI 10.1016/j.imavis.2019.07.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU3YI
UT WOS:000501614200005
DA 2024-07-18
ER

PT J
AU Kim, DH
   Lee, MK
   Lee, SH
   Song, BC
AF Kim, Dae Ha
   Lee, Min Kyu
   Lee, Seung Hyun
   Song, Byung Cheol
TI Macro unit-based convolutional neural network for very light-weight deep
   learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep neural networks; Light-weight deep learning; Macro-unit
AB When implementing a deep neural network in an embedded system or SoC for mobile devices, its large parameter size can be a significant burden on the internal memory design. In this paper, we propose a new deep neural network that reduces computation and the number of model parameters but maintains reasonable performance. The configuration of the proposed network is as follows: First, we present a macro unit (MU) to reduce heavy computations and also to learn sufficient feature maps. Second, we employ asymmetric convolution of the well-known Inception network to further efficiently manipulate feature maps within the MU. Third, all the feature maps produced from MU(s) of each layer are concatenated and then the grouped feature map is distributed to all the MUs of the next layer for transferring richer information. Experimental results show that the proposed network achieves about 10% higher performance than DenseNet-BC in case of extremely small parameter size for CIFAR-100. The proposed network also has very few learning parameters and smaller floating point operations per second (FLOPS) than the other networks optimized for mobile devices such as MobileNet V2. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Kim, Dae Ha; Lee, Min Kyu; Lee, Seung Hyun; Song, Byung Cheol] Inha Univ, Dept Elect Engn, 100 Inha Ro, Incheon 22212, South Korea.
C3 Inha University
RP Song, BC (corresponding author), Inha Univ, Dept Elect Engn, 100 Inha Ro, Incheon 22212, South Korea.
EM bcsong@inha.ac.kr
RI Lee, Seunghyun/AAR-3231-2020; Song, Byungcheol/AAH-9770-2019; Kim,
   Daeha/HJH-1957-2023
OI Lee, Seunghyun/0000-0001-7139-1764; 
FU Inha University Research Grant
FX This work was supported by Inha University Research Grant.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], INCEPTION V4 INCEPTI
   [Anonymous], 2017, P INT C LEARN REPR T
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], 2018, CVPR
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2017, INT C LEARN REPR
   [Anonymous], 2017, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2017.243
   [Anonymous], 2018, ECCV
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], TINY IMAGENET IMAGE
   [Anonymous], 2018, CVPR
   [Anonymous], CVPRW
   [Anonymous], 2014, P BRIT MACHINE VISIO
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   [Anonymous], 2017, P IEEE C COMP VIS PA
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Boureau Y.-l., 2008, ADV NEURAL INFORM PR, P1185
   Chrabaszcz P., 2017, A downsampled variant of imagenet as an alternative to the cifar datasets
   Goodfellow I.J., 2013, MULTIDIGIT NUMBER RE
   Han S., 2015, ARXIV151000149
   Hanson S. J., 1989, Advances in Neural Information Processing Systems, P177
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Huang Gao, 2018, CVPR
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salakhutdinov R., 2009, AISTATS
   Sifre L., 2014, THESIS CITESEER
   Simonyan K., 2014, 14091556 ARXIV
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wen W, 2016, ADV NEUR IN, V29
   Xie S., 2016, ARXIV161105431
   Xu WH, 2017, INT CONF ASIC, P904, DOI 10.1109/ASICON.2017.8252623
   Zhang X., 2017, ARXIV170701083
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
NR 40
TC 2
Z9 2
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2019
VL 87
BP 68
EP 75
DI 10.1016/j.imavis.2019.02.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IF3NV
UT WOS:000472988400007
DA 2024-07-18
ER

PT J
AU Sugimura, D
   Teshima, F
   Hamamoto, T
AF Sugimura, Daisuke
   Teshima, Fumihiro
   Hamamoto, Takayuki
TI Online background subtraction with freely moving cameras using different
   motion boundaries
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Online background subtraction; Freely moving camera; Interactive image
   segmentation; Seeds estimation; Motion boundary
ID VIDEO ANALYSIS; SEGMENTATION
AB We propose a method for online background subtraction from a successive-frame video captured using a freely moving camera. Our method exploits a technique of interactive image segmentation with seeds (the subsets of pixels marked as "foreground" and "background"). The key novelty of our method is to automatically estimate the seeds by exploiting two different motion boundaries that are respectively computed using the magnitude and direction of the flow field. The magnitude of flow field is likely to be useful in differentiating the foreground and background motions when the moving objects and the camera make a movement towards the same direction. In contrast, the direction of flow field helps in discriminating the observed motions when the amount of displacement of the moving objects and the camera is the same. By adaptively exploiting the advantages of these different motion boundaries, our method enables to estimate the reliable foreground/background seeds. With the estimated seeds, our method performs accurate background subtraction even when the complex camera movements (e.g., large pan-tilt-zoom, rotation) are made. Our experiments demonstrate the effectiveness of our method using public dataset and other real image sequences. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Sugimura, Daisuke] Tsuda Univ, Dept Comp Sci, Tokyo 1878577, Japan.
   [Teshima, Fumihiro; Hamamoto, Takayuki] Tokyo Univ Sci, Dept Elect Engn, Tokyo 1258585, Japan.
C3 Tokyo University of Science
RP Sugimura, D (corresponding author), Tsuda Univ, Dept Comp Sci, Tokyo 1878577, Japan.
EM sugimura@tsuda.ac.jp
OI Hamamoto, Takayuki/0000-0001-8246-8325
CR Baker S., PROC IEEE INT C COMP
   Berger M, 2014, PROC CVPR IEEE, P1274, DOI 10.1109/CVPR.2014.166
   Berrabah SA, 2006, IEEE IMAGE PROC, P1125, DOI 10.1109/ICIP.2006.312754
   Bideau P, 2016, LECT NOTES COMPUT SC, V9912, P433, DOI 10.1007/978-3-319-46484-8_26
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Bramberger M, 2004, RTAS 2004: 10TH IEEE REAL-TIME AND EMBEDDED TECHNOLOGY AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P174, DOI 10.1109/RTTAS.2004.1317262
   Bremond F, 2006, BEHAV RES METHODS, V38, P416, DOI 10.3758/BF03192795
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Burgos-Artizzu XP, 2012, PROC CVPR IEEE, P1322, DOI 10.1109/CVPR.2012.6247817
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cavallaro A, 2005, IEEE T CIRC SYST VID, V15, P1200, DOI 10.1109/TCSVT.2005.854240
   Chen L, 2015, IEEE T MULTIMEDIA, V17, P2225, DOI 10.1109/TMM.2015.2481711
   Chen Y, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P1056, DOI 10.1109/ROBIO.2014.7090472
   Cui XY, 2012, LECT NOTES COMPUT SC, V7572, P612, DOI 10.1007/978-3-642-33718-5_44
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Elqursh A, 2012, LECT NOTES COMPUT SC, V7577, P228, DOI 10.1007/978-3-642-33783-3_17
   Ferone A, 2014, IEEE T SYST MAN CY-S, V44, P571, DOI 10.1109/TSMC.2013.2280121
   Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035
   Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883
   Jin YX, 2008, IEEE IMAGE PROC, P1572, DOI 10.1109/ICIP.2008.4712069
   Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374
   Kwak S, 2011, IEEE I CONF COMP VIS, P2174, DOI 10.1109/ICCV.2011.6126494
   Liu F, 2009, PROC CVPR IEEE, P320, DOI 10.1109/CVPRW.2009.5206857
   Mittal A, 2004, PROC CVPR IEEE, P302
   Narayana M, 2013, IEEE I CONF COMP VIS, P1577, DOI 10.1109/ICCV.2013.199
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Sajid H, 2015, IEEE IMAGE PROC, P4530, DOI 10.1109/ICIP.2015.7351664
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Sheikh Y, 2009, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2009.5459334
   Shi F, 2013, IEEE I CONF COMP VIS, P3088, DOI 10.1109/ICCV.2013.383
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222
   Tron R., 2007, PROC IEEE CS C COMPU, P1
   Tsai YW, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON CONTROL AND ROBOTICS ENGINEERING, P1
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Zamalieva D, 2014, LECT NOTES COMPUT SC, V8689, P803, DOI 10.1007/978-3-319-10590-1_52
   Zhang G, 2007, AEROSP CONF PROC, P3929
   Zhang GF, 2011, IEEE T PATTERN ANAL, V33, P603, DOI 10.1109/TPAMI.2010.115
   Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52
NR 43
TC 6
Z9 6
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2018
VL 76
BP 76
EP 92
DI 10.1016/j.imavis.2018.06.003
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GR1TB
UT WOS:000442333500007
DA 2024-07-18
ER

PT J
AU Tolias, G
   Chum, O
AF Tolias, Giorgos
   Chum, Ondrej
TI Efficient contour match kernel
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sketch-based image retrieval; Efficient contour matching; Kernel
   descriptors; Asymmetric feature maps
AB We propose a novel concept of asymmetric feature maps (AFM), which allows to evaluate multiple kernels between a query and database entries without increasing the memory requirements. To demonstrate the advantages of the AFM method, we derive an efficient contour match kernel - short vector image representation that, due to asymmetric feature maps, supports efficient scale and translation invariant sketch-based image retrieval. Unlike most of the short-code based retrieval systems, the proposed method provides the query localization in the retrieved image. The efficiency of the search is boosted by approximating a 2D translation search via trigonometric polynomial of scores by 1D projections. The projections are a special case of AFM. An order of magnitude speed-up is achieved compared to traditional trigonometric polynomials. The results are boosted by an image-based average query expansion approach and, without any learning, significantly outperform the state-of-the-art hand-crafted descriptors on standard benchmarks. Our method competes well with recent CNN-based approaches that require large amounts of labeled sketches, images and sketch-image pairs. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Tolias, Giorgos; Chum, Ondrej] Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Visual Recognit Grp, Prague, Czech Republic.
C3 Czech Technical University Prague
RP Tolias, G (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Visual Recognit Grp, Prague, Czech Republic.
EM giorgos.tolias@cmp.felk.cvut.cz
RI Chum, Ondrej/F-5262-2015; Tolias, Giorgos/O-9939-2017
OI Tolias, Giorgos/0000-0002-9570-3870
FU  [MSMT LL1303 ERC-CZ]
FX The authors were supported by the MSMT LL1303 ERC-CZ grant.
CR [Anonymous], 2007, ICCV
   [Anonymous], 2011, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2005, CVPR
   [Anonymous], 2016, BMVC
   [Anonymous], 2015, BMVC
   [Anonymous], 2015, BMVC
   [Anonymous], ICMR
   [Anonymous], BMVC
   [Anonymous], ICCV
   [Anonymous], 2016, ECCVW
   [Anonymous], 2013, ICCV
   [Anonymous], 2007, CVPR
   [Anonymous], 2014, ICIP
   [Anonymous], CVPR
   [Anonymous], 2014, P INT C LEARN REPR B
   [Anonymous], 2007, NEURAL INFORM PROCES
   [Anonymous], CVPR
   [Anonymous], 2004, ECCV WORKSHOPS
   [Anonymous], 2010, CVPR
   [Anonymous], 2003, ICCV
   Bo L., 2009, EFFICIENT MATCH KERN
   Bui T., 2016, ARXIV PREPRINT ARXIV
   Bui T., 2015, ICCV
   Cao X., 2013, ICCV
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Chum O, 2017, IMAGE VISION COMPUT, V66, P36, DOI 10.1016/j.imavis.2017.07.001
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Eitz M, 2010, COMPUT GRAPH-UK, V34, P482, DOI 10.1016/j.cag.2010.07.002
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Joly A., 2009, ACM MULTIMEDIA
   Kokkinos I, 2011, INT J COMPUT VISION, V93, P201, DOI 10.1007/s11263-010-0398-7
   Li Y., 2014, BMVC
   Ma C., 2013, BMVC
   Parui S, 2014, LECT NOTES COMPUT SC, V8694, P398, DOI 10.1007/978-3-319-10599-4_26
   Riemenschneider H., 2011, COMP VIS WINT WORKSH
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Schindler K, 2008, PATTERN RECOGN, V41, P3736, DOI 10.1016/j.patcog.2008.05.025
   Scholkopf B., 2002, Encyclopedia of Biostatistics
   Shrivastava A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024188
   Sun X., 2013, ACM MULTIMEDIA
   Thayananthan A., 2003, CVPR
   Tolias G., 2017, CVPR
   Tolias G, 2015, COMPUT VIS IMAGE UND, V140, P9, DOI 10.1016/j.cviu.2015.06.007
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153
NR 48
TC 0
Z9 1
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2018
VL 76
BP 14
EP 26
DI 10.1016/j.imavis.2018.04.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GR1TB
UT WOS:000442333500002
DA 2024-07-18
ER

PT J
AU Harbas, I
   Prentasic, P
   Subasic, M
AF Harbas, Iva
   Prentasic, Pavle
   Subasic, Marko
TI Detection of roadside vegetation using Fully Convolutional Networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image analysis; Vegetation detection; Roadside maintenance; Deep
   learning; Convolutional neural networks
AB Vegetation detection is a common procedure in remote sensing, but recently it has also been applied in robotics as an aid in navigation of autonomous vehicles. In this paper, we present a method for roadside vegetation detection intended for traffic infrastructure maintenance. While many published methods use Near Infrared images for vegetation detection, our method uses images from the visible spectrum which allows the use of a common color camera on-board a vehicle. Deep neural networks have proven to be a very promising machine learning technique and have shown excellent results in different computer vision problems. In this paper, we show that Fully Convolutional Neural Networks can be effectively used in a real-world application for detecting roadside vegetation. For training and testing purposes, we have created our own image database which contains roadside vegetation in various conditions. We present promising experimental results and a discussion of encountered problems in a real-world application as well as a comparison with several alternative approaches. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Harbas, Iva; Prentasic, Pavle; Subasic, Marko] Fac Elect Engn & Comp, Dept Elect Syst & Informat Proc, Unska 3, Zagreb 10000, Croatia.
C3 University of Zagreb
RP Harbas, I (corresponding author), Fac Elect Engn & Comp, Dept Elect Syst & Informat Proc, Unska 3, Zagreb 10000, Croatia.
EM iva.harbas@fer.hr
FU European Regional Development Fund [KK.01.1.1.01.0009]
FX This research has been supported by the European Regional Development
   Fund under the grant KK.01.1.1.01.0009 (DATACROSS).
CR [Anonymous], 2017, P 2017 IEEE 2 ECUADO
   [Anonymous], SIGN PROC COMM SYST
   [Anonymous], VEH EL SAF ICVES IEE
   [Anonymous], 2016, CoRR
   [Anonymous], CONS EL 2008 ICCE 20, DOI DOI 10.1109/ICCE.2008.4587982
   [Anonymous], CORR
   [Anonymous], 2016, CORR
   [Anonymous], 2014, EUR C COMP VIS ECCV
   [Anonymous], CORR
   [Anonymous], VIS INF PROC EUVIP 2
   [Anonymous], 2014, CORR
   [Anonymous], 2015, P 23 ACM INT C MULT
   [Anonymous], INT SYST 2014 INT C
   [Anonymous], ROB SCI SYST RSS 201
   Bradley DA, 2007, IEEE INT CONF ROBOT, P503, DOI 10.1109/ROBOT.2007.363836
   Carranza EJM, 2001, INT GEOSCI REMOTE SE, P1324, DOI 10.1109/IGARSS.2001.976833
   Chowdhury S, 2015, EXPERT SYST APPL, V42, P5047, DOI 10.1016/j.eswa.2015.02.047
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843
   Ciresan DC, 2011, PROC INT CONF DOC, P1135, DOI 10.1109/ICDAR.2011.229
   De Biasio TAM, 2013, I CONF SENS TECHNOL, P704, DOI 10.1109/ICSensT.2013.6727744
   Deng L, 2013, IEEE INT NEW CIRC
   Dos Santos C., 2014, Coling, P69
   Fan H, 2016, IEEE INT VEH SYM, P735, DOI 10.1109/IVS.2016.7535469
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Ghazal M, 2015, IEEE INT SYMP SIGNAL, P332, DOI 10.1109/ISSPIT.2015.7394354
   Harbas I, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P420, DOI 10.1109/CISP.2014.7003817
   Herman S., 2004, US Patent, Patent No. [6,832,000, 6832000]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Langford ZL, 2017, INT CONF DAT MIN WOR, P322, DOI 10.1109/ICDMW.2017.48
   Motohka T, 2010, REMOTE SENS-BASEL, V2, P2369, DOI 10.3390/rs2102369
   Nguyen D., 2011, 2011 Proceedings of IEEE International Conference on Industrial Technology (ICIT 2011), P358, DOI 10.1109/ICIT.2011.5754402
   Nguyen DV, 2012, ROBOT AUTON SYST, V60, P1498, DOI 10.1016/j.robot.2012.07.022
   Nguyen DV, 2012, IEEE INT C INTELL TR, P230, DOI 10.1109/ITSC.2012.6338752
   Nguyen DV, 2012, ROBOT AUTON SYST, V60, P498, DOI 10.1016/j.robot.2011.11.012
   Pan Z., 2010, P 2 INT C INFORM SCI, P250, DOI [10.1109/ICISE.2010.5691105, DOI 10.1109/ICISE.2010.5691105]
   Potena C, 2017, ADV INTELL SYST COMP, V531, P105, DOI 10.1007/978-3-319-48036-7_9
   Simonyan K., 2014, 14091556 ARXIV
   Zhan ZQ, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P13
   Zhang XY, 2017, INT GEOSCI REMOTE SE, P3479, DOI 10.1109/IGARSS.2017.8127748
NR 39
TC 8
Z9 8
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2018
VL 74
BP 1
EP 9
DI 10.1016/j.imavis.2018.03.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GJ9UE
UT WOS:000435749600001
DA 2024-07-18
ER

PT J
AU Levinshtein, A
   Phung, E
   Aarabi, P
AF Levinshtein, Alex
   Phung, Edmund
   Aarabi, Parham
TI Hybrid eye center localization using cascaded regression and
   hand-crafted model fitting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Eye center detection; Eye tracking; Facial feature alignment; Cascaded
   regression
ID HOUGH-TRANSFORM; FACE ALIGNMENT
AB We propose a new cascaded regressor for eye center detection. Previous methods start from a face or an eye detector and use either advanced features or powerful regressors for eye center localization, but not both. Instead, we detect the eyes more accurately using an existing facial feature alignment method. We improve the robustness of localization by using both advanced features and powerful regression machinery. Unlike most other methods that do not refine the regression results, we make the localization more accurate by adding a robust circle fitting post-processing step. Finally, using a simple hand-crafted method for eye center localization, we show how to train the cascaded regressor without the need for manually annotated training data. We evaluate our new approach and show that it achieves state-of-the-art performance on the BioID, GI4E, and the TalkingFace datasets. At an average normalized error of e < 0.05, the regressor trained on manually annotated data yields an accuracy of 95.07% (BioID), 99.27% (GI4E), and 95.68% (TalkingFace). The automatically trained regressor is nearly as good, yielding an accuracy of 93.9% (BioID), 99.27% (GI4E), and 95.46% (TalkingFace). (C) 2018 Elsevier B.V. All rights reserved.
C1 [Levinshtein, Alex; Phung, Edmund; Aarabi, Parham] ModiFace Inc, Toronto, ON, Canada.
   [Aarabi, Parham] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
C3 University of Toronto
RP Levinshtein, A (corresponding author), ModiFace Inc, Toronto, ON, Canada.
EM alex@modiface.com
CR Ahuja K, 2016, IEEE IMAGE PROC, P3121, DOI 10.1109/ICIP.2016.7532934
   [Anonymous], 2009, BMVC
   Antonakos E, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431445
   Ariz M, 2016, COMPUT VIS IMAGE UND, V148, P201, DOI 10.1016/j.cviu.2015.04.009
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Fuhl W, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P123, DOI 10.1145/2857491.2857505
   Fuhl W, 2015, LECT NOTES COMPUT SC, V9256, P39, DOI 10.1007/978-3-319-23192-1_4
   George A, 2016, IET COMPUT VIS, V10, P660, DOI 10.1049/iet-cvi.2015.0316
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Kawaguchi T, 2000, IEEE IMAGE PROC, P49, DOI 10.1109/ICIP.2000.900889
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Levinshtein A., 2017, GLOB C SIGN INF PROC
   Li D., 2005, CVPRW
   Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Skodras E, 2015, IMAGE VISION COMPUT, V36, P51, DOI 10.1016/j.imavis.2015.01.006
   Swirski L., 2012, P S EYE TRACK RES AP, P173
   Tian D., 2016, VISUAL COMMUNICATION, P1, DOI DOI 10.1109/VCIP.2016.7805483
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Toennies K, 2002, INT C PATT RECOG, P1053, DOI 10.1109/ICPR.2002.1048486
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Wood E., 2014, P S EYE TRACK RES AP, P207, DOI DOI 10.1145/2578153.2578185
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081
   Zhou MC, 2015, IEEE IMAGE PROC, P4466, DOI 10.1109/ICIP.2015.7351651
NR 26
TC 15
Z9 16
U1 0
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2018
VL 71
BP 17
EP 24
DI 10.1016/j.imavis.2018.01.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GB1QS
UT WOS:000428825900002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hu, YL
   Li, YS
   Song, R
   Rao, P
   Wang, YL
AF Hu, Yinlin
   Li, Yunsong
   Song, Rui
   Rao, Peng
   Wang, Yangli
TI Minimum barrier superpixel segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Superpixels; Minimum barrier distance; Clustering
AB Superpixel has become an essential processing unit in many computer vision systems, and superpixel segmentation of images is one of the most important step. In this paper, an efficient superpixel segmentation algorithm was proposed. We introduce a new compact-aware minimum barrier distance for superpixel segmentation (MBS), and a propagation scheme for the cluster centers between adjacent levels on a hierarchical architecture. Experiments show that it achieves state-of-the-art performance and can be configured with simple trade-off between performance and efficiency. Furthermore, the compactness of segmented super-pixel could be flexibly controlled continuously by only one parameter, which could be easily integrated in other computer vision tasks. The source code of MBS is available at https://github.com/YinlinHu/MBS. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Hu, Yinlin; Li, Yunsong; Song, Rui; Wang, Yangli] Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Shaanxi, Peoples R China.
   [Song, Rui; Rao, Peng] Chinese Acad Sci, Shanghai Inst Tech Phys, Key Lab Infrared Syst Detect & Imaging Technol, Beijing, Peoples R China.
C3 Xidian University; Shanghai Institute of Technical Physics, CAS; Chinese
   Academy of Sciences
RP Song, R (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Shaanxi, Peoples R China.; Song, R (corresponding author), Chinese Acad Sci, Shanghai Inst Tech Phys, Key Lab Infrared Syst Detect & Imaging Technol, Beijing, Peoples R China.
EM huyinlin@gmail.com; ysli@mail.xidian.edu.cn; rsong@xidian.edu.cn;
   yliwang@mail.xidian.edu.cn
RI chen, bin/KBQ-8114-2024
OI chen, bin/0000-0002-3398-1314; Hu, Yinlin/0000-0003-2614-5200
FU NSFC [61401337, 61222101]; 111 Project [B08038, B08028]; Program of
   Innovative Research Team in Shaanxi Province; Fundamental Research Funds
   for the Central Universities; Key Laboratory of Infrared System
   Detection and Imaging Technology, Shanghai Institute of Technical
   Physics, Chinese Academy of Sciences
FX This work was supported by NSFC grant (no. 61401337 and no. 61222101),
   the 111 Project (B08038 and B08028), Program of Innovative Research Team
   in Shaanxi Province, Fundamental Research Funds for the Central
   Universities, and Key Laboratory of Infrared System Detection and
   Imaging Technology, Shanghai Institute of Technical Physics, Chinese
   Academy of Sciences.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2009, ICCV
   [Anonymous], 2011, CVPR
   [Anonymous], 2010, ECCV
   [Anonymous], 2011, ICCV
   [Anonymous], 2015, ICCV
   [Anonymous], TPAMI
   [Anonymous], 2003, ICCV
   [Anonymous], 2004, IJCV
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Ciesielski K.C., 2014, CVIU
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Moore AlastairP., 2008, CVPR
   Moore AlastairP., 2010, CVPR
   Mori G., 2005, ICCV
   Rosenfeld A, 1968, DISTANCE FUNCTIONS D
   Schick A., 2012, ICPR
   Strand R., 2013, CVIU
   Stutz D., 2015, GCPR
   Van den Bergh M, 2015, INT J COMPUT VISION, V111, P298, DOI 10.1007/s11263-014-0744-2
   Vedaldi A., 2008, ECCV
   Veksler Olga., 2010, ECCV
   Wang P., 2013, IJCV
   Zhang Y., 2011, ICCV
   Zitnick C.L., 2007, IJCV
NR 26
TC 11
Z9 11
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2018
VL 70
BP 1
EP 10
DI 10.1016/j.imavis.2017.12.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GA7AR
UT WOS:000428487500001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Zhang, Q
   Han, JG
   Wang, L
AF Liu Yi
   Zhang Qiang
   Han Jungong
   Wang Long
TI Salient object detection employing robust sparse representation and
   local consistency
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; Robust sparse representation; Local
   consistency; Complex structures
ID VISUAL-ATTENTION; OPTIMIZATION
AB Many sparse representation (SR) based salient object detection methods have been presented in the past few years. Given a background dictionary, these methods usually detect the saliency by measuring the reconstruction errors, leading to the failure for those images with complex structures. In this paper, we propose to replace the traditional SR model with a robust sparse representation (RSR) model, for salient object detection, which replaces the least squared errors by the sparse errors. Such a change dramatically improves the robustness of the saliency detection in the existence of non-Gaussian noise, which is the case in most practical applications. By virtual of RSR, salient objects can equivalently be viewed as the sparse but strong "outlets" within an image so that the salient object detection problem can be reformulated to a sparsity pursuit one. Moreover, we jointly utilize the representation coefficients and the reconstruction errors to construct the saliency measure in the proposed method. Finally, we integrate a local consistency prior among spatially adjacent regions into the RSR model in order to uniformly highlight the whole salient object. Experimental results demonstrate that the proposed method significantly outperforms the traditional SR based methods and is competitive with some current state-of-the-art methods, especially for those images with complex structures. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Liu Yi; Zhang Qiang] Xidian Univ, Key Lab Elect Equipment Struct Design, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
   [Liu Yi; Zhang Qiang] Xidian Univ, Sch Mechanoelect Engn, Ctr Complex Syst, Xian 710071, Shaanxi, Peoples R China.
   [Han Jungong] Univ Lancaster, Sch Comp & Commun, Lancaster LA1 4YW, England.
   [Wang Long] Peking Univ, Coll Engn, Ctr Syst & Control, Beijing 100871, Peoples R China.
C3 Xidian University; Xidian University; Lancaster University; Peking
   University
RP Zhang, Q (corresponding author), Xidian Univ, Dept Automat Control, POB 183,2 South TaiBai Rd, Xian 710071, Shaanxi, Peoples R China.
EM qzhang@xidian.edu.cn
RI Han, Jungong/ABE-6812-2020
OI Han, Jungong/0000-0003-4361-956X
FU National Natural Science Foundation of China [61773301]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2016JM6008];
   Fundamental Research Funds for the Central Universities [j132170401]
FX This work is supported by the National Natural Science Foundation of
   China under grant no. 61773301, by the Natural Science Basic Research
   Plan in Shaanxi Province of China (program no. 2016JM6008), and by the
   Fundamental Research Funds for the Central Universities under grant no.
   j132170401.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2487833
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia
   [Anonymous], IEEE T IMAGE PROCESS
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Fan Q, 2016, NEUROCOMPUTING, V175, P81, DOI 10.1016/j.neucom.2015.10.030
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Han JG, 2013, NEUROCOMPUTING, V111, P70, DOI 10.1016/j.neucom.2012.12.015
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Huo L, 2016, NEUROCOMPUTING, V194, P348, DOI 10.1016/j.neucom.2016.02.044
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Li C, 2016, IEEE GEOSCI REMOTE S, V13, P641, DOI 10.1109/LGRS.2016.2532380
   Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158
   Li Y, 2009, IEEE IMAGE PROC, P3093, DOI 10.1109/ICIP.2009.5414465
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Peng P, 2015, NEUROCOMPUTING, V166, P337, DOI 10.1016/j.neucom.2015.03.067
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ren JQ, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301391
   Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang P, 2012, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2012.6248054
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Zhang Q, 2016, IEEE T IMAGE PROCESS, V25, P2045, DOI 10.1109/TIP.2016.2524212
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 44
TC 13
Z9 14
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 155
EP 167
DI 10.1016/j.imavis.2017.10.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100013
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Berriel, RF
   de Aguiar, E
   de Souza, AF
   Oliveira-Santos, T
AF Berriel, Rodrigo F.
   de Aguiar, Edilson
   de Souza, Alberto F.
   Oliveira-Santos, Thiago
TI Ego-Lane Analysis System (ELAS): Dataset and algorithms
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ego-lane analysis; Lane estimation; Kalman filter; Particle filter;
   Dataset; Image processing
ID VISION SYSTEM; OBSTACLE
AB Decreasing costs of vision sensors and advances in embedded hardware boosted lane related research detection, estimation, tracking, etc. - in the past two decades. The interest in this topic has increased even more with the demand for advanced driver assistance systems (ADAS) and self-driving cars. Although extensively studied independently, there is still need for studies that propose a combined solution for the multiple problems related to the ego-lane, such as lane departure warning (LDW), lane change detection, lane marking type (LMT) classification, road markings detection and classification, and detection of adjacent lanes (i.e., immediate left and right lanes) presence. In this paper, we propose a real-time Ego-Lane Analysis System (ELAS) capable of estimating ego-lane position, classifying LMTs and road markings, performing LDW and detecting lane change events. The proposed vision-based system works on a temporal sequence of images. Lane marking features are extracted in perspective and Inverse Perspective Mapping (IPM) images that are combined to increase robustness. The final estimated lane is modeled as a spline using a combination of methods (Hough lines with Kalman filter and spline with particle filter). Based on the estimated lane, all other events are detected. To validate ELAS and cover the lack of lane datasets in the literature, a new dataset with more than 20 different scenes (in more than 15,000 frames) and considering a variety of scenarios (urban road, highways, traffic, shadows, etc.) was created. The dataset was manually annotated and made publicly available to enable evaluation of several events that are of interest for the research community (i.e., lane estimation, change, and centering; road markings; intersections; LMTs; crosswalks and adjacent lanes). Moreover, the system was also validated quantitatively and qualitatively on other public datasets. ELAS achieved high detection rates in all real-world events and proved to be ready for real-time applications. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Berriel, Rodrigo F.; de Aguiar, Edilson; de Souza, Alberto F.; Oliveira-Santos, Thiago] Univ Fed Espirito Santo, Vitoria, Brazil.
C3 Universidade Federal do Espirito Santo
RP Berriel, RF (corresponding author), Univ Fed Espirito Santo, Vitoria, Brazil.
EM rfberriel@inf.ufes.br
RI Berriel, Rodrigo Ferreira/X-7372-2019; Oliveira-Santos,
   Thiago/AAM-5721-2020; De Souza, Alberto F./C-4546-2013
OI Oliveira-Santos, Thiago/0000-0001-7607-635X; De Souza, Alberto
   F./0000-0003-1561-8447; Berriel, Rodrigo/0000-0002-6701-893X
FU Fundacao de Amparo Pesquisa do Espirito Santo FAPES [53631242/11,
   60902841/13, 66610354/2014]; Coordenacao de Aperfeicoamento de Pessoal
   de Nivel Superior CAPES [11012/13-7]; Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico CNPq, Brazil [552630/2011-0,
   312786/2014-1]
FX The authors would like to thank Fundacao de Amparo Pesquisa do Espirito
   Santo FAPES (grants 53631242/11 and 60902841/13, and scholarship
   66610354/2014), Coordenacao de Aperfeicoamento de Pessoal de Nivel
   Superior CAPES (grant 11012/13-7), and Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico CNPq, Brazil (grants
   552630/2011-0, 312786/2014-1) for their financial support to this
   research work.
CR Aly M, 2008, IEEE INT VEH SYM, P165, DOI 10.1109/ivs.2008.4621152
   Berriel R, 2015, SIBGRAPI, P149, DOI 10.1109/SIBGRAPI.2015.15
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   Borkar A, 2012, IEEE T INTELL TRANSP, V13, P365, DOI 10.1109/TITS.2011.2173196
   Conselho Nacional de Transit, 2007, MAN BRAS SIN TRANS
   de Paula MB, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2438714
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Hur J, 2013, IEEE INT VEH SYM, P1297, DOI 10.1109/IVS.2013.6629645
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E
   Lee JW, 2002, COMPUT VIS IMAGE UND, V86, P52, DOI 10.1006/cviu.2002.0958
   Li QQ, 2014, IEEE T VEH TECHNOL, V63, P540, DOI 10.1109/TVT.2013.2281199
   Lindner P., 2009, INT TRANSP SYST ITSC, P1
   Lum H., 1995, Public Roads, V58, P14
   MALLOT HA, 1991, BIOL CYBERN, V64, P177, DOI 10.1007/BF00201978
   MARAGOS PA, 1986, SYSTEMS MAN CYBERN A, V34, P1228
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   McCall J. C., 2005, COMP VIS PATT REC WO, P59
   McCall JC, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P533
   Nieto M, 2011, MACH VISION APPL, V22, P927, DOI 10.1007/s00138-010-0287-7
   Satzoda RK, 2013, IEEE COMPUT SOC CONF, P604, DOI 10.1109/CVPRW.2013.91
   Satzoda RK, 2015, IEEE T CIRC SYST VID, V25, P1870, DOI 10.1109/TCSVT.2015.2406171
   Satzoda RK, 2014, INT C PATT RECOG, P2625, DOI 10.1109/ICPR.2014.453
   Satzoda RK, 2014, IEEE COMPUT SOC CONF, P708, DOI 10.1109/CVPRW.2014.108
   Schreiber M, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P597, DOI 10.1109/ITSC.2014.6957755
   Suchitra S, 2013, IEEE INT C INTELL TR, P1929, DOI 10.1109/ITSC.2013.6728511
   Thrun S., 2005, PROBABILISTIC ROBOTI
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
NR 29
TC 36
Z9 36
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2017
VL 68
SI SI
BP 64
EP 75
DI 10.1016/j.imavis.2017.07.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FR9UP
UT WOS:000419418900007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, XJ
   Kong, AWK
AF Li, Xiaojie
   Kong, Adams Wai Kin
TI A multi-model restoration algorithm for recovering blood vessels in skin
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE JPEG compression; Biometrics; Image restoration; Deblocking; Image
   quality; Forensics
ID BLOCKING ARTIFACTS; REDUCTION; TRANSFORM; DCT; DEBLOCKING; PROJECTION;
   PATTERNS
AB Blood vessels under skin surface have been used as a biometric trait for many years. Traditionally, they are used only in commercial and governmental applications because infrared images are required to capture high quality blood vessels. Recent research results demonstrate that blood vessels can be extracted directly from color images potentially for forensic applications. However, color images taken by consumer cameras are likely compressed by the JPEG compression method. As a result, the quality of the color images is seriously degraded, which makes the blood vessels difficult to be visualized. In this paper, a multi-model restoration algorithm (MMRA) is presented to remove blocking artifacts in JPEG compressed images and restore the lost information. Two mathematical properties in the JPEG compression process are identified and used to design MMRA. MMRA is based on a tailor-made clustering scheme to group training data and learns a model, which predicts original discrete cosine transform coefficients, from each grouped dataset. An open skin image database containing 978 forearm images and 916 thigh images with weak blood vessel information and a set of diverse skin images collected from the Internet are used to evaluate MMRA. Different resolutions and different compression factors are examined. The experimental results show clearly that MMRA restores blood vessels more effectively than the state-of-the-art deblocking methods. (C) 2017 Elsevier B.V. All rights reserved.
EM xli16@e.ntu.edu.sg; adamskong@ntu.edu.sg
FU Ministry of Education, Singapore through Academic Research Fund Tier 2
   [MOE2012-T2-1-024]
FX This work is partially supported by the Ministry of Education, Singapore
   through Academic Research Fund Tier 2, MOE2012-T2-1-024.
CR Bruckstein AM, 2003, IEEE T IMAGE PROCESS, V12, P1132, DOI 10.1109/TIP.2003.816023
   C. E. Prevention, 2010, NAT STRAT CHILD EXPL
   Chang CL, 2010, IEEE T IMAGE PROCESS, V19, P1740, DOI 10.1109/TIP.2010.2044964
   Choi H., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P303, DOI 10.1109/BTAS.2012.6374593
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Jia K, 2006, PATTERN RECOGN LETT, V27, P1768, DOI 10.1016/j.patrec.2006.02.009
   Lee JE, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P1, DOI [10.1109/PLASMA.2008.4591032, 10.1109/BSYM.2008.4655515]
   Lee YL, 1998, IEEE T IMAGE PROCESS, V7, P229, DOI 10.1109/83.661000
   Li XJ, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P210, DOI 10.1109/SSCI.2015.40
   Li XJ, 2013, IEEE INT WORKS INFOR, P19, DOI 10.1109/WIFS.2013.6707788
   Li YC, 2014, PATTERN RECOGN, V47, P1261, DOI 10.1016/j.patcog.2013.09.012
   Li Y, 2014, LECT NOTES COMPUT SC, V8690, P174, DOI 10.1007/978-3-319-10605-2_12
   Liaw YC, 2002, PATTERN RECOGN, V35, P329, DOI 10.1016/S0031-3203(01)00048-6
   Liew AWC, 2004, IEEE T CIRC SYST VID, V14, P450, DOI 10.1109/TCSVT.2004.825555
   Luo Y, 2003, IEEE T IMAGE PROCESS, V12, P838, DOI 10.1109/TIP.2003.814252
   Florentín-Nuñez MN, 2013, NEUROCOMPUTING, V121, P32, DOI 10.1016/j.neucom.2012.10.029
   Noda H, 2011, PATTERN RECOGN, V44, P788, DOI 10.1016/j.patcog.2010.10.022
   Nurhudatiana A, 2013, IEEE T INF FOREN SEC, V8, P998, DOI 10.1109/TIFS.2013.2258338
   Paek H, 1998, IEEE T CIRC SYST VID, V8, P358, DOI 10.1109/76.678636
   Park J, 2005, IEEE T IMAGE PROCESS, V14, P461, DOI 10.1109/TIP.2004.842354
   REEVE HC, 1984, OPT ENG, V23, P34, DOI 10.1117/12.7973248
   Shen MY, 1998, J VIS COMMUN IMAGE R, V9, P2, DOI 10.1006/jvci.1997.0378
   Si X., 2014, IEEE IJCB 2014, P1
   Song JH, 2015, IEEE J BIOMED HEALTH, V19, P773, DOI 10.1109/JBHI.2014.2313145
   Srinivas N., 2015, HUMAN IDENTIFICATION
   Su H, 2014, IEEE T INF FOREN SEC, V9, P666, DOI 10.1109/TIFS.2014.2306591
   Sun DQ, 2007, IEEE T IMAGE PROCESS, V16, P2743, DOI 10.1109/TIP.2007.904969
   Tang C., 2015, INFORM FUSION
   Tang CY, 2011, IEEE T INF FOREN SEC, V6, P1038, DOI 10.1109/TIFS.2011.2157821
   Tran TD, 2003, IEEE T SIGNAL PROCES, V51, P1557, DOI 10.1109/TSP.2003.811222
   Tsaig Y, 2005, IEEE T CIRC SYST VID, V15, P154, DOI 10.1109/TCSVT.2004.839980
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang HG, 2008, PATTERN RECOGN, V41, P1514, DOI 10.1016/j.patcog.2007.10.021
   Wang L, 2008, PATTERN RECOGN, V41, P920, DOI 10.1016/j.patcog.2007.07.012
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watanabe Taku, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P3625
   Weerasinghe C, 2002, IEEE T CIRC SYST VID, V12, P891, DOI 10.1109/TCSVT.2002.804881
   Xiong ZX, 1997, IEEE T CIRC SYST VID, V7, P433, DOI 10.1109/76.564123
   Yang XL, 2010, IEEE IMAGE PROC, P2789, DOI 10.1109/ICIP.2010.5651017
   Zeng B, 2008, IEEE T CIRC SYST VID, V18, P305, DOI 10.1109/TCSVT.2008.918455
   Zhang H., 2012, BTAS, P77
   Zhang XF, 2013, IEEE T IMAGE PROCESS, V22, P4613, DOI 10.1109/TIP.2013.2274386
NR 43
TC 2
Z9 2
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2017
VL 61
BP 40
EP 53
DI 10.1016/j.imavis.2017.02.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EU7HK
UT WOS:000401205700004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Mukherjee, P
   Lall, B
AF Mukherjee, Prerana
   Lall, Brejesh
TI Saliency and KAZE features assisted object segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Saliency; KAZE; Unsupervised segmentation; Occlusion boundaries
ID IMAGE; EXTRACTION; INTEGRATION; PROPOSALS
AB In this paper, we propose an unsupervised salient object segmentation approach using saliency and object features. In the proposed method, we utilize occlusion boundaries to construct a region-prior map which is then enhanced using object properties. To reject the non-salient regions, a region rejection strategy is employed based on the amount of detail (saliency information) and density of KAZE keypoints contained in them. Using the region rejection scheme, we obtain a threshold for binarizing the saliency map. The binarized saliency map is used to form a salient superpixel cluster. Finally, an iterative grabcut segmentation is applied with salient texture keypoints (SIFT keypoints on the Gabor convolved texture map) supplemented with salient KAZE keypoints (keypoints inside saliency cluster) as the foreground seeds and the binarized saliency map (obtained using the region rejection strategy) as a probably foreground region. We perform experiments on several datasets and show that the proposed segmentation framework outperforms the state of the art unsupervised salient object segmentation approaches on various performance metrics. (C) 2017 Elsevier B.V. All rights reserved.
EM eez138300@ee.iitd.ac.in; brejesh@ee.iitd.ac.in
RI Zorzi, Michele/GQQ-2252-2022; Mukherjee, Prerana/AAH-4473-2021
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Aldana-Iuit J., 2016, SADDLE CHASING FAST
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5540073
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Aytekin Ç, 2015, IEEE IMAGE PROC, P1692, DOI 10.1109/ICIP.2015.7351089
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bradski G, 2000, DR DOBBS J, V25, P120
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao XC, 2016, NEUROCOMPUTING, V172, P235, DOI 10.1016/j.neucom.2014.12.105
   CARREIRA J, 2010, PROC CVPR IEEE, P3241, DOI DOI 10.1109/CVPR.2010.5540063
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Florack L. M. J., 1994, Journal of Mathematical Imaging and Vision, V4, P325, DOI 10.1007/BF01262401
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Houhou N, 2009, NUMER MATH-THEORY ME, V2, P445, DOI 10.4208/nmtma.2009.m9007s
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liao XL, 2014, SIGNAL PROCESS, V105, P122, DOI 10.1016/j.sigpro.2014.04.035
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Liu GC, 2010, IEEE T PATTERN ANAL, V32, P910, DOI 10.1109/TPAMI.2009.40
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Martins P., 2012, BRIT MACHIN VIS C BM, V2012, P1
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk Krystian., 2003, BRIT MACHINE VISION, V2, P779
   Mishra AK, 2012, IEEE T PATTERN ANAL, V34, P639, DOI 10.1109/TPAMI.2011.171
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Qi W., 2015, Comput. Vis. Media, V1, P309, DOI DOI 10.1007/s41095-015-0028-y
   Qin CC, 2014, NEUROCOMPUTING, V129, P378, DOI 10.1016/j.neucom.2013.09.021
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Srivastava S., 2015, APPL SOFT COMPUT
   Stein A, 2007, IEEE I CONF COMP VIS, P110
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   van de Sande K.E. A., 2008, CIVR, P141, DOI DOI 10.1145/1386352.1386376
   Wakeham W., 1980, Fick's Law of Diffusion
   Wang KZ, 2015, IEEE T IMAGE PROCESS, V24, P3019, DOI 10.1109/TIP.2015.2432712
   Weickert J, 2001, PATTERN RECOGN, V34, P1813, DOI 10.1016/S0031-3203(00)00109-6
   Winn J, 2005, IEEE I CONF COMP VIS, P756
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yanulevskaya V, 2014, PROC CVPR IEEE, P3134, DOI 10.1109/CVPR.2014.401
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zitnick CL, 2011, IEEE I CONF COMP VIS, P359, DOI 10.1109/ICCV.2011.6126263
   Zou WB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.78
NR 71
TC 21
Z9 25
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2017
VL 61
BP 82
EP 97
DI 10.1016/j.imavis.2017.02.008
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EU7HK
UT WOS:000401205700007
DA 2024-07-18
ER

PT J
AU Yang, S
   Xiao, B
   Yan, LP
   Xia, YQ
   Fu, MY
   Liu, Y
AF Yang, Sai
   Xiao, Bo
   Yan, Liping
   Xia, Yuanqing
   Fu, Mengyin
   Liu, Yang
TI Robust scene matching method based on sparse representation and
   iterative correction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Scene matching; Sparse representation; Iterative correction
ID CORRELATION-COEFFICIENT; FACE RECOGNITION; IMAGE
AB This article presents an efficient scene matching method robust to noise and occlusion. The method combines a coarse matching method with a fine matching method by iterative correction. Both coarse matching method and fine matching method, inspired by sparse representation for face recognition, are resistant to noise and occlusion inherently. In each step of iterative matching, the result of coarse matching is introduced into fine matching as prior knowledge, which gives a rough range about the possible positions. Then, the fine matching finds the most reasonable result based on the rough range given by coarse matching. Finally, the result of fine matching is brought back to coarse matching as post knowledge to correct it. Experiments demonstrate that the robustness to noise and occlusion is improved compared with the matching methods without iterative correction. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Yang, Sai; Yan, Liping; Xia, Yuanqing; Fu, Mengyin; Liu, Yang] Beijing Inst Technol, Key Lab Intelligent Control & Decis Complex Syst, Sch Automat, Beijing 100081, Peoples R China.
   [Xiao, Bo] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
   [Yan, Liping] Minist Ind & Informat Technol, Key Lab Autonomous Nav & Control Deep Space Explo, Beijing, Peoples R China.
C3 Beijing Institute of Technology; Beijing University of Posts &
   Telecommunications
RP Yan, LP (corresponding author), Beijing Inst Technol, Key Lab Intelligent Control & Decis Complex Syst, Sch Automat, Beijing 100081, Peoples R China.; Yan, LP (corresponding author), Minist Ind & Informat Technol, Key Lab Autonomous Nav & Control Deep Space Explo, Beijing, Peoples R China.
EM liping.yan@gmail.com
RI fu, meng/GZG-3120-2022; liu, yang/AFS-1797-2022
OI liu, yang/0000-0001-9704-8120
FU NSFC [61225015, 61473040]; innovative research groups of the National
   Natural Science Foundation of China [61321002]; China Postdoctoral
   Science Foundation [2015M580051]
FX The work was supported by the NSFC under grants 61225015 and 61473040,
   the innovative research groups of the National Natural Science
   Foundation of China under grant 61321002, and China Postdoctoral Science
   Foundation under grant 2015M580051.
CR Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bilal M, 2012, IET IMAGE PROCESS, V6, P197, DOI 10.1049/iet-ipr.2009.0090
   Canny J., 1986, IEEE T PATTERN ANAL, V8, P184
   Choi MS, 2002, PATTERN RECOGN, V35, P119, DOI 10.1016/S0031-3203(01)00025-5
   Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Donoho DL, 2000, SIAM J MATH ANAL, V31, P1062, DOI 10.1137/S0036141098344403
   Flitton G, 2013, PATTERN RECOGN, V46, P2420, DOI 10.1016/j.patcog.2013.02.008
   Forssén PE, 2009, IMAGE VISION COMPUT, V27, P99, DOI 10.1016/j.imavis.2006.10.005
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Huang LZ, 2014, OPTIK, V125, P414, DOI 10.1016/j.ijleo.2013.06.085
   Ito Izumi, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2818, DOI 10.1109/ICASSP.2014.6854114
   Kaneko S, 2003, PATTERN RECOGN, V36, P1165, DOI 10.1016/S0031-3203(02)00081-X
   Kaneko S, 2002, PATTERN RECOGN, V35, P2223, DOI 10.1016/S0031-3203(01)00177-7
   Lin F., 2015, 34 CHIN CONTR C, P527
   Lindeberg T, 2013, J MATH IMAGING VIS, V46, P177, DOI 10.1007/s10851-012-0378-3
   Liu B., 2007, FIRE CONTROL COMMAND, V32, P17
   [刘宝生 Liu Baosheng], 2005, [光电工程, Opto-Electronic Engineering], V32, P59
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Nalpantidis L, 2011, IET IMAGE PROCESS, V5, P481, DOI 10.1049/iet-ipr.2009.0262
   Pati Y., 1993, P 27 ANN AS C SIGN S, P659
   Ping ZHOU., 2011, Journal of Computational Information Systems, V7, P1516
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Veeraraghavan A, 2011, IEEE T PATTERN ANAL, V33, P671, DOI 10.1109/TPAMI.2010.87
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yoo JC, 2012, IET IMAGE PROCESS, V6, P483, DOI 10.1049/iet-ipr.2011.0025
   Yoo J, 2014, PATTERN RECOGN, V47, P3006, DOI 10.1016/j.patcog.2014.02.016
   Zhu H, 2013, OPTIK, V124, P4460, DOI 10.1016/j.ijleo.2013.03.021
NR 29
TC 9
Z9 9
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 115
EP 123
DI 10.1016/j.imavis.2016.11.009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800012
DA 2024-07-18
ER

PT J
AU Yue, ZS
   Meng, DY
   He, J
   Zhang, GM
AF Yue, Zongsheng
   Meng, Deyu
   He, Juan
   Zhang, Gemeng
TI Semi-supervised learning through adaptive Laplacian graph trimming
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semi-supervised learning; Graph Laplacian; Self-paced learning; Nearest
   neighborhood graph
AB Graph-based semi-supervised learning (GSSL) attracts considerable attention in recent years. The performance of a general GSSL method relies on the quality of Laplacian weighted graph (LWR) composed of the similarity imposed on input examples. A key for constructing an effective LWR is on the proper selection of the neighborhood size K or epsilon on the construction of KNN graph or epsilon-neighbor graph on training samples, which constitutes the fundamental elements in LWR. Specifically, too large K or epsilon will result in "shortcut" phenomenon while too small ones cannot guarantee to represent a complete manifold structure underlying data. To this issue, this study attempts to propose a method, called adaptive Laplacian graph trimming (ALGT), to make an automatic tuning to cut improper inter-cluster shortcut edges while enhance the connection between intra-cluster samples, so as to adaptively fit a proper LWR from data. The superiority of the proposed method is substantiated by experimental results implemented on synthetic and UCI data sets. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Yue, Zongsheng; Meng, Deyu; He, Juan; Zhang, Gemeng] Xi An Jiao Tong Univ, Sch Math & Stat, Xian, Shaanxi, Peoples R China.
   [Yue, Zongsheng; Meng, Deyu; He, Juan; Zhang, Gemeng] Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian, Shaanxi, Peoples R China.
   [Meng, Deyu] Macau Univ Sci & Technol, Fac Informat Technol, Taipa, Macau, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University; Macau University
   of Science & Technology
RP Meng, DY (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian, Shaanxi, Peoples R China.; Meng, DY (corresponding author), Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian, Shaanxi, Peoples R China.
EM dymeng@mail.xjtu.edu.cn
FU National Grand Fundamental Research 973 Program of China [2013CB329404];
   China NSFC project [61373114]; Macau FDCT project [019/2014/A1]
FX This research was supported by the National Grand Fundamental Research
   973 Program of China under Grant No. 2013CB329404, the China NSFC
   project under contract 61373114, and partially by Macau FDCT project
   with no. 019/2014/A1.
CR [Anonymous], AAAI C ART INT AAAI
   [Anonymous], INT C MACH LEARN ICM
   [Anonymous], NEURAL INFORM PROCES
   [Anonymous], COMPUT SCI
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Belkin M., 2003, ADV NEURAL INF PROCE
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Blum A., 2004, INT C MACH LEARN ICM
   CASTELLI V, 1995, PATTERN RECOGN LETT, V16, P105, DOI 10.1016/0167-8655(94)00074-D
   DAITCH SI, 2009, INT C MACH LEARN ICM
   Dornaika F, 2014, EXPERT SYST APPL, V41, P7744, DOI 10.1016/j.eswa.2014.06.025
   Goldberg A. B., 2006, P 1 WORKSH GRAPH BAS, P45, DOI [DOI 10.5555/1654758, DOI 10.3115/1654758.1654769]
   Jebara T., 2009, INT C MACH LEARN ICM
   Jiang L., 2014, ACM INT C MULT ACM M
   Kumar MP, 2010, ADV NEURAL INFORM PR
   Liu BB, 2009, IET IMAGE PROCESS, V3, P115, DOI 10.1049/iet-ipr.2008.0112
   Liu XL, 2014, INFORM SCIENCES, V277, P327, DOI 10.1016/j.ins.2014.02.067
   Maier M., 2008, ADV NEURAL INF PROCE
   Maier M, 2007, LECT NOTES ARTIF INT, V4754, P196
   Melacci S, 2011, J MACH LEARN RES, V12, P1149
   Min, 2008, TECH REP
   Niyogi P., 2005, INT WORK ARTIF INTEL
   Peng X., 2016, IEEE T NEURAL NETW L
   Ramanan D., 2013, COMP VIS PATT REC CV
   Ratsaby J., 2003, ANN C COMP LEARN THE
   Rosenberg C., 2010, IEEE WORKSH MOT VID
   Szummer M., 2002, ADV NEURAL INF PROCE
   Tang K., 2012, ADV NEURAL INF PROCE
   Wang J, 2013, J MACH LEARN RES, V14, P771
   Yong J.L., 2011, IEEE C COMP VIS PATT
   [张春永 ZHANG Chunyong], 2008, [计算机工程与科学, Computer Engineering and Science], V30, P30
   Zhang DW, 2015, IEEE I CONF COMP VIS, P594, DOI 10.1109/ICCV.2015.75
   Zhao Q., 2015, SELF PACED LEARNING
   Zhou D., 2004, ADV NEURAL INF PROCE
NR 34
TC 7
Z9 7
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 38
EP 47
DI 10.1016/j.imavis.2016.11.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800005
DA 2024-07-18
ER

PT J
AU Walecki, R
   Rudovic, O
   Pavlovic, V
   Pantic, M
AF Walecki, Robert
   Rudovic, Ognjen
   Pavlovic, Vladimir
   Pantic, Maja
TI Variable-state Latent Conditional Random Field models for facial
   expression analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression; Action unit; Conditional Random Fields; Sequence
   classification; Segmentation
ID POSTERIOR REGULARIZATION; ACTION RECOGNITION; MACHINE
AB Automated recognition of facial expressions of emotions, and detection of facial action units (AUs) from videos depends critically on modeling of their dynamics. Some of these dynamics are characterized by changes in temporal phases (onset-apex-offset) and intensity of emotion expressions and AUs. The appearance of these changes may vary considerably among subjects, making the recognition/detection task very challenging. The state-of-the-art Latent Conditional Random Fields (L-CRF) framework allows us to efficiently encode these dynamics through the latent states accounting for the temporal consistency in emotion expression and ordinal relationships between its intensity levels. These latent states are typically assumed to be either unordered (nominal) or fully ordered (ordinal). Yet, while the video segments containing activation of the target AU may better be described using ordinal latent states (corresponding to the AU intensity levels), the segments Where this AU does not occur, may better be described using unordered (nominal) latent states. To address this, we propose the variable-state L-CRF (VSL-CRF) model that automatically selects the optimal latent states for the target image sequence, based on the input data and underlying dynamics of the sequence. To reduce the model overfitting, we propose a novel graph-Laplacian regularization of the latent states. We evaluate the VSL-CRF on the tasks of facial expression recognition using the CK+ dataset, and AU detection using the GEMEP-FERA and DISFA datasets, and show that the propoSed model achieves better generalization performance compared to traditional L-CRFs and other related state-of-the-art models. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Walecki, Robert; Rudovic, Ognjen; Pantic, Maja] Imperial Coll, Dept Comp, London, England.
   [Pavlovic, Vladimir] Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ USA.
C3 Imperial College London; Rutgers University System; Rutgers University
   New Brunswick
RP Walecki, R (corresponding author), Imperial Coll, Dept Comp, London, England.
EM r.walecki14@imperial.ac.uk
OI Pavlovic, Vladimir/0000-0003-3979-1236
FU European Community Horizon 2020 [645094]; National Science Foundation
   [IIS0916812]
FX This work has been funded by the European Community Horizon 2020
   [H2020/2014-2020] under grant agreement no. 645094 (SEWA). The work of
   Vladimir Pavlovic has been funded by the National Science Foundation
   under grant no. IIS0916812.
CR [Anonymous], 2005, Handbook of nonverbal behavior research methods in the affective sciences
   [Anonymous], 2004, Advances in Neural Information Processing Systems (NIPS)
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chang KY, 2009, PROC CVPR IEEE, P533, DOI 10.1109/CVPRW.2009.5206612
   Chew SW, 2012, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2012.6247973
   Chew Sien W., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P915, DOI 10.1109/FG.2011.5771373
   Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515
   Chung F. R., 1997, AM MATH SOC, V5, P5
   Cohn J. F, 2014, ALP NORM MTMKL FRAME, P1104
   Ding XY, 2013, IEEE I CONF COMP VIS, P2400, DOI 10.1109/ICCV.2013.298
   Ekman P, 1978, FACIAL ACTION CODING
   Ganchev K., 2013, CROSS LINGUAL DISCRI, P1996
   Ganchev K, 2010, J MACH LEARN RES, V11, P2001
   Held M., 1974, Mathematical Programming, V6, P62, DOI 10.1007/BF01580223
   Jain S., 2011, FACIAL EXPRESSION RE, P1642
   Jiang B., 2012, FACIAL ACTION DETECT
   Jiang BH, 2014, IEEE T CYBERNETICS, V44, P161, DOI 10.1109/TCYB.2013.2249063
   Kim M, 2010, LECT NOTES ARTIF INT, V6322, P51
   Kim M, 2010, LECT NOTES COMPUT SC, V6313, P649
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Lafferty John, 2001, INT C MACH LEARN ICM
   Littlewort G, 2003, REAL TIME FACE DETEC
   Liu M., 2013, LEARNING EXPRESSIONL, P1749
   Lucey P., 2010, EXTENDED COHN KANADE
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   MCCULLAGH P, 1980, J ROY STAT SOC B MET, V42, P109
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124
   Rudovic O., 2012, ECCVW
   Rudovic O, 2015, IEEE T PATTERN ANAL, V37, P944, DOI 10.1109/TPAMI.2014.2356192
   Rudovic O, 2012, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2012.6247983
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021
   Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567
   Shan C., 2005, CONDITIONAL MUTUAL I
   Shang LF, 2009, PROC CVPR IEEE, P2090, DOI 10.1109/CVPRW.2009.5206509
   Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014
   Song Y., 2015, EXPLOITING SPARSITY
   Usman T., 2011, EMOTION RECOGNITION, P872
   Valstar M., 2012, T SYSTEMS MAN CYBERN, V42
   Valstar M., 2011, 1 FACIAL EXPRESSION, P921
   Valstar M. F., 2005, FACIAL ACTION UNIT D
   van der Maaten L, 2012, COGN PROCESS, V13, P507, DOI 10.1007/s10339-011-0419-7
   Wang S., 2006, CVPR, P1097
   Wang Z., 2013, CVPR, DOI DOI 10.1109/CVPR.2013.439
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang X, 2013, INT CONF IMAG VIS, P202, DOI 10.1109/IVCNZ.2013.6727016
   Zhong L, 2015, IEEE T CYBERNETICS, V45, P1499, DOI 10.1109/TCYB.2014.2354351
   Zhu J, 2014, J MACH LEARN RES, V15, P1799
   Zhu YC, 2014, INT C PATT RECOG, P1663, DOI 10.1109/ICPR.2014.293
NR 54
TC 6
Z9 8
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 25
EP 37
DI 10.1016/j.imavis.2016.04.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700004
OA hybrid
DA 2024-07-18
ER

PT J
AU Yang, M
   Wang, X
   Liu, WY
   Shen, LL
AF Yang, Meng
   Wang, Xing
   Liu, Weiyang
   Shen, Linlin
TI Joint regularized nearest points for image set based face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Image set; Joint regularized nearest points; Sparse
   representation
ID REPRESENTATION
AB Face recognition based on image set has attracted much attention due to its promising performance to overcome various variations. Recently, classifiers of regularized nearest points, including sparse approximated nearest points (SANP), regularized nearest points (RNP) and collaborative regularized nearest points (CRNP), have achieved state-of-the-art performance for image set based face recognition. From a query set and a single-class gallery set, SANP and RNP both generate a pair of nearest points, between which the distance is regarded as the between-set distance. However, the computing of nearest points for each single-class gallery set in SANP and RNP ignores collaboration and competition with other classes, which may cause a wrong-class gallery set to have a small between-set distance. CRNP used collaborative representation to overcome this shortcoming but it doesn't explicitly minimize the between-set distance. In order to solve these issues and fully exploit the advantages of nearest points based approaches, in this paper a novel joint regularized nearest points (JRNP) is proposed for face recognition based on image sets. In JRNP, the nearest point in the query set is generated by considering the entire gallery set of all classes; at the same time, JRNP explicitly minimizes the between-set distance of the query set and a single-class gallery set. Furthermore, we proposed algorithms of greedy JRNP and adaptive JRNP to solve the presented model, and the classification is then based on the joint distance between the regularized nearest points in image sets. Extensive experiments were conducted on benchmark databases (e.g., Honda/UCSD, CMU Mobo, You Tube Celebrities databases, and the large-scale You Tube Face datasets). The experimental results clearly show that our JRNP leads the performance in face recognition based on image sets. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Yang, Meng] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Yang, Meng; Wang, Xing; Shen, Linlin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Liu, Weiyang] Peking Univ, Sch Elect & Comp Engn, Beijing, Peoples R China.
C3 Sun Yat Sen University; Shenzhen University; Peking University
RP Yang, M (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.; Yang, M (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
EM yang.meng@szu.edu.cn
RI Shen, Linlin/AEX-9392-2022; Yang, Michael Ying/AAC-6698-2019
OI Shen, Linlin/0000-0003-1420-0815; Yang, Michael Ying/0000-0002-0649-9987
FU National Natural Science Foundation of China [61402289, 61272050];
   Shenzhen Scientific Research and Development [JCYJ20140509172609171,
   JCYJ20130329115750231]; Scientific Research Fund for new teacher
   Shenzhen University [201536]; Scientific Research fund for Advanced
   Talents of Shenzhen University [000070]
FX This work is partially supported by the National Natural Science
   Foundation of China under Grants no. 61402289 and 61272050, and Shenzhen
   Scientific Research and Development Funding Program under Grants
   JCYJ20140509172609171 and JCYJ20130329115750231, Scientific Research
   Fund for new teacher of Shenzhen University (Grant no. 201536),
   Scientific Research fund for Advanced Talents of Shenzhen University
   (Grant no. 000070).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P BMVC
   [Anonymous], 2001, Cmu Ri Tr 01-18
   [Anonymous], P CVPR
   [Anonymous], P ICCV
   Arandjelovic O., 2005, P CVPR
   Cevikalp H., 2010, P CVPR
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Cui Z., 2012, P CVPR
   Cui Z, 2015, NEUROCOMPUTING, V147, P403, DOI 10.1016/j.neucom.2014.06.044
   Cui Z, 2014, NEUROCOMPUTING, V135, P306, DOI 10.1016/j.neucom.2013.12.004
   Fan W., 2006, P CVPR
   Fitzgibbon A. W., 2003, P CVPR
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu YQ, 2012, IEEE T PATTERN ANAL, V34, P1992, DOI 10.1109/TPAMI.2011.283
   Huang ZH, 2015, IMAGE VISION COMPUT, V37, P12, DOI 10.1016/j.imavis.2014.12.005
   Kim M., 2008, P CVPR, P1
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Lee K., 2003, P CVPR
   Lee K. C., 2007, P ACCV
   Liao SC, 2013, IEEE T PATTERN ANAL, V35, P1193, DOI 10.1109/TPAMI.2012.191
   Liu HD, 2014, IMAGE VISION COMPUT, V32, P335, DOI 10.1016/j.imavis.2014.02.010
   Liu W., 2006, P ECCV
   Liu X., 2003, P CVPR
   Lu J. W., 2013, P ICCV
   Moeini A, 2015, IMAGE VISION COMPUT, V36, P9, DOI 10.1016/j.imavis.2015.01.007
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Nesterov Y., 1994, Interior-Point Polynomial Algorithms in Convex Programming
   Nishiyama M., 2005, P AVBBPA
   Nishiyama M., 2007, P CVPR
   Shakhnnarvovich G., 2002, P ECCV
   Stallkamp J., 2007, P ICCV, P1
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang R., 2012, P CVPR
   Wang R., 2008, P CVPR, P1
   Wang R. P., 2009, P CVPR
   Wang TS, 2009, PATTERN RECOGN LETT, V30, P1161, DOI 10.1016/j.patrec.2009.06.002
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y., 2013, P BMVC
   Yamaguchi O., 1998, P FG
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yang M., 2015, P FG
   Yang M., 2013, P FG, P1
   Zhang L., 2014, ARXIV12042358
   Zhou S., 2002, P ECCV
   Zhu PF, 2014, IEEE T INF FOREN SEC, V9, P1120, DOI 10.1109/TIFS.2014.2324277
NR 48
TC 17
Z9 18
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 47
EP 60
DI 10.1016/j.imavis.2016.07.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700006
DA 2024-07-18
ER

PT J
AU Xie, J
   Fang, Y
AF Xie, Jin
   Fang, Yi
TI Dynamic texture recognition with video set based collaborative
   representation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dynamic texture classification; Local binary pattern; Texture feature
   extraction; Collaborative representation
ID CLASSIFICATION
AB Efficient feature description and classification of dynamic texture (DT) is an important problem in computer vision and pattern recognition. Recently, the local binary pattern (LBP) based dynamic texture descriptor has been proposed to classify DTs by extending the LBP operator used in static texture analysis to the temporal domain. However, the extended LBP operator cannot characterize the intrinsic motion of dynamic texture well. In this paper, we propose a novel video set based collaborative representation dynamic texture classification method. First, we divide the dynamic texture sequence into subsequences along the temporal axis to form the video set. For each DT, we extract the video set based LBP histogram to describe it. We then propose a regularized collaborative representation model to code the LBP histograms of the query video sets over the LBP histograms of the training video sets. Finally, with the coding coefficients, the distance between the query video set and the training video sets can be calculated for classification. Experimental results on the benchmark dynamic texture datasets demonstrate that the proposed method can yield good performance in terms of both classification accuracy and efficiency. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Fang, Yi] New York Univ Abu Dhabi, Dept Elect & Comp Engn, Abu Dhabi, U Arab Emirates.
   New York Univ Multimedia & Visual Comp, Abu Dhabi, U Arab Emirates.
C3 New York University Abu Dhabi
RP Fang, Y (corresponding author), New York Univ Abu Dhabi, Dept Elect & Comp Engn, Abu Dhabi, U Arab Emirates.
EM jin.xie@nyu.edu; yfang@nyu.edu
CR [Anonymous], P AS C COMP VIS
   [Anonymous], 2005, P INT WORKSH TEXT AN
   [Anonymous], 2006, INT WORKSOP DYNAMICA
   [Anonymous], 2005, WACV MOTION
   Bouthemy P, 1998, INT C PATT RECOG, P905, DOI 10.1109/ICPR.1998.711298
   Chan A.B., 2007, CVPR
   Derpanis KG, 2012, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2012.6247815
   Derpanis KG, 2012, IEEE T PATTERN ANAL, V34, P1193, DOI 10.1109/TPAMI.2011.221
   Derpanis KG, 2010, PROC CVPR IEEE, P191, DOI 10.1109/CVPR.2010.5540213
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Fablet R, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P652, DOI 10.1109/ICIP.2001.958203
   Ghanem B., 2010, LECT NOTES COMPUT SC, P223
   Guo Y., 2013, LOCAL BINARY PATTERN, P113
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Ji H, 2013, IEEE T IMAGE PROCESS, V22, P286, DOI 10.1109/TIP.2012.2214040
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Péteri R, 2005, LECT NOTES COMPUT SC, V3523, P223
   Péteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009
   Ravichandran A, 2013, IEEE T PATTERN ANAL, V35, P342, DOI 10.1109/TPAMI.2012.83
   Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847
   Shao L., 2015, INT J COMPUT VISION, V24, P1
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871
   Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0
   Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372
   Yu MC, 2015, INT SYMP NETW COD, P1, DOI [10.1109/IRMMW-THz.2015.7327562, 10.1080/0740817X.2014.999179, 10.1109/NETCOD.2015.7176778]
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhu PF, 2014, IEEE T INF FOREN SEC, V9, P1120, DOI 10.1109/TIFS.2014.2324277
NR 31
TC 7
Z9 7
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 86
EP 92
DI 10.1016/j.imavis.2016.03.006
PN 2
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300006
DA 2024-07-18
ER

PT J
AU Wang, ZL
   Wang, JJ
   Zhang, S
   Gong, YH
AF Wang, Zelun
   Wang, Jinjun
   Zhang, Shun
   Gong, Yihong
TI Visual tracking based on online sparse feature learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Sparse coding; Sparse feature; Bayesian classifier;
   Haar-like features
ID OBJECT TRACKING; ROBUST
AB Various visual tracking approaches have been proposed for robust target tracking, among which using sparse representation of the tracking target yields promising performance. Some earlier works in this line used a fixed subset of features to compress the target's appearance, which has limited modeling capacity between the target and the background, and could not accommodate their appearance change over long period of time. In this paper, we propose a visual tracking method by modeling targets with online-learned sparse features. We first extract high dimensional Haar-like features as an over-completed basis set, and then solve the feature selection problem in an efficient Lrregularized sparse-coding process. The selected low-dimensional representation best discriminates the target from its neighboring background. Next we use a naive Bayesian classifier to select the most-likely target candidate by a binary classification process. The online feature selection process happens when there are significant appearance changes identified by a thresholding strategy. In this way, our proposed method could work for long tracking tasks. At the same time, our comprehensive experimental evaluation has shown that the proposed methods achieve excellent running speed and higher accuracy over many state-of-the-art approaches. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Wang, Zelun] Texas A&M Univ, College Stn, TX 77843 USA.
   [Wang, Jinjun; Zhang, Shun; Gong, Yihong] Xi An Jiao Tong Univ, Xian 710049, Shaanxi, Peoples R China.
C3 Texas A&M University System; Texas A&M University College Station; Xi'an
   Jiaotong University
RP Wang, JJ (corresponding author), Xi An Jiao Tong Univ, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
EM jinjun@mail.xjtu.edu.cn
OI Zhang, Shun/0000-0003-3380-8957
FU National High Technology Research and Development Program of China (863
   Program) [2014AA015205]; National Science Foundation of China [61332018]
FX This work is supported by the National High Technology Research and
   Development Program of China (863 Program) under Grant No. 2014AA015205,
   and the National Science Foundation of China under Grant No. 61332018.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], COMP VIS PATT REC CV
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mei X, 2013, IEEE T IMAGE PROCESS, V22, P2661, DOI 10.1109/TIP.2013.2255301
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Salti S, 2012, IEEE T IMAGE PROCESS, V21, P4334, DOI 10.1109/TIP.2012.2206035
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Williams C.K.I., PASCAL VISUAL OBJECT
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678
   Zhang K., 2014, Proceedings of the 14th Workshop on Domain-Specific Modeling, P1, DOI DOI 10.1038/KI.2014.274
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 33
TC 8
Z9 8
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2015
VL 38
BP 24
EP 32
DI 10.1016/j.imavis.2015.04.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CK4LX
UT WOS:000356196400003
DA 2024-07-18
ER

PT J
AU Unzueta, L
   Pimenta, W
   Goenetxea, J
   Santos, LP
   Dornaika, F
AF Unzueta, Luis
   Pimenta, Waldir
   Goenetxea, Jon
   Santos, Luis Paulo
   Dornaika, Fadi
TI Efficient generic face model fitting to images and videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face model fitting; Head pose estimation; Facial feature detection; Face
   tracking
ID ACTIVE APPEARANCE MODELS; POSE; FEATURES; TRACKING
AB In this paper we present a robust and lightweight method for the automatic fitting of deformable 3D face models on facial images. Popular fitting techniques such as those based on statistical models of shape and appearance require a training stage based on a set of facial images and their corresponding facial landmarks, which have to be manually labeled. Therefore, new images in which to fit the model cannot differ too much in shape and appearance (including illumination variation, facial hair, wrinkles, etc.) from those used for training. By contrast, our approach can fit a generic face model in two steps: (1) the detection of facial features based on local image gradient analysis and (2) the backprojection of a deformable 3D face model through the optimization of its deformation parameters. The proposed approach can retain the advantages of both learning-free and learning-based approaches. Thus, we can estimate the position, orientation, shape and actions of faces, and initialize user-specific face tracking approaches, such as Online Appearance Models (OAMs), which have shown to be more robust than generic user tracking approaches. Experimental results show that our method outperforms other fitting alternatives under challenging illumination conditions and with a computational cost that allows its implementation in devices with low hardware specifications, such as smartphones and tablets. Our proposed approach lends itself nicely to many frameworks addressing semantic inference in face images and videos. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Unzueta, Luis; Goenetxea, Jon] Vicomtech IK4, Donostia San Sebastian 20009, Spain.
   [Pimenta, Waldir; Santos, Luis Paulo] Univ Minho, Dept Informat, P-4710057 Braga, Portugal.
   [Dornaika, Fadi] Univ Basque Country, EHU UPV, Comp Engn Fac, Donostia San Sebastian 20018, Spain.
   [Dornaika, Fadi] Ikerbasque, Basque Fdn Sci, Bilbao 48011, Spain.
C3 Universidade do Minho; University of Basque Country; Basque Foundation
   for Science
RP Unzueta, L (corresponding author), Vicomtech IK4, Paseo Mikeletegi 57, Donostia San Sebastian 20009, Spain.
EM lunzueta@vicomtech.org; wpimenta@di.uminho.pt; jgoenetxea@vicomtech.org;
   psantos@di.uminho.pt; fadi.dornaika@ehu.es
RI Santos, Luis Paulo/A-1897-2009; Unzueta, Luis/L-6867-2014
OI Santos, Luis Paulo/0000-0003-4466-1129; Unzueta,
   Luis/0000-0001-5648-0910; Pimenta, Waldir/0000-0001-9916-2285;
   Goenetxea, Jon/0000-0001-8412-5123
FU FCT (Portuguese Foundation for Science and Technology)
   [PEst-OE/EEI/UI0752/2011]; Basque Government [S-PR13UN007]
FX We want to acknowledge Fernando De la Torre and Jason Saragih for their
   respective clarifications about the implementations of their methods SDM
   and CLM for the experimental setup. We also thank Nerea Aranjuelo and
   Victor Goni from Vicomtech-IK4 for their aid in the experimental work.
   Luis Paulo Santos is partially funded by the FCT (Portuguese Foundation
   for Science and Technology) within project PEst-OE/EEI/UI0752/2011. This
   work is partially supported by the Basque Government under the project
   S-PR13UN007.
CR Ahlberg J., 2001, CANDIDE-3 -- an updated parameterized face
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2013, P IEEE C COMP VIS PA
   Asteriadis S, 2009, PATTERN RECOGN, V42, P1388, DOI 10.1016/j.patcog.2009.01.009
   Asthana A., 2013, P IEEE C COMP VIS PA
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Blanz V., 2004, COMPUTER VISION PATT, V2, P454
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Chen CW, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3133, DOI 10.1109/IROS.2008.4650788
   Chiang CC, 2003, REAL-TIME IMAGING, V9, P277, DOI 10.1016/j.rti.2003.08.003
   Cootes T.F., 1992, BRIT MACHINCE VISION, P266, DOI DOI 10.1007/978-1-4471-3201-1_28
   Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Da Silva MP, 2009, PSYCHNOLOGY J, V7, P243
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   Dornaika F., 2009, P WORKSH APPL COMP V, P1
   Dornaika F, 2008, INT J COMPUT VISION, V76, P257, DOI 10.1007/s11263-007-0059-7
   Dornaika F, 2006, IEEE T CIRC SYST VID, V16, P1107, DOI 10.1109/TCSVT.2006.881200
   Hamada T, 2000, PATTERN RECOGN LETT, V21, P407, DOI 10.1016/S0167-8655(00)00009-X
   Jeng SH, 1998, PATTERN RECOGN, V31, P273, DOI 10.1016/S0031-3203(97)00048-4
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kalbkhani H, 2013, IET COMPUT VIS, V7, P184, DOI 10.1049/iet-cvi.2011.0091
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Mingcai Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3963, DOI 10.1109/ICPR.2010.964
   Mingcai Zhou, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P919, DOI 10.1109/CSSE.2008.279
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Peng XM, 2011, PATTERN RECOGN, V44, P544, DOI 10.1016/j.patcog.2010.09.015
   Reisfeld D, 1998, COMPUT VIS IMAGE UND, V71, P413, DOI 10.1006/cviu.1997.0640
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tzimiropoulos Georgios, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P650, DOI 10.1007/978-3-642-37431-9_50
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Votsis GN, 2003, SIGNAL PROCESS-IMAGE, V18, P67, DOI 10.1016/S0923-5965(02)00103-0
   Vukadinovic D., 2005, P IEEE INT C SYST MA, V2
   Wong KW, 2001, PATTERN RECOGN, V34, P1993, DOI 10.1016/S0031-3203(00)00134-5
   Xiao J, 2004, PROC CVPR IEEE, P535
   Zhang C., 2010, A survey of recent advances in face detection
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 44
TC 15
Z9 16
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2014
VL 32
IS 5
BP 321
EP 334
DI 10.1016/j.imavis.2014.02.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AH3HI
UT WOS:000336013900002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lakemond, R
   Fookes, C
   Sridharan, S
AF Lakemond, Ruan
   Fookes, Clinton
   Sridharan, Sridha
TI Evaluation of two-view geometry methods with automatic ground-truth
   generation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Evaluation; Database; Automated ground truth; Structure from motion;
   Multi-view geometry
ID INTEREST POINT DETECTORS; CALIBRATION; DESCRIPTORS; PERFORMANCE;
   FEATURES; SCALE
AB A large number of methods have been published that aim to evaluate various components of multi-view geometry systems. Most of these have focused on the feature extraction, description and matching stages (the visual front end), since geometry computation can be evaluated through simulation. Many data sets are constrained to small scale scenes or planar scenes that are not challenging to new algorithms, or require special equipment. This paper presents a method for automatically generating geometry ground truth and challenging test cases from high spatio-temporal resolution video. The objective of the system is to enable data collection at any physical scale, in any location and in various parts of the electromagnetic spectrum.
   The data generation process consists of collecting high resolution video, computing accurate sparse 3D reconstruction, video frame culling and down sampling, and test case selection. The evaluation process consists of applying a test 2-view geometry method to every test case and comparing the results to the ground truth. This system facilitates the evaluation of the whole geometry computation process or any part thereof against data compatible with a realistic application. A collection of example data sets and evaluations is included to demonstrate the range of applications of the proposed system. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Lakemond, Ruan; Fookes, Clinton; Sridharan, Sridha] Queensland Univ Technol, Image & Video Res Lab, Brisbane, Qld 4001, Australia.
C3 Queensland University of Technology (QUT)
RP Lakemond, R (corresponding author), GPO Box 2434, Brisbane, Qld 4001, Australia.
EM r.lakemond@qut.edu.au; c.fookes@qut.edu.au; s.sridharan@qut.edu.au
RI ; Fookes, Clinton/I-9786-2012
OI Sridharan, Sridha/0000-0003-4316-9001; Fookes,
   Clinton/0000-0002-8515-6324
FU Australian Research Council [LP0990135]; Australian Research Council
   [LP0990135] Funding Source: Australian Research Council
FX This project was supported by Australian Research Council grant number
   LP0990135.
CR Aanæs H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8
   Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694
   [Anonymous], P INT C SIGN PROC CO
   [Anonymous], P EUROPEAN C COMPUTE, DOI DOI 10.1007/3-540-57956-7
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   Bradski G., DR DOBBS J SOFTWARE
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fraundorfer F., 2005, Proceedings of computer vision and pattern recognition-CVPR workshops, P33
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Ke Y, 2004, PROC CVPR IEEE, P506
   Lakemond R., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P530, DOI 10.1109/DICTA.2011.95
   Lakemond R, 2011, IET COMPUT VIS, V5, P222, DOI 10.1049/iet-cvi.2010.0045
   Lakemond R., 2011, J MATH IMAGING VIS, P1
   Lakemond R., 2010, THESIS QUEENSLAND U
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Lieberknecht S, 2009, INT SYM MIX AUGMENT, P145, DOI 10.1109/ISMAR.2009.5336487
   Liu J., 2009, P INT SENS SENS NETW
   Liu J, 2006, LECT NOTES COMPUT SC, V4291, P558
   López AM, 1999, IEEE T PATTERN ANAL, V21, P327, DOI 10.1109/34.761263
   Lourakis Manolis IA, 2009, ACM TRANS MATH SOFTW, V36, P1, DOI DOI 10.1145/1486525.1486527
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   McCane B, 2001, COMPUT VIS IMAGE UND, V84, P126, DOI 10.1006/cviu.2001.0930
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Papalazarou C, 2009, LECT NOTES COMPUT SC, V5807, P1
   Pinto N., 2011, IEEE WORKSHOP APPL C, P463, DOI [10.1109/WACV. 2011.5711540., DOI 10.1109/WACV.2011.5711540]
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Stolkin R, 2006, MEAS SCI TECHNOL, V17, P2721, DOI 10.1088/0957-0233/17/10/026
   Strecha C., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587706
   Torr PHS, 1999, INT J COMPUT VISION, V32, P27, DOI 10.1023/A:1008140928553
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Vidas S., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P217, DOI 10.1109/DICTA.2011.43
   Vidas S, 2012, IEEE T INSTRUM MEAS, V61, P1625, DOI 10.1109/TIM.2012.2182851
   Williams C.K.I., PASCAL VISUAL OBJECT
   Winder S.A. J., 2007, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1
   Zimmermann K, 2009, IEEE T PATTERN ANAL, V31, P677, DOI 10.1109/TPAMI.2008.119
NR 50
TC 3
Z9 5
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2013
VL 31
IS 12
BP 921
EP 934
DI 10.1016/j.imavis.2013.09.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 282DU
UT WOS:000329151300003
DA 2024-07-18
ER

PT J
AU Dupac, J
   Matas, J
   Naiser, F
AF Dupac, Jan
   Matas, Jiri
   Naiser, Filip
TI Ultra-fast tracking based on zero-shift points
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Tracking; Zero-shift point (ZSP); Multi-scale Flock of ZSPs
AB A novel tracker of so called zero-shift points (ZSPs) is presented. ZSPs are points where a dot product with a single period of a sinusoidal wave, both in horizontal and vertical directions, is equal to zero. Very efficient tracking and localization of ZSPs is possible as a consequence of the existence of the field of 2D shift vectors pointing toward them. A single point is tracked on average in less than 10 mu s on a standard notebook. When organized in a Multi-scale Flock (MSF), the ZSPs become a core of a robust, fast and accurate tracker. We demonstrated the applicability of the combination of MSF-ZSP with RANSAC based homography estimation on standard sequences reporting good tracking results. (C) 2012 Published by Elsevier B.V.
C1 [Matas, Jiri; Naiser, Filip] Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Prague 16627 6, Czech Republic.
   [Dupac, Jan] RS Dynam Sro, Prague 14900 4, Czech Republic.
C3 Czech Technical University Prague
RP Matas, J (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Prague 16627 6, Czech Republic.
EM matas@cmp.felk.cvut.cz
RI , Matas/AAW-3282-2020
OI Matas, Jiri/0000-0003-0863-4844
FU Czech Science Foundation [GACR P103/12/G084]; EC project [FP7-ICT-247022
   MASH]
FX The authors were supported by the Czech Science Foundation Project GACR
   P103/12/G084 and EC project FP7-ICT-247022 MASH.
CR [Anonymous], 1977, TECHNIQUES AUTOMATIC
   Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dupac J., 2011, CTUCMP201104 DEP CYB
   Dupac J., 2011, P 36 INT C AC SPEECH
   Dupac J, 2006, LECT NOTES COMPUT SC, V4174, P760
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Holzer S, 2010, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2010.5539851
   Jurie F., 2002, P BRIT MACH VIS C BM
   Kalal Z., 2011, INT C PATT REC
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Klein G., 2007, 6 IEEE ACM INT S MIX
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Zimmermann K, 2009, IEEE T PATTERN ANAL, V31, P677, DOI 10.1109/TPAMI.2008.119
NR 18
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 1016
EP 1031
DI 10.1016/j.imavis.2012.08.015
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800009
DA 2024-07-18
ER

PT J
AU Guerra-Filho, G
   Biswas, A
AF Guerra-Filho, Gutemberg
   Biswas, Arnab
TI The human motion database: A cognitive and parametric sampling of human
   motion
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Human motion database; Quantitative evaluation; Parametric and cognitive
   sampling; Motion synthesis and analysis
AB Motion databases have a strong potential to guide progress in the field of machine recognition and motion-based animation. Existing databases either have a very loose structure that does not sample the domain according to any controlled methodology or too few action samples which limit their potential to quantitatively evaluate the performance of motion-based techniques. The controlled sampling of the motor domain in the database may lead investigators to identify the fundamental difficulties of motion cognition problems and allow the addressing of these issues in a more objective way. In this paper, we describe the construction of our Human Motion Database using controlled sampling methods (parametric and cognitive sampling) to obtain the structure necessary for the quantitative evaluation of several motion-based research problems. The Human Motion Database is organized into several components: the praxicon dataset, the cross-validation dataset, the generalization dataset, the compositionality dataset, and the interaction dataset The main contributions of this paper include (1) a survey of human motion databases describing data sources related to motion synthesis and analysis problems, (2) a sampling methodology that takes advantage of a systematic controlled capture, denoted as cognitive sampling and parametric sampling, and (3) a novel structured motion database organized into several datasets addressing a number of aspects in the motion domain. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Guerra-Filho, Gutemberg; Biswas, Arnab] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA.
C3 University of Texas System; University of Texas Arlington
RP Guerra-Filho, G (corresponding author), Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA.
EM guerra@cse.uta.edu; abiswas@uta.edu
CR [Anonymous], 2006, CS0608 BROWN U
   [Anonymous], 2001, CMU MOTION BODY MOBO
   [Anonymous], 2007, Computer Graphics Technical Report CG-2007-2
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Hwang BW, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P243
   ICS, 2003, ICS ACT DAT
   Ma YL, 2006, BEHAV RES METHODS, V38, P134, DOI 10.3758/BF03192758
NR 7
TC 27
Z9 33
U1 1
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 251
EP 261
DI 10.1016/j.imavis.2011.12.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000013
OA Green Published
DA 2024-07-18
ER

PT J
AU Garcia-Diaz, A
   Fdez-Vidal, XR
   Pardo, XM
   Dosil, R
AF Garcia-Diaz, Anton
   Fdez-Vidal, Xose R.
   Pardo, Xose M.
   Dosil, Raquel
TI Saliency from hierarchical adaptation through decorrelation and variance
   normalization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Saliency; Bottom-up; Eye fixations; Decorrelation; Whitening; Visual
   attention
ID COLOR; ORIENTATION; ATTENTION; FRAMEWORK; MODEL
AB This paper presents a novel approach to visual saliency that relies on a contextually adapted representation produced through adaptive whitening of color and scale features. Unlike previous models, the proposal is grounded on the specific adaptation of the basis of low level features to the statistical structure of the image. Adaptation is achieved through decorrelation and contrast normalization in several steps in a hierarchical approach, in compliance with coarse features described in biological visual systems. Saliency is simply computed as the square of the vector norm in the resulting representation. The performance of the model is compared with several state-of-the-art approaches, in predicting human fixations using three different eye-tracking datasets. Referring this measure to the performance of human priority maps, the model proves to be the only one able to keep the same behavior through different datasets, showing free of biases. Moreover, it is able to predict a wide set of relevant psychophysical observations, to our knowledge, not reproduced together by any other model before. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Garcia-Diaz, Anton; Fdez-Vidal, Xose R.; Pardo, Xose M.; Dosil, Raquel] Univ Santiago de Compostela, Dept Elect & Comp Sci, Comp Vis Grp, Santiago De Compostela, Spain.
C3 Universidade de Santiago de Compostela
RP Garcia-Diaz, A (corresponding author), Univ Santiago de Compostela, Dept Elect & Comp Sci, Comp Vis Grp, Santiago De Compostela, Spain.
EM anton.garcia@usc.es; xose.vidal@usc.es; xose.pardo@usc.es;
   raquel.dosil@usc.es
RI Dosil, Raquel/JSK-7672-2023; Fdez-Vidal, Xose R./L-5740-2014; Pardo,
   Xose M./L-8567-2014
OI Dosil, Raquel/0000-0001-8171-9268; Garcia-Diaz,
   Anton/0000-0001-5965-9238; Fdez-Vidal, Xose R./0000-0001-9388-7461;
   Pardo, Xose M./0000-0002-3997-5150
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2008, BRIT MACHINE VISION
   [Anonymous], 2008, NIPS
   [Anonymous], THESIS U W AUSTR
   Birmingham E, 2009, VISION RES, V49, P2992, DOI 10.1016/j.visres.2009.09.014
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Bruce NDB, 2009, IEEE IMAGE PROC, P3089, DOI 10.1109/ICIP.2009.5414483
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   CARDOSO JF, 1993, IEE PROC-F, V140, P362, DOI 10.1049/ip-f-2.1993.0054
   Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Garcia-Diaz A, 2009, LECT NOTES COMPUT SC, V5807, P343
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Harel J, 2009, LECT NOTES ARTIF INT, V5395, P1
   Hou X., 2007, ADV NEURODYN, P999
   Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kanan C., 2010, IEEE INT C COMP VIS
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Liu Z, 2010, OPT ENG, V49, DOI 10.1117/1.3281667
   Morrone M.C., 1998, P ROY SOC LOND B BIO, P221
   NOTHDURFT HC, 1993, SPATIAL VISION, V7, P341, DOI 10.1163/156856893X00487
   Parikh N, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/1/016006
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Rosenholtz R, 2004, J VISION, V4, P224, DOI 10.1167/4.3.9
   Ruesch J, 2008, IEEE INT CONF ROBOT, P962, DOI 10.1109/ROBOT.2008.4543329
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   TREISMAN A, 1988, PSYCHOL REV, V95, P15, DOI 10.1037/0033-295X.95.1.15
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
   Zhaoping L, 2006, VIS COGN, V14, P911, DOI 10.1080/13506280500196035
NR 40
TC 160
Z9 167
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2012
VL 30
IS 1
BP 51
EP 64
DI 10.1016/j.imavis.2011.11.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900WC
UT WOS:000300921400005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gordon, S
   Greenspan, H
AF Gordon, Shiri
   Greenspan, Hayit
TI An agglomerative segmentation framework for non-convex regions within
   uterine cervix images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Medical image analysis; Image segmentation; Graph cuts; Cervical cancer;
   Cervicography images
ID CLASSIFICATION; COLOR
AB The National Cancer Institute has collected a large database of uterine cervix images termed "cervigrams", for cervical cancer screening research. Tissues of interest within the cervigram, in particular the lesions, are of varying sizes and of complexnon-convex shapes. The tissues possess similar color features and their boundaries are not always clear. The main objective of the current work is to provide a segmentation framework for tissues of interest within the cervix, that can cope with these difficulties in an unsupervised manner and with a minimal number of parameters.
   The proposed framework transitions from pixels to a set of small coherent regions (superpixels), which are grouped bottom-up into larger, non-convex, perceptually similar regions. The merging process is performed utilizing a new graph-cut criterion termed the normalized-mean cut (NMCut) and an agglomerative clustering framework. Superpixels similarity is computed via a locally scaled similarity measure that combines region and edge information. Segmentation quality is evaluated by measuring the overlap accuracy of the generated segments and tissues that were manually marked by medical experts.
   Experiments are conducted on two sets of cervigrams and lead to the following set of observations and conclusions: 1) The generated superpixels provide an accurate decomposition of the different tissues; 2) The local scaling process improves the clustering results; 3) The influence of different graph-cut criterions on the segmentation accuracy is evaluated and the NMCut criterion is shown to provide the best results; 4) A comparison between several modifications to the agglomerative clustering process is conducted. The results are shown to be strongly influenced by the merging procedure; 5) The agglomerative clustering framework is shown to outperform a state-of-the-art spectral clustering algorithm. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Gordon, Shiri; Greenspan, Hayit] Tel Aviv Univ, IL-69978 Tel Aviv, Israel.
C3 Tel Aviv University
RP Gordon, S (corresponding author), Tel Aviv Univ, IL-69978 Tel Aviv, Israel.
EM gordonha@post.tau.ac.il
FU Communications Engineering Branch, NLM, NIH; Hormonal and Reproductive
   Epidemiology Branch, NCI, NIH
FX We would like to thank the Communications Engineering Branch, NLM, NIH
   and the Hormonal and Reproductive Epidemiology Branch, NCI, NIH, for the
   data and support of the work.
CR [Anonymous], 2001, CVPR
   [Anonymous], 2001, SPECTRAL CLUSTERING
   Corona E, 2008, 2008 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS & INTERPRETATION, P145, DOI 10.1109/SSIAI.2008.4512306
   CRISTOFORONI PM, 1995, OBSTET GYNECOL, V85, P1011, DOI 10.1016/0029-7844(95)00051-R
   Ding C, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P139, DOI 10.1109/ICDM.2002.1183896
   Dvir H., 2006, P 2006 C COMP VIS PA, P95
   FOWLKES C, 2004, CSD041340 U CAL DIV
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   GORDON S, 2007, P IEEE INT S BIOM IM
   HERMES L, 2002, EUR C COMP VIS, V2, P577
   Huang Xiaolei, 2008, P SPIE MED IMAGING
   Jeronimo J, 2003, INT J GYNECOL OBSTET, V83, P311, DOI 10.1016/S0020-7292(03)00299-6
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   Kullback S., 1968, INFORM THEORY STAT
   Lange H, 2005, P SOC PHOTO-OPT INS, V5747, P1004, DOI 10.1117/12.596064
   LI W, 2008, P SPIE MED IMAGING
   MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468
   O'Callaghan RJ, 2005, IEEE T IMAGE PROCESS, V14, P49, DOI 10.1109/TIP.2004.838695
   Park SY, 2008, J BIOMED OPT, V13, DOI 10.1117/1.2830654
   Pogue BW, 2000, J BIOMED OPT, V5, P72, DOI 10.1117/1.429971
   Schiffman M, 2000, ACTA CYTOL, V44, P726, DOI 10.1159/000328554
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Srinivasan Y, 2005, PROC SPIE, V5747, P995, DOI 10.1117/12.597075
   *US FDA, P040028 PMA US FOOD
   Van Raad V, 2006, PROC SPIE, V6144, DOI 10.1117/12.651119
   Zelnik-Manor Lihi, 2004, P NEUR INF PROC SYST
   ZIMMERMAN G, 2006, P SPIE MED IMAGING, V6144, P2037
   Zimmerman G, 2006, I S BIOMED IMAGING, P1348
NR 29
TC 4
Z9 5
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1682
EP 1701
DI 10.1016/j.imavis.2010.05.008
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300010
DA 2024-07-18
ER

PT J
AU Haro, G
   Pardàs, M
AF Haro, Gloria
   Pardas, Montse
TI Shape from incomplete silhouettes based on the reprojection error
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape from silhouette; Visual hull; Multi-camera; Background subtraction
AB Traditional shape from silhouette methods compute the 3D shape as the intersection of the back-projected silhouettes in the 3D space, the so called visual hull. However, silhouettes that have been obtained with background subtraction techniques often present miss-detection errors (produced by false negatives or occlusions) which produce incomplete 3D shapes. Our approach deals with miss-detections, false alarms, and noise in the silhouettes. We recover the voxel occupancy which describes the 3D shape by minimizing an energy based on an approximation of the error between the shape 2D projections and the silhouettes. Two variants of the projection - and as a result the energy - as a function of the voxel occupancy are proposed. One of these variants outperforms the other. The energy also includes a sparsity measure, a regularization term, and takes into account the visibility of the voxels in each view in order to handle self-occlusions. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Haro, Gloria] Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona, Spain.
   [Pardas, Montse] Univ Politecn Cataluna, Dept Signal Theory & Commun, E-08028 Barcelona, Spain.
C3 Pompeu Fabra University; Universitat Politecnica de Catalunya
RP Haro, G (corresponding author), Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona, Spain.
EM gloria.haro@upf.edu; montse.pardas@upc.edu
RI Pardas, Montse/G-3967-2014; Haro, Gloria/D-3394-2014
OI Pardas, Montse/0000-0002-5861-6356; Haro, Gloria/0000-0002-8194-8092
FU Spanish Ministerio de Ciencia e Innovacion [TEC2007-66858/TCM, MTM
   2009-08171, CENIT-VISION 2007-1007]
FX This work has been partially supported by the Spanish Ministerio de
   Ciencia e Innovacion, under Juan de la Cierva program, Ramon y Cajal
   program, project TEC2007-66858/TCM, project MTM 2009-08171, and project
   CENIT-VISION 2007-1007. We thank Marcel Alcoverro and Albert Gil for
   their help and assistance with the code. We also thank Marcel Alcoverro,
   Josep Ramon Casas, Vicent Caselles and Jordi Salvador for fruitful
   conversations. Finally, we thank the reviewers for their useful comments
   which helped to improve the manuscript. GH performed Part of this work
   while at Universitat Politecnica de Catalunya thanks to Juan de la
   Cierva program.
CR [Anonymous], THESIS STANFORD U
   Casas J.R., 2006, P HCSNET WORKSH US V
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Cheung GKM, 2000, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2000.854944
   DEBONET J, 1999, P IEEE 11 INT C COMP
   Franco J.S., 2003, P 14 BRIT MACHINE VI, P329, DOI [10.5244/C.17.32, DOI 10.5244/C.17.32]
   Franco JS, 2009, IEEE T PATTERN ANAL, V31, P414, DOI 10.1109/TPAMI.2008.104
   Franco JS, 2005, IEEE I CONF COMP VIS, P1747
   Gargallo P., 2007, P IEEE 11 INT C COMP, P1
   GARGALLO P, 2007, P 8 AS C COMP VIS AC
   HARO G, 2009, P 10 INT WORKSH IM A
   HERNANDEZ C, 2007, P 2007 IEEE C COMP V
   Kolev K., 2007, WORKSH PHOT AN COMP
   KOLEV K, 2008, EUR C COMP VIS ECCV
   Landabaso JL, 2008, COMPUT VIS IMAGE UND, V112, P210, DOI 10.1016/j.cviu.2008.02.006
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Lintner S, 2004, INVERSE PROBL, V20, P815, DOI 10.1088/0266-5611/20/3/010
   MANESSIS A, 2000, P INT C COMP VIS PAT, V2, P666
   Matusik W, 2001, SPRING EUROGRAP, P115
   Matusik W., 2000, P SIGGRAPH
   MICHOUD B, 2006, P EUR, P13
   Rockafellar R. T., 2015, CONVEX ANAL, DOI DOI 10.1515/9781400873173
   SINHA S, 2005, P IEEE 11 INT C COMP
   Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839
   SOLEM JE, 2005, P 2005 IEEE C COMP V, V2, P892
   TAYLOR CJ, 2003, P IEEE 9 INT C COMP, V1
NR 26
TC 13
Z9 16
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2010
VL 28
IS 9
BP 1354
EP 1368
DI 10.1016/j.imavis.2010.01.016
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 620NN
UT WOS:000279506700003
DA 2024-07-18
ER

PT J
AU Sun, TH
   Tseng, CC
   Chen, MS
AF Sun, Te-Hsiu
   Tseng, Chun-Chieh
   Chen, Min-Sheng
TI Electric contacts inspection using machine vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Machine vision; Surface defects; Electric contact; Computer vision;
   Quality control
ID AUTOMATED VISUAL INSPECTION; METAL-SURFACE INSPECTION; DEFECTS; SYSTEM
AB Machine vision is an excellent tool for inspecting a variety of industrial items such as textiles, printed circuit boards, electric components, labels, integrated circuits (IC), machine tools and fruits. In this paper, we propose machine vision-based inspection system for electric contact (EC), which are popularly used in switches, breakers and relays, and are important components in the electrical industry. The proposed system consists of three sub-systems, which inspect the top, side, and bottom surfaces of electric contact for different types of defects respectively. The system acquires the digital image of three views and classifies the surface defects including cracks, breaks, and scratches. For each view, this study develops different image pre-processing and feature extraction methods to enhance and detect the surface defects. The proposed system was implemented and verified using 229 samples collected from the EC production lines. Experimental results show the proposed system is effective and efficient in identifying EC defects. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Sun, Te-Hsiu] Chaoyang Univ Technol, Dept Ind Engn & Management, Wufeng 413, Taichung County, Taiwan.
   [Tseng, Chun-Chieh; Chen, Min-Sheng] Natl Yunlin Univ Sci & Technol, Dept Ind Engn & Management, Yunlin, Taiwan.
C3 Chaoyang University of Technology; National Yunlin University Science &
   Technology
RP Sun, TH (corresponding author), Chaoyang Univ Technol, Dept Ind Engn & Management, 168 Gifeng E Rd, Wufeng 413, Taichung County, Taiwan.
EM tehsiusun@yahoo.com.tw
CR BATCHELOR BG, 1983, IMAGE VISION COMPUT, P21
   Blasco J, 2007, J FOOD ENG, V81, P535, DOI 10.1016/j.jfoodeng.2006.12.007
   Chen MC, 2002, COMPUT IND, V47, P185, DOI 10.1016/S0166-3615(01)00143-9
   Chen MC, 2000, INT J PROD RES, V38, P2967, DOI 10.1080/00207540050117396
   Chen MC, 1999, PATTERN RECOGN LETT, V20, P707, DOI 10.1016/S0167-8655(99)00035-5
   CHIN RT, 1988, COMPUT VISION GRAPH, V41, P346, DOI 10.1016/0734-189X(88)90108-9
   CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309
   DON HS, 1984, IEEE T SYST MAN CYB, V14, P139, DOI 10.1109/TSMC.1984.6313276
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Guu SM., 1999, Proc. Natl. Sci. Counc. Repub. China Part A Phys. Sci. Eng, V23, P348
   Lahajnar F, 2002, COMPUT IND, V47, P113, DOI 10.1016/S0166-3615(01)00134-8
   LEE HK, 1999, IEEE INT C SYST MAN, V2, P975
   Lin HD, 2007, IMAGE VISION COMPUT, V25, P1785, DOI 10.1016/j.imavis.2007.02.002
   Malamas EN, 2003, IMAGE VISION COMPUT, V21, P171, DOI 10.1016/S0262-8856(02)00152-X
   Martínez-Antón JC, 2001, P SOC PHOTO-OPT INS, V4399, P27, DOI 10.1117/12.445586
   McBride JW, 1996, IEEE T COMPON PACK A, V19, P87, DOI 10.1109/95.486567
   Meriaudeau F, 2002, P SOC PHOTO-OPT INS, V4664, P190, DOI 10.1117/12.460197
   NADABAR SG, 1995, P SOC PHOTO-OPT INS, V2622, P616, DOI 10.1117/12.216858
   NEWMAN TS, 1995, COMPUT VIS IMAGE UND, V61, P231, DOI 10.1006/cviu.1995.1017
   SANBY C, 1995, MECHATRONICS, V5, P215, DOI 10.1016/0957-4158(95)00012-T
   Spath H, 1996, COMPUTING, V57, P179, DOI 10.1007/BF02276879
   Steiner D, 2007, J COMPUT INF SCI ENG, V7, P85, DOI 10.1115/1.2424244
   SURESH BR, 1983, IEEE T PATTERN ANAL, V5, P563, DOI 10.1109/TPAMI.1983.4767445
   Suzuki K, 2003, COMPUT VIS IMAGE UND, V89, P1, DOI 10.1016/S1077-3142(02)00030-9
   Thomas A. D. H., 1995, Real-Time Imaging, V1, P139, DOI 10.1006/rtim.1995.1014
   Tien FC, 2004, INT J PROD RES, V42, P2477, DOI 10.1080/00207540310001659656
   Wang MJJ, 2002, INT J PROD RES, V40, P2835, DOI 10.1080/00207540210136568
   WONG BK, 1995, IEE C APPL MACH VIS
   Wu WY, 2003, IMAGING SCI J, V51, P79, DOI 10.1080/13682199.2003.11784415
   Wu WY, 1996, COMPUT IND, V28, P103, DOI 10.1016/0166-3615(95)00063-1
   Xian W., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P1490, DOI 10.1109/ROBOT.1990.126217
   Zheng H, 2002, J MATER PROCESS TECH, V125, P427, DOI 10.1016/S0924-0136(02)00294-7
NR 32
TC 47
Z9 63
U1 11
U2 68
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 890
EP 901
DI 10.1016/j.imavis.2009.11.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200005
DA 2024-07-18
ER

PT J
AU Liu, C
   Yuen, PC
AF Liu, Chang
   Yuen, Pong C.
TI Human action recognition using boosted EigenActions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human action recognition; Salient action unit; Adaboost
ID MOTION; SURVEILLANCE; MANIFOLDS; TRACKING; SHAPE
AB This paper proposes a boosting EigenActions algorithm for human action recognition. A spatio-temporal Information Saliency Map (ISM) is calculated from a video sequence by estimating pixel density function. A continuous human action is segmented into a set of primitive periodic motion cycles from information saliency curve. Each cycle of motion is represented by a Salient Action Unit (SAU), which is used to determine the EigenAction using principle component analysis. A human action classifier is developed using multi-class Adaboost algorithm with Bayesian hypothesis as the weak classifier. Given a human action video sequence, the proposed method effectively locates the SAUs in the video, and recognizes the human actions by categorizing the SAUs. Two publicly available human action databases, namely KTH and Weizmann, are selected for evaluation. The average recognition accuracy are 81.5% and 98.3% for KTH and Weizmann databases, respectively. Comparative results with two recent methods and robustness test results are also reported. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Liu, Chang; Yuen, Pong C.] Hong Kong Baptist Univ, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Baptist University
RP Yuen, PC (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
EM cliu@comp.hkbu.edu.hk; pcyuen@comp.hkbu.edu.hk
OI Yuen, Pong Chi/0000-0002-9343-2202; Liu, Chang/0009-0001-7457-0204
FU Hong Kong Baptist University
FX This project is partially supported by the Faculty Research Grant of
   Hong Kong Baptist University. The authors would like to thank the
   Computer Vision Lab in Weizmann Institute of Science for the
   contribution of the Weizmann human action dataset, and thank the
   Computer Vision & Active Perception Lab in Royal Institute of Technology
   for the contribution of the KTH human action dataset.
CR Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   Ali S., 2008, IEEE T PATTERN ANAL
   [Anonymous], P IEEE C COMP VIS PA
   Babu RV, 2004, IMAGE VISION COMPUT, V22, P597, DOI 10.1016/j.imavis.2003.11.004
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Brand M, 2000, IEEE T PATTERN ANAL, V22, P844, DOI 10.1109/34.868685
   Briassouli A, 2007, IEEE T PATTERN ANAL, V29, P1244, DOI [10.1109/TPAMI.2007.1042, 10.1109/TPAMI.2007.1042.]
   Davis JW, 2002, INT C PATT RECOG, P315, DOI 10.1109/ICPR.2002.1044702
   DOLLAR P, 2005, IEEE INT WORKSH VIS, P5
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Fathi A., 2008, IEEE COMP SOC C COMP
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   JIA K, 2008, IEEE COMP SOC C COMP
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   LIU C, 2008, IEEE INT C AUT FAC G
   Liu C, 2009, PATTERN RECOGN, V42, P2897, DOI 10.1016/j.patcog.2009.02.002
   Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604
   Liu J., 2008, IEEE COMP SOC C COMP
   Mang T, 2008, PATTERN RECOGN, V41, P2309, DOI 10.1016/j.patcog.2007.11.024
   Masoud O, 2003, IMAGE VISION COMPUT, V21, P729, DOI 10.1016/S0262-8856(03)00068-4
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oh SM, 2008, INT J COMPUT VISION, V77, P103, DOI 10.1007/s11263-007-0062-z
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4
   Paulhac L, 2008, LECT NOTES COMPUT SC, V5112, P670, DOI 10.1007/978-3-540-69812-8_66
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Ren HB, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P523
   Ren HB, 2002, INT C PATT RECOG, P494, DOI 10.1109/ICPR.2002.1048346
   RODRIGUEZ M, 2008, IEEE COMP SOC C COMP
   Ryoo MS, 2009, INT J COMPUT VISION, V82, P1, DOI 10.1007/s11263-008-0181-1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   SHI Q, 2008, IEEE COMP SOC C COMP
   SOUVENIR R, 2008, IEEE COMP SOC C COMP
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2008, COMPUT VIS IMAGE UND, V110, P153, DOI 10.1016/j.cviu.2007.06.001
   Wang L, 2007, IEEE T IMAGE PROCESS, V16, P1646, DOI 10.1109/TIP.2007.896661
   Xiang SM, 2008, PATTERN RECOGN, V41, P3653, DOI 10.1016/j.patcog.2008.05.016
   Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Yi HR, 2005, PATTERN RECOGN LETT, V26, P1221, DOI 10.1016/j.patrec.2004.11.011
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Zelnik-Manor L, 2006, IEEE T PATTERN ANAL, V28, P1530, DOI 10.1109/TPAMI.2006.194
NR 49
TC 32
Z9 36
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 825
EP 835
DI 10.1016/j.imavis.2009.07.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900011
DA 2024-07-18
ER

PT J
AU Xiong, L
   Zheng, NN
   Liu, JY
   Du, SY
   Liu, YH
AF Xiong, Lei
   Zheng, Nanning
   Liu, Jianyi
   Du, Shaoyi
   Liu, Yuehu
TI Eye synthesis using the eye curve model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image processing; Shape modeling; Facial expression synthesis; Image
   warping
AB Eyes are a critical part in exhibiting facial expressions. Because of the appearance diversity of eyes due to motion, it is difficult to synthesize eye with a particular facial expression. Traditional methods have failed to adequately catch motion-related appearance changes. In order to generate a photorealistic expression eye, we propose a two-step method. First, we propose a curve-based model to represent eyes. The model uses one circle and four skewed elliptical arcs to represent the shape of eyes, and divides the entire eye region into six sub-regions that correspond to different anatomical components of eyes. Then we propose a structure-based-similarity (SBS) framework to synthesize expression eyes using the eye curve model. The main contributions of this paper are: first of all, the proposed eye curve model can represent the diversity of eyes due to motion and structure, which is better than some traditional models. Second, the SBS framework is flexible. In multiple samples and multiple targets situation, the framework can synthesize eyes which exhibit same expression with different personal style. In single sample and single target situation, the framework can clone this expression successful. Experimental results show that synthesized eyes are realistic and expressive. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Xiong, Lei; Zheng, Nanning; Liu, Jianyi; Du, Shaoyi; Liu, Yuehu] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi Prov, Peoples R China.
   [Xiong, Lei] AF Engn Univ, Xian 710038, Peoples R China.
C3 Xi'an Jiaotong University; Air Force Engineering University
RP Xiong, L (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi Prov, Peoples R China.
EM Lei.xiong12@gmail.com
RI Liu, Kai/IST-6808-2023
CR Abboud B, 2005, IEE P-VIS IMAGE SIGN, V152, P327, DOI 10.1049/ip-vis:20045060
   Abboud B, 2004, SIGNAL PROCESS-IMAGE, V19, P723, DOI 10.1016/j.image.2004.05.009
   [Anonymous], 2000, P 4 IEEE INT C AUT F
   BOYLE EA, 1994, LANG SPEECH, V37, P1, DOI 10.1177/002383099403700101
   Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657
   Deng JY, 1997, PATTERN RECOGN, V30, P403, DOI 10.1016/S0031-3203(96)00086-6
   DU YZ, 2004, THESIS TSINGHUA U BE
   Ekman P., 2002, FACIAL ACTION CODING
   Fukuda K, 2001, INT J PSYCHOPHYSIOL, V40, P239, DOI 10.1016/S0167-8760(00)00192-6
   Ghent J, 2005, IMAGE VISION COMPUT, V23, P1041, DOI 10.1016/j.imavis.2005.06.011
   Jiang Da-Long, 2004, Chinese Journal of Computers, V27, P750
   Kalra P., 1992, Computer Graphics Forum, V11, pC59, DOI 10.1111/1467-8659.1130059
   Lei Xiong, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P473
   Liu ZC, 2001, COMP GRAPH, P271
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Moriyama T, 2006, IEEE T PATTERN ANAL, V28, P738, DOI 10.1109/TPAMI.2006.98
   Moriyama T, 2002, INT C PATT RECOG, P78, DOI 10.1109/ICPR.2002.1047404
   Parke F., 1996, COMPUTER FACIAL ANIM
   SINGH K., 1998, SIGGRAPH 98, P405, DOI DOI 10.1145/280814.280946
   TIAN Y, 2000, P INT C MULT US INT, P143
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   Yuille A. L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P104, DOI 10.1109/CVPR.1989.37836
   ZHANG Q, 2003, P ACM SIGGRAPH EUR S, P16
NR 23
TC 3
Z9 4
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 329
EP 342
DI 10.1016/j.imavis.2009.06.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300005
DA 2024-07-18
ER

PT J
AU Chen, Y
   Adjouadi, M
   Han, CA
   Wang, J
   Barreto, A
   Rishe, N
   Andrian, J
AF Chen, Yu
   Adjouadi, Malek
   Han, Changan
   Wang, Jin
   Barreto, Armando
   Rishe, Naphtali
   Andrian, Jean
TI A highly accurate and computationally efficient approach for
   unconstrained iris segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Image processing; Color images; Iris segmentation; Iris
   recognition; Hough transform; Step length; Noise reduction; Non-circular
   iris boundary
ID RECOGNITION
AB Biometric research has experienced significant advances in recent years given the need for more stringent security requirements. More important is the need to overcome the rigid constraints necessitated by the practical implementation of sensible but effective security methods such as iris recognition. An inventive iris acquisition method with less constrained image taking conditions can impose minimal to no constraints on the iris verification and identification process as well as on the subject. Consequently, to provide acceptable measures of accuracy, it is critical for such an iris recognition system to be complemented by a robust iris segmentation approach to overcome various noise effects introduced through image capture under different recording environments and scenarios. This research introduces a robust and fast segmentation approach towards less constrained iris recognition using noisy images contained in the UBIRIS.v2 database (the second version of the UBIRIS noisy iris database). The proposed algorithm consists of five steps, which include: (1) detecting the approximate localization of the eye area of the noisy image captured at the visible wavelength using the extracted sclera area, (2) defining the outer iris boundary which is the boundary between iris and sclera, (3) detecting the upper and lower eyelids, (4) conducting the verification and correction for outer iris boundary detection and (5) detecting the pupil area and eyelashes and providing means for verification of the reliability of the segmentation results. The results demonstrate that the accuracy is estimated as 98% when using 500 randomly selected images from the UBIRIS.v2 partial database, and estimated at >= 97% in a "Noisy Iris Challenge Evaluation (NICE.I)" in an international competition that involved 97 participants worldwide, ranking this research group in sixth position. This accuracy is achieved with a processing speed nearing real time. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Chen, Yu; Adjouadi, Malek; Han, Changan; Wang, Jin; Barreto, Armando; Rishe, Naphtali; Andrian, Jean] Florida Int Univ, Coll Engn & Comp, Miami, FL 33174 USA.
C3 State University System of Florida; Florida International University
RP Adjouadi, M (corresponding author), Florida Int Univ, Coll Engn & Comp, Miami, FL 33174 USA.
EM adjouadi@fiu.edu
RI Adjouadi, Malek/AAV-2037-2021
OI Barreto, Armando/0000-0002-5572-284X; Adjouadi,
   Malek/0000-0001-5380-3155
FU National Science Foundation [HRD-0833093, CNS-0426125, CNS-0520811,
   CNS-0540592]; Division Of Computer and Network Systems; Direct For
   Computer & Info Scie & Enginr [0837556] Funding Source: National Science
   Foundation; Division Of Human Resource Development; Direct For Education
   and Human Resources [0833093] Funding Source: National Science
   Foundation
FX The authors appreciate the support provided by the National Science
   Foundation under grants HRD-0833093, CNS-0426125, CNS-0520811, and
   CNS-0540592.
CR Adjouadi M, 1996, IEEE T SIGNAL PROCES, V44, P409, DOI 10.1109/78.485936
   ADJOUADI M, 1994, IEEE T PATTERN ANAL, V16, P1212, DOI 10.1109/34.387486
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE 1 INT C BIOM
   BELLMAN R, 2003, DYNAMIC PROGRAMMING, P81
   Candocia F, 1997, IEEE T IMAGE PROCESS, V6, P1460, DOI 10.1109/83.624977
   CHEN Y, 2008, APPL IM PATT REC AIP
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Kittler J., 1983, Image and Vision Computing, V1, P37, DOI [DOI 10.1016/0262-8856(83)90006-9, 10.1016/0262-8856(83)90006-9]
   Kong WK, 2003, INT J PATTERN RECOGN, V17, P1025, DOI 10.1142/S0218001403002733
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Matey JR, 2006, P IEEE, V94, P1936, DOI 10.1109/JPROC.2006.884091
   PROENCA H, 2005, SPRINGER LECT NOTES, V1, P970
   Proença H, 2007, IEEE T PATTERN ANAL, V29, P607, DOI 10.1109/TPAMI.2007.1016
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   WOODS R, 2002, DIGITAL IMAGE PROCES, P295
   [No title captured]
NR 19
TC 63
Z9 71
U1 0
U2 19
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2010
VL 28
IS 2
SI SI
BP 261
EP 269
DI 10.1016/j.imavis.2009.04.017
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 538GR
UT WOS:000273173100008
DA 2024-07-18
ER

PT J
AU Sankowski, W
   Grabowski, K
   Napieralska, M
   Zubert, M
   Napieralski, A
AF Sankowski, Wojciech
   Grabowski, Kamil
   Napieralska, Malgorzata
   Zubert, Mariusz
   Napieralski, Andrzej
TI Reliable algorithm for iris segmentation in eye image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris segmentation; Iris localization; Eyelids localization
ID RECOGNITION
AB The paper presents a novel algorithm for iris segmentation in eye images taken under visible and near infrared light. The proposed approach consists of the following stages: reflections localization, reflections filling in, iris boundaries localization and eyelids boundaries localization. Here, each of these stages is detailed. Authors' solution obtained the second rank in the "Noisy Iris Challenge Evaluation - Part I" contest, in which all iris segmentation algorithms submitted to the contest were evaluated and compared. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Sankowski, Wojciech; Grabowski, Kamil; Napieralska, Malgorzata; Zubert, Mariusz; Napieralski, Andrzej] Tech Univ Lodz, Dept Microelect & Comp Sci, PL-90924 Lodz, Poland.
C3 Lodz University of Technology
RP Sankowski, W (corresponding author), Tech Univ Lodz, Dept Microelect & Comp Sci, Wolczanska 221-223, PL-90924 Lodz, Poland.
EM wsan@dmcs.pl
RI Zubert, Mariusz/L-9604-2018; Sankowski, Wojciech/T-4558-2019;
   Napieralska, Malgorzata/T-3804-2018; Grabowski, Kamil/AAI-4793-2021;
   Napieralski, Andrzej/M-1621-2016
OI Zubert, Mariusz/0000-0001-7924-7724; Sankowski,
   Wojciech/0000-0001-5169-4901; Napieralska,
   Malgorzata/0000-0002-5831-311X; Grabowski, Kamil/0000-0002-0362-8480;
   Napieralski, Andrzej/0000-0002-3844-3435
FU Polish State Committee [3 T11 B00 827]; two Internal University Grants
   [K-25/1/2007-Dz.S, K25/ B.W.4/2008]
FX The work reported in this paper has been supported by the Polish State
   Committee for Scientific Research Grant 3 T11 B00 827 and two Internal
   University Grants: K-25/1/2007-Dz.S and K25/ B.W.4/2008.
CR [Anonymous], P IEEE 1 INT C BIOM
   Camus TA, 2002, INT C PATT RECOG, P389, DOI 10.1109/ICPR.2002.1044732
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN J, 1993, T PATTERN ANAL MACHI, P1148
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Grabowski K, 2006, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE MIXED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, P684, DOI 10.1109/MIXDES.2006.1706671
   Proença H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Rossant F., 2005, IEEE INT C IM PROC 2, V3, pIII 
   Sankowski W., 2006, Iris Finder-Program For Reliable Iris LocalizationIn Images Taken Under Visible Light
   SANKOWSKI W, 2007, INT C MIX DES INT CI, P622
   SANKOWSKI W, 2006, IMPROVEMENTS IRIS FI
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   ZUO J, 2008, P 19 INT C PATT REC, P1
NR 14
TC 55
Z9 61
U1 1
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2010
VL 28
IS 2
SI SI
BP 231
EP 237
DI 10.1016/j.imavis.2009.05.014
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 538GR
UT WOS:000273173100004
DA 2024-07-18
ER

PT J
AU Julià, C
   Sappa, AD
   Lumbreras, F
   Serrat, J
   López, A
AF Julia, Carme
   Sappa, Angel D.
   Lumbreras, Felipe
   Serrat, Joan
   Lopez, Antonio
TI An iterative multiresolution scheme for SFM with missing data: Single
   and multiple object scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Structure from Motion; Factorization techniques
ID FACTORIZATION METHOD; MOTION; SHAPE; RECONSTRUCTION; MATRIX
AB Most of the techniques proposed for tackling the Structure from Motion problem (SFM) cannot deal with high percentages of missing data in the matrix of trajectories. Furthermore, an additional problem should be faced up when working with multiple object scenes: the rank of the matrix of trajectories should be estimated. This paper presents an iterative multiresolution scheme for SFM with missing data to be used in both the single and multiple object cases. The proposed scheme aims at recovering missing entries in the original input matrix. The objective is to improve the results by applying a factorization technique to the partially or totally filled in matrix instead of to the original input one. Experimental results obtained with synthetic and real data sequences, containing single and multiple objects, are presented to show the viability of the proposed approach. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Julia, Carme] URV, ETSE, Intelligent Robot & Comp Vis Grp, Dept Math & Comp Sci, Tarragona 43007, Spain.
   [Sappa, Angel D.; Lumbreras, Felipe; Serrat, Joan; Lopez, Antonio] Comp Vis Ctr, Barcelona 08193, Spain.
C3 Universitat Rovira i Virgili; Centre de Visio per Computador (CVC)
RP Julià, C (corresponding author), URV, ETSE, Intelligent Robot & Comp Vis Grp, Dept Math & Comp Sci, Av Paisos Catalans 26, Tarragona 43007, Spain.
EM cjulia@cvc.uab.es
RI Julia, Carme/G-2367-2016; Sappa, Angel D./A-2072-2009; Serrat,
   Joan/L-4735-2014; López, Antonio M/L-5303-2014; Lumbreras,
   Felipe/L-9387-2014
OI Julia, Carme/0000-0003-3440-6175; López, Antonio M/0000-0002-6979-5783;
   Sappa, Angel/0000-0003-2468-0031; Serrat, Joan/0000-0002-4554-199X;
   Lumbreras, Felipe/0000-0003-2887-8053
FU Spanish Government [TRA2007-62526/AUT, DPI2007-66556-C03-03]; MIPRCV
   [CSD2007-00018]; Catalan Government [CTP 2008ITT 00001]
FX This work has been partially supported by the Spanish Government under
   Projects TRA2007-62526/AUT and DPI2007-66556-C03-03; research programme
   Consolider-Ingenio 2010; MIPRCV (CSD2007-00018); and Catalan Government
   under Project CTP 2008ITT 00001.
CR Aanæs H, 2002, IEEE T PATTERN ANAL, V24, P1215, DOI 10.1109/TPAMI.2002.1033213
   [Anonymous], P AUSTR JAP ADV WORK
   [Anonymous], ACCV
   Boult T. E., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P179, DOI 10.1109/WVM.1991.212809
   Buchanan AM, 2005, PROC CVPR IEEE, P316
   Chen P, 2004, IEEE T PATTERN ANAL, V26, P1051, DOI 10.1109/TPAMI.2004.52
   Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999
   Friedland S, 2006, LINEAR ALGEBRA APPL, V416, P8, DOI 10.1016/j.laa.2005.05.009
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Guerreiro RFC, 2003, LECT NOTES COMPUT SC, V2683, P450
   Guilbert N, 2006, INT J COMPUT VISION, V69, P317, DOI 10.1007/s11263-006-8113-4
   Han M., 2000, INT J COMPUT VISION, V53, P285
   JACOBS DW, 2001, COMPUTER VISION IMAG, P57
   Jia HJ, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P1101
   Julià C, 2008, ELECTRON LETT, V44, P279, DOI 10.1049/el:20082503
   JULIA C, 2006, LNCS, V1, P555
   Julià C, 2006, LECT NOTES COMPUT SC, V4141, P804
   Julià C, 2009, J MATH IMAGING VIS, V34, P240, DOI 10.1007/s10851-009-0144-3
   Ma Y., 2004, INVITATION 3D VISION
   Martinec D, 2005, PROC CVPR IEEE, P198
   Morita T, 1997, IEEE T PATTERN ANAL, V19, P858, DOI 10.1109/34.608289
   Morris DD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P696, DOI 10.1109/ICCV.1998.710793
   Okatani T, 2007, INT J COMPUT VISION, V72, P329, DOI 10.1007/s11263-006-9785-5
   Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098
   QUAN L, 1996, CVPR
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Triggs B, 1997, IMAGE VISION COMPUT, V15, P617, DOI 10.1016/S0262-8856(97)00016-4
   Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520
   Wiberg T., 1976, PROC 2 S COMPUTATION, P229
   Zelnik-Manor L, 2003, PROC CVPR IEEE, P287
NR 30
TC 2
Z9 3
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 164
EP 176
DI 10.1016/j.imavis.2009.05.015
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000016
DA 2024-07-18
ER

PT J
AU Haxhimusa, Y
   Kropatsch, WG
   Pizlo, Z
   Ion, A
AF Haxhimusa, Yll
   Kropatsch, Walter G.
   Pizlo, Zygmunt
   Ion, Adrian
TI Approximative graph pyramid solution of the E-TSP
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Hierarchical representation; Graph pyramids; Human problem solving;
   Traveling salesman problem; Boruvka's minimum spanning tree
ID TRAVELING SALESMAN PROBLEM; HUMAN-PERFORMANCE; SEGMENTATION; COMPLEXITY;
   VISION; MODELS
AB The traveling salesman problem (TSP) is difficult to solve for input instances with large number of cities. Instead of finding the solution for an input with a large number of cities, the problem is transformed into a simpler form containing smaller number of cities, which is then solved optimally. Graph pyramid solution strategies, using Boruvka's minimum spanning tree step, convert, in a bottom-up processing, a 2D Euclidean TSP problem with a large number of cities into successively smaller problems (graphs) with similar layout and solution, until the number of cities is small enough to seek the optimal solution. Expanding this tour solution in a top-down manner, to the lower levels of the pyramid, leads to an approximate solution. The new model has an adaptive spatial structure and it simulates visual acuity and visual attention. The model solves the TSP problem sequentially, by moving attention from city to city, and the quality of the solutions is similar to the solutions produced by humans. The graph pyramid data structures and processing strategies provide good methods for finding near-optimal solutions for computationally hard problems. Isolating processing used by humans to solve computationally hard problems is of general importance to psychology community and might lead to advances in pattern recognition. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Haxhimusa, Yll; Pizlo, Zygmunt] Purdue Univ, Dept Psychol Sci, Coll Liberal Arts, Lafayette, IN 47907 USA.
   [Haxhimusa, Yll; Kropatsch, Walter G.; Ion, Adrian] Vienna Univ Technol, Fac Informat, Inst Comp Aided Automat Pattern Recognit & Image, Vienna, Austria.
C3 Purdue University System; Purdue University; Technische Universitat Wien
RP Haxhimusa, Y (corresponding author), Purdue Univ, Dept Psychol Sci, Coll Liberal Arts, 703 3rd St, Lafayette, IN 47907 USA.
EM yll@psych.purdue.edu; krw@prip.tuwien.ac.at; pizlo@psych.purdue.edu;
   ion@prip.tuwien.ac.at
FU Direct For Computer & Info Scie & Enginr; Div Of Information &
   Intelligent Systems [0812167] Funding Source: National Science
   Foundation
CR AMMON K, 1993, ARTIF INTELL, V61, P291, DOI 10.1016/0004-3702(93)90070-R
   Andrews J, 2007, P NATL ACAD SCI USA, V104, P1118, DOI 10.1073/pnas.0609910104
   [Anonymous], COMBINATORIAL OPTIMI
   [Anonymous], 94075 CSD TR PURD U
   [Anonymous], 2002, The Traveling Salesman Problem and its Variations
   [Anonymous], 1997, Local Search in Combinatorial Optimization
   [Anonymous], 1993, A vision of the brain
   Atallah M.J., 1999, ALGORITHMS THEORY CO
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   BISTER M, 1990, PATTERN RECOGN LETT, V11, P605, DOI 10.1016/0167-8655(90)90013-R
   BOUMAN C, 1991, IEEE T PATTERN ANAL, V13, P99, DOI 10.1109/34.67641
   Chernyak DA, 2001, IEEE T SYST MAN CY B, V31, P514, DOI 10.1109/3477.938257
   Chowdhury N, 1997, PATTERN RECOGN, V30, P1919, DOI 10.1016/S0031-3203(96)00188-4
   CHRISTOFIDES N, 1975, GRAPH THEORY  AN ALG
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   EDELSBRUNNER H, 1983, IEEE T INFORMATION T, V29, P71
   Giesen J., 1999, Proceedings of the Fifteenth Annual Symposium on Computational Geometry, P207, DOI 10.1145/304893.304973
   Graham SM, 2000, MEM COGNITION, V28, P1191, DOI 10.3758/BF03211820
   Gutin G, 2002, DISCRETE APPL MATH, V117, P81, DOI 10.1016/S0166-218X(01)00195-0
   Helsgaun K, 2000, EUR J OPER RES, V126, P106, DOI 10.1016/S0377-2217(99)00284-2
   Jolion J.M., 1994, PYRAMID FRAMEWORK EA
   JOLION JM, 1992, CVGIP-IMAG UNDERSTAN, V55, P339, DOI 10.1016/1049-9660(92)90031-W
   Koffka K., 1935, Principles of gestalt psychology
   Kropatsch WG, 2004, LECT NOTES COMPUT SC, V3322, P77
   Kropatsch WG, 2005, PATTERN RECOGN LETT, V26, P319, DOI 10.1016/j.patrec.2004.10.026
   LANCE GN, 1967, COMPUT J, V9, P373, DOI 10.1093/comjnl/9.4.373
   LARKIN JH, 1988, COGNITIVE SCI, V12, P101, DOI 10.1207/s15516709cog1201_3
   LEE M, 2005, P 1 INT WORKSH HUM P
   MacGregor JN, 2000, MEM COGNITION, V28, P1183, DOI 10.3758/BF03211819
   MacGregor JN, 1996, PERCEPT PSYCHOPHYS, V58, P527, DOI 10.3758/BF03213088
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   MONTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307, DOI 10.1109/34.88566
   Nesetril J, 2001, DISCRETE MATH, V233, P3, DOI 10.1016/S0012-365X(00)00224-7
   Newell A., 1972, HUMAN PROBLEM SOLVIN, V104
   Ormrod J.E., 1999, Human learning, V3rd
   Pizlo Z, 2005, MEM COGNITION, V33, P1069, DOI 10.3758/BF03193214
   Pizlo Z, 2004, PROC SPIE, V5299, P205, DOI 10.1117/12.543423
   Pizlo Z, 2003, P SOC PHOTO-OPT INS, V5016, P1, DOI 10.1117/12.479704
   Pizlo Z, 2001, VISION RES, V41, P3145, DOI 10.1016/S0042-6989(01)00173-0
   PIZLO Z, 1995, VISION RES, V35, P1089, DOI 10.1016/0042-6989(94)00195-R
   Pizlo Z, 1997, VISION RES, V37, P1217, DOI 10.1016/S0042-6989(96)00220-9
   PIZLO Z, 2005, P 1 INT WORKSH HUM P
   Pizlo Z, 2006, J PROBL SOLVING, V1, P83, DOI 10.7771/1932-6246.1009
   POYLA G, 1957, SOLVE IT NEW ASPECT
   PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Russel S., 1995, Pearson Series, V1st, DOI [10.1017/S0269888900007724, DOI 10.1017/S0269888900007724]
   SETHIAN JA, 2006, LEVEL SET METHODS FA
   Shortliffe E, 2012, COMPUTER BASED MED C, V2
   STARK L, 1997, P IEEE INT C NEUR NE, V4, P2294
   TSOTSOS JK, 1990, BEHAV BRAIN SCI, V13, P423, DOI 10.1017/S0140525X00079577
   TSOTSOS JK, 1992, INT J COMPUT VISION, V7, P127, DOI 10.1007/BF00128132
   VALDESPEREZ RE, 1995, AI MAG, V16, P37
   van Rooij I, 2003, MEM COGNITION, V31, P215, DOI 10.3758/BF03194380
   Vickers D, 2001, PSYCHOL RES-PSYCH FO, V65, P34, DOI 10.1007/s004260000031
   Wagman M., 2002, Problem-solving processes in humans and computers: Theory and research in psychology and artificial intelligence
   Wang H.-C., 2012, J VISION, V12, P26, DOI https://doi.org/10.1167/12.6.26
   WATT RJ, 1987, J OPT SOC AM A, V4, P2006, DOI 10.1364/JOSAA.4.002006
   WOLFE W, 1994, 1994 IEEE INT C NEUR, V7, P4577
   Yuille AL, 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1
   J PROBLEM SOLVING
NR 61
TC 11
Z9 13
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 887
EP 896
DI 10.1016/j.imavis.2008.06.016
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300007
DA 2024-07-18
ER

PT J
AU Felsberg, M
   Kalkan, S
   Krüger, N
AF Felsberg, Michael
   Kalkan, Sinan
   Kruger, Norbert
TI Continuous dimensionality characterization of image structures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Intrinsic dimensionality; Feature extraction and classification
ID INTRINSIC DIMENSIONALITY; CONSTRAINTS
AB Intrinsic dimensionality is a concept introduced by statistics and later used in image processing to measure the dimensionality of a data set. In this paper, we introduce a continuous representation of the intrinsic dimension of an image patch in terms of its local spectrum or, equivalently, its gradient field. By making use of a cone structure and barycentric co-ordinates, we can associate three confidences to the three different ideal cases of intrinsic dimensions corresponding to homogeneous image patches, edge-like structures and junctions. The main novelty of our approach is the representation of confidences as prior probabilities which can be used within a probabilistic framework. To show the potential of our continuous representation, we highlight applications in various contexts such as image structure classification, feature detection and localisation, visual scene statistics and optic flow evaluation. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Kalkan, Sinan] Univ Gottingen, BCCN, D-37073 Gottingen, Germany.
   [Felsberg, Michael] Linkoping Univ, Comp Vis Lab, Dept EE, S-58183 Linkoping, Sweden.
   [Kruger, Norbert] Univ So Denmark, Cognit Vis Grp, Odense, Denmark.
C3 University of Gottingen; Linkoping University; University of Southern
   Denmark
RP Kalkan, S (corresponding author), Univ Gottingen, BCCN, Bunsenstr 10, D-37073 Gottingen, Germany.
EM mfe@isy.liu.se; sinan@bccn-goettingen.de; norbert@mip.sdu.dk
RI Kalkan, Sinan/A-4843-2016; KALKAN, Sinan/AAC-3625-2019; Kruger,
   Norbert/P-6315-2015
OI Felsberg, Michael/0000-0002-6096-3648; Kruger,
   Norbert/0000-0002-3931-116X; Kalkan, Sinan/0000-0003-0915-5917
FU European Community's Seventh Framework Programme [FP7/2007-2013,
   215078]; CENIIT Project CAIRIS; EC [IST-FP6-FET-016276-2]; Danish
   National Project NISA
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme (FP7/2007-2013) under
   Grant Agreement No. 215078 DIPLECS and from the CENIIT Project CAIRIS.
   This work has further been supported by the EC Grant Drivsco
   (IST-FP6-FET-016276-2) and the Danish National Project NISA. However,
   this paper does not necessarily represent the opinion of the European
   Community, and the European Community is not responsible for any use
   which may be made of its contents.
CR [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], P C COMP VIS PATT RE
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   BAYERL P, INT J COMPUTER VISIO
   BIGUN J, 1988, THESIS LINKOPING U S
   BIGUN J, 1986, P IEEE 1 INT C COMP
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626
   Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189
   Coexeter H.S. M., 1969, Introduction to Geometry, V2nd
   Costa JA, 2004, IEEE T SIGNAL PROCES, V52, P2210, DOI 10.1109/TSP.2004.831130
   Felsberg M, 2006, IEEE T PATTERN ANAL, V28, P209, DOI 10.1109/TPAMI.2006.29
   FELSBERG M, 2003, 25 DAGM S MUST
   FELSBERG M, 2004, 26 DAGM S MUST TUB
   Forstner W., 1987, P ISPRS INT C FAST P, V2, P4
   FORSTNER W, 1994, P 3 EUR C COMP VIS S, V2
   FORSTNER W, 1998, LECT NOTES EARTH SCI
   GEUSEBROEK JM, 2005, LNCS, V3459
   GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1
   GRIMSON WEL, 1983, COMPUT VISION GRAPH, V24, P28, DOI 10.1016/0734-189X(83)90019-1
   Harris C., 1988, Proc. Alvey Vision Conference
   Hough P.V.C., U.S.Patent, Patent No. [3,069,654, 3069654]
   Johansson B, 2004, THESIS LINKOPING U S
   KALKAN S, 2006, IEEE C COMP VIS PATT
   KALKAN S, 2005, COMPUTATION NEURAL S, V16, P341
   KOTHE U, 2003, P 9 INT C COMP VIS N
   Krieger G, 1996, IEEE T IMAGE PROCESS, V5, P1026, DOI 10.1109/83.503917
   Krüger N, 2004, ADV IMAG ELECT PHYS, V131, P81, DOI 10.1016/S1076-5670(04)31003-7
   Krüger N, 2004, PATTERN RECOGN LETT, V25, P849, DOI 10.1016/j.patrec.2004.01.021
   KRUGER N, 2005, P 1 INT S BRAIN VIS
   KRUGER N, 2003, BRIT MACH VIS C
   Lee AB, 2003, INT J COMPUT VISION, V54, P83, DOI 10.1023/A:1023705401078
   Levina Elizaveta, 2004, Advances in neural information processing systems, V17
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   MUHLICH M, 2001, P 12 SCAND C IM AN
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833
   Parida L, 1998, IEEE T PATTERN ANAL, V20, P687, DOI 10.1109/34.689300
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   PUGEAULT N, 2006, WORKSH PERC ORG COMP
   ROHR K, 1992, INT J COMPUT VISION, V9, P213, DOI 10.1007/BF00133702
   SHI K, COMPUTER VISION PATT
   TRUNK GV, 1968, GEN SYST, V13, P49
   Weickert J, 2002, J VIS COMMUN IMAGE R, V13, P103, DOI 10.1006/jvci.2001.0495
   ZETZSCHE C, 1990, VISION RES, V30, P1111, DOI 10.1016/0042-6989(90)90120-A
NR 44
TC 29
Z9 31
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 628
EP 636
DI 10.1016/j.imavis.2008.06.018
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kaplan, LM
   Nasrabadi, NM
AF Kaplan, Lance M.
   Nasrabadi, Nasser M.
TI Block Wiener-based image registration for moving target indication
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image registration; Wiener filtering; Least mean-squared estimation;
   Moving target indication
ID SAR
AB This paper develops a block Wiener-based image registration method to align consecutive frames in a video sequence. The main purpose of this registration technique is to serve as a processing step in a moving target indication (MTI) algorithm, where subsequent steps include frame-to-frame differencing and thresholding. Experiments show that the block Wiener-based approach is computationally efficient and effective in terms of facilitating a MTI. These experiments compare the block Wiener-based against traditional global parametric registration, pixel-based Wiener registration, block-based motion compensation, and state-of-the-art phase-based registration. Published by Elsevier B.V.
C1 [Kaplan, Lance M.; Nasrabadi, Nasser M.] USA, Res Lab, Adelphi, MD 20783 USA.
C3 United States Department of Defense; US Army Research, Development &
   Engineering Command (RDECOM); US Army Research Laboratory (ARL)
RP Kaplan, LM (corresponding author), USA, Res Lab, 2800 Powder Mill Rd, Adelphi, MD 20783 USA.
EM lkaplan@arl.army.mil; nnasraba@arl.army.mil
CR BIEMOND J, 1987, SIGNAL PROCESS, V13, P399, DOI 10.1016/0165-1684(87)90021-1
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   HAYKIN S, 1991, ADPATIVE FILTER THEO
   Hemmendorff M, 2002, IEEE T MED IMAGING, V21, P1536, DOI 10.1109/TMI.2002.806581
   Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201
   Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105
   Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   JAIN J, 1981, IEEE T COMMUN, V29, P556
   Kaplan LM, 2001, IEEE T AERO ELEC SYS, V37, P436, DOI 10.1109/7.937460
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   NASRABADI N, 2007, J APPL REMOTE SENS, V1, P1
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Ranney KI, 2006, IEEE T GEOSCI REMOTE, V44, P201, DOI 10.1109/TGRS.2005.859956
   SALGIAN G, 2006, P 25 ARM SCI C ORL F
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Soumekh M, 1999, IEEE T IMAGE PROCESS, V8, P127, DOI 10.1109/83.736707
   Toyama K., 1999, The Proceedings of the Seventh IEEE International Conference on Computer Vision, V1, P255
   van Herk M, 1998, MED PHYS, V25, P2054, DOI 10.1118/1.598393
   Yetik IS, 2006, IEEE T SIGNAL PROCES, V54, P1737, DOI 10.1109/TSP.2006.870552
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 21
TC 3
Z9 5
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 694
EP 703
DI 10.1016/j.imavis.2008.07.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000010
DA 2024-07-18
ER

PT J
AU Al-Kindi, GA
   Shirinzadeh, B
AF Al-Kindi, Ghassan A.
   Shirinzadeh, Bijan
TI Feasibility assessment of vision-based surface roughness parameters
   acquisition for different types of machined specimens
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vision-based topography; Image texture; Roughness parameters; Surface
   measurement
ID TEXTURE FEATURES; INSPECTION; SYSTEM
AB This paper presents a feasibility assessment of acquiring vision-based surface roughness parameters for specimens produced by different machining type processes. Twenty produced specimens using five of the most common machining operations were employed in the investigation. Stylus-based measurements of these specimens are performed and results are compared to vision-based measurements using amplitude, spacing and hybrid roughness parameters. The applied filtering technique was based on 0.8 mm cut-off value and was maintained identical for both stylus and vision data to enable comparable results. Two models of surface irradiance were employed in the interpretation of the vision data. A third model was also established by utilising an additional filtering operation on the vision data. This allows assessment of the impact of this case on acquired values of surface parameters. Ambient lighting was used to minimize the effects of specular type of reflection. Results showed that although there is a considerable change in the parameter values acquired from vision data compared to stylus data, it is possible to obtain roughness parameters using vision-based method to a certain limit of accuracy. However, some roughness evaluation parameters proved to be more reliable than others. The overall results of this paper would encourage further developments in this area to achieve robust 3D vision based roughness measurement systems for industrial use. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Al-Kindi, Ghassan A.] Univ Technol Baghdad, Dept Mech Engn, Baghdad, Iraq.
   [Al-Kindi, Ghassan A.; Shirinzadeh, Bijan] Monash Univ, Dept Mech Engn, Clayton, Vic 3800, Australia.
C3 University of Technology- Iraq; Monash University
RP Al-Kindi, GA (corresponding author), Univ Technol Baghdad, Dept Mech Engn, Baghdad, Iraq.
EM ghassan_alkindi@yahoo.com
FU Mechanical Engineering Department Monash University; Department of
   Education, Science and Training of the Australian government
FX This work was carried out in the Robotics and Mechatronics Research
   Laboratory of the Mechanical Engineering Department Monash University
   with the support of an Endeavour Fellowship given by the Department of
   Education, Science and Training of the Australian government.
CR Al-Kindi GA, 2007, INT J MACH TOOL MANU, V47, P697, DOI 10.1016/j.ijmachtools.2006.04.013
   ALKINDI GA, 1992, INT J PROD RES, V30, P241, DOI 10.1080/00207549208942892
   ALKINDI GAH, 1989, P I MECH ENG B-J ENG, V203, P211, DOI 10.1243/PIME_PROC_1989_203_072_02
   [Anonymous], 1996, 42881996 ISO
   BRADY C, 2001, J ADV MANUFACTURING, V17, P435
   Gadelmawla ES, 2004, NDT&E INT, V37, P577, DOI 10.1016/j.ndteint.2004.03.004
   JETLEY S, 1993, IEE P 36 MIDW S CIRC, V2, P1456
   Kiran MB, 1998, INT J MACH TOOL MANU, V38, P685, DOI 10.1016/S0890-6955(97)00118-1
   Kumar R, 2005, INT J MACH TOOL MANU, V45, P228, DOI 10.1016/j.ijmachtools.2004.07.001
   Lee BY, 2004, MECHATRONICS, V14, P129, DOI 10.1016/S0957-4158(02)00096-X
   Lee BY, 2001, INT J MACH TOOL MANU, V41, P1251, DOI 10.1016/S0890-6955(01)00023-2
   Lee KC, 2005, PRECIS ENG, V29, P95, DOI 10.1016/j.precisioneng.2004.05.002
   Li XQ, 2004, INT J PROD RES, V42, P2279, DOI 10.1080/0020754042000197702
   Lo SP, 2005, INT J ADV MANUF TECH, V26, P1071, DOI 10.1007/s00170-004-2073-z
   Ramana KV, 1996, PATTERN RECOGN, V29, P1447, DOI 10.1016/0031-3203(96)00008-8
   Tasan YC, 2005, WEAR, V258, P83, DOI 10.1016/j.wear.2004.05.018
   Whitehouse DJ, 1997, MEAS SCI TECHNOL, V8, P955, DOI 10.1088/0957-0233/8/9/002
NR 17
TC 27
Z9 28
U1 2
U2 17
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 444
EP 458
DI 10.1016/j.imavis.2008.06.011
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600015
DA 2024-07-18
ER

PT J
AU Maltoni, D
   Cappelli, R
AF Maltoni, Davide
   Cappelli, Raffaele
TI Advances in fingerprint modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometric systems; Fingerprints; Skin distortion model; Synthetic
   generation; Fake fingers
ID ALGORITHM
AB Although fingerprint recognition is a mature technology and nowadays commercial state-of-the-art systems can be successfully used in a number of real applications, not all the problems have been solved and the research is still very active in the field. Effectively dealing with fingerprint distortion is one of the problems that is currently attracting a lot of attention and it seems that accurate models of the finger skin are necessary to cope with the often undesired effects of distortion. This paper discusses the recent advances in fingerprint modeling and focuses on a specific model which proved to be particularly effective. Practical applications of this model to fingerprint synthesis and fake detection are also introduced. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Maltoni, Davide; Cappelli, Raffaele] Univ Bologna, DEIS, Biometr Syst Lab, I-47023 Cesena, Italy.
C3 University of Bologna
RP Cappelli, R (corresponding author), Univ Bologna, DEIS, Biometr Syst Lab, Via Sacchi 3, I-47023 Cesena, Italy.
EM maltoni@csr.unibo.it; cappelli@csr.unibo.it
OI Cappelli, Raffaele/0000-0003-3054-9363
CR *AM NAT STAND I, X9842001 AM NAT STAN
   [Anonymous], 2003, Handbook of fingerprint recognition
   Antonelli A, 2006, IEEE T INF FOREN SEC, V1, P360, DOI 10.1109/TIFS.2006.879289
   Bazen AM, 2003, PATTERN RECOGN, V36, P1859, DOI 10.1016/S0031-3203(03)00036-0
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Cappelli R, 2006, IEEE T PATTERN ANAL, V28, P3, DOI 10.1109/TPAMI.2006.20
   CAPPELLI R, 2001, P 2 INT C ADV PATT R, P369
   Chen XJ, 2006, IEEE T INF FOREN SEC, V1, P169, DOI 10.1109/TIFS.2006.873605
   Chen XJ, 2006, IEEE T IMAGE PROCESS, V15, P767, DOI 10.1109/TIP.2005.860597
   Kang HS, 2003, LECT NOTES ARTIF INT, V2774, P1245
   Kovács-Vajna ZM, 2000, IEEE T PATTERN ANAL, V22, P1266, DOI 10.1109/34.888711
   Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140
   Matsumoto T., 2002, P SPIE, V4677
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   RAFFIA NK, 1998, P INT C PATT REC, V2, P1659
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   RATHA NK, 2001, P 3 INT C AUD VID BA, P223
   Ross A, 2006, IEEE T PATTERN ANAL, V28, P19, DOI 10.1109/TPAMI.2006.11
   Senior AW, 2001, IEICE T INF SYST, VE84D, P825
   THALHEIM L, 2002, C T MAGAZINE
   Thebaud L., 1999, Systems and methods with identity verification by comparison and interpretation of skin patterns such as finger-prints, U. S. Patent, Patent No. [5 909 501, 5909501]
   Uludag U, 2004, PROC SPIE, V5306, P622, DOI 10.1117/12.530907
   *US BIOM WORK GROU, 2002, BIOM EV METH
   van der Putte T, 2000, INT FED INFO PROC, V52, P289
   Watson CI, 2000, P SOC PHOTO-OPT INS, V4043, P166, DOI 10.1117/12.381591
NR 25
TC 20
Z9 24
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 2
PY 2009
VL 27
IS 3
SI SI
BP 258
EP 268
DI 10.1016/j.imavis.2007.01.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 393QA
UT WOS:000262386600005
DA 2024-07-18
ER

PT J
AU Traver, VJ
   Pla, F
AF Traver, V. Javier
   Pla, Filiberto
TI Log-polar mapping template design: From task-level requirements to
   geometry parameters
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE log-polar vision; receptive fields; design criteria; genetic algorithm
ID FACE DETECTION; TRACKING; SEARCH
AB The best parameters defining the geometry of a visual sensor generally depend on the particular visual task the sensor is intended to be used in. However, translating task requirements directly into low-level geometric parameters may be difficult, since deep knowledge of the sensor design is usually required, but end users of a sensor need not necessarily be its designers. A framework is suggested to facilitate this translation by including an intermediate layer, the design criteria, between task requirements and sensor parameters. The proposed framework is illustrated with a log-polar space-variant vision model. The motivation behind using this particular sensor is the observation that, in the literature, little attention has been paid to the proper choice of the sensor parameters, or the lack of justification of the chosen configuration. Sets of general-purpose design criteria and task specifications are provided and discussed. The process of finding the best geometric parameters for a given set of (many and/or mutually conflicting) design criteria is automated with a multi-objective genetic algorithm. Some examples are given demonstrating the feasibility and potential of the approach. (c) 2008 Published by Elsevier B.V.
C1 [Traver, V. Javier; Pla, Filiberto] Univ Jaume 1, Dep Llenguatges & Sistemes Informat, E-12080 Castellon de La Plana, Spain.
C3 Universitat Jaume I
RP Traver, VJ (corresponding author), Univ Jaume 1, Dep Llenguatges & Sistemes Informat, Campus Riu Sec,Edifici TI, E-12080 Castellon de La Plana, Spain.
EM javier.traver@uji.es; filiberto.pla@uji.es
RI Pla, Filiberto/AAD-1208-2022; Traver, V. Javier/F-8865-2016
OI Pla, Filiberto/0000-0003-0054-3489; Traver, V.
   Javier/0000-0002-1596-8466
FU Fundacio Caixa-Castello Bancaixa [P1-1B2004-33, P1-1A2004-02]; Spanish
   Ministerio de Educacion y Ciencia [CSD2007-00018]
FX Acknowledgment to projects P1-1B2004-33 and P1-1A2004-02, funded by
   Fundacio Caixa-Castello Bancaixa, and to projects HP2005-0095
   (Integrated Actions) and CSD2007-00018 (Consolider Ingenio 2010), both
   funded by the Spanish Ministerio de Educacion y Ciencia.
CR [Anonymous], 2004, ACM Trans Embedded Comput Syst, DOI DOI 10.1145/972627.972631
   [Anonymous], ENCY SENSORS
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2006, Evolutionary Computation: A Unified Approach
   [Anonymous], 2004, Wiley InterScience electronic collection.
   Bernardino A, 1998, ROBOT AUTON SYST, V25, P137, DOI 10.1016/S0921-8890(98)00043-8
   Bernardino A, 1999, IEEE T ROBOTIC AUTOM, V15, P1080, DOI 10.1109/70.817671
   BERNARDINO A, 1996, WORKSH PERF CHAR VIS
   Bevilacqua A, 2005, IMAGE VISION COMPUT, V23, P815, DOI 10.1016/j.imavis.2005.04.001
   Bolduc M, 1998, COMPUT VIS IMAGE UND, V69, P170, DOI 10.1006/cviu.1997.0560
   Chakrabarty K, 2002, IEEE T COMPUT, V51, P1448, DOI 10.1109/TC.2002.1146711
   Coello CAC, 2000, ACM COMPUT SURV, V32, P109, DOI 10.1145/358923.358929
   COOMBS D, 1993, INT J COMPUT VISION, V11, P147, DOI 10.1007/BF01469226
   Dequen G, 2007, LECT NOTES COMPUT SC, V4478, P404
   DERSPIEGEL JV, 1989, ANALOG VLSI NEURAL N
   FISCHL B, 1997, THESIS BOSTON U
   FISHER TE, 1988, SPIE DIGITAL OPTICAL, V938, P122
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   HICKS R, 2001, P IEEE COMP VIS PATT, V1, P584
   Hicks RA, 2005, J OPT SOC AM A, V22, P323, DOI 10.1364/JOSAA.22.000323
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Hörster E, 2006, MULTIMEDIA SYST, V12, P195, DOI 10.1007/S00530-006-0057-6
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Jurie F, 1999, PATTERN RECOGN, V32, P865, DOI 10.1016/S0031-3203(98)00096-X
   MILANESE R, 1993, THESIS U GENEVA GENE
   PARDO F, 1996, SPIE C ADV FOC PLAN
   PETERS IIR, 1996, COMPUTATION LOG POLA
   Robertson N, 2006, LECT NOTES COMPUT SC, V3952, P402
   Robinson D, 2005, SIGNAL PROCESS-IMAGE, V20, P554, DOI 10.1016/j.image.2005.03.010
   ROJER AS, 1990, INT C PATT REC ICPR, P278
   RuizdelSolar J, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P739
   SANDINI G, 2000, P 1 IEEE SAM WORKSH
   SCHWARTZ EL, 1977, BIOL CYBERN, V25, P181, DOI 10.1007/BF01885636
   Sun YR, 2003, ARTIF INTELL, V146, P77, DOI 10.1016/S0004-3702(02)00399-5
   Traver VJ, 2005, COMPUT VIS IMAGE UND, V97, P209, DOI 10.1016/j.cviu.2004.07.007
   Traver VJ, 2003, LECT NOTES COMPUT SC, V2886, P164
   Traver VJ, 2003, IMAGE VISION COMPUT, V21, P145, DOI 10.1016/S0262-8856(02)00150-6
   TRAVER VJ, 2002, THESIS U JAUME 1 CAS
   TRAVER VJ, 2004, INT C IM AN REC ICIA, V1, P538
   Wall M., 1996, GAlib: A C++ library of genetic algorithm components
   WEIMAN CFR, 1988, PREPRINT P SPIE, V938
   WEIMAN CFR, 1994, NASA PHASE 2 SBIR FI
   WEIMAN CFR, 1994, SPIE, V2239
   WEIMAN CFR, 1990, SPIE S OE AER SENS O
   Wilson JohnP., 1992, CURRENT RES LATE PRE, P245
   Wodnicki R., 1995, CUST INT CIRC C SANT
   Woelders WW, 1997, J SPEECH LANG HEAR R, V40, P1425, DOI 10.1044/jslhr.4006.1425
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
NR 48
TC 27
Z9 29
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1354
EP 1370
DI 10.1016/j.imavis.2007.11.009
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700006
DA 2024-07-18
ER

PT J
AU Lin, TH
   Shih, WP
AF Lin, Tzung-Han
   Shih, Wen-Pin
TI Automatic face authentication with self compensation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; face authentication; automatic feature detection; self
   compensation
ID RECOGNITION
AB This paper presents a novel method for automatic face authentication in which the variance of faces due to aging has been considered. A bilateral symmetrical plane is used for weighting the correspondences of the scanned model and database model upon model verification. This bilateral symmetrical plane is determined by the nose tip and two canthus features. The coupled 2D and 3D feature extraction method is introduced to determine the positions of these canthus features. The central profile on this bilateral symmetrical plane is the foundation of the face recognition. A weighting function is used to determine the rational points for the correspondences of the optimized iterative closest point method. The discrepancy value is evaluated for the authentication and compensation between different models. We have implemented this method on the practical authentication of human faces. The result illustrates that this method works well in both self authentication and mutual authentication. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Lin, Tzung-Han; Shih, Wen-Pin] Natl Taiwan Univ, Dept Mech Engn, Taipei 106, Taiwan.
C3 National Taiwan University
RP Shih, WP (corresponding author), Natl Taiwan Univ, Dept Mech Engn, 1,Sec 4,Rossevelt Rd, Taipei 106, Taiwan.
EM wpshih@ntu.edu.tw
RI Shih, Wen-Pin/AAA-2794-2021
OI Shih, Wen-Pin/0009-0009-3683-6030; Shih, Wen-Pin/0000-0002-6855-5024
CR BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9
   Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62
   CHANG KI, 2003, WORKSH MULT US AUTH, P25
   GORDON G, 1992, P IEEE COMP SOC C CO, P108
   Hamann B., 1993, GEOMETRIC MODELLING, P139, DOI DOI 10.1007/978-3-7091-6916-2_10
   Hesher C, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P201, DOI 10.1109/ISSPA.2003.1224850
   Lin TH., 2006, P 44 ANN SE REGIONAL, P423
   Lu X, 2005, 5th International Workshop on Microprocessor Test and Verification: Common Challenges and Solutions, Proceedings, P97
   Lu XG, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P156
   Lu XG, 2004, INT C PATT RECOG, P362, DOI 10.1109/ICPR.2004.1334127
   Mariani R., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P496, DOI 10.1109/ICIAP.1999.797644
   Song H, 2005, APPL OPTICS, V44, P677, DOI 10.1364/AO.44.000677
   Wang YJ, 2006, IMAGE VISION COMPUT, V24, P176, DOI 10.1016/j.imavis.2005.09.025
   Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006
   Yuille A. L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P104, DOI 10.1109/CVPR.1989.37836
   Zhang JY, 2004, J RARE EARTH, V22, P43
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 18
TC 0
Z9 1
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 863
EP 870
DI 10.1016/j.imavis.2007.10.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900013
DA 2024-07-18
ER

PT J
AU Dell'Acqua, A
   Sarti, A
   Tubaro, S
AF Dell'Acqua, Andrea
   Sarti, Augusto
   Tubaro, Stefano
TI 3D Motion from structures of points, lines and planes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE camera tracking; Geometric Algebra; Extended Kalman Filter
AB In this article we propose a method for estimating the camera motion from a video-sequence acquired in the presence of general 3D structures. Solutions to this problem are commonly based on the tracking of point-like features, as they usually back-project onto viewpoint-invariant 3D features. In order to improve the robustness, the accuracy and the generality of the approach, we are interested in tracking and using a wider class of structures. In addition to points, in fact, we also simultaneously consider lines and planes. In order to be able to work on all such structures with a compact and unified formalism, we use here the Conformal Model of Geometric Algebra, which proved very powerful and flexible.
   As an example of application of our approach, we propose a causal algorithm based on an Extended Kalman Filter, for the estimation of 3D structure and motion from 2D observations of points, lines and coplanar features, and we evaluate its performance on both synthetic and real sequences. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Dell'Acqua, Andrea; Sarti, Augusto; Tubaro, Stefano] Politecn Milan, Dept Elect & Informat, I-20133 Milan, Italy.
C3 Polytechnic University of Milan
RP Dell'Acqua, A (corresponding author), Politecn Milan, Dept Elect & Informat, Piazza Leonardo Da Vinci 32, I-20133 Milan, Italy.
EM andrea.dellacqu@gmail.com
CR Alon J, 2000, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2000.854911
   [Anonymous], EUR C COMP VIS
   [Anonymous], CLIFFORD ALGEBRA GEO
   [Anonymous], 2000, LNCS, DOI DOI 10.1007/3-540-44480-7
   [Anonymous], 2006, P BRIT MACH VIS C
   AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503
   Bartoli A, 2004, INT J COMPUT VISION, V57, P159, DOI 10.1023/B:VISI.0000013092.07433.82
   Bartoli A, 2003, INT J COMPUT VISION, V52, P45, DOI 10.1023/A:1022318524906
   BARYOCORROCHANO E, 1996, ICPR 96
   BAYLIS WE, 1996, ALBEBRAS APPL PHYS M
   BEARDSLEY P, 1996, EUR C COMP VIS, P683
   Chiuso A, 2002, IEEE T PATTERN ANAL, V24, P523, DOI 10.1109/34.993559
   CHIUSO A, 1999, 99003 ESSRL
   CHIUSO A, 2000, LECT NOTES COMPUTER, V1842, P735
   Davison AJ, 2003, P 9 INT C COMP VIS I
   Dellaert F, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P2, DOI 10.1109/ACV.1998.732850
   DORAN C, 2000, UNCERTAINTY GEOMETRI
   DORST L, 2001, SIGGRAPH 2001
   DORST L, 1999, GEOMETRIC ALGEBRA PR
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   Grewal Mohinder S., 1993, Kalman filtering: Theory and Practice with MATLAB
   Gruber A, 2004, PROC CVPR IEEE, P707
   Hall B.C, 2003, Lie Groups, Lie Algebras, and Representations; An Elementary Introduction
   Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Haykin S. S., 2008, ADAPTIVE FILTER THEO
   Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362
   Jebara T, 1999, IEEE SIGNAL PROC MAG, V16, P66, DOI 10.1109/79.768574
   JEZOUIN JL, 1990, ICCV, P441
   LASENBY AN, 2000, P MATH SURFACES, V9, P144
   LASENBY AN, 2003, UNPUB ACM T COMPUTER
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055
   Ma Y, 2004, INT J COMPUT VISION, V59, P115, DOI 10.1023/B:VISI.0000022286.53224.3d
   Ma Y., 2004, INVITATION 3D VISION
   Morris DD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P696, DOI 10.1109/ICCV.1998.710793
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705
   Rosenhahn B, 2005, J MATH IMAGING VIS, V22, P27, DOI 10.1007/s10851-005-4781-x
   SHAKERNIA O, 2002, INT C ROB AUT ICRA
   SOMMER G, 2001, COMPUTER VISION ROBO, P7
   Strom, 2001, P S IM AN SWED SOC A, P13
   STROM J, 1999, P MOD PEOPL WORKSH I
   SZELISKI R, 1998, MSRATR9864
   TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228
   Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388
   VIEVILLE T, 1990, IEEE INT C COMP VIS, P517
   ZHANG Y, 2001, MOTOR EXTENDED KALMA, P501
NR 49
TC 5
Z9 5
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 529
EP 549
DI 10.1016/j.imavis.2007.07.001
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100006
DA 2024-07-18
ER

PT J
AU Greenhill, D
   Renno, J
   Orwell, J
   Jones, GA
AF Greenhill, D.
   Renno, J.
   Orwell, J.
   Jones, G. A.
TI Occlusion analysis: Learning and utilising depth maps in object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE object tracking; occlusion analysis; depth map
AB Complex scenes such as underground stations and malls are composed of static occlusion structures such as walls, entrances, columns, turnstiles and barriers. Unless this occlusion landscape is made explicit such structures can defeat the process of tracking individuals through the scene. This paper describes a method of generating the probability density functions for the depth of the scene at each pixel from a training set of detected blobs, i.e., observations of detected moving people. As the results are necessarily noisy, a regularization process is employed to recover the most self-consistent scene depth structure. An occlusion reasoning framework is proposed to enable object tracking methodologies to make effective use of the recovered depth. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Greenhill, D.; Renno, J.; Orwell, J.; Jones, G. A.] Kingston Univ, Fac Comp & Informat Syst & Maths, Digital Imaging Res Ctr, Kingston upon Thames KT1 2EE, Surrey, England.
C3 Kingston University
RP Jones, GA (corresponding author), Kingston Univ, Fac Comp & Informat Syst & Maths, Digital Imaging Res Ctr, Penrhyn Rd, Kingston upon Thames KT1 2EE, Surrey, England.
EM d.greenhill@kingston.ac.uk; j.renno@kingston.ac.uk;
   j.orwell@kingston.ac.uk; g.jones@kingston.ac.uk
CR Bar-Shalom Y., 1988, MATH SCI ENG
   CHANG TH, 2001, 2 EUR WORKSH ADV VID, P79
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cucchiara R., 2004, P ACM 2 INT WORKSHOP, P81
   Fujiyoshi H, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P15, DOI 10.1109/ACV.1998.732852
   HAMPEL FR, 1986, APPROACH BASED INFLU
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088
   MARCENARO L, 2002, 3 IEEE INT WORKSH PE, P56
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   ORWELL J, 2000, FIRST IEEE INT WORKS, P72
   PIATER JH, 2002, 3 IEEE INT WORKSH PE, P1
   Remagnino P, 2004, PATTERN RECOGN, V37, P675, DOI 10.1016/j.patcog.2003.09.017
   RENNO J, 2002, BRIT MACH VIS C CARD, P607
   Schödl A, 2001, PROC CVPR IEEE, P639
   SENIOR A, 2002, 3 IEEE INT WORKSH PE, P48
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tao H, 2000, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2000.854760
   XU M, 2002, P BMVC, P777
   Xu M, 2006, IMAGE VISION COMPUT, V24, P1202, DOI 10.1016/j.imavis.2005.06.004
   YANG T, 2005, IEEE COMP SOC C COMP, V1, P970
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
NR 23
TC 18
Z9 21
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 430
EP 441
DI 10.1016/j.imavis.2006.12.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500011
DA 2024-07-18
ER

PT J
AU Islam, MS
   Sluzek, A
AF Islam, Md. Saiful
   Sluzek, Andrzej
TI Relative scale method to locate an object in cluttered environment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE relative scale; object localization; multidimensional hashing
ID POSE; RECOGNITION
AB This paper proposes an efficient method to locate a three-dimensional object in cluttered environment. Model of the object is represented in a reference scale by the local features extracted from several reference images. A PCA-based hashing technique is introduced for accessing the database of reference features efficiently. Localization is performed in an estimated relative scale. Firstly, a pair of stereo images is captured simultaneously by calibrated cameras. Then the object is identified in both images by extracting features and matching them with reference features, clustering the matched features with generalized Hough transformation, and verifying clusters with spatial relations between the features. After the identification process, knowledge-based correspondences of features belonging to the object present in the stereo images are used for the estimation of the 3D position. The localization method is robust to different kinds of geometric and photometric transformations in addition to cluttering, partial occlusions and background changes. As both the model representation and localization are single-scale processes, the method is efficient in memory usage and computing time. The proposed relative scale method has been implemented and experiments have been carried out on a set of objects. The method results very good accuracy and takes only a few seconds for object localization by our primary implementation. An application of the relative scale method for exploration of an object in cluttered environment is demonstrated. The proposed method could be useful for many other practical applications. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Islam, Md. Saiful; Sluzek, Andrzej] Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Singapore 639798, Singapore.
   [Sluzek, Andrzej] SWPS, Warsaw, Poland.
C3 Nanyang Technological University; SWPS University of Social Sciences &
   Humanities
RP Islam, MS (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Singapore 639798, Singapore.
EM saiful@pmail.ntu.edu.sg; assluzek@ntu.edu.sg
RI Islam, Saiful/B-9632-2012; SLUZEK, ANDRZEJ/Q-5398-2019; Sluzek, Andrzej
   S/A-3672-2011
OI Islam, Saiful/0000-0002-2670-6007; SLUZEK, ANDRZEJ/0000-0003-4148-2600;
   Sluzek, Andrzej S/0000-0003-4148-2600
CR ABOZAID A, 1988, P 4 INT C PATT REC, P309
   Ayache N., 1991, ARTIFICIAL VISION MO
   Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899
   Boshra M, 2002, IMAGE VISION COMPUT, V20, P469, DOI 10.1016/S0262-8856(02)00020-3
   CALIFANO A, 1994, IEEE T PATTERN ANAL, V16, P373, DOI 10.1109/34.277591
   Chen JL, 1996, IEEE T PATTERN ANAL, V18, P52, DOI 10.1109/34.476010
   Cózar JR, 2001, IMAGE VISION COMPUT, V19, P1057, DOI 10.1016/S0262-8856(01)00066-X
   DENTON T, 2005, DUCS0508 DEP COMP SC
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Harris C., 1998, P 4 ALV VIS C
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Häusler G, 1999, COMPUT VIS IMAGE UND, V73, P64, DOI 10.1006/cviu.1998.0704
   HU MK, 1962, IRS T INFORM THEORY, V8
   Islam M. S., 2005, Machine Graphics & Vision, V14, P259
   ISLAM MS, 2005, P INT C INT SYST ICI
   ISLAM MS, 2003, P 2 INT C COMP INT R
   ISLAM MS, 2005, P MIR 2005 COMP VIS, P9
   ISLAM MS, 2005, P IEEE INT C IM PROC
   Joseph SH, 1999, COMPUT VIS IMAGE UND, V73, P215, DOI 10.1006/cviu.1998.0733
   Jurie F, 2004, PROC CVPR IEEE, P90
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   KOSAKA A, 1992, CVGIP-IMAG UNDERSTAN, V56, P271, DOI 10.1016/1049-9660(92)90045-5
   Kovacic S, 1998, PATTERN RECOGN, V31, P1407, DOI 10.1016/S0031-3203(98)00012-0
   LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047
   Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MA Y, 2000, THESIS U CALIFORNIA
   MAITRA S, 1979, P IEEE, V67, P697, DOI 10.1109/PROC.1979.11309
   MENG M, 1998, THESIS PURDUE U
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K., 2002, P EUR C COMP VIS ECC
   Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011
   Nene S. A., 1996, COLUMBIA OBJECT IMAG
   Reiss T.H., 1993, RECOGNIZING PLANAR O
   Rosin PL, 1999, IEEE T SYST MAN CY B, V29, P297, DOI 10.1109/3477.752804
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   SHEU DD, 1992, PATTERN RECOGN, V25, P771, DOI 10.1016/0031-3203(92)90031-D
   SLUZEK A, 2005, P 8 MIL AER PROGR LO
   STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604
   Wong AKC, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P1202, DOI 10.1109/IROS.1998.727463
NR 43
TC 12
Z9 12
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 259
EP 274
DI 10.1016/j.imavis.2007.06.001
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500010
DA 2024-07-18
ER

PT J
AU Babu, RV
   Pérez, P
   Bouthemy, P
AF Babu, R. Venkatesh
   Perez, Patrick
   Bouthemy, Patrick
TI Robust tracking with motion estimation and local Kernel-based color
   modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE visual tracking; mean-shift; object tracking; kernel tracking
ID SEARCH ALGORITHM; MEAN SHIFT
AB Visual tracking has been a challenging problem in computer vision over the decades. The applications of visual tracking are far-reaching, ranging from surveillance and monitoring to smart rooms. Mean-shift tracker, which gained attention recently, is known for tracking objects in a cluttered environment. In this work, we propose a new method to track objects by combining two well-known trackers, sum-of-squared differences (SSD) and color-based mean-shift (MS) tracker. In the proposed combination, the two trackers complement each other by overcoming their respective disadvantages. The rapid model change in SSD tracker is overcome by the MS tracker module, while the inability of MS tracker to handle large displacements is circumvented by the SSD module. The performance of the combined tracker is illustrated to be better than those of the individual trackers, for tracking fast-moving objects. Since the MS tracker relies on global object parameters such as color, the performance of the tracker degrades when the object undergoes partial occlusion. To avoid adverse effects of the global model, we use MS tracker to track local object properties instead of the global ones. Further, likelihood ratio weighting is used for the SSD tracker to avoid drift during partial occlusion and to update the MS tracking modules. The proposed tracker outperforms the traditional MS tracker as illustrated. (c) 2006 Elsevier B.V. All rights reserved.
C1 Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.
   IRISA INRIA, Rennes, France.
C3 Indian Institute of Science (IISC) - Bangalore; Universite de Rennes;
   Universite Paris Saclay
RP Babu, RV (corresponding author), Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.
EM venkatesh.babu@gmail.com
RI Radhakrishnan, Venkatesh Babu/D-5313-2009
OI Radhakrishnan, Venkatesh Babu/0000-0002-1926-1804
CR [Anonymous], 2000, P IEEE C COMP VIS PA
   Avidan S, 2001, PROC CVPR IEEE, P184
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Cheung GKM, 2003, PROC CVPR IEEE, P77
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Deguchi K, 2004, INT C PATT RECOG, P506, DOI 10.1109/ICPR.2004.1334577
   Fieguth P, 1997, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.1997.609292
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104
   Hager GD, 2004, PROC CVPR IEEE, P790
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Isard M., 1996, ECCV, P343
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Nguyen HT, 2004, IEEE T PATTERN ANAL, V26, P1099, DOI 10.1109/TPAMI.2004.45
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   PEREZ P, 2002, P EUR C COMP VIS COP
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Porikli F., 2005, IEEE Intl. Conf. Multimedia and Expo, P1234
   Shan C, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P669
   Shen CH, 2005, IEEE I CONF COMP VIS, P1516
   Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yang C, 2005, PROC CVPR IEEE, P176
   Yang J, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P142, DOI 10.1109/ACV.1996.572043
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   Zhu ZW, 2002, INT C PATT RECOG, P318, DOI 10.1109/ICPR.2002.1047460
   Zivkovic Z, 2004, PROC CVPR IEEE, P798
NR 34
TC 57
Z9 79
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1205
EP 1216
DI 10.1016/j.imavis.2006.07.016
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sun, J
   Smith, M
   Smith, L
   Midha, S
   Bamber, J
AF Sun, Jiuai
   Smith, Melvyn
   Smith, Lyndon
   Midha, Sagar
   Bamber, Jeff
TI Object surface recovery using a multi-light photometric stereo technique
   for non-Lambertian surfaces subject to shadows and specularities
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE photometric stereo; specular reflection; shadows; surface reflectance;
   surface orientation; height map; linear least-squares solution
ID SHAPE
AB This paper presents a new multi-light source photometric stereo system for reconstructing images of various characteristics of non-Lambertian rough surfaces with widely varying texture and specularity. Compared to the traditional three-light photometric stereo method, extra lights are employed using a hierarchical selection strategy to eliminate the effects of shadows and specularities, and to make the system more robust. We also show that six lights is the minimum needed in order to apply photometric stereo to the entire visible surface of any convex object. Experiments on synthetic and real scenes demonstrate that the proposed method can extract surface reflectance and orientation effectively, even in the presence of strong shadows and highlights. Hence, the method offers advantages in the recovery of dichromatic surfaces possessing rough texture or deeply relieved topographic features, with applications in reverse engineering and industrial surface inspection. Experimental results are presented in the paper.
C1 Univ W England, Fac CEMS, Machine Vis Lab, Bristol BS16 1QY, Avon, England.
   Inst Canc Res, Ultrasound & Opt Imaging, Surrey SM2 5PT, England.
   Royal Marsden NHS Trust, Surrey SM2 5PT, England.
C3 University of West England; University of London; Institute of Cancer
   Research - UK; Royal Marsden NHS Foundation Trust
RP Sun, J (corresponding author), Univ W England, Fac CEMS, Machine Vis Lab, Bristol BS16 1QY, Avon, England.
EM jiuai2.sun@uwe.ac.uk
RI ; Bamber, Jeffrey/B-8839-2014
OI Smith, Melvyn/0000-0002-5307-8288; Smith, Lyndon/0000-0001-5821-0586;
   Bamber, Jeffrey/0000-0001-9436-1832
CR Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898
   COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6
   Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816
   HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0
   Mallick SP, 2005, PROC CVPR IEEE, P619
   Nicodemus F., 1977, GEOMETRICAL CONSIDER
   Rushmeier H., 1997, Rendering Techniques '97. Proceedings of the Eurographics Workshop. Eurographics, P35
   SATO Y, 1997, SIGGRAPH 97, P379
   SMITH ML, 2000, SURFACE INSPECTION T
   Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627
   TAGARE HD, 1991, IEEE T PATTERN ANAL, V13, P133, DOI 10.1109/34.67643
   Tsumura N, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P77
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   WU J, 2003, THESIS H WATT U
NR 14
TC 60
Z9 71
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1050
EP 1057
DI 10.1016/j.imavis.2006.04.025
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300003
DA 2024-07-18
ER

PT J
AU Patricio, MA
   Maravall, D
AF Patricio, M. A.
   Maravall, D.
TI A novel generalization of the gray-scale histogram and its application
   to the automated visual measurement and inspection of wooden Pallets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE generalized gray-level histogram; automatic visual inspection; image
   segmentation; defect detection; texture recognition; wood inspection
ID DEFECT DETECTION; SURFACE-DEFECTS; GABOR FILTERS; CT IMAGERY; LUMBER
AB We present a novel concept, the histogram of connected elements (HCE) which is a generalization of the usual gray-level histogram of digital images is introduced and its application to automatic visual measurement and inspection system, currently operating at several European inspection plants. The main objective of the system is to automate the inspection of used wooden pallets. The paper begins with a brief description of the system, including some comments on the electromechanical handling of the inspected objects and the illumination set-up. Then, the paper presents the segmentation method used to extract the pallet elements, as an initial step for pallet measurements and the detection of possible defects. This method consists of an initial threshold on the histogram based on a Bayesian statistical classifier, followed by an iterative, heuristic search of the optimum threshold of the histogram. Finally, the paper introduces the application of the histogram of connected elements to the detection of very thin cracks, one of the hardest problems involved in the visual inspection of used pallets. Experimental results are obtained and we present a comparative study with several well-known and thoroughly tested techniques for the segmentation of textured images, including two algorithms belonging to the adaptive Bayesian family of restoration and segmentation methods and a probabilistic relaxation process. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Carlos III Madrid, Dept Informat, Colmenarejo 28270, Spain.
   Univ Politecn Madrid, Dept Inteligencia Artificial, Madrid, Spain.
C3 Universidad Carlos III de Madrid; Universidad Politecnica de Madrid
RP Patricio, MA (corresponding author), Univ Carlos III Madrid, Dept Informat, Avd Univ Carlos III,22, Colmenarejo 28270, Spain.
EM mpatrici@inf.uc3m.es; dmaravall@fi.upm.es
RI Patricio, Miguel A./AAZ-4876-2020
OI Patricio, Miguel A./0000-0002-9304-826X
CR ASTROM A, 2001, P 12 SCAND C IMAG AN, V319, P770
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Cho T-H., 1990, P IEEE INT C SYST MA, P345
   CHO TH, 1990, P 10 INT C PATT REC, V1, P726
   Ciccotelli J., 1992, IND METROLOGY, V2, P185
   Conners R.W., 1992, IND METROLOGY, V2, P317
   Duda R., 1973, Pattern Classification and Scene Analysis
   DUNN D, 1995, IEEE T IMAGE PROCESS, V4, P947, DOI 10.1109/83.392336
   ERSBOLL BK, 1992, IND METROLOGY, V2, P219
   Escofet J, 1998, OPT ENG, V37, P2297, DOI 10.1117/1.601751
   Glasbey CA., 1995, IMAGE ANAL BIOL SCI
   Hemayed EE, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P351, DOI 10.1109/AVSS.2003.1217942
   HOLYEN S, 1989, P 3 INT C SCANN TECH, P1
   Hu CS, 2003, J WOOD SCI, V49, P492, DOI 10.1007/s10086-002-0509-3
   HUBER HA, 1985, FOREST PROD J, V35, P79
   Jasper WJ, 1996, OPT ENG, V35, P3140, DOI 10.1117/1.601054
   Kabir MF, 2003, WOOD FIBER SCI, V35, P341
   Kabir MF, 2002, WOOD FIBER SCI, V34, P165
   KIM CW, 1994, PATTERN RECOGN LETT, V15, P713, DOI 10.1016/0167-8655(94)90076-0
   Kittler J, 2000, PATTERN RECOGN, V33, P705, DOI 10.1016/S0031-3203(99)00081-3
   KLINKHACHORN P, 1993, FOREST PRODUCTION J, V35, P79
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   Kumar A, 2002, IEEE T SYST MAN CY B, V32, P553, DOI 10.1109/TSMCB.2002.1033176
   Lampinen J, 1996, INT J PATTERN RECOGN, V10, P97, DOI 10.1142/S0218001496000098
   Levine MartinD., 1985, VISION MAN MACHINE
   Malasne N, 2000, P SOC PHOTO-OPT INS, V4116, P429, DOI 10.1117/12.406522
   MARAVALL D, 2002, PATTERN RECOGN, P399
   MCDONALD KA, 1981, FOREST PRODUCTION J, V31, P33
   MORING I, 1986, AUTOMATIC VISUAL WOO, V2, P290
   NEUBAUER C, 1992, P INT JOINT C NEUR N, P1148
   NISKANEN M, 2002, P SPIE INT SOC OPT E, V46, P123
   Packianather MS, 2000, INT J ADV MANUF TECH, V16, P424, DOI 10.1007/s001700050174
   PATRICIO MA, 2001, BIOINSPIRED APPL CON, P160
   Pham D. T., 1998, Thirteenth International Conference on Applications of Artificial Intelligence in Engineering AIENG XIII, P105
   Polzleitner W., 1992, IND METROLOGY, V2, P283, DOI [10.1016/0921-5956(92)80008-H, DOI 10.1016/0921-5956(92)80008-H]
   Rosandich R., 1997, INTELLIGENT VISUAL I
   Schmoldt DL, 2000, WOOD FIBER SCI, V32, P287
   Silven O, 1996, INT J PATTERN RECOGN, V10, P83, DOI 10.1142/S0218001496000086
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Wyckhuyse A, 2001, RES NONDESTRUCT EVAL, V13, P13
   Zhu DP, 1996, IEEE T SYST MAN CY B, V26, P522, DOI 10.1109/3477.517028
NR 42
TC 18
Z9 21
U1 2
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 805
EP 816
DI 10.1016/j.imavis.2006.05.020
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600004
DA 2024-07-18
ER

PT J
AU López, MT
   Fernández, MA
   Fernández-Caballero, A
   Mira, J
   Delgado, AE
AF Lopez, Maria T.
   Fernandez, Miguel A.
   Fernandez-Caballero, Antonio
   Mira, Jose
   Delgado, Ana E.
TI Dynamic visual attention model in image sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE dynamic visual attention; motion; segmentation; feature extraction;
   feature integration
ID SELECTIVE ATTENTION; LATERAL INTERACTION; ACCUMULATIVE COMPUTATION;
   IDENTIFICATION MODEL; NETWORK ARCHITECTURE; MOTION DETECTION;
   SEGMENTATION; RECOGNITION; SEARCH; INTEGRATION
AB A new computational architecture of dynamic visual attention is introduced in this paper. Our approach defines a model for the generation of an active attention focus on a dynamic scene captured from a still or moving camera. The aim is to obtain the objects that keep the observer's attention in accordance with a set of predefined features, including color, motion and shape. The solution proposed to the selective visual attention problem consists in decomposing the input images of an indefinite sequence of images into its moving objects, by defining which of these elements are of the user's interest, and by keeping attention on those elements through time. Thus, the three tasks involved in the attention model are introduced. The Feature-Extraction task obtains those features (color, motion and shape features) necessary to perform object segmentation. The Attention-Capture task applies the criteria established by the user (values provided through parameters) to the extracted features and obtains the different parts of the objects of potential interest. Lastly, the Attention-Reinforcement task maintains attention on certain elements (or objects) of the image sequence that are of real interest. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Castilla La Mancha, Escuela Politecn Super Albacete, Dept Sistemas Informat, Albacete 02071, Spain.
   Univ Castilla La Mancha, Inst Invest Informat Albacete, Albacete 02071, Spain.
   Univ Nacl Educ Distancia, ETSI Informat, Dept Inteligencia Artificial, Madrid 28040, Spain.
C3 Universidad de Castilla-La Mancha; Universidad de Castilla-La Mancha;
   Universidad Nacional de Educacion a Distancia (UNED)
RP Fernández-Caballero, A (corresponding author), Univ Castilla La Mancha, Escuela Politecn Super Albacete, Dept Sistemas Informat, Albacete 02071, Spain.
EM mlopez@info-ab.uclm.es; miki@info-ab.uclm.es; caballer@info-ab.uclm.es;
   jmira@dia.uned.es; adelgado@dia.uned.es
RI Delgado García, Ana E./E-9526-2015; Fernández-Caballero,
   Antonio/N-5019-2019; Lopez Bonal, Maria Teresa/A-8333-2015
OI Delgado García, Ana E./0000-0001-6619-1223; Fernández-Caballero,
   Antonio/0000-0002-8211-0398; Lopez Bonal, Maria
   Teresa/0000-0002-2846-3483
CR Backer G., 2003, INT WORKSHOP ATTENTI, P9
   BALKENIUS C, P EUROBOT 99
   Baluja S, 1997, ROBOT AUTON SYST, V22, P329, DOI 10.1016/S0921-8890(97)00046-8
   Bonaiuto J, 2006, IMAGE VISION COMPUT, V24, P557, DOI 10.1016/j.imavis.2005.09.008
   CAETANO F, 2000, SBA CONTROLE AUTOMAC, V11, P187
   Chung D, 2002, LECT NOTES COMPUT SC, V2525, P558
   Czúni L, 2001, REAL-TIME IMAGING, V7, P77, DOI 10.1006/rtim.2000.0222
   Deco G, 2001, VIS COGN, V8, P119, DOI 10.1080/13506280042000054
   Desimone R., 1989, Handbook of Neuropsychology, V2, P267
   Fernandez MA, 1995, LECT NOTES COMPUT SC, V930, P137
   FERNANDEZ MA, 1992, IAPR WORKSH MACH VIS, P249
   Fernández-Caballero A, 2003, NEURAL NETWORKS, V16, P205, DOI 10.1016/S0893-6080(02)00233-2
   Fernandez-Caballero A, 2003, PATTERN RECOGN, V36, P1131, DOI 10.1016/S0031-3203(02)00116-4
   Fernández-Caballero A, 2003, NEUROCOMPUTING, V50, P341, DOI 10.1016/S0925-2312(02)00571-4
   Fernandez-Caballero A, 2001, PATTERN RECOGN LETT, V22, P1517, DOI 10.1016/S0167-8655(01)00105-2
   Fernández-Martínez P, 2003, B UNIONE MAT ITAL, V6B, P49
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   GOTZE N, 1996, AKTIVES SEHEN TECHNI, P186
   HASEGAWA O, 1994, SYST COMPUT JPN, V25, P11, DOI 10.1002/scj.4690251102
   Heinke D, 2005, COMPUT VIS IMAGE UND, V100, P172, DOI 10.1016/j.cviu.2004.10.010
   Heinke D, 2002, NEUROCOMPUTING, V44, P817, DOI 10.1016/S0925-2312(02)00478-2
   Herpers R, 2001, IMAGE VISION COMPUT, V19, P793, DOI 10.1016/S0262-8856(00)00107-4
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   López MT, 2003, LECT NOTES COMPUT SC, V2686, P694
   Maki A, 2000, COMPUT VIS IMAGE UND, V78, P351, DOI 10.1006/cviu.2000.0840
   Mertsching B., 1998, Proceedings of NC 1998. International ICSC/IFAC Symposium on Neural Computation, P469
   Minato T, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1422, DOI 10.1109/IROS.2001.977180
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Mozer M.C., 1991, PERCEPTION MULTIPLE
   Paletta L, 2000, ROBOT AUTON SYST, V31, P71, DOI 10.1016/S0921-8890(99)00079-2
   Posner M.I., 1994, Images of mind
   Postma EO, 1997, NEURAL NETWORKS, V10, P993, DOI 10.1016/S0893-6080(97)00034-8
   Rothenstein AL, 2008, IMAGE VISION COMPUT, V26, P114, DOI 10.1016/j.imavis.2005.08.011
   Salah AA, 2002, IEEE T PATTERN ANAL, V24, P420, DOI 10.1109/34.990146
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vecera S. P., 2000, Brain and Mind, V1, P353, DOI [DOI 10.1023/A:1011565623996, 10.1023/A]
   Wada T, 2000, IEEE T PATTERN ANAL, V22, P873, DOI 10.1109/34.868687
   Walther D, 2002, LECT NOTES COMPUT SC, V2525, P472
   WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774
   Ye YM, 1999, COMPUT VIS IMAGE UND, V73, P145, DOI 10.1006/cviu.1998.0736
   YONN KJ, 2000, 1 INT WORKSH HUM FRI, P109
   Zhang DS, 2001, CIRC SYST SIGNAL PR, V20, P143, DOI 10.1007/BF01201137
NR 44
TC 27
Z9 30
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 597
EP 613
DI 10.1016/j.imavis.2006.05.004
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200007
OA Green Published
DA 2024-07-18
ER

PT J
AU Zhang, YB
   Martínez, AM
AF Zhang, Yongbin
   Martinez, Aleix M.
TI A weighted probabilistic approach to face recognition from multiple
   images and video sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
ID EIGENFACES; SEPARATION
AB To date, advances in face recognition have been dominated by the design of algorithms that do recognition from a single test image. Recently, an obvious but important question has been put forward. Will the recognition results of such approaches be generally improved when using multiple images or video sequences? To test this, we extend the formulation of a probabilistic appearance-based face recognition approach (which was originally defined to do recognition from a single still) to work with multiple images and video sequences. In our algorithm, as it is the case in most appearance-based approaches, we will need to use a feature extraction algorithm to find those features that best describe and discriminate among face images of distinct people. We will show that regardless of the algorithm used, the recognition results improve considerably when one uses a video sequence rather than a single still. Hence, a positive answer to our question (in the general sense) seems reasonable. The probabilistic algorithm we propose in this paper is robust to partial occlusions, orientation and expression changes, and does not require of a precise localization of the face or facial features. We will also show how these problems are more easily solved when one uses a video sequence rather than a single image for testing. The limitations of our algorithm will also be discussed. Understanding the limitations of current techniques when applied to video is important, because it helps identify those weak points that require further consideration. (c) 2005 Elsevier B.V. All rights reserved.
C1 Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Martínez, AM (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, 2015 Neil Ave, Columbus, OH 43210 USA.
EM aleix@ece.osu.edu
RI Martinez, Aleix M/A-2380-2008
CR [Anonymous], 1994, IEEE C COMP VIS PATT
   [Anonymous], 2003, ACM COMPUTING SURVEY
   Bartlett M.S., 2001, FACE IMAGE ANAL UNSU
   Bartlett MS, 1999, PSYCHOPHYSIOLOGY, V36, P253, DOI 10.1017/S0048577299971664
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Duda R. O., 2001, PATTERN CLASSIFICATI
   Edwards G. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P486, DOI 10.1109/CVPR.1999.786982
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fisher RA, 1938, ANN EUGENIC, V8, P376, DOI 10.1111/j.1469-1809.1938.tb02189.x
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   GATHER U, 2001, P WORKSH STAT METH S, P147
   Gong S., 1994, EUR WORKSH COMB REAL, P96
   GORODNICHY D, 2004, WORKSH ENH INF SYST
   Hallinan P., 1999, Two and Three-dimensional Patterns of the Face
   HEISEL B, 2001, P NIPS
   Howell AJ, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P224, DOI 10.1109/AFGR.1996.557268
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Lee KC, 2003, PROC CVPR IEEE, P313
   LI GY, 1985, J AM STAT ASSOC, V80, P759, DOI 10.2307/2288497
   LI H, 2001, J OPTICAL SOC AM, V8
   Martínez A, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P35, DOI 10.1109/IVL.1999.781120
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Martínez AM, 2003, VISION RES, V43, P1047, DOI 10.1016/S0042-6989(03)00079-8
   MARTINEZ AM, 2005, FACE PROCESSING ADV
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Phillips P., 2005, P IEEE COMP VIS PATT
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   PHILLIPS PJ, 2002, 6965 NISTIR
   Shakhnarovich G, 2002, LECT NOTES COMPUT SC, V2352, P851, DOI 10.1007/3-540-47977-5_56
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Srinivasan S, 2002, INT C PATT RECOG, P302, DOI 10.1109/ICPR.2002.1047456
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vetter T, 1997, J OPT SOC AM A, V14, P2152, DOI 10.1364/JOSAA.14.002152
   WECHSLER H, 1997, P INT C AUD VID BAS, P117
   YACOOB Y, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P70, DOI 10.1109/CVPR.1994.323812
   Zhou SH, 2003, COMPUT VIS IMAGE UND, V91, P214, DOI 10.1016/S1077-3142(03)00080-8
NR 43
TC 41
Z9 49
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2006
VL 24
IS 6
BP 626
EP 638
DI 10.1016/j.imavis.2005.08.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 061NB
UT WOS:000238878200009
DA 2024-07-18
ER

PT J
AU Bigand, A
   Evrard, L
   Dubus, JP
AF Bigand, A.
   Evrard, L.
   Dubus, J. P.
TI A new perceptual organization approach to 3D measuring system based on
   the fuzzy integral
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE computer vision; perceptual organization; fuzzy integral
ID COMPUTER VISION; SEGMENTATION; OPERATORS; NETWORKS; FUSION
AB A new algorithm for perceptual grouping using the fuzzy integral and primarily aimed at static scenes (industrial images) analysis is presented. Our purpose is to build the planar surfaces of three-dimensional (3D) polyhedric objects from labeled line segments using an active vision system (projection of laser planes on the object and 3D reconstruction using a CCD camera). Each line segment is first characterized by three geometric constraints, which are assigned by a specific membership function. These constraints are used in geometric relations between image features (such as collinear and parallel relations) through the fuzzy integral for grouping the line segments with accuracy, since edge detection gives imperfect and incomplete information. (c) 2006 Elsevier B.V. All rights reserved.
C1 Littoral Univ, F-62228 Calais, France.
   Univ Lille 1, Lab ID3, F-59655 Villeneuve Dascq, France.
C3 Universite du Littoral-Cote-d'Opale; Universite de Lille
RP Bigand, A (corresponding author), Littoral Univ, BP649, F-62228 Calais, France.
EM abigand@iup-calais.univ-littoral.fr
CR Auephanwiriyakul S., 2002, Information Fusion, V3, P69, DOI 10.1016/S1566-2535(01)00054-9
   Bloch I, 1996, IEEE T SYST MAN CY A, V26, P52, DOI 10.1109/3468.477860
   BOLDT M, 1989, IEEE T SYST MAN CYB, V19, P1581, DOI 10.1109/21.44073
   Bouchon-Meunier B., 1998, AGGREGATION FUSION I
   Boyer KL, 1999, COMPUT VIS IMAGE UND, V76, P1, DOI 10.1006/cviu.1999.0797
   Chiang JH, 1999, IEEE T FUZZY SYST, V7, P63, DOI 10.1109/91.746311
   Denneberg D, 1994, non-additive measure and integral
   EVRARD L, 1996, EUR SPIE C BES
   EVRARD L, 1996, 3 FRANC JAP C MECHAT
   FANG LC, 1999, IMAGE VISION COMPUTI, V17
   Grabisch M, 2000, IEEE T FUZZY SYST, V8, P627, DOI 10.1109/91.873585
   GRABISCH M, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, P47, DOI 10.1109/FUZZY.1992.258678
   GRABISCH M, 1994, FUZZY SET SYST, V65, P255, DOI 10.1016/0165-0114(94)90023-X
   GRABISCH M, 1995, IEEE T FUZZY SYST, V3, P96, DOI 10.1109/91.366561
   GRABISCH M, 1998, FUZZY INTEGRAL FLEXI
   GRANDJEAN P, 1991, THESIS LAAS TOULOUSE
   Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791
   ISHII K, 1985, INT J MAN MACH STUD, V22, P19, DOI 10.1016/S0020-7373(85)80075-4
   JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102
   KANG HB, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, P651, DOI 10.1109/FUZZY.1992.258737
   LI J, 2004, IEEE T FUZZY SYSTEMS, V12
   Lowe D. G., 1985, Perceptual Organization and Visual Recognition
   LOWE DG, 1987, ARTIFICIAL INTELLIGE, V31
   Murofushi T, 2000, STUD FUZZ SOFT COMP, V40, P3
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   PARK IK, 2004, PATTERN RECOGNITION, V37
   SARKAR S, 1993, IEEE T SYST MAN CYB, V23, P382, DOI 10.1109/21.229452
   Sugeno, 1974, THESIS TOKYO I TECHN
   TAHANI H, 1990, IEEE T SYST MAN CYB, V20, P733, DOI 10.1109/21.57289
   Tanaka K., 1991, International Journal of Approximate Reasoning, V5, P213, DOI 10.1016/0888-613X(91)90009-B
   TAREL JP, 1995, P SCAND C IM AN UPPS, P1061
   VASSEUR P, 1999, PATTERN RECOGNITION, V32
   WALKER EL, 1994, FUZZY SETS SYSTEMS, V65, P187
   Wang J, 1997, NEURAL NETWORKS, V10, P183, DOI 10.1016/S0893-6080(96)00080-9
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   YlaJaaski A, 1996, COMPUT VIS IMAGE UND, V63, P399, DOI 10.1006/cviu.1996.0031
   Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, P3, DOI 10.1016/0165-0114(78)90029-5
NR 37
TC 0
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2006
VL 24
IS 4
BP 381
EP 393
DI 10.1016/j.imavis.2005.12.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 049US
UT WOS:000238043500007
DA 2024-07-18
ER

PT J
AU Licsár, A
   Szirányi, T
AF Licsár, A
   Szirányi, T
TI User-adaptive hand gesture recognition system with interactive training
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE hand gesture recognition; user-independent recognition;
   supervised/unsupervised training; camera-projector systems
AB Our paper proposes a vision-based hand gesture recognition system with interactive training, aimed to achieve a user-independent application by on-line supervised training. Usual recognition systems involve a preliminary off-line training phase, separated from the recognition phase. If the system recognizes unknown (non-trainer) users the recognition rate of gesture classes could decrease. The recognition has to be suspended and all gestures need to be retrained with an improved training set, resulting in inconveniences. Our new approach introduces an on-line training method embedded into the recognition process, being interactively controlled by the user and adapting to his/her gestures. Our main goal is that any non-trainer users be able to use the system instantly and if the recognition accuracy decreases only the faulty detected gestures be retrained realizing fast adaptation. We implement the proposed system as a camera-projector system in which users can directly interact with the projected image by hand gestures, realizing an augmented reality tool in a multi-user environment. The emphasis is on the novel approach of dynamic and quick follow-up training capabilities instead of handling large pretrained databases. We also conducted tests on several users in real environments for a practical application. (c) 2005 Elsevier Ltd. All rights reserved.
C1 Univ Veszprem, Dept Image Proc & Neurocomp, H-8200 Veszprem, Hungary.
   Hungarian Acad Sci, Comp & Automat Res Inst, Analog & Neural Comp Lab, H-1111 Budapest, Hungary.
C3 University of Pannonia; Hungarian Academy of Sciences; Hungarian
   Research Network; HUN-REN Institute for Computer Science & Control
RP Univ Veszprem, Dept Image Proc & Neurocomp, Egyetem 10, H-8200 Veszprem, Hungary.
EM licsara@almos.vein.hu; sziranyi@sztaki.hu
RI Sziranyi, Tamas/A-3410-2008; Rohlf, F J/A-8710-2008
OI Sziranyi, Tamas/0000-0003-2989-0214
CR ALT FL, 1962, J ACM, V9, P240, DOI 10.1145/321119.321122
   [Anonymous], PRIS
   Athitsos V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P45, DOI 10.1109/AFGR.2002.1004129
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   CHO K, 1994, IEEE T PATTERN ANAL, V16, P882, DOI 10.1109/34.310683
   Crowley J., 1995, International Workshop on Gesture and Face Recognition, P195
   Czúni L, 2004, SMPTE MOTION IMAG J, V113, P170, DOI 10.5594/J16286
   FRASER QS, 1996, P CHI 96 VANC, P134
   Freeman W. T., 1995, P INT WORKSH AUT FAC, V12, P296
   Hall D, 2001, ROBOT AUTON SYST, V35, P211, DOI 10.1016/S0921-8890(01)00125-7
   IMAGAWA K, 2000, P 4 AS C COMP VIS, P943
   KOIKE H., 2000, P CHI 00, P121
   KOVACS L, 2004, P SCCG, P183
   Leubner C, 2001, EUROMICRO CONF PROC, P308, DOI 10.1109/EURMIC.2001.952469
   Licsár A, 2004, LECT NOTES COMPUT SC, V3058, P83
   LICSAR A, 2004, DYNAMIC TRAINING HAN, P971
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   Poggio T., 2003, NOTICES AMS, V50, P537
   Pratt W.K., 1977, DIGITAL IMAGE PROCES
   QUEK F, 1995, FINGER MOUSE FREEHOU, P372
   Ramamoorthy A, 2003, PATTERN RECOGN, V36, P2069, DOI 10.1016/S0031-3203(03)00042-6
   RAYTCHEV B, 2002, PATTERN RECOGN, V21, P69
   Rui Y, 1998, SER SOFTW ENGN KNOWL, V8, P165
   SCHLENZIG J, 1994, CONF REC ASILOMAR C, P1267, DOI 10.1109/ACSSC.1994.471662
   STARNER T, 1995, VISUAL RECOGNITION A, P189
   STORRING M, 1999, 7 S INT ROB SYST COI, P20
   STREITZ NA, 1994, LOC REM DESKT ENV P, P345
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Wellner P., 1993, COMMUN ACM, V36, P87
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   ZHANG DS, 2002, P 5 AS C COMP VIS AC, P652
NR 31
TC 43
Z9 51
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2005
VL 23
IS 12
BP 1102
EP 1114
DI 10.1016/j.imavis.2005.07.016
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 971ZK
UT WOS:000232423400007
DA 2024-07-18
ER

PT J
AU Zhang, D
   Li, HF
   Du, MH
AF Zhang, D
   Li, HF
   Du, MH
TI Fast MAP-based multiframe super-re solution image reconstruction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE super-resolution; MAP; computational complexity; image reconstruction
ID HIGH-RESOLUTION IMAGE; SUPERRESOLUTION IMAGE; ALGORITHM; MOTION;
   SEQUENCE; FRAMES; NOISY
AB Super-resolution image reconstruction produces a high-resolution image from a set of shifted, blurred, and decimated versions thereof. Previously published papers have not addressed the computational complexity of this ill-conditioned large scale problem adequately. In this paper, the computational complexity of MAP-based multiframe super-resolution algorithms is studied, and a new fast algorithm, as well as methods for parallel image reconstruction is also presented. The proposed fast algorithm splits the multiple input low-resolution images into several subsets according to their translation relations, and then applies normal MAP algorithm to each subset, the reconstructed images are processed subsequently at a successive level until the desired resolution is achieved. Experiment results are also provided to demonstrate the efficiency of the proposed techniques. (c) 2005 Elsevier B.V. All rights reserved.
C1 Shaoguan Univ, Dept Comp Sci, Shaoguan, Peoples R China.
   S China Univ Technol, Dept Elect & Commun Engn, Guangzhou, Peoples R China.
C3 Shaoguan University; South China University of Technology
RP Shaoguan Univ, Dept Comp Sci, Shaoguan, Peoples R China.
EM changnuode@hotmail.com
CR [Anonymous], 1994, FIA9412 NASA
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536
   Chalidabhongse J, 1997, IEEE T CIRC SYST VID, V7, P477, DOI 10.1109/76.585927
   CONNOLLY T, 1997, P INT C IM PROC, V1, P917
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   Hardie RC, 1998, OPT ENG, V37, P247, DOI 10.1117/1.601623
   Kaltenbacher E., 1996, Proceedings of the IEEE 1996 National Aerospace and Electronics Conference NAECON 1996 (Cat. No.96CH35934), P702, DOI 10.1109/NAECON.1996.517726
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   OSKOUIFARD P, 1988, IEEE T MED IMAGING, V7, P45, DOI 10.1109/42.3928
   Patti AJ, 2001, IEEE T IMAGE PROCESS, V10, P179, DOI 10.1109/83.892456
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Shin J.H., 1999, P 1999 INT C IM PROC, V3, P676
   TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
NR 20
TC 20
Z9 27
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2005
VL 23
IS 7
BP 671
EP 679
DI 10.1016/j.imavis.2005.03.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 940LX
UT WOS:000230147100006
DA 2024-07-18
ER

PT J
AU Gelgon, M
   Bouthemy, P
   Le Cadre, JP
AF Gelgon, M
   Bouthemy, P
   Le Cadre, JP
TI Recovery of the trajectories of multiple moving objects in an image
   sequence with a PMHT approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multiple object tracking; trajectory reconstruction; data association;
   EM algorithm; PMHT
ID MAXIMUM-LIKELIHOOD; MIXTURE DENSITIES; INCOMPLETE DATA; TRACKING;
   SEGMENTATION; ALGORITHM
AB This paper is concerned with the tracking of multiple moving objects in an image sequence and the reconstruction of the entire trajectories of these objects all over the sequence. More specifically, we address the joint issue of trajectory estimation and measurement-to-trajectory associations, which is the key problem in that context due to the occurrence of object occlusions or crossings. An original and efficient scheme is proposed, that adapts the probabilistic multiple hypothesis tracking (PMHT) technique to the case of tracking of regions in video, for which geometry and motion models can be introduced. Moreover, reliable partial associations can be obtained as an initialization. Data association and trajectory estimation are conducted within a probabilistic framework. The latter relies on Kalman filtering, while the former is solved with an EM algorithm for which a suitable initial configuration can be defined. The proposed tracking method is validated by experiments carried out on real image sequences depicting complex situations. (C) 2004 Elsevier B.V. All rights reserved.
C1 Ecole Polytech Univ Nantes, LINA, F-44306 Nantes, France.
   INRIA, IRISA, F-35042 Rennes, France.
   CNRS, IRISA, F-35042 Rennes, France.
C3 Nantes Universite; Universite de Rennes; Inria; Universite de Rennes;
   Centre National de la Recherche Scientifique (CNRS)
RP Ecole Polytech Univ Nantes, LINA, Rue C Pauc, F-44306 Nantes, France.
EM marc.gelgon@polytech.univ-nantes.fr; bouthemy@irisa.fr; lecadre@irisa.fr
CR BARSHALOM Y, 1993, PRINCIPLES TECHNIQUE
   Blake A., 1998, ACTIVE CONTOURS
   Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539
   COX IJ, 1993, INT J COMPUT VISION, V10, P53, DOI 10.1007/BF01440847
   COX P, 1989, PATTERN RECOGN LETT, V9, P327, DOI 10.1016/0167-8655(89)90061-5
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560
   Gauvrit H, 1997, IEEE T AERO ELEC SYS, V33, P1242, DOI 10.1109/7.625121
   GELGON M, 1999, P INT S PHYS IM PROC, P80
   GIANNOPOULOS E, 1997, 31 AS C SIGN SYST CO
   Hammoud R, 2000, INT C PATT RECOG, P71, DOI 10.1109/ICPR.2000.906020
   Hue C, 2002, IEEE T AERO ELEC SYS, V38, P791, DOI 10.1109/TAES.2002.1039400
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Marques F, 1997, P SOC PHOTO-OPT INS, V3024, P190, DOI 10.1117/12.263229
   Meyer F. G., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P746, DOI 10.1109/CVPR.1993.341154
   MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/ciun.1994.1042
   Molnar KJ, 1998, IEEE T SIGNAL PROCES, V46, P115, DOI 10.1109/78.651193
   Moscheni F, 1998, IEEE T PATTERN ANAL, V20, P897, DOI 10.1109/34.713358
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   Odobez JM, 1998, SIGNAL PROCESS, V66, P143, DOI 10.1016/S0165-1684(98)00003-6
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   RASMUSSEN C, 1998, P INT C COMP VIS PAT, P18
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Ringer M, 2002, LECT NOTES COMPUT SC, V2350, P524
   Strandlie A, 1999, COMPUT PHYS COMMUN, V123, P77, DOI 10.1016/S0010-4655(99)00258-1
   Streit R., 1993, 6th Joint Service Data Fusion Symposium, P1015
   STREIT RL, 1998, STUDIES PROBABIL SES, V9801
   TAREL JP, 2002, P EUR C COMP VIS ECC, P492
   WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7
   Zaveri MA, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P73, DOI 10.1109/AVSS.2003.1217904
   ZHANG ZY, 1992, INT J COMPUT VISION, V7, P211, DOI 10.1007/BF00126394
NR 32
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2005
VL 23
IS 1
BP 19
EP 31
DI 10.1016/j.imavis.2004.07.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 882BO
UT WOS:000225913700003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fränti, P
   Ageenko, E
   Kopylov, P
   Gröhn, S
   Berger, F
AF Fränti, P
   Ageenko, E
   Kopylov, P
   Gröhn, S
   Berger, F
TI Compression of map images for real-time applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image compression; map images; real-time applications; personal
   navigation; spatial access
ID LOSSLESS COMPRESSION
AB Digital maps can be stored and distributed electronically using compressed raster image formats. We introduce a storage system for the map images that supports compact storage size, decompression of partial image, and smooth transitions between various scales. The main objective of the proposed storage system is to provide map images for real-time applications that use portable devices with low memory and computing resources. Compact storage size is achieved by dividing the maps into binary layers, which are compressed using context-based statistical modeling and arithmetic coding. Partial image decompression is supported by tiling the image into blocks and implementing direct access to the compressed blocks. In this paper, we give overview of the system architecture, describe the compression technique, and discuss implementation aspects. Experimental results are given both in terms of compression ratios and image retrieval timings. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Joensuu, Dept Comp Sci, FIN-80101 Joensuu, Finland.
C3 University of Eastern Finland
RP Univ Joensuu, Dept Comp Sci, POB 111, FIN-80101 Joensuu, Finland.
EM franti@cs.joensuu.fi
CR Ageenko E, 2000, COMPUT GRAPH-UK, V24, P91, DOI 10.1016/S0097-8493(99)00140-5
   Ageenko EI, 1998, OPT ENG, V37, P1530, DOI 10.1117/1.601668
   Ageenko EI, 1999, SOFTWARE PRACT EXPER, V29, P943, DOI 10.1002/(SICI)1097-024X(199909)29:11<943::AID-SPE266>3.0.CO;2-K
   AGEENKO EI, 2001, IEEE INT C IM PROC I, V3, P458
   ARPS RB, 1994, P IEEE, V82, P889, DOI 10.1109/5.286193
   Fränti P, 2002, INT CONF ACOUST SPEE, P2677
   FRANTI P, 2003, GIM NT, V17, P28
   FRANTI P, 2002, IEEE INT C IM PROC I, V3, P917
   GELLERSEN HW, 2000, P 2 INT S HANDH UB C
   Haskell BG, 1998, IEEE T CIRC SYST VID, V8, P814, DOI 10.1109/76.735379
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   *ISO IEC, 1999, FIN COMM DRAFT ISO I
   *ISO IEC, 1993, PROGR BIL IM COMPR 1
   Kaplan ED., 1996, UNDERSTANDING GPS PR
   KOPYLOV P, 2004, IN PRESS IEEE T IMAG
   Kraak M.J., 2000, WEB CARTOGRAPHY
   Kraak M.J., 1996, Cartography, visualization of spatial data
   LANGDON GG, 1981, IEEE T COMMUN, V29, P858, DOI 10.1109/TCOM.1981.1095052
   Miano J., 1999, Compressed image file formats: Jpeg, png, gif, xbm, bmp
   Murray J.D., 1996, ENCY GRAPHICS FILE F, VSecond
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   PENNEBAKER WB, 1988, IBM J RES DEV, V32, P717, DOI 10.1147/rd.326.0717
   ROELOFS G, 1999, DEFINITIVE GUIDE
   Samet H., 1989, APPL SPATIAL DATA ST
   TOMPKINS D, 1999, ADDITIONAL EXTENSION
   Weinberger MJ, 1996, IEEE T IMAGE PROCESS, V5, P575, DOI 10.1109/83.491334
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
   ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934
   [No title captured]
   [No title captured]
NR 31
TC 6
Z9 7
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2004
VL 22
IS 13
BP 1105
EP 1115
DI 10.1016/j.imavis.2004.05.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 862LY
UT WOS:000224493600002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bullock, DJ
   Zelek, JS
AF Bullock, DJ
   Zelek, JS
TI Real-time tracking for visual interface applications in cluttered and
   occluding situations
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE visual tracking; particle filter; user interface; real-time; optical
   flow
AB Visual interface systems require object tracking techniques with real-time performance for ubiquitous interaction. A probabilistic framework for a visual tracking system, which robustly tracks targets in real-time using color and motion cues, is presented. The algorithm is based on particle filtering techniques of the I-Condensation filter. An innovation of the paper is the use of motion cues to guide the propagation of particle samples which are being evaluated using color cues. This results in a probabilistic blob tracking method which is shown to greatly outperform conventional blob trackers when in the presence of occlusion and clutter. A second innovation presented is the use of motion-based temporal signatures for the visual recognition of an initialization cue. This allows for passive initialization of the tracking system. The application presented here is the task of digital video annotation using a hand-held marking device. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.
C3 University of Guelph
RP Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.
EM dbullock@uoguelph.ca; jzelek@uoguelph.ca
CR [Anonymous], 487 MIT MED LAB
   CAMUS T, 1998, J REAL TIME IMAGING, P71
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   GONCALVES L, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P764, DOI 10.1109/ICCV.1995.466861
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1998, PROC 5 EUROPEAN C CO, V1, P893
   JANG G, ROBUST REALTIME FACE
   KING O, 2000, ECCV, P695
   MACKAY D, 1997, INTRO MONTE CARLO ME
   RASMUSSEN C, 1996, TR95041 U N CAR
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Welch G, 2000, TR95041 U N CAR DEP
NR 12
TC 10
Z9 10
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 1083
EP 1091
DI 10.1016/j.imavis.2004.03.024
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800013
DA 2024-07-18
ER

PT J
AU De Stefano, A
   White, PR
   Collis, WB
AF De Stefano, A
   White, PR
   Collis, WB
TI Film grain reduction on colour images using undecimated wavelet
   transform
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE film grain; noise reduction; wavelet transform; training algorithms
ID NOISE-REDUCTION; ENHANCEMENT; APPROXIMATION; SHRINKAGE
AB The presence of film grain often imposes the crucial quality choice between film enlargement and speed. In this work we present an automatic technique for reducing the amount of grain on film images. The technique reduces the noise by thresholding the wavelet components of the image with parameterised family of functions obtained with an initial training on a set of images. The training produces the parameters identifying the functions by optimising a cost function related to the image visual quality. The method has been tested on images contaminated by artificial and by real grain noise from two Kodak film makes. Being the main focus of this work on the grain reduction aspect rather than on the modelling side, we rely on a well known and state of the art software (Furnace) instead of producing a new noise model. The results demonstrate the efficiency of the method in reducing the grain noise and the ability of the technique in adapting the parameters to the noise level on each colour component. Another relevant characteristic of the method is its potential to be used for various different applications, class of images and type of noises just by modifying training set of images, cost function and shape of the thresholding functions. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Southampton, Inst Sound & Vibrat Res, Highfield SO17 1BJ, Hants, England.
   Foundry, London, England.
C3 University of Southampton
RP Univ Southampton, Inst Sound & Vibrat Res, Highfield SO17 1BJ, Hants, England.
EM ads@isvr.soton.ac.uk; prw@isvr.soton.ac.uk; bill@thefoundry.co.uk
OI White, Paul/0000-0002-4787-8713
CR Abramovich F., 1995, WAVELETS STAT
   ALGAZI VR, 1995, IEEE T IMAGE PROCESS, V4, P1460, DOI 10.1109/83.465112
   ALGAZI VR, 1975, IEEE T CIRCUITS SYST, V22, P943, DOI 10.1109/TCS.1975.1084002
   [Anonymous], 1998, Wavelet Analysis: the Scalable Structure of Information
   [Anonymous], 2008, A wavelet tour of signal processing: The sparse way
   ARSENAULT HH, 1981, J OPT SOC AM, V71, P91, DOI 10.1364/JOSA.71.000091
   Bruce A, 1996, IEEE SPECTRUM, V33, P26, DOI 10.1109/6.540087
   CASTELMAN KR, 1996, DIGITAL IMAGE PROCES
   Chen B, 1999, IMAGE VISION COMPUT, V17, P913, DOI 10.1016/S0262-8856(98)00165-6
   Chui C. K., 1992, An Introduction to Wavelets, DOI 10.2307/2153134
   COIFMANN RR, 1995, TRANSLATION INVARIAN
   COLLIS WB, UNPUB SYNTHETISING F
   DEST, 2000, P 5 IMA C SIGN PROC
   Devaux JC, 2001, OPT ENG, V40, P1302, DOI 10.1117/1.1385166
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301
   DUTTILLEUX P, 1989, WAVELET TIME FREQUEN, P298
   EGIAZARIAN K, 2001, IEEE P, V3, P1869
   EGIAZARIAN K, 2000, P SOC PHOTO-OPT INS, V4170, P13
   ESTEFANO A, 2000, ICIP IEEE C VANC, P2000
   ESTEFANO A, 2000, THESIS ISVR U SOUTHA
   FALCONER DG, 1970, OPT ACTA, V17, P693, DOI 10.1080/713818360
   Fischer M, 2002, IEEE T IMAGE PROCESS, V11, P717, DOI [10.1109/TIP.2002.800893, 10.1109/TIP2002.800893]
   FISCHER M, 2000, P 10 EUR SIGN PROC C, V1, P1
   Fligge M, 1997, ASTRON ASTROPHYS SUP, V124, P579, DOI 10.1051/aas:1997208
   HENTEA TA, 1984, IEEE T SYST MAN CYB, V14, P230, DOI 10.1109/TSMC.1984.6313206
   HUNT BR, 1975, P IEEE, V63, P693, DOI 10.1109/PROC.1975.9801
   HUNT BR, 1977, IEEE T COMPUT, V26, P219, DOI 10.1109/TC.1977.1674810
   Jansen M, 1999, P SOC PHOTO-OPT INS, V3813, P580, DOI 10.1117/12.366813
   KASTURI R, 1984, P 7 C PATT REC, V1, P148
   Kaufmann GH, 1996, OPT ENG, V35, P9, DOI 10.1117/1.600874
   KINGSBURY N, 2000, IEE C, P1
   Kouassi R, 2001, SIGNAL PROCESS-IMAGE, V16, P541, DOI 10.1016/S0923-5965(00)00035-7
   Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432
   Lina JM, 1997, P SOC PHOTO-OPT INS, V3169, P67, DOI 10.1117/12.279680
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MCLEAN I, 2001, IEEE SEM, V2, P1
   Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332
   NADERI F, 1978, APPL OPTICS, V17, P1228, DOI 10.1364/AO.17.001228
   Öktem R, 1999, ELECTRON LETT, V35, P1830, DOI 10.1049/el:19991261
   OKTEM R, 2001, IEEE P, V4, P2063
   OKTEM R, 1998, SIGNAL IMGE DENOISIN
   PESS WH, 1988, NUMERICAL RECIPES C
   SCHUMAKER LL, 1994, RECENT DV WAVELET AN
   SHARMA A, 2001, DIGITAL PHOTO TECHNI, P62
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Soon IY, 1998, SPEECH COMMUN, V24, P249, DOI 10.1016/S0167-6393(98)00019-3
   Starck JL, 1998, PUBL ASTRON SOC PAC, V110, P193, DOI 10.1086/316124
   STRANG G, 1996, WAVELET FILTER BANKS
   TAVILDAR AS, 1985, SIGNAL PROCESS, V8, P363, DOI 10.1016/0165-1684(85)90112-4
   TAVILDAR AS, 1984, SIGNAL PROCESS, V6, P225
   Uenohara M, 1998, IEEE T IMAGE PROCESS, V7, P116, DOI 10.1109/83.650856
   VANROOSMALEN PMB, 1996, IEEE INT C IM PROC, V1, P375
   WEI D, 1995, IEEE T IMAGE PROCESS, V1, P610
   XU YS, 1994, IEEE T IMAGE PROCESS, V3, P747, DOI 10.1109/83.336245
NR 56
TC 3
Z9 3
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2004
VL 22
IS 11
BP 873
EP 882
DI 10.1016/j.imavis.2004.04.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 847MJ
UT WOS:000223396600002
DA 2024-07-18
ER

PT J
AU Campbell, N
   Dalton, C
   Gibson, D
   Oziem, D
   Thomas, B
AF Campbell, N
   Dalton, C
   Gibson, D
   Oziem, D
   Thomas, B
TI Practical generation of video textures using the auto-regressive process
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE auto-reggressive process; video textures; principal component analysis;
   motion signatures; image-based rendering
AB Recently, there have been several attempts at creating 'video textures', that is, synthesising new (potentially infinitely long) video clips based on existing ones. One method for achieving this is to transform each frame of the video into an eigenspace using Principal Components Analysis so that the original sequence can be viewed as a signature through a low-dimensional space. A new sequence can be generated by moving through this space and creating 'similar' signatures. These signatures may be derived using an auto-regressive process (ARP). Such an ARP assumes that the signature has Gaussian statistics. For many sequences this assumption is valid, however, some sequences are strongly non-linearly correlated, in which case their statistical properties are non-Gaussian. We examine two methods by which such non-linearities may be overcome. The first is by modelling the non-linearity automatically using a spline, and the second using a combined appearance model. New video sequences created using these approaches contain images never present in the original sequence and appear very convincing, (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.
C3 University of Bristol
RP Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.
EM neill.campbell@briston.ac.uk
RI Gibson, David/HTQ-3690-2023
CR Bishop C.M., 1994, MIXTURE DENSITY NETW
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Blake A., 1998, ACTIVE CONTOURS
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Bowden Richard, 2000, IEEE WORKSH HUM MOD, V2000
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   DEVIN VE, 2001, BRIT MACH VIS C, P603
   Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584
   Gibson DP, 2000, INT C PATT RECOG, P881, DOI 10.1109/ICPR.2000.903684
   GIBSON DP, 1999, THESIS U BRISTOL
   HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936
   Ljung L, 1999, PRENTICE HALL INFORM, P503
   Reissell LM, 2001, COMPUT GRAPH FORUM, V20, pC339
   REYNARD D, 1996, P EUR C COMP VIS, V1, P357
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658
   ZEEVI A, 1996, P ADV NEUR INF PROC
NR 17
TC 6
Z9 8
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 819
EP 827
DI 10.1016/j.imavis.2004.02.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300009
DA 2024-07-18
ER

PT J
AU Van der Weken, D
   Nachtegael, M
   Kerre, EE
AF Van der Weken, D
   Nachtegael, M
   Kerre, EE
TI Using similarity measures and homogeneity for the comparison of images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fuzzy set theory; similarity measures; image analysis
ID FUZZY-SETS
AB Fuzzy techniques can be applied in several domains of image processing. In this paper, we will show how notions of fuzzy set theory are used in establishing measures for image comparison. Objective quality measures or measures of comparison are of great importance in the field of image processing. These measures serve as a tool to evaluate and to compare different algorithms designed to solve problems, such as noise reduction, deblurring, compression, etc. Consequently these measures serve as a basis on which one algorithm is preferred to another. It is well known that classical quality measures, such as the MSE (mean square error) or the PSNR (peak-signal-to-noise-ratio), do not always correspond to visual observations. Therefore, several researchers are-and have been-looking for new quality measures, better adapted to human perception.
   Van der Weken et al. [Proceedings of ICASSP'2002, Orlando, 2002] gave an overview of similarity measures, originally introduced to express the degree of comparison between two fuzzy sets, which can be applied to images. These similarity measures are all pixel-based, and have therefore not always satisfactory results. To cope with this drawback, we propose similarity measures based on neighbourhoods, so that the relevant structures of the images are observed better. In this way, 13 new similarity measures were found to be appropriate for the comparison of images. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Ghent, Dept Appl Math & Comp Sci, Fuzziness & Uncertainty Modelling Res Unit, B-9000 Ghent, Belgium.
C3 Ghent University
RP Univ Ghent, Dept Appl Math & Comp Sci, Fuzziness & Uncertainty Modelling Res Unit, Krijgslaan 281,Blds S9, B-9000 Ghent, Belgium.
EM dietrich.vanderweken@ugent.be; mike.nachtegael@ugent.be;
   etienne.kerre@ugent.be
CR CHEN SM, 1995, FUZZY SET SYST, V72, P79, DOI 10.1016/0165-0114(94)00284-E
   CHEN SM, 1995, FUZZY SET SYST, V74, P217, DOI 10.1016/0165-0114(94)00339-9
   DEBAETS B, 2002, P EUSFLAT 2002 2 C E, P249
   Dubois D, 1980, Fuzzy sets and systems
   Fan JL, 1999, FUZZY SET SYST, V101, P403, DOI 10.1016/S0165-0114(97)00108-5
   KULLBACK S, 1959, INFORMATION THEORY S
   LIU XC, 1992, FUZZY SET SYST, V52, P305, DOI 10.1016/0165-0114(92)90239-Z
   PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4
   Van der Weken D, 2002, INT CONF ACOUST SPEE, P3317
   VANDERWEKEN D, 2001, INTELLECTUAL SYSTEMS, V6, P231
   VANDERWEKEN D, 2002, SIMILARITY MEASURES
   Wang WJ, 1997, FUZZY SET SYST, V85, P305, DOI 10.1016/0165-0114(95)00365-7
   WANG XZ, 1995, FUZZY SET SYST, V73, P259, DOI 10.1016/0165-0114(94)00308-T
NR 13
TC 82
Z9 90
U1 4
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 20
PY 2004
VL 22
IS 9
BP 695
EP 702
DI 10.1016/j.imavis.2004.03.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 834WE
UT WOS:000222440800002
DA 2024-07-18
ER

PT J
AU Tai, JC
   Tseng, ST
   Lin, CP
   Song, KT
AF Tai, JC
   Tseng, ST
   Lin, CP
   Song, KT
TI Real-time image tracking for automatic traffic monitoring and
   enforcement applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image tracking; active contour model; traffic monitoring
AB This paper presents an image tracking system and its applications for traffic monitoring and accident detection at road intersections. Locations of motorcycles as well as automobiles are obtained in real time using the active contour model approach. Image measurement is further incorporated with Kalman filtering techniques to track individual vehicle motion. To initialize image tracking of vehicles at a junction, we propose a contour initialization method based on the concept of contour growing. Using a specially designed circuit board, a stand-alone image tracker has been designed and created for automatic traffic monitoring. We successfully achieved real-time image tracking of multi-lane vehicles. Interesting experimental results are presented to demonstrate the effectiveness of the proposed system. (C) 2003 Elsevier B.V. All rights reserved.
C1 Natl Tsing Hua Univ, Dept Elect & Control Engn, Hsinchu 300, Taiwan.
C3 National Tsing Hua University
RP Natl Tsing Hua Univ, Dept Elect & Control Engn, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM tjc.ece88g@nctu.edu.tw
CR Baumberg A. M., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P194, DOI 10.1109/MNRAO.1994.346236
   Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371
   Blake A., 1998, ACTIVE CONTOURS
   Cucchiara R., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P119, DOI 10.1109/6979.880969
   Cucchiara R, 1999, IEE CONF PUBL, P138, DOI 10.1049/cp:19990297
   Ferrier N. J., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P81, DOI 10.1109/ACV.1994.341292
   Iannizzotto G, 2000, IEEE IMAGE PROC, P316, DOI 10.1109/ICIP.2000.900958
   Ikeda T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P859, DOI 10.1109/ICPR.1996.547290
   Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968
   KASS M, 1988, INT J COMPUT VISION, V3, P163
   Kilger M., 1992, Proceedings. IEEE Workshop on Applications of Computer Vision (Cat. No.92TH0446-5), P11, DOI 10.1109/ACV.1992.240332
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   Lim DW, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P126, DOI 10.1109/IAI.2002.999903
   Lin CP, 2003, IEEE INT CONF ROBOT, P2091, DOI 10.1109/ROBOT.2003.1241902
   Mikic I, 2000, INT C PATT RECOG, P321, DOI 10.1109/ICPR.2000.905341
   Ninomiya Y., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P315, DOI 10.1109/IVS.1995.528300
   Seki M, 2003, PROC CVPR IEEE, P65
   SONG KT, 1999, J CHINESE FUZZY SYST, V5, P43
   Terzopoulos D., 1992, TRACKING KALMAN SNAK, P3
   Torres-Huitzil C, 2000, 5TH INTERNATIONAL WORKSHOP ON COMPUTER ARCHITECTURES FOR MACHINE PERCEPTION, PROCEEDINGS, P112, DOI 10.1109/CAMP.2000.875965
   Tseng ST, 2002, IEEE 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P1, DOI 10.1109/ITSC.2002.1041179
   VIEREN C, 1995, PATTERN RECOGN LETT, V16, P679, DOI 10.1016/0167-8655(95)00019-D
   Won Kim, 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P216, DOI 10.1109/IROS.1999.813007
   [No title captured]
NR 24
TC 74
Z9 93
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2004
VL 22
IS 6
BP 485
EP 501
DI 10.1016/j.imavis.2003.12.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 817HB
UT WOS:000221167500005
DA 2024-07-18
ER

PT J
AU Kokaram, A
AF Kokaram, A
TI A statistical framework for picture reconstruction using 2D AR models
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Statistical Methods in Video Processing
CY JUN 01-02, 2002
CL COPENHAGEN, DENMARK
DE video reconstruction; statistical interpolation; texture synthesis;
   image reconstruction; image restoration; filling in; Gibbs sampling;
   Bayesian inference; 2D autoregressive models
AB This paper presents a framework for 'Filling In' missing gaps in images and particularly patches with texture. The algorithm can also be used as a fallback mode in treating missing data for video sequence reconstruction. The underlying idea is to construct a parametric model of the p.d.f. of the texture to be re-synthesised and then draw samples from that p.d.f. to create the resulting reconstruction. A Bayesian approach is used to articulate 2D Autoregressive Models as generative models for texture (using the Gibbs sampler) given surrounding boundary conditions. A fast implementation is presented that iterates between pixelwise updates and blockwise parametric model estimation. The novel ideas in this paper are joint parameter estimation and fast, efficient texture reconstruction using linear models. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Dublin Trinity Coll, Dept Elect & Elect Engn, Dublin 2, Ireland.
C3 Trinity College Dublin
RP Kokaram, A (corresponding author), Univ Dublin Trinity Coll, Dept Elect & Elect Engn, Dublin 2, Ireland.
EM anil.kokaram@tcd.ie
OI Kokaram, Anil/0000-0001-5304-6238
CR BERTALIMIO M, 2000, P SIGGRAPH
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Heeger DJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC648
   HIRANI AN, 1996, P SIGGRAPH 96, P269
   Kokaram A., 1998, Motion Picture Restoration
   KOKARAM AC, 1996, SIGNAL PROCESS, V1, P5
   RUANAIDH JJO, 1996, SPRINGER SERIES STAT
   STROHMER T, 1977, IEEE IMAGE PROCESSIN, P540
NR 8
TC 23
Z9 23
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2004
VL 22
IS 2
BP 165
EP 171
DI 10.1016/j.imavis.2003.07.010
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 769DW
UT WOS:000188612000009
DA 2024-07-18
ER

PT J
AU Hsieh, JW
   Hu, WF
   Chang, CJ
   Chen, YS
AF Hsieh, JW
   Hu, WF
   Chang, CJ
   Chen, YS
TI Shadow elimination for effective moving object detection by Gaussian
   shadow modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gaussian shadow modeling; moment analysis; shadow elimination; object
   segmentation
ID TRACKING
AB This paper presents a novel approach for eliminating unexpected shadows from multiple pedestrians from a static and textured background using Gaussian shadow modeling. First, a set of moving regions are segmented from the static background using a background subtraction technique. The extracted moving region may contain multiple shadows from various pedestrians. In order to remove these unwanted shadows completely, a histogram-based method is proposed for isolating each pedestrian from the extracted moving region. Based on the results, a coarse-to-fine shadow modeling process is then applied for eliminating the unwanted shadow from the detected pedestrian. At the coarse stage, a moment-based method is first used for obtaining the rough shadow boundaries. Then, the rough approximation of the shadow region can be further refined through Gaussian shadow modeling. The chosen shadow model is parameterized with several features including the orientation, mean intensity, and center position of a shadow region. With these features, the chosen model can precisely model different shadows at different conditions and provide good capabilities for completely eliminating the unexpected shadows from the scene background. Due to the simplicity of the proposed method, all the shadows can be eliminated immediately (in less than 0.5 s). Experiments demonstrate that approximately 94% of shadows can be successfully eliminated from the scene background. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Yuan Ze Univ, Dept Elect Engn, Chungli 320, Taiwan.
C3 Yuan Ze University
RP Yuan Ze Univ, Dept Elect Engn, 135 Yuan Tung Rd, Chungli 320, Taiwan.
EM shieh@saturn.yzu.edu.tw
CR Chang CC, 2001, IEEE T CIRC SYST VID, V11, P9, DOI 10.1109/76.894279
   Cheng HH, 2001, IEEE-ASME T MECH, V6, P170, DOI 10.1109/3516.928732
   DENIEL GP, 2001, IEEE T CIRCUITS SYST, V11, P788
   Haritaoglu I., 1998, P INT C AUTOMATIC FA, P1
   Hu Z, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P233, DOI 10.1109/IVS.2000.898347
   Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263
   Nadimi S, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1048398
   Naito T, 2000, IEEE T VEH TECHNOL, V49, P2309, DOI 10.1109/25.901900
   Onoguchi E, 1998, INT C PATT RECOG, P583, DOI 10.1109/ICPR.1998.711210
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172
   Tao XP, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT PROCESSING SYSTEMS, VOLS 1 & 2, P1302, DOI 10.1109/ICIPS.1997.669208
   TOYAMA K, 1999, IEEE INT C COMP VIS, P199
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 15
TC 107
Z9 136
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2003
VL 21
IS 6
BP 505
EP 516
DI 10.1016/S0262-8856(03)00030-1
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 688BA
UT WOS:000183411300004
DA 2024-07-18
ER

PT J
AU Kastrinaki, V
   Zervakis, M
   Kalaitzakis, K
AF Kastrinaki, V
   Zervakis, M
   Kalaitzakis, K
TI A survey of video processing techniques for traffic applications
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE traffic monitoring; automatic vehicle guidance; automatic lane finding;
   object detection; dynamic scene analysis
ID IMAGE SEQUENCES; OBSTACLE DETECTION; VEHICLE DETECTION; OBJECT
   DETECTION; MOVING-OBJECTS; MACHINE VISION; TRACKING; ROAD; MODEL;
   RECOGNITION
AB Video sensors become particularly important in traffic applications mainly due to their fast response. easy installation. operation and maintenance, and their ability to monitor wide areas. Research in several fields of traffic applications has resulted in a wealth of video processing and analysis methods. Two of the most demanding and widely studied applications relate to traffic monitoring and automatic vehicle guidance. In general. systems developed for these areas must integrate. amongst then, other tasks, the analysis of their static environment (automatic lane finding) and the detection of static or moving obstacles (object detection) within their space of interest. In this paper we present an overview of image processing and analysis tools used in these applications and we relate these tools with complete systems developed for specific traffic applications. More specifically. we categorize processing methods based on the intrinsic organization of their input data (feature-driven, area-driven. or model-based) and the domain of processing (spatial/franic or temporal/video). Furthermore. we discriminate between the cases of static and mobile camera. Based on this categorization of processing tools, we present representative systems that have been deployed for operation. Thus. the purpose of the paper is threefold. First. to classify image-processing methods used in traffic applications. Second, to provide the advantages and disadvantages of these algorithms. Third, from this integrated consideration, to attempt an evaluation of shortcomings and general needs in this field of active research. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Tech Univ Crete, Dept Elect & Comp Engn, Digital Image & Signal Proc Lab, Khania 73100, Greece.
C3 Technical University of Crete
RP Tech Univ Crete, Dept Elect & Comp Engn, Digital Image & Signal Proc Lab, Khania 73100, Greece.
EM michalis@systems.tuc.gr
OI Kalaitzakis, Kostas/0000-0001-7589-2240
CR AACH T, 1995, SIGNAL PROCESS-IMAGE, V7, P147, DOI 10.1016/0923-5965(95)00003-F
   [Anonymous], IEEE T ROBOTICS AUTO
   [Anonymous], P INT C INT AUT SYST
   Badenas J, 2001, PATTERN ANAL APPL, V4, P28, DOI 10.1007/s100440170022
   Badenas J, 2001, PATTERN RECOGN, V34, P661, DOI 10.1016/S0031-3203(00)00014-5
   Beauvais M, 2000, IMAGE VISION COMPUT, V18, P397, DOI 10.1016/S0262-8856(99)00035-9
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   Bertozzi M, 1997, J SYST ARCHITECT, V43, P317, DOI 10.1016/S1383-7621(96)00106-3
   BERTOZZI M, 1997, COMPUTER VISION, V30
   Betke M, 2000, MACH VISION APPL, V12, P69, DOI 10.1007/s001380050126
   Beucher S., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), P296, DOI 10.1109/IVS.1994.639531
   BLOSSEVILLE JM, 1994, IFAC TRANSPORTATION
   Broggi A, 1995, J ARTIF INTELL RES, V3, P325, DOI 10.1613/jair.185
   BROGGI A, 1995, IEEE T IMAGE PROCESS, V4, P217, DOI 10.1109/83.342193
   BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7
   Buluswar SD, 1998, ENG APPL ARTIF INTEL, V11, P245, DOI 10.1016/S0952-1976(97)00079-1
   BURT PJ, 1988, P IEEE, V76, P1006, DOI 10.1109/5.5971
   CARLSSON S, 1990, LECT NOTES COMPUT SC, V427, P297, DOI 10.1007/BFb0014876
   Chavand F, 1997, IEEE T INSTRUM MEAS, V46, P1229, DOI 10.1109/19.668259
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Coombs D, 1998, IEEE T ROBOTIC AUTOM, V14, P49, DOI 10.1109/70.660840
   CRISMAN JD, 1993, IEEE T ROBOTICS AUTO, V9
   DICKINSON KW, 1989, IEE CONF PUBL, V299, P56
   Dickmanns E., 1990, IEEE T SYST MAN CYB, V20
   DICKMANNS ED, 1992, IEEE T PATTERN ANAL, V14, P199, DOI 10.1109/34.121789
   DICKMANNS ED, CONCISE ENCY TRAFFIC
   DICKMANNS ED, 1988, MACH VISION APPL, V1, P223
   DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8
   DUBUISSON MP, 1995, INT J COMPUT VISION, V14, P83, DOI 10.1007/BF01421490
   ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X
   Enkelmann W., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P356, DOI 10.1109/IVS.1995.528307
   ENKELMANN W, 1990, LECT NOTES COMPUT SC, V427, P134, DOI 10.1007/BFb0014859
   ENKELMANN W, 1987, MOTION UNDERSTANDING, P189
   Enkelmann W., 1989, IFAC Control, Computers, Communications in Transportation
   Fathy M, 1995, PATTERN RECOGN LETT, V16, P1321, DOI 10.1016/0167-8655(95)00081-X
   FATHY M, 1998, IEEE T VEHICULAR TEC, V47
   Foresti GL, 1999, IEEE T VEH TECHNOL, V48, P301, DOI 10.1109/25.740109
   FORESTI GL, 1994, IEEE T VEHICULAR TEC, V43
   Fraile R., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P697
   Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006
   GIACHETTI A, 1998, IEEE T ROBOTICS AUTO, V14
   GLOYER B, 1995, P IS T SPIE S EL IM
   GOTO Y, 1986, P 1 JOINT C ACM IEEE
   Handmann U, 2000, IMAGE VISION COMPUT, V18, P367, DOI 10.1016/S0262-8856(99)00032-3
   HOGG DC, 1984, IEE P INT C ROAD TRA, P115
   Hoose N., 1991, COMPUTER IMAGE PROCE
   HOOSE N, 1994, IFAC TRANSPORTATION
   Hoose N., 1992, TRAFFIC ENG CONTROL, P140
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   HOUGHTON AD, 1989, IEE CONF PUBL, V299, P71
   Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105
   Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770
   JAIN A, 1992, PATTERN RECOGN LETT, V13, P41, DOI 10.1016/0167-8655(92)90113-E
   JUNG YK, 2001, PCM 2001, P190
   Kasprzak W., 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P725
   Kato S, 2001, JSAE REV, V22, P503, DOI 10.1016/S0389-4304(01)00137-0
   KEHTARNAVAZ N, 1991, IEEE T VEH TECHNOL, V40, P654, DOI 10.1109/25.97520
   KENUE SK, 1991, P SOC PHOTO-OPT INS, V1388, P222, DOI 10.1117/12.48089
   Kim J.B., 2001, Proc. Austral. Joint Conf. Artif. Intell, P213, DOI [10.1007/3-540-45656-219, DOI 10.1007/3-540-45656-219]
   Klausmann P, 1999, PATTERN RECOGN, V32, P2063, DOI 10.1016/S0031-3203(99)00121-1
   Kluge K., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), P109, DOI 10.1109/IVS.1994.639482
   Kluge K., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P488, DOI 10.1109/IVS.1995.528330
   KLUGE K, 1995, IEEE P INTELLIGENT V, V95, P54
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   KORIES R, 1984, P INT JOINT C PATT R, P778
   KORIES R, 1986, WORKSHOP MOTION REPR, P101
   KUEHNLE A, 1991, PATTERN RECOGN LETT, V12, P249, DOI 10.1016/0167-8655(91)90039-O
   LEBLANC DJ, 1996, IEEE CONTROL SYS DEC
   Lee KW, 1998, ELECTRON LETT, V34, P256, DOI 10.1049/el:19980176
   Li XB, 2002, PATTERN RECOGN, V35, P967, DOI 10.1016/S0031-3203(01)00079-6
   LUONG QT, 1995, P INT C COMP VIS ICC, P12
   MAGEE MJ, 1985, IEEE T PATTERN ANAL, V7, P629, DOI 10.1109/TPAMI.1985.4767719
   MALLOT HA, 1991, BIOL CYBERN, V64, P177, DOI 10.1007/BF00201978
   MAMMAR S, 1994, IFAC TRANSPORTATION
   MANTRI S, 1995, TRANSPORT RES C-EMER, V3, P161, DOI 10.1016/0968-090X(95)00004-3
   MATTHIES L, 1992, INT J COMPUT VISION, V8, P71, DOI 10.1007/BF00126401
   Michalopoulos P. G., 1991, IEEE T VEHICULAR TEC, V40
   MICHALOPOULOS PG, 1993, TRAFFIC ENG CONT FEB, P66
   MICHALOPOULOS PG, 1997, IFAC TRANSPORTATION
   Moon H, 2002, IMAGE VISION COMPUT, V20, P1, DOI 10.1016/S0262-8856(01)00059-2
   MORGENTHALER DG, 1990, IEEE T SYST MAN CYB, V20, P1301, DOI 10.1109/21.61202
   Nagai A., 1999, Systems and Computers in Japan, V30, P107, DOI 10.1002/(SICI)1520-684X(199910)30:11<107::AID-SCJ12>3.0.CO;2-C
   Nagel H.-H., 1983, P IJCAI, P945
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833
   Nagel HH, 2000, IMAGE VISION COMPUT, V18, P435, DOI 10.1016/S0262-8856(99)00038-4
   NOORALAHIYAN AY, 1998, MATH COMPUTER MODELI, V27
   PAPAGEORGIOU M, CONCISE ENCY TRAFFIC, P610
   Paragios N, 1999, SIGNAL PROCESS-IMAGE, V14, P277, DOI 10.1016/S0923-5965(98)00011-3
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Park Y, 2001, PATTERN RECOGN LETT, V22, P883, DOI 10.1016/S0167-8655(01)00034-4
   Pomerleau D., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P506, DOI 10.1109/IVS.1995.528333
   Pomerleau D, 1996, IEEE EXPERT, V11, P19, DOI 10.1109/64.491277
   Pomerleau DA., 1989, ADV NEURAL INFORM PR, V1, P305
   POSTAIRE JG, 1986, IFAC TRANSP S INT FE
   Ross B., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P148, DOI 10.1109/CVPR.1993.340996
   Rourke A., 1989, P WORLD C TRANSP RES, P169
   Sandakly F, 1997, ROBOT AUTON SYST, V21, P399, DOI 10.1016/S0921-8890(97)00029-8
   Schick J., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P256, DOI 10.1109/WVM.1991.212799
   SCHODEL H, 1994, FUZZY SET SYST, V63, P271, DOI 10.1016/0165-0114(94)90215-1
   SHIMIZU K, 1989, IEE CONF PUBL, V299, P61
   SHLADOVER SE, 1991, IEEE T VEH TECHNOL, V40, P114, DOI 10.1109/25.69979
   SMITH SM, 1994, ENG APPL ARTIF INTEL, V7, P191, DOI 10.1016/0952-1976(94)90023-X
   SOUMELIDIS A, 1997, IFAC TRANSPORTATION
   STEWART BD, 1994, P 7 INT C ROAD TRAFF
   Sullivan GD, 1997, IMAGE VISION COMPUT, V15, P649, DOI 10.1016/S0262-8856(97)00009-7
   TAKABA S, 1984, P IEE C ROAD TRAFF D
   Tan TN, 1998, INT J COMPUT VISION, V27, P5, DOI 10.1023/A:1007924428535
   TAYLOR CJ, 1997, IFAC TRANSPORTATION
   TECHMER A, 2001, DAGM 2001, P202
   Thomanek F., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), P231, DOI 10.1109/IVS.1994.639510
   THORPE C, 1988, IEEE T PATTERN ANAL, V10, P362, DOI 10.1109/34.3900
   TRIVEDI MM, 1990, IEEE T SYST MAN CYB, V20, P1285, DOI 10.1109/21.61201
   TSUGAWA S, 1994, IEEE T IND ELECTRON, V41, P398, DOI 10.1109/41.303790
   TURK MA, 1988, IEEE T PATTERN ANAL, V10, P342, DOI 10.1109/34.3899
   VELASTIN SA, 1994, IFAC TRANSPORTATION
   WAN CL, 1994, IFAC TRANSPORTATION
   WAN CL, 1989, IFAC CONTROL COMPUTE
   WANG Y, 1994, PATTERN RECOGN, V21, P677
   Weber J., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P530, DOI 10.1109/IVS.1995.528337
   Wöhler C, 2001, IMAGE VISION COMPUT, V19, P593, DOI 10.1016/S0262-8856(01)00040-3
   WON Y, 2001, SSPR SPR 2000, P806
   Wu YG, 1996, ARTIF INTELL ENG, V10, P323, DOI 10.1016/0954-1810(96)00009-X
   XIE M, 1994, MACH VISION APPL, V7, P165, DOI 10.1007/BF01211661
   YU X, 1992, P IEEE INTELLIGENT V, V92, P166
   Yuille AL, 2000, IEEE T PATTERN ANAL, V22, P160, DOI 10.1109/34.825754
   ZHANG J, 1994, P IEEE S INT VEH 94
   ZHENG QF, 1995, INT J COMPUT VISION, V15, P31, DOI 10.1007/BF01450849
   Zhu ZG, 2000, IMAGE VISION COMPUT, V18, P781, DOI 10.1016/S0262-8856(99)00046-3
NR 128
TC 304
Z9 425
U1 2
U2 86
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2003
VL 21
IS 4
BP 359
EP 381
DI 10.1016/S0262-8856(03)00004-0
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 669PH
UT WOS:000182359300004
DA 2024-07-18
ER

PT J
AU Tognola, G
   Parazzini, M
   Svelto, C
   Ravazzani, P
   Grandori, F
AF Tognola, G
   Parazzini, M
   Svelto, C
   Ravazzani, P
   Grandori, F
TI A fast and reliable system for 3D surface acquisition and reconstruction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D Laser scanner; surface reconstruction; unorganized data; geometrical
   deformable model
AB A prototype 3D scanning system is presented together with a novel surface reconstruction algorithm to obtain an explicit 3D reconstruction of both open and closed surfaces, with particular attention to anatomical parts for biomedical applications. The whole system is based on acquisition of unorganized range data by laser scanning and successive image processing, by expanding and fitting a regular geometrical model within the range data, for surface reconstruction. The prototype system proved to be working finely, with an estimated resolution < 10 mu m, a repeatability < 50 mum, and an acquisition noise of similar to 170 mum (rms value). Simulations with a synthetic test surface are described to provide quantitative figures on the robustness to noise of the proposed reconstruction algorithm. Reconstruction of 3D models of human organs are presented as well. (C) 2003 Published by Elsevier Science B.V.
C1 Politecn Milan, CNR, Inst Biomed Engn, I-20133 Milan, Italy.
   Politecn Milan, INFM, Dept Elect & Informat, I-20133 Milan, Italy.
   CNR, IEIIT, I-20133 Milan, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Polytechnic University of
   Milan; Polytechnic University of Milan; Consiglio Nazionale delle
   Ricerche (CNR); Istituto Nazionale per la Fisica della Materia
   (INFM-CNR); Consiglio Nazionale delle Ricerche (CNR); Istituto di
   Elettronica e di Ingegneria dell'Informazione e delle Telecomunicazioni
   (IEIIT-CNR)
RP Politecn Milan, CNR, Inst Biomed Engn, Piazza Leonardo da Vinci 32, I-20133 Milan, Italy.
EM gabriella.tognola@polimi.it
RI Tognola, Gabriella/AAW-5316-2020; Parazzini, Marta/J-8175-2014; Tognola,
   Gabriella/GNH-3487-2022; Tognola, Gabriella/B-9025-2015; Ravazzani,
   Paolo/B-9139-2015
OI Parazzini, Marta/0000-0001-9008-7530; Tognola,
   Gabriella/0000-0002-2433-449X; Ravazzani, Paolo/0000-0003-0282-3329
CR BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Bulpitt AJ, 1996, IMAGE VISION COMPUT, V14, P573, DOI 10.1016/0262-8856(96)01102-X
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cignoni P, 1998, COMPUT GRAPH-UK, V22, P37, DOI 10.1016/S0097-8493(97)00082-4
   Josefsson T, 1996, COMPUT METH PROG BIO, V49, P119, DOI 10.1016/0169-2607(96)01715-4
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   MILLER JV, 1991, COMP GRAPH, V25, P217, DOI 10.1145/127719.122742
   Montagnat J, 2001, IMAGE VISION COMPUT, V19, P1023, DOI 10.1016/S0262-8856(01)00064-6
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660
   Shen J, 1998, GRAPH MODEL IM PROC, V60, P461, DOI 10.1006/gmip.1998.0484
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659
   Tognola G, 2001, P ANN INT IEEE EMBS, V23, P2534, DOI 10.1109/IEMBS.2001.1017295
   Tognola G, 2002, IEEE IMTC P, P171, DOI 10.1109/IMTC.2002.1006835
   WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L
NR 18
TC 16
Z9 18
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2003
VL 21
IS 3
BP 295
EP 305
AR PII S0262-8856(02)00160-9
DI 10.1016/S0262-8856(02)00160-9
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657GN
UT WOS:000181658100006
DA 2024-07-18
ER

PT J
AU Traver, VJ
   Pla, F
AF Traver, VJ
   Pla, F
TI Dealing with 2D translation estimation in log-polar imagery
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE log-polar mapping; active vision; motion estimation; steepest descent;
   projections
ID BINOCULAR TRACKING; VISION; PERCEPTION; MOTION
AB Log-polar mapping has been proposed as a very appropriate space-variant imaging model in active vision applications. This biologically inspired model has several advantages, and facilitates some visual tasks. For example, it provides an efficient data reduction, and simplifies rotational and scaling image transformations. However, simple translations become a difficult transform due to the log-polar geometry. There is no doubt about the importance of translation estimation in active visual tracking. Therefore, in this work, the problem of translation estimation in log-polar images is tackled. Two different approaches are presented, and their performances are evaluated and compared. One approach uses a gradient descent for minimizing a dissimilarity measure, while the other converts the 2D problem into two simpler 1D problems, by using projections. As the experimental results reveal, this second approach, besides being more efficient, can deal with larger translations than the gradient-based search can. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Comp Vis Grp, E-12080 Castellon de La Plana, Spain.
C3 Universitat Jaume I
RP Traver, VJ (corresponding author), Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Comp Vis Grp, Campus Riu Sec, E-12080 Castellon de La Plana, Spain.
EM vtraver@uji.es
RI Pla, Filiberto/AAD-1208-2022; Traver, V. Javier/F-8865-2016
OI Pla, Filiberto/0000-0003-0054-3489; Traver, V.
   Javier/0000-0002-1596-8466
CR Ahrns I., 1998, P ART INT, P89
   Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571
   [Anonymous], 1998, HDB MATH COMPUTATION
   BALSI M, 1997, EUR C CIRC THEOR DES
   Bernardino A, 1998, ROBOT AUTON SYST, V25, P137, DOI 10.1016/S0921-8890(98)00043-8
   Bernardino A, 1999, IEEE T ROBOTIC AUTOM, V15, P1080, DOI 10.1109/70.817671
   BERNARDINO A, 2000, S INT ROB SYST READ
   Bolduc M, 1998, COMPUT VIS IMAGE UND, V69, P170, DOI 10.1006/cviu.1997.0560
   Boluda JA, 1996, ICECS 96 - PROCEEDINGS OF THE THIRD IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS, AND SYSTEMS, VOLS 1 AND 2, P680, DOI 10.1109/ICECS.1996.584453
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Capurro C, 1997, INT J COMPUT VISION, V24, P79, DOI 10.1023/A:1007974208880
   DANIILIDIS K, 1996, COMP SUPPL, V11, P1
   DANIILIDIS K, 1995, INT C COMP AN IM PAT, P65
   Dias J, 1997, REAL-TIME IMAGING, V3, P213, DOI 10.1006/rtim.1996.0053
   Giachetti A, 2000, IMAGE VISION COMPUT, V18, P247, DOI 10.1016/S0262-8856(99)00018-9
   HODGSON RM, 1995, INT C IM PROC ITS AP, P11
   Jurie F, 1999, PATTERN RECOGN, V32, P865, DOI 10.1016/S0031-3203(98)00096-X
   KRUGER V, 1995, THESIS I INFORMATIK
   LIM FL, 1996, INT C PATT REC ICPR, P745
   LIN T, 1994, VISION INTERFACE, V6, P73
   Lucchese L, 2001, COMPUT VIS IMAGE UND, V81, P72, DOI 10.1006/cviu.2000.0885
   MIKRUT Z, 1999, 4 C NEUR NETW THEIR
   OKAJIMA N, 2000, 17 SENS S KAW JAP
   Oshiro N, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P791, DOI 10.1109/IROS.1996.571053
   PANERAI F, 1995, TR195 LIRA DIST U GE
   PETERS RA, 1996, COMPUTATION LOG POLA
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Rao S.S., 1984, OPTIMIZATION THEORY
   SANDINI G, 2000, P 1 IEEE SAM WORKSH
   SCHWARTZ EL, 1977, BIOL CYBERN, V25, P181, DOI 10.1007/BF01885636
   SHAH S, 1993, TRCIM9318 MCGILL U
   TONG F, 1995, IEEE T PATTERN ANAL, V17, P500, DOI 10.1109/34.391393
   Traver V. J., 2001, SPAN S PATT REC IM A, V2, P281
   Tunley H., 1994, BRIT MACH VIS C, V2, P579
   Weiman C. F., 1989, SPIE, P843
   Yamamoto H, 1996, COMPUT VIS IMAGE UND, V63, P50, DOI 10.1006/cviu.1996.0004
NR 36
TC 17
Z9 20
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 10
PY 2003
VL 21
IS 2
BP 145
EP 160
AR PII S0262-8856(02)00150-6
DI 10.1016/S0262-8856(02)00150-6
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 655CP
UT WOS:000181534000002
DA 2024-07-18
ER

PT J
AU Vareto, RH
   Yu, LH
   Boult, TE
   Schwartz, WR
   Günther, M
AF Vareto, Rafael Henrique
   Yu, Linghu
   Boult, Terrance Edward
   Schwartz, William Robson
   Gunther, Manuel
TI Open-set face recognition with maximal entropy and Objectosphere loss
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Neural networks; Biometrics; Classification; Face recognition; Open
   -set; Watchlist
AB Open-set face recognition characterizes a scenario where unknown individuals, unseen during the training and enrollment stages, appear on operation time. This work concentrates on watchlists, an open-set task that is expected to operate at a low false-positive identification rate and generally includes only a few enrollment samples per identity. We introduce a compact adapter network that benefits from additional negative face images when combined with distinct cost functions, such as Objectosphere Loss (OS) and the proposed Maximal Entropy Loss (MEL). MEL modifies the traditional Cross-Entropy loss in favor of increasing the entropy for negative samples and attaches a penalty to known target classes in pursuance of gallery specialization. The proposed approach adopts pre-trained deep neural networks (DNNs) for face recognition as feature extractors. Then, the adapter network takes deep feature representations and acts as a substitute for the output layer of the pre-trained DNN in exchange for an agile domain adaptation. Promising results have been achieved following open-set protocols for three different datasets: LFW, IJB-C, and UCCS as well as state-of-the-art performance when supplementary negative data is properly selected to fine-tune the adapter network.
C1 [Vareto, Rafael Henrique; Schwartz, William Robson] Univ Fed Minas Gerais, Smart Sense Lab, Belo Horizonte, Brazil.
   [Vareto, Rafael Henrique; Yu, Linghu; Gunther, Manuel] Univ Zurich, Dept Informat, Zurich, Switzerland.
   [Boult, Terrance Edward; Gunther, Manuel] Univ Colorado Colorado Springs, Vis & Secur Technol Lab, Colorado Springs, CO USA.
C3 Universidade Federal de Minas Gerais; University of Zurich; University
   of Colorado System; University of Colorado at Colorado Springs
RP Vareto, RH (corresponding author), Univ Fed Minas Gerais, Smart Sense Lab, Belo Horizonte, Brazil.
EM rafaelvareto@dcc.ufmg.br; linghu@ifi.uzh.ch; tboult@vast.uccs.edu;
   william@dcc.ufmg.br; guenther@ifi.uzh.ch
OI Gunther, Manuel/0000-0003-1489-7448; Vareto, Rafael/0000-0002-0431-5945
FU Brazilian National Council for Scientific and Technological
   Development-CNPq [309953/2019-7, 203402/2020-0]; Minas Gerais Research
   Foundation-FAPEMIG [PPM-00540-17]; Federal University of Minas Gerais
   (UFMG); University of Zurich (UZH)
FX The authors would like to thank the Brazilian National Council for
   Scientific and Technological Development-CNPq (Grants 309953/2019-7 and
   203402/2020-0) , the Minas Gerais Research Foundation-FAPEMIG (Grant
   PPM-00540-17) , the Federal University of Minas Gerais (UFMG) and,
   especially, the University of Zurich (UZH) .
CR Anjos A., 2012, P 20 ACM C MULT SYST
   [Anonymous], 2011, Handbook of Face Recognition, Chapter Evaluation Methods in Face Recognition
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen JC, 2016, IEEE WINT CONF APPL
   Chowdhury Aruni Roy, 2016, WINT C APPL COMP VIS
   Cohen Paul R., 1997, INT WORKSH ART INT S
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dhamija AR, 2018, 32 C NEURAL INFORM P
   dos Santos CE, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P188, DOI 10.1109/SIBGRAPI.2014.23
   Grother Patrick, 2022, Technical report
   Günther M, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P697, DOI 10.1109/BTAS.2017.8272759
   Günther M, 2012, LECT NOTES COMPUT SC, V7585, P547, DOI 10.1007/978-3-642-33885-4_55
   Günther M, 2017, IEEE COMPUT SOC CONF, P573, DOI 10.1109/CVPRW.2017.85
   Gunther Manuel, 2020, INT C BIOM SPEC INT
   Hassen M, 2020, PROCEEDINGS OF THE 2020 SIAM INTERNATIONAL CONFERENCE ON DATA MINING (SDM), P154, DOI 10.1137/1.9781611976236.18
   Henrydoss James, 2020, INT C BIG DAT BIGDAT
   Hill Kashmir, 2020, Wrongfully Accused by an Algorithm
   Kim M, 2022, PROC CVPR IEEE, P18729, DOI 10.1109/CVPR52688.2022.01819
   Kong S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P793, DOI 10.1109/ICCV48922.2021.00085
   Krizhevsky Alex, 2010, Cifar datasets-10
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li CC, 2018, IEEE WINT CONF APPL, P131, DOI 10.1109/WACV.2018.00021
   Liang XZ, 2017, LECT NOTES COMPUT SC, V10635, P413, DOI 10.1007/978-3-319-70096-0_43
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Liu WY, 2016, PR MACH LEARN RES, V48
   Martínez-Díaz Y, 2019, IEEE INT CONF COMP V, P2721, DOI 10.1109/ICCVW.2019.00333
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Palechor Andres, 2023, WINT C APPL COMP VIS
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Perera Pramuditha, 2020, C COMP VIS PATT REC
   Poh N., 2012, Technical report
   Romm Tony, 2017, Washington PostJuly
   Sankaranarayanan S, 2016, INT CONF BIOMETR THE
   Sapkota Archana, 2013, Biometrics Theory, Applications and Systems (BTAS)
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Vareto R, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P634, DOI 10.1109/BTAS.2017.8272751
   Vareto RH, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020)
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yue ZQ, 2021, PROC CVPR IEEE, P15399, DOI 10.1109/CVPR46437.2021.01515
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhou Da-Wei, 2021, C COMP VIS PATT REC
NR 47
TC 1
Z9 1
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104862
DI 10.1016/j.imavis.2023.104862
EA DEC 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DX4M8
UT WOS:001135370500001
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Shahadat, N
   Maida, AS
AF Shahadat, Nazmul
   Maida, Anthony S.
TI Cross channel weight sharing for image classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hypercomplex networks; Quaternion networks; PHM layer; Axial-attention
   networks; Attention networks; Representation learning; Weight sharing;
   Hypercomplex dense layer; PHM based dense layer; Deep learning
ID CONVOLUTIONAL NEURAL-NETWORKS; EXTRACTION; ALGORITHM; FILTER
AB Hypercomplex convolutional neural networks (HCNNs) have recently been used to improve deep learning architectures due to their ability to share weights across input channels and thus improve the cohesiveness of learned representations within the layers. Much work has been done to study the effect of hypercomplex representation in CNNs. However, to date, none of these models have used fully hypercomplex architectures, meaning that some of the layers in these earlier networks used conventional real-valued calculations that did not engage cross-channel weight sharing. Here, we introduce and study full hypercomplex CNNs by ensuring all layers perform hypercomplex calculations. For the earlier HCNNs, the real-valued layers are found in: (I) in the front end of the networks, (II) in the back end of the networks, and (III) in the residual blocks of the networks. The present research examines the performance of HCNNs when the modules mentioned above are replaced with hypercomplex equivalents. These representational networks have outperformed and shown state-of-the-art results compared to previous hypercomplex models (on some specific datasets). A disadvantage of these representational networks is that they consume high computational costs. To reduce this cost, novel separable hypercomplex networks (SHNNs) are proposed. They are created by factoring a quaternion convolutional module into two consecutive separable vectormap convolutional modules. As the successive layers of deep HCNNs perform local hierarchical grouping on increasingly abstract features, these groupings are responsible for the long-distance interaction problems found in the dense layers. To handle these problems, researchers have applied attention mechanisms in hypercomplex space. This paper offers a perspective on the basic concepts of representational networks and attention-based representational networks with the focus on (1) reviewing deep full HCNNs, including hypercomplex-based fully connected dense layer; (2) analyzing hypercomplex-based separable concept; (3) describing how the hypercomplex spatial layer of residual bottleneck block is replaced with an attention layer; and (4) providing a comprehensive summary comparing the performance of recent deep HCNNs, deep convolutional neural networks, and original attention based networks. We compare the performance of the networks in terms of accuracy and the number of trainable parameters on several image classification datasets.
C1 [Shahadat, Nazmul] Truman State Univ, Comp Sci, Kirksville, MO 63501 USA.
   [Maida, Anthony S.] Univ Louisiana Lafayette, Sch Comp & Informat, Lafayette, LA 70504 USA.
C3 University of Louisiana Lafayette
RP Shahadat, N (corresponding author), Truman State Univ, Comp Sci, Kirksville, MO 63501 USA.
EM nshahadat@truman.edu
RI Maida, Anthony S/KIL-7180-2024
CR Ameen S, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12197
   Anderson Timothy, 2017, Split-Complex Convolutional Neural Networks
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision
   Arena P., 1994, 1994 IEEE International Symposium on Circuits and Systems (Cat. No.94CH3435-5), P307, DOI 10.1109/ISCAS.1994.409587
   Arjovsky M, 2016, PR MACH LEARN RES, V48
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bechet F, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1343
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   BIRX DL, 1993, IEEE T NEURAL NETWOR, V4, P127, DOI 10.1109/72.182703
   Bordes A, 2014, Arxiv, DOI arXiv:1406.3676
   Buchholz Sven, 2006, 2006 14 EUR SIGN PRO, P1
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Comminiello D, 2019, INT CONF ACOUST SPEE, P8533, DOI [10.1109/icassp.2019.8682711, 10.1109/ICASSP.2019.8682711]
   Cui YD, 2013, 2013 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P527, DOI 10.1109/SII.2013.6776617
   Danihelka I, 2016, PR MACH LEARN RES, V48
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong C, 2015, IEEE COMPUT SOC CONF
   Ebrahimi A, 2020, INT CONF IMAG VIS
   Fortuna L, 2001, IEEE T NEURAL NETWOR, V12, P318, DOI 10.1109/72.914526
   Fukushima S., 1982, inCompetition and Cooperation in Neural Nets, P267, DOI 10.1007/978-3-642-46466-9_18
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Galvez RL, 2018, TENCON IEEE REGION, P2023, DOI 10.1109/TENCON.2018.8650517
   Garcia B., 2016, Convolutional Neural Netw. Vis. Recognit., V2, P225
   Gaudet CS, 2021, IEEE IMAGE PROC, P319, DOI 10.1109/ICIP42928.2021.9506529
   Gaudet CJ, 2018, IEEE IJCNN
   Gaudet Chase John, 2020, Removing dimensional restrictions on complex/hyper-complex convolutions
   Georgiou George Michael, 1992, PhD thesis
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Goh SL, 2007, NEURAL COMPUT, V19, P1039, DOI 10.1162/neco.2007.19.4.1039
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hirose A, 1996, IEEE T NEURAL NETWOR, V7, P1032, DOI 10.1109/72.508945
   Hirose A, 2012, IEEE T NEUR NET LEAR, V23, P541, DOI 10.1109/TNNLS.2012.2183613
   Hirose A, 2010, LECT NOTES ARTIF INT, V6114, P42, DOI 10.1007/978-3-642-13232-2_6
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Isokawa T, 2003, LECT NOTES ARTIF INT, V2774, P318
   Isokawa T, 2012, INFORMATION, V3, P756, DOI 10.3390/info3040756
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K., 2019, Int J Sci Technol Res, V8, P667
   Kuznetsova A, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P83, DOI 10.1109/ICCVW.2013.18
   Le Ya, 2015, CS 231N, P3
   LEUNG H, 1991, IEEE T SIGNAL PROCES, V39, P2101, DOI 10.1109/78.134446
   Leung MKK, 2014, BIOINFORMATICS, V30, P121, DOI 10.1093/bioinformatics/btu277
   Liang HW, 2019, LECT NOTES COMPUT SC, V11818, P329, DOI 10.1007/978-3-030-31456-9_37
   Liang ZY, 2019, POWDER TECHNOL, V353, P156, DOI 10.1016/j.powtec.2019.05.025
   LITTLE GR, 1990, APPL OPTICS, V29, P1591, DOI 10.1364/AO.29.001591
   Long Cameron E., 2019, PhD thesis
   Ma JS, 2015, J CHEM INF MODEL, V55, P263, DOI 10.1021/ci500747n
   Matsui N, 2004, J INTELL FUZZY SYST, V15, P149
   Mitchell T. M., 1997, MACHINE LEARNING
   Muppidi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6309, DOI 10.1109/ICASSP39728.2021.9414248
   Nguyen HBD, 2019, 2019 26TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), P314, DOI [10.1109/ict.2019.8798856, 10.1109/ICT.2019.8798856]
   Nitta T, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P1099
   Nitta T, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2754
   Parcollet T, 2018, Arxiv, DOI arXiv:1806.07789
   Parcollet T, 2019, INT CONF ACOUST SPEE, P8514, DOI [10.1109/icassp.2019.8682495, 10.1109/ICASSP.2019.8682495]
   Parcollet T, 2016, IEEE W SP LANG TECH, P362, DOI 10.1109/SLT.2016.7846290
   Pavllo D, 2020, INT J COMPUT VISION, V128, P855, DOI 10.1007/s11263-019-01245-6
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Ramachandran P, 2019, Arxiv, DOI arXiv:1906.05909
   Ranga V, 2018, J ENG SCI TECHNOL, V13, P2655
   Rioux-Maldague L, 2014, 2014 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P92, DOI 10.1109/CRV.2014.20
   Sarigül M, 2019, NEURAL NETWORKS, V116, P279, DOI 10.1016/j.neunet.2019.04.025
   Sawada H, 2003, IEICE T FUND ELECTR, VE86A, P590
   Shahadat N., 2023, arXiv
   Shahadat Nazmul, 2021, arXiv
   Shahadat Nazmul, 2023, arXiv
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutskever I, 2014, ADV NEUR IN, V27
   Takahashi K, 2017, IEEE/SICE I S SYS IN, P875, DOI 10.1109/SII.2017.8279333
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Tompson J, 2014, ADV NEUR IN, V27
   Trabelsi C, 2018, Arxiv, DOI [arXiv:1705.09792, DOI 10.48550/ARXIV.1705.09792]
   Tygert M, 2016, Arxiv, DOI arXiv:1506.08230
   Upadhyay Shweta, 2020, Technical report
   Vaswani A, 2017, ADV NEUR IN, V30
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wisdom S, 2016, ADV NEUR IN, V29
   Worrall DE, 2017, PROC CVPR IEEE, P7168, DOI 10.1109/CVPR.2017.758
   Wu JS, 2020, NEUROCOMPUTING, V397, P179, DOI 10.1016/j.neucom.2020.02.053
   Xiong HY, 2015, SCIENCE, V347, DOI 10.1126/science.1254806
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yamaki R, 2009, IEEE GEOSCI REMOTE S, V6, P18, DOI 10.1109/LGRS.2008.2005588
   Yang BS, 2019, Arxiv, DOI arXiv:1904.03107
   Yao J, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3284671
   Yin QL, 2019, IEEE ACCESS, V7, P20293, DOI 10.1109/ACCESS.2019.2897000
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zambaldi Vinicius, 2018, INT C LEARN REPR
   Zhang AS, 2021, Arxiv, DOI arXiv:2102.08597
   Zhang YW, 1997, IEEE T NEURAL NETWOR, V8, P1031, DOI 10.1109/72.623205
   Zhang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P7177, DOI 10.1109/TGRS.2017.2743222
   Zhu XY, 2018, LECT NOTES COMPUT SC, V11212, P645, DOI 10.1007/978-3-030-01237-3_39
NR 103
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104872
DI 10.1016/j.imavis.2023.104872
EA DEC 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DM5I9
UT WOS:001132469900001
DA 2024-07-18
ER

PT J
AU Kefalas, T
   Fotiadou, E
   Georgopoulos, M
   Panagakis, Y
   Ma, PC
   Petridis, S
   Stafylakis, T
   Pantic, M
AF Kefalas, Triantafyllos
   Fotiadou, Eftychia
   Georgopoulos, Markos
   Panagakis, Yannis
   Ma, Pingchuan
   Petridis, Stavros
   Stafylakis, Themos
   Pantic, Maja
TI KAN-AV dataset for audio-visual face and speech analysis in the wild
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE KAN-AV; Speaker verification; Kinship verification; Age-invariant;
   Cross-modal matching; Audio-visual
ID RECOGNITION; REPRESENTATIONS; FAMILIES; DATABASE
AB Human-computer interaction is becoming increasingly prevalent in daily life with the adoption of intelligent devices. These devices must be capable of interacting in diverse settings, such as environments with noise, music and differing illumination and occlusion conditions. They must also interact with a variety of end users across ages and backgrounds. Therefore, the machine learning community needs in-the-wild multi-modal datasets to develop models for face and speech analysis so that they can be applicable in most real world scenarios. However, most existing audio and audio-visual databases are captured in controlled conditions with few or no age and kinship labels. In this paper, we introduce the KAN-AV dataset which contains 98 h of audio-visual data from 970 identities across ages. Two thirds of the identities have kin relations in the dataset. The dataset is manually annotated with labels for kinship, age, and gender and is intended to drive future research in face and speech analysis.
C1 [Kefalas, Triantafyllos; Fotiadou, Eftychia; Georgopoulos, Markos; Ma, Pingchuan; Petridis, Stavros; Pantic, Maja] Imperial Coll, Dept Comp, London, England.
   [Panagakis, Yannis] Univ Athens, Dept Informat & Telecommun, Athens, Greece.
   [Stafylakis, Themos] Omilia Conversat Intelligence, Athens, Greece.
C3 Imperial College London; National & Kapodistrian University of Athens
RP Kefalas, T (corresponding author), Imperial Coll, Dept Comp, London, England.
EM tk15@ic.ac.uk
RI Ma, Pingchuan/AFR-0634-2022
OI Ma, Pingchuan/0000-0003-3752-0803
FU EPSRC [EP/M507878/1, EP/N509486/1]
FX The work of T. Kefalas is funded by the EPSRC grants EP/M507878/1 and
   EP/N509486/1.
CR Afouras T, 2018, Arxiv, DOI arXiv:1809.00496
   [Anonymous], INTERNET MOVIE DATAB
   [Anonymous], Free Encyclopedia
   Bernard D, 2017, IEEE SYS MAN CYBERN, P210, DOI 10.1109/SMC.2017.8122604
   Bhattacharjee U, 2016, 2016 INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (ICRAIE)
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Bimbot F, 2004, EURASIP J APPL SIG P, V2004, P430, DOI 10.1155/S1110865704310024
   Burkhardt F, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1562
   catalog.ldc, Switchboard-1 release 2
   catalog.ldc.upenn, YOHO speaker verification
   challenge.ai. iqiyi, 2019 iQIYI celebrity video identification Challenge
   challenge.ai.iqiyi, iQIYI-VID Dataset
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Che C., 1995, EUROSPEECH 1995 4 EU, P625
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chung JS, 2018, INTERSPEECH, P1086
   Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Cogswell M, 2016, Arxiv, DOI arXiv:1511.06068
   commonvoice.mozilla, Why Common Voice?
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Deller J.R., 2000, Discrete-Time Processing of Speech Signals, Vsecond, DOI DOI 10.1109/9780470544402.CH11
   developers.google, Machine learning fairness
   Feng L., 2005, A new database for speaker recognition
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128
   Georgopoulos M, 2021, INT J COMPUT VISION, V129, P2288, DOI 10.1007/s11263-021-01448-w
   Georgopoulos M, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103954
   Georgopoulos M, 2020, IEEE COMPUT SOC CONF, P66, DOI 10.1109/CVPRW50498.2020.00015
   Georgopoulos M, 2018, IMAGE VISION COMPUT, V80, P58, DOI 10.1016/j.imavis.2018.05.003
   Godfrey J. J., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P517, DOI 10.1109/ICASSP.1992.225858
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gulati A, 2020, INTERSPEECH, P5036, DOI 10.21437/Interspeech.2020-3015
   Harnsberger JD, 2010, J VOICE, V24, P523, DOI 10.1016/j.jvoice.2009.01.003
   Higgins A., 1991, Digital Signal Processing, V1, P89, DOI 10.1016/1051-2004(91)90098-6
   Huang YL, 2020, Arxiv, DOI arXiv:2011.11818
   Iannizzotto G, 2018, C HUM SYST INTERACT, P50, DOI 10.1109/HSI.2018.8431232
   IBM, IBM Watson Speech-to-Text
   Kelly F., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P478, DOI 10.1109/ICB.2012.6199796
   Kelly F, 2013, INTERSPEECH, P1623
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1435, DOI 10.1109/TASL.2006.881693
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D. P., 2014, arXiv
   Li Z., 2023, IEEE T NEUR NET LEAR
   Liu YL, 2019, Arxiv, DOI arXiv:1811.07548
   Liu YL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2516, DOI 10.1145/3343031.3356081
   Ma PC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7613, DOI 10.1109/ICASSP39728.2021.9414567
   McGee P., 2019, Financial Times
   McLaren M, 2016, INTERSPEECH, P818, DOI 10.21437/Interspeech.2016-1129
   MILLAR JB, 1994, INT CONF ACOUST SPEE, P97
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Nagrani A, 2020, COMPUT SPEECH LANG, V60, DOI 10.1016/j.csl.2019.101027
   Nagrani A, 2018, PROC CVPR IEEE, P8427, DOI 10.1109/CVPR.2018.00879
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Paszke A, 2019, ADV NEUR IN, V32
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petridis S, 2018, IEEE W SP LANG TECH, P513, DOI 10.1109/SLT.2018.8639643
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Robinson J. P., 2016, P 24 ACM INT C MULT, P242, DOI DOI 10.1145/2964284.2967219
   Robinson JP, 2021, IEEE T MULTIMEDIA, V24, P3582, DOI 10.1109/TMM.2021.3103074
   Robinson JP, 2020, IEEE INT CONF AUTOMA, P857, DOI [10.1109/fg47880.2020.00138, 10.1109/FG47880.2020.00138]
   robots.ox, VGG-M Face
   ROSE RC, 1990, INT CONF ACOUST SPEE, P293, DOI 10.1109/ICASSP.1990.115638
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Sagonas C, 2016, INT C PATT RECOG, P4226, DOI 10.1109/ICPR.2016.7900297
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shang DP, 2018, CHIN AUTOM CONGR, P4178, DOI 10.1109/CAC.2018.8623298
   Shukla A, 2023, IEEE T AFFECT COMPUT, V14, P406, DOI 10.1109/TAFFC.2021.3062406
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snyder D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5329
   SOONG FK, 1988, IEEE T ACOUST SPEECH, V36, P871, DOI 10.1109/29.1598
   Spiegl W., 2009, INTERSPEECH, P2923
   Sultan M.R., 2019, 2019 22 INT C COMP I, P1
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tang H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P610, DOI 10.1145/3394171.3413884
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Watanabe S, 2017, IEEE J-STSP, V11, P1240, DOI 10.1109/JSTSP.2017.2763455
   Waters R., 2015, Financial Times
   Wu XT, 2019, Arxiv, DOI arXiv:1906.10096
   Yamamoto R., 2019, arXiv, DOI DOI 10.48550/ARXIV.1910.11480
   Yang HY, 2021, IEEE T PATTERN ANAL, V43, P499, DOI 10.1109/TPAMI.2019.2930985
   Zha ZC, 2023, IEEE T CIRC SYST VID, V33, P3947, DOI 10.1109/TCSVT.2023.3236636
   Zhang YD, 2019, Arxiv, DOI arXiv:1910.06745
NR 89
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104839
DI 10.1016/j.imavis.2023.104839
EA OCT 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Y7RO0
UT WOS:001107197500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhu, YJ
   Xie, JM
   Liu, MY
   Yao, L
   Chen, YP
AF Zhu, Yijie
   Xie, Jingming
   Liu, Moyun
   Yao, Lei
   Chen, Youping
TI BF3D: Bi-directional fusion 3D detector with semantic sampling and
   geometric mapping
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; 3D object detection; Bi-directional fusion; Semantic
   sampling; Geometric mapping
ID VOXELNET
AB 3D object detection is a key task in environmental awareness, which plays a vital role in autonomous driving safety. Lidars and cameras are widely used sensors that provide complementary information for accurate 3D detection. However, due to the domain difference between the two modalities, it is challenging to leverage their respective strengths and fuse them perfectly. In this paper, an end-to-end detector termed BF3D is proposed, which integrates with the semantic sampling module, geometric point-image mapping module, and bi-directional attention fusion module. Specifically, the semantic sampling module incorporates a novel downsampling strategy to preserve more foreground points and pixels. Additionally, the geometric point-image mapping module is developed to find geometric correlation pixels of the point and take advantage of the high density of image features. We also introduce a bi-directional attention fusion module to combine useful information from the two modalities by attention mechanism. Extensive experiments demonstrate that BF3D outperforms both single-and multi-modal 3D detectors. Codes are available at: https://github.com/hustzyj/BF3D.
C1 [Zhu, Yijie; Xie, Jingming; Liu, Moyun; Yao, Lei; Chen, Youping] Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Xie, JM (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.
EM xjmhust@hust.edu.cn
RI Chen, Youping/G-2931-2010
OI Chen, Youping/0000-0002-9626-9009; Yao, Lei/0009-0007-0304-3056
FU Hubei Provincial Key Research and Development Program Project of China
   [2020BA B035]
FX This work is sponsored by the Hubei Provincial Key Research and
   Development Program Project of China (no. 2020BA B035) .
CR Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Deng JJ, 2021, AAAI CONF ARTIF INTE, V35, P1201
   Erçelik E, 2021, IEEE ACCESS, V9, P143138, DOI 10.1109/ACCESS.2021.3120261
   Feng Yong, 2023, Image and Vision Computing
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   He T, 2019, AAAI CONF ARTIF INTE, P8409
   Jiaming Sun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10545, DOI 10.1109/CVPR42600.2020.01056
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111
   Li PL, 2019, PROC CVPR IEEE, P7636, DOI 10.1109/CVPR.2019.00783
   Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Lin CM, 2022, IEEE T INTELL TRANSP, V23, P18040, DOI 10.1109/TITS.2022.3154537
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2929, DOI 10.1109/ICCV48922.2021.00294
   Liu Z, 2022, Arxiv, DOI arXiv:2112.11088
   Liu Z, 2020, AAAI CONF ARTIF INTE, V34, P11677
   Luo SJ, 2021, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR46437.2021.00608
   Misra I, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2886, DOI 10.1109/ICCV48922.2021.00290
   Ng MY, 2020, IEEE COMPUT SOC CONF, P4306, DOI 10.1109/CVPRW50498.2020.00508
   Pan XR, 2021, PROC CVPR IEEE, P7459, DOI 10.1109/CVPR46437.2021.00738
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2020, PROC CVPR IEEE, P4403, DOI 10.1109/CVPR42600.2020.00446
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qingyong Hu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11105, DOI 10.1109/CVPR42600.2020.01112
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2016, PROC CVPR IEEE, P1525, DOI 10.1109/CVPR.2016.169
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Sindagi VA, 2019, IEEE INT CONF ROBOT, P7276, DOI [10.1109/ICRA.2019.8794195, 10.1109/icra.2019.8794195]
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Tengteng Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P35, DOI 10.1007/978-3-030-58555-6_3
   Vaswani A, 2017, ADV NEUR IN, V30
   Vora S, 2020, PROC CVPR IEEE, P4603, DOI 10.1109/CVPR42600.2020.00466
   Wu YQ, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104430
   Xie L, 2020, AAAI CONF ARTIF INTE, V34, P12460
   Xie Qizhe, 2020, SELF TRAINING NOISY, DOI 10.1109/cvpr42600.2020.01046
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Yoo JH, 2020, SELECTED PAPERS FROM THE NINETEENTH BIENNIAL IEEE CONFERENCE ON ELECTROMAGNETIC FIELD COMPUTATION (IEEE CEFC 2020), DOI [10.1109/CEFC46938.2020.9451336, 10.1007/978-3-030-58583-9_43]
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zaiwei Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P311, DOI [10.1061/9780784482933.027, 10.1007/978-3-030-58610-2_19]
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zimmer W, 2022, Arxiv, DOI arXiv:2207.05200
NR 54
TC 1
Z9 1
U1 11
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104835
DI 10.1016/j.imavis.2023.104835
EA OCT 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA W1LO4
UT WOS:001089314100001
DA 2024-07-18
ER

PT J
AU Hu, XG
   Liu, YJ
AF Hu, Xuegang
   Liu, Yuanjing
TI Lightweight multi-scale attention-guided network for real-time semantic
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Lightweight network; Attention mechanism; Multi-scale feature fusion;
   Real-time semantic segmentation
AB The wide application of small mobile devices makes the demand for lightweight real-time semantic segmentation algorithm become more and more intense, which makes it become one of the most popular research topics in the field of computer vision. However, some current methods blindly pursue low parameter numbers and high inference speeds, resulting in excessively low model accuracy and a loss of practical value. Therefore, a lightweight multi-scale attention-guided network for real-time semantic segmentation(LMANet) based on asymmetric encoder-decoder is proposed in this paper to solve the above dilemmas. In the encoder, we propose multi-scale asymmetric residual(MAR) modules to extract local spatial information and context information to enhance feature expression. In the decoder, we design an attention feature fusion(AFF) module and an attention pyramid refining (APR) module. AFF module guides the fusion of low-level and middle-level feature information through high-level semantic information, and finally refines the fusion result through APR module. In addition, we improve the segmentation performance of the model with the help of the attention modules in the network. Our network is tested on two complex urban road datasets. The experimental results show that LMANet achieves 70.6% mIoU and 66.5% mIoU on Cityscapes and Camvid datasets at 112FPS and 333FPS respectively, only 0.95 M parameters without any pre-training or pre-processing. Compared with most of existing state-of-the-art models, our network not only guarantees reasonable inference speed and parameter quantity, but also improves the accuracy as much as possible, which makes it more practical.
C1 [Hu, Xuegang] Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Chongqing 400065, Peoples R China.
   [Liu, Yuanjing] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
   of Posts & Telecommunications
RP Liu, YJ (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing 400065, Peoples R China.
EM S210131148@stu.cqupt.edu.cn
RI Liu, Junjie/KHV-6949-2024
FU National Natural Science Foundation of China [62076044]; Natural
   Sci-ence Foundation of Chongqing, China [cstc2019jcyj-zdxm0011]
FX We thank all the anonymous reviewers for their constructive
   sug-gestions. This work is supported by the National Natural Science
   Foundation of China (Project Number 62076044) , and the Natural Sci-ence
   Foundation of Chongqing, China (Grant No. cstc2019jcyj-zdxm0011) .
CR Taghanaki SA, 2021, ARTIF INTELL REV, V54, P137, DOI 10.1007/s10462-020-09854-1
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Changqian Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12413, DOI 10.1109/CVPR42600.2020.01243
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen PR, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/ATSIP.2020.25
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Feng D, 2021, IEEE T INTELL TRANSP, V22, P1341, DOI 10.1109/TITS.2020.2972974
   Gao GW, 2022, IEEE T INTELL TRANSP, V23, P25489, DOI 10.1109/TITS.2021.3098355
   Han HY, 2021, IEEE T INTELL TRANSP, V22, P1041, DOI 10.1109/TITS.2019.2962094
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hao XC, 2021, IMAGE VISION COMPUT, V114, DOI 10.1016/j.imavis.2021.104269
   Hao Y., 2022, arXiv
   Hao YY, 2021, IEEE INT CONF COMP V, P1551, DOI 10.1109/ICCVW54120.2021.00180
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu XG, 2022, APPL INTELL, V52, P580, DOI 10.1007/s10489-021-02446-8
   Li G, 2019, Arxiv, DOI arXiv:1907.11357
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Liu J, 2020, INT CONF ACOUST SPEE, P2373, DOI [10.1109/icassp40776.2020.9053838, 10.1109/ICASSP40776.2020.9053838]
   Liu MY, 2019, Arxiv, DOI arXiv:1909.08599
   Lo S. Y., 2019, P ACM MULTIMEDIA ASI, P1, DOI DOI 10.1145/3338533.3366558
   Lou A, 2021, IEEE IMAGE PROC, P1894, DOI 10.1109/ICIP42928.2021.9506485
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Poudel RPK, 2018, Arxiv, DOI arXiv:1805.04554
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Poudel R. P. K., 2019, arXiv
   Qin ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P763, DOI 10.1109/ICCV48922.2021.00082
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Tang XY, 2021, INFORM SCIENCES, V565, P326, DOI 10.1016/j.ins.2021.02.004
   Wang JW, 2020, APPL INTELL, V50, P1045, DOI 10.1007/s10489-019-01587-1
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang Y, 2019, IEEE IMAGE PROC, P1860, DOI [10.1109/icip.2019.8803154, 10.1109/ICIP.2019.8803154]
   Weng X, 2022, IEEE T INTELL TRANSP, V23, P17224, DOI 10.1109/TITS.2022.3150350
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P775, DOI 10.1007/978-3-030-58452-8_45
   Xiao CJ, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104470
   Yang QH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2315, DOI 10.1109/ICASSP39728.2021.9413767
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu Wang, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11858), P41, DOI 10.1007/978-3-030-31723-2_4
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhong Z., 2020, P IEEE CVF C COMP VI, P13065, DOI DOI 10.1109/CVPR42600.2020.01308
   Zhuang MX, 2021, NEUROCOMPUTING, V459, P349, DOI 10.1016/j.neucom.2021.07.019
NR 48
TC 4
Z9 4
U1 8
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104823
DI 10.1016/j.imavis.2023.104823
EA SEP 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA U8ZC0
UT WOS:001087616600001
DA 2024-07-18
ER

PT J
AU Almattar, W
   Luqman, H
   Khan, FA
AF Almattar, Wadha
   Luqman, Hamzah
   Khan, Fakhri Alam
TI Diabetic retinopathy grading review: Current techniques and future
   directions
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Diabetic retinopathy; Retinal fundus images; Diabetic retinopathy
   stages; Computer-aided diagnosis; Machine learning
ID CONVOLUTIONAL NEURAL-NETWORKS; IMAGES; CLASSIFICATION; SEGMENTATION;
   DIAGNOSIS
AB Diabetic retinopathy (DR) is widely recognized as a leading cause of blindness among individuals with diabetes worldwide. Therefore, early diagnosis of DR plays a crucial role in preserving patients' vision and halting the progression of the disease to advanced stages. However, manual diagnosis of DR in clinical practice is timeconsuming and susceptible to human error, especially during the early stages when the lesions associated with DR are often minute and challenging to identify. Furthermore, with the projected surge in the number of diabetic patients and a concurrent shortage of ophthalmologists, there will be insufficient healthcare professionals available to examine all individuals at risk. The application of machine- and deep learning-based techniques has proven effective in diagnosing medical images, including those related to DR. In this review, we surveyed and analyzed 55 DR grading studies published between 2018 and 2022 extracted from four academic digital libraries: Scopus, Web of Science, Google Scholar, and Science Direct. The review provides a comprehensive discussion and analysis of these selected studies, considering various aspects such as benchmark DR datasets, classification tasks, preprocessing techniques, learning approaches, and performance evaluation measures. Within the literature on DR grading, supervised-based learning techniques have been found to be more prevalent than semi-supervised learning techniques. Furthermore, researchers predominantly addressed this problem as an image-level classification task, overlooking the distinctive characteristics of lesions within each grade. Numerous proposed techniques primarily concentrate on detecting the early stages of DR, while a limited number of studies address the disease's advanced stages. The primary findings of our analysis reveal a potential direction for future research that emphasizes data- and model-centric approaches.
C1 [Almattar, Wadha; Luqman, Hamzah; Khan, Fakhri Alam] King Fahd Univ Petr & Minerals, Informat & Comp Sci Dept, Dhahran 31261, Saudi Arabia.
   [Almattar, Wadha] Imam Abdulrahman Bin Faisal Univ, Dept Comp Sci, Dammam 31441, Saudi Arabia.
   [Khan, Fakhri Alam] KFUPM, Interdisciplinary Res Ctr Intelligent Secure Syst, Dhahran, Saudi Arabia.
   [Luqman, Hamzah; Khan, Fakhri Alam] KFUPM, SDAIA KFUPM Joint Res Ctr Artificial Intelligence, Dhahran, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals; Imam Abdulrahman Bin
   Faisal University; King Fahd University of Petroleum & Minerals; King
   Fahd University of Petroleum & Minerals
RP Almattar, W; Luqman, H (corresponding author), King Fahd Univ Petr & Minerals, Informat & Comp Sci Dept, Dhahran 31261, Saudi Arabia.
EM wmalmattar@iau.edu.sa; hluqman@kfupm.edu.sa
FU King Fahd University of Petroleum and Minerals (KFUPM) under the
   Interdisciplinary Research Center for Intelligent Secure Systems (IRC-
   ISS) [INSS2205]
FX <BOLD> The authors have no conflicts of interest to declare. All
   co-authors have seen and agree with the contents of the manuscript and
   there is no financial interest to report. </BOLD> The authors would like
   to acknowledge the support received from the King Fahd University of
   Petroleum and Minerals (KFUPM) under the Interdisciplinary Research
   Center for Intelligent Secure Systems (IRC- ISS) for funding this work
   through project number INSS2205.
CR Abdelmaksoud E., 2020, INT C DAT AN BUS IND
   Abdelmaksoud E, 2021, IEEE ACCESS, V9, P15939, DOI 10.1109/ACCESS.2021.3052870
   Abramoff Michael, 2013, Retina, Vfifth, P151
   Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Al-Diri B, 2008, IEEE ENG MED BIO, P2262, DOI 10.1109/IEMBS.2008.4649647
   Alyoubi W. L., 2020, Informatics in Medicine Unlocked, V20, DOI [DOI 10.1016/J.IMU.2020.100377, 10.1016/j.imu.2020.100377]
   Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   Alzubaidi L., 2021, arXiv
   American Diabetes Association, 2023, About Us
   [Anonymous], 2023, Desktop Fundus Camera
   [Anonymous], 2023, Portable Fundus Camera
   Aouf M, 2015, OPTIC DISC OPTIC CUP
   APTOS, 2023, Diabetic Retinopathy Detection
   Arora Mamta, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P189, DOI 10.1109/COMITCon.2019.8862217
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Barhate Nikhil, 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P298, DOI 10.1109/ICCCA49541.2020.9250772
   Bhardwaj C, 2021, NEURAL COMPUT APPL, V33, P13999, DOI 10.1007/s00521-021-06042-2
   Bhatti E., 2019, Commun. Comp. Inform. Sci., V1036, P174
   Burlina P, 2020, JAMA OPHTHALMOL, V138, P1070, DOI 10.1001/jamaophthalmol.2020.3269
   Chakravarthy SN, 2019, IEEE IJCNN
   Chowdhury M.S., 2019, INT C COMP COMM CHEM
   Cinarer Gokalp, 2022, Intelligent and Fuzzy Techniques for Emerging Conditions and Digital Transformation: Proceedings of the INFUS 2021 Conference. Lecture Notes in Networks and Systems (308), P147, DOI 10.1007/978-3-030-85577-2_17
   Dai L, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23458-5
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Deepa V, 2022, J KING SAUD UNIV-COM, V34, P6255, DOI 10.1016/j.jksuci.2021.05.009
   DeepDR, 2019, About Us
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doshi N., 2020, INT C SIGN PROC INT
   Elyan Eyad, 2022, Artificial Intelligence Surgery, V2
   EyePACS, 2023, Diabetic Retinopathy Detection
   Foo A., 2020, 32 INN APPL ART INT
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   G. E. Associates, 2023, Gadsden Eye Associates
   Gayathri S, 2021, PHYS ENG SCI MED, V44, P639, DOI 10.1007/s13246-021-01012-3
   Gayathri S., 2020, Biomed. Sign. Proc. Control, V62, P9
   Hacisoftaoglu RE, 2020, PATTERN RECOGN LETT, V135, P409, DOI 10.1016/j.patrec.2020.04.009
   Harihanth K., 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P1042, DOI 10.1109/ICISS49785.2020.9315991
   He J., 2019, IEEE INT C POW INT C
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Hoover A, 2015, Structured analysis of the retina stare
   Hua CH, 2021, IEEE J BIOMED HEALTH, V25, P2686, DOI 10.1109/JBHI.2020.3041848
   International Diabetes Federation, 2021, IDF Diabetes Atlas, V10th ed.
   Ishtiaq U, 2020, MULTIMED TOOLS APPL, V79, P15209, DOI 10.1007/s11042-018-7044-8
   Islam MM, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105320
   Islam MR, 2020, IEEE REGION 10 SYMP, P888
   Jadhav AS, 2021, EVOL INTELL, V14, P1431, DOI 10.1007/s12065-020-00400-0
   Jiang HY, 2020, IEEE ENG MED BIO, P1560, DOI 10.1109/EMBC44109.2020.9175884
   Kalyani G, 2023, COMPLEX INTELL SYST, V9, P2651, DOI 10.1007/s40747-021-00318-9
   Kandel I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062021
   Karki SS, 2021, 2021 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P68, DOI 10.1109/ESCI50559.2021.9397035
   Kauppi T., 2007, Evaluation Database and Methodology for Diabetic Retinopathy Algorithms
   Kauppi T., 2007, P BRIT MACH VIS C, V1
   Khan Z, 2021, IEEE ACCESS, V9, P61408, DOI 10.1109/ACCESS.2021.3074422
   Köhler T, 2013, COMP MED SY, P95, DOI 10.1109/CBMS.2013.6627771
   Kumar G, 2021, SIGNAL IMAGE VIDEO P, V15, P1679, DOI 10.1007/s11760-021-01904-7
   Lal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113922
   Lands A., 2020, INT C TRENDS EL INF
   Lee J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0075699
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Li YJ, 2021, IEEE ACCESS, V9, P140759, DOI 10.1109/ACCESS.2021.3119434
   Lian C.-Y., 2018, J. Inform. Hiding Multimedia Sign. Proc. C, V9
   Lian CY, 2018, ICAIP 2018: 2018 THE 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN IMAGE PROCESSING, P68, DOI 10.1145/3239576.3239589
   Liu H, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8840174
   Liu YP, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.002
   Luo YG, 2020, IEEE ACCESS, V8, P92352, DOI 10.1109/ACCESS.2020.2994047
   Mahiba C, 2019, MEASUREMENT, V135, P762, DOI 10.1016/j.measurement.2018.12.032
   Martinez-Murcia FJ, 2021, NEUROCOMPUTING, V452, P424, DOI 10.1016/j.neucom.2020.04.148
   Matsoukas C., 2021, arXiv, V8
   Metan A.C., 2019, IEEE INT C IM VIS CO
   Nazir T, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.003
   Niemeijer M, 2010, IEEE T MED IMAGING, V29, P185, DOI 10.1109/TMI.2009.2033909
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Qummar S, 2019, IEEE ACCESS, V7, P150530, DOI 10.1109/ACCESS.2019.2947484
   Rahim SS, 2019, LECT NOTES COMPUT SC, V11713, P114, DOI 10.1007/978-3-030-29726-8_8
   Saeed F, 2021, Arxiv, DOI [arXiv:2110.03877, 10.48550/arXiv.2110.03877, DOI 10.48550/ARXIV.2110.03877]
   Saeed F, 2021, IEEE ACCESS, V9, P41344, DOI 10.1109/ACCESS.2021.3065273
   Samanta A, 2020, PATTERN RECOGN LETT, V135, P293, DOI 10.1016/j.patrec.2020.04.026
   Shen ZY, 2021, IEEE T MED IMAGING, V40, P996, DOI 10.1109/TMI.2020.3043495
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Suedumrong C, 2022, LECT NOTE NETW SYST, V359, P56, DOI 10.1007/978-3-030-89880-9_5
   Sugeno A, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104795
   T. A. S. of Retina Specialist, 2023, Retina Image Bank Dataset
   Tan MX, 2019, PR MACH LEARN RES, V97
   Taufiqurrahman Shidqie, 2020, 2020 IEEE Region 10 Conference (TENCON), P235, DOI 10.1109/TENCON50793.2020.9293739
   Togacar M, 2022, Comput. Methods Prog. Biomed., V214, P2
   Tsiknakis N, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104599
   Vives-Boix V., 2021, Comput. Methods Prog. Biomed., V206, P7
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   WHO, 2023, ABOUT US
   Wild S, 2004, DIABETES CARE, V27, P1047, DOI 10.2337/diacare.27.5.1047
   Wilkinson CP, 2003, OPHTHALMOLOGY, V110, P1677, DOI 10.1016/S0161-6420(03)00475-5
   Yaqoob M.K., 2020, IEEE INT MULTITOP C, V11
   Yaqoob MK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113883
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhang GH, 2021, IEEE ACCESS, V9, P35778, DOI 10.1109/ACCESS.2021.3061690
   Zhang W, 2019, KNOWL-BASED SYST, V175, P12, DOI 10.1016/j.knosys.2019.03.016
   Zhao ZY, 2020, IEEE IMAGE PROC, P2496, DOI [10.1109/ICIP40778.2020.9191345, 10.1109/icip40778.2020.9191345]
   Zhao ZY, 2019, IEEE IMAGE PROC, P1385, DOI [10.1109/ICIP.2019.8803074, 10.1109/icip.2019.8803074]
   Zhixiang Qian, 2021, 2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P2652, DOI 10.1109/IAEAC50856.2021.9390963
   Zhou K., 2018, ANN INT C IEEE ENG M, V8
   Zhou Y, 2021, IEEE T MED IMAGING, V40, P818, DOI 10.1109/TMI.2020.3037771
   Zhou Y, 2019, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2019.00218
NR 103
TC 1
Z9 1
U1 6
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104821
DI 10.1016/j.imavis.2023.104821
EA SEP 2023
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA U5QT0
UT WOS:001085355000001
DA 2024-07-18
ER

PT J
AU Bruni, V
   Vitulano, D
   Marconi, S
AF Bruni, Vittoria
   Vitulano, Domenico
   Marconi, Silvia
TI A supervised approach for the detection of AM-FM signals' interference
   regions in spectrogram images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multicomponent signals; Instantaneous frequency estimation; Interfering
   AM-FM signals; Machine learning; Spectrogram classification;
   Convolutional neural networks; Supervised learning
ID INSTANTANEOUS FREQUENCY ESTIMATION; EMPIRICAL MODE DECOMPOSITION;
   MULTICOMPONENT LFM SIGNALS; TIME-FREQUENCY; IF ESTIMATION; WIGNER
   DISTRIBUTION; VITERBI ALGORITHM; EXTRACTION; TRANSFORM; NOISE
AB Ridge curves retrieval in time-frequency (TF) domains is fundamental in many application fields as they convey most of information concerning the instantaneous frequencies of non-stationary signals. However, it represents a very hard task in the case of multicomponent signals having non-separable modes as they generate interference in TF domains. A preliminary detection of these interference regions may be then useful for the definition of effective strategies for ridge curve recovery. This paper introduces SIID-CNN (Spectrogram Image Interference Detection via CNN), that is a novel approach based on machine learning for the automatic detection of interference regions in spectrogram images. Each spectrogram sample is suitably classified as interference, single mode or background by accounting for its relative information. Some critical problems, such as the training set size and the type of examples to use for populating the training set, are dealt with. Experimental results show that a local linear model for spectrogram image and a small training set can guarantee good classification rates for a wide class of non-stationary signals, even in the presence of moderate noise.
C1 [Bruni, Vittoria; Vitulano, Domenico] Sapienza Univ Rome, Dept Basic & Appl Sci Engn, Via Antonio Scarpa 16, I-00161 Rome, Italy.
   [Marconi, Silvia] Sapienza Univ Rome, Dept Methods & Models Econ, Terr & Finance, Via Castro Laurenziano 9, I-00161 Rome, Italy.
C3 Sapienza University Rome; Sapienza University Rome
RP Bruni, V (corresponding author), Sapienza Univ Rome, Dept Basic & Appl Sci Engn, Via Antonio Scarpa 16, I-00161 Rome, Italy.
EM vittoria.bruni@uniroma1.it
FU PNRR-CN1_SPOKE_6 Spoke 6 -Multiscale modeling engineering applications
   [B83C22002940006]; MUR National Recovery and Resilience Plan - European
   Union - NextGenerationEU [PE0000013-FAIR]
FX The Authors would like to thank the anonymous Reviewers for their
   comments and suggestions that contributed to improve the paper. This
   work has been partially supported by PNRR-CN1_SPOKE_6 Spoke 6
   -Multiscale modeling engineering applications B83C22002940006, and by
   PE0000013-FAIR under the MUR National Recovery and Resilience Plan
   funded by the European Union - NextGenerationEU. This research has been
   accomplished within RITA (Research ITalian network on Approximation) and
   the Italian national research group GNCS (INdAM).
CR Aggarwal C.C., 2018, NEURAL NETWORKS DEEP, DOI DOI 10.1007/978-3-319-94463-0
   Alieva T, 2003, IEEE T SIGNAL PROCES, V51, P112, DOI 10.1109/TSP.2002.806593
   Auger F, 2013, IEEE SIGNAL PROC MAG, V30, P32, DOI 10.1109/MSP.2013.2265316
   BARBAROSSA S, 1995, IEEE T SIGNAL PROCES, V43, P1511, DOI 10.1109/78.388866
   Boashash B, 2003, TIME FREQUENCY SIGNAL ANALYSIS AND PROCESSING: A COMPREHENSIVE REFERENCE, P627
   Bouchikhi A, 2014, IEEE T AERO ELEC SYS, V50, P1222, DOI 10.1109/TAES.2014.120202
   Bruni Vittoria, 2020, Image Analysis and Recognition. 17th International Conference (ICIAR 2020). Proceedings. Lecture Notes in Computer Science (LNCS 12132), P36, DOI 10.1007/978-3-030-50516-5_4
   Bruni V, 2013, SIGNAL PROCESS, V93, P882, DOI 10.1016/j.sigpro.2012.10.012
   Bruni V., 2010, P 2010 2 INT WORKSH
   Bruni V, 2022, DIGIT SIGNAL PROCESS, V128, DOI 10.1016/j.dsp.2022.103635
   Bruni V, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9030247
   Bruni V, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122170
   Bruni V, 2020, MATH COMPUT SIMULAT, V176, P96, DOI 10.1016/j.matcom.2019.11.006
   Bruni V, 2020, EURASIP J ADV SIG PR, V2020, DOI 10.1186/s13634-020-00673-8
   Bruni V, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7040358
   Bruni V, 2018, EUR SIGNAL PR CONF, P722, DOI 10.23919/EUSIPCO.2018.8553498
   Candès EJ, 2008, APPL COMPUT HARMON A, V24, P14, DOI 10.1016/j.acha.2007.04.003
   Carmona RA, 1999, IEEE T SIGNAL PROCES, V47, P480, DOI 10.1109/78.740131
   Carmona RA, 1997, IEEE T SIGNAL PROCES, V45, P2586, DOI 10.1109/78.640725
   Chen HL, 2019, IEEE ACCESS, V7, P136358, DOI 10.1109/ACCESS.2019.2919321
   Chen SQ, 2017, IEEE T SIGNAL PROCES, V65, P6024, DOI 10.1109/TSP.2017.2731300
   Chen SQ, 2017, IEEE SENS J, V17, P5994, DOI 10.1109/JSEN.2017.2737467
   Chen SQ, 2017, IEEE T IND ELECTRON, V64, P1370, DOI 10.1109/TIE.2016.2612174
   Chen SQ, 2016, IEEE T INSTRUM MEAS, V65, P276, DOI 10.1109/TIM.2015.2494632
   Chen VC, 2006, IEEE T AERO ELEC SYS, V42, P2, DOI 10.1109/TAES.2006.1603402
   Cicone A, 2019, ADV MATH METHODS HIG, P69
   Cuomo S, 2022, J SCI COMPUT, V92, DOI 10.1007/s10915-022-01939-z
   Daubechies I., 2015, Philos. Trans. R. Soc. A Math. Phys. Eng. Sci., V374
   Daubechies I, 2011, APPL COMPUT HARMON A, V30, P243, DOI 10.1016/j.acha.2010.08.002
   Ding YP, 2014, IEEE T GEOSCI REMOTE, V52, P5807, DOI 10.1109/TGRS.2013.2292826
   Djurovic I, 2004, SIGNAL PROCESS, V84, P631, DOI 10.1016/j.sigpro.2003.12.006
   Djurovic I, 2017, SIGNAL PROCESS, V135, P48, DOI 10.1016/j.sigpro.2016.12.027
   Dong XJ, 2018, IEEE SENS J, V18, P3734, DOI 10.1109/JSEN.2018.2812848
   Doweck Y, 2015, IEEE T SIGNAL PROCES, V63, P1765, DOI 10.1109/TSP.2015.2391075
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   Feng ZP, 2011, J SOUND VIB, V330, P1225, DOI 10.1016/j.jsv.2010.09.030
   Firat H, 2022, REMOTE SENS APPL, V25, DOI 10.1016/j.rsase.2022.100694
   Flandrin P, 2001, PROC SPIE, V4391, P161, DOI 10.1117/12.421196
   Guillemain P, 1996, P IEEE, V84, P561, DOI 10.1109/5.488700
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Ioana C, 2010, APPL ACOUST, V71, P1070, DOI 10.1016/j.apacoust.2010.04.009
   Ioana C, 2010, IEEE T SIGNAL PROCES, V58, P4093, DOI 10.1109/TSP.2010.2048102
   Josephson J.R., 1994, ABDUCTIVE INFERENCE
   Khan NA, 2022, SIGNAL PROCESS, V195, DOI 10.1016/j.sigpro.2022.108494
   Khan NA, 2019, CIRC SYST SIGNAL PR, V38, P2227, DOI 10.1007/s00034-018-0960-z
   Khan NA, 2019, SIGNAL IMAGE VIDEO P, V13, P517, DOI 10.1007/s11760-018-1377-7
   Khan NA, 2016, INT J ADAPT CONTROL, V30, P429, DOI 10.1002/acs.2583
   Li P, 2020, CIRC SYST SIGNAL PR, V39, P3105, DOI 10.1007/s00034-019-01314-8
   Li P, 2018, SIGNAL IMAGE VIDEO P, V12, P171, DOI 10.1007/s11760-017-1143-2
   Lyonnet B, 2010, IEEE RAD CONF, P915, DOI 10.1109/RADAR.2010.5494489
   Mallat S., 1998, WAVELET TOUR SIGNAL
   Meignen S, 2022, IEEE T SIGNAL PROCES, V70, P216, DOI 10.1109/TSP.2021.3137080
   Mohammadi M, 2018, CIRC SYST SIGNAL PR, V37, P3154, DOI 10.1007/s00034-018-0802-z
   Njirjak M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10060965
   Pan PP, 2023, IEEE T NEUR NET LEAR, V34, P9274, DOI 10.1109/TNNLS.2022.3157723
   Pham DH, 2017, IEEE T SIGNAL PROCES, V65, P3168, DOI 10.1109/TSP.2017.2686355
   Rankine L, 2007, SIGNAL PROCESS, V87, P1234, DOI 10.1016/j.sigpro.2006.10.013
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shi Y., 2019, P 2019 IOP C SER EAR, V384
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stankovic L, 1999, IEEE T SIGNAL PROCES, V47, P1099, DOI 10.1109/78.752607
   Stankovic L, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL VI, PROCEEDINGS, P121
   Stankovic L, 2002, IEEE SIGNAL PROC LET, V9, P286, DOI 10.1109/LSP.2002.803409
   Stankovic L, 2018, SIGNAL PROCESS, V142, P468, DOI 10.1016/j.sigpro.2017.08.001
   Stankovic L, 2015, IEEE T AERO ELEC SYS, V51, P1155, DOI 10.1109/TAES.2014.140098
   Sucic V, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-125
   Swärd J, 2016, IEEE T SIGNAL PROCES, V64, P1798, DOI 10.1109/TSP.2015.2507538
   Upadhyay A, 2020, CIRC SYST SIGNAL PR, V39, P6316, DOI 10.1007/s00034-020-01487-7
   Wang G, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2015.2450196
   WOOD JC, 1994, IEEE T SIGNAL PROCES, V42, P3166, DOI 10.1109/78.330375
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Yang Y, 2015, IEEE SIGNAL PROC LET, V22, P1373, DOI 10.1109/LSP.2014.2377038
   Yang Y, 2014, IEEE T INSTRUM MEAS, V63, P3169, DOI 10.1109/TIM.2014.2313961
   Yu G, 2017, IEEE T IND ELECTRON, V64, P8042, DOI 10.1109/TIE.2017.2696503
   Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102
   Zhang HJ, 2015, IEEE T AERO ELEC SYS, V51, P326, DOI 10.1109/TAES.2014.130554
   Zhang Q, 2008, IEEE T GEOSCI REMOTE, V46, P291, DOI 10.1109/TGRS.2007.907105
   Zhu XX, 2020, CIRC SYST SIGNAL PR, V39, P2574, DOI 10.1007/s00034-019-01278-9
   Zhu XX, 2020, DIGIT SIGNAL PROCESS, V104, DOI 10.1016/j.dsp.2020.102783
   Zhu XX, 2019, MECH SYST SIGNAL PR, V115, P720, DOI 10.1016/j.ymssp.2018.06.047
NR 80
TC 0
Z9 0
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104812
DI 10.1016/j.imavis.2023.104812
EA SEP 2023
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA T8PK3
UT WOS:001080546700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ding, YQ
   Sun, YP
   Li, ZC
AF Ding, Yuqing
   Sun, Yanpeng
   Li, Zechao
TI Who is partner: A new perspective on data association of multi-object
   tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Data association; Multi -object tracking; Kalman filter
ID PERFORMANCE
AB Occlusion problem refers to the challenge of accurately tracking blocked or occluded objects. It occurs when mul-tiple objects are moving nearby or overlapping with each other in the scene. Despite its frequent occurrence in multi-object tracking (MOT) tasks, occlusion is often overlooked by researchers. This paper proposes a simple and effective method to partially solve the occlusion problems of multi-object tracking by developing the Partner Mining Module (PMM) and the Partner Updating Module (PUM). The PMM module mines the space relationship between objects, and the PUM module uses the relationship obtained by the PMM module to update lost tracklets' positions. Importantly, these two modules can be integrated into existing data association-based multi-object tracking methods without any additional training expenses. Furthermore, this study proposes novel methods for computing measurement uncertainty to enhance trajectory accuracy. Experiments conducted on MOT16 and MOT17 datasets show the effectiveness of the proposed modules. Integration of PMM and PUM into original methods substantially enhances the IDF1 score by 1 point.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Ding, Yuqing; Sun, Yanpeng; Li, Zechao] Nanjing Univ Sci & Technol, Nanjing 210014, Peoples R China.
C3 Nanjing University of Science & Technology
RP Li, ZC (corresponding author), Nanjing Univ Sci & Technol, Nanjing 210014, Peoples R China.
EM zechao.li@njust.edu.cn
FU National Natural Science Foundation of China [U21B2043];  [U20B2064]
FX <B>Declaration of Competing Interest</B> This work was partially
   supported by the National Natural Science Foundation of China (Grant No.
   U20B2064 and U21B2043) .
CR Aharon N, 2022, Arxiv, DOI [arXiv:2206.14651, DOI 10.48550/ARXIV.2206.14651]
   Ali I, 2012, IMAGE VISION COMPUT, V30, P966, DOI 10.1016/j.imavis.2012.08.013
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Brasó G, 2020, PROC CVPR IEEE, P6246, DOI 10.1109/CVPR42600.2020.00628
   Cai JR, 2022, PROC CVPR IEEE, P8080, DOI 10.1109/CVPR52688.2022.00792
   Cao JK, 2023, Arxiv, DOI arXiv:2203.14360
   Chen C, 2023, IEEE T INTELL TRANSP, V24, P13023, DOI 10.1109/TITS.2022.3232153
   Chu P, 2021, Arxiv, DOI arXiv:2104.00194
   Dendorfer P, 2021, INT J COMPUT VISION, V129, P845, DOI 10.1007/s11263-020-01393-0
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Fuentes LM, 2006, IMAGE VISION COMPUT, V24, P1165, DOI 10.1016/j.imavis.2005.06.006
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Han SD, 2022, NEUROCOMPUTING, V476, P75, DOI 10.1016/j.neucom.2021.12.104
   Jinlong Peng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P145, DOI 10.1007/978-3-030-58548-8_9
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kumar A, 2021, JRDB ACT WORKSHOP CV
   Li Shuai, 2022, P IEEECVF C COMPUTER, P8855
   Li Z., 2023, IEEE T NEUR NET LEAR
   Li ZC, 2022, IEEE T PATTERN ANAL, V44, P9904, DOI 10.1109/TPAMI.2021.3132068
   Liang C, 2022, AAAI CONF ARTIF INTE, P1546
   Liang C, 2022, Arxiv, DOI arXiv:2010.12138
   Lou J, 2023, IEEE Trans. Neural Netw. Learn. Syst., V34, P2162
   Lv YJ, 2022, IEEE T INF FOREN SEC, V17, P3254, DOI 10.1109/TIFS.2022.3202119
   Magee DR, 2004, IMAGE VISION COMPUT, V22, P143, DOI 10.1016/S0262-8856(03)00145-8
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Saleh F, 2021, PROC CVPR IEEE, P14324, DOI 10.1109/CVPR46437.2021.01410
   Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007
   Shao S, 2018, Arxiv, DOI [arXiv:1805.00123, DOI 10.48550/ARXIV.1805.00123]
   Shuai B, 2021, PROC CVPR IEEE, P12367, DOI 10.1109/CVPR46437.2021.01219
   Song YM, 2019, IEEE ACCESS, V7, P165103, DOI 10.1109/ACCESS.2019.2953276
   Stadler D, 2022, IEEE WINT CONF APPL, P133, DOI 10.1109/WACVW54805.2022.00019
   Sun P., 2020, arXiv
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Sundararaman R, 2021, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR46437.2021.00386
   Wang Q, 2021, PROC CVPR IEEE, P3875, DOI 10.1109/CVPR46437.2021.00387
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu JL, 2021, PROC CVPR IEEE, P12347, DOI 10.1109/CVPR46437.2021.01217
   Wu YR, 2023, ACM T EMBED COMPUT S, V22, DOI 10.1145/3587038
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Yang F, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104091
   Yu E, 2021, Arxiv, DOI arXiv:2105.04322
   Zeng FG, 2022, LECT NOTES COMPUT SC, V13687, P659, DOI 10.1007/978-3-031-19812-0_38
   Zhang S, P IEEE C COMPUTER VI, P3213
   Zhang YF, 2022, LECT NOTES COMPUT SC, V13682, P1, DOI 10.1007/978-3-031-20047-2_1
   Zhang YF, 2022, LECT NOTES COMPUT SC, V13682, P22, DOI 10.1007/978-3-031-20047-2_2
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zheng LY, 2021, PROC CVPR IEEE, P2453, DOI 10.1109/CVPR46437.2021.00248
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
NR 55
TC 1
Z9 1
U1 4
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104737
DI 10.1016/j.imavis.2023.104737
EA JUN 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Q7BS0
UT WOS:001059044900001
DA 2024-07-18
ER

PT J
AU Rao, PS
   Parida, P
   Sahu, G
   Dash, S
AF Rao, P. Sankara
   Parida, Priyadarsan
   Sahu, Gupteswar
   Dash, Sonali
TI A multi-view human gait recognition using hybrid whale and gray wolf
   optimization algorithm with a random forest classifier
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gait recognition; Gradient gait energy image; Hybrid whale and gray wolf
   optimization algo; rithm; And random forest classifier
ID SENSOR DATA; MODEL; SELECTION; MOTION
AB Gait recognition has become one of the furthest promising behavioral biometric techniques for identifying individuals. Gait recognition models are capable of identifying humans at a distance based on their walking manner without their permission or interference. However, it is usually noted that the performance of a gait recognition approach will drop drastically in the presence of covariates such as carrying conditions, clothing conditions, and variations in the view angle. Therefore, it is necessary to develop a robust gait recognition system in order to identify the most significant gait features. In this paper, we introduced a recently developed hybrid whale and gray wolf optimization algorithm (WGWOA) for determining the optimal subset of gait features by combining the advantages of whale optimization and gray wolf optimization techniques. Moreover, we employed principal component analysis (PCA) to extract the essential gait features from the gradient gait energy image (GGEI) and random forest (RF) approach to classify the optimal gait features. The proposed method has been assessed on the publicly available largest multi-view CASIA-B and OU-MVLP benchmark datasets. Experimental results indicate that the proposed model achieved an accuracy of 99.25%, 98.39%, and 97.97% under normal, carrying a bag and wearing coat walking conditions, respectively on the CASIA-B dataset. Furthermore, the proposed model achieved an accuracy of 97.63% under normal conditions on the OU-MVLP dataset. The comparative results also confirm that the proposed algorithm is superior to the contemporary approaches.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Rao, P. Sankara; Parida, Priyadarsan] GIET Univ, Dept Elect & Commun Engn, Gunupur 765022, Odisha, India.
   [Rao, P. Sankara; Sahu, Gupteswar] Raghu Engn Coll, Dept Elect & Commun Engn, Visakhapatnam 531162, Andhra Pradesh, India.
   [Dash, Sonali] Chandigarh Univ, Dept Comp Sci Engn, Chandigarh 140413, Punjab, India.
C3 GIET University; Chandigarh University
RP Parida, P (corresponding author), GIET Univ, Dept Elect & Commun Engn, Gunupur 765022, Odisha, India.
EM priyadarsanparida@giet.edu
RI Parida, Priyadarsan/E-1204-2019; PALLA, Dr. SANKARA RAO/HZM-0829-2023
OI Parida, Priyadarsan/0000-0002-6071-764X; PALLA, Dr. SANKARA
   RAO/0000-0002-9070-9333
CR Ababneh J, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/3517145
   Ahmed K, 2023, SIGNAL IMAGE VIDEO P, V17, P925, DOI 10.1007/s11760-022-02217-z
   Almomani A, 2019, MACHINE LEARNING COM, P184, DOI [10.1201/9780429504044-8, DOI 10.1201/9780429504044-8]
   Amirsadri S, 2018, NEURAL COMPUT APPL, V30, P3707, DOI 10.1007/s00521-017-2952-5
   Arora P, 2015, PATTERN RECOGN LETT, V68, P336, DOI 10.1016/j.patrec.2015.05.016
   Awad A., 2018, BIOMETRIC BASED PHYS, P387, DOI [10.1007/978-3-319-98734-7_15, DOI 10.1007/978-3-319-98734-7_15]
   Balli S, 2019, MEAS CONTROL-UK, V52, P37, DOI 10.1177/0020294018813692
   Begum N, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13090231
   Beibei L., P 32 BRIT MACH VIS C, P1
   Beibei L., IEEE INT C COMP VIS, P14648
   Berezniker A. V., 2021, Moscow University Computational Mathematics and Cybernetics, P135, DOI 10.3103/S027864192104004X
   Binsaadoon AG, 2016, 2016 WORLD SYMPOSIUM ON COMPUTER APPLICATIONS & RESEARCH (WSCAR), P59, DOI 10.1109/WSCAR.2016.29
   Chao Fan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14213, DOI 10.1109/CVPR42600.2020.01423
   Chao HQ, 2022, IEEE T PATTERN ANAL, V44, P3467, DOI 10.1109/TPAMI.2021.3057879
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Chtourou I, 2018, PROCEDIA COMPUT SCI, V126, P759, DOI 10.1016/j.procs.2018.08.010
   Dudek G, 2015, ADV INTELL SYST COMP, V323, P821, DOI 10.1007/978-3-319-11310-4_71
   Dupuis Y, 2013, IMAGE VISION COMPUT, V31, P580, DOI 10.1016/j.imavis.2013.04.001
   Fandy I.P., INT C INF COMP 2020, P1, DOI [10.1109/ICIC50835.2020.9288653, DOI 10.1109/ICIC50835.2020.9288653]
   Gao FR, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/6693206
   Gao ZM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/2981282
   Gul S, 2021, EXPERT SYST APPL, V179, DOI 10.1016/j.eswa.2021.115057
   Guru VGM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1367, DOI 10.1109/CCAA.2016.7813931
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hema M., 2020, International Journal of Advanced Science and Technology, V29, P2684, DOI [10.1109/ITNEC56291.2023.10082363, DOI 10.1109/ITNEC56291.2023.10082363]
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Isaac ERHP, 2017, IEEE SIGNAL PROC LET, V24, P1188, DOI 10.1109/LSP.2017.2715179
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Khalid B., 2009, INT C IM CRIM DET PR, DOI [10.1049/ic.2009.0230, DOI 10.1049/IC.2009.0230]
   Khan A, 2022, CMC-COMPUT MATER CON, V70, P2113, DOI 10.32604/cmc.2022.018270
   Krzeszowski T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236794
   Kumar P, 2019, IEEE T FUZZY SYST, V27, P956, DOI 10.1109/TFUZZ.2018.2870590
   Luo J, 2015, INT J OPT, V2015, DOI 10.1155/2015/763908
   Ma L, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1578-z
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Masadeh Raja., 2018, Adv Syst Sci Appl, V18, P63, DOI [10.25728/assa.2018.18.2.576, DOI 10.25728/ASSA.2018.18.2.576]
   Min PP, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT), P121, DOI 10.1109/icoict.2019.8835194
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Palla SR, 2022, COMP M BIO BIO E-IV, V10, P565, DOI 10.1080/21681163.2021.2012829
   Park H, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/5755785
   Pérez-Ibarra JC, 2020, IEEE ASME INT C ADV, P1167, DOI 10.1109/AIM43001.2020.9158938
   Premalatha G, 2020, COMPUT INTELL-US, V36, P1261, DOI 10.1111/coin.12340
   Rana N, 2020, NEURAL COMPUT APPL, V32, P16245, DOI 10.1007/s00521-020-04849-z
   Rida I, 2019, IET BIOMETRICS, V8, P14, DOI 10.1049/iet-bmt.2018.5063
   Rida I, 2016, IEEE SIGNAL PROC LET, V23, P154, DOI 10.1109/LSP.2015.2507200
   Saihui Hou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P382, DOI 10.1007/978-3-030-58545-7_22
   Saleem F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227584
   Singh JP, 2018, IEEE ACCESS, V6, P70497, DOI 10.1109/ACCESS.2018.2879896
   Song CF, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106988
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Tafazzoli F, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013036
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Teng ZJ, 2019, SOFT COMPUT, V23, P6617, DOI 10.1007/s00500-018-3310-y
   Wang XH, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065719500278
   Wang XH, 2021, IEEE ACM T COMPUT BI, V18, P963, DOI 10.1109/TCBB.2019.2951146
   Wang XJ, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176627
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Wu X, 2023, IEEE T IMAGE PROCESS, V32, P364, DOI 10.1109/TIP.2022.3228497
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yang Y., 2022, COMPUT VIS PATTERN R, DOI 10.48550
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang ZY, 2022, IEEE T PATTERN ANAL, V44, P345, DOI 10.1109/TPAMI.2020.2998790
NR 65
TC 4
Z9 4
U1 3
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104721
DI 10.1016/j.imavis.2023.104721
EA JUN 2023
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA L5HD9
UT WOS:001023564400001
DA 2024-07-18
ER

PT J
AU Umer, M
   Sadiq, S
   Alhebshi, RM
   Alsubai, S
   Al Hejaili, A
   Eshmawi, AA
   Nappi, M
   Ashraf, I
AF Umer, Muhammad
   Sadiq, Saima
   Alhebshi, Reemah M.
   Alsubai, Shtwai
   Al Hejaili, Abdullah
   Eshmawi, Ala' Abdulmajid
   Nappi, Michele
   Ashraf, Imran
TI Face mask detection using deep convolutional neural network and
   multi-stage image processing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Real-time surveillance; Biometrics; Face mask detection; Feature
   extraction; Region of interest extraction
AB Face mask detection has several applications including real-time surveillance, biometrics, etc. Face mask detec-tion is also useful for surveillance of the public to ensure face mask wearing in public places. Ensuring that people are wearing a face mask is not possible with monitoring staff; instead, automatic systems are a much better choice for face mask detection and monitoring to help manage public behaviour and contribute to restricting the outbreak of COVID-19. Despite the availability of several such systems, the lack of a real image dataset is a big hurdle to validating state-of-the-art face mask detection systems. In addition, using the simulated datasets lack the analysis needed for real-world scenarios. This study builds a new dataset namely RILFD by taking real pictures using a camera and annotating them with two labels (with mask, without mask) which are publicly available for future research. In addition, this study investigates various machine learning models and off-the-shelf deep learning models YOLOv3 and Faster R-CNN for the detection of face masks. The customized CNN models in combination with the 4 steps of image processing are proposed for face mask detection. The proposed approach outperforms other models and proved its robustness with a 97.5% of accuracy score in face mask detec-tion on the RILFD dataset and two publicly available datasets (MAFA and MOXA).& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Umer, Muhammad] Islamia Univ Bahawalpur, Dept Comp Sci & Informat Technol, Bahawalpur 63100, Pakistan.
   [Sadiq, Saima] Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Sci, Rahim Yar Khan, Pakistan.
   [Alhebshi, Reemah M.] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Sci, Jeddah, Saudi Arabia.
   [Alsubai, Shtwai] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci Al Kharj, Dept Comp Sci, POB 151, Al Kharj 11942, Saudi Arabia.
   [Al Hejaili, Abdullah] Univ Tabuk, Fac Comp & Informat Technol, Comp Sci Dept, Tabuk 71491, Saudi Arabia.
   [Eshmawi, Ala' Abdulmajid] Univ Jeddah, Coll Comp Sci & Engn, Dept Cybersecur, Jeddah, Saudi Arabia.
   [Nappi, Michele] Univ Salerno, Dept Comp Sci, Fisciano, Italy.
   [Ashraf, Imran] Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 Islamia University of Bahawalpur; Khwaja Fareed University of
   Engineering & Information Technology, Pakistan; King Abdulaziz
   University; Prince Sattam Bin Abdulaziz University; University of Tabuk;
   University of Jeddah; University of Salerno; Yeungnam University
RP Nappi, M (corresponding author), Univ Salerno, Dept Comp Sci, Fisciano, Italy.; Ashraf, I (corresponding author), Yeungnam Univ, Informat & Commun Engn, Gyongsan 38541, South Korea.
EM umersabir1996@gmail.com; s.kamrran@gmail.com; ralhebshi@kau.edu.sa;
   Sa.alsubai@psau.edu.sa; a.alhejaili@ut.edu.sa; aaeshmawi@uj.edu.sa;
   mnappi@unisa.it; imranashraf@ynu.ac.kr
RI Alhebshi, Reemah/GWQ-8527-2022; Umer, Muhammad/AAX-4594-2020; Alsubai,
   Shtwai/ABW-9013-2022; Umer, Muhammad/KHU-2339-2024
OI Alhebshi, Reemah/0000-0001-7940-059X; Umer,
   Muhammad/0000-0002-6015-9326; Alsubai, Shtwai/0000-0002-6584-7400; Umer,
   Muhammad/0009-0001-8751-6100
CR Aravind KR, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P1191, DOI 10.1109/ICISC.2018.8398993
   Asif Sohaib, 2021, 2021 4th International Conference on Artificial Intelligence and Big Data (ICAIBD), P70, DOI 10.1109/ICAIBD51990.2021.9459008
   Boateng EY, 2019, J Data Anal Inf Process, V07, P190, DOI [DOI 10.4236/JDAIP.2019.74012, 10.4236/jdaip.2019.74012]
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Bu W, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P458, DOI 10.1109/ICCIS.2017.8274819
   Cahyana Nur Heri, 2021, RSF C SERIES ENG TEC, V1, P407
   Chauhan R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P278, DOI 10.1109/ICSCCC.2018.8703316
   Chavda A, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9418207
   Chiang Daniell, 2020, FACE MASK DETECTION, V15
   Cimmino L, 2022, IEEE ACCESS, V10, P94388, DOI 10.1109/ACCESS.2022.3203579
   Costa DG, 2015, INT J HYPERTHER, P1
   Daho ME, 2015, J MED IMAG HEALTH IN, V5, P539, DOI 10.1166/jmihi.2015.1423
   Dogo EM, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL TECHNIQUES, ELECTRONICS AND MECHANICAL SYSTEMS (CTEMS), P92, DOI 10.1109/CTEMS.2018.8769211
   Edla Damodar Reddy, 2018, Procedia Computer Science, V132, P1523, DOI 10.1016/j.procs.2018.05.116
   Fan XQ, 2021, IEEE SYS MAN CYBERN, P832, DOI 10.1109/SMC52423.2021.9659271
   Feng S, 2020, LANCET RESP MED, V8, P434, DOI 10.1016/S2213-2600(20)30134-X
   GARDNER WA, 1984, SIGNAL PROCESS, V6, P113, DOI 10.1016/0165-1684(84)90013-6
   Ge SM, 2017, PROC CVPR IEEE, P426, DOI 10.1109/CVPR.2017.53
   Ho HT, 2013, IEEE T IMAGE PROCESS, V22, P1571, DOI 10.1109/TIP.2012.2233489
   Imran Molla M. M., 2021, Proceedings of the 11th National Technical Seminar on Unmanned System Technology 2019. NUSYS19. Lecture Notes in Electrical Engineering (LNEE 666), P357, DOI 10.1007/978-981-15-5281-6_25
   Jiang M., 2020, RETINAMASK FACE MASK
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Karim M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12063203
   Khalid M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082788
   Khandelwal P., 2020, Using computer vision to enhance safety of workforceinmanufacturinginapostcovidworld
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kuo CJ, 2003, IEEE T MULTIMEDIA, V5, P8, DOI 10.1109/TMM.2003.808815
   Leung NHL, 2020, NAT MED, V26, P676, DOI 10.1038/s41591-020-0843-2
   Li X, 2022, IEEE T CIRC SYST VID, V32, P1792, DOI 10.1109/TCSVT.2021.3082635
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Mahrishi M, 2021, IEEE ACCESS, V9, P143378, DOI 10.1109/ACCESS.2021.3118048
   Manzoor M, 2021, IEEE ACCESS, V9, P128359, DOI 10.1109/ACCESS.2021.3112546
   Mohan Puranjay, 2021, Innovations in Electrical and Electronic Engineering. Proceedings of ICEEE 2021. Lecture Notes in Electrical Engineering (LNEE 756), P657, DOI 10.1007/978-981-16-0749-3_52
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Nair A., 2018, INT J RECENT CONTRIB, V6, P4, DOI [10.3991/ijes.v6i4.9317, DOI 10.3991/IJES.V6I4.9317]
   Nick Todd G., 2007, V404, P273, DOI 10.1007/978-1-59745-530-5_14
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy Biparnak, 2020, Trans Indian Natl Acad Eng, V5, P509, DOI 10.1007/s41403-020-00157-z
   Saif MA, 2018, AIP CONF PROC, V2048, DOI 10.1063/1.5082126
   Scholkopf B., 1996, Artificial Neural Networks - ICANN 96. 1996 International Conference Proceedings, P47
   Sethi S, 2021, J BIOMED INFORM, V120, DOI 10.1016/j.jbi.2021.103848
   Sharaff A, 2019, ADV INTELL SYST, V924, P189, DOI 10.1007/978-981-13-6861-5_17
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Venkateswarlu I.B., 2020, 2020 IEEE 4 C INFORM, P1, DOI 10.1109/CICT51604.2020.9312083
   Wang W, 2020, MOB INF SYST, V2020, DOI 10.1155/2020/7602384
   Wang Y, 2020, FACE MASK TYPE DETEC
   Wang ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1072
   Wen CY, 2005, J FORENSIC SCI, V50, P593
   Wenyuan Liu, 2021, 2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP), P631, DOI 10.1109/ICSP51882.2021.9408671
   Wobot Intelligence, 2021, FAC MARK DET DAT
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P33, DOI 10.1016/j.patrec.2017.09.011
   Ziwei Song, 2021, 2021 IEEE Seventh International Conference on Big Data Computing Service and Applications (BigDataService), P96, DOI 10.1109/BigDataService52369.2021.00017
NR 59
TC 10
Z9 10
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2023
VL 133
AR 104657
DI 10.1016/j.imavis.2023.104657
EA MAR 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA M3OG4
UT WOS:001029300000001
DA 2024-07-18
ER

PT J
AU Yu, XY
   Yan, L
   Yang, Y
   Zhou, LB
   Ou, LL
AF Yu, Xinyi
   Yan, Ling
   Yang, Yang
   Zhou, Libo
   Ou, Linlin
TI Conditional generative data-free knowledge distillation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Data -free knowledge distillation; Generative adversarial networks;
   Model compression; Convolutional neural networks
AB Knowledge distillation has made remarkable achievements in model compression. However, most existing methods require the original training data, which is usually unavailable due to privacy and security issues. This paper proposes a conditional generative data-free knowledge distillation (CGDD) framework for training light-weight networks without real data. This framework realizes efficient knowledge distillation based on conditional image generation. Specifically, we treat the preset labels as ground truth to train a semi-supervised conditional generator. The trained generator can produce specified classes of training images. During training, we force the student model to extract the hidden knowledge in teacher feature maps, which provide crucial cues to the learn-ing process. Meanwhile, we construct an adversarial training framework to promote distillation performance. The framework will help the student model to explore larger data space. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on different datasets. Compared with other data-free works, our method obtains state-of-the-art results on CIFAR100, Caltech101, and different versions of ImageNet datasets. The codes will be released.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Yu, Xinyi; Yan, Ling; Yang, Yang; Zhou, Libo; Ou, Linlin] Zhejiang Univ Technol, Coll Informat & Engn, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Ou, LL (corresponding author), Zhejiang Univ Technol, Coll Informat & Engn, Hangzhou, Zhejiang, Peoples R China.
EM yuxy@zjut.edu.cn; lingyan@zjut.edu.cn; yangyang98@zjut.edu.cn;
   libozhou@zjut.edu.cn; linlinou@zjut.edu.cn
RI Zhou, Libo/AAP-5373-2021; ou, linlin/G-7964-2012
FU National Natural Science Foundation of China [62203392]; Natural Science
   Foundation of Zhejiang Province [LY21F030018, LQ22F030021]
FX Acknowledgments This work was supported by National Natural Science
   Foundation of China (Grant No. 62203392) and Natural Science Foundation
   of Zhejiang Province (Grant No. LY21F030018 and No. LQ22F030021) .
CR [Anonymous], MNIST DATABASE HANDW
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298965
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Ashok A., 2018, INT C LEARNING REPRE
   Bai HL, 2020, AAAI CONF ARTIF INTE, V34, P3203
   Brock A., 2018, PREPRINT
   Chebotar Y, 2016, INTERSPEECH, P3439, DOI 10.21437/Interspeech.2016-1190
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen HT, 2019, IEEE I CONF COMP VIS, P3513, DOI 10.1109/ICCV.2019.00361
   Deng J., 2009, J ALLOY COMPD, P248, DOI DOI 10.1016/j.jallcom.2006.10.076
   Denil M., 2013, P 26 INT C NEUR INF, P2148
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fang G, 2021, arXiv
   Fang GF, 2020, Arxiv, DOI arXiv:1912.11006
   Furlanello T, 2018, PR MACH LEARN RES, V80
   Gammulle H, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107039
   Gong X, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15056, DOI 10.1109/ICCV48922.2021.01480
   Lopes RG, 2017, Arxiv, DOI arXiv:1710.07535
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu J., ECAI 2020 24 EUROPEA, P1159
   Gwern, MAK AN FAC STYL
   Hahn S., 2019, P INT C REC ADV NAT, P423
   Han S, 2015, ADV NEUR IN, V28
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, COMPUT SCI, V2
   Hongxu Yin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8712, DOI 10.1109/CVPR42600.2020.00874
   Jin Y., 2021, 6 IEEE INT C COMP CO, P447, DOI DOI 10.1109/ICCCS52626.2021.9449145
   Kairouz P, 2021, FOUND TRENDS MACH LE, V14, P1, DOI 10.1561/2200000083
   Kingma Diederik P, 2014, INT C LEARNING REPRE
   Komodakis N, 2017, P ICLR
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurata G, 2018, IEEE W SP LANG TECH, P411, DOI 10.1109/SLT.2018.8639629
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li QQ, 2017, PROC CVPR IEEE, P7341, DOI 10.1109/CVPR.2017.776
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Liu YF, 2023, IEEE T PATTERN ANAL, V45, P7035, DOI 10.1109/TPAMI.2020.3001940
   Liu YA, 2021, PROC CVPR IEEE, P1512, DOI 10.1109/CVPR46437.2021.00156
   Luo L., 2020, arXiv
   Ma J., 2019, C NEURAL INFORM PROC
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191
   Nagel M, 2019, IEEE I CONF COMP VIS, P1325, DOI 10.1109/ICCV.2019.00141
   Nayak GK, 2019, PR MACH LEARN RES, V97
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Radford A., 2015, ARXIV151106434
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romero A., 2015, INT C LEARNING REPRE
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Sauer Axel, 2022, SIGGRAPH22 Conference Proceeding: Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings, DOI 10.1145/3528233.3530738
   Srinivas S., 2015, P BRIT MACH VIS C 20, DOI DOI 10.5244/C.29.31
   Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4323
   Tang JL, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401109
   Wang HJ, 2020, Cambria Sinophone Wo, P111, DOI 10.1109/CVPRW50498.2020.00020
   Wang L, 2022, IEEE T PATTERN ANAL, V44, P3048, DOI 10.1109/TPAMI.2021.3055564
   Xia W., 2022, IEEE T PATTERN ANAL, DOI 10.1109/TPAMI.2022.3181070
   Yao LW, 2021, PROC CVPR IEEE, P10170, DOI 10.1109/CVPR46437.2021.01004
   Yaohui Cai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13166, DOI 10.1109/CVPR42600.2020.01318
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Zhang GW, 2021, AUTOMAT CONSTR, V128, DOI 10.1016/j.autcon.2021.103764
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhao HR, 2022, INT J MACH LEARN CYB, V13, P1213, DOI 10.1007/s13042-021-01443-0
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
NR 66
TC 4
Z9 4
U1 2
U2 37
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2023
VL 131
AR 104627
DI 10.1016/j.imavis.2023.104627
EA FEB 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 8X2OP
UT WOS:000931857200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tang, QS
   Bai, XY
   Guo, JT
   Pan, BL
   Jiang, WM
AF Tang, Qingsong
   Bai, Xinyu
   Guo, Jinting
   Pan, Bolin
   Jiang, Wuming
TI DFAF3D:A dual-feature-aware anchor-free single-stage 3D detector for
   point clouds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dual feature aware; Deformable offset self -attention; Spatial -context
   feature extraction; 3D object detection
AB Currently, anchor-free single-stage 3D object detection methods based on point clouds have attracted extensive attention due to their high efficiency. It is crucial to enhance the ability of the center features to represent the ob-ject for such methods. In this paper, we propose a dual spatial-context feature extraction (SCFE) module to ex-tract both spatial and context features of point clouds in parallel for 3D object detection, in which, we design a deformable offset self-attention (DOSA) structure in the context feature extraction branch to learn the relative structure information of point clouds. Correspondingly, we design a coordinate attentional feature fusion (CAFF) module, which adaptively fuses spatial and context features of different resolutions while preserving co-ordinate information thus making the features of center point more representative. Experiments on KITTI dem-onstrate that the proposed method outperforms all previous anchor-free methods in general and has comparable performance to anchor-based methods in comprehensive performance and it achieves good trade-offs in terms of accuracy, speed and parameter size. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Tang, Qingsong; Bai, Xinyu; Guo, Jinting; Pan, Bolin] Northeastern Univ, Coll Sci, Dept Math, Shenyang 110819, Liaoning, Peoples R China.
   [Jiang, Wuming] Beijing Eyecool Technol Co Ltd, Beijing 100089, Peoples R China.
C3 Northeastern University - China
RP Tang, QS (corresponding author), Northeastern Univ, Coll Sci, Dept Math, Shenyang 110819, Liaoning, Peoples R China.
EM tangqs@mail.neu.edu.cn
RI Jiang, Wuming/HJH-8495-2023
CR Bhattacharyya P, 2021, IEEE INT CONF COMP V, P3022, DOI 10.1109/ICCVW54120.2021.00337
   Chen YL, 2019, IEEE I CONF COMP VIS, P9774, DOI [10.1109/iccv.2019.00987, 10.1109/ICCV.2019.00987]
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai YM, 2021, IEEE WINT CONF APPL, P3559, DOI 10.1109/WACV48630.2021.00360
   Ge RZ, 2021, Arxiv, DOI arXiv:2107.14342
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Graham B, 2015, Arxiv, DOI arXiv:1505.02890
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   He Chenhang, P IEEE CVF C COMPUTE, P11873
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He YQ, 2021, NEUROCOMPUTING, V459, P201, DOI 10.1016/j.neucom.2021.06.046
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Jiang-Jiang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10093, DOI 10.1109/CVPR42600.2020.01011
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li JL, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4622, DOI 10.1145/3474085.3475314
   Li JL, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P553, DOI 10.1145/3474085.3475208
   Liu Z, 2020, AAAI CONF ARTIF INTE, V34, P11677
   Liu ZL, 2020, AAAI CONF ARTIF INTE, V34, P11685
   Qi CR, 2017, ADV NEUR IN, V30
   Qi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P68, DOI 10.1007/978-3-030-58589-1_5
   Qian R, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108796
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Shi Shaoshuai, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P10529
   Smith LN, 2019, PROC SPIE, V11006, DOI 10.1117/12.2520589
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Guojun, 2022, 8TH23 IEEE T INTELL, P953
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Ye YY, 2020, NEUROCOMPUTING, V379, P53, DOI 10.1016/j.neucom.2019.09.086
   Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zheng W, 2021, AAAI CONF ARTIF INTE, V35, P3555
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 43
TC 4
Z9 4
U1 2
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104594
DI 10.1016/j.imavis.2022.104594
EA DEC 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7S6FQ
UT WOS:000910848000006
DA 2024-07-18
ER

PT J
AU Albraikan, AA
   Alzahrani, JS
   Alshahrani, R
   Yafoz, A
   Alsini, R
   Hilal, AM
   Alkhayyat, A
   Gupta, D
AF Albraikan, Amani Abdulrahman
   Alzahrani, Jaber S.
   Alshahrani, Reem
   Yafoz, Ayman
   Alsini, Raed
   Hilal, Anwer Mustafa
   Alkhayyat, Ahmed
   Gupta, Deepak
TI Intelligent facial expression recognition and classification using
   optimal deep transfer learning model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Deep learning; Mask RCNN; Face detection;
   Machine learning; Adam optimizer
ID EMOTION RECOGNITION
AB Facial expression is commonly utilized by humans to deliver their mood and emotional state to other people. Fa-cial expression recognition (FER) becomes a hot research area in recent days, and it is a tedious process owing to the presence of high intra-class variation. The conventional methods for FEC are mainly based on handcrafted fea-tures with a classification model trained on image or video datasets. Since the facial datasets involve large vari-ations in the images and comprise partial faces, it is needed to design automated FER models. The latest advancements in artificial intelligence (AI) and deep learning (DL) models find useful for better understanding of facial emotions related to face images. In this aspect, this paper presents an intelligent FER using optimal deep transfer learning (IFER-DTFL) model. The proposed IFER-DTFL technique aims to detect the face and identify the facial expressions automatically. The IFER-DTFL technique encompasses a three state process: face detection, feature extraction, and expression classification. In addition, a mask RCNN model is used for the detection of faces. Moreover, the Adam optimizer with Densely Connected Networks (DenseNet121) model is employed for feature extraction process. Furthermore, the weighted kernel extreme learning machine (WKELM) model is utilized to classify the facial expressions. A comprehensive set of simulations were carried out on benchmark dataset and the results are inspected under varying aspects. The experimental results pointed out the supremacy of the IFER-DTFL technique over the other recent techniques interms of several performance measures.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Albraikan, Amani Abdulrahman] Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Comp Sci, POB 84428, Riyadh 11671, Saudi Arabia.
   [Alzahrani, Jaber S.] Umm Al Qura Univ, Coll Engn Alqunfudah, Dept Ind Engn, Mecca, Saudi Arabia.
   [Alshahrani, Reem] Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, POB 11099, Taif 21944, Saudi Arabia.
   [Yafoz, Ayman; Alsini, Raed] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Syst, Jeddah, Saudi Arabia.
   [Hilal, Anwer Mustafa] Prince Sattam bin Abdulaziz Univ, Dept Comp & Self Dev, Preparatory Year Deanship, Alkharj, Saudi Arabia.
   [Alkhayyat, Ahmed] Islamic Univ, Coll Tech Engn, Najaf, Iraq.
   [Gupta, Deepak] Maharaja Agrasen Inst Technol, Dept Comp Sci & Engn, Delhi, India.
   [Gupta, Deepak] Chandigarh Univ, UCRD, Mohali, Punjab, India.
C3 Princess Nourah bint Abdulrahman University; Umm Al Qura University;
   Taif University; King Abdulaziz University; Prince Sattam Bin Abdulaziz
   University; Islamic University College; Maharaja Agrasen Institute of
   Technology; Chandigarh University
RP Gupta, D (corresponding author), Maharaja Agrasen Inst Technol, Dept Comp Sci & Engn, Delhi, India.
EM deepakgupta@mait.ac.in
RI Gupta, Deepak/AAV-2728-2020; Alsini, Raed/AEG-9852-2022; Alzahrani,
   Jaber/AGX-4231-2022; alkhayyat, ahmed/B-6434-2018; Yafoz,
   Ayman/GNW-2880-2022; Hilal, Anwer Mustafa/ABF-7667-2021; Albraikan,
   Amani/JKJ-4955-2023
OI Gupta, Deepak/0000-0002-3019-7161; Alsini, Raed/0000-0002-3163-575X;
   alkhayyat, ahmed/0000-0002-1270-4713; Yafoz, Ayman/0000-0003-0320-2583;
   Albraikan, Amani/0000-0001-9678-9744
FU Princess Nourah bint Abdulrahman University Researchers Supporting
   Project [PNURSP2022R191]; Princess Nourah bint Abdulrahman University,
   Riyadh, Saudi Arabia; Deanship of Scientific Research at Umm Al-Qura
   University [22UQU4340237DSR53]; Taif University, Taif, Saudi Arabia.
   [TURSP-2020/346]
FX Princess Nourah bint Abdulrahman University Researchers Supporting
   Project number (PNURSP2022R191), Princess Nourah bint Abdulrahman
   University, Riyadh, Saudi Arabia. The authors would like to thank the
   Deanship of Scientific Research at Umm Al-Qura University for supporting
   this work by Grant Code: 22UQU4340237DSR53. Taif University Researchers
   Supporting Project number (TURSP-2020/346), Taif University, Taif, Saudi
   Arabia.
CR Akhand MAH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091036
   Alreshidi A, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7010006
   [Anonymous], 2017, IN P IEEE C COMPUTER
   Ekman P., 2006, Darwin and facial expression a century of research in review, P169
   Fernández-Caballero A, 2016, J BIOMED INFORM, V64, P55, DOI 10.1016/j.jbi.2016.09.015
   Giannopoulos P., 2018, ADV HYBRIDIZATION IN, P1, DOI DOI 10.1007/978-3-319-66790-4_1
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Kim JH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062026
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Mellouk W., 2020, Procedia Computer Science, V175, P689, DOI [DOI 10.1016/J.PROCS.2020.07.101, 10.1016/j.procs.2020.07.101]
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mollahosseini A., 2022, P 2016 IEEE WINT C A, P1
   O'Toole AJ, 2005, IEEE T PATTERN ANAL, V27, P812, DOI 10.1109/TPAMI.2005.90
   Rescigno M, 2020, MULTIMED TOOLS APPL, V79, P35811, DOI 10.1007/s11042-020-09405-4
   Sarvakar K., 2021, MATER TODAY-PROC
   Sepas-Moghaddam A, 2020, INT CONF ACOUST SPEE, P3367, DOI [10.1109/icassp40776.2020.9053919, 10.1109/ICASSP40776.2020.9053919]
   Siddiqui MFH, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4030046
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Su SSW, 2021, J MATH-UK, V2021, DOI 10.1155/2021/8892636
   Suchitra P.S., 2022, P 2016 3 INT C SIGNA, P666
   Thonse U, 2018, PSYCHIAT RES, V264, P354, DOI 10.1016/j.psychres.2018.03.027
   Xu CC, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/5761414
   Yaddaden Y., 2022, P 9 ACM INT C PERVAS, V16, P1
   Yu XM, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030508
NR 24
TC 5
Z9 5
U1 7
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104583
DI 10.1016/j.imavis.2022.104583
EA NOV 2022
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500005
DA 2024-07-18
ER

PT J
AU Aziere, N
   Todorovic, S
AF Aziere, Nicolas
   Todorovic, Sinisa
TI Multistage temporal convolution transformer for action segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action segmentation; Video understanding; Full supervision; Transformer
   network; Hybrid models; CNNs
AB This paper addresses fully supervised action segmentation. Transformers have been shown to have large model capacity and powerful sequence modeling abilities, and hence seem quite suitable for capturing action grammar in videos. However, their performance in video understanding still lags behind that of temporal convolutional networks, or ConvNets for short. We hypothesize that this is because: (i) ConvNets tend to generalize better than Transformers, and (ii) Transformer's large model capacity requires significantly larger training datasets than existing action segmentation benchmarks. We specify a new hybrid model, TCTr, that combines the strengths from both frameworks. TCTr seamlessly unifies depth-wise convolution and self-attention in a principled manner. Also, TCTr addresses the Transformer's quadratic computational and memory complexity in the sequence length by learning how to adaptively estimate attention from local temporal neighborhoods, instead of all frames. Our experiments show that TCTr significantly outperforms the state of the art on the Breakfast, GTEA, and 50Salads datasets.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Aziere, Nicolas; Todorovic, Sinisa] Oregon State Univ, Corvallis, OR 97331 USA.
C3 Oregon State University
RP Aziere, N (corresponding author), Oregon State Univ, Corvallis, OR 97331 USA.
EM azieren@oregonstate.edu; sinisa@oregonstate.edu
CR Ahn H., 2021, P IEEE INT C COMPUTE, P16302
   [Anonymous], 2022, IMAGE VISION COMPUT, V128
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen M.-H., 2020, CVPR, V8, P9
   Dai Z., 2021, CORR, V1, P3
   Ding L., 2018, CVPR, V2, P3
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Farha Y.A., 2019, CVPR, V1
   Fathi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3281, DOI 10.1109/CVPR.2011.5995444
   Gao SH, 2021, PROC CVPR IEEE, P16800, DOI 10.1109/CVPR46437.2021.01653
   Ishikawa Y, 2021, IEEE WINT CONF APPL, P2321, DOI 10.1109/WACV48630.2021.00237
   Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Lei P, 2018, PROC CVPR IEEE, P6742, DOI 10.1109/CVPR.2018.00705
   Li J, 2021, PROC CVPR IEEE, P12623, DOI 10.1109/CVPR46437.2021.01244
   Li S.-J., 2020, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2020.30217562, DOI 10.1109/TPAMI.2020.30217562]
   Liu Z., 2021, arXiv
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loukas A., 2020, IBER CONF INF SYST, DOI DOI 10.23919/cisti49556.2020.9141108
   Singhania D., 2021, CVPR, V1
   Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482
   Wang D., 2021, AAAI, V35, P9
   Wang YQ, 2021, PROC CVPR IEEE, P8737, DOI 10.1109/CVPR46437.2021.00863
   Wang Z., 2020, ECCV, V3, P9
   Wu HP, 2021, Arxiv, DOI [arXiv:2103.15808, DOI 10.48550/ARXIV.2103.15808]
   Yi Fangqiu, 2021, BMVC
   Zaheer Muhammad Zaigham, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P358, DOI 10.1007/978-3-030-58542-6_22
NR 27
TC 9
Z9 9
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104567
DI 10.1016/j.imavis.2022.104567
EA OCT 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6A7AA
UT WOS:000880802600003
DA 2024-07-18
ER

PT J
AU Wang, L
   Huang, S
   Huangfu, LW
   Liu, B
   Zhang, XH
AF Wang, Lei
   Huang, Sheng
   Huangfu, Luwen
   Liu, Bo
   Zhang, Xiaohong
TI Multi-label out-of-distribution detection via exploiting sparsity and
   co-occurrence of labels
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi -label learning; Out -of -distribution detection; Image
   classification; Sparse learning; Label co -occurrence
ID SEGMENTATION
AB Although Out-Of-Distribution (OOD) detection has been extensively studied, the OOD detection under multi -label settings, which is closer to the real world, is still in its infancy. The pioneer work ignores some unique prop-erties of multi-label images, such as the sparsity and co-occurrence of labels. Here, we empirically observe that these properties readily distinguish OOD and in-distribution data. Motivated by this observation, we propose a novel multi-label OOD detection approach named Sparse Label Co-occurrence Scoring (SLCS) to exploit the spar-sity and co-occurrence information of labels. SLCS follows conventions and deems the logits outputted by the penultimate layer of the trained multi-label image classification model as the prediction confidences of a sample to categories in the training label set. A logit sparse filtering process is employed to filter out the low-confidence logits for avoiding the interference of low-confidence predictions while preserving the high-confidence logits to obtain the label sparsity. Then, the label co-occurrence pairs are counted for each sample based on its predicted categories and the label co-occurrence matrix constructed on the training set. Finally, the preserved logits are weighted by the label co-occurrence information and accumulated to produce the OOD detection score for each sample. Extensive experimental results on three well-known multi-label image datasets demonstrate the discriminating power of SLCS, which achieves greatly improved performances compared with the only multi -label OOD detection approach - JointEnergry and the state-of-the-art single-label OOD detection approaches. The performance improvements of SLCS over JointEnergy in FPR95 are 12.85%, 12.41%, and 9.50% on MS-COCO, VOC 2012, and NUS-WIDE datasets respectively. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Wang, Lei; Huang, Sheng; Zhang, Xiaohong] Chongqing Univ, Sch Big Data & Software Engn, Chonqqing 400044, Peoples R China.
   [Huang, Sheng; Zhang, Xiaohong] Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400044, Peoples R China.
   [Huangfu, Luwen] San Diego State Univ, Fowler Coll Business, San Diego, CA 92182 USA.
   [Huangfu, Luwen] San Diego State Univ, Ctr Human Dynam Mobile Age, San Diego, CA 92182 USA.
   [Liu, Bo] Walmart Global Tech, Sunnyvale, CA 94086 USA.
C3 Chongqing University; California State University System; San Diego
   State University; California State University System; San Diego State
   University
RP Huang, S (corresponding author), Chongqing Univ, Sch Big Data & Software Engn, Chonqqing 400044, Peoples R China.
EM wangleii@cqu.edu.cn; huangsheng@cqu.edu.cn; lhuangfu@sdsu.edu;
   kfliubo@gmail.com; xhongz@cqu.edu.cn
RI xiao, ming/KHT-1774-2024; Zhang, Yuting/JZE-2800-2024; Zhang,
   Xiaohong/A-3060-2015; Liu, Jinyu/JYQ-6274-2024
OI Huangfu, Vivian L./0000-0003-3926-7901
FU National Natural Sci- ence Foundation of China [62176030]; Natural Sci-
   ence Foundation of Chongqing [cstc2021jcyj-msxmX0568]
FX Acknowledgements Reported research is partly supported by the National
   Natural Sci- ence Foundation of China under Grant 62176030, and the
   Natural Sci- ence Foundation of Chongqing under Grant
   cstc2021jcyj-msxmX0568.
CR Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   [Anonymous], 2009, ADV NEURAL INFORM PR
   Bao SL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2079, DOI 10.1145/3343031.3350915
   Bevandic P, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104490
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Cao PP, 2021, IMAGE VISION COMPUT, V113, DOI 10.1016/j.imavis.2021.104238
   Chen BZ, 2020, IEEE J BIOMED HEALTH, V24, P2292, DOI 10.1109/JBHI.2020.2967084
   Chen JF, 2021, LECT NOTES ARTIF INT, V12977, P430, DOI 10.1007/978-3-030-86523-8_26
   Chen L, 2019, IEEE T IMAGE PROCESS, V28, P4883, DOI 10.1109/TIP.2019.2913079
   Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Deng J., 2009, J ALLOY COMPD, P248, DOI DOI 10.1016/j.jallcom.2006.10.076
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Glorot X., 2010, 13 INT C ARTIFICIAL, V9, P249
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grady L, 2004, LECT NOTES COMPUT SC, V3117, P230
   Hendrycks D, 2018, Arxiv, DOI arXiv:1610.02136
   Huang H., 2021, P WORKSHOP ARTIFICIA
   Huang R, 2021, C NEUR INF PROC SYST
   Huang R, 2021, PROC CVPR IEEE, P8706, DOI 10.1109/CVPR46437.2021.00860
   Huang S.J., 2012, 26 AAAI C ART INT, P949
   Jin Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P649, DOI 10.1007/978-3-030-58589-1_39
   Kai W., 2017, COMPRESSED SENSING B, P66
   Kristiadi A, 2020, PR MACH LEARN RES, V119
   Kukanov I, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P136, DOI 10.1109/ICASSP.2018.8461396
   Kurata G., 2016, Improved neural network-based multi-label classification with better initialization leveraging label cooccurrence, P521, DOI DOI 10.18653/V1/N16-1063
   Lakshminarayanan B, 2017, ADV NEUR IN, V30
   Lee KM, 2018, Arxiv, DOI arXiv:1711.09325
   Lee K, 2018, ADV NEUR IN, V31
   Liang SY, 2020, Arxiv, DOI [arXiv:1706.02690, DOI 10.48550/ARXIV.1706.02690]
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Lin ZQ, 2021, PROC CVPR IEEE, P15308, DOI 10.1109/CVPR46437.2021.01506
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Liu JZ, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P115, DOI 10.1145/3077136.3080834
   Liu Weitang, 2020, ADV NEURAL INFORM PR, V33, P21464
   Moeini A, 2017, IMAGE VISION COMPUT, V57, P1, DOI 10.1016/j.imavis.2016.11.002
   Mostajabi Mohammadreza, 2019, arXiv
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nam Jinseok, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8725, P437, DOI 10.1007/978-3-662-44851-9_28
   Oramas S, 2017, Arxiv, DOI arXiv:1707.04916
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Reiss S, 2021, PROC CVPR IEEE, P9527, DOI 10.1109/CVPR46437.2021.00941
   Sricharan K, 2018, Arxiv, DOI arXiv:1812.00239
   Sun YY, 2021, ADV NEUR IN, V34
   Szymanski P, 2019, J MACH LEARN RES, V20
   Tang KK, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1133, DOI 10.1109/ICCV48922.2021.00119
   Vernekar S, 2019, Arxiv, DOI [arXiv:1910.04241, 10.48550/arXiv.1910.04241]
   Wang Haoran, 2021, Advances in Neural Information Processing Systems, V34
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang XD, 2017, IMAGE VISION COMPUT, V63, P10, DOI 10.1016/j.imavis.2017.05.004
   Wei YC, 2014, Arxiv, DOI arXiv:1406.5726
   Xu X.S., 2012, SEMISUPERVISED MULTI, P737
   Yang JK, 2024, Arxiv, DOI [arXiv:2110.11334, DOI 10.48550/ARXIV.2110.11334]
   Yen-Chang Hsu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10948, DOI 10.1109/CVPR42600.2020.01096
   Zaeemzadeh A, 2021, PROC CVPR IEEE, P9447, DOI 10.1109/CVPR46437.2021.00933
   Zhao H., 2018, INT C ARTIFICIAL INT, P1943
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
   Zhu Y, 2018, IEEE T KNOWL DATA EN, V30, P1081, DOI 10.1109/TKDE.2017.2785795
NR 60
TC 3
Z9 3
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104548
DI 10.1016/j.imavis.2022.104548
EA SEP 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5S1KH
UT WOS:000874957400001
DA 2024-07-18
ER

PT J
AU Manikandan, VP
   Rahamathunnisa, U
AF Manikandan, V. P.
   Rahamathunnisa, U.
TI A neural network aided attuned scheme for gun detection in video
   surveillance images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Classification; CNN; Feature extraction; Deep learning; Object detection
ID WEAPON DETECTION
AB ABS T R A C T Closed Circuit Television (CCTV) cameras are installed and monitored in private and open spaces for security pur-poses. The video and image footages are used for rapid actions, identity, and object detection in commercial and residential security. Object and human detection require different classifications based on the features exhibited from the static/ mobile footages. This article introduces an Attuned Object Detection Scheme (AODS) for harmful object detection from CCTV inputs. The proposed scheme relies on a convolution neural network (CNN) for object detection and classification. The classification is performed based on the Object's features extracted and analyzed using CNN. The hidden layer processes are split into different feature-constraint-based analyses for identifying the Object. In the classification process, feature attenuation between the dimensional representation and segmented input is performed. Based on this process, the input is classified for hazardous objects detection. The consecutive processing layer of CNN identifies deviations in dimensional feature representation, preventing multi-object errors. The proposed scheme's performance is verified using the metrics accuracy, precision, and F1-Score.External dataset training has improved accuracy by 8.08% and reduced error and complexity by 7.47 and 8.23 percentage points, respectively, in this process. Object classification based on labels is expected to be implemented in the future.02022 Elsevier B.V. All rights reserved.
C1 [Manikandan, V. P.; Rahamathunnisa, U.] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Rahamathunnisa, U (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, India.
EM rahamathu.u@vit.ac.in
CR Ahmed AA, 2021, IEEE ACCESS, V9, P63283, DOI 10.1109/ACCESS.2021.3074319
   Ahmed I, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107489
   Bellazi KM, 2020, IEEE ACCESS, V8, P218304, DOI 10.1109/ACCESS.2020.3042699
   Bhatti MT, 2021, IEEE ACCESS, V9, P34366, DOI 10.1109/ACCESS.2021.3059170
   Cameron J, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113672
   Castillo A, 2019, NEUROCOMPUTING, V330, P151, DOI 10.1016/j.neucom.2018.10.076
   Choi JG, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115400
   Galab MK, 2021, ARAB J SCI ENG, V46, P4049, DOI 10.1007/s13369-021-05401-4
   Giveki D, 2021, INT J APPROX REASON, V135, P1, DOI 10.1016/j.ijar.2021.04.007
   Jin R, 2020, IEEE GEOSCI REMOTE S, V17, P839, DOI 10.1109/LGRS.2019.2936173
   Liu YQ, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102767
   López-Rubio E, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115150
   Maqsood R, 2021, MULTIMED TOOLS APPL, V80, P18693, DOI 10.1007/s11042-021-10570-3
   Mohtavipour SM, 2022, VISUAL COMPUT, V38, P2057, DOI 10.1007/s00371-021-02266-4
   Olmos R, 2019, INFORM FUSION, V49, P271, DOI 10.1016/j.inffus.2018.11.015
   Park J, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116508
   Premachandra C, 2021, IEEE SENS J, V21, P10752, DOI 10.1109/JSEN.2021.3059102
   Rodda A., 2020, MATER TODAY-PROC
   González JLS, 2020, NEURAL NETWORKS, V132, P297, DOI 10.1016/j.neunet.2020.09.013
   Shahbaz A, 2021, IEEE SENS J, V21, P9359, DOI 10.1109/JSEN.2021.3054940
   Sikandar T, 2019, MULTIMEDIA SYST, V25, P229, DOI 10.1007/s00530-018-0599-4
   Stainer MJ, 2021, APPL ERGON, V93, DOI 10.1016/j.apergo.2021.103383
   Sung C-S, 2021, MULTIMED TOOLS APPL, P1
   Vallez N, 2021, NEURAL COMPUT APPL, V33, P5885, DOI 10.1007/s00521-020-05365-w
   Velasco-Mata A, 2021, NEURAL COMPUT APPL, V33, P17273, DOI 10.1007/s00521-021-06317-8
   Wang DW, 2019, IEEE ACCESS, V7, P171461, DOI 10.1109/ACCESS.2019.2955995
   Xu J, 2021, MULTIMED TOOLS APPL, V80, P5495, DOI 10.1007/s11042-020-09964-6
   Xu N, 2021, NEUROCOMPUTING, V466, P113, DOI 10.1016/j.neucom.2021.09.037
NR 28
TC 4
Z9 4
U1 2
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104406
DI 10.1016/j.imavis.2022.104406
EA MAR 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0M9DZ
UT WOS:000782449300001
DA 2024-07-18
ER

PT J
AU Chai, EH
   Ta, L
   Ma, ZF
   Zhi, M
AF Chai, Enhui
   Ta, Lin
   Ma, Zhanfei
   Zhi, Min
TI ERF-YOLO: A YOLO algorithm compatible with fewer parameters and higher
   accuracy
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE The effective receptive field; The activation function; The backbone
   network; Concat; The anchor box loss function
ID NETWORKS
AB Research shows that theoretical receptive field and effective receptive field are very important to target detection results. The effective receptive field determines the contribution of different positions in the theoretical receptive field. Therefore, the main purpose of this work is to increase the effective receptive field area and reduce the number of parameters. This idea obtains a high-precision and high-speed target detector. First, the algorithm needs to optimize the activation function to improve the efficiency of feature extraction. Second, the model structure needs to select the backbone network and improve the convolutional layer structure. Then, the enhanced network requires increasing the number of the residual structures and the "Concat" to improve feature extraction performance. Finally, the network needs to combine the optimized convolutional layer and the anchor box loss function to improve the performance of the anchor box. The project designed a YOLO algorithm (ERF-YOLO) with a larger effective receptive field. The training and testing of the experiment use PASCAL VOC data set and MS COCO data set respectively. Experimental results show that the parameter of ERF-YOLO is close to half of YOLO v4. In terms of detection accuracy, ERF-YOLO is superior to many current algorithms. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Chai, Enhui; Ma, Zhanfei] Inner Mongolia Univ Sci & Technol, Baotou Teachers Coll, Baotou, Peoples R China.
   [Ta, Lin] Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
   [Zhi, Min] Inner Mongolia Teaching Univ, Baotou, Peoples R China.
C3 Inner Mongolia University of Science & Technology; Baotou Teachers
   College; Beijing University of Posts & Telecommunications
RP Ma, ZF (corresponding author), Inner Mongolia Univ Sci & Technol, Baotou Teachers Coll, Baotou, Peoples R China.
EM chai1309787302@163.com
FU National Natural Science Founda-tion of China [61762071]; Inner Mongolia
   Natural Science Foundation [2019MS06037]
FX This work was supported by the National Natural Science Founda-tion of
   China (No. 61762071) and the Inner Mongolia Natural Science Foundation
   (No. 2019MS06037) . At the same time, thanks to the re-searchers who
   provided valuable comments and assistance in the writ-ing and review of
   the paper.
CR Alexey B, 2020, COMPUTER VISION PATT
   [Anonymous], 2017, Understanding the effective receptive field in deep convolutional neural networks
   [Anonymous], 2013, ARXIV PREPRINT ARXIV, DOI [DOI 10.48550/ARXIV.1312.6229, 10.48550/arXiv.1312.6229]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dai JF, 2016, ADV NEUR IN, V29
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Kaiming H., CVPR 2015, P770
   Kim, 2020, PROBABILISTIC ANCHOR
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S., 2019, CVPR
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Mingxing T., 2019, EFFICIENTNET RETINKI
   Misra D, 2020, MISH SELF REGULARIZE
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Ramachandran P., 2017, COMPUTER SCI
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Simonyan K., 2014, CORR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan M., 2020, P 2020 IEEE CVF C CO, P10
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang C.Y., 2020, CVPR
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wang CY, 2023, J INF SCI ENG, V39, P691, DOI 10.6688/JISE.202305_39(3).0015
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang TC, 2019, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2019.00206
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang YX, 2021, PROC CVPR IEEE, P10140, DOI 10.1109/CVPR46437.2021.01001
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhou X., 2019, ARXIV190407850
NR 48
TC 12
Z9 13
U1 12
U2 97
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104317
DI 10.1016/j.imavis.2021.104317
EA NOV 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WZ2LF
UT WOS:000719802700002
DA 2024-07-18
ER

PT J
AU Zhu, XG
   Wang, HY
   Liu, PL
   Yang, ZT
   Qian, JC
AF Zhu, Xiaoguang
   Wang, Haoyu
   Liu, Peilin
   Yang, Zhantao
   Qian, Jiuchao
TI Graph-based reasoning attention pooling with curriculum design for
   content-based image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Content-based image retrieval; Graph convolutional networks; Curriculum
   design
ID FEATURES
AB Global single-pass methods have shown superior efficiency over local aggregation methods on content-based image retrieval. However, they tend to fail under challenging environments since the structural relations among regions are not exploited. To address this issue, we propose a novel Graph-based Reasoning Attention Pooling with Curriculum Design (GRAP-CD) to improve the network capability through training modification and trainable pooling. GRAP-CD can not only explore relations among salient regions but also gradually train the network to achieve better local minima. The graph-based reasoning layers regard the feature map from the last convolution layer as a graph and construct the structural relations. Then the graph-based attention layer enhances the key information guided by the relations. Besides, a front-end curriculum design is introduced to split the training dataset from simple to complex and train the model step by step, which further helps the GRAP firstly learn the basic feature information from simple samples and then learn to dig the more representative features with hard positive samples. Experimental results on popular benchmarks ROxford and RParis datasets achieve improvement over state-of-the-art global single-pass methods and competitive results with local aggregation methods. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhu, Xiaoguang; Wang, Haoyu; Liu, Peilin; Yang, Zhantao; Qian, Jiuchao] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Liu, PL (corresponding author), Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.
EM zhuxiaoguang178@sjtu.edu.cn; gogowhy@sjtu.edu.cn; liupeilin@sjtu.edu.cn;
   y2242794082@sjtu.edu.cn; jcqian@sjtu.edu.cn
RI Wang, Haoyu/AAC-8649-2019
OI Wang, Haoyu/0000-0002-2124-3453; Qian, Jiuchao/0000-0002-4313-9956; ,
   Zhantao/0000-0003-2765-295X; Zhu, Xiaoguang/0000-0001-9554-2133
FU National Natural Science Foundation of China [61903246]
FX The authors were supported by the the National Natural Science
   Foundation of China under Grant 61903246.
CR [Anonymous], 2016, P INT C LEARN REPR
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chang C, 2019, PROC CVPR IEEE, P9415, DOI 10.1109/CVPR.2019.00965
   Chen W., 2021, DEEP IMAGE RETRIEVAL
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Garcia N, 2019, IMAGE VISION COMPUT, V82, P18, DOI 10.1016/j.imavis.2019.01.001
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Hacohen G, 2019, PR MACH LEARN RES, V97
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Iscen A, 2017, PROC CVPR IEEE, P926, DOI 10.1109/CVPR.2017.105
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kim HJ, 2017, PROC CVPR IEEE, P3251, DOI 10.1109/CVPR.2017.346
   Kim J., 2018, BMVC, P209
   Kingma D. P., 2015, P INT C LEARN REPR, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   Kipf TN, 2017, INT C LEARN REPR
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Lou YH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1128, DOI 10.1145/3240508.3240602
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J., 2014, Advances in neural information processing systems
   Mishchuk A., 2017, P ADV NEURAL INFORM, P4826
   Mishkin D, 2018, LECT NOTES COMPUT SC, V11213, P287, DOI 10.1007/978-3-030-01240-3_18
   Mopuri Konda Reddy, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P62, DOI 10.1109/CVPRW.2015.7301273
   Ng Tony, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P253, DOI 10.1007/978-3-030-58595-2_16
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Radenovic F, 2018, PROC CVPR IEEE, P5706, DOI 10.1109/CVPR.2018.00598
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Revaud J, 2019, IEEE I CONF COMP VIS, P5106, DOI 10.1109/ICCV.2019.00521
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Teichmann M, 2019, PROC CVPR IEEE, P5104, DOI 10.1109/CVPR.2019.00525
   Tolias Giorgos, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P460, DOI 10.1007/978-3-030-58452-8_27
   Tolias G, 2016, INT J COMPUT VISION, V116, P247, DOI 10.1007/s11263-015-0810-4
   Tolias G, 2013, IEEE I CONF COMP VIS, P1401, DOI 10.1109/ICCV.2013.177
   Xu D, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1326, DOI 10.1145/2964284.2964329
   Yang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1513, DOI 10.1145/3123266.3123396
   Yang L., 2019, DUAL SELF PACED GRAP, P4062
   Yang TY, 2019, IEEE INT CONF COMP V, P2913, DOI 10.1109/ICCVW.2019.00353
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhu XG, 2020, IEEE SIGNAL PROC LET, V27, P1665, DOI 10.1109/LSP.2020.3024794
   Zhu YY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P99, DOI 10.1145/3240508.3240525
NR 55
TC 3
Z9 3
U1 4
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104289
DI 10.1016/j.imavis.2021.104289
EA SEP 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WC6NH
UT WOS:000704372400001
DA 2024-07-18
ER

PT J
AU Zhang, ZQ
   Luo, YM
   Gou, J
AF Zhang, Zhiqian
   Luo, Yanmin
   Gou, Jin
TI Double anchor embedding for accurate multi-person 2D pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Double anchor embedding; Ghost joint suppression; Greedy joint
   inference; Multi-person pose estimation
AB Multi-person pose estimation is an important field in computer vision. Due to the lower time complexity, the bottom-up approaches have recently received more attention in multi-person 2D pose estimation, however, they are more sensitive to challenges in real-world scenarios. In this paper, we propose a multi-person pose estimation algorithm based on the Double Anchor Embedding (DAE), which shows that bottom-up algorithms are still competitive in precision. Firstly, for reducing the modeling difficulty of the detection task we divide the human joints into upper and lower half groups which are internally continuous and highly correlated. Accordingly, a novel joint affinity cue, called Double Anchor Embedding is designed, which can help the network effectively extract the information of both local contexts and global contexts, so that can better cope with occluded scenes and complex postures. Secondly, the parallel greedy joint inference algorithm is proposed to alleviate the mismatching problem of distant joints in the post-processing stage, which can also accelerate the matching process to some extent. Extensive experiments on two challenging datasets demonstrate the effectiveness and potential of our proposed framework, which is comparable to the current state-of-the-art methods.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhang, Zhiqian; Luo, Yanmin; Gou, Jin] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Zhang, Zhiqian; Luo, Yanmin; Gou, Jin] Huaqiao Univ, Xiamen Key Lab Comp Vis & Pattern Recognit, Xiamen 361021, Peoples R China.
C3 Huaqiao University; Huaqiao University
RP Luo, YM (corresponding author), Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
EM zqzhang@stu.hqu.edu.cn; lym@hqu.edu.cn; goujin@hqu.edu.cn
RI Zhang, Zhiqian/P-7746-2018
OI Zhang, Zhiqian/0000-0003-1226-4807
FU Science and Technology Bureau of Quanzhou [2018C113R]; Natural Science
   Foundation of Fujian Province China [2020J01082]; Subsidized Project for
   Postgraduates' Innovative Fund in Scientific Research of Huaqiao
   University [18013083026, 61901183]
FX This work was supported by the Science and Technology Bureau of Quanzhou
   under Grant 2018C113R, in part by Natural Science Foundation of Fujian
   Province China under Grant 2020J01082, in part by the Subsidized Project
   for Postgraduates' Innovative Fund in Scientific Research of Huaqiao
   University under Grant 18013083026, and in part by theNational Natural
   Science Foundation of China under Grant 61901183.
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   [Anonymous], 2017, P 31 INT C NEUR INF
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen Y., P IEEE INT C COMP VI, P2353
   Chen YC, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102897
   Cheng B., P IEEE C COMP VIS PA, P5386
   Dang Q, 2019, TSINGHUA SCI TECHNOL, V24, P663, DOI 10.26599/TST.2018.9010100
   Ding YH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3369393
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Fieraru M, 2018, IEEE COMPUT SOC CONF, P318, DOI 10.1109/CVPRW.2018.00058
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Insafutdinov E, 2017, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2017.142
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Iqbal U, 2017, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2017.495
   Jin S, 2019, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2019.00581
   Ke LP, 2018, LECT NOTES COMPUT SC, V11206, P731, DOI 10.1007/978-3-030-01216-8_44
   Kocabas M, 2018, LECT NOTES COMPUT SC, V11215, P437, DOI 10.1007/978-3-030-01252-6_26
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Levinkov E, 2017, PROC CVPR IEEE, P1904, DOI 10.1109/CVPR.2017.206
   Li J., AAAI C ART INT, P11354
   Li J., P IEEE C COMP VIS PA, P10863
   Li JJ, 2019, ARXIV PREPRINT ARXIV
   Liang S, 2018, COMPUT VIS IMAGE UND, V176, P1, DOI 10.1016/j.cviu.2018.10.006
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Liu WT, 2018, AAAI CONF ARTIF INTE, P7170
   Luo YM, 2019, IEEE T IMAGE PROCESS, V28, P142, DOI 10.1109/TIP.2018.2865666
   Miao JX, 2022, IEEE T NEUR NET LEAR, V33, P4624, DOI 10.1109/TNNLS.2021.3059515
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Munea TL, 2020, IEEE ACCESS, V8, P133330, DOI 10.1109/ACCESS.2020.3010248
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P705, DOI 10.1007/978-3-030-01228-1_42
   Nie XC, 2019, IEEE I CONF COMP VIS, P6950, DOI 10.1109/ICCV.2019.00705
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Paszke A., ADV NEURAL INFORM PR, V2019, P8024
   Pikramenos G, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05162-5
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82
   Ren S, 2015, FASTER R CNN REAL TI, P91
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Su K, 2019, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2019.00582
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun M, 2012, PROC CVPR IEEE, P3394, DOI 10.1109/CVPR.2012.6248079
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tang W, 2018, LECT NOTES COMPUT SC, V11207, P197, DOI 10.1007/978-3-030-01219-9_12
   Tang W, 2019, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2019.00120
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yu D., 2019, ARXIV PREPRINT ARXIV
NR 53
TC 10
Z9 10
U1 3
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104198
DI 10.1016/j.imavis.2021.104198
EA MAY 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700005
DA 2024-07-18
ER

PT J
AU Yao, JX
   Ye, YT
AF Yao, Jingxuan
   Ye, Yuntao
TI The effect of image recognition traffic prediction method under deep
   learning and naive Bayes algorithm on freeway traffic safety
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; LSTM; Naive Bayes; Traffic flow prediction; Image
   processing
ID FLOW FORECASTING-MODEL; LSTM; NETWORK
AB In order to study and predict the freeway traffic safety and realize the traffic flow in the nonlinear big data environment, based on deep learning, the long-short-time memory (LSTM) model based on recurrent neural network is proposed. The traffic flowis predicted and the predicted value of traffic flow is comparedwith the actual value at different times. The mean absolute percentage error of LSTM prediction model is tested and compared with the error of time proximity, periodicity, and trend. At the same time, the naive Bayes algorithm is used to carry out image recognition processing for attributes such as license plate number and vehicle color to conduct vehicle matching. The data processing, training process, and model realization of the model are studied, and the accuracy of the naive Bayesian algorithm is tested. The results show that the predicted value of the traffic flow prediction model based on LSTM is not much different from the actual value. The average prediction error for the period from May 7, 2018 to May 9, 2018 is approximately 13.8%. When the time series is 6, the error of the predictionmodel based on LSTMis 10.72%, and the prediction errors of the three sequences of time proximity, periodicity, and trend are 15.66%, 17.59%, and 20.67%, respectively. Considering the three sequences comprehensively, the prediction model can achieve good prediction effect. The accuracy of the vehicle matching model based on naive Bayes is about 82.7%, which can meet the requirements of the system. Therefore, it can be concluded that the LSTM traffic flow prediction model based on deep learning and the image recognition vehicle matching model based on naive Bayes can realize the traffic safety prediction of freeway, which has great practical significance. (c) 2020 Published by Elsevier B.V.
C1 [Yao, Jingxuan; Ye, Yuntao] Changan Univ, Sch Automobile, Xian 710064, Peoples R China.
C3 Chang'an University
RP Yao, JX (corresponding author), Changan Univ, Sch Automobile, Xian 710064, Peoples R China.
EM 344037579@qq.com
CR Aggarwal R., 2017, INT J COMPUT SCI MOB, V6
   Dias KL, 2019, COMPUT NETW, V158, P143, DOI 10.1016/j.comnet.2019.04.004
   Dong CJ, 2017, TRANSPORTMETRICA A, V13, P91, DOI 10.1080/23249935.2016.1212290
   Dong FL, 2019, J STAT COMPUT SIM, V89, P2151, DOI 10.1080/00949655.2019.1612395
   Habtemichael FG, 2016, TRANSPORT RES C-EMER, V66, P61, DOI 10.1016/j.trc.2015.08.017
   Hoshino T, 2018, ELECTR COMMUN JPN, V101, P3, DOI 10.1002/ecj.11964
   Jain G, 2019, ANN MATH ARTIF INTEL, V85, P21, DOI 10.1007/s10472-018-9612-z
   Jin YL, 2019, IEEE ACCESS, V7, P125101, DOI 10.1109/ACCESS.2019.2933319
   Jongen S, 2017, PSYCHOPHARMACOLOGY, V234, P837, DOI 10.1007/s00213-016-4519-z
   Li HJ, 2017, IET INTELL TRANSP SY, V11, P212, DOI 10.1049/iet-its.2016.0297
   Li ZZ, 2017, PROMET-ZAGREB, V29, P143, DOI 10.7307/ptt.v29i2.2041
   Peng YA, 2018, SIGNAL IMAGE VIDEO P, V12, P99, DOI 10.1007/s11760-017-1135-2
   Phusittrakool A, 2018, IET INTELL TRANSP SY, V12, P113, DOI 10.1049/iet-its.2017.0007
   Seliem H, 2018, IEEE ACCESS, V6, P20125, DOI 10.1109/ACCESS.2018.2824839
   Tian LL, 2019, CLUSTER COMPUT, V22, P573, DOI 10.1007/s10586-017-1340-3
   Tian Y, 2018, NEUROCOMPUTING, V318, P297, DOI 10.1016/j.neucom.2018.08.067
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Yang BL, 2019, NEUROCOMPUTING, V332, P320, DOI 10.1016/j.neucom.2018.12.016
   Yang HF, 2017, IEEE T NEUR NET LEAR, V28, P2371, DOI 10.1109/TNNLS.2016.2574840
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zhang H, 2019, INT J MOD PHYS C, V30, DOI 10.1142/S0129183119500347
   Zhang H, 2018, APPL INTELL, V48, P2429, DOI 10.1007/s10489-017-1095-9
   Zhou HX, 2019, IEEE ACCESS, V7, P78063, DOI 10.1109/ACCESS.2019.2923006
   Zhou YW, 2018, INFORM SCIENCES, V444, P135, DOI 10.1016/j.ins.2018.02.053
NR 24
TC 14
Z9 14
U1 5
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 103971
DI 10.1016/j.imavis.2020.103971
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000001
DA 2024-07-18
ER

PT J
AU Chen, Y
   Hu, SJ
   Mao, H
   Deng, W
   Gao, X
AF Chen, Yan
   Hu, Shenjian
   Mao, He
   Deng, Wei
   Gao, Xin
TI Application of the best evacuation model of deep learning in the design
   of public structures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Evacuation; Deep learning; VR video tracking method; YOLO-based
   recursive neural network model; Simulation
AB Evacuation behavior is an important factor which must be considered in the design of public structures. With the continuous complexity of structure, more and more factors should be considered in evacuation. The traditional design based on experience may have some limitations in practice. Based on the deep neural network model, the evacuation design simulation for subway station buildings is implemented. VR video tracking technologies such as auxiliary image data pre-training algorithm, tracking sequence pre-training algorithm, and recursive neural network model based on You Only Look Once (YOLO) arc introduced. Compared with the convolutional neural network (CNN) model, the classified data set pre-training model, and YOLO algorithm, the accuracy and training speed of the model algorithm are verified. In simulation, the Zhujiang New Town Station in Guangzhou is taken as the object. The initial evacuation test point is selected according to the structure of the subway platform, and the test personnel are selected according to the test requirements. The average evacuation time and the average satisfaction score of the testers under the influence factors such as gender, age, subway frequency, and familiarity with VR equipment, as well as under the initial starting points of different evacuation tests. The results show that the accuracy of the algorithm is lower than that of the CNN, but the training speed is faster. The accuracy of the model based on YOLO recurrent neural network is the highest. Although the training speed is 19 ms, which is higher than other models, the overall performance is the best. Differences in factors such as gender, age, frequency of subway ride, and familiarity with VR devices will result in different differences in average evacuation time and average satisfaction score. When the platform center is used as the initial evacuation point, the average evacuation time is the shortest, and the average satisfaction score of the testers is the highest. In conclusion, through VR video tracking technology, the actual situation of subway station buildings can be well simulated, and further design schemes can be made according to the simulated situation, which has practical reference significance. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Chen, Yan; Hu, Shenjian; Deng, Wei; Gao, Xin] Dalian Univ Technol, Sch Architecture & Fine Art, Dalian 116024, Peoples R China.
   [Mao, He] Suzhou Univ Sci & Technol, Coll Art, Suzhou 116011, Peoples R China.
C3 Dalian University of Technology; Suzhou University of Science &
   Technology
RP Gao, X (corresponding author), Dalian Univ Technol, Sch Architecture & Fine Art, Dalian 116024, Peoples R China.
EM caro@163.com
OI Gao, Xin/0000-0002-0545-8905
FU National Natural Science Foundation of China [51978118]; Natural Science
   Foundation of Liaoning Province [2019-ZD-0135]
FX The authors appreciate the financial supported by the National Natural
   Science Foundation of China: Research on Comprehensive Renewal Methods
   of Existing Residential Buildings in the North under Multi-Quality
   Targets (No. 51978118) and the Natural Science Foundation of Liaoning
   Province: "Micro-field" Construction of Underground Rail Transit Space
   and Green Energy-saving Technology (No. 2019-ZD-0135).
CR Arias S, 2019, FIRE TECHNOL, V55, P2319, DOI 10.1007/s10694-019-00868-y
   Cao LJ, 2019, COMPUT HUM BEHAV, V90, P37, DOI 10.1016/j.chb.2018.08.041
   Chen BH, 2020, J ELECTR ENG TECHNOL, V15, P441, DOI 10.1007/s42835-019-00230-w
   Deng YL, 2018, SAFETY SCI, V103, P172, DOI 10.1016/j.ssci.2017.10.017
   Dos Reis DH, 2019, APPL ARTIF INTELL, V33, P1290, DOI 10.1080/08839514.2019.1684778
   Douven I, 2018, PSYCHON B REV, V25, P1203, DOI 10.3758/s13423-017-1344-2
   Du GF, 2019, IEEE T TRANSP ELECTR, V5, P490, DOI 10.1109/TTE.2019.2899207
   Elbamby MS, 2018, IEEE NETWORK, V32, P78, DOI 10.1109/MNET.2018.1700268
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   우경하, 2019, [Journal of Korea Safety Management & Science, 대한안전경영과학회지], V21, P17, DOI 10.12812/ksms.2019.21.3.017
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Seula Park, 2018, [Journal of The Korean Society of Hazard Mitigation, 한국방재학회논문집], V18, P387, DOI 10.9798/KOSHAM.2018.18.7.387
   Tucker A, 2018, FIRE SAFETY J, V99, P1, DOI 10.1016/j.firesaf.2018.04.011
   Xia YQ, 2019, ENG FAIL ANAL, V104, P626, DOI 10.1016/j.engfailanal.2019.06.047
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang HW, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225363
   Zhang KH, 2018, PATTERN RECOGN, V83, P185, DOI 10.1016/j.patcog.2018.05.017
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
NR 19
TC 113
Z9 114
U1 14
U2 113
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103975
DI 10.1016/j.imavis.2020.103975
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700003
DA 2024-07-18
ER

PT J
AU Zeng, KW
   Ning, MN
   Wang, YH
   Guo, Y
AF Zeng, Kaiwei
   Ning, Munan
   Wang, Yaohua
   Guo, Yang
TI Energy clustering for unsupervised person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Fully unsupervised method; Hierarchical
   clustering; Energy distance
AB Due to the high cost of data annotation in supervised person re-identification (re-ID) methods, unsupervised methods become more attractive in the real world. Recently, the hierarchical clustering serves as a promising unsupervised method. One key factor of hierarchical clustering is the distance measurement strategy. Ideally, a good distance measurement should consider both inter-cluster and intra-cluster distance of all samples. To solve this problem, we propose to use the energy distance to measure inter-cluster distance in hierarchical clustering (E-cluster), and use the sum of squares of deviations (SSD) as a regularization term to measure intra-cluster distance for further performance promotion. We evaluate our method on Market-1501 and DukeMTMC-reID. Extensive experiments show that E-cluster obtains significant improvements over the state-of-the-arts fully unsupervised methods. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zeng, Kaiwei; Ning, Munan; Wang, Yaohua; Guo, Yang] Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Wang, YH; Guo, Y (corresponding author), Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
EM zengkaiwei14@nudt.edu.cn
FU Science and Technology Planning Project of Hunan Province [2019RS2027];
   National Key Research and Development Program of China [2018YFB0204301]
FX We thank the reviewers for their feedback. We thank our group members
   for feedback and the stimulating intellectual environment they provide.
   This researchwas supported by The Science and Technology Planning
   Project of Hunan Province (No. 2019RS2027) and National Key Research and
   Development Program of China (No. 2018YFB0204301).
CR [Anonymous], 2016, NIPS
   [Anonymous], 2016, ICML
   Chen Y., 2018, ARXIV180807301
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding G., 2019, ARXIV190601308
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, COMPUT SCI, V2
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szekely G.J., 2012, CONTESTS HIGHER MATH
   Szekely G.J., 2003, E STAT ENERGY STAT S
   Székely GJ, 2013, J STAT PLAN INFER, V143, P1249, DOI 10.1016/j.jspi.2013.03.018
   Székely GJ, 2005, J CLASSIF, V22, P151, DOI 10.1007/s00357-005-0012-9
   Székely GJ, 2005, J MULTIVARIATE ANAL, V93, P58, DOI 10.1016/j.jmva.2003.12.002
   Tian H, 2019, NEUROCOMPUTING, V359, P93, DOI 10.1016/j.neucom.2019.05.037
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Wu Z., 2018, ARXIV180501978
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xu Jiaolong, 2019, IEEE ACCESS
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 33
TC 19
Z9 19
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2020
VL 98
AR 103913
DI 10.1016/j.imavis.2020.103913
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR9US
UT WOS:000536040700002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, WH
   Liu, GM
   Shi, JW
   Zhang, H
   Dai, GJ
AF Zhou, Wenhui
   Liu, Gaomin
   Shi, Jiangwei
   Zhang, Hua
   Dai, Guojun
TI Depth-guided view synthesis for light field reconstruction from a single
   image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Light field; Convolutional neural network; Depth estimation; View
   synthesis; View inpainting
AB Light field imaging has recently become a promising technology for 3D rendering and displaying. However, capturing real-world light field images still faces many challenges in both the quantity and quality. In this paper, we develop a learning based technique to reconstruct light field from a single 2D RGB image. It includes three steps: unsupervised monocular depth estimation, view synthesis and depth-guided view inpainting. We first propose a novel monocular depth estimation network to predict disparity maps of each sub-aperture views from the central view of light field. Then we synthesize the initial sub-aperture views by using the warping scheme. Considering that occlusion makes synthesis ambiguous for pixels invisible in the central view, we present a simple but effective fully convolutional network (FCN) for view inpainting. Note that the proposed network architecture is a general framework for light field reconstruction, which can be extended to take a sparse set of views as input without changing any structure or parameters of the network. Comparison experiments demonstrate that our method outperforms the state-of-the-art light field reconstruction methods with single-view input, and achieves comparable results with the multi-input methods. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zhou, Wenhui; Liu, Gaomin; Shi, Jiangwei; Zhang, Hua; Dai, Guojun] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Zhou, Wenhui] Zhejiang Prov Key Lab Informat Proc Commun & Netw, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University
RP Zhang, H (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
EM zhangh@hdu.edu.cn
RI Zhou, Wenhui/AAL-8470-2021
OI Zhou, Wenhui/0000-0003-2216-8878
FU National Key R&D Program of China [2017YFE0118200]; Open Project of
   Zhejiang Provincial Key Laboratory of Information Processing,
   Communication and Networking; Key Program of Zhejiang Provincial Natural
   Science Foundation of China [LZ14F020003]
FX This work is supported in part by the National Key R&D Program of China
   (2017YFE0118200), Open Project of Zhejiang Provincial Key Laboratory of
   Information Processing, Communication and Networking, and the Key
   Program of Zhejiang Provincial Natural Science Foundation of China
   (LZ14F020003). The authors are grateful for the anonymous reviewers who
   made constructive comments.
CR [Anonymous], SYNTHESIZING 4D SPAT
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2005, Comput. Sci. Tech. Rep.
   [Anonymous], 2018, EUR C COMP VIS
   [Anonymous], EUROGRAPHICS
   [Anonymous], 2015, INT C LEARN REPR ICL
   [Anonymous], 2009, INT C COMP PHOT
   Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168
   Buyssens P, 2017, IEEE T IMAGE PROCESS, V26, P525, DOI 10.1109/TIP.2016.2619263
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Guo M., 2018, AS C COMP VIS, P50
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang FC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766922
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Levin A, 2010, PROC CVPR IEEE, P1831, DOI 10.1109/CVPR.2010.5539854
   Mateos J, 2009, IEEE IMAGE PROC, P129, DOI 10.1109/ICIP.2009.5414169
   Mitra K., 2012, P IEEE COMP SOC C CO, P22
   Mumtaz S, 2017, MMWAVE MASSIVE MIMO: A PARADIGM FOR 5G, P1, DOI 10.1016/B978-0-12-804418-6.00001-7
   Srinivasan P.P., 2017, INT C COMPUTER VISIO, P1
   Sun L, 2015, PR IEEE I C PROGR IN, P1, DOI 10.1109/PIC.2015.7489798
   Vadathya A.K., 2018, COMP CAM DISPL CCD W
   Vagharshakyan S, 2018, IEEE T PATTERN ANAL, V40, P133, DOI 10.1109/TPAMI.2017.2653101
   Wang TC, 2016, IEEE T PATTERN ANAL, V38, P2170, DOI 10.1109/TPAMI.2016.2515615
   Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398
   Wang Y, 2018, OPTIM ENG, V4, P1, DOI DOI 10.1002/adma.201802563
   Wang YC, 2019, INT J ADV MANUF TECH, V105, P4059, DOI 10.1007/s00170-018-1927-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Wanner S, 2012, LECT NOTES COMPUT SC, V7576, P608, DOI 10.1007/978-3-642-33715-4_44
   Wu G., 2017, IEEE C COMPUTER VISI
   Wu GC, 2019, IEEE T PATTERN ANAL, V41, P1681, DOI 10.1109/TPAMI.2018.2845393
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Yoon Y, 2015, IEEE CUST INTEGR CIR
   Yoon Y, 2017, IEEE SIGNAL PROC LET, V24, P848, DOI 10.1109/LSP.2017.2669333
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 36
TC 7
Z9 8
U1 1
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103874
DI 10.1016/j.imavis.2020.103874
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000003
DA 2024-07-18
ER

PT J
AU Zhou, XF
   Li, GY
   Gong, C
   Liu, Z
   Zhang, JY
AF Zhou, Xiaofei
   Li, Gongyang
   Gong, Chen
   Liu, Zhi
   Zhang, Jiyong
TI Attention-guided RGBD saliency detection using appearance information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RGBD; Saliency; Bottom-up; Top-down; Attention; Appearance
ID OBJECT DETECTION; FUSION; FEATURES; NETWORK
AB Most of the deep convolutional neural networks (CNNs) based RGBD saliency models either regard the RGB and depth cues as the same status or trust the depth information excessively. However, they ignore that the low-quality depth map is an interference factor and the multi-level deep features that originated from RGB images contain abundant appearance information. Therefore, we propose a novel RGBD saliency model, where the attention-guided bottom-up and top-down modules are powerfully combined by using multilevel deep RGB features, to utilize the deep RGB and depth features in a sufficient and appropriate way. Concretely, a two-stream structure based bottom-up module is first constructed to dig and fuse the RGB and depth information, yielding the fused deep feature. Besides, the module embeds the depth cue based attention maps to guide the indication of salient objects. Then, considering the abundant appearance information, a top-down module is deployed to perform coarse-to-fine saliency inference, where the fused deep feature is progressively integrated with appearance information. Similarly, the attention map is also inserted into this module for locating salient objects. Extensive experiments are performed on five public RGBD datasets and the corresponding experimental results firmly demonstrate the effectiveness and superiority of our model when compared with the state-of-the-art RGBD saliency models. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zhou, Xiaofei; Zhang, Jiyong] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou 310018, Peoples R China.
   [Li, Gongyang; Liu, Zhi] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Li, Gongyang; Liu, Zhi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Gong, Chen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Key Lab Intelligent Percept & Syst High Dimens In, Minist Educ, Nanjing 210094, Jiangsu, Peoples R China.
C3 Hangzhou Dianzi University; Shanghai University; Shanghai University;
   Nanjing University of Science & Technology
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM zxforchid@outlook.com; ligongyang@shu.edu.cn; chen.gong@njust.edu.cn;
   liuzhisjtu@163.com; jzhang@hdu.edu.cn
RI Li, Gongyang/IXD-9078-2023; GONG, CHEN/JDW-5727-2023; LIU,
   Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131; , Gongyang Li/0000-0001-7324-1196; Zhang,
   Jiyong/0000-0001-9600-8477
FU National Natural Science Foundation of China [61901145, 61771301,
   61973162, 61972123]
FX This work was supported by the National Natural Science Foundation of
   China under grants 61901145, 61771301, 61973162 and 61972123.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen H, 2020, IEEE T CYBERNETICS, V50, P4808, DOI 10.1109/TCYB.2019.2934986
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007
   Chen YX, 2014, INTERNATIONAL CONFERENCE ON MECHANICS AND MATERIALS ENGINEERING (ICMME 2014), P23
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Lau CP, 2018, IEEE T IMAGE PROCESS, V27, P5787, DOI 10.1109/TIP.2018.2858146
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu ZY, 2019, NEUROCOMPUTING, V363, P46, DOI 10.1016/j.neucom.2019.07.012
   Mukherjee P, 2017, IMAGE VISION COMPUT, V61, P82, DOI 10.1016/j.imavis.2017.02.008
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Shigematsu R, 2017, IEEE INT CONF COMP V, P2749, DOI 10.1109/ICCVW.2017.323
   Simonyan K., 2014, 14091556 ARXIV
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stefic D, 2016, IMAGE VISION COMPUT, V52, P195, DOI 10.1016/j.imavis.2016.06.006
   Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934
   Tian HW, 2014, IEEE T IMAGE PROCESS, V23, P4389, DOI 10.1109/TIP.2014.2350914
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Wang AZ, 2017, IEEE SIGNAL PROC LET, V24, P663, DOI 10.1109/LSP.2017.2688136
   Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wen HF, 2019, J VIS COMMUN IMAGE R, V62, P279, DOI 10.1016/j.jvcir.2019.05.018
   Xu XY, 2017, PATTERN RECOGN, V72, P300, DOI 10.1016/j.patcog.2017.07.026
   Yu QH, 2018, PROC CVPR IEEE, P8280, DOI 10.1109/CVPR.2018.00864
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou XF, 2018, IEEE T MULTIMEDIA, V20, P2993, DOI 10.1109/TMM.2018.2829605
   Zhou XF, 2016, IEEE SIGNAL PROC LET, V23, P517, DOI 10.1109/LSP.2016.2536743
   Zhu CB, 2019, IEEE INT CON MULTI, P199, DOI 10.1109/ICME.2019.00042
   Zhu CB, 2017, IEEE INT CONF COMP V, P1509, DOI 10.1109/ICCVW.2017.178
NR 58
TC 27
Z9 29
U1 2
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103888
DI 10.1016/j.imavis.2020.103888
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000008
DA 2024-07-18
ER

PT J
AU Zhang, X
   Jiang, ZG
   Zhang, HP
AF Zhang, Xin
   Jiang, Zhiguo
   Zhang, Haopeng
TI Out-of-region keypoint localization for 6D pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 6D pose estimation; Keypoint representation; Localization confidence;
   Real-time processing
AB This paper addresses the problem of instance level 6D pose estimation from a single RGB image. Our approach simultaneously detects objects and recovers poses by predicting the 2D image locations of the object's 3D bounding box vertices. Specifically, we focus on the challenge of locating virtual keypoints outside the object region proposals, and propose a boundary-based keypoint representation which incorporates classification and regression schemes to reduce output space. Moreover, our method predicts localization confidences and alleviates the influence of difficult keypoints by a voting process. We implement the proposed method based on 2D detection pipeline, meanwhile bridge the feature gap between detection and pose estimation. Our network has real-time processing capability, which runs 30 fps on a GTX 1080Ti GPU. For single object and multiple objects pose estimation on two benchmark datasets, our approach achieves competitive or superior performance compared with state-of-the-art RGB based pose estimation methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Zhang, Xin; Jiang, Zhiguo; Zhang, Haopeng] Beihang Univ, Sch Astronaut, Image Proc Ctr, Beijing 102206, Peoples R China.
   [Zhang, Xin; Jiang, Zhiguo; Zhang, Haopeng] Beijing Key Lab Digital Media, Beijing 102206, Peoples R China.
   [Zhang, Xin; Jiang, Zhiguo; Zhang, Haopeng] Minist Educ, Key Lab Spacecraft Design Optimizat & Dynam Simul, Beijing 102206, Peoples R China.
C3 Beihang University
RP Zhang, HP (corresponding author), Beihang Univ, Sch Astronaut, Image Proc Ctr, Beijing 102206, Peoples R China.
EM zhang_xin_by@buaa.edu.cn; jiangzg@buaa.edu.cn; zhanghaopeng@buaa.edu.cn
RI Zhang, Haopeng/C-5472-2014
OI Zhang, Haopeng/0000-0003-1981-8307
FU National Natural Science Foundation of China [61501009, 61771031];
   National Key Research and Development Program of China [2016YFB0501300,
   2016YFB0501302]; Fundamental Research Funds for the Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China (grant nos. 61501009 and 61771031), the National Key
   Research and Development Program of China (grant nos. 2016YFB0501300 and
   2016YFB0501302), and the Fundamental Research Funds for the Central
   Universities.
CR [Anonymous], 2013, PROC ASIAN C COMPUT
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Cao Z, 2016, IEEE INT CONF ROBOT, P2441, DOI 10.1109/ICRA.2016.7487396
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   He Kaiming, 2017, P IEEE INT C COMPUTE
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Hinterstoisser S, 2016, LECT NOTES COMPUT SC, V9907, P834, DOI 10.1007/978-3-319-46487-9_51
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Hu YL, 2019, PROC CVPR IEEE, P3380, DOI 10.1109/CVPR.2019.00350
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Kehl W, 2016, LECT NOTES COMPUT SC, V9907, P205, DOI 10.1007/978-3-319-46487-9_13
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   Moolan-Feroze O, 2018, IEEE INT C INT ROBOT, P82, DOI 10.1109/IROS.2018.8594297
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Pavlakos G, 2017, LAW PRACT REASON, P113
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Rad M, 2018, PROC CVPR IEEE, P4663, DOI 10.1109/CVPR.2018.00490
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Rubio A, 2015, IEEE INT CONF ROBOT, P1397, DOI 10.1109/ICRA.2015.7139372
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43
   Svärm L, 2014, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2014.75
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Tremblay J., 2018, ARXIV180910790, P306
   Tulsiani S, 2015, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2015.7298758
   Vidal J, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P405, DOI 10.1109/ICCAR.2018.8384709
   Wang ZR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1014
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Yan Y, 2019, J COASTAL RES, P6, DOI 10.2112/SI98-002.1
   Zhang X, 2019, IMAGE VISION COMPUT, V89, P1, DOI 10.1016/j.imavis.2019.06.013
   Zhu MQ, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON TEACHING AND COMPUTATIONAL SCIENCE (ICTCS 2018), P3, DOI 10.5729/ictcs.2018.1.3
NR 41
TC 8
Z9 8
U1 2
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103854
DI 10.1016/j.imavis.2019.103854
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000003
DA 2024-07-18
ER

PT J
AU Xue, TF
   Owens, A
   Scharstein, D
   Goesele, M
   Szeliski, R
AF Xue, Tianfan
   Owens, Andrew
   Scharstein, Daniel
   Goesele, Michael
   Szeliski, Richard
TI Multi-frame stereo matching with edges, planes, and superpixels
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo; Edge matching; Superpixels; Plane fitting
ID OCCLUDING CONTOURS
AB We present a multi-frame narrow-baseline stereo matching algorithm based on extracting and matching edges across multiple frames. Edge matching allows us to focus on the important features at the very beginning, and deal with occlusion boundaries as well as untextured regions. Given the initial sparse matches, we fit overlapping local planes to form a coarse, over-complete representation of the scene. After breaking up the reference image in our sequence into superpixels, we perform a Markov random field optimization to assign each superpixel to one of the plane hypotheses. Finally, we refine our continuous depth map estimate using a piecewise-continuous variational optimization. Our approach successfully deals with depth discontinuities, occlusions, and large textureless regions, while also producing detailed and accurate depth maps. We show that our method out-performs competing methods on high-resolution multi-frame stereo benchmarks and is well-suited for view interpolation applications. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Xue, Tianfan] MIT, Cambridge, MA 02139 USA.
   [Owens, Andrew] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Scharstein, Daniel] Middlebury Coll, Middlebury, VT 05753 USA.
   [Goesele, Michael] Tech Univ Darmstadt, Darmstadt, Germany.
   [Szeliski, Richard] Facebook, Menlo Pk, CA USA.
C3 Massachusetts Institute of Technology (MIT); University of California
   System; University of California Berkeley; Technical University of
   Darmstadt; Facebook Inc
RP Xue, TF (corresponding author), MIT, Cambridge, MA 02139 USA.
EM tfxue@csail.mit.edu
OI /0000-0001-5031-6618
FU NSF [IIS-1320715, IIS-1718376]
FX Part of this work was done when the authors were in Microsoft Research.
   D. Scharstein gratefully acknowledges support through NSF awards
   IIS-1320715 and IIS-1718376.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], AIM351 STANF U AI LA
   [Anonymous], 2008, CVPR
   [Anonymous], 2013, ACM Transaction on Graphics
   [Anonymous], 2016, AS C COMP VIS
   [Anonymous], 2014, ECCV
   [Anonymous], 2013, WERTUNG THEORIEN INS, DOI DOI 10.HTTP://WWW.10.1109/CVPR.2001.990462
   [Anonymous], 2015, CVPR
   [Anonymous], 2016, J MACH LEARN RES
   [Anonymous], 2017, CVPR
   [Anonymous], 2012, CVPR
   [Anonymous], 2006, CVPR
   Baker H.H., 1980, IMAGE UNDERSTANDING, P168
   Bleyer M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3081, DOI 10.1109/CVPR.2011.5995581
   Bleyer M, 2010, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2010.5539783
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chakrabarti A, 2015, PROC CVPR IEEE, P4009, DOI 10.1109/CVPR.2015.7299027
   Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Geiger A., 2010, ACCV
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Ishikawa H., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P232, DOI 10.1007/BFb0055670
   Jung IL, 2013, IEEE IMAGE PROC, P2082, DOI 10.1109/ICIP.2013.6738429
   Kang SB, 2004, INT J COMPUT VISION, V58, P139, DOI 10.1023/B:VISI.0000015917.35451.df
   Knapitsch Arno, 2017, ACM Transactions on Graphics, V36, DOI 10.1145/3072959.3073599
   Nakamura Y, 1996, PROC CVPR IEEE, P371, DOI 10.1109/CVPR.1996.517099
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   SCHARSTEIN D, 1994, INT C PATT RECOG, P572, DOI 10.1109/ICPR.1994.576363
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein D., 2010, MIDDLEBURY STEREO VI
   Schmid C, 2000, INT J COMPUT VISION, V40, P199, DOI 10.1023/A:1008135310502
   Shan Q, 2014, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR.2014.511
   Sinha S., 2013, CVPR
   Szeliski R, 1998, INT J COMPUT VISION, V28, P27, DOI 10.1023/A:1008050630628
   Szeliski R, 2006, ACM T GRAPHIC, V25, P1135, DOI 10.1145/1141911.1142005
   Thuerck D., 2016, EUROGRAPHICS
   VENKATESWAR V, 1995, INT J COMPUT VISION, V15, P245, DOI 10.1007/BF01451743
   Vogel C, 2015, INT J COMPUT VISION, V115, P1, DOI 10.1007/s11263-015-0806-0
   WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981
   Yamaguchi K., 2012, ECCV
   Zach C, 2014, LECT NOTES COMPUT SC, V8693, P772, DOI 10.1007/978-3-319-10602-1_50
NR 48
TC 14
Z9 14
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2019
VL 91
AR 103771
DI 10.1016/j.imavis.2019.05.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU3YI
UT WOS:000501614200001
OA Bronze
DA 2024-07-18
ER

PT J
AU Conze, PH
   Tilquin, F
   Lamard, M
   Heitz, F
   Quellec, G
AF Conze, Pierre-Henri
   Tilquin, Florian
   Lamard, Mathieu
   Heitz, Fabrice
   Quellec, Gwenole
TI Unsupervised learning-based long-term superpixel tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Superpixel matching; Unsupervised learning; Superpixel tracking;
   Multi-step integration; Random forests; Forward-backward consistency
ID FORESTS
AB Finding correspondences between structural entities decomposing images is of high interest for computer vision applications. In particular, we analyze how to accurately track superpixels - visual primitives generated by aggregating adjacent pixels sharing similar characteristics - over extended time periods relying on unsupervised learning and temporal integration. A two-step video processing pipeline dedicated to long-term superpixel tracking is proposed. First, unsupervised learning-based superpixel matching provides correspondences between consecutive and distant frames using new context-rich features extended from greyscale to multi-channel and forward-backward consistency constraints. Resulting elementary matches are then combined along multi-step paths running through the whole sequence with various inter-frame distances. This produces a large set of candidate long-term superpixel pairings upon which majority voting is performed. Video object tracking experiments demonstrate the accuracy of our elementary estimator against state-of-the-art methods and proves the ability of multi-step integration to provide accurate long-term superpixel matches compared to usual direct and sequential integration. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Conze, Pierre-Henri] IMT Atlantique, Technopole Brest Iroise, F-29238 Brest, France.
   [Conze, Pierre-Henri; Lamard, Mathieu; Quellec, Gwenole] INSERM, UMR 1101, LaTIM, 22 Av Camille Desmoulins, F-29238 Brest, France.
   [Tilquin, Florian; Heitz, Fabrice] Unistra, CNRS, UMR 7357, ICube, 300 Bd Sebastien Brant, F-67412 Illkirch Graffenstaden, France.
   [Lamard, Mathieu] Univ Bretagne Occidentale, 2 Av Foch, F-29609 Brest, France.
C3 IMT - Institut Mines-Telecom; IMT Atlantique; Institut National de la
   Sante et de la Recherche Medicale (Inserm); Universite de Bretagne
   Occidentale; Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute for Engineering & Systems Sciences (INSIS); Universite de
   Bretagne Occidentale
RP Conze, PH (corresponding author), IMT Atlantique, Technopole Brest Iroise, F-29238 Brest, France.; Conze, PH (corresponding author), LaTIM, UMR 1101, 22 Av Camille Desmoulins, F-29238 Brest, France.
EM pierre-henri.conze@imt-atlantique.fr
RI Conze, Pierre-Henri/AAE-9248-2020; Quellec, Gwenole/L-9946-2015
OI Conze, Pierre-Henri/0000-0003-2214-3654; Quellec,
   Gwenole/0000-0003-1669-7140
FU France Life Imaging [ANR-11-INBS-0006]; (French "Investissements
   d'Avenir" program)
FX This work was partly funded by France Life Imaging (grant
   ANR-11-INBS-0006 from the French "Investissements d'Avenir" program).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], PAC RIM C MULT
   [Anonymous], 170108936 ARXIV
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cao X, 2011, IEEE T BROADCAST, V57, P491, DOI 10.1109/TBC.2011.2127650
   Chang HS, 2013, IEEE IMAGE PROC, P3835, DOI 10.1109/ICIP.2013.6738790
   Chang J, 2013, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2013.267
   Conze PH, 2017, I S BIOMED IMAGING, P490, DOI 10.1109/ISBI.2017.7950567
   Conze PH, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Conze PH, 2016, COMPUT VIS IMAGE UND, V150, P66, DOI 10.1016/j.cviu.2016.04.013
   Crivelli T, 2015, IEEE T IMAGE PROCESS, V24, P484, DOI 10.1109/TIP.2014.2336547
   Donné S, 2015, LECT NOTES COMPUT SC, V9386, P205, DOI 10.1007/978-3-319-25903-1_18
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Giraud R, 2017, IEEE T IMAGE PROCESS, V26, P4068, DOI 10.1109/TIP.2017.2708504
   Glocker B, 2014, LECT NOTES COMPUT SC, V8673, P251, DOI 10.1007/978-3-319-10404-1_32
   Kanavati F, 2017, PATTERN RECOGN, V63, P561, DOI 10.1016/j.patcog.2016.09.026
   Kristan M., 2016, WORKSH EUR C COMP VI
   Lee SH, 2017, I C INF COMM TECH CO, P1061, DOI 10.1109/ICTC.2017.8190854
   Lezama J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3369, DOI 10.1109/CVPR.2011.6044588
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Roth S, 2009, LECT NOTES COMPUT SC, V5604, P1, DOI 10.1007/978-3-642-03061-1_1
   Seitz S.M., 2006, IEEE COMP SOC C COMP, P519
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   Sznitman R, 2012, LECT NOTES COMPUT SC, V7511, P568, DOI 10.1007/978-3-642-33418-4_70
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang L, 2017, IEEE T ENERGY CONVER, V32, P1574, DOI 10.1109/TEC.2017.2710352
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 37
TC 5
Z9 5
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 289
EP 301
DI 10.1016/j.imavis.2019.06.011
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900023
OA Green Submitted, Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Lee, E
   Kim, D
AF Lee, Eunseop
   Kim, Daijin
TI Accurate traffic light detection using deep neural network with focal
   regression loss
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Advanced driving assistance system; Traffic light detection; Small
   object detection; Deep neural network; Focal regression loss; Freestyle
   anchor box
ID RECOGNITION
AB This paper proposes a method that uses a deep neural network (DNN) to detect small traffic lights (TLs) in images captured by cameras mounted in vehicles. The proposed TL detector has a DNN architecture of encoder-decoder with focal regression loss; this loss function reduces loss of well-regressed easy examples. The proposed TL detector has freestyle anchor boxes that are placed at arbitrary locations in a grid cell of an input image, so it can detect small objects located at borders of the grid cell. We evaluate the proposed TL detector with a focal regression loss on two public TL datasets: Bosch small traffic light dataset, and LISA traffic lights data set. Compared to state-of-the-art TL detectors, the proposed TL detector achieves 7.19%42.03% higher mAP on the Bosch-TL dataset and 19.86%-49.16% higher AUC on the LISA-TL dataset. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Lee, Eunseop; Kim, Daijin] POSTECH, Dept Comp Sci & Engn, San 31, Pohang 790784, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Kim, D (corresponding author), POSTECH, Dept Comp Sci & Engn, San 31, Pohang 790784, South Korea.
EM eunseop90@postech.ac.kr; dkim@postech.ac.kr
FU MSIT (Ministry of Science, ICT), Korea, under the SW Starlab support
   program [IITP-2017-0-00897]; Institute for Information & Communications
   Technology Promotion (IITP) grant - Korea government (MSIT)
   [IITP-2018-0-01290]
FX This research was partially supported by the MSIT (Ministry of Science,
   ICT), Korea, under the SW Starlab support program (IITP-2017-0-00897)
   supervised by the IITP (Institute for Information & Communications
   Technology Promotion). This research was partially supported by
   Institute for Information & Communications Technology Promotion (IITP)
   grant funded by the Korea government (MSIT) (IITP-2018-0-01290,
   Development of Open Informal Dataset and Dynamic Object Recognition
   Technology Affecting Autonomous Driving).
CR [Anonymous], ARXIV180502523
   [Anonymous], 2018, ARXIV180607987
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Behrendt Karsten, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1370, DOI 10.1109/ICRA.2017.7989163
   Chen Z., 2018, ABS180207845 COMP RE
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Charette R, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P333, DOI 10.1109/IROS.2009.5353941
   de Charette R, 2009, IEEE INT VEH SYM, P358, DOI 10.1109/IVS.2009.5164304
   Deng H, 2017, PATTERN RECOGN, V61, P66, DOI 10.1016/j.patcog.2016.07.036
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diaz-Cabrera M, 2015, EXPERT SYST APPL, V42, P3911, DOI 10.1016/j.eswa.2014.12.037
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Du XP, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P1323, DOI 10.1109/ICISCE.2017.275
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu C.-Y., 2017, ABS170106659 COMP RE
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Haltakov V, 2015, LECT NOTES COMPUT SC, V9358, P446, DOI 10.1007/978-3-319-24947-6_37
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosseinyalamdary S, 2017, ISPRS J PHOTOGRAMM, V125, P184, DOI 10.1016/j.isprsjprs.2017.01.008
   Jensen MB, 2017, IEEE COMPUT SOC CONF, P882, DOI 10.1109/CVPRW.2017.122
   Ji Y, 2015, IEEE INT VEH SYM, P280, DOI 10.1109/IVS.2015.7225699
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li X, 2018, IEEE T INTELL TRANSP, V19, P199, DOI 10.1109/TITS.2017.2749971
   Li YS, 2018, PATTERN RECOGN, V77, P113, DOI 10.1016/j.patcog.2017.12.012
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Ohn-Bar E, 2017, PATTERN RECOGN, V61, P557, DOI 10.1016/j.patcog.2016.06.002
   Philipsen MP, 2015, IEEE INT C INTELL TR, P2341, DOI 10.1109/ITSC.2015.378
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salti S, 2015, PATTERN RECOGN, V48, P1039, DOI 10.1016/j.patcog.2014.05.017
   Sermanet P., 2013, INT C LEARN REPR, DOI DOI 10.1016/J.VISRES.2006.11.009
   Shi ZW, 2016, IEEE T INTELL TRANSP, V17, P690, DOI 10.1109/TITS.2015.2481459
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Sooksatra S., 2014, Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), 2014 11th International Conference on, P1, DOI [DOI 10.1109/ECTICON.2014.6839767, 10.1109/ecticon.2014.6839767]
   Vard A, 2012, PATTERN RECOGN LETT, V33, P543, DOI 10.1016/j.patrec.2011.11.012
   Wang J, 2018, PATTERN RECOGN, V83, P260, DOI 10.1016/j.patcog.2018.05.009
   Weber M, 2016, IEEE INT VEH SYM, P342, DOI 10.1109/IVS.2016.7535408
   Woo S, 2018, IEEE WINT CONF APPL, P1093, DOI 10.1109/WACV.2018.00125
   Yang J, 2017, IEEE COMPUT SOC CONF, P2025, DOI 10.1109/CVPRW.2017.253
NR 46
TC 17
Z9 18
U1 2
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2019
VL 87
BP 24
EP 36
DI 10.1016/j.imavis.2019.04.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IF3NV
UT WOS:000472988400003
DA 2024-07-18
ER

PT J
AU Ertugrul, IÖ
   Jeni, LA
   Dibeklioglu, H
AF Ertugrul, Itir Onal
   Jeni, Laszlo A.
   Dibeklioglu, Hamdi
TI Modeling and synthesis of kinship patterns of facial expressions
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Kinship synthesis; Kinship verification; Temporal analysis; Facial
   action units; Facial dynamics
ID FACE
AB Analysis of kinship from facial images or videos is an important problem. Prior machine learning and computer vision studies approach kinship analysis as a verification or recognition task. In this paper, for the first time in the literature, we propose a kinship synthesis framework, which generates smile and disgust videos of (probable) children from the expression videos (smile and disgust) of parents. While the appearance of a child's expression is learned using a convolutional encoder-decoder network, another neural network models the dynamics of the corresponding expression. The expression video of the estimated child is synthesized by the combined use of appearance and dynamics models. In order to validate our results, we perform kinship verification experiments using videos of real parents and estimated children generated by our framework. The results show that generated videos of children achieve higher correct verification rates than those of real children. Our results also indicate that the use of generated videos together with the real ones in the training of kinship verification models, increases the accuracy, suggesting that such videos can be used as a synthetic dataset. Furthermore, we evaluate the expression similarity between input and output frames, and show that the proposed method can fairly retain the expression of input faces while transforming the facial identity. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Ertugrul, Itir Onal; Jeni, Laszlo A.] Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA.
   [Dibeklioglu, Hamdi] Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
C3 Carnegie Mellon University; Ihsan Dogramaci Bilkent University
RP Ertugrul, IÖ (corresponding author), Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA.
EM iertugru@andrew.cmu.edu
RI Dibeklioglu, Hamdi/AAB-6907-2020
CR [Anonymous], 2017, SEGNET DEEP CONVOLUT
   [Anonymous], PATTERN RECOGN
   [Anonymous], 2016, IEEE T PATTERN ANAL
   [Anonymous], 2016, CVPR
   [Anonymous], 2017, VISUAL COMPUT
   [Anonymous], 2016, P ADV NEUR INF PROC
   Bartlett M.S., 2003, ADV NEURAL INF PROCE, P1295
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Biehl M, 1997, J NONVERBAL BEHAV, V21, P3, DOI 10.1023/A:1024902500935
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dehghan A, 2014, PROC CVPR IEEE, P1757, DOI 10.1109/CVPR.2014.227
   Dibeklioglu H, 2015, IEEE T IMAGE PROCESS, V24, P1928, DOI 10.1109/TIP.2015.2412377
   Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189
   Dibeklioglu H, 2012, LECT NOTES COMPUT SC, V7574, P525, DOI 10.1007/978-3-642-33712-3_38
   Eibl-Eibesfeldt I., 1989, HUMAN ETHOLOGY
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Ertugrul IÖ, 2017, IEEE INT CONF AUTOMA, P33, DOI 10.1109/FG.2017.14
   Fang RG, 2013, IEEE IMAGE PROC, P2983, DOI 10.1109/ICIP.2013.6738614
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Ghahramani M, 2014, MACH VISION APPL, V25, P919, DOI 10.1007/s00138-013-0566-1
   Ghodrati A., 2015, ARXIV151108446
   Girard JM, 2017, IEEE INT CONF AUTOMA, P581, DOI 10.1109/FG.2017.144
   Guo GD, 2012, IEEE T INSTRUM MEAS, V61, P2322, DOI 10.1109/TIM.2012.2187468
   Guo YH, 2014, INT C PATT RECOG, P4287, DOI 10.1109/ICPR.2014.735
   Hu Junlin., 2014, COMPUTER VISION ACCV, P252
   Jack RE, 2013, VIS COGN, V21, P1248, DOI 10.1080/13506285.2013.835367
   Jeni L.A., 2015, IEEE AFGR
   Jeni LA, 2013, INT CONF AFFECT, P245, DOI 10.1109/ACII.2013.47
   Kim JU, 2017, IEEE ENG MED BIO, P685, DOI 10.1109/EMBC.2017.8036917
   Koelstra S., 2008, P IEEE INT C AUT FAC, P1
   Kohli N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P245, DOI 10.1109/BTAS.2012.6374584
   Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Peleg G, 2006, P NATL ACAD SCI USA, V103, P15921, DOI 10.1073/pnas.0607551103
   Peng X., 2016, ECCV
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   Platt JC, 2000, ADV NEUR IN, P61
   Puthenputhussery A., 2016, ICIP
   Qin X, 2017, NEURAL PROCESS LETT, V47, P1
   Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462
   Robinson J.P., 2016, ARXIV160402182
   Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008
   Shimada Keiji, 2013, International Journal of Computer Theory and Engineering, V5, P24, DOI 10.7763/IJCTE.2013.V5.640
   Vukotie V., 2017, ARXIV170204125
   Wang SY, 2017, IEEE INT CONF AUTOMA, P216, DOI [10.1109/FG.2017.35, 10.1109/ICEMI.2017.8265769]
   Xia SY, 2012, INT C PATT RECOG, P549
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yan H., 2016, IMAGE VIS COMPUT
   Yan HB, 2017, IMAGE VISION COMPUT, V60, P91, DOI 10.1016/j.imavis.2016.08.009
   Yan HB, 2015, IEEE T CYBERNETICS, V45, P2535, DOI 10.1109/TCYB.2014.2376934
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Yang J., 2015, Advances in Neural Information Processing Systems, P1099
   Zhou X., 2011, ACM Multimedia, P953
   Zhou XZ, 2016, INFORM FUSION, V32, P40, DOI 10.1016/j.inffus.2015.08.006
   Zhou Xiuzhuang, 2012, P 20 ACM INT C MULT, P725, DOI [DOI 10.1145/2393347, DOI 10.1145/2393347.2396297]
NR 57
TC 3
Z9 4
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 133
EP 143
DI 10.1016/j.imavis.2018.09.012
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800012
DA 2024-07-18
ER

PT J
AU Jacques, JCS Jr
   Baro, X
   Escalera, S
AF Jacques, Julio C. S. Junior
   Baro, Xavier
   Escalera, Sergio
TI Exploiting feature representations through similarity learning,
   post-ranking and ranking aggregation for person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Person re-identification; Similarity learning; Feature fusion;
   Post-ranking; Ranking aggregation
ID NETWORK
AB Person re-identification has received special attention by the human analysis community in the last few years. To address the challenges in this field, many researchers have proposed different strategies, which basically exploit either cross-view invariant features or cross-view robust metrics. In this work, we propose to exploit a post-ranking approach and combine different feature representations through ranking aggregation. Spatial information, which potentially benefits the person matching, is represented using a 2D body model, from which color and texture information are extracted and combined. We also consider background/foreground information, automatically extracted via Deep Decompositional Network, and the usage of Convolutional Neural Network (CNN) features. To describe the matching between images we use the polynomial feature map, also taking into account local and global information. The Discriminant Context Information Analysis based post-ranking approach is used to improve initial ranking lists. Finally, the Stuart ranking aggregation method is employed to combine complementary ranking lists obtained from different feature representations. Experimental results demonstrated that we improve the state-of-the-art on VIPeR and PRID450s datasets, achieving 67.21% and 75.64% on top-1 rank recognition rate, respectively, as well as obtaining competitive results on CUHK01 dataset. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Jacques, Julio C. S. Junior; Baro, Xavier] Univ Oberta Catalunya, Fac Comp Sci Multimedia & Telecommun, Barcelona, Spain.
   [Jacques, Julio C. S. Junior; Baro, Xavier; Escalera, Sergio] Univ Autonoma Barcelona, Comp Vis Ctr, Barcelona, Spain.
   [Escalera, Sergio] Univ Barcelona, Dept Math & Informat, Barcelona, Spain.
C3 UOC Universitat Oberta de Catalunya; Autonomous University of Barcelona;
   Centre de Visio per Computador (CVC); University of Barcelona
RP Jacques, JCS Jr (corresponding author), Univ Oberta Catalunya, Fac Comp Sci Multimedia & Telecommun, Barcelona, Spain.
EM juliojj@gmail.com
RI Baró, Xavier/A-4064-2011; Escalera, Sergio/L-2998-2015
OI Baró, Xavier/0000-0001-5338-3007; Escalera, Sergio/0000-0003-0617-8873;
   Silveira Jacques Junior, Julio Cezar/0000-0001-6785-7146
FU Spanish projects (MINECO/FEDER, UE) [TIN2015-66951-C2-2-R,
   TIN2016-74946-P]; European Comission Horizon 2020 granted project SEE.4C
   under call H2020-ICT-2015; CERCA Programme/Generalitat de Catalunya;
   NVIDIA Corporation
FX This work has been partially supported by the Spanish projects
   TIN2015-66951-C2-2-R and TIN2016-74946-P (MINECO/FEDER, UE), by the
   European Comission Horizon 2020 granted project SEE.4C under call
   H2020-ICT-2015, and by the CERCA Programme/Generalitat de Catalunya. We
   gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan Xp GPUs used for this research.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], 2016, IEEE WINT CONF APPL
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2007, 10 INT WORKSH PERF E
   [Anonymous], 2015, ICCV
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Prates RFD, 2015, IEEE IMAGE PROC, P1975, DOI 10.1109/ICIP.2015.7351146
   Du YN, 2012, INT C PATT RECOG, P1371
   García J, 2017, IEEE T IMAGE PROCESS, V26, P1650, DOI 10.1109/TIP.2017.2652725
   García J, 2015, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2015.154
   Gong S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Jojic N, 2009, PROC CVPR IEEE, P2044, DOI 10.1109/CVPRW.2009.5206581
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kolde R, 2012, BIOINFORMATICS, V28, P573, DOI 10.1093/bioinformatics/btr709
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Luo P, 2013, IEEE I CONF COMP VIS, P2648, DOI 10.1109/ICCV.2013.329
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Mirmahboub B, 2017, IEEE WINT CONF APPL, P1306, DOI 10.1109/WACV.2017.150
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Stuart JM, 2003, SCIENCE, V302, P249, DOI 10.1126/science.1087447
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao Haiyu, 2017, P CVPR JUL, P1077
NR 38
TC 4
Z9 5
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 76
EP 85
DI 10.1016/j.imavis.2018.08.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tian, Q
   Arbel, T
   Clark, JJ
AF Tian, Qing
   Arbel, Tal
   Clark, James J.
TI Structured deep Fisher pruning for efficient facial trait classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Neural network pruning; Fisher LDA; Facial trait classification
ID LOCAL BINARY PATTERNS; GENDER CLASSIFICATION; FACE-RECOGNITION; COLUMNAR
   ORGANIZATION; NEURAL-NETWORKS; NEURONS; CORTEX; FEATURES; BARREL; IMAGES
AB High efficiency is desirable for many interactive biometrics tasks, including facial trait recognition. Although deep convolutional nets are effective for a multitude of classification tasks, their high space and time demands make them impractical for PCs and mobile devices without a powerful GPU. In this paper, we propose a structured filter-level pruning approach based on Fisher LDA [1], which boosts efficiency while maintaining accuracy for facial trait classification. It starts from the last convolutional layer where we find filter activations are less correlated. Through Fisher's LDA, we show that this decorrelation makes it safe to discard directly filters with high within-class variance and low between-class variance. The pruning goes on by tracing deconvolution based dependency over layers. Combined with light classifiers, the reduced CNNs can achieve comparable accuracies on example facial traits from the LFWA(+) and CelebA datasets, but with large reductions in model size (96%-98% for VGG-16, 81% for GoogLeNet) and computation (as high as 80% for VGG-16, 61% for GoogLeNet). (C) 2018 Elsevier B.V. All rights reserved.
C1 [Tian, Qing] McGill Univ, Ctr Intelligent Machines, 3480 Univ St, Montreal, PQ, Canada.
   McGill Univ, ECE Dept, 3480 Univ St, Montreal, PQ, Canada.
C3 McGill University; McGill University
RP Tian, Q (corresponding author), McGill Univ, Ctr Intelligent Machines, 3480 Univ St, Montreal, PQ, Canada.
EM qing.tian@mail.mcgill.ca; arbel@cim.mcgill.ca; clark@cim.mcgill.ca
RI Clark, James/JPK-8317-2023; tian, qing/JMQ-8820-2023; Tian,
   Qing/ACD-4955-2022
OI Tian, Qing/0000-0003-1808-2887
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   McGill MEDA Award
FX The authors gratefully acknowledge the support of the Natural Sciences
   and Engineering Research Council of Canada (NSERC) and McGill MEDA
   Award. We would also like to acknowledge the support of NVIDIA
   Corporation with the donation of the GPUs used for this research.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   ALBRIGHT TD, 1984, J NEUROPHYSIOL, V51, P16, DOI 10.1152/jn.1984.51.1.16
   [Anonymous], 1990, NIPS
   [Anonymous], NEUR NETW 1999 IJCNN
   [Anonymous], 2014, ICLR
   [Anonymous], P NIPS
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, CORR
   [Anonymous], 2016, ICLR
   [Anonymous], 1989, ADV NEURAL INFORM PR
   [Anonymous], 2015, P INT C COMP VIS ICC
   [Anonymous], 2015, P COMP SCI SWANS UK
   [Anonymous], 2015, ARXIV151208571
   [Anonymous], 2005, ORG BEHAV NEUROPSYCH
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, 3 INT C LEARN REPR I
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   [Anonymous], 1996, ICML
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   [Anonymous], 2016, INT J COMPUT VIS IJC
   Ba LJ, 2014, ADV NEUR IN, V27
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Courbariaux M, 2015, ADV NEUR IN, V28
   Cun Y.L., 1989, Advances in neural information processing systems, V2, P598
   Egger V, 2008, CEREB CORTEX, V18, P876, DOI 10.1093/cercor/bhm126
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gaiwak A, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON PERSONAL WIRELESS COMMUNICATIONS, P441, DOI 10.1109/ICPWC.2005.1431384
   Geoffrey EHinton., 2012, Improving neural networks by preventing co-adaptation of feature detectors
   GOLDMAN PS, 1977, BRAIN RES, V122, P393, DOI 10.1016/0006-8993(77)90453-X
   Guo YW, 2016, ADV NEUR IN, V29
   Han S, 2015, P ADV NEUR INF PROC, V2015, P1135
   Hassibi B., 1993, Second order derivatives for network pruning: Optimal brain surgeon
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu Hengyuan, 2016, Network trimming: A data-driven neuron pruning approach towards efficient deep architectures
   Huang G.B., 2008, PROC WORKSHOP FACES
   HUBEL DH, 1974, J COMP NEUROL, V158, P295, DOI 10.1002/cne.901580305
   Iandola F.N., 2016, PROC INT C LEARN
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jin X, 2016, ARXIV160705423
   Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4
   Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li SX, 2015, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2015.7298618
   Li YP, 1999, LECT NOTES COMPUT SC, V1689, P234
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Lübke J, 2003, CEREB CORTEX, V13, P1051, DOI 10.1093/cercor/13.10.1051
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Mariet Z., 2016, INT C LEARN REPR
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701
   MOUNTCASTLE VB, 1957, J NEUROPHYSIOL, V20, P408, DOI 10.1152/jn.1957.20.4.408
   OToole AJ, 1997, PERCEPTION, V26, P75, DOI 10.1068/p260075
   Perez C, 2012, INT J OPTOMECHATRONI, V6, P92, DOI 10.1080/15599612.2012.663463
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Poggio B., 1992, Hyberbf networks for gender classification
   Polyak A, 2015, IEEE ACCESS, V3, P2163, DOI 10.1109/ACCESS.2015.2494536
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452
   Reid DA, 2013, HANDB STAT, V31, P327, DOI 10.1016/B978-0-444-53859-8.00013-8
   Rinkus GJ, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00160
   Rinkus GJ, 2010, FRONT NEUROANAT, V4, DOI 10.3389/fnana.2010.00017
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Struc V, 2009, INFORMATICA-LITHUAN, V20, P115
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang Y, 2013, ARXIV
   Tian Q, 2017, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2017.78
   Toews M, 2009, IEEE T PATTERN ANAL, V31, P1567, DOI 10.1109/TPAMI.2008.233
   Turk MatthewA., 1991, P CVPR 91, P586
   Ullah I., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P417
   Valiant LG, 2006, BIOL CYBERN, V95, P205, DOI 10.1007/s00422-006-0079-3
   Verma A, 2014, INT CONF SOFT COMP, P33, DOI 10.1109/ISCMI.2014.17
   WOOLSEY TA, 1970, BRAIN RES, V17, P205, DOI 10.1016/0006-8993(70)90079-X
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yosinski J, 2015, DEEP LEARNING WORKSH, DOI DOI 10.48550/ARXIV.1506.06579
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zhong Y, 2016, IEEE IMAGE PROC, P3239, DOI 10.1109/ICIP.2016.7532958
NR 93
TC 7
Z9 7
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2018
VL 77
BP 45
EP 59
DI 10.1016/j.imavis.2018.06.008
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV7DT
UT WOS:000446282900005
DA 2024-07-18
ER

PT J
AU Gilles, J
   Alvarez, F
   Ferrante, N
   Fortman, M
   Tahir, L
   Tarter, A
   von Seeger, A
AF Gilles, J.
   Alvarez, F.
   Ferrante, N.
   Fortman, M.
   Tahir, L.
   Tarter, A.
   von Seeger, A.
TI Detection of moving objects through turbulent media. Decomposition of
   Oscillatory vs Non-Oscillatory spatio-temporal vector fields
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Moving object detection; Atmospheric turbulence; Decomposition; Curvelet
   spaces
ID CONTINUOUS CURVELET TRANSFORM; IMAGE DECOMPOSITION; NOISE REMOVAL;
   OPTICAL-FLOW; STABILIZATION; RESTORATION
AB In this paper, we investigate how moving objects can be detected when images are impacted by atmospheric turbulence. We present a geometric spatio-temporal point of view to the problem and show that it is possible to distinguish movement due to the turbulence vs. moving objects. To perform this task, we propose an extension of 2D cartoon+texture decomposition algorithms to 3D vector fields. Our algorithm is based on curvelet spaces which permit to better characterize the movement flow geometry. We present experiments on real data which illustrate the efficiency of the proposed method. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Gilles, J.; Alvarez, F.; Ferrante, N.] San Diego State Univ, Dept Math & Stat, 5500 Campanile Dr, San Diego, CA 92182 USA.
   [Fortman, M.] Lake Forest Coll, LFC 582,555 N Sheridan Rd, Lake Forest, IL 60045 USA.
   [Tahir, L.] Mills Coll, 5000 MacArthur Blvd, Oakland, CA 94613 USA.
   [Tarter, A.] Creighton Univ, 2500 Calif Plaza, Omaha, NE 68178 USA.
   [von Seeger, A.] Georgetown Univ, Dept Math, 327A St Marys Hall,3700 O St NW, Washington, DC 20057 USA.
C3 California State University System; San Diego State University;
   Creighton University; Georgetown University
RP Gilles, J (corresponding author), San Diego State Univ, Dept Math & Stat, 5500 Campanile Dr, San Diego, CA 92182 USA.
EM jgilles@sdsu.edu; aalvarez.fr@gmail.com; nicholas.b.ferrante@icloud.com;
   fortmanma@mx.lakeforest.edu; ltahir@mills.edu; act72583@creighton.edu;
   amv48@georgetown.edu
OI Gilles, Jerome/0000-0002-5626-8386; von Seeger,
   Anneke/0000-0001-6962-9403
FU Air Force Office of Scientific Research [FA9550-15-1-0065]; NSF
   [DMS-1556480]
FX The authors want to thank the anonymous reviewers for their comments and
   suggestions which permit to deeply improve the manuscript. This material
   is based upon work supported by the Air Force Office of Scientific
   Research under award number FA9550-15-1-0065 and the NSF grant
   DMS-1556480.
CR Anantrasirichai N, 2013, IEEE T IMAGE PROCESS, V22, P2398, DOI 10.1109/TIP.2013.2249078
   [Anonymous], 1992, THEORY FUNCTION SPAC
   Apuroop A., 2014, P 2014 IND C COMP VI, DOI 10.1145/2683483.2683512
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   AUJOL JF, 2003, IMAGE DECOMPOSITION, P297, DOI DOI 10.1007/3-540-44935-3_21
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candès EJ, 2005, APPL COMPUT HARMON A, V19, P162, DOI 10.1016/j.acha.2005.02.003
   Candès EJ, 2005, APPL COMPUT HARMON A, V19, P198, DOI 10.1016/j.acha.2005.02.004
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319, DOI 10.1109/83.661182
   Chen E, 2014, APPL OPTICS, V53, P1181, DOI 10.1364/AO.53.001181
   Donoho DL, 2000, P SOC PHOTO-OPT INS, V4056, P12, DOI 10.1117/12.381679
   Fishbain B, 2007, J REAL-TIME IMAGE PR, V2, P11, DOI 10.1007/s11554-007-0037-x
   Frakes DH, 2001, INT CONF ACOUST SPEE, P1881, DOI 10.1109/ICASSP.2001.941311
   Gepshtein S., 2004, P EUSIPCO VIENN AUST
   Gilles J., 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1JEI.25.3.033003
   Gilles J, 2017, PATTERN RECOGN LETT, V86, P38, DOI 10.1016/j.patrec.2016.12.020
   Gilles J, 2014, SIAM J IMAGING SCI, V7, P157, DOI 10.1137/130923774
   Gilles J, 2013, IEEE T SIGNAL PROCES, V61, P3999, DOI 10.1109/TSP.2013.2265222
   Gilles J, 2012, PROC SPIE, V8355, DOI 10.1117/12.917234
   Guyon Charles., 2012, Principal component analysis
   Halder KK, 2016, J MOD OPTIC, V63, P1015, DOI 10.1080/09500340.2015.1117665
   Halder KK, 2014, APPL OPTICS, V53, P7087, DOI 10.1364/AO.53.007087
   Halder KK, 2013, LECT NOTES COMPUT SC, V8192, P60, DOI 10.1007/978-3-319-02895-8_6
   Halder KK, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P394, DOI 10.1109/ICACCI.2013.6637204
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Li DL, 2007, IEEE GEOSCI REMOTE S, V4, P340, DOI 10.1109/LGRS.2007.895691
   Lou YF, 2013, INVERSE PROBL IMAG, V7, P839, DOI 10.3934/ipi.2013.7.839
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Mao Y, 2012, INVERSE PROBL IMAG, V6, P531, DOI 10.3934/ipi.2012.6.531
   Meinhardt-Llopis E, 2014, IMAGE PROCESS ON LIN, V4, P187, DOI 10.5201/ipol.2014.105
   Meinhardt-Llopis E, 2013, IMAGE PROCESS ON LIN, V3, P151, DOI 10.5201/ipol.2013.20
   MEYER Y, 2001, 15 JB LEWIS MEMORIAL
   Micheli M, 2014, J MATH IMAGING VIS, V48, P185, DOI 10.1007/s10851-012-0410-7
   Oreifej O, 2013, IEEE T PATTERN ANAL, V35, P450, DOI 10.1109/TPAMI.2012.97
   Osher S, 2002, SIAM MULTISCALE MODE, V1, P349, DOI DOI 10.1137/S1540345902416247
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Robinson PE, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.063010
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Song CX, 2015, INFRARED PHYS TECHN, V71, P171, DOI 10.1016/j.infrared.2015.03.009
   Starck JL, 2003, PROC SPIE, V5207, P571, DOI 10.1117/12.507447
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Ten Daubechies I., 1992, lecture on wavelets
   Vercauteren T., 2009, NEUROIMAGE S1, V45
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Yang B, 2013, INT CONF INFO SCI, P414
   Ying L., 2005, OPTICS PHOTONICS
   Yuan J, 2005, LECT NOTES COMPUT SC, V3752, P1
   Yuan J, 2007, SIAM J SCI COMPUT, V29, P2283, DOI 10.1137/060660709
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhu X, 2010, PROC SPIE, V7543, DOI 10.1117/12.840127
   Zwart CM, 2012, PROC SPIE, V8355, DOI 10.1117/12.921125
NR 56
TC 5
Z9 6
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2018
VL 73
BP 40
EP 55
DI 10.1016/j.imavis.2018.03.006
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GH7SF
UT WOS:000433653000004
OA Bronze
DA 2024-07-18
ER

PT J
AU Belgacem, S
   Chatelain, C
   Paquet, T
AF Belgacem, Selma
   Chatelain, Clement
   Paquet, Thierry
TI Gesture sequence recognition with one shot learned CRF/HMM hybrid model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gesture recognition; One-shot-learning; Hybrid system; Hidden Markov
   model; Conditional random field; Gesture characterisation
AB In this paper, we propose a novel markovian hybrid system CRF/HMM for gesture recognition, and a novel motion description method called gesture signature for gesture characterisation. The gesture signature is computed using the optical flows in order to describe the location, velocity and orientation of the gesture global motion. We elaborated the proposed hybrid CRF/HMM model by combining the modeling ability of Hidden Markov Models and the discriminative ability of Conditional Random Fields. In the context of one-shot-learning, this model is applied to the recognition of gestures in videos. In this extreme case, the proposed framework achieves very interesting performance and remains independent from the moving object type, which suggest possible application to other motion-based recognition tasks. (C) 2017 Elsevier B.V. All rights reserved.
EM belgacemselma@yahoo.fr
RI chatelain, clement/AAC-7383-2022
OI chatelain, clement/0000-0001-8377-0630; Belgacem,
   Selma/0000-0003-0872-0582
CR [Anonymous], P C ADV NEUR INF PRO
   [Anonymous], 2012, 2012 IEEE COMP SOC C, DOI DOI 10.1109/CVPRW.2012.6239179
   [Anonymous], 2001, PROC 18 INT C MACH L
   AUSTIN S, 1991, INT CONF ACOUST SPEE, P697, DOI 10.1109/ICASSP.1991.150435
   BENGIO Y, 1995, NEURAL COMPUT, V7, P1289, DOI 10.1162/neco.1995.7.6.1289
   Bhandarkar SM, 2009, COMPUT VIS IMAGE UND, V113, P708, DOI 10.1016/j.cviu.2008.11.010
   Corradini A., 2001, Lecture Notes in Computer Science, Revised Papers from the International Gesture Workshop on Gesture and Sign Languages in Human-Computer Interaction, V2298, P34
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ganapathiraju A., 2000, Speech Transcription Workshop, P504
   Gilloux M, 1995, ICDAR, P394
   Gunawardana Asela., 2005, Proceedings of Nineth European Conference on Speech Communication and Technology (EuroSpeech 2005), P1117
   Guyon I., 2012, P IEEE COMP SOC C CO, P1
   Hebert D, 2011, PROC INT CONF DOC, P493, DOI 10.1109/ICDAR.2011.105
   Jackson E., 2012, CVPR 2012 WORKSH GES
   Johansen F., 1996, ICSLP
   Knerr S, 1998, INT C PATT RECOG, P1518, DOI 10.1109/ICPR.1998.711996
   Konencny J., 2012, ICPR 2012 WORKSH GES
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   Marukatat S, 2001, PROC INT CONF DOC, P731, DOI 10.1109/ICDAR.2001.953886
   MATAN O, 1992, ADV NEUR IN, V4, P488
   Morgan N., 1993, INT J PATTERN RECOGN, V7
   Morita M., 2003, INT J DOC ANAL RECOG, V6
   Neidle C, 2001, BEHAV RES METH INS C, V33, P311, DOI 10.3758/BF03195384
   NILES LT, 1990, INT CONF ACOUST SPEE, P417, DOI 10.1109/ICASSP.1990.115724
   Ong SCW, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P559, DOI 10.1109/AFGR.2004.1301592
   Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Radosavljevic V, 2010, FRONT ARTIF INTEL AP, V215, P809, DOI 10.3233/978-1-60750-606-5-809
   Rajko S, 2005, LECT NOTES COMPUT SC, V3804, P227
   Rigoll G, 1994, IEEE T SPEECH AUDI P, V2, P175, DOI 10.1109/89.260360
   SAYRE KM, 1973, PATTERN RECOGN, V5, P213, DOI 10.1016/0031-3203(73)90044-7
   Soullard Y., 2011, EUR S ART NEUR NETW
   Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013
   Thomas S, 2015, PATTERN ANAL APPL, V18, P1003, DOI 10.1007/s10044-014-0433-3
   Trentin E, 2001, NEUROCOMPUTING, V37, P91, DOI 10.1016/S0925-2312(00)00308-8
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895
   von Agris Ulrich, 2008, Universal Access in the Information Society, V6, P323, DOI 10.1007/s10209-007-0104-x
   Weiss D., 2012, CVPR 2012 WORKSH GES
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P1635, DOI 10.1109/TPAMI.2012.253
   Zavaliagkos G., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P949, DOI 10.1142/S0218001493000480
NR 41
TC 27
Z9 28
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2017
VL 61
BP 12
EP 21
DI 10.1016/j.imavis.2017.02.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EU7HK
UT WOS:000401205700002
DA 2024-07-18
ER

PT J
AU Trokielewicz, M
   Czajka, A
   Maciejewicz, P
AF Trokielewicz, Mateusz
   Czajka, Adam
   Maciejewicz, Piotr
TI Implications of ocular pathologies for iris recognition reliability
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris recognition; Ocular disease; Biometrics; Ophthalmology
AB This paper presents an analysis of how iris recognition is influenced by eye disease and an appropriate dataset comprising 2996 images of irises taken from 230 distinct eyes (including 184 affected by more than 20 different eye conditions). The images were collected in near infrared and visible light during routine ophthalmological examination. The experimental study carried out utilizing four independent iris recognition algorithms (MIRLIN, VeriEye, OSIRIS and IriCore) renders four valuable results. First, the enrollment process is highly sensitive to those eye conditions that obstruct the iris or cause geometrical distortions. Second, even those conditions that do not produce visible changes to the structure of the iris may increase the dissimilarity between samples of the same eyes. Third, eye conditions affecting the geometry or the tissue structure of the iris or otherwise producing obstructions significantly decrease same-eye similarity and have a lower, yet still statistically significant, influence on impostor comparison scores. Fourth, for unhealthy eyes, the most prominent effect of disease on iris recognition is to cause segmentation errors. To our knowledge this paper describes the largest database of iris images for disease-affected eyes made publicly available to researchers and offers the most comprehensive study of what we can expect when iris recognition is employed for diseased eyes. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Trokielewicz, Mateusz; Czajka, Adam] Res & Acad Comp Network NASIC, Biometr Lab, Kolska 12, PL-01045 Warsaw, Poland.
   [Trokielewicz, Mateusz; Czajka, Adam] Warsaw Univ Technol, Inst Control & Computat Engn, Nowowiejska 15-19, PL-00665 Warsaw, Poland.
   [Maciejewicz, Piotr] Med Univ Warsaw, Dept Ophthalmol, Lindleya 4, PL-02005 Warsaw, Poland.
C3 Warsaw University of Technology; Medical University of Warsaw
RP Czajka, A (corresponding author), Res & Acad Comp Network NASIC, Biometr Lab, Kolska 12, PL-01045 Warsaw, Poland.
EM aczajka@elka.pw.edu.pl
RI Trokielewicz, Mateusz/AAC-2728-2020
OI Trokielewicz, Mateusz/0000-0002-7363-8385
CR [Anonymous], 2013, IREX 6 TEMPORAL STAB
   [Anonymous], 2012, P 2012 IEEE COMP VIS
   Aslam T. M., 2009, J R SOC INTERFACE, V2009, P6
   Baker S.E., 2013, Handbook of Iris Recognition, P205
   Borgen H, 2009, LECT NOTES COMPUT SC, V5558, P857, DOI 10.1007/978-3-642-01793-3_87
   Czajka A, 2014, COMM COM INF SC, V452, P284, DOI 10.1007/978-3-662-44485-6_20
   Daugman J.G., 1994, U.S. Patent, Patent No. 5291560
   Dhir L, 2010, EYE, V24, P1006, DOI 10.1038/eye.2009.275
   Fenker SamuelP., 2011, WORKSHOP APPL COMPUT, P232, DOI DOI 10.1109/WACV.2011.5711508
   Flom L., 1987, US Patent, Patent No. [4641349, 4,641,349]
   Guillaume Sutra, BIOMETRIC REFERENCE
   International Civil Aviation Organization, 2006, 9303 INT CIV AV ORG
   IriTech Inc, 2013, IRICORE SOFTWARE DEV
   McConnon G., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P277, DOI 10.1109/ICB.2012.6199820
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Phillips P. J., 2005, BIOMETRICS THEORY AP, P1
   Roizenblatt R, 2004, BIOMED ENG ONLINE, V3, DOI 10.1186/1475-925X-3-2
   Seyeddain O, 2014, EUR J OPHTHALMOL, V24, P58, DOI 10.5301/ejo.5000343
   Smart Sensors Ltd, 2013, MIRLIN SDI VERS 2 23
   Trokielewicz M., 2015, 2 IEEE INT C CYB CYB
   Trokielewicz M., 2015, IEEE 3 INT WORKSH BI
   Trokielewicz M., 2015, 7 IEEE INT C BIOM TH
   Trokielewicz M, 2014, PROC SPIE, V9290, DOI 10.1117/12.2076040
   Yuan XY, 2007, J ZHEJIANG UNIV-SC A, V8, P1227, DOI 10.1631/jzus.2007.A1227
NR 24
TC 10
Z9 10
U1 1
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 158
EP 167
DI 10.1016/j.imavis.2016.08.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, DJ
   Li, QQ
   Chen, Y
   Cao, M
   He, L
   Zhang, BL
AF Zhang, Dejin
   Li, Qingquan
   Chen, Ying
   Cao, Min
   He, Li
   Zhang, Bailing
TI An efficient and reliable coarse-to-fine approach for asphalt pavement
   crack detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pavement crack detection; Adaptive thresholding; Image segmentation;
   Region growing algorithm
ID THRESHOLD SELECTION METHOD
AB Among the various defects of asphalt pavement distress, much attention has been paid to cracks which often cause significant engineering and economic problems. Crack detection is not an easy task since images of road pavement surface are very difficult to analyze. In this paper, a highly efficient pavement crack detection system is proposed, which has the following distinguishing features. Firstly, a new description of the cracks is proposed based on the spatially clustered pixels with similar gray levels. Secondly, an adaptive thresholding method is presented for image segmentation by comprehensively taking into account the spatial distribution, intensities and geometric features of cracks. Thirdly, a new concept termed Region of Belief (ROB) is introduced to facilitate the subsequent detection by defining some credibility factors which indicate the reliability that a region could be labeled as a distress region which contains cracks, and an algorithm to extract such ROBs is devised accordingly. Lastly, a novel region growing algorithm is propounded for crack detection, which features starting with an ROB seed, determining the searching scope with a specially devised rule, and searching and merging a ROB with different regions following a similarity criterion which synthetically takes different cues into consideration. Two different types of experiments were conducted. The first one was carried out using 10,000 of our field-captured images which were taken from different road conditions and environments. The second one was completed using a benchmark dataset for a comparison with other recent publications. The evaluation performance is satisfactory for a variety of different cracks. For our own data, the detection accuracy is over 95% and more than 90% of coherent cracks Without disconnected fragments have been correctly detected as the integrated ones. For the benchmark data, our detection performance also outperforms previously published results. Currently, our approach has been widely applied in China. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zhang, Dejin; Li, Qingquan] Shenzhen Univ, Shenzhen Key Lab Spatial Informat Smart Sensing &, Shenzhen 518060, Peoples R China.
   [Zhang, Dejin; Li, Qingquan] Shenzhen Univ, Natl Adm Surveying Mapping & Geo Informat, Key Lab Geoenvironm Monitoring Coastal Zone, Shenzhen 518060, Peoples R China.
   [Chen, Ying; Cao, Min] Wuhan Wuda Zoyon Sci & Technol Co Ltd, Wuhan 430223, Peoples R China.
   [He, Li] Hubei Univ Technol, Sch Elect & Elect Engn, Wuhan 430068, Peoples R China.
   [Zhang, Bailing] Xian Jiaotong Liverpool Univ, Dept Comp Sci & Software Engn, Suzhou 215123, Peoples R China.
C3 Shenzhen University; Shenzhen University; Hubei University of
   Technology; Xi'an Jiaotong-Liverpool University
RP He, L (corresponding author), Hubei Univ Technol, Sch Elect & Elect Engn, Wuhan 430068, Peoples R China.
EM heli.edu@hotmail.com
FU Major Technology Research Grant for Shenzhen Strategic Emerging
   Industries, Shenzhen, China [JSGG20121026111056204]
FX The project is funded by the Major Technology Research Grant for
   Shenzhen Strategic Emerging Industries, Shenzhen, China
   (JSGG20121026111056204).
CR [Anonymous], DIGITAL IMAGE PROCES
   Bai XZ, 2012, APPL OPTICS, V51, P5201, DOI 10.1364/AO.51.005201
   Boyle, 2014, CENGAGE LEARNING
   Bray J, 2006, IEEE IJCNN, P907
   Chambon S, 2011, INT J GEOPHYS, V2011, DOI 10.1155/2011/989354
   Chanda B, 1998, PATTERN RECOGN, V31, P1469, DOI 10.1016/S0031-3203(98)00014-4
   [陈琪 Chen Qi], 2010, [电子与信息学报, Journal of Electronics & Information Technology], V32, P1100
   El-Korchi T., 1990, TRANSPORT RES REC, V1260, P74
   Elbehiery H., 2007, INT J COMPUT INF SYS, V1, P1462
   Eslami R, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P465, DOI 10.1109/ICME.2006.262573
   Gavilán M, 2011, SENSORS-BASEL, V11, P9628, DOI 10.3390/s111009628
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   Huang YX, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2177650
   Li Li, 2012, Proceedings of the 12th International Conference of Transportation Professionals (CICTP 2012), P3095, DOI 10.1061/9780784412442.315
   Li QQ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P792, DOI 10.1109/CISP.2008.13
   Liu FF, 2008, KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS, P610, DOI 10.1109/KAM.2008.29
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   McCall JC, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P533
   Moghadas Nejad F, 2011, EXPERT SYST APPL, V38, P9442, DOI 10.1016/j.eswa.2011.01.089
   Moghadas Nejad F, 2011, EXPERT SYST APPL, V38, P2857, DOI 10.1016/j.eswa.2010.08.079
   Oliveira Henrique, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P622
   Oliveira H, 2013, IEEE T INTELL TRANSP, V14, P155, DOI 10.1109/TITS.2012.2208630
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   POLLARD D, 1982, IEEE T INFORM THEORY, V28, P199, DOI 10.1109/TIT.1982.1056481
   Robert J.M., 1990, COMPUTATIONAL GEOMET, P11
   Shu Z., 2010, 9 INT S DISTR COMP A
   Sun Y, 2009, INT CONF ELECTRO INF, P371
   Sy N. T., 2008, MELECON 2008 - 2008 IEEE Mediterranean Electrotechnical Conference, P847, DOI 10.1109/MELCON.2008.4618541
   Tanaka N., 1998, Proceedings of IAPR Workshop on Machine Vision Applications, P154
   WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351
   Yan MO, 2007, ICEMI 2007: PROCEEDINGS OF 2007 8TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS, VOL IV, P548
   Ying L, 2009, INT C EL TECHN EIT09, P7
   Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1624, DOI 10.1109/TITS.2011.2158001
   Zou Q, 2012, PATTERN RECOGN LETT, V33, P227, DOI 10.1016/j.patrec.2011.11.004
NR 35
TC 98
Z9 108
U1 2
U2 89
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 130
EP 146
DI 10.1016/j.imavis.2016.11.018
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800011
DA 2024-07-18
ER

PT J
AU Nappi, M
   Ricciardi, S
   Tistarelli, M
AF Nappi, Michele
   Ricciardi, Stefano
   Tistarelli, Massimo
TI Deceiving faces: When plastic surgery challenges face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Plastic surgery; State of the art survey
ID CLASSIFICATION; SCALE
AB An exponential growth of the number of plastic surgery treatments specific to face (from the minimally-invasive ones to the real surgical procedures) has characterized the last two decades and it seems likely that this phenomenon, that has social and cultural meanings and implications, could spread even further in the next years as the average cost of these treatments is lowering and the wish for "beautification" is becoming part of the global esthetics sense. For these reasons, face recognition as an established research topic has a new major challenge: delivering methods capable of high recognition accuracy even in case probe and gallery differ by a surgical alteration of face shape. To this aim is of fundamental importance understanding the range and the extent of the modification produced by the various types of treatments or by a combination of them. We present a survey of the state of the art on this topic, starting by an analysis of the diffusion of the facial plastic surgery and describing the key aspects of each of the most statistically relevant treatments available, resumed by a synthetic table. The paper includes a brief description of all the approaches proposed in the field so far to the best of authors' knowledge and a comparison of the performance reported by the existing methods when applied to the most referenced plastic surgery face dataset to date. A critical discussion of the results achieved so far and an insight about the challenges that still have to be addressed concludes this work. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Nappi, Michele; Ricciardi, Stefano] Univ Salerno, BipLab, I-84084 Fisciano, SA, Italy.
   [Tistarelli, Massimo] Univ Sassari, Comp Vis Lab, I-07041 Alghero, SS, Italy.
C3 University of Salerno; University of Sassari
RP Ricciardi, S (corresponding author), Univ Salerno, BipLab, I-84084 Fisciano, SA, Italy.
EM mnappi@unisa.it; sricciardi@unisa.it; tista@uniss.it
RI Tistarelli, Massimo/AAH-9437-2021; Nappi, Michele/X-3089-2019;
   Ricciardi, Stefano/R-4359-2016
OI Tistarelli, Massimo/0000-0002-3406-3048; Ricciardi,
   Stefano/0000-0003-2123-452X; Nappi, Michele/0000-0002-2517-2867
CR Aggarwal G., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P113, DOI 10.1109/WACV.2012.6163008
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2013, AGR ARCHAEOLOGY
   [Anonymous], 2010, J TELECOMMUN INF TEC
   [Anonymous], IEEE T PATTERN ANAL
   Bargiela A., 2002, Granular computing: an introduction
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bhatt HS, 2013, IEEE T INF FOREN SEC, V8, P89, DOI 10.1109/TIFS.2012.2223684
   Cox IJ, 1996, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.1996.517076
   De Marsico M, 2015, PATTERN RECOGN, V48, P1261, DOI 10.1016/j.patcog.2014.10.004
   De Marsico M, 2011, LECT NOTES COMPUT SC, V6754, P191, DOI 10.1007/978-3-642-21596-4_20
   De Marsico M, 2010, IEEE IMAGE PROC, P1597, DOI 10.1109/ICIP.2010.5650758
   De Marsico M, 2010, IEEE T SYST MAN CY A, V40, P121, DOI 10.1109/TSMCA.2009.2033031
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   El-Said SA, 2014, INT J COMPUT APPL T, V49, P352, DOI 10.1504/IJCAT.2014.062371
   Fisher Y., 1994, Fractal Image Compression
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Ibrahim, 2013, IJCSI INT J COMPUT S, V10
   Kennedy J., 2001, Swarm Intelligence
   Klare B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1513, DOI 10.1109/ICPR.2010.374
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Lakshmiprabha NS, 2011, IM INF PROC ICIIP 20, P1, DOI [10.1109/ICIIP.2011.6108945, DOI 10.1109/ICIIP.2011.6108945]
   Lei Z, 2012, IEEE T INF FOREN SEC, V7, P1707, DOI 10.1109/TIFS.2012.2210041
   Leyvand T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360637
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Li SZ, 2009, PROC CVPR IEEE, P267, DOI 10.1109/FSKD.2009.137
   Liao SC, 2009, LECT NOTES COMPUT SC, V5558, P209, DOI 10.1007/978-3-642-01793-3_22
   Lin TsauYoung., 2002, DATA MINING ROUGH SE
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu X., 2012, COMPUTER VISION ACCV, P565
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maatta J, 2011, INT JOINT C BIOM IJC, P1, DOI DOI 10.1109/IJCB.2011.6117510
   Mika S., 1999, NNSP, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Mun M., 2014, INT J COMPUT SCI INF, V5, P3711
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002
   Ponmuthuramalingam P., 2013, INT J ADV RES COMPUT, V3, P316
   Schroff F, 2011, IEEE I CONF COMP VIS, P2494, DOI 10.1109/ICCV.2011.6126535
   Shen LL, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/30274
   Singh Richa, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P72, DOI 10.1109/CVPR.2009.5204287
   Singh R., IEEE T INF FOREN SEC, V5
   Singh R, 2009, IMAGE VISION COMPUT, V27, P245, DOI 10.1016/j.imavis.2007.06.010
   Struc V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/847680
   Verghis T. J., COMPUSOFT INT J ADV, V3
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M. H., FACE RECOGNITION USI
   Zhao W, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P336, DOI 10.1109/AFGR.1998.670971
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
   Zhu C., 2011, COMP VIS PATT REC NP, P448
NR 53
TC 30
Z9 31
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2016
VL 54
BP 71
EP 82
DI 10.1016/j.imavis.2016.08.012
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EB6UG
UT WOS:000387520500007
DA 2024-07-18
ER

PT J
AU Ding, XY
   Chu, WS
   De la Torre, F
   Cohn, JF
   Wang, Q
AF Ding, Xiaoyu
   Chu, Wen-Sheng
   De la Torre, Fernando
   Cohn, Jeffery F.
   Wang, Qiao
TI Cascade of Tasks for facial expression analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automated facial expression analysis; Action unit detection; FACS
ID RECOGNITION; DYNAMICS; EMOTION; ALCOHOL; FACE
AB Automatic facial action unit (AU) detection from video is a long-standing problem in facial expression analysis. Existing work typically poses AU detection as a classification problem between frames or segments of positive and negative examples, and emphasizes the use of different features or classifiers. In this paper, we propose a novel AU event detection method, Cascade of Tasks (CoT), which combines the use of different tasks (i.e., frame-level detection, segment-level detection and transition detection). We train CoT sequentially embracing diversity to ensure robustness and generalization to unseen data. Unlike conventional frame-based metrics that evaluate frames independently, we propose a new event-based metric to evaluate detection performance at the event-level. The event-based metric measures the ratio of correctly detected AU events instead of frames. We show how the CoT method consistently outperforms state-of-the-art approaches in both frame-based and event-based metrics, across four datasets that differ in complexity: CK+, FERA, RU-FACS and GFT. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Ding, Xiaoyu; Wang, Qiao] Southeast Univ, Sch Informat Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Chu, Wen-Sheng; De la Torre, Fernando; Cohn, Jeffery F.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   [Cohn, Jeffery F.] Univ Pittsburgh, Dept Psychol, Pittsburgh, PA 15260 USA.
C3 Southeast University - China; Carnegie Mellon University; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); University of
   Pittsburgh
RP Ding, XY (corresponding author), Southeast Univ, Sch Informat Sci & Engn, Nanjing, Jiangsu, Peoples R China.
EM leonxd@andrew.cmu.edu; wschu@cmu.edu; ftorre@cs.cmu.edu;
   jeffcohn@pitt.edu; qiaowang@seu.edu.cn
RI Chu, Wen-Sheng/AAF-6871-2019; Wang, Qiao/AAU-2338-2020
OI Chu, Wen-Sheng/0000-0001-8592-6088; Wang, Qiao/0000-0002-5271-0472
FU National Institute of Mental Health of the National Institutes of Health
   [MH096951]; National Science Foundation [RI-1116583, IIS 1418026,
   1418520-L]; Specific Medical Science Fund of Technological Innovation
   and Achievements Transformation of Jiangsu Province [BL2012025]; NSF of
   China [91330109]; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [1418520] Funding Source: National
   Science Foundation
FX Research reported in this publication was supported in part by the
   National Institute of Mental Health of the National Institutes of Health
   under award number MH096951 and the National Science Foundation under
   the grants RI-1116583, IIS 1418026 and 1418520-L. The content is solely
   the responsibility of the authors and does not necessarily represent the
   official views of the National Institutes of Health or the National
   Science Foundation. X. Ding and Q. Wang are supported by Specific
   Medical Science Fund of Technological Innovation and Achievements
   Transformation of Jiangsu Province under Grant No. BL2012025, and NSF of
   China under Grant No. 91330109.
CR Almaev TR, 2013, INT CONF AFFECT, P356, DOI 10.1109/ACII.2013.65
   Ambadar Z, 2009, J NONVERBAL BEHAV, V33, P17, DOI 10.1007/s10919-008-0059-5
   [Anonymous], PAMI
   [Anonymous], COMBINED SUPPORT VEC
   [Anonymous], IMAGE VIS COMPUT
   [Anonymous], KERNEL CONDITIONAL O
   [Anonymous], NONPARAMETRIC DISCRI
   [Anonymous], 2013, FACING IMBALANCED DA
   [Anonymous], EXTENDED COHN KANADE
   [Anonymous], INTERSPEECH
   [Anonymous], SUPERVISED DESCENT M
   [Anonymous], 2014, IEEE INT CONF AUTOMA
   [Anonymous], ACTION UNIT DETECTIO
   [Anonymous], IEEE INT C SYST MAN
   [Anonymous], VARIABLE STATE LATEN
   [Anonymous], ACTION UNIT DETECTIO
   [Anonymous], PERSON INDEPENDENT F
   [Anonymous], JOINT SEGMENTATION C
   [Anonymous], UNSUPERVISED DISCOVE
   [Anonymous], FEATURES FUSION EXPR
   [Anonymous], CVPR WORKSH
   [Anonymous], LEARNING ACTIVE FACI
   [Anonymous], EMOTION RECOGNITION
   [Anonymous], FAST FACS COMPUTER A
   [Anonymous], PAMI
   [Anonymous], CROWDSOURCING MICROL
   [Anonymous], UNSUPERVISED TEMPORA
   [Anonymous], UNIFIED PROBABILISTI
   [Anonymous], DECISION LEVEL FUSIO
   [Anonymous], OXFORD U PRESS SERIE
   [Anonymous], SELECTIVE TRANSFER M
   [Anonymous], HDB AFFECTIVE COMPUT
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], IEEE T AFFECT COMPUT
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chang Kai-Yueh., 2009, Learning partially-observed hidden conditional random fields for facial expression recognition"
   Chen SZ, 2013, IMAGE VISION COMPUT, V31, P175, DOI 10.1016/j.imavis.2012.06.014
   Ekman P., 2005, WHAT FACE REVEALS
   Ekman P., 2002, FACIAL ACTION CODING
   Fairbairn CE, 2013, EMOTION, V13, P468, DOI 10.1037/a0030934
   Jiang BH, 2014, IEEE T CYBERNETICS, V44, P161, DOI 10.1109/TCYB.2013.2249063
   Koelstra S, 2013, IMAGE VISION COMPUT, V31, P164, DOI 10.1016/j.imavis.2012.10.002
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Littlewort GC, 2009, IMAGE VISION COMPUT, V27, P1797, DOI 10.1016/j.imavis.2008.12.010
   Lucey Simon., 2007, FACE RECOGNITION DEL, P275
   Martinez A, 2012, J MACH LEARN RES, V13, P1589
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Pantic M., 2007, FACE RECOGNITION, P377
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Platt J., PROBABILISTIC OUTPUT
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P762, DOI 10.1016/j.imavis.2012.01.006
   Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008
   Sayette MA, 2012, PSYCHOL SCI, V23, P869, DOI 10.1177/0956797611435134
   Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Stratou G, 2012, IMAGE VISION COMPUT, V30, P728, DOI 10.1016/j.imavis.2012.02.001
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P966, DOI 10.1109/TSMCB.2012.2200675
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Wu TF, 2012, IEEE T SYST MAN CY B, V42, P1027, DOI 10.1109/TSMCB.2012.2195170
   Wu Xiaoyun., 2004, INCORPORATING PRIOR
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
NR 67
TC 7
Z9 9
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2016
VL 51
BP 36
EP 48
DI 10.1016/j.imavis.2016.03.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4HB
UT WOS:000378455900004
OA hybrid
DA 2024-07-18
ER

PT J
AU Niroshika, UAA
   Meegama, RGN
AF Niroshika, U. A. A.
   Meegama, R. G. N.
TI BLAID: Boundaries from Locally Adaptive Isotropic Detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Corner detection; Object boundaries; Corner points
ID TIME CORNER DETECTION; MOTION
AB Detection of corners is an important task in computer vision to capture discontinuous boundaries of objects of interest. Present operators designed to detect boundaries having sharp corners often produce unsatisfactory results because the points detected could also be an isolated point, ending of a thin line or a maximum curvature region of a planar curve. A novel corner detection operator, capable of detecting corner points that exist only on the boundary of an object, is presented in this paper. Initially, candidate corner points are detected by exploiting intensity information of the local neighborhood and associated connectivity patterns around the center point within a local window. Further verification is done to confirm whether the detected corner point is on the boundary of the targeted object. As the proposed operator is isotropic, it covers all the orientations and corner angles by performing a single computation step within the local window. The performance of the operator is tested with both synthetic and real images and the results are compared with other major corner detectors. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Niroshika, U. A. A.] Sri Lanka Inst Informat Technol, Fac Comp, Dept Informat Technol, Malabe, Sri Lanka.
   [Meegama, R. G. N.] Univ Sri Jayewardenepura, Fac Sci Appl, Dept Comp Sci, Nugegoda 10250, Sri Lanka.
C3 Sri Lanka Institute of Information Technology (SLIIT); University Sri
   Jayewardenepura
RP Meegama, RGN (corresponding author), Univ Sri Jayewardenepura, Fac Sci Appl, Dept Comp Sci, Nugegoda 10250, Sri Lanka.
EM aruni_niroshika@yahoo.com; rgn@sci.sjp.ac.lk
CR [Anonymous], 1979, P 6 INT JOINT C ART
   Awrangjeb M, 2012, IEEE T IMAGE PROCESS, V21, P4167, DOI 10.1109/TIP.2012.2200493
   Ballard D.H., 1982, Computer Vision
   Basak J, 2000, IEEE T NEURAL NETWOR, V11, P1124, DOI 10.1109/72.870044
   BASAK J, 1995, IEEE T NEURAL NETWOR, V6, P1337, DOI 10.1109/72.471373
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579
   de la Escalera A, 2010, SENSORS-BASEL, V10, P2027, DOI 10.3390/s100302027
   DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733
   Dongxiang Zhou, 2004, Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788), P4020, DOI 10.1109/WCICA.2004.1342254
   Duan XH, 2010, INT CONF ACOUST SPEE, P1462, DOI 10.1109/ICASSP.2010.5495486
   Forlenza L, 2012, SENSORS-BASEL, V12, P863, DOI 10.3390/s120100863
   HAN MH, 1990, PATTERN RECOGN, V23, P21, DOI 10.1016/0031-3203(90)90046-N
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Harris C., 1990, P 1 EUR C COMP VIS, P118
   Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4
   Kovacs A., 2011, PATTERN RECOGN LETT, V15, P2239
   Liu YR, 2008, IEEE INT C NETW SENS, P708
   Mokhtarian F, 2006, COMPUT VIS IMAGE UND, V102, P81, DOI 10.1016/j.cviu.2005.11.001
   Montero Andres Solis, 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P495, DOI 10.1109/CIT.2010.109
   Moravec Hans P., 1977, P INT JOINT C ART IN, P584
   RANGARAJAN K, 1989, COMPUT VISION GRAPH, V48, P230, DOI 10.1016/S0734-189X(89)80039-8
   Reid ID, 1996, INT J COMPUT VISION, V18, P41, DOI 10.1007/BF00126139
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Shapiro LS., 1995, AFFINE ANAL IMAGE SE
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Sojka E., 2002, Proceedings of the 18th ACM Spring Conference on Computer Graphics, SCCG '02, P55
   Subramanyam M. V., 2012, INT J SIGNAL IMAGE P, V3, P111
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   Viswanathan D. G., 2014, FEATURES ACCELERATED
   WANG H, 1995, IMAGE VISION COMPUT, V13, P695, DOI 10.1016/0262-8856(95)98864-P
   Weerasena H. H., 2011, 2011 7th International Conference on Information Assurance and Security (IAS), P280, DOI 10.1109/ISIAS.2011.6122846
   Wei He, 2010, Proceedings 2010 International Conference on Optoelectronics and Image Processing (ICOIP 2010), P40, DOI 10.1109/ICOIP.2010.97
   Zhang XH, 2010, PATTERN RECOGN, V43, P1207, DOI 10.1016/j.patcog.2009.10.017
   Zhao J, 2009, 2009 INTERNATIONAL ASIA SYMPOSIUM ON INTELLIGENT INTERACTION AND AFFECTIVE COMPUTING, P112, DOI 10.1109/ASIA.2009.23
   Zheng ZQ, 1999, PATTERN RECOGN LETT, V20, P149, DOI 10.1016/S0167-8655(98)00134-2
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 38
TC 0
Z9 0
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2016
VL 51
BP 49
EP 57
DI 10.1016/j.imavis.2016.04.006
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4HB
UT WOS:000378455900005
DA 2024-07-18
ER

PT J
AU Yang, L
   Jing, LP
   Ng, MK
   Yu, J
AF Yang, Liu
   Jing, Liping
   Ng, Michael K.
   Yu, Jian
TI A discriminative and sparse topic model for image classification and
   annotation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Graphical model; Discriminative topic; Sparsity; Image classification;
   Image annotation
AB Image classification is to assign a category of an image and image annotation is to describe individual components of an image by using some annotation terms. These two learning tasks are strongly related. The main contribution of this paper is to propose a new discriminative and sparse topic model (DSTM) for image classification and annotation by combining visual, annotation and label information from a set of training images. The essential features of DSTM different from existing approaches are that (i) the label information is enforced in the generation of both visual words and annotation terms such that each generative latent topic corresponds to a category; (ii) the zero-mean Laplace distribution is employed to give a sparse representation of images in visual words and annotation terms such that relevant words and terms are associated with latent topics. Experimental results demonstrate that the proposed method provides the discrimination ability in classification and annotation, and its performance is better than the other testing methods (sLDA-ann, abc-corr-LDA, SupDocNADE, SAGE and MedSTC) for LabelMe, UIUC, NUS-WIDE and PascalVOC07 images. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Yang, Liu; Jing, Liping; Yu, Jian] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
   [Yang, Liu] Tianjin Normal Univ, Coll Comp & Informat Engn, Tianjin, Peoples R China.
   [Ng, Michael K.] Hong Kong Baptist Univ, Dept Math, Kowloon Tong, Hong Kong, Peoples R China.
C3 Beijing Jiaotong University; Tianjin Normal University; Hong Kong
   Baptist University
RP Jing, LP (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
EM yangliubjtu@bjtu.edu.cn; lpjing@bjtu.edu.cn; mng@math.hkbu.edu.hk;
   jianyu@bjtu.edu.cn
RI NG, Michael/AAG-9117-2020; Yu, Jian/HJY-2670-2023; Ng,
   Michael/B-7189-2009
OI Ng, Michael/0000-0001-6833-5227; wang, jingsong/0000-0003-2569-7265
FU National Natural Science Foundation of China [61105056, 61370129,
   61375062]; Fundamental Research Funds through the Central Universities
   [2014JBM029]; CCF-Tencent Open Research Fund; Research Grants Council,
   Hong Kong, through the General Research Fund; Hong Kong Baptist
   University (HKBU), Hong Kong [202013, 12302715]; HKBU [FRG2/14-15/087]
FX The work of L. Yang, L. Jing, and J. Yu was supported in part by the
   National Natural Science Foundation of China under Grant 61105056, under
   Grant 61370129, and Grant 61375062, in part by the Fundamental Research
   Funds through the Central Universities under Grant 2014JBM029, and in
   part by the CCF-Tencent Open Research Fund. The work of M.K. Ng was
   supported in part by the Research Grants Council, Hong Kong, through the
   General Research Fund, Hong Kong Baptist University (HKBU), Hong Kong,
   under Grant 202013 and Grant 12302715, and in part by HKBU under Grant
   FRG2/14-15/087.
CR [Anonymous], P EUR C COMP VIS
   [Anonymous], INT C MACH LEARN
   [Anonymous], 2009, P ACM INT C IM VID R
   [Anonymous], INT C COMP VIS PATT
   Babacan SD, 2010, IEEE T IMAGE PROCESS, V19, P53, DOI 10.1109/TIP.2009.2032894
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Cai X, 2012, LECT NOTES COMPUT SC, V7577, P823, DOI 10.1007/978-3-642-33783-3_59
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Dong PX, 2013, PATTERN RECOGN, V46, P1382, DOI 10.1016/j.patcog.2012.10.029
   Eisenstein J, 2011, P 28 INT C MACHINE L, P1041
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Feng Y., 2010, Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010), P831
   Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989
   Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128
   Guan Y., 2009, J MACHINE LEARNING R, P185
   Jing LP, 2012, IEEE T IMAGE PROCESS, V21, P4508, DOI 10.1109/TIP.2012.2206040
   Lau J. H., 2014, P 14 C EUR CHAPT ASS, P530, DOI [DOI 10.3115/V1/E14-1056, 10.3115/v1/E14-1056]
   Li Fei-Fei, 2007, INT C COMPUTER VISIO, P1
   Li Xiao-xu, 2012, Journal of China Universities of Posts and Telecommunications, V19, P107, DOI 10.1016/S1005-8885(11)60254-9
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Poison NicholasG., 2010, Bayesian Statistics, V9
   Qi Z., 2011, P 17 ACM SIGKDD INT, P1199, DOI DOI 10.1145/2020408.2020592
   Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Seeger MW, 2008, J MACH LEARN RES, V9, P759
   Shenghua Gao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2809, DOI 10.1109/CVPR.2011.5995454
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang YS, 2011, ADV MAT SCI ENG-BOCA, P1
   Weinshall D., 2013, P INT C MACHINE LEAR, P711
   Zhang Aonan., 2013, Proceedings of the 22nd international conference on World Wide Web, P1489
   Zheng Y, 2014, PROC CVPR IEEE, P1370, DOI 10.1109/CVPR.2014.178
   Zhou Z.-H., 2007, P ADV NEUR INF PROC, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019
   Zhu J., 2011, UAI, P831
NR 40
TC 7
Z9 12
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2016
VL 51
BP 22
EP 35
DI 10.1016/j.imavis.2016.03.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4HB
UT WOS:000378455900003
DA 2024-07-18
ER

PT J
AU Mertens, B
   Delchambre, A
AF Mertens, Benjamin
   Delchambre, Alain
TI 3D reconstruction: Why should the accuracy always be presented in the
   pixel unit?
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Error; Structured light; Stereoscopy; Pixel; Parallax
AB This paper analyses the error presentation of parallax-based techniques (mainly stereoscopy and structured light). They are usually presented using an absolute (mm) or a relative (%) scale. These results are hard to compare between different systems as they are system-dependent. This paper presents results using the pixel unit which avoids the influence of geometric parameters. Moreover it is apt at evaluating whether the system under-performs or is similar compared to theoretical accuracy. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Mertens, Benjamin; Delchambre, Alain] Univ Libre Bruxelles, BEAMS Dept, Ave F Roosevelt 50,CP 165-56, B-1050 Brussels, Belgium.
C3 Universite Libre de Bruxelles
RP Mertens, B (corresponding author), Univ Libre Bruxelles, BEAMS Dept, Ave F Roosevelt 50,CP 165-56, B-1050 Brussels, Belgium.
EM benjamin.mertens@ulb.ac.be
RI Delchambre, Alain/ABE-9019-2021
OI Delchambre, Alain/0000-0002-6047-1002
FU Belgian FNRS under the research grant CDR-Endovision [J.0.123.13]
FX This research is partially funded by the Belgian FNRS (J.0.123.13) under
   the research grant CDR-Endovision.
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Lavoie P., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P370, DOI 10.1109/ICIAP.1999.797623
   Li F, 2014, OPT LASER ENG, V55, P189, DOI 10.1016/j.optlaseng.2013.11.004
   Mertens B, 2013, INT J OPTOMECHATRONI, V7, P105, DOI 10.1080/15599612.2013.785041
   Salvi J, 2010, PATTERN RECOGN, V43, P2666, DOI 10.1016/j.patcog.2010.03.004
   Wu TT, 2007, OPT EXPRESS, V15, P10421, DOI 10.1364/OE.15.010421
   Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035
NR 7
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR-MAY
PY 2016
VL 48-49
BP 57
EP 60
DI 10.1016/j.imavis.2016.02.002
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO4GS
UT WOS:000377740400006
DA 2024-07-18
ER

PT J
AU Blanco-Gonzalo, R
   Sanchez-Reillo, R
   Miguel-Hurtado, O
   Bella-Pulgarin, E
AF Blanco-Gonzalo, Ramon
   Sanchez-Reillo, Raul
   Miguel-Hurtado, Oscar
   Bella-Pulgarin, Eric
TI Automatic usability and stress analysis in mobile biometrics
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Usability; Mobile devices; Biometrics; Stress; Handwritten signature
   recognition
ID HANDWRITTEN SIGNATURE RECOGNITION
AB This article focuses on the usability evaluation of biometric recognition systems in mobile devices. In particular, a behavioural modality has been used: the dynamic handwritten signature. Testing usability in behavioural modalities involves a big challenge due to the number of degrees of freedom that users have in interacting with sensors, as well as the variety of capture devices to be used. In this context we propose a usability evaluation that allows users to interact freely with the system while minimizing errors at the same time. The participants signed in a smartphone with a stylus through the different phases in the use of a biometric system: training, enrolment and verification. In addition, a profound study on the automation of the evaluation processes has been done, so as to reduce the resources employed. The influence of the users' stress has also been studied, to obtain conclusions on its impact on both the usability systems in scenarios where the user may suffer a certain level of stress, such as in courts, banks or even shopping. In brief, the results shown in this paper prove not only that a dynamic handwritten signature is a trustable solution for a large number of applications in the real world, but also that the evaluation of the usability of biometric systems can be carried out at lower costs and shorter duration. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Blanco-Gonzalo, Ramon; Sanchez-Reillo, Raul; Miguel-Hurtado, Oscar; Bella-Pulgarin, Eric] Univ Carlos III Madrid, E-28903 Getafe, Spain.
C3 Universidad Carlos III de Madrid
RP Blanco-Gonzalo, R (corresponding author), Univ Carlos III Madrid, E-28903 Getafe, Spain.
EM rbgonzal@ing.uc3m.es; rsreillo@ing.uc3m.es; omiguel@ing.uc3m.es;
   ebella@ing.uc3m.es
RI Sanchez-Reillo, Raul/Z-3333-2019; Blanco-Gonzalo, Ramon/L-2286-2013
OI Sanchez-Reillo, Raul/0000-0003-4239-985X; Blanco-Gonzalo,
   Ramon/0000-0001-7125-6490
CR [Anonymous], 2005, Biometric Technology Today, V13, P6, DOI DOI 10.1016/S0969-4765(05)70368-4
   [Anonymous], P CARN C SEC TECHN
   [Anonymous], 2019, ISO 9241-210:2019
   [Anonymous], 2008, P INT S WORLD WIRELE, DOI DOI 10.1109/W0WM0M.2008.4594857
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   Blanco-Gonzalo R, 2014, ADV INTELL SYST, V300, P289, DOI 10.1007/978-3-319-08491-6_24
   Blanco-Gonzalo R, 2014, IET BIOMETRICS, V3, P139, DOI 10.1049/iet-bmt.2013.0044
   Blanco-Gonzalo R, 2012, INT CARN CONF SECU, P174, DOI 10.1109/CCST.2012.6393554
   Cho DH, 2005, Sixth International Conference on Software Engineerng, Artificial Intelligence, Networking and Parallel/Distributed Computing and First AICS International Workshop on Self-Assembling Wireless Networks, Proceedings, P254
   de Santos Sierra A., 2011, 2011 Third World Congress on Nature and Biologically Inspired Computing (NaBIC 2011), P237, DOI 10.1109/NaBIC.2011.6089603
   Elliott SJ, 2010, INT CARN CONF SECU, P259, DOI 10.1109/CCST.2010.5678710
   Erbilek M, 2012, IET BIOMETRICS, V1, P136, DOI 10.1049/iet-bmt.2012.0011
   Fairhurst Michael, 2013, AGE FACTORS BIOMETRI
   Houmani N, 2012, PATTERN RECOGN, V45, P993, DOI 10.1016/j.patcog.2011.08.008
   KEKRE HB, 2009, ADV COMP C 2009 IACC, P535
   Kukula E., 2008, DESIGN EVALUATION HU
   Kukula EP, 2009, LECT NOTES COMPUT SC, V5618, P168, DOI 10.1007/978-3-642-02559-4_19
   Nielsen J., 2014, TIME BUDGETS USABILI
   Pascual-Gaspar JM, 2009, LECT NOTES COMPUT SC, V5558, P1180, DOI 10.1007/978-3-642-01793-3_119
   Stein C., BIOM SPEC INT GROUP, P1
   Theofanos M., 2014, USABILITY BIOMETRICS
   Theofanos M., 2007, IEEE Conference on Biometrics: Theory, Applications and Systems, P1
   Wamsley A., 2011, 2011 Carnahan Conference on Security Technology, P1, DOI DOI 10.1109/CCST.2011.6095939
NR 23
TC 11
Z9 12
U1 0
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1173
EP 1180
DI 10.1016/j.imavis.2014.09.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600018
DA 2024-07-18
ER

PT J
AU Yan, F
   Kittler, J
   Windridge, D
   Christmas, W
   Mikolajczyk, K
   Cox, S
   Huang, Q
AF Yan, Fei
   Kittler, Josef
   Windridge, David
   Christmas, William
   Mikolajczyk, Krystian
   Cox, Stephen
   Huang, Qiang
TI Automatic annotation of tennis games: An integration of audio, vision,
   and learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Tennis annotation; Object tracking; Audio event classification; Sequence
   labelling; Structured output learning; Hidden Markov model
ID TRACKING
AB Fully automatic annotation of tennis game using broadcast video is a task with a great potential but with enormous challenges. In this paper we describe our approach to this task, which integrates computer vision, machine listening, and machine learning. At the low level processing, we improve upon our previously proposed state-of-the-art tennis ball tracking algorithm and employ audio signal processing techniques to detect key events and construct features for classifying the events. At high level analysis, we model event classification as a sequence labelling problem, and investigate four machine learning techniques using simulated event sequences. Finally, we evaluate our proposed approach on three real world tennis games, and discuss the interplay between audio, vision and learning. To the best of our knowledge, our system is the only one that can annotate tennis game at such a detailed level. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Yan, Fei; Kittler, Josef; Windridge, David; Christmas, William; Mikolajczyk, Krystian] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
   [Cox, Stephen; Huang, Qiang] Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.
C3 University of Surrey; University of East Anglia
RP Yan, F (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
EM f.yan@surrey.ac.uk
OI Windridge, David/0000-0001-5507-8516
FU EPSRC/DSTL project [EP/K014307/1]; EU Chist-Era EPSRC Visual Sense
   project [EP/K01904X/1]; EPSRC [EP/K01904X/1, EP/K014307/1, EP/F069626/1,
   EP/F069421/1] Funding Source: UKRI
FX This work has been supported by the EPSRC/DSTL project EP/K014307/1 and
   the EU Chist-Era EPSRC Visual Sense project EP/K01904X/1.
CR Altun Y., 2005, THESIS BROWN U USA
   [Anonymous], INT C VIS IM SIM
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Christmas W. J., 2005, 4 INT WORKSH CONT BA
   COLDEFY F, 2004, IEEE INT WORKSH MULT
   Huang Q., 2011, INT C AUD VIS SPEECH
   Huang YP, 2009, EXPERT SYST APPL, V36, P9907, DOI 10.1016/j.eswa.2009.01.078
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Kijak E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P309
   Kijak E., 2003, INT WORKSH CONT BAS
   Kittler J., 2005, 14 SCAND C IM AN
   Kolonias I, 2004, LECT NOTES COMPUT SC, V3138, P1078
   Lai JH, 2011, J VIS COMMUN IMAGE R, V22, P271, DOI 10.1016/j.jvcir.2011.01.001
   Ng A., 2002, DISCRIMINATIVE VS GE
   Taskar Ben., 2003, Max-margin markov networks
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Yan F, 2008, IEEE T PATTERN ANAL, V30, P1814, DOI 10.1109/TPAMI.2007.70834
   Yan F, 2012, INT C PATT RECOG, P3577
   Yu XG, 2004, IEEE IMAGE PROC, P1049
   Zhu G., 2006, INT C PATT REC
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
NR 21
TC 22
Z9 23
U1 1
U2 19
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 896
EP 903
DI 10.1016/j.imavis.2014.08.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900007
DA 2024-07-18
ER

PT J
AU Liem, MC
   Gavrila, DM
AF Liem, Martijn C.
   Gavrila, Dariu M.
TI Coupled person orientation estimation and appearance modeling using
   spherical harmonics
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person appearance modeling; Orientation estimation; Spherical harmonics
ID TRACKING; PEOPLE
AB We present a novel approach for the estimation of a person's overall body orientation, 3D shape and texture, from overlapping cameras. A distinguishing aspect of our approach is the use of spherical harmonics for 3D shape- and texture-representation; it offers a compact, low-dimensional representation, which elegantly copes with rotation estimation. The estimation process alternates between the estimation of texture, orientation and shape. Texture is estimated by sampling image intensities with the predicted 3D shape (i.e. torso and head) and the predicted orientation, from the last time step. Orientation (i.e. rotation around torso major axis) is estimated by minimizing the difference between a learned texture model in a canonical orientation and the current texture estimate. The newly estimated orientation allows to update the 3D shape estimate, taking into account the new 3D shape measurement obtained by volume carving.
   We investigate various components of our approach in experiments on synthetic and real-world data. We show that our proposed method has lower orientation estimation error than other methods that use fixed 3D shape models, for data involving persons. (C) 2014 Elsevier RV. All rights reserved.
C1 [Liem, Martijn C.; Gavrila, Dariu M.] Univ Amsterdam, Inst Informat, Intelligent Autonomous Syst Grp, NL-1098 XH Amsterdam, Netherlands.
   [Gavrila, Dariu M.] Daimler Res & Dev, Environm Percept Dept, D-89081 Ulm, Germany.
C3 University of Amsterdam; Daimler AG
RP Liem, MC (corresponding author), Univ Amsterdam, Inst Informat, Intelligent Autonomous Syst Grp, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
EM M.C.Liem@uva.nl; D.M.Gavrila@uva.nl
FU EC's Seventh Framework Programme under ADABTS project [218197]
FX The authors would like to thank Leo Dorst from the University of
   Amsterdam for proof reading the paper. This research has received
   funding from the EC's Seventh Framework Programme under grant agreement
   number 218197, the ADABTS project.
CR Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156
   [Anonymous], 2013, 2013 10 IEEE INT C W
   [Anonymous], 2006, 2006 IEEE COMPUTER S
   Balan A. O., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI [10.1109/CVPR.2007.383340, DOI 10.1109/CVPR.2007.383340]
   Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chen C, 2012, PROC CVPR IEEE, P1544, DOI 10.1109/CVPR.2012.6247845
   Cheung KM, 2005, INT J COMPUT VISION, V62, P221, DOI 10.1007/s11263-005-4881-5
   Enzweiler M, 2010, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2010.5540110
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755
   Gandhi T, 2007, MACH VISION APPL, V18, P207, DOI 10.1007/s00138-006-0063-x
   Gandhi T, 2008, IEEE INT VEH SYM, P795
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Green R., 2003, GAME DEV C
   Hofmann M, 2011, COMPUT VIS IMAGE UND, V115, P1559, DOI 10.1016/j.cviu.2011.08.002
   Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   Liem Martijn, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P173, DOI 10.1007/978-3-642-23123-0_18
   Liem Martijn C., 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P203, DOI 10.1007/978-3-642-39402-7_21
   Liu K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.33
   Makadia A, 2003, PROC CVPR IEEE, P217
   Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764
   Mitzel D, 2012, LECT NOTES COMPUT SC, V7576, P566, DOI 10.1007/978-3-642-33715-4_41
   Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392
   Shimizu H, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P596
   Yue Z., 2008, EURASIP J ADV SIG PR, V2008
NR 31
TC 7
Z9 8
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 728
EP 738
DI 10.1016/j.imavis.2014.04.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700010
DA 2024-07-18
ER

PT J
AU Zhang, X
   Yin, LJ
   Cohn, JF
   Canavan, S
   Reale, M
   Horowitz, A
   Liu, P
   Girard, JM
AF Zhang, Xing
   Yin, Lijun
   Cohn, Jeffrey F.
   Canavan, Shaun
   Reale, Michael
   Horowitz, Andy
   Liu, Peng
   Girard, Jeffrey M.
TI BP4D-Spontaneous: a high-resolution spontaneous 3D dynamic facial
   expression database
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D facial expression; FACS; Spontaneous expression; Dynamic facial
   expression database
ID RECOGNITION; PAIN; COLLECTION
AB Facial expression is central to human experience. Its efficiency and valid measurement are challenges that automated facial image analysis seeks to address. Most publically available databases are limited to 2D static images or video of posed facial behavior. Because posed and un-posed (aka "spontaneous") facial expressions differ along several dimensions including complexity and timing, well-annotated video of un-posed facial behavior is needed. Moreover, because the face is a three-dimensional deformable object, 2D video may be insufficient, and therefore 3D video archives are required. We present a newly developed 3D video database of spontaneous facial expressions in a diverse group of young adults. Well-validated emotion inductions were used to elicit expressions of emotion and paralinguistic communication. Frame-level ground-truth for facial actions was obtained using the Facial Action Coding System. Facial features were tracked in both 2D and 3D domains. To the best of our knowledge, this new database is the first of its kind for the public. The work promotes the exploration of 3D spatiotemporal features in subtle facial expression, better understanding of the relation between pose and motion dynamics in facial action units, and deeper understanding of naturally occurring facial action. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Zhang, Xing; Yin, Lijun; Canavan, Shaun; Reale, Michael; Horowitz, Andy; Liu, Peng] SUNY Binghamton, Binghamton, NY 13902 USA.
   [Cohn, Jeffrey F.; Girard, Jeffrey M.] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Binghamton; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); University of Pittsburgh
RP Zhang, X (corresponding author), SUNY Binghamton, Binghamton, NY 13902 USA.
EM xzhang7@cs.binghamton.edu; lijun@cs.binghamton.edu
RI Girard, Jeffrey M/H-4088-2019; Liu, Peng/R-6881-2017
OI Girard, Jeffrey M/0000-0002-7359-3746; Reale,
   Michael/0000-0003-2147-4443
FU National Science Foundation [IIS-1051103, IIS-1051169, CNS-1205664,
   CNS-1205195]; Direct For Computer & Info Scie & Enginr; Division Of
   Computer and Network Systems [1205195] Funding Source: National Science
   Foundation; Direct For Computer & Info Scie & Enginr; Division Of
   Computer and Network Systems [1205664] Funding Source: National Science
   Foundation
FX This material is based upon the work supported in part by the National
   Science Foundation under grants IIS-1051103, IIS-1051169, CNS-1205664,
   and CNS-1205195. We would like to thank Nicki Siverling, Dean Rosenwald,
   and Shaun Zuratovic for FACS coding. We would also like to thank Dr.
   Peter Gerhardstein for the help on data collection.
CR Ambadar Z, 2009, J NONVERBAL BEHAV, V33, P17, DOI 10.1007/s10919-008-0059-5
   [Anonymous], J PERS SOC PSYCHOL
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], CVPR4HB IEEE
   [Anonymous], ACM INT C MULT INT
   [Anonymous], 2011, IEEE INT C AUT FAC G
   [Anonymous], 2008, IEEE INT C AUT FAC G
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2 IEEE WORKSH CVPR H
   [Anonymous], HDB EMOTION ELICITAT
   [Anonymous], 2005, Handbook of nonverbal behavior research methods in the affective sciences
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], 10 EUR C COMP VIS EC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], USING ACTOR PORTRAYA
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], J IMAGE VIS IN PRESS
   Baron-Cohen S, 1998, NATURE, V392, P459, DOI 10.1038/33076
   Canavan S, 2013, IEEE INT CON MULTI
   CLARK DM, 1983, ADV BEHAV RES THER, V5, P27, DOI 10.1016/0146-6402(83)90014-0
   Coan J., 2007, Oxford handbook on emotion elicitation and assessment
   Cohn Jeffrey, 2007, The handbook of emotion elicitation and assessment, P203, DOI DOI 10.1093/OSO/9780195169157.003.0014
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cosker D, 2011, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2011.6126510
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   DAVIDSON RJ, 1990, J PERS SOC PSYCHOL, V58, P330, DOI 10.1037/0022-3514.58.2.330
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   EKMAN P, 1985, J PERS SOC PSYCHOL, V49, P1416, DOI 10.1037/0022-3514.49.5.1416
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman Paul., 1982, EMFACS: Coder's instructions
   Fanelli G, 2010, IEEE T MULTIMEDIA, V12, P591, DOI 10.1109/TMM.2010.2052239
   Fleiss Joseph L., 1981, STAT METHODS RATES P
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Hoque ME, 2012, IEEE T AFFECT COMPUT, V3, P323, DOI 10.1109/T-AFFC.2012.11
   Keltner D, 1996, COGNITION EMOTION, V10, P155, DOI 10.1080/026999396380312
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lucey P, 2012, IMAGE VISION COMPUT, V30, P197, DOI 10.1016/j.imavis.2011.12.003
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Marcus DK, 1999, COGNITION EMOTION, V13, P105, DOI 10.1080/026999399379393
   Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2
   Mavadati S.M., 2013, IEEE Transactions on Affective Computing, V1
   Noldus LPJJ, 2000, BEHAV RES METH INS C, V32, P197, DOI 10.3758/BF03200802
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   PRKACHIN KM, 1992, PAIN, V51, P297, DOI 10.1016/0304-3959(92)90213-U
   Rottenberg J., 2007, HDB EMOTION ELICITAT, P9
   Rozin P., 2008, Handbook of emotions, V3rd, P757
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Schmidt KL, 2006, J NONVERBAL BEHAV, V30, P37, DOI 10.1007/s10919-005-0003-x
   von Baeyer CL, 2005, J PAIN, V6, P218, DOI 10.1016/j.jpain.2005.01.349
   Wang J., 2006, IEEE CVPR
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 59
TC 413
Z9 452
U1 5
U2 43
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 692
EP 706
DI 10.1016/j.imavis.2014.06.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700008
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Bedagkar-Gala, A
   Shah, SK
AF Bedagkar-Gala, Apurva
   Shah, Shishir K.
TI A survey of approaches and trends in person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Multi-camera tracking; Video surveillance;
   Closed set Re-ID; Open set Re-ID; Short and long period Re-ID
ID PEOPLE REIDENTIFICATION; FACE RECOGNITION; TRACKING; MULTIPLE; MODEL;
   CLASSIFICATION; CAMERAS; SCALE
AB Person re-identification is a fundamental task in automated video surveillance and has been an area of intense research in the past few years. Given an image/video of a person taken from one camera, re-identification is the process of identifying the person from images/videos taken from a different camera. Re-identification is indispensable in establishing consistent labeling across multiple cameras or even within the same camera to reestablish disconnected or lost tracks. Apart from surveillance it has applications in robotics, multimedia and forensics. Person re-identification is a difficult problem because of the visual ambiguity and spatiotemporal uncertainty in a person's appearance across different cameras. These difficulties are often compounded by low resolution images or poor quality video feeds with large amounts of unrelated information in them that does not aid re-identification. The spatial or temporal conditions to constrain the problem are hard to capture. However, the problem has received significant attention from the computer vision research community due to its wide applicability and utility. In this paper, we explore the problem of person re-identification and discuss the current solutions. Open issues and challenges of the problem are highlighted with a discussion on potential directions for further research. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Bedagkar-Gala, Apurva; Shah, Shishir K.] Univ Houston, Dept Comp Sci, Quantitat Imaging Lab, Houston, TX 77204 USA.
C3 University of Houston System; University of Houston
RP Shah, SK (corresponding author), Univ Houston, Dept Comp Sci, 4800 Calhoun,501 PGH, Houston, TX 77204 USA.
EM avbedagk@central.uh.edu; sshah@central.uh.edu
OI Shah, Shishir/0000-0003-4093-6906
FU US Department of Justice [2009-MU-MU-K004]
FX This work was supported in part by the US Department of Justice
   2009-MU-MU-K004. Any opinions, findings, conclusions or recommendations
   expressed in this paper are those of the authors and do not necessarily
   reflect the views of our sponsors.
CR Albiol A, 2012, IET COMPUT VIS, V6, P378, DOI 10.1049/iet-cvi.2011.0140
   Andriluka M., 2008, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)
   Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   [Anonymous], 2006, DISTANCE METRIC LEAR
   [Anonymous], I LIDS MULT CAM TRAC
   [Anonymous], PROC BRIT MACH VIS C
   [Anonymous], 2007, 10 INT WORKSH PERF E
   [Anonymous], EL IM C 3D IM PROC A
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], P 21 BRIT MACH VIS C
   [Anonymous], 2013, IEEE ICC
   [Anonymous], APPEARANCE DESCRIPTO
   [Anonymous], INT C IM PROC
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], VIP VISION TOOL COMP
   [Anonymous], 2010, P IEEE 2010 2 INT C
   [Anonymous], J IVIP
   [Anonymous], 2008, P 2008 IEEE C COMP V
   [Anonymous], P SPIE DEF SEC S UN
   [Anonymous], 1992, BREAKTHROUGHS STAT M, DOI DOI 10.1007/978-1-4612-4380-9_14
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2012, DICTA
   [Anonymous], 2010, Asian Conference on Computer Vision
   Ao M, 2009, ADV PATTERN RECOGNIT, P155, DOI 10.1007/978-1-84882-385-3_6
   Avraham Tamar, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P381, DOI 10.1007/978-3-642-33863-2_38
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P1, DOI 10.1109/AVSS.2010.68
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bak S, 2012, LECT NOTES COMPUT SC, V7574, P806, DOI 10.1007/978-3-642-33712-3_58
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   Baltieri D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1817, DOI 10.1109/ICCVW.2011.6130469
   Baltieri D, 2011, LECT NOTES COMPUT SC, V6978, P197, DOI 10.1007/978-3-642-24085-0_21
   Barbosa IB, 2012, LECT NOTES COMPUT SC, V7583, P433, DOI 10.1007/978-3-642-33863-2_43
   Bauml M., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P291, DOI 10.1109/AVSS.2011.6027339
   Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Bedagkar-Gala A, 2012, PATTERN RECOGN LETT, V33, P1908, DOI 10.1016/j.patrec.2011.09.005
   Bedagkar-Gala A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1721, DOI 10.1109/ICCVW.2011.6130457
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Brun L, 2011, LECT NOTES COMPUT SC, V6658, P285, DOI 10.1007/978-3-642-20844-7_29
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cong DNT, 2010, SIGNAL PROCESS, V90, P2362, DOI 10.1016/j.sigpro.2009.09.005
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Detmold Henry, 2007, 2007 First ACM/IEEE International Conference on Distributed Smart Cameras, P195, DOI 10.1109/ICDSC.2007.4357524
   Ess A., 2007, INT C COMPUTER VISIO, P1
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Forssen P.-E., 2007, IEEE International Conference on Computer Vision (ICCV), P1, DOI DOI 10.1109/CVPR.2007.383120
   Gabran W, 2013, IEEE ICC
   Gallagher A. C., 2008, IEEE C COMPUTER VISI, P1
   Gandhi T, 2007, MACH VISION APPL, V18, P207, DOI 10.1007/s00138-006-0063-x
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hamdoun F., 2008, 2 ACMIEEE INT C DIST, P1
   Hampapur A, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1133
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Javed O, 2005, PROC CVPR IEEE, P26
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Jaynes C., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P309
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Jungling Kai., 2011, COMPUTER VISION PATT, P55, DOI 10.1109/CVPRW.2011.5981771
   Kai Jungling, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P448, DOI 10.1109/AVSS.2010.75
   Kang JM, 2004, INT C PATT RECOG, P759, DOI 10.1109/ICPR.2004.1333883
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Layne R, 2012, LECT NOTES COMPUT SC, V7583, P402, DOI 10.1007/978-3-642-33863-2_40
   Leibe Bastian, 2004, WORKSH STAT LEARN CO
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loy CC, 2013, IEEE IMAGE PROC, P3567, DOI 10.1109/ICIP.2013.6738736
   Loy CC, 2012, IEEE T PATTERN ANAL, V34, P1799, DOI 10.1109/TPAMI.2011.246
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Makris D, 2004, PROC CVPR IEEE, P205
   Mazzon R, 2012, PATTERN RECOGN LETT, V33, P1828, DOI 10.1016/j.patrec.2012.02.014
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nandakumar K, 2009, LECT NOTES COMPUT SC, V5558, P743, DOI 10.1007/978-3-642-01793-3_76
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Park U, 2006, INT C PATT RECOG, P1204
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Prosser B., 2008, P GB MACH VIS C 2008
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Rahimi A, 2004, PROC CVPR IEEE, P187
   Satta R, 2011, LECT NOTES COMPUT SC, V6979, P140, DOI 10.1007/978-3-642-24088-1_15
   Satta R, 2012, LECT NOTES COMPUT SC, V7583, P453, DOI 10.1007/978-3-642-33863-2_45
   Satta R, 2012, PATTERN RECOGN LETT, V33, P1838, DOI 10.1016/j.patrec.2012.03.026
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Simi Wang, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1876, DOI 10.1109/ICCVW.2011.6130477
   Simonnet D, 2012, LECT NOTES COMPUT SC, V7583, P423, DOI 10.1007/978-3-642-33863-2_42
   Sivic Josef., 2006, British Machine Vision Conference, P909
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang Y, 2010, LECT NOTES COMPUT SC, V6315, P155, DOI 10.1007/978-3-642-15555-0_12
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu Y, 2012, LECT NOTES COMPUT SC, V7574, P497, DOI 10.1007/978-3-642-33712-3_36
   Yang A., 2007, Feature Selection in Face Recognition: A Sparse Representation Perspective
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Ying Zhang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P368, DOI 10.1109/ICIG.2011.40
   Yinghao Cai, 2010, Computer Vision. International Workshops (ACCV 2010). Revised Selected Papers, P205, DOI 10.1007/978-3-642-22822-3_21
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2012, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2012.6247985
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
NR 116
TC 308
Z9 345
U1 2
U2 110
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2014
VL 32
IS 4
BP 270
EP 286
DI 10.1016/j.imavis.2014.02.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AG0MN
UT WOS:000335109700005
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Palazón-González, V
   Marzal, A
AF Palazon-Gonzalez, Vicente
   Marzal, Andres
TI On the dynamic time warping of cyclic sequences for shape retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cyclic sequences; Cyclic strings; Dynamic time warping; Shape retrieval;
   Shape recognition
ID FOURIER DESCRIPTORS; NONRIGID SHAPES; REPRESENTATION; COMPUTATION;
   MULTISCALE; DISTANCE
AB In recent years, in shape retrieval, methods based on dynamic time warping and sequences where each point of the contour is represented by elements of several dimensions have had a significant presence. In this approach each point of the closed contour contains information with respect to the other ones, this global information is very discriminant. The current state-of-the-art shape retrieval is based on the analysis of these distances to learn better ones.
   These methods are robust to noise and invariant to transformations, but, they obtain the invariance to the starting point with a brute force cyclic alignment which has a high computational time. In this work, we present cyclic dynamic time warping. It can obtain the cyclic alignment in O(n(2)logn) time, where n is the size of both sequences. Experimental results show that our proposal is a better alternative than the brute force cyclic alignment and other heuristics for obtaining this invariance. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Palazon-Gonzalez, Vicente] Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Castellon De La Plana, Spain.
   Inst New Imaging Technol, Castellon De La Plana, Spain.
C3 Universitat Jaume I
RP Palazón-González, V (corresponding author), Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Castellon De La Plana, Spain.
EM palazon@lsi.uji.es; amarzal@lsi.uji.es
FU Spanish Government [TIN2010-18958, CSD2007-00018]; Generalitat
   Valenciana [Prometeo/2010/028]; Fundacio Caixa Castello-Bancaixa
   [P11B2009-48]
FX Work partially supported by the Spanish Government (TIN2010-18958 and
   Consolider Ingenio 2010 CSD2007-00018), the Generalitat Valenciana
   (Prometeo/2010/028), and Fundacio Caixa Castello-Bancaixa (P11B2009-48).
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   [Anonymous], 1995, MACHINE VISION
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Bartolini I, 2005, IEEE T PATTERN ANAL, V27, P142, DOI 10.1109/TPAMI.2005.21
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Cormen T.H., 1990, Introduction to Algorithms
   Crespo JBFP, 2011, IEEE T IMAGE PROCESS, V20, P2896, DOI 10.1109/TIP.2011.2146264
   Folkers A, 2002, INT C PATT RECOG, P521, DOI 10.1109/ICPR.2002.1047991
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   Horn B.K.P, 1986, Robot Vision
   Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9
   Keogh E, 2009, VLDB J, V18, P611, DOI 10.1007/s00778-008-0111-4
   Klette R., 2004, DIGITAL GEOMETRY GEO
   Kontschieder P, 2010, LECT NOTES COMPUT SC, V5996, P655
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   MAES M, 1990, INFORM PROCESS LETT, V35, P73, DOI 10.1016/0020-0190(90)90109-B
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Marzal A, 2000, INT C PATT RECOG, P891, DOI 10.1109/ICPR.2000.906217
   MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   MYERS C, 1980, IEEE T ACOUST SPEECH, V28, P623, DOI 10.1109/TASSP.1980.1163491
   Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   SANKOFF D, 1983, TIME WARPS STRING ED
   Sharvit D, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P56, DOI 10.1109/IVL.1998.694496
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Van Rijsbergen C. J., 1979, Information Retrieval, V2nd
   VIDAL E, 1995, IEEE T PATTERN ANAL, V17, P899, DOI 10.1109/34.406656
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   [No title captured]
NR 37
TC 26
Z9 28
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 978
EP 990
DI 10.1016/j.imavis.2012.08.012
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800006
OA Green Published
DA 2024-07-18
ER

PT J
AU Lim, KB
   Wu, JY
AF Lim, Kah Bin
   Wu, Jia Yun
TI Recognition of occluded objects by reducing feature interactions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Occlusion recognition; Appearance; Geometry; Spectral matching
AB The main difficulty for the recognition of occluded objects lies in the fact that the original feature set is corrupted and no longer reliable to represent the object of interest. This corruption is caused by the interactions between features from different objects, denoted as feature interactions, which is a key issue addressed in our algorithm. In this paper, a local to global strategy is represented for the occlusion recognition problem, which combines the pairwise grouping and graph matching algorithms. Local appearance similarity serves as priors to reduce feature interactions, by which the performance of graph matching algorithms is improved in order to deal with the contaminated data set. With our formulation, a global decision on object recognition can be made based on locally gathered information. Experimental results show that the proposed framework can dramatically reduce incorrect matches and objects under severe occlusions can still be recognized. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Lim, Kah Bin; Wu, Jia Yun] Natl Univ Singapore, Mechatron & Control Lab1, Singapore 117548, Singapore.
C3 National University of Singapore
RP Wu, JY (corresponding author), Natl Univ Singapore, Mechatron & Control Lab1, Singapore 117548, Singapore.
EM g0700814@nus.edu.sg
RI Bin Lim, Kah/Q-9927-2019
OI Lim, Kah Bin/0000-0002-2118-0966
CR [Anonymous], 2006, ADV NEURAL INFORM PR
   [Anonymous], INT J COMPUT VIS
   [Anonymous], INTERNATIONAL CONFER
   [Anonymous], EUROPEAN CONFERENCE
   [Anonymous], INTERNATIONAL CONFER
   [Anonymous], INTERNATIONAL CONFER
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], EUROPEAN CONFERENCE
   [Anonymous], INTERNATIONAL WORKSH
   [Anonymous], EUROPEAN CONFERENCE
   [Anonymous], INTERNATIONAL CONFER
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], INTERNATIONAL CONFER
   Carcassoni M, 2000, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2000.855881
   Estrada FJ, 2009, PROC CVPR IEEE, P1279, DOI 10.1109/CVPRW.2009.5206514
   Galun M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P716
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Leordeanu Marius, 2009, THESIS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346
   Peng Chang, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P498, DOI 10.1109/CVPR.1999.784727
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Stein AN, 2009, IMAGE VISION COMPUT, V27, P514, DOI 10.1016/j.imavis.2008.04.017
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Wang H, 2009, IEEE T IMAGE PROCESS, V18, P140, DOI 10.1109/TIP.2008.2006602
   Zass R., 2008, INT C COMPUTER VISIO
NR 27
TC 0
Z9 1
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2012
VL 30
IS 11
BP 906
EP 914
DI 10.1016/j.imavis.2012.07.006
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 052CW
UT WOS:000312176300009
DA 2024-07-18
ER

PT J
AU Guo, XJ
   Cao, XC
AF Guo, Xiaojie
   Cao, Xiaochun
TI MIFT: A framework for feature descriptors to be mirror reflection
   invariant
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Mirror reflection invariance; Local image feature; MIFT
ID PERFORMANCE EVALUATION; OBJECT RECOGNITION; SYMMETRY; SCALE;
   REPRESENTATION
AB Visual matching is one of the most fundamental and important tasks in computer vision and pattern recognition. The images often appear to be scaled, rotated, view point changed and flipped (mirror reflected). The popular way to match such images employs local image features, such as SIFT and its variations (e.g. OpponentSIFT and HSVSIFT). Although the common local image features are able to deal with the transformations including scale, rotation and view point change, they fail to handle the mirror reflection. This paper presents a framework, mirror-reflection invariantfeature transform (MIFT), for improving their degenerated performance due to mirror reflections. The experiments demonstrate the robust performance of MIFT. An application to symmetric axis detection is also shown. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Guo, Xiaojie; Cao, Xiaochun] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Cao, XC (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM xguo@tju.edu.cn; xcao@tju.edu.cn
RI Guo, Xiaojie/AAC-3114-2022
FU National Natural Science Foundation of China [60905019]; Tianjin Key
   Technologies RD program [11ZCKFGX00800]; Tsinghua-Tencent Joint
   Laboratory for Internet Innovation Technology; SKL of CGCAD; CAS
   [XDA06030601]
FX This work was supported by the National Natural Science Foundation of
   China (no. 60905019), Tianjin Key Technologies R&D program (no.
   11ZCKFGX00800), Tsinghua-Tencent Joint Laboratory for Internet
   Innovation Technology, SKL of CG&CAD, and the Strategic and Pilot
   Project of CAS under XDA06030601.
CR [Anonymous], P ACM INT C IM VID R
   [Anonymous], TRECVID WORKSH
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], IEEE T PATTERN ANAL
   Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Carneiro G, 2002, LECT NOTES COMPUT SC, V2350, P282
   Choi I, 2004, IEEE SIGNAL PROC LET, V11, P255, DOI 10.1109/LSP.2003.821691
   Ferrari V, 2004, LECT NOTES COMPUT SC, V3021, P40
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FLORACK L., 1991, 7 SCANDINAVIAN C IMA, P338
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Harris C., 1988, ALVEY VISION C, P147151
   Hayfron-Acquah JB, 2003, PATTERN RECOGN LETT, V24, P2175, DOI 10.1016/S0167-8655(03)00086-2
   Johnson AE, 1997, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.1997.609400
   Ke Y, 2004, PROC CVPR IEEE, P506
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Lazebnik S, 2003, PROC CVPR IEEE, P319
   Lee S, 2009, PROC CVPR IEEE, P1046, DOI 10.1109/CVPRW.2009.5206814
   Li CL, 2009, PATTERN RECOGN LETT, V30, P544, DOI 10.1016/j.patrec.2008.12.004
   Lin IJ, 1997, IEEE T SIGNAL PROCES, V45, P2701, DOI 10.1109/78.650096
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508
   Lu YX, 2009, FOUND TRENDS COMPUT, V5, P1, DOI 10.1561/0600000008
   Ma R., 2010, P ACM INT C IMAGE VI, P228
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Pollefeys M, 2002, COMMUN ACM, V45, P50, DOI 10.1145/514236.514263
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Tan HK, 2009, IMAGE VISION COMPUT, V27, P1470, DOI 10.1016/j.imavis.2009.01.002
   Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P910, DOI 10.1109/34.608294
   Tola E., 2008, IEEE C COMPUTER VISI, P1
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Van Gool L., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P642, DOI 10.1007/BFb0015574
   Winder S., 2009, IEEE C COMPUTER VISI, P1
   Winder S.A. J., 2007, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang DS, 2003, J VIS COMMUN IMAGE R, V14, P41, DOI 10.1016/S1047-3203(03)00003-8
NR 51
TC 8
Z9 12
U1 2
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 546
EP 556
DI 10.1016/j.imavis.2012.05.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100015
DA 2024-07-18
ER

PT J
AU Chen, F
   Wang, Q
   Wang, S
   Zhang, WD
   Xu, WL
AF Chen, Feng
   Wang, Qing
   Wang, Song
   Zhang, Weidong
   Xu, Wenli
TI Object tracking via appearance modeling and sparse representation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Target variation; Online appearance modeling; Sparse representation;
   Bayesian inference
AB This paper proposes a robust tracking method by the combination of appearance modeling and sparse representation. In this method, the appearance of an object is modeled by multiple linear subspaces. Then within the sparse representation framework, we construct a similarity measure to evaluate the distance between a target candidate and the learned appearance model. Finally, tracking is achieved by Bayesian inference, in which a particle filter is used to estimate the target state sequentially over time. With the tracking result, the learned appearance model will be updated adaptively. The combination of appearance modeling and sparse representation makes our tracking algorithm robust to most of possible target variations due to illumination changes, pose changes, deformations and occlusions. Theoretic analysis and experiments compared with state-of-the-art methods demonstrate the effectivity of the proposed algorithm. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Chen, Feng; Wang, Qing; Xu, Wenli] Tsinghua Univ, Dept Automat, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
   [Wang, Song] Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
   [Zhang, Weidong] NIH, Ctr Clin, Bethesda, MD 20892 USA.
C3 Tsinghua University; University of South Carolina System; University of
   South Carolina Columbia; National Institutes of Health (NIH) - USA; NIH
   Clinical Center (CC)
RP Chen, F (corresponding author), Tsinghua Univ, Dept Automat, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM chenfeng@mail.tsinghua.edu.cn; qing-wang07@mails.tsinghua.edu.cn
RI Zhang, Weidong/AAU-3038-2020; Chen, Feng/K-4179-2012
OI Zhang, Weidong/0000-0003-2495-4469; Wang, Song/0000-0003-4152-5295
FU National Natural Science Foundation of China [60772050, 61071131]; No.2
   Important National Science and Technology Specific Projects
   [2009ZX02001]; United Technologies Research Center (UTRC)
FX This work was supported by National Natural Science Foundation of China
   (Project no. 60772050 and Project no. 61071131), No.2 Important National
   Science and Technology Specific Projects (Project no. 2009ZX02001) and
   United Technologies Research Center (UTRC).
CR Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Black M.J., 1996, Fourth European Conference on Computer 650 Vision (ECCV), P329
   Brand M, 2002, LECT NOTES COMPUT SC, V2350, P707
   Candes E.J., 2009, ROBUST PRINCIPAL COM
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Ho J., 2004, CVPR, P782
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lee H., 2007, NIPS
   Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432
   Li X, 2008, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2008.4587516
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   PARAG T., 2008, IEEE C COMPUTER VISI, P1, DOI [DOI 10.1109/CVPR.2008.4587556, 10.1109/CVPR.2008.4587556]
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
NR 23
TC 46
Z9 63
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2011
VL 29
IS 11
BP 787
EP 796
DI 10.1016/j.imavis.2011.08.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 864EE
UT WOS:000298219000007
DA 2024-07-18
ER

PT J
AU Shu, X
   Wu, XJ
AF Shu, Xin
   Wu, Xiao-Jun
TI A novel contour descriptor for 2D shape matching and its application to
   image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape matching; Shape retrieval; Contour points distribution histogram
   (CPDH); Earth mover's distance (EMD)
ID REPRESENTATION; RECOGNITION; DISTANCE
AB We suggest a novel shape contour descriptor for shape matching and retrieval. The new descriptor is called contour points distribution histogram (CPDH) which is based on the distribution of points on object contour under polar coordinates. CPDH not only conforms to the human visual perception but also the computational complexity of it is low. Invariant to scale and translation are the intrinsic properties of CPDH and the problem of the invariant to rotation can be partially resolved in the matching process. After the CPDHs of images are generated, the similarity value of the images is obtained by EMD (Earth Mover's Distance) metric. In order to make the EMD method used effectively for the matching of CPDHs, we also develop a new approach to the ground distance used in the EMD metric under polar coordinates. Experimental results of image retrieval demonstrate that the novel descriptor has a strong capability in handling a variety of shapes. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Wu, Xiao-Jun] Jiangnan Univ, Sch Informat Engn, Dept Comp Sci & Technol, Wuxi 214122, Peoples R China.
   [Shu, Xin; Wu, Xiao-Jun] Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Peoples R China.
   [Shu, Xin] Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212003, Peoples R China.
C3 Jiangnan University; Jiangnan University; Jiangsu University of Science
   & Technology
RP Wu, XJ (corresponding author), Jiangnan Univ, Sch Informat Engn, Dept Comp Sci & Technol, Wuxi 214122, Peoples R China.
EM ecsishu@yahoo.com.cn; wu_xiaojun@yahoo.com.cn
RI cai, bo/G-1491-2010
FU National Natural Science Foundation of PR China [60572034, 60973094];
   Natural Science Foundation of Jiangsu Province [BK2006081]; Natural
   Science Foundation of Jiangsu Provincial Universities [10KJB520006]
FX The authors would like to thank the anonymous reviewers for their
   constructive advices. This work is supported by National Natural Science
   Foundation of PR China (Grant Nos. 60572034, 60973094) and Natural
   Science Foundation of Jiangsu Province (Grant No. BK2006081) and Natural
   Science Foundation of Jiangsu Provincial Universities (Grant
   No.10KJB520006). The authors thank Dr. Yossi Rubner for making the EMD
   codes available on the web.
CR Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   [Anonymous], 1997, Image Databases and Multi-Media Search, DOI DOI 10.1142/9789812797988_
   Attalla E, 2005, PATTERN RECOGN, V38, P2229, DOI 10.1016/j.patcog.2005.02.009
   Bartolini I, 2005, IEEE T PATTERN ANAL, V27, P142, DOI 10.1109/TPAMI.2005.21
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chen YW, 2009, PATTERN RECOGN LETT, V30, P799, DOI 10.1016/j.patrec.2008.04.015
   DA L, 2000, SHAPE ANAL CLASSIFIC
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010
   Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   RUBNER Y, 1997, IM UND WORKSH, P661
   Rui Y, 1998, SER SOFTW ENGN KNOWL, V8, P165
   Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   Xie J, 2008, PATTERN RECOGN, V41, P1756, DOI 10.1016/j.patcog.2007.11.005
   Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 30
TC 133
Z9 172
U1 0
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2011
VL 29
IS 4
BP 286
EP 294
DI 10.1016/j.imavis.2010.11.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 727UR
UT WOS:000287828800008
DA 2024-07-18
ER

PT J
AU Anthimopoulos, M
   Gatos, B
   Pratikakis, I
AF Anthimopoulos, Marios
   Gatos, Basilis
   Pratikakis, Ioannis
TI A two-stage scheme for text detection in video images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Text detection; Video OCR; Content-based indexing; SVM
ID EXTRACTION; SEGMENTATION; LOCALIZATION
AB This paper proposes a two-stage system for text detection in video images. In the first stage, text lines are detected based on the edge map of the image leading in a high recall rate with low computational time expenses. In the second stage, the result is refined using a sliding window and an SVM classifier trained on features obtained by a new Local Binary Pattern-based operator (eLBP) that describes the local edge distribution. The whole algorithm is used in a multiresolution fashion enabling detection of characters for a broad size range. Experimental results, based on a new evaluation methodology, show the promising overall performance of the system on a challenging corpus, and prove the superior discriminating ability of the proposed feature set against the best features reported in the literature. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Anthimopoulos, Marios; Gatos, Basilis; Pratikakis, Ioannis] Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Computat Intelligence Lab, Athens 15310, Greece.
C3 National Centre of Scientific Research "Demokritos"
RP Anthimopoulos, M (corresponding author), Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Computat Intelligence Lab, Athens 15310, Greece.
EM anthimop@iit.demokritos.gr; bgat@iit.demokritos.gr;
   ipratika@iit.demokritos.gr
RI PRATIKAKIS, IOANNIS/AAD-3387-2019
OI PRATIKAKIS, IOANNIS/0000-0002-4124-3688
FU EU [FP7-ICT-217061]
FX Part of this research was carried out within the framework of the
   co-funded by the EU project CASAM (FP7-ICT-217061).
CR [Anonymous], 1992, R. woods digital image processing
   ANTHIMOPOULOS M, 2007, INT C COMP VIS THEOR, P161
   Anthimopoulos M, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P286, DOI 10.1109/DAS.2008.72
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Cai M, 2002, IEEE IMAGE PROC, P117
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen DT, 2004, SIGNAL PROCESS-IMAGE, V19, P205, DOI 10.1016/S0923-5965(03)00075-4
   Crandall D., 2003, International Journal on Document Analysis and Recognition, V5, P138, DOI 10.1007/s10032-002-0091-7
   Doermann D, 2003, PROC INT CONF DOC, P606
   Gargi U., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P29, DOI 10.1109/ICDAR.1999.791717
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538
   Jung C, 2009, PATTERN RECOGN LETT, V30, P114, DOI 10.1016/j.patrec.2008.05.014
   Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012
   Jung K, 2001, PATTERN RECOGN LETT, V22, P1503, DOI 10.1016/S0167-8655(01)00096-4
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Kim KI, 2001, PATTERN RECOGN, V34, P527, DOI 10.1016/S0031-3203(00)00095-9
   Kim W, 2009, IEEE T IMAGE PROCESS, V18, P401, DOI 10.1109/TIP.2008.2008225
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z
   LIANG J, 1997, SPIE, P149
   Lienhart R, 2003, INT SER VIDEO COMPUT, V6, P155
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   Lienhart R, 2000, MULTIMEDIA SYST, V8, P69, DOI 10.1007/s005300050006
   Lim YK, 2000, INT C PATT RECOG, P409, DOI 10.1109/ICPR.2000.902945
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Sato T, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P52, DOI 10.1109/CAIVD.1998.646033
   Sobottka K., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P57, DOI 10.1109/ICDAR.1999.791724
   Vapnik V., 1999, NATURE STAT LEARNING
   VASANT M, INT WORKSH DOC AN SY, P576
   WOLF C, 2004, LIRISRR200413 INSA L
   Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0
   XI J, 2001, INT C MULT EXP, P873
   Yanikoglu BA, 1998, PATTERN RECOGN, V31, P1191, DOI 10.1016/S0031-3203(97)00137-4
   Ye QX, 2005, IMAGE VISION COMPUT, V23, P565, DOI 10.1016/j.imavis.2005.01.004
   ZHANG HM, 2005, IJCNN 05 P 2005 IEEE, V3, P1806
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
NR 37
TC 47
Z9 54
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2010
VL 28
IS 9
BP 1413
EP 1426
DI 10.1016/j.imavis.2010.03.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 620NN
UT WOS:000279506700008
DA 2024-07-18
ER

PT J
AU Singh, R
   Vatsa, M
   Ross, A
   Noore, A
AF Singh, Richa
   Vatsa, Mayank
   Ross, Arun
   Noore, Afzel
TI Biometric classifier update using online learning: A case study in near
   infrared face verification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Online learning; Support vector machine; Near infrared face
   verification
ID RECOGNITION
AB The performance of a large scale biometric system may deteriorate over time as new individuals are continually enrolled. To maintain an acceptable level of performance, the classifier has to be re-trained off-line in batch mode using both existing and new data. The process of re-training can be computationally expensive and time consuming. This paper presents a new biometric classifier update algorithm that incrementally re-trains the classifier using online learning and progressively establishes a decision hyper-plane for improved classification. The proposed algorithm incorporates soft labels and granular computing in the formulation of a 2 nu-Online Granular Soft Support Vector Machine (SVM) to re-train the classifier using only the new data. Granular computing makes it adaptive to local and global variations in data distribution, while soft labels provide resilience to noise. Each time data is acquired, new support vectors that are linearly independent are added and existing support vectors that do not improve the classifier performance are removed. This constrains the size of the support vectors and significantly reduces the training time without compromising the classification accuracy. The efficacy of the proposed online learning strategy is validated in a near infrared face verification application involving different covariates. The results obtained on a heterogeneous near infrared face database of 328 subjects show that in all experiments using different feature extraction and classification algorithms the proposed online 2 nu-Granular Soft Support Vector Machine learning approach is 2-3 times faster while achieving a high level of accuracy similar to offline training using all data. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Singh, Richa; Vatsa, Mayank] Indraprastha Inst Informat Technol, New Delhi, India.
   [Ross, Arun; Noore, Afzel] W Virginia Univ, Lane Dept CSEE, Morgantown, WV 26506 USA.
C3 Indraprastha Institute of Information Technology Delhi; West Virginia
   University
RP Vatsa, M (corresponding author), Indraprastha Inst Informat Technol, New Delhi, India.
EM rsingh@iiitd.ac.in; mayank@iiitd.ac.in; arun.ross@mail.wvu.edu;
   afzel.noore@mail.wvu.edu
RI Vatsa, Mayank/AAR-7199-2020; Singh, Richa/M-9961-2017
OI Vatsa, Mayank/0000-0001-5952-2274; Singh, Richa/0000-0003-4060-4573
FU National Institute of Justice, United States Department of Justice; US
   National Science Foundation CAREER [IIS 0642554]
FX The authors would like to thank the reviewers and guest editors for
   their constructive and useful comments. The authors would like to thank
   Equinox Corporation, IEEE OTCBVS WS Series Bench, Center for Biometrics
   and Security Research, and AuthenMetric Co. Ltd. for granting us access
   to the face databases used in this research. Singh, Vatsa and Noore were
   supported in part through a Grant (Award No. 2003-RCCX-K001) from the
   National Institute of Justice, United States Department of Justice. Ross
   was supported by US National Science Foundation CAREER Grant No. IIS
   0642554.
CR Auer P, 2002, J COMPUT SYST SCI, V64, P48, DOI 10.1006/jcss.2001.1795
   Bargiela A., 2002, INT SERIES ENG COMPU
   Cauwenberghs Gert., 2000, Incremental and decremental support vector machine learning, P409
   Chew H., 2004, OPTIMIZATION CONTROL
   FLETCHER R., 1987, PRACTICAL METHODS OP
   Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991
   Li S.Z., 2005, Handbook of Face Recognition
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Raducanu B, 2008, PATTERN ANAL APPL, V11, P259, DOI 10.1007/s10044-008-0131-0
   Sculley D., 2007, P 30 ANN INT ACM SIG, P415
   Singh R, 2008, INFORM FUSION, V9, P200, DOI 10.1016/j.inffus.2006.06.002
   Singh R, 2007, IEEE T SYST MAN CY B, V37, P1212, DOI 10.1109/TSMCB.2007.903537
   Skocaj D, 2008, IMAGE VISION COMPUT, V26, P27, DOI 10.1016/j.imavis.2005.07.028
   Tao Q, 2005, IEEE T NEURAL NETWOR, V16, P1561, DOI 10.1109/tnn.2005.857955
   Tax DMJ, 2003, 2003 IEEE XIII WORKSHOP ON NEURAL NETWORKS FOR SIGNAL PROCESSING - NNSP'03, P499, DOI 10.1109/NNSP.2003.1318049
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   URAY M, 2007, P BRIT MACH VIS C, P272
   Vapnik V., 1999, NATURE STAT LEARNING
   Wechsler H., 2006, Reliable face recognition methods-system design, implementation and evaluation
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zivkovic Z, 2004, IEEE T PATTERN ANAL, V26, P651, DOI 10.1109/TPAMI.2004.1273970
NR 22
TC 19
Z9 22
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2010
VL 28
IS 7
SI SI
BP 1098
EP 1105
DI 10.1016/j.imavis.2010.01.009
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 603UP
UT WOS:000278233900004
DA 2024-07-18
ER

PT J
AU Ashraf, AB
   Lucey, S
   Cohn, JF
   Chen, T
   Ambadar, Z
   Prkachin, KM
   Solomon, PE
AF Ashraf, Ahmed Bilal
   Lucey, Simon
   Cohn, Jeffrey F.
   Chen, Tsuhan
   Ambadar, Zara
   Prkachin, Kenneth M.
   Solomon, Patricia E.
TI The painful face - Pain expression recognition using active appearance
   models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active appearance models; Support vector machines; Pain; Facial
   expression; Automatic facial image analysis; FACS
ID FACIAL EXPRESSIONS
AB Pain is typically assessed by patient self-report. Self-reported pain, however, is difficult to interpret and may be impaired or in some circumstances (i.e., young children and the severely ill) not even possible. To circumvent these problems behavioral scientists have identified reliable and valid facial indicators of pain. Hitherto, these methods have required manual measurement by highly skilled human observers. In this paper we explore an approach for automatically recognizing acute pain without the need for human observers. Specifically, our study was restricted to automatically detecting pain in adult patients with rotator cuff injuries. The system employed video input of the patients as they moved their affected and unaffected shoulder. Two types of ground truth were considered. Sequence-level ground truth consisted of Likert-type ratings by skilled observers. Frame-level ground truth was calculated from presence/absence and intensity of facial actions previously associated with pain. Active appearance models (AAM) were used to decouple shape and appearance in the digitized face images. Support vector machines (SVM) were compared for several representations from the AAM and of ground truth of varying granularity. We explored two questions pertinent to the construction, design and development of automatic pain detection systems. First, at what level (i.e., sequence- or frame-level) should datasets be labeled in order to obtain satisfactory automatic pain detection performance? Second, how important is it, at both levels of labeling, that we non-rigidly register the face? (C) 2009 Elsevier B.V. All rights reserved.
C1 [Ashraf, Ahmed Bilal; Lucey, Simon; Cohn, Jeffrey F.; Chen, Tsuhan; Ambadar, Zara; Prkachin, Kenneth M.; Solomon, Patricia E.] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh
RP Cohn, JF (corresponding author), Univ Pittsburgh, 3137 Sennott Sq,210 S Bouquet St, Pittsburgh, PA 15260 USA.
EM bilal@cmu.edu; slucey@ieee.org; jeffcohn@cs.cmu.edu; tsuhan@cmu.edu;
   ambadar@pitt.edu; kmprk@unbc.ca; solomon@mcmaster.ca
OI Solomon, Patricia/0000-0002-5014-0795; Lucey, Simon/0000-0002-6326-042X;
   Chen, Tsuhan/0000-0003-3951-7931
FU CIHR [MOP 77799]; NIMH [MH 51435]
FX This research was supported by CIHR Grant MOP 77799 and NIMH Grant MH
   51435.
CR Anastasi A., 2002, Psychological Testing, V7th
   [Anonymous], INT J WAVELETS MULTI
   [Anonymous], 1965, The expression of emotions in man and animal
   [Anonymous], 1988, STAT POWER ANAL SOCI
   Ashraf AB, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P9
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Bartlett MS, 2004, IEEE SYS MAN CYBERN, P592
   Cohn Jeffrey, 2007, The handbook of emotion elicitation and assessment, P203, DOI DOI 10.1093/OSO/9780195169157.003.0014
   COOTES T, 2001, PAMI, V23, P81
   Cornelius R.R., 1996, SCI EMOTION
   Craig K.D., 2001, HDB PAIN ASSESSMENT
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Ekman P., 2005, WHAT FACE REVEALS
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P, 1978, FACIAL ACTION CODING
   Hadjistavropouls T, 2004, PAIN: PSYCHOLOGICAL PERSPECTIVES, P87
   Hsu Chih-Wei., 2005, A practical guide to support vector classification
   Kerlinger F.N., 1973, Foundations of behavioral research: Educational, psychological and sociological inquiry
   Littlewort GC, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P15
   Lucey S., 2007, FACE RECOGNITION BOO
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2
   Pantic M, 2005, IEEE SYS MAN CYBERN, P3358
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   PANTIC M, 2006, P ACM INT C MULT INT
   Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010
   PRKACHIN KM, 1992, PAIN, V51, P297, DOI 10.1016/0304-3959(92)90213-U
   PRKACHIN KM, 1994, PAIN, V58, P253, DOI 10.1016/0304-3959(94)90206-2
   Scherer K., 1982, HDB METHODS NONVERBA
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Valstar M.F., 2006, International Conference on Multimodal Interfaces, P162, DOI DOI 10.1145/1180995.1181031
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Williams ACD, 2000, PAIN, V85, P457, DOI 10.1016/S0304-3959(99)00299-7
NR 35
TC 222
Z9 265
U1 0
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2009
VL 27
IS 12
SI SI
BP 1788
EP 1796
DI 10.1016/j.imavis.2009.05.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 513PL
UT WOS:000271335000005
PM 22837587
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Colbry, D
   Stockman, G
AF Colbry, Dirk
   Stockman, George
TI The 3DID face alignment system for verifying identity
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; 3D face verification
ID RECOGNITION; 2D
AB The 3DID system verifies the identity of a cooperative person by matching a sensed 3D surface of the face to a face model stored during a prior enrollment. First, anchor point detection is performed based on a shape index; then, a rigid alignment is determined between the observed and model face anchor points. A best alignment is determined using an improved Iterative Closest Point (ICP) algorithm that aligns the surfaces allowing for trimming of 10% noise points. Trimmed Root Mean Squared (RMS) error for the same person is almost always smaller than 1.3 mm: whereas for different persons, it is almost always larger than this threshold. Performance analysis shows that the 3DID system is fast enough (<2 s on a 3.2 MHz P4), reliable enough (1% equal error rate with 1.5% reject rate), and flexible enough (handles 30 degrees of yaw and 15 degrees of roll and pitch) to be practical in several applications. 3DID is also user friendly, providing several displays of intuitive value to human agents either in online or delayed analysis mode. An inexpensive scanner is needed for widespread use. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Colbry, Dirk] Arizona State Univ, Ctr Cognit Ubiquitous Comp, Sch Comp & Informat, Tempe, AZ 85287 USA.
   [Stockman, George] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
C3 Arizona State University; Arizona State University-Tempe; Michigan State
   University
RP Colbry, D (corresponding author), Arizona State Univ, Ctr Cognit Ubiquitous Comp, Sch Comp & Informat, Tempe, AZ 85287 USA.
EM Dirk.Colbry@asu.edu; stockman@cse.msu.edu
OI Colbry, Dirk/0000-0003-0666-9883
CR ACHERMANN B, 2000, P 15 INT C PATT REC, V2, P2809
   [Anonymous], THESIS MICHIGAN STAT
   [Anonymous], 1989, WORKSH INT 3D SCEN
   [Anonymous], P IEEE C COMP VIS PA
   Ansari AN, 2005, PATTERN RECOGN, V38, P2549, DOI 10.1016/j.patcog.2005.04.016
   BELLON ORP, 2005, P 13 INT C IM AN PRO, P1051
   Benabdelkader C, 2005, IMAGE VISION COMPUT, V23, P339, DOI 10.1016/j.imavis.2004.09.004
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Boehnen C, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P310, DOI 10.1109/3DIM.2005.13
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Bowyer KW, 2004, INT C PATT RECOG, P358, DOI 10.1109/ICPR.2004.1334126
   Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y
   BRONSTEIN AM, 2003, IEEE INT WORKSH AN M, P232
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   Chetverikov D, 2002, INT C PATT RECOG, P545, DOI 10.1109/ICPR.2002.1047997
   COLBRY D, 2005, P WORKSH ADV 3D IM S
   GORDON G, 1992, P IEEE COMP SOC C CO, P108
   HESHER C, 2002, P INT MULT COMP SCI
   IP HHS, 1996, INT J COMPUTER GRAPH, V12
   Lee J. C., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P722, DOI 10.1109/ICCV.1990.139627
   Lee Y, 2005, LECT NOTES COMPUT SC, V3546, P909
   Li S.Z., 2005, Handbook of Face Recognition
   Lu X, 2005, 5th International Workshop on Microprocessor Test and Verification: Common Challenges and Solutions, Proceedings, P97
   LU X, 2005, P IEEE WORKSH APPL C
   Malassiotis S, 2005, PATTERN RECOGN, V38, P2537, DOI 10.1016/j.patcog.2005.02.001
   Manjunath B. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P373, DOI 10.1109/CVPR.1992.223162
   Phillips P.J., 2003, Face Recognition Vendor Test (FRVT) 2002: Evaluation Report
   RICCIO D, 2005, P INT C IM AN PROC, P986
   Savvides M, 2004, INT C PATT RECOG, P810
   Stockman G., 2006, Sensor Review, V26, P116, DOI 10.1108/02602280610652703
   Tanaka HT, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P372, DOI 10.1109/AFGR.1998.670977
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1
   XU C, 2004, P SPIE
   YIN JQ, 2003, J EXP THER ONCOL, V3, P1
   VIVID910 MINOLTA VIV
NR 38
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1121
EP 1133
DI 10.1016/j.imavis.2008.10.016
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000013
DA 2024-07-18
ER

PT J
AU Foggia, P
   Percannella, G
   Sansone, C
   Vento, M
AF Foggia, P.
   Percannella, G.
   Sansone, C.
   Vento, M.
TI Benchmarking graph-based clustering algorithms
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Benchmarking; Graph-based clustering; Cluster detection
AB Among all the different clustering approaches proposed so far, graph-based algorithms are particularly suited for dealing with data that does not come from a Gaussian or a spherical distribution. They can be used for detecting clusters of any size and shape without the need of specifying the actual number of clusters; moreover, they can be profitably used in cluster detection problems.
   Despite of the fact that graph-based methods are gaining more and more popularity in different scientific areas, the choice of an appropriate algorithm for a given application is still the most crucial task. In this paper, we then present a detailed performance evaluation of five different graph-based clustering approaches on a database of synthetically generated graphs. The main findings of such an analysis were that algorithms based on the Minimum Spanning Tree perform better than other approaches.
   Four of the algorithms selected for comparison have been chosen from the open literature. While these algorithms do not require the setting of the number of clusters, they need, however, some parameters to be provided by the user. So, as the fifth algorithm under comparison, we propose an approach that overcomes this limitation, proving to be an effective solution in real applications where a completely unsupervised method for cluster detection is desirable. This was confirmed by a further comparative analysis carried out on four datasets coming from the UCI Machine Learning Repository. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Percannella, G.; Vento, M.] Univ Salerno, Dipartimento Ingn Informaz & Ingn Elettr, I-84084 Fisciano, SA, Italy.
   [Foggia, P.; Sansone, C.] Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy.
C3 University of Salerno; University of Naples Federico II
RP Percannella, G (corresponding author), Univ Salerno, Dipartimento Ingn Informaz & Ingn Elettr, Via P Te Don Melillo, I-84084 Fisciano, SA, Italy.
EM foggiapa@unina.it; pergen@unisa.it; carlosan@unina.it; mvento@unisa.it
RI Sansone, Carlo/AGZ-8858-2022
OI Percannella, Gennaro/0000-0002-1227-0353; Sansone,
   Carlo/0000-0002-8176-6950; FOGGIA, PASQUALE/0000-0002-7096-1902
CR ANDERS KH, 2000, P IAPRS C AMST, V33, P75
   [Anonymous], 1995, SELF ORG MAPS
   [Anonymous], 1978, Fundamentals of Computer Algorithms
   [Anonymous], 2000, THESIS U ULTRECHT
   Asuncion A., 2007, Uci machine learning repository
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bezdek James C., 1981, PATTERN RECOGN
   Brandes U, 2003, LECT NOTES COMPUT SC, V2832, P568
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Cheng HD, 2003, PATTERN RECOGN, V36, P2967, DOI 10.1016/S0031-3203(03)00192-4
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   De Santo M, 2005, PATTERN ANAL APPL, V7, P447, DOI 10.1007/s10044-004-0227-0
   De Santo M, 2003, PATTERN RECOGN LETT, V24, P1067, DOI 10.1016/S0167-8655(02)00253-2
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Enright AJ, 2002, NUCLEIC ACIDS RES, V30, P1575, DOI 10.1093/nar/30.7.1575
   Foggia P, 2007, LECT NOTES COMPUT SC, V4538, P215
   Gaertler M, 2002, THESIS U KONSTANZ
   Günter S, 2003, PATTERN RECOGN LETT, V24, P1107, DOI 10.1016/S0167-8655(02)00257-X
   HUBERT L, 1976, BRIT J MATH STAT PSY, V29, P190, DOI 10.1111/j.2044-8317.1976.tb00714.x
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Juszczak P., 2006, PhD thesis
   Kannan R, 2000, ANN IEEE SYMP FOUND, P367, DOI 10.1109/SFCS.2000.892125
   Kim DW, 2005, PATTERN RECOGN, V38, P607, DOI 10.1016/j.patcog.2004.09.006
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083
NR 28
TC 11
Z9 11
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 979
EP 988
DI 10.1016/j.imavis.2008.05.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300014
DA 2024-07-18
ER

EF