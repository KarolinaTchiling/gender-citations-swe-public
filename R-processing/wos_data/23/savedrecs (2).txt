FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Schouten, B
   Jacobs, B
AF Schouten, Ben
   Jacobs, Bart
TI Biometrics and their use in e-passports
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Privacy; Security; Passports
ID FACE RECOGNITION; SECURITY
AB A successful design, deployment and operation of biometric systems depends highly on the results for existing biometrical technologies and components. These existing technologies as well as new solutions need to be evaluated on their performance. However it is often forgotten that the biometric (iris, finger, face e.g.) is only one part of a fully deployed application. As biometric (sub)systems are often not designed with security and or privacy in mind, system integrators will need to address the requirements of the deployed application in this light. The fears and concerns of a significant segment of the user population need to be addressed as early as possible in the design process, to ensure that appropriate mechanisms are in place to reassure such users. These concerns may relate to privacy or to safety issues, which may be addressed in part through legal and regulatory measures.
   This article discusses the requirements, design and application scenario's of biometrical systems in general and the introduction of a new biometrical passport in The Netherlands in particular. On the one hand it is based on one of the authors' (BS) lecture notes of the Second International Summer School on "Biometrics for Secure Authentication", Alghero (IT), Summer 2005 (The summer school is co-organized by the BioSecure network of Excellence in Biometrics and supported by the European Biometrics Forum). On the other hand it is based on the other authors' (BJ) experiences as external advisor of the Ministry of Internal Affairs in The Netherlands - which is responsible for the introduction of the new passport. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Schouten, Ben] Ctr Math & Comp Sci, NL-1090 GB Amsterdam, Netherlands.
   [Jacobs, Bart] Radboud Univ Nijmegen, NL-6500 GL Nijmegen, Netherlands.
   [Jacobs, Bart] Tech Univ Eindhoven, NL-6500 GL Nijmegen, Netherlands.
C3 Radboud University Nijmegen; Eindhoven University of Technology
RP Schouten, B (corresponding author), Ctr Math & Comp Sci, POB 94079, NL-1090 GB Amsterdam, Netherlands.
EM B.A.M.Schouten@cwi.nl; B.Jacobs@cs.ru.nl
CR ALBRECHT A, 2003, PNAE0303 CWI CTR MAT
   [Anonymous], PKI MACH READ TRAV D
   [Anonymous], 2003, Handbook of fingerprint recognition
   [Anonymous], IEEE S RES SEC PRIV
   [Anonymous], GUIDE BIOMETRICS
   Bartlett M.S., 2001, FACE IMAGE ANAL UNSU
   Bundesamt fur Sicherheit in der Informationstechnik (BSI),, 2006, TR03110 BSI
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cox IJ, 1996, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.1996.517076
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Fatakusi O, 2008, LECT NOTES COMP SCI, V4756, P881
   HES R, 1999, FACE VALUE BIOMETRIC
   Hoepman JH, 2006, LECT NOTES COMPUT SC, V4266, P152
   Juels A., 2005, SECURITY PRIVACY ISS
   KC G, 2005, 23575 IBM RC
   Manjunath B. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P373, DOI 10.1109/CVPR.1992.223162
   Rejman-Greene M, 2004, BIOMETRIC SYSTEMS
   Richter H., 2008, NLUUG Spring Conference on Security, P21
   Ross A., 2004, P EUROPEAN SIGNAL PR, P1221
   Schimke S, 2005, PROC SPIE, V5681, P474, DOI 10.1117/12.585485
   Snelick R, 2005, IEEE T PATTERN ANAL, V27, P450, DOI 10.1109/TPAMI.2005.57
   Tabassi E., 2004, Tech. Rep., NISTIR7151
   The Ministry of the Interior and Kingdom Relations, 2005, 2B NOT 2B
   TISTARELLI M, 2005, REPORT STATE ART FAC
   Türk L, 1999, AEROSP SCI TECHNOL, V3, P71, DOI 10.1016/S1270-9638(99)80031-5
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 27
TC 44
Z9 47
U1 0
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 2
PY 2009
VL 27
IS 3
BP 305
EP 312
DI 10.1016/j.imavis.2008.05.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 393QA
UT WOS:000262386600009
OA Green Published
DA 2024-07-18
ER

PT J
AU Bauckhage, C
   Tsotsos, JK
   Bunn, FE
AF Bauckhage, Christian
   Tsotsos, John K.
   Bunn, Frank E.
TI Automatic detection of abnormal gait
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Gait analysis; Shape encoding; Vector space embedding; SVM
   classification
ID PERCEPTION; MOTION
AB Analysing human gait has found considerable interest in recent computer vision research. So far, however, contributions to this topic exclusively dealt with the tasks of person identification or activity recognition. In this paper, we consider a different application for gait analysis and examine its use as a means of deducing the physical well-being of people. Understanding the detection of unusual movement patterns as a two-class problem suggests using support vector machines for classification. We present a homeomorphisms between 2D lattices and binary shapes that provides a robust vector space embedding of segmented body silhouettes. Experimental results demonstrate that feature vectors obtained from this scheme are well suited to detect abnormal gait. Wavering, faltering, and falling can be detected reliably across individuals without tracking or recognising limbs or body parts. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Bauckhage, Christian] Deutsch Telekom Labs, Berlin, Germany.
   [Tsotsos, John K.] York Univ, Ctr Vis Res, Toronto, ON M3J 2R7, Canada.
   [Bunn, Frank E.] StressCam Operat & Syst Ltd, Toronto, ON, Canada.
C3 Deutsche Telekom AG; York University - Canada
RP Bauckhage, C (corresponding author), Deutsch Telekom Labs, Berlin, Germany.
EM bauckhag@cs.yorku.ca
RI Tsotsos, John K/G-3436-2011; Tsotsos, John/N-1131-2019; Tsotsos,
   John/HTO-0616-2023; Bauckhage, Christian/M-7872-2014
OI Tsotsos, John/0000-0002-8621-9147; Bauckhage,
   Christian/0000-0001-6615-2128
CR [Anonymous], LECT NOTES COMPUT SC
   Bauckhage C, 2005, IEEE IMAGE PROC, P1489
   BenAbdelkader C, 2004, EURASIP J APPL SIG P, V2004, P572, DOI 10.1155/S1110865704309236
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Boyd JE, 2004, COMPUT VIS IMAGE UND, V96, P35, DOI 10.1016/j.cviu.2004.04.004
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   Kienzle W., 2005, Advances, V17, P673
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Little J., 1998, VIDERE, V1, P1
   Moeslund T., 2000, Computer Vision and Image Understanding, V81, P221
   Murray M P, 1967, Am J Phys Med, V46, P290
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Tolliver D, 2003, LECT NOTES COMPUT SC, V2688, P734
   Vapnik V., 2005, NEC Journal of Advanced Technology, V2, P137
   Veeraraghavan A, 2004, PROC CVPR IEEE, P730
   Veres G., 2004, P 2004 IEEE COMP VIS, DOI [10.1109/CVPR.2004.1315243, DOI 10.1109/CVPR.2004.1315243]
   Wang L, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P433, DOI 10.1109/ICIP.2002.1038998
NR 24
TC 35
Z9 37
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 108
EP 115
DI 10.1016/j.imavis.2006.10.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700012
DA 2024-07-18
ER

PT J
AU Das, P
   Veksler, O
   Zavadsky, V
   Boykov, Y
AF Das, Piali
   Veksler, Olga
   Zavadsky, Vyacheslav
   Boykov, Yuri
TI Semiautomatic segmentation with compact shape prior
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Segmentation; Shape prior; Graph cut; Parameter estimation
ID GRAPH; ALGORITHMS
AB In recent years, interactive methods for segmentation are increasing in Popularity due to their success in different domains such as medical image processing, photo editing, etc. We present an interactive segmentation algorithm that can segment an object of interest from its background with minimum guidance from the user, who just has to select a single seed pixel inside the object of interest. Due to minimal requirements from the user, we call our algorithm semiautomatic. To obtain a reliable and robust segmentation with such low user guidance, we have to make several assumptions. Our main assumption is that the object to be segmented is of compact shape, or can be approximated by several connected roughly collinear compact pieces. We base our work on the powerful graph cut segmentation algorithm of Boykov and Jolly, which allows straightforward incorporation of the compact shape constraint. In order to make the graph cut approach suitable for our semiautomatic framework, we address several well-known issues of graph cut segmentation technique. In particular, we counteract the bias towards shorter segmentation boundaries and develop a method for automatic selection of parameters. We demonstrate the effectiveness of our approach on the challenging industrial application of transistor gate segmentation in images of integrated chips. Our approach produces highly accurate results in real-time. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Veksler, Olga; Boykov, Yuri] Univ Western Ontario, Middlesex Coll, London, ON N6A 5B7, Canada.
   [Zavadsky, Vyacheslav] Semicond Insight Inc, Ottawa, ON, Canada.
   [Das, Piali] Atamai Inc, London, ON, Canada.
C3 Western University (University of Western Ontario)
RP Veksler, O (corresponding author), Univ Western Ontario, Middlesex Coll, London, ON N6A 5B7, Canada.
EM pdas@imaging.robarts.ca; olga@csd.uwo.ca; vyacheslavz@semiconductor.com;
   yuri@csd.uwo.ca
RI Boykov, Yuri/C-1718-2015; Veksler, Olga/B-6549-2015
OI Veksler, Olga/0000-0002-9664-6601
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681
   [Anonymous], 2001, Interactive graph cuts for optimal boundary & region segmentation of objects in nd images, DOI DOI 10.1109/ICCV.2001.937505
   [Anonymous], 1962, FLOWS NETWORKS
   BLAKE A, 2004, ECCV, V1, P428
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Cohen LD, 1996, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.1996.517144
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Cremers D., 2007, INT C COMPUTER VISIO, P1, DOI [10.1109/CVPR.2007.383012, DOI 10.1109/CVPR.2007.383012]
   Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5
   Falcao AX, 1998, GRAPH MODEL IM PROC, V60, P233, DOI 10.1006/gmip.1998.0475
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Freedman D, 2005, PROC CVPR IEEE, P755
   Gonzalez W., 1996, DIGITAL IMAGE PROCES
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P469, DOI 10.1109/TPAMI.2006.57
   Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599
   KASS M, 1998, INT J COMPUT VISION, V2, P321
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kumar MP, 2005, PROC CVPR IEEE, P18
   Lee SH, 2006, IEEE T IMAGE PROCESS, V15, P2843, DOI 10.1109/TIP.2006.877308
   Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   ROUSSON M, 2002, ECCV, V2, P78
   Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407
   Slabaugh G, 2005, IEEE IMAGE PROC, P1973
   Tsai A, 2001, PROC CVPR IEEE, P463
   Veksler O, 2000, PROC CVPR IEEE, P339, DOI 10.1109/CVPR.2000.855838
   VEKSLER O, 2001, IEEE T PAMI, V24, P1654
   Wang S, 2005, IEEE T PATTERN ANAL, V27, P546, DOI 10.1109/TPAMI.2005.84
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
NR 33
TC 47
Z9 68
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 206
EP 219
DI 10.1016/j.imavis.2008.02.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700020
DA 2024-07-18
ER

PT J
AU Wang, Y
   Samaras, D
AF Wang, Yang
   Samaras, Dimitris
TI Estimation of multiple directional illuminants from a single image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE reflectance; illumination
ID REFLECTANCE; SHAPE; MODELS
AB We present a new method for the detection and estimation of multiple directional illuminants, using only one single image of an object with known geometry. It obviates the need to modify the imaged scene by inserting calibration objects of any particular geometry, relying instead on partial knowledge of the geometry of the scene. We first develop our method for the case of a Lambertian sphere with known size, illuminated by a set of directional light sources. A novel and robust way is proposed to segment the surface into regions, with each region illuminated by a different set of sources. Our region-based least-squares method is impervious to noise and missing data, which is crucial to extending the method to arbitrary smooth geometry and to surfaces having both Lambertian and specular properties. We propose a novel methodology that integrates information from shadows and shading in the presence of strong directional sources of illumination, even when significant non-directional sources exist in the scene and the object surface is not Lambertian. We demonstrate experimentally the accuracy of our method, both in detecting the number of light sources and in estimating their directions, by testing on images of a variety of synthetic and real objects. (C) 2008 Published by Elsevier B.V.
C1 [Wang, Yang; Samaras, Dimitris] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Wang, Y (corresponding author), SUNY Stony Brook, Dept Comp Sci, 2429 Comp Sci, Stony Brook, NY 11794 USA.
EM yangwang@cs.sunysb.edu
CR [Anonymous], ACM SIGGRAPH 1997 C
   [Anonymous], ACM SIGGRAPH 1996 C
   [Anonymous], ACM SIGGRAPH 1998 C
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Chojnacki W, 1997, J MATH IMAGING VIS, V7, P139, DOI 10.1023/A:1008201505044
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Haykin S., 1986, Adaptive filter theory, P607
   HE XD, 1991, ACM SIGGRAPH COMPUTE, P175
   HORN BKP, 1985, INT JOINT C ART INT, P932
   HOUGEN DR, 1993, INT C COMP VIS, P29
   HU QY, 2001, THESIS SUNY STONY BR
   KIM T, 2001, INT C COMP VIS
   KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279
   LAFORTUNE EPF, 1997, ANN C SERIES, P117
   Langer MS, 1997, PROC CVPR IEEE, P172, DOI 10.1109/CVPR.1997.609316
   LEE CH, 1985, ARTIF INTELL, V26, P125, DOI 10.1016/0004-3702(85)90026-8
   LIN S, 1999, ICCV, P855
   LIN S, 2002, EUR C COMP VIS, P210
   LOSCOS C, 1999, ACM EUR WORKSH REND, P235
   Marschner SR, 2000, APPL OPTICS, V39, P2592, DOI 10.1364/AO.39.002592
   Marschner SR, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P262
   Powell MW, 2001, IEEE T PATTERN ANAL, V23, P1022, DOI 10.1109/34.955114
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317
   Samaras D, 2003, IEEE T PATTERN ANAL, V25, P247, DOI 10.1109/TPAMI.2003.1177155
   Samaras D, 2000, PROC CVPR IEEE, P480, DOI 10.1109/CVPR.2000.855858
   SAMARAS D, 1999, INT C COMP VIS, P868
   Sato I, 2001, PROC CVPR IEEE, P400
   Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093
   TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105
   Wang Y, 2003, GRAPH MODELS, V65, P185, DOI 10.1016/S1524-0703(03)00043-2
   WANG Y, 2002, EUR C COMP VIS, P272
   WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078
   YANG Y, 1991, IEEE P COMP VIS PATT, P534
   Yu YZ, 1999, COMP GRAPH, P215
   Zhang YF, 2001, IEEE T PATTERN ANAL, V23, P915, DOI 10.1109/34.946995
   ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658
   ZHOU W, 2002, EUR C COMP VIS, P206
NR 38
TC 7
Z9 9
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1179
EP 1195
DI 10.1016/j.imavis.2007.12.009
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300001
DA 2024-07-18
ER

PT J
AU Bennett, B
   Magee, DR
   Cohn, AG
   Hogg, DC
AF Bennett, Brandon
   Magee, Derek R.
   Cohn, Anthony G.
   Hogg, David C.
TI Enhanced tracking and recognition of moving objects by reasoning about
   spatio-temporal continuity
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE visual surveillance; spatial reasoning; temporal reasoning; resolving
   ambiguity; continuity
AB A framework for the logical and statistical analysis and annotation of dynamic scenes containing occlusion and other uncertainties is presented. This framework consists of three elements; an object tracker module, an object recognition/classification module and a logical consistency, ambiguity and error reasoning engine. The principle behind the object tracker and object recognition modules is to reduce error by increasing ambiguity (by merging objects in close proximity and presenting multiple hypotheses). The reasoning engine deals with error, ambiguity and occlusion in a unified framework to produce a hypothesis that satisfies fundamental constraints on the spatio-temporal continuity of objects. Our algorithm finds a globally consistent model of an extended video sequence that is maximally supported by a voting function based on the output of a statistical classifier. The system results in an annotation that is significantly more accurate than what would be obtained by by-frame evaluation of the classifier output. The framework has been implemented and applied successfully to the analysis of team sports with a single camera. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
C3 University of Leeds
RP Cohn, AG (corresponding author), Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
EM agc@comp.leeds.ac.uk
OI Hogg, David/0000-0002-6125-9564
CR [Anonymous], P IEEE WORKSH EV MIN
   [Anonymous], 1963, DYNAMIC PROGRAMMING
   [Anonymous], P 7 INT JOINT C ART
   Bennett B, 2002, APPL INTELL, V17, P239, DOI 10.1023/A:1020083231504
   Bennett B, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P503
   Bennett B, 2001, FUND INFORM, V46, P145
   Cohn AG, 2001, FUND INFORM, V46, P1
   Cootes T., 1998, Proc. ECCV, V2, P484
   CUI Z, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P679
   DOCKSTADER S, 2001, P IEEE WORKSH MULT O
   ELGAMMAL A, 2001, P INT C COMP VIS, P9
   Fernyhough J, 2000, IMAGE VISION COMPUT, V18, P81, DOI 10.1016/S0262-8856(99)00023-2
   GALATA A, 2002, P EUR C ART INT, P741
   Galton A., 2000, Qualitative Spatial Change
   Ha DM, 2004, IMAGE VISION COMPUT, V22, P899, DOI 10.1016/j.imavis.2004.05.006
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Heikkilä J, 2004, IMAGE VISION COMPUT, V22, P563, DOI 10.1016/j.imavis.2003.09.010
   Howarth RJ, 2000, IMAGE VISION COMPUT, V18, P105, DOI 10.1016/S0262-8856(99)00025-6
   Hudelot C, 2003, PROC INT C TOOLS ART, P398, DOI 10.1109/TAI.2003.1250217
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   KOLLER D, 1994, P EUR C COMP VIS, P189
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   Magee DR, 2002, IMAGE VISION COMPUT, V20, P581, DOI 10.1016/S0262-8856(02)00047-1
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   NEEDHAM C, IN PRESS ARTIFICIAL
   Needham C.J., 2001, PROC BMVA BRIT MACHI, V1, P93, DOI DOI 10.5244/C.15.11
   NEUMANN B, 2003, ICVS, P212
   Pece AV, 2002, LECT NOTES COMPUT SC, V2350, P3
   Randell D. A., 1992, Principles of Knowledge Representation and Reasoning: Proceedings of the Third International Conference (KR '92), P165
   Remagnino P., 1997, PROC BRIT MACHINE VI, P380
   ROSALES R, 1998, P IEEE WORKSH INT VI
   SANTOS P, 2003, IJCAI, P1408
   SHERRAH J, 2000, P BRIT MACH VIS C, P252
   SIDENBLADH H, 2002, P EUR C COMP VIS, P784
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   *SWED I COMP SCI, SICSTUS PROL
   Toyama K., 1999, The Proceedings of the Seventh IEEE International Conference on Computer Vision, V1, P255
   Weld D., 1990, READINGS QUALITATIVE
   Xu M, 2005, IEE P-VIS IMAGE SIGN, V152, P232, DOI 10.1049/ip-vis:20041257
   Yang DB, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P122
NR 41
TC 7
Z9 14
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 67
EP 81
DI 10.1016/j.imavis.2005.08.012
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100007
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Skocaj, D
   Leonardis, A
AF Skocaj, Danijel
   Leonardis, Ales
TI Incremental and robust learning of subspace representations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE subspace learning; incremental learning; robust learning
ID PRINCIPAL COMPONENT ANALYSIS; RECOGNITION
AB Learning is a fundamental capability of any cognitive system. To enable efficient operation of a cognitive agent in a real-world environment, visual learning has to be a continuous and robust process. In this article, we present a method for subspace learning, which takes these considerations into account. We present an incremental method, which sequentially updates the principal subspace considering weighted influence of individual images as well as individual pixels within an image. We further extend this approach to enable determination of consistencies in the input data and imputation of the inconsistent values using the previously acquired knowledge, resulting in a novel method for incremental, weighted, and robust subspace learning. We demonstrate the effectiveness of the proposed concept in several experiments on learning of object and background representations. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Ljubljana, Fac Comp & Informat Sci, Visual Cognit Syst Lab, SI-1001 Ljubljana, Slovenia.
C3 University of Ljubljana
RP Skocaj, D (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Visual Cognit Syst Lab, Trzaska 25, SI-1001 Ljubljana, Slovenia.
EM danijel.skocaj@fri.uni.lj.si; alesl@fri.uni-lj.si
CR Aanæs H, 2002, IEEE T PATTERN ANAL, V24, P1215, DOI 10.1109/TPAMI.2002.1033213
   Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113
   [Anonymous], EARLY VISUAL LEARNIN
   Artac M, 2002, INT C PATT RECOG, P781, DOI 10.1109/ICPR.2002.1048133
   ARTAC M, 2002, IEEE C ROB AUT, P1025
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   BRAND M, 2002, EUR C COMP VIS, V1, P707
   BUNCH JR, 1978, NUMER MATH, V31, P111, DOI 10.1007/BF01397471
   Chandrasekaran S, 1997, GRAPH MODEL IM PROC, V59, P321, DOI 10.1006/gmip.1997.0425
   DAYHOT R, 2000, CVPR, P685
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541
   Edwards JL, 1998, MACH VISION APPL, V10, P232, DOI 10.1007/s001380050075
   Fergus R, 2003, PROC CVPR IEEE, P264
   FERRARI V, 2004, ECCV, V1, P40
   GABRIEL KR, 1979, TECHNOMETRICS, V21, P489, DOI 10.2307/1268288
   GRANLUND GH, 2002, COGNITIVE VISION BAC
   Gu M., 1993, Research Report YALEU/DCS/RR-966
   Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525
   Hall P. M., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P286
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Jogan M, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P37, DOI 10.1109/OMNVIS.2000.853802
   Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145
   Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830
   Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432
   LIU X, 2002, ICASSP 2002
   LOWE DG, 2001, CVPR, P628
   MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511, DOI 10.1109/TPAMI.1982.4767295
   MURASE H, 1995, SCIA95, P325
   Ohba K, 1997, IEEE T PATTERN ANAL, V19, P1043, DOI 10.1109/34.615453
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   RAO R, 1997, CVPR 97, P540
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651
   SIDENBLADH H, 2000, AFGR00, P368
   Skocaj D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1494
   Skocaj D, 2002, LECT NOTES COMPUT SC, V2353, P761
   SKOCAJ D, 2003, THESIS U LJUBLJANA L
   VERNON D, 2005, ECVISION EUROPEAN RE
   Weber M, 2000, LECT NOTES COMPUT SC, V1842, P18
   Wiberg T., 1976, Second Symposium on Computational Statistics, P229
   XU L, 1995, IEEE T NEURAL NETWOR, V6, P131, DOI 10.1109/72.363442
NR 44
TC 17
Z9 21
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 27
EP 38
DI 10.1016/j.imavis.2005.07.028
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100004
DA 2024-07-18
ER

PT J
AU Sebe, N
   Lew, MS
   Sun, Y
   Cohen, I
   Gevers, T
   Huang, TS
AF Sebe, N.
   Lew, M. S.
   Sun, Y.
   Cohen, I.
   Gevers, T.
   Huang, T. S.
TI Authentic facial expression analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE authentic emotions; facial expression analysis; classifiers
ID ALGORITHMS
AB There is a growing trend toward emotional intelligence in human-computer interaction paradigms. In order to react appropriately to a human, the computer would need to have some perception of the emotional state of the human. We assert that the most informative channel for machine perception of emotions is through facial expressions in video. One current difficulty in evaluating automatic emotion detection is that there are currently no international databases which are based on authentic emotions. The current facial expression databases contain facial expressions which are not naturally linked to the emotional state of the test subject. Our contributions in this work are twofold: first, we create the first authentic facial expression database where the test subjects are showing the natural facial expressions based upon their emotional state. Second, we evaluate the several promising machine learning algorithms for emotion detection which include techniques such as Bayesian networks, SVMs, and decision trees. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Amsterdam, Fac Sci, NL-1012 WX Amsterdam, Netherlands.
   Leiden Univ, LIACS Media Lab, NL-2300 RA Leiden, Netherlands.
   Sichuan Univ, Sch Comp Sci, Chengdu, Peoples R China.
   HP Labs, Palo Alto, CA 94304 USA.
   Univ Illinois, Beckman Inst, Urbana, IL 61801 USA.
C3 University of Amsterdam; Leiden University; Leiden University - Excl
   LUMC; Sichuan University; Hewlett-Packard; University of Illinois
   System; University of Illinois Urbana-Champaign
RP Sebe, N (corresponding author), Univ Amsterdam, Fac Sci, NL-1012 WX Amsterdam, Netherlands.
EM nicu@science.uva.nl; mlew@liacs.nl; sunyafei@cs.scu.edu.cn;
   iracohen@hp.com; gevers@science.uva.nl; huang@ifp.uiuc.edu
RI Sebe, Niculae/KEC-2000-2024; yan, shuicheng/A-8531-2014; yan,
   shuicheng/HCH-9860-2022
OI Sebe, Niculae/0000-0002-6597-7248; yan, shuicheng/0000-0001-8906-3777;
   yan, shuicheng/0000-0003-4527-1018
CR AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G
   Bartlett M.S., 2003, CVPR WORKSH COMP VIS
   Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169
   Bourel F, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P113, DOI 10.1109/AFGR.2002.1004141
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Clark P., 1989, Machine Learning, V3, P261, DOI 10.1007/BF00116835
   Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127
   COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Ekman P, 1978, FACIAL ACTION CODING
   Ekman P., 1982, EMOTION HUMAN FACE
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Freund Y., 1996, ICML 96, P148
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Goleman D, 2020, Emotional intelligence: Why it can matter more than IQ
   Hertz J., 1991, LECT NOTES SANTA FE
   IZARD CE, 1994, PSYCHOL BULL, V115, P288, DOI 10.1037/0033-2909.115.2.288
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, P537, DOI 10.1142/S021821309700027X
   LITTLESTONE N, 1993, MACH LEARN, V10, P57
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Murthy SK, 1994, J ARTIF INTELL RES, V2, P1, DOI 10.1613/jair.63
   Oliver N, 2000, PATTERN RECOGN, V33, P1369, DOI 10.1016/S0031-3203(99)00113-2
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Salovey P., 1990, IMAGINATION COGNITIO, V9, P185, DOI [10.2190/DUGG-P24E-52WK-6CDG, DOI 10.2190/DUGG-P24E-52WK-6CDG]
   SEBE N, 2003, ROBUST COMPUTER VISI, pCH7
   Tao H, 1998, PROC CVPR IEEE, P735, DOI 10.1109/CVPR.1998.698685
   Vapnik V., 1999, NATURE STAT LEARNING
   Zhang YP, 2003, INT CONF ACOUST SPEE, P113
NR 33
TC 149
Z9 170
U1 2
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 3
PY 2007
VL 25
IS 12
BP 1856
EP 1863
DI 10.1016/j.imavis.2005.12.021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220BD
UT WOS:000250131000004
DA 2024-07-18
ER

PT J
AU Wang, JG
   Sung, E
AF Wang, Jian-Gang
   Sung, Eric
TI EM enhancement of 3D head pose estimated by point at infinity
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE head pose; vanishing point; expectation-maximisation algorithm; model
   adaptation
ID PERSPECTIVE; TRACKING
AB Head pose estimation is a key task for visual surveillance, HCI and face recognition applications. In this paper, a new approach is proposed for estimating 3D head pose from a monocular image. The approach assumes the full perspective projection camera model. Our approach employs general prior knowledge of face structure and the corresponding geometrical constraints provided by the location of a certain vanishing point to determine the pose of human faces. To achieve this, eye-lines, formed from the far and near eye corners, and mouth-line of the mouth corners are assumed parallel in 3D space. Then the vanishing point of these parallel lines found by the intersection of the eye-line and mouth-line in the image can be used to infer the 3D orientation and location of the human face. In order to deal with the variance of the facial model parameters, e.g. ratio between the eye-line and the mouth-line, an EM framework is applied to update the parameters. We first compute the 3D pose using some initially learnt parameters (such as ratio and length) and then adapt the parameters statistically for individual persons and their facial expressions by minimizing the residual errors between the projection of the model features points and the actual features on the image. In doing so, we assume every facial feature point can be associated to each of features points in 3D model with some a posteriori probability. The expectation step of the EM algorithm provides an iterative framework for computing the a posterori probabilities using Gaussian mixtures defined over the parameters. The robustness analysis of the algorithm on synthetic data and some real images with known ground-truth are included. (C) 2006 Elsevier B.V. All rights reserved.
C1 Inst Infocomm Res, Singapore 119613, Singapore.
   Nanyang Technol Univ, Singapore 639798, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); Nanyang Technological University
RP Wang, JG (corresponding author), Inst Infocomm Res, 21 Mui Keng Terrace, Singapore 119613, Singapore.
EM jgwang@i2r.a-star.edu.sg; eericsung@ntu.edu.sg
RI wang, jian/GVS-0711-2022
CR ALAMNSA A, 2003, IEEE T PAMI, V25, P502
   [Anonymous], P C IM VIS COMP NZ
   [Anonymous], 2001, MULTIPLE VIEW GEOMET
   CHOI KN, 1998, FACE RECOGNITION THE, P412
   David P, 2002, LECT NOTES COMPUT SC, V2352, P698
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965
   FAUGERS OD, 1993, 3 DIMENSIONAL VISION
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gallagher AC, 2002, PATTERN RECOGN, V35, P1527, DOI 10.1016/S0031-3203(01)00128-5
   Gee A, 1996, IMAGE VISION COMPUT, V14, P105, DOI 10.1016/0262-8856(95)01044-0
   GEE A, 1994, INT C PATT RECOG, P758, DOI 10.1109/ICPR.1994.576433
   GONG S, 1998, P BMVC 98, P272
   Haralick R.M., 1993, COMPUTER ROBOT VISIO
   HARALICK RM, 1989, PATTERN RECOGN, V22, P225, DOI 10.1016/0031-3203(89)90071-X
   HESS M, 2004, P PICT COD S SAN FRA
   Horaud R, 1997, INT J COMPUT VISION, V22, P173, DOI 10.1023/A:1007940112931
   Horprasert T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P242, DOI 10.1109/AFGR.1996.557271
   *INTERSENSE INC, INERTIACUBE2
   Jebara TS, 1997, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.1997.609312
   Jones MJ, 1998, PROC CVPR IEEE, P820, DOI 10.1109/CVPR.1998.698699
   Kanatani K., 1993, GEOMETRIC COMPUTATIO
   Liebowitz D., 2001, CAMERA CALIBRATION R
   MAGEE MJ, 1984, COMPUT VISION GRAPH, V26, P256, DOI 10.1016/0734-189X(84)90188-9
   Morency LP, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P45
   OBERKAMPF D, 1996, COMPUTER VISION IMAG, V63, P485
   OLIVER N, 1997, P COMP VIS PATT REC
   Parodi P, 1996, IEEE T PATTERN ANAL, V18, P211, DOI 10.1109/34.481545
   Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210
   Press W, 1992, NUMERICAL RECIPES, P55
   SEMPLE JG, 1952, ALGEBRAIC PROJECTIVE
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   TORDOFF B, 2002, P BRIT MACH VIS C, P807
   TORRESANI L, 2003, P NEUR INF PROC SYST
   *U STIRL, FAC DAT
   Wang JG, 1999, PATTERN RECOGN LETT, V20, P1053, DOI 10.1016/S0167-8655(99)00072-0
   WANG JZ, 2000, PROTEIN TECHNICAL MA, P8
   WANG LL, 1991, IEEE T PATTERN ANAL, V13, P370, DOI 10.1109/34.88572
   Weiss I, 2001, IEEE T PATTERN ANAL, V23, P116, DOI 10.1109/34.908963
   Wells WM, 1997, INT J COMPUT VISION, V21, P63, DOI 10.1023/A:1007923522710
   Wen Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1343, DOI 10.1109/ICCV.2003.1238646
   WU H, 2001, P SCAND C IM AN JUN
   VIDERE DESIGN MEGA D
NR 43
TC 70
Z9 87
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 3
PY 2007
VL 25
IS 12
BP 1864
EP 1874
DI 10.1016/j.imavis.2005.12.017
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220BD
UT WOS:000250131000005
DA 2024-07-18
ER

PT J
AU Meriaudeau, F
AF Meriaudeau, F.
TI Real time multispectral high temperature measurement: Application to
   control in the industry
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE high temperature measurements; CCD camera; Planck's law; machine vision
ID HEAT-TREATMENT PROCESSES; LASER CLADDING PROCESS; CAMERAS; SYSTEMS
AB Many devices are used to realize non-contact temperature measurements. Whenever the body to be controlled behaves as a black body, all the devices inferring the true temperature from the body radiation are accurate and reliable. On the other hand, when it exhibits a behavior different from the black body, emissivity compensations need to be done. In case of a known emissivity, the spectral system (single wavelength) is used whereas, for gray body (unknown but constant emissivity in a narrow bandwidth) a bicolor system is more likely to be utilized. For all other cases, assumptions about the emissivity variations as a function of the wavelength and the temperature have to be ascertained and multispectral system or "hybrid-systems" which are a mix between spectral and multispectral systems have been built and used in particular cases.
   In this paper, a real time multispectral imaging system based on two CCD cameras is presented. The system is herein carefully characterized and applications such as vision control system are presented. An extension of the system with three cameras is also exposed in the perspectives. (C) 2006 Elsevier B.V. All rights reserved.
C1 Image Proc, Lab Le2i, F-71200 Le Creusot, France.
C3 Universite de Bourgogne
RP Meriaudeau, F (corresponding author), Image Proc, Lab Le2i, 12 Rue Fonderie, F-71200 Le Creusot, France.
EM f.meriaudeau@iutlecreusot.u-bourgogne.fr
CR Chrzanowski K, 1999, APPL OPTICS, V38, P2820, DOI 10.1364/AO.38.002820
   DEWITT DP, 1986, OPT ENG, V25, P596, DOI 10.1117/12.7973867
   DEWITT DP, 1989, J THERMOPHYSICS, V3, P1153
   Gardner J. L., 1981, High Temperatures - High Pressures, V13, P459
   Hiernaut J.-P., 1989, High Temp, V21, P139
   HUNTER GB, 1984, SPIE THERMOSENSE, V520, P40
   KAPLAN H, 1989, P INFRAMATION 2001, V2, P89
   Legrand AC, 2001, J ELECTRON IMAGING, V10, P274, DOI 10.1117/1.1314334
   LEGRAND AC, 1999, P ADV SENSORS METAL, V1, P317
   LEGRAND AC, 2002, THERDMOGRAPHIE MULTI
   Meriaudeau F, 1996, J LASER APPL, V8, P317, DOI 10.2351/1.4745438
   Meriaudeau F, 1997, LASER ENG, V6, P161
   Meriaudeau F, 1996, OPT ENG, V35, P3470, DOI 10.1117/1.601109
   NORDINE PC, 1986, HIGH TEMP SCI, V21, P97
   PAJANI D, 2001, TECHNIQUES ILINGENIE, V740, P1
   PAJANI D, 1989, MEASURES THERMOGRAPH
   PAJANI D, 2001, THERMOGRAPHIE TECHNO, V2741, P1
   REINER E, 1996, P IEEE 22 INT C IND, V2, P1295
   Tsai B. K., 1993, Measurement, V11, P211, DOI 10.1016/0263-2241(93)90040-O
   Zauner G, 2004, BBA LIB, V5303, P81, DOI 10.1117/12.526339
   Zauner G, 2003, P SOC PHOTO-OPT INS, V5011, P283, DOI 10.1117/12.477505
NR 21
TC 62
Z9 69
U1 2
U2 48
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1124
EP 1133
DI 10.1016/j.imavis.2006.04.019
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300010
DA 2024-07-18
ER

PT J
AU Shahir, S
   Basir, O
   Kamel, M
AF Shahir, Shahed
   Basir, Otman
   Kamel, Mohamed
TI Stand-alone embedded vision system based on fuzzy associative database
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stand-alone vision system; fuzzy; pose descriptors; sensors; state
   machine
ID PATTERN-RECOGNITION; COMPUTATION; MOMENTS; POSE
AB In this paper, a design methodology for a stand-alone embedded vision system (SEVS) is presented. The combination of region-based features and fuzzy theory defines the system, which is fast, flexible, and efficient. The proposed system can help to achieve flexible manufacturing goals and enhance safety. The advantages of the proposed system over traditional non-imaging sensors for manufacturing purposes include the recognition of the incoming product prior to determining its position, orientation, and speed. Region-based features - such as, Zernike moments, the first invariant function of central moments, and compactness - are utilized as pose descriptors. Moreover, we study the robustness of the pose descriptors and compare the fuzzy associative database (FAD) with maximum likelihood (ML) and a radial-basis function network to achieve multiple-pose detection. In addition, an ML estimation is employed to train the system automatically. It is demonstrated that the system can reliably recognize products with fairly complex shapes. When a product is successfully recognized, the system provides the essential information to a process controller or programmable logic controller for further action without requiring any particular interface. In the case of unrecognized objects, the system sends an appropriate message to the controller. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Shahir, S (corresponding author), Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
EM sshahir@pami.uwaterloo.ca; obasir@pami.uwaterloo.ca;
   mkamel@pami.uwaterloo.ca
RI Kamel, Mohamed S/D-9323-2011; Basir, Otman/ISU-4477-2023
OI Kamel, Mohamed/0000-0001-6173-8082; Basir, Otman/0000-0002-6454-0538
CR [Anonymous], 1997, NEURO FUZZY SOFT COM
   [Anonymous], PRINCIPLES OPTIC
   Bailey RR, 1996, IEEE T PATTERN ANAL, V18, P389, DOI 10.1109/34.491620
   Belkasim S, 2001, PATTERN RECOGN, V34, P1867, DOI 10.1016/S0031-3203(00)00112-6
   BLIND S, 2000, IEEE INT C ROB AUT, P115
   CANNY JF, 1994, IEEE INT CONF ROBOT, P1951, DOI 10.1109/ROBOT.1994.351176
   CARLISLE B, 1994, IEEE INT CONF ROBOT, P1650, DOI 10.1109/ROBOT.1994.351354
   COLLINS G, 2001, IEE MANUFACTURING EN, V80, P89
   DUDA RO, 2001, STORK PATTERN CLASSI
   Figueiredo MAT, 2000, INT C PATT RECOG, P618, DOI 10.1109/ICPR.2000.906151
   FUKUMI M, 1992, IEEE T NEURAL NETWOR, V3, P272, DOI 10.1109/72.125868
   Goldberg K, 1999, IEEE T ROBOTIC AUTOM, V15, P849, DOI 10.1109/70.795790
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HADDADNIA J, 2002, IEEE INT C NEUR NETW, V1, P11
   HARDIN W, 2004, NONIMAGING SENSORS D, P29
   HORN BKP, 1987, MASSACHUSETTS I TECH
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Jia YB, 1996, INT J ROBOT RES, V15, P365, DOI 10.1177/027836499601500405
   Jia YB, 1999, INT J ROBOT RES, V18, P466
   KOSTKO B, 1992, NEURAL FUZZY SYSTEMS
   MUKUNDAN R, 1995, PATTERN RECOGN, V28, P1433, DOI 10.1016/0031-3203(95)00011-N
   Peng J, 1998, IEEE T PATTERN ANAL, V20, P139, DOI 10.1109/34.659932
   RAO AS, 1994, IEEE T IND ELECTRON, V41, P51, DOI 10.1109/41.281608
   REEVES AP, 1988, IEEE T PATTERN ANAL, V10, P937, DOI 10.1109/34.9115
   Sahambi HS, 2003, IEEE T NEURAL NETWOR, V14, P138, DOI 10.1109/TNN.2002.806949
   Shahir S, 2004, 1ST CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P295, DOI 10.1109/CCCRV.2004.1301458
   SHAHIR S, 2003, INT S CIRC SYST ISCA, V5, P805
   SMITH L, 2002, METAL POWDER REPORT, P20
   TIMOTHY P, 1997, COMPUTER INTEGRATED, V10, P176
   WALLACK A, 1993, IEEE INT C ROB AUT, V1, P692
   Zhang SG, 2001, NETWORKS, V37, P102, DOI 10.1002/1097-0037(200103)37:2<102::AID-NET5>3.0.CO;2-S
NR 32
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1165
EP 1173
DI 10.1016/j.imavis.2006.06.010
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300013
DA 2024-07-18
ER

PT J
AU Ceccarelli, M
AF Ceccarelli, Michele
TI A finite Markov Random Field approach to fast edge-preserving image
   recovery
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Markov random fields; image denoising; edge-preserving potentials
ID ANISOTROPIC DIFFUSION; REGULARIZATION; RESTORATION; ENHANCEMENT
AB We investigate the properties of edge-preserving smoothing in the context of Finite Markov Random Fields (FMRF). Our main result follows from the definition of discontinuity adaptive potential for FMRF which imposes to penalize linearly image gradients. This is in agreement with the Total Variation based regularization approach to image recovery and analysis. We also report a fast computational algorithm exploiting the finiteness of the field, it uses integer arithmetic and a gradient descent updating procedure. Numerical results on real images and comparisons with anisotropic diffusion and half-quadratic regularization are reported. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Sannio, RCOST, I-82100 Benevento, Italy.
C3 University of Sannio
RP Ceccarelli, M (corresponding author), Univ Sannio, RCOST, Via Traiano, I-82100 Benevento, Italy.
EM ceccarelli@unisannio.it
RI Ceccarelli, Michele/AGP-1739-2022
OI Ceccarelli, Michele/0000-0002-4702-6617
CR Achim A, 2003, IEEE T GEOSCI REMOTE, V41, P1773, DOI 10.1109/TGRS.2003.813488
   ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   [Anonymous], 1987, Visual Reconstruction
   [Anonymous], 1995, Markov random field modeling in computer vision
   Antonelli L, 2002, LECT NOTES COMPUT SC, V2330, P171
   Ceccarelli M, 2002, IEE P-VIS IMAGE SIGN, V149, P244, DOI 10.1049/ip-vis:20020421
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GEMAN S, 1995, P STAT COMP SECT AM, P12
   Gonzales R., 1992, DIGITAL IMAGE PROCES
   GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985
   HEBERT T, 1989, IEEE T MED IMAGING, V8, P194, DOI 10.1109/42.24868
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   LI SZ, 1995, IEEE T PATTERN ANAL, V17, P576, DOI 10.1109/34.387504
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807
   Trucco E., 1998, INTRO TECHNIQUES 3D
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
NR 26
TC 12
Z9 14
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 792
EP 804
DI 10.1016/j.imavis.2006.05.021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600003
DA 2024-07-18
ER

PT J
AU Broumandnia, A
   Shanbehzadeh, J
AF Broumandnia, Ali
   Shanbehzadeh, Jamshid
TI Fast Zernike wavelet moments for Farsi character recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE wavelet moments; Zernike moments; character recognition; character
   segmentation; neural networks; fast feature extraction
ID ALGORITHM; SEGMENTATION
AB Farsi character recognition (FCR) systems perform recognition of Farsi documents. This paper presents a novel approach of fast Farsi character recognition based on fast zernike wavelet moments and artificial neural networks. Fast Zernike wavelet moments and artificial neural networks are employed in feature extraction and classification, respectively. A simulation result shows superiority of novel scheme over similar ones in terms of precision 4.37 times in average, and improves recognition speed by about 8.0 times in average. (c) 2006 Elsevier B.V. All rights reserved.
C1 Islamic Azad Univ, Sci & Res Branch, Tehran 14515755, Iran.
   Tarbiat Moallem Univ, Dept Comp Engn, Tehran, Iran.
C3 Islamic Azad University; Kharazmi University
RP Broumandnia, A (corresponding author), Islamic Azad Univ, Sci & Res Branch, Tehran 14515755, Iran.
EM broumandnia@azad.ac.ir
RI Broumandnia, Ali/I-6383-2018
OI Broumandnia, Ali/0000-0001-5145-2013
CR ALYOUSEFI H, 1992, IEEE TRANSITION PATT, V14
   AMIN A, 1991, INT J MAN MACH STUD, V35, P767
   AMOR NB, 2005, P 4 INT S IM SIGN PR
   [Anonymous], 2000, Wavelet theory and its application to pattern recognition
   Bushofa BMF, 1997, IMAGE VISION COMPUT, V15, P167, DOI 10.1016/S0262-8856(96)01119-5
   Chim YC, 1999, IMAGE VISION COMPUT, V17, P299, DOI 10.1016/S0262-8856(98)00110-3
   COWELL J, 2002, FAST RECOGNITION SYS
   El Gowely K., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P700, DOI 10.1109/ICPR.1990.118196
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   KLASSEN TJ, 2002, ONLONE RECOGNITION A
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   MENHAJ MB, 2002, SIMULATION SEGMENTAT
   Micheli-Tzanakou E., 2000, Supervised and Unsupervised Pattern Recognition: Feature Extraction and Computational Intelligence
   Mowlaei A., 2002, FEATURE EXTRACTION W
   Mukundan R., 2003, PATTERN RECOGN, V36, P1733
   NANDEDKAR AV, 2004, P 4 INT C COMP INF T
   Pan H, 2005, PATTERN RECOGN, V38, P395, DOI 10.1016/j.patcog.2004.05.016
   SARFRAZ M, P 2003 INT C GEOM MO
   Sastry CS, 2004, PATTERN RECOGN LETT, V25, P1845, DOI 10.1016/j.patrec.2004.07.011
   Smith S.W., 2003, Digital Signal Processing
   TEODORIDIS S, 2003, PATTERN RECOGNITION
   THUILLAND M, 2001, WAVELET SOFT COMPUTI
   Vakil-Baghmisheh MT, 2004, NEUROCOMPUTING, V62, P39, DOI 10.1016/j.neucom.2003.11.011
   WATANABE S, 1971, PATTERN RECOGN, V3, P385, DOI 10.1016/0031-3203(71)90029-X
   Zheng LY, 2004, PATTERN RECOGN LETT, V25, P1723, DOI 10.1016/j.patrec.2004.06.015
NR 25
TC 49
Z9 52
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 717
EP 726
DI 10.1016/j.imavis.2006.05.014
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200017
DA 2024-07-18
ER

PT J
AU Salvi, J
   Matabosch, C
   Fofi, D
   Forest, J
AF Salvi, Joaquim
   Matabosch, Carles
   Fofi, David
   Forest, Josep
TI A review of recent range image registration methods with accuracy
   evaluation
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE computer vision; 3D reconstruction; range image; registration
ID SURFACE REGISTRATION; 3D
AB The three-dimensional reconstruction of real objects is an important topic in computer vision. Most of the acquisition systems are limited to reconstruct a partial view of the object obtaining in blind areas and occlusions, while in most applications a full reconstruction is required. Many authors have proposed techniques to fuse 3D surfaces by determining the motion between the different views. The first problem is related to obtaining a rough registration when such motion is not available. The second one is focused on obtaining a fine registration from an initial approximation. In this paper, a survey of the most common techniques is presented. Furthermore, a sample of the techniques has been programmed and experimental results are reported to determine the best method in the presence of noise and outliers, providing a useful guide for an interested reader including a Matlab toolbox available at the webpage of the authors. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Girona, Inst Informat & Applicat, Girona 17071, Spain.
   Univ Burgundy, Lab Elect Informat & Image, F-71200 Le Creusot, France.
C3 Universitat de Girona
RP Salvi, J (corresponding author), Univ Girona, Inst Informat & Applicat, Av Lluis Santalo SN, Girona 17071, Spain.
EM qsalvi@eia.udg.es; cmatabos@eia.udg.es;
   d.foti@iutlecreusot.u-bourgogne.fr; forest@eia.udg.es
RI ; Salvi, Joaquim/L-2648-2014; Fofi, David/F-4087-2012
OI Forest, Josep/0000-0002-4868-5884; Salvi, Joaquim/0000-0002-9482-7126;
   Fofi, David/0000-0002-9180-9539
CR [Anonymous], 1997, THESIS CARNEGIE MELL
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Brunnstrom K., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P689, DOI 10.1109/ICPR.1996.547653
   CARMICHAEL O, 1999, 2 INT C 3D DIG IM MO, P258
   CHEN C, 2005, INT C 3 D DIG IM MOD, P254
   Chen CS, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P242, DOI 10.1109/ICCV.1998.710725
   Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043
   Chow CK, 2004, PATTERN RECOGN, V37, P105, DOI 10.1016/S0031-3203(03)00222-X
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   Chung DH, 1998, PATTERN RECOGN, V31, P457, DOI 10.1016/S0031-3203(97)00063-0
   Dalley G, 2002, COMPUT VIS IMAGE UND, V87, P104, DOI 10.1006/cviu.2002.0986
   FELDMAR J, 1994, RIGID AFFINE LOCALLY
   Forest J, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P73, DOI 10.1109/IRDS.2002.1041365
   GAGNON H, 1994, COMPUTER VISION PATT, P581
   Godin G., 1994, Proceedings of the SPIE - The International Society for Optical Engineering, V2350, P279, DOI 10.1117/12.189139
   Godin G, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P179, DOI 10.1109/IM.2001.924430
   Greenspan M, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P161, DOI 10.1109/IM.2001.924426
   HUBER D, 1999, INT C INT ROB SYST, P1121
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Jost T, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P540, DOI 10.1109/TDPVT.2002.1024114
   Kim SH, 2003, P WORKSHOP FRONTIERS, V12, P155
   Masuda T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P879, DOI 10.1109/ICPR.1996.546150
   Masuda T, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P439, DOI 10.1109/TDPVT.2002.1024099
   Masuda T, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P254, DOI 10.1109/IM.2001.924447
   Matabosch C, 2004, IEEE INT CONF ROBOT, P678, DOI 10.1109/ROBOT.2004.1307227
   MATABOSCH C, 2003, WORKSH EUR SCI IND C, P405
   Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002
   Schutz C., 1998, P 3 AS C COMP VIS, V1, P490
   Sharp GC, 2004, IEEE T PATTERN ANAL, V26, P1037, DOI 10.1109/TPAMI.2004.49
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   Silva L, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P268, DOI 10.1109/IM.2003.1240259
   STAMOS J, 2003, IEEE COMPUTER SOC C, V2, P555
   Tarel Jean-Philippe., 1998, P IEEE WORSHOP MODEL, P13
   Trucco E, 1999, PATTERN RECOGN LETT, V20, P889, DOI 10.1016/S0167-8655(99)00055-0
   TURK G, 1996, SIGGRAPH 94 P 21 ANN, P311
   ULLRICH A, 2002, 3D DAT PROC VIS TRAN, P852
   Wyngaerd JV, 2002, COMPUT VIS IMAGE UND, V87, P8, DOI 10.1006/cviu.2002.0979
   ZHANG Z., 1992, ITERATIVE POINT MATC
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zinsser T, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P695
NR 44
TC 426
Z9 507
U1 1
U2 190
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 578
EP 596
DI 10.1016/j.imavis.2006.05.012
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bannister, PR
   Brady, JM
   Jenkinson, M
AF Bannister, Peter R.
   Brady, J. Michael
   Jenkinson, Mark
TI Integrating temporal information with a non-rigid method of motion
   correction for functional magnetic resonance images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE FMRI; image registration; non-rigid motion; motion correction;
   slice-timing correction
ID REGISTRATION; FMRI
AB Existing approaches to the problem of subject motion artefacts in FMRl data have applied rigid-body registration techniques to what is a non-rigid problem. We propose a model, which can account for the non-linear characteristics of movement effects, known to result from the acquisition methods used to form these images. The model also facilitates the proper application of temporal corrections, which are needed to compensate for acquisition delays. Results of an implementation based on this model reveal that it is possible to correct these effects, leading to accurate realignment and timing correction. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 3PJ, England.
   John Radcliffe Hosp, Oxford Ctr Funct Magnet Resonance Imaging Brain, Oxford OX3 9DU, England.
C3 University of Oxford; University of Oxford
RP Bannister, PR (corresponding author), Univ Oxford, Dept Engn Sci, Robot Res Grp, Pk Rd, Oxford OX1 3PJ, England.
EM prb@robots.ox.ac.uk; jmb@robots.ox.ac.uk; mark@fmrib.ox.ac.uk
RI Jenkinson, Mark/AAC-8861-2019
OI Jenkinson, Mark/0000-0001-6043-0166
CR [Anonymous], 1996, Computer graphics: principles and practice
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   COX RW, 1996, MOTION FUNCTIONAL MR
   Friston K., 1995, HUM BRAIN MAP, V2, P165, DOI DOI 10.1002/HBM.460030303
   Goebel R., 1999, NEUROIMAGE
   Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132
   JENKINSON M, 2000, P 6 INT C FUNCT MAPP, P479
   Kim B, 1999, MAGN RESON MED, V41, P964, DOI 10.1002/(SICI)1522-2594(199905)41:5<964::AID-MRM16>3.0.CO;2-D
   Muresan L, 2002, PROC SPIE, V4683, P444, DOI 10.1117/12.463613
   NOLL DC, 1997, INT SOC MAGNETIC RES, P1677
   OSTUNI JL, 1989, J COMPUTER ASSISTED, V13, P20
   PARK H, 2005, P INT SOC MAGN RES M, V13
   PAUL RL, 1981, SERIES ARTIFICIAL IN
   Press W. H., 1995, Numerical Recipes in C: The Art of Scientific Computing
   Rohling R, 1997, Med Image Anal, V1, P177, DOI 10.1016/S1361-8415(97)85009-8
   WOODS RP, 1992, J COMPUT ASSIST TOMO, V16, P620, DOI 10.1097/00004728-199207000-00024
NR 16
TC 14
Z9 16
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 311
EP 320
DI 10.1016/j.imavis.2005.10.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100007
DA 2024-07-18
ER

PT J
AU Gaviao, W
   Scharcanski, J
AF Gaviao, Wilson
   Scharcanski, Jacob
TI Evaluating the mid-secretory endometrium appearance using hysteroscopic
   digital video summarization
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, State Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE medical image analysis; video summarization; hysteroscopies; gynecology
AB Often, it is necessary to evaluate the mid-secretory endometrium appearance in Gynecology. For this purpose, hysteroscopic videos have been used, and are of fundamental importance nowadays for diagnosis/prognosis of several uterine pathologies. These videos are continuous (non-interrupted) video sequences, usually recorded in full. However, only a few segments of the recorded videos are relevant for diagnosis/prognosis, and need to be evaluated and referenced later. This paper proposes a new technique to identify clinically relevant segments in diagnostic hysteroscopy videos and, consequently, to find images that present the best view of the endometrium details (e.g. glandular openings and vascularization). Our method produce a rich and compact video summary which supports fast video browsing. This method is based on an extension of known properties of the singular value decomposition (SVD), and it is adaptive, in the sense that it minimizes the need of parameter adjustments. Our preliminary experimental results indicate that our method produces compact video summaries containing a selection of clinically relevant video segments. These experimental results were validated by specialists. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Fed Rio Grande Sul, Inst Informat, BR-91501970 Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Scharcanski, J (corresponding author), Univ Fed Rio Grande Sul, Inst Informat, Av Bento Goncalves 9500,Caixa Postal 15064, BR-91501970 Porto Alegre, RS, Brazil.
EM wgaviao@inf.ufrgs.br; jacobs@inf.ufrgs.br
RI Scharcanski, Jacob/AAA-4799-2021
OI Scharcanski, Jacob/0000-0002-9223-4693
CR [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 1999, Visual Information Retrieval
   Bowman A., 1997, Applied Smoothing Techniques for Data Analysis: The Kernel Approach with S-Plus Illustrations
   Golub CH., 1989, MATRIX COMPUTATIONS
   Gong YH, 2003, MULTIMEDIA SYST, V9, P157, DOI 10.1007/s00530-003-0086-3
   Hamou J, 1991, HYSTEROSCOPY MICROCO
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   Huang CL, 2001, IEEE T CIRC SYST VID, V11, P1281, DOI 10.1109/76.974682
   LEE S, IEEE SIGNAL PROCESSI, V11
   Li Y, 2004, IEEE T CIRC SYST VID, V14, P1073, DOI 10.1109/TCSVT.2004.831968
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Masamoto H, 2000, HUM REPROD, V15, P2112, DOI 10.1093/humrep/15.10.2112
   Sahouria E, 1999, IEEE T CIRC SYST VID, V9, P1290, DOI 10.1109/76.809163
   SAKUMOTO T, 1992, HORM RES, V37, P48, DOI 10.1159/000182349
   SBEH ZB, 2001, IEEE T MED IMAGING, V20, P1321
   Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
NR 17
TC 5
Z9 5
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 70
EP 77
DI 10.1016/j.imavis.2006.01.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600009
DA 2024-07-18
ER

PT J
AU Roberts, TJ
   McKenna, SJ
   Ricketts, IW
AF Roberts, Timothy J.
   McKenna, Stephen J.
   Ricketts, Ian W.
TI Human tracking using 3D surface colour distributions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE human tracking; articulated models; sequential estimation; human
   computer interfaces
ID MOTION; RECOGNITION
AB A likelihood formulation for detailed human tracking in real-world scenes is presented. In this formulation, the appearance, modelled using feature distributions defined over regions on the surface of an articulated 3D model, is estimated and propagated as part of the state. The benefit of such a formulation over currently used techniques is that it provides a dense, highly discriminatory object-based cue that applies in real world scenes. Multi-dimensional histograms are used to represent the feature distributions and an on-line clustering algorithm, driven by prior knowledge of clothing structure, is derived that enhances appearance estimation and computational efficiency. An investigation of the likelihood model shows its profile to be smooth and broad while region grouping is shown to improve localisation and discrimination. These properties of the likelihood model ease pose estimation by allowing coarse, hierarchical sampling and local optimisation. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Dundee, Div Appl Comp, Dundee DD1 4HN, Scotland.
C3 University of Dundee
RP McKenna, SJ (corresponding author), Univ Dundee, Div Appl Comp, Queen Mother Bldg, Dundee DD1 4HN, Scotland.
EM troberts@computing.dundee.ac.uk; ste-phen@computing.dundee.ac.uk;
   ricketts@computing.dundee.ac.uk
RI McKenna, Stephen/AAL-8335-2020
OI McKenna, Stephen/0000-0003-0530-2035
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   BAUMBERG A, 1997, MOTION BASED RECOGNI, P39
   Black M.J., 1997, Motion-based Recognition, P245
   Bowden R, 2000, IMAGE VISION COMPUT, V18, P729, DOI 10.1016/S0262-8856(99)00076-1
   Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581
   CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K
   CHAM T, 1999, IEEE INT C COMP VIS, V2, P239
   Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676
   Comaniciu D., 2000, IEEE Proc. on Computer Vision and Pattern Recognition on, P673
   Darrell T, 2000, INT J COMPUT VISION, V37, P175, DOI 10.1023/A:1008103604354
   Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758
   Elgammal A, 2001, PROC CVPR IEEE, P563
   Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056
   Gong S., 2000, Dynamic vision from images to face recognition
   Hogg D., 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3
   ISARD M, 1996, EUR C COMP VIS, V1, P343
   Jojic N, 1998, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.1998.698656
   Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241
   Kakadiaris IA, 1996, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.1996.517057
   Karaulova I. A., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P352
   MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020
   McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   MOESLUND TB, 1999, L1A9901 U AALB
   MOESLUND TB, 2000, IEEE INT C FAC GEST, P362
   Okada R., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P336, DOI 10.1109/AFGR.2000.840656
   Park JS, 2000, PROC SPIE, V3972, P2
   PLANKERS R, 2001, THESIS EPFL SWITZ
   PUZICHA J, 1999, IEEE INT C COMP VIS, P1165
   Ronfard R, 2002, LECT NOTES COMPUT SC, V2353, P700
   Sidenbladh H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P709, DOI 10.1109/ICCV.2001.937696
   SIDENBLADH H, 2000, INT C AUT FAC GEST R, P368
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Sminchisescu C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P27, DOI 10.1109/AFGR.2002.1004125
   SMINCHISESCU C, 2001, IEEE C COMP VIS PATT, V1, P477
   Song Y, 2000, PROC CVPR IEEE, P810, DOI 10.1109/CVPR.2000.855904
   Wachter S, 1999, COMPUT VIS IMAGE UND, V74, P174, DOI 10.1006/cviu.1999.0758
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   ZHAO T, 2002, AS C COMP VIS MELB, P144
NR 42
TC 4
Z9 6
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2006
VL 24
IS 12
BP 1332
EP 1342
DI 10.1016/j.imavis.2006.04.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 107AH
UT WOS:000242142600007
DA 2024-07-18
ER

PT J
AU Marcenaro, L
   Marchesotti, L
   Regazzoni, CS
AF Marcenaro, L.
   Marchesotti, L.
   Regazzoni, C. S.
TI Self-organizing shape description for tracking and classifying multiple
   interacting objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Performance Evaluation of Tracking and Surveillance (PETS)
CY DEC09, 2001
CL Kauai, HI
SP IEEE
ID HUMAN MOTION; IMAGE; SEQUENCES; ELEMENT
AB The problem faced in this work is related to tracking and recognition of rigid and non-rigid interacting objects in complex scenes from a static camera. The processing steps leading to the description of the behavior of objects in terms of trajectories and typology will be illustrated in details and the performances of the system will be discussed. The proposed approach uses an empty reference image for object extraction through image difference; the reference frame is updated continuously by a high level background updating module taking into account the detected objects and their classification tag. The tracking module is responsible for objects labelling being able to preserve objects identity even when an occlusion occurs on the image plane between different objects. A novel approach is considered for tracking and recognition. which is based on different features selection strategies applied to an initially redundant set of shape points (i.e. corners). Shortterm and long-term memory models are used in a cooperative scheme. The two level feature selection strategy used by long-term shape models is described: at lower level a spatial-temporal voting method is used to assess temporal stability of spatial groups of corners; at the higher level, a supervised self-organizing scheme is used for objects classification. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Genoa, Dept Biophys & Elect Engn, DIBE, I-16145 Genoa, Italy.
C3 University of Genoa
RP Regazzoni, CS (corresponding author), Univ Genoa, Dept Biophys & Elect Engn, DIBE, Via Opera Pia 11A, I-16145 Genoa, Italy.
EM carlo@dibe.unige.it
RI Regazzoni, Carlo S/B-6092-2012
OI Regazzoni, Carlo S/0000-0001-6617-1417; Marcenaro,
   Lucio/0000-0003-1515-120X
CR AKITA K, 1984, PATTERN RECOGN, V17, P73, DOI 10.1016/0031-3203(84)90036-0
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   BAUMBERG AM, 1994, 9411 U LEEDS SCH COM
   BOSE B, 2004, THESIS MIT
   COLLINS R, 1999, SYSTEM VIDEO SURVEIL
   Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109
   Dockstader SL, 2001, P IEEE, V89, P1441, DOI 10.1109/5.959340
   Foresti G.L., 2000, MULTIMEDIA VIDEO BAS
   Foresti GL, 1997, IEEE SIGNAL PROC LET, V4, P248, DOI 10.1109/97.623040
   FORESTI GL, 1994, P 1994 INT C IND EL, P984
   Fukunaga K., 1989, STAT PATTERN RECOGNI
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Grimson W., 1990, OBJECT RECOGNITION C
   Haag M, 1999, INT J COMPUT VISION, V35, P295, DOI 10.1023/A:1008112528134
   HARALICK RM, 1992, COMPUTER ROBOT VISIO, P28
   HARITAOGLU I, 1998, P EUR C COMP VIS
   Hoshino J, 2001, J VISUAL COMP ANIMAT, V12, P23, DOI 10.1002/vis.242
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kalman R.E., 1960, J BASIC ENG-T ASME, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]
   KANADE T, 1992, COOPERATIVE MULTISEN, P28
   LOUTAS E, 2001, 8 IEEE INT C IM PROC
   MARCHESOTTI L, 2004, INT C MULT EXP TAIP
   OBERTI F, 2000, EUR SIGN PROC C EUS
   OBERTI F, 2002, P ICIP 2002 ROCH NEW
   Peterfreund N, 1999, IEEE T PATTERN ANAL, V21, P564, DOI 10.1109/34.771328
   REGAZZONI CS, 2000, ADV STUDIES I MULTIS
   REGAZZONI CS, 1997, ROAD VEHICLE AUTOMAT, V2, P297
   REGAZZONI CS, 1994, 1 IEE EINT C IM PROC, V1, P106
   RHEG J, 1995, IEEE INT C COMP VIS, P612
   Sacchi C, 2001, SIGNAL PROCESS, V81, P1017, DOI 10.1016/S0165-1684(00)00280-2
   Serra Ph Salembier, 1994, J SIGNAL PROCESSING
   STARNER TE, 1999, WEARABEL COMPUTING C
   Swets DL, 1999, IEEE T PATTERN ANAL, V21, P386, DOI 10.1109/34.765652
   TESCHIONI A, 2006, NONLINEAR SIGNAL IMA, P28
   TESEI A, 1996, LONG MEMORY MATCHING, P283
   THEIL A, 2000, 1 IEEE INT WORKSH PE, P80
   Tsap LV, 2000, IEEE T PATTERN ANAL, V22, P526, DOI 10.1109/34.857007
   2000, 1 IEEE INT WORKSH PE
   2000, IEEE T PATTERN ANAL, V22
   2001, 2 IEE EINT WORKSH PE
NR 43
TC 11
Z9 13
U1 1
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2006
VL 24
IS 11
BP 1179
EP 1191
DI 10.1016/j.imavis.2005.06.012
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 101CJ
UT WOS:000241716200004
DA 2024-07-18
ER

PT J
AU Hodgson, S
   Harrison, RF
   Cross, SS
AF Hodgson, Simon
   Harrison, Robert F.
   Cross, Simon S.
TI An automated pattern recognition system for the quantification of
   inflammatory cells in hepatitis-C-infected liver biopsies
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE liver biopsy analysis; feature extraction; pattern recognition; Bayesian
   decision theory; Gaussian mixture models; sequential forward floating
   search
ID CHRONIC VIRAL-HEPATITIS; DIGITAL IMAGE-ANALYSIS; NUCLEAR ANTIGEN;
   FIBROSIS
AB This paper presents an automated system for the quantification of inflammatory cells in hepatitis-C-infected liver biopsies. Initially, features are extracted from colour-corrected biopsy images at positions of interest identified by adaptive thresholding and clump decomposition. A sequential floating search method and principal component, analysis are used to reduce dimensionality. Manually annotated training images allow supervised training. The performance of Gaussian parametric and mixture models is compared when used to classify regions as either inflammatory or healthy. The system is optimized using a response surface method that maximises the area under the receiver operating characteristic curve. This system is then tested on images previously-ranked by a number of observers with varying levels of expertise. These results are compared to the automated system using Spearman rank correlation. Results show that this system can rank 15 test images, with varying degrees of inflammation, in strong agreement with five expert pathologists. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield S1 3JD, S Yorkshire, England.
   Univ Sheffield, Sch Med & Biomed Sci, Div Genom Med, Acad Unit Pathol, Sheffield S10 2RX, S Yorkshire, England.
C3 University of Sheffield; University of Sheffield
RP Harrison, RF (corresponding author), Univ Sheffield, Dept Automat Control & Syst Engn, Mappin St, Sheffield S1 3JD, S Yorkshire, England.
EM cop01sh@shef.ac.uk; r.f.harrison@shef.ac.uk; s.s.cross@shef.ac.uk
RI Harrison, Robert F/B-9034-2008
OI Harrison, Robert F/0000-0002-9323-8637; Cross, Simon/0000-0003-2044-1754
CR [Anonymous], 1999, WEEKLY EPIDEMIOLOGIC, V74, P421
   [Anonymous], 2015, INTRO MED STAT
   [Anonymous], 2002, ADV PTRN RECOGNIT
   [Anonymous], HEP C
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Booth J C., 2001, Gut, V49, P11
   Box G., 1987, Empirical Model-Building and Response Surfaces, DOI DOI 10.1080/00401706.1988.10488371
   Caballero T, 2001, J HEPATOL, V34, P740, DOI 10.1016/S0168-8278(01)00006-X
   CARDEI V, 1996, CSCS, V12
   Cross SS, 2002, HISTOPATHOLOGY, V41, P91, DOI 10.1046/j.1365-2559.2002.01423.x
   *DEP HLTH, 2001, CHIEF MED OFF ANN RE
   Donato MF, 2002, DIGEST LIVER DIS, V34, P197, DOI 10.1016/S1590-8658(02)80193-1
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Goldin RD, 1996, J HEPATOL, V25, P649, DOI 10.1016/S0168-8278(96)80234-0
   HALLINAN JS, 1999, THESIS U QUEENSLAND
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Haralick R. M., 1992, COMPUTER ROBOT VISIO, V1
   *INT CHESS CLUB, 2002, ICC HELP FIL RATINGS
   ISHAK K, 1995, J HEPATOL, V22, P696, DOI 10.1016/0168-8278(95)80226-6
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Kendall M., 1990, Correlation methods
   Lake-Bakaar G, 2002, DIGEST DIS SCI, V47, P1644, DOI 10.1023/A:1015800126283
   LIU L, 1998, 98017 BOST U COMP SC
   *MATH WORKS, 2005, MATL VERS 7 3
   Myers R.H., 2016, Response Surface Methodology: Process and Product Optimization Using Designed Experiments
   O'Brien MJ, 2000, AM J CLIN PATHOL, V114, P712, DOI 10.1309/D7AU-EYW7-4B6C-K08Y
   OREFEI E, 2003, REV PATHOLOGY LIVER
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Russ J.C., 1992, The Image Processing Handbook
   Schalkoff Robert J., 1989, Digital image processing and computer vision
   Scheuer PJ, 1994, LIVER BIOPSY INTERPR
   SCOTT MJJ, 1998, 323 CUEDFINFENGTR
   TEO T, 1994, PATTERN RECOGN, V15, P1013
   Werling K, 2001, EUR J GASTROEN HEPAT, V13, P489, DOI 10.1097/00042737-200105000-00005
   Würflinger T, 2004, COMPUT MED IMAG GRAP, V28, P87, DOI 10.1016/j.compmedimag.2003.07.001
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   ZUWAYLIF FH, 1979, APPL GEN STAT
NR 38
TC 6
Z9 6
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 1025
EP 1038
DI 10.1016/j.imavis.2006.02.019
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200011
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Zheng, ZL
   Yang, J
AF Zheng, Zhonglong
   Yang, Jie
TI Supervised locality pursuit embedding for pattern classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE dimensionality reduction; principal component analysis; linear
   discriminant analysis; locality pursuit embedding; supervised learning
   methods
ID DISCRIMINANT-ANALYSIS; FACE RECOGNITION; EIGENFACES
AB In pattern recognition research, dimensionality reduction techniques are widely used since it may be difficult to recognize multidimensional data especially if the number of samples in a data set is not large comparing with the dimensionality of data space. Locality pursuit embedding (LPE) is a recently proposed method for unsupervised linear dimensionality reduction. LPE seeks to preserve the local structure, which is usually more significant than the global structure preserved by principal component analysis (PCA) and linear discriminant analysis (LDA). In this paper, we investigate its extension, called supervised locality pursuit embedding (SLPE), using class labels of data points to enhance its discriminant power in their mapping into a low dimensional space. We compare the proposed SLPE approach with traditional LPE, PCA and LDA methods on real-world data sets including handwritten digits, character data set and face images. Experimental results demonstrate that SLPE is superior to other three methods in terms of recognition accuracy. (c) 2006 Elsevier B.V. All rights reserved.
C1 Zhejiang Normal Univ, Inst Informat Sci & Engn, Jinhua 321004, Zhejiang, Peoples R China.
   Shanghai Jiao Tong Univ, Inst Image & Proc & Pattern Recognit, Shanghai 200030, Peoples R China.
C3 Zhejiang Normal University; Shanghai Jiao Tong University
RP Zheng, ZL (corresponding author), Zhejiang Normal Univ, Inst Informat Sci & Engn, POB 143, Jinhua 321004, Zhejiang, Peoples R China.
EM zhonglong@zjnu.cn
CR Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M., 2001, P C ADV NEUR INF PRO, V15
   Benavente R, 1998, 24 COMP VIS CTR
   Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9
   Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127
   Cohen I., 2003, IEEE C COMP VIS PATT
   de Ridder D, 2003, LECT NOTES COMPUT SC, V2714, P333
   De Ridder D., 2002, PH200201 DELFT U TEC, P1
   Graf ABA, 2003, IEEE T NEURAL NETWOR, V14, P597, DOI 10.1109/TNN.2003.811708
   He X, 2003, P C ADV NER INF PROC
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   HE XF, 2003, IEEE INT C COMP VIS
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Klock H, 2000, PATTERN RECOGN, V33, P651, DOI 10.1016/S0031-3203(99)00078-3
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li RP, 2002, FUZZY SET SYST, V130, P101, DOI 10.1016/S0165-0114(02)00050-7
   Liu QS, 2004, IEEE T CIRC SYST VID, V14, P42, DOI 10.1109/TCSVT.2003.818352
   LIU W, 2004, IEEE P INT C AUT FAC
   Min WL, 2004, PATTERN RECOGN, V37, P781, DOI 10.1016/j.patcog.2003.09.005
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Zhao W, 1998, PROC CVPR IEEE, P164, DOI 10.1109/CVPR.1998.698604
   ZHENG X, 2004, ACM C MULT NEW YORK
   ZHENG Z, 2004, 17 AUSTR JOINT C ART
NR 29
TC 11
Z9 11
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 819
EP 826
DI 10.1016/j.imavis.2006.02.007
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100003
DA 2024-07-18
ER

PT J
AU Cordón, O
   Damas, S
   Santamaría, J
AF Cordon, O.
   Damas, S.
   Santamaria, J.
TI Feature-based image registration by means of the CHC evolutionary
   algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image registration; genetic algorithms; CHC; iterative closest point
ID GLOBAL OPTIMIZATION; GENETIC ALGORITHM
AB Image registration has been a very active research area in the computer vision community. In the last few years, there is an increasing interest on the application of evolutionary computation in this field and several evolutionary approaches have been proposed obtaining promising results. In this contribution we introduce the use of an advanced evolutionary algorithm, CHC, to solve the 3D image registration problem. The new proposal will be validated using different shapes (both synthetic and magnetic resonance images, and with several of the latter affected by noise and occlusion), considering four different transformations for each of them, and comparing the results with those from ICP, from the usually applied binary-coded genetic algorithms, and from real-coded genetic algorithms. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Granada, Dept Software Engn, Granada, Spain.
   Univ Granada, Dept Comp Sci & AI, Granada, Spain.
C3 University of Granada; University of Granada
RP Damas, S (corresponding author), Univ Granada, Dept Software Engn, Granada, Spain.
EM ocordon@decsai.ugr.es; sdamas@ugr.es; jsantam@ugr.es
RI Santamaria, Jose/A-6415-2011; Cordon Garcia, Oscar/F-6672-2011; Damas,
   Sergio/D-8556-2012
OI Santamaria, Jose/0000-0002-2022-6838; Cordon Garcia,
   Oscar/0000-0001-5112-5629; Damas, Sergio/0000-0002-8377-8349
CR [Anonymous], 1996, GENETIC ALGORITHMS D, DOI DOI 10.1007/978-3-662-03315-9_4
   [Anonymous], IEEE SE C LOUISV EEU
   Back T., 1997, Handbook of evolutionary computation, V1st
   BARDINET E, 2000, 2 INT S ADV CONC INT, V2, P73
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Chen Y, 2002, IEEE T KNOWL DATA EN, V14, P79, DOI 10.1109/69.979974
   Cordón O, 2006, J HEURISTICS, V12, P73, DOI 10.1007/s10732-006-4983-4
   Cordón O, 2003, ADVANCES IN SOFT COMPUTING: ENGINEERING DESIGN AND MANUFACTURING, P233
   Cordón O, 2003, LECT NOTES ARTIF INT, V2715, P404
   Eshelman L.J., 1991, Foundations of genetic algorithms, V1, P265, DOI DOI 10.1016/B978-0-08-050684-5.50020-3
   ESHELMAN LJ, 1993, FOUNDATIONS OF GENETIC ALGORITHMS 2, P187
   FERNANDEZVIDAL S, 2000, INT C PATT REC ICPR, V1, P712
   Garai G, 2002, IMAGE VISION COMPUT, V20, P265, DOI 10.1016/S0262-8856(02)00019-7
   GOSHTASBY AA, 2005, Z 3D IMAGE REGISTRAT
   He RJ, 2002, COMPUT MED IMAG GRAP, V26, P277, DOI 10.1016/S0895-6111(02)00019-8
   HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5
   Holland I.H., 1975, ADAPTATION NATURAL A
   Kwan RKS, 1999, IEEE T MED IMAGING, V18, P1085, DOI 10.1109/42.816072
   MONGA O, 1991, IMAGE VISION COMPUT, V9, P203, DOI 10.1016/0262-8856(91)90025-K
   Pennec X, 2000, BIOMED EN S, P499
   THIRION JP, 1995, COMPUT VIS IMAGE UND, V61, P190, DOI 10.1006/cviu.1995.1015
   Tsang PWM, 1997, IMAGE VISION COMPUT, V15, P819, DOI 10.1016/S0262-8856(97)00028-0
   Yamany SM, 1999, PATTERN RECOGN, V32, P1817, DOI 10.1016/S0031-3203(99)00060-6
   Zhang WY, 2002, J INTELL MANUF, V13, P119, DOI 10.1023/A:1014584213713
NR 25
TC 45
Z9 50
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 525
EP 533
DI 10.1016/j.imavis.2006.02.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600011
DA 2024-07-18
ER

PT J
AU Duci, A
   Yezzi, AJ
   Mitter, SK
   Soatto, S
AF Duci, A
   Yezzi, AJ
   Mitter, SK
   Soatto, S
TI Region matching with missing parts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE shape; variational; registration; missing part; inpainting
ID SHAPE SPACES; RECOGNITION
AB We present a variational approach to the problem of registering planar shapes despite missing parts. Registration is achieved through the evolution of a partial differential equation that simultaneously estimates the shape of the missing region, the underlying 'complete shape' and the collection of group elements (Euclidean, affine) corresponding to the registration. Our technique can be used both for shapes, for instance represented as characteristic functions (binary images) and for grayscale images where it can be interpreted as region 'inpainting.' The novelty of the approach lies on the fact that, rather than estimating the missing region in each image independently. we pose the problem as a joint registration with respect to an underlying 'complete shape' from which the complete version of the original data is obtained via a group action. We simultaneously estimate the complete shape and the group action in an alternating minimization scheme. (c) 2005 Elsevier B.V. All rights reserved.
C1 Scuola Normale Super Pisa, I-56100 Pisa, Italy.
C3 Scuola Normale Superiore di Pisa
RP Scuola Normale Super Pisa, Piazza Cavalieri 7, I-56100 Pisa, Italy.
EM alessandro.duci@sns.it
RI Yezzi, Anthony/AAB-4235-2020
CR Alvarez L, 1999, LECT NOTES COMPUT SC, V1682, P235
   ALVAREZ L, 1993, ARCH RATIONAL MECH, P123
   ALVAREZ L, 1994, GEOMETRIC DRIVEN DIF
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 1993, General pattern theory
   [Anonymous], GEOMETRIC METHODS CO
   AZENCOTT R, 1996, P 13 INT C PATT REC, V1, P687
   BEREZIAT D, 1997, P SPIE
   BERGER M, 1998, DEFORMABLE AREA BASE
   BURL MC, 1995, P INT WORKSH AUT FAC, P154
   CARNE TK, 1990, P LOND MATH SOC, V61, P407
   Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   GRENANDER U, 1994, J R STAT SOC B, V56, P549
   Jackway PT, 1996, IEEE T PATTERN ANAL, V18, P38, DOI 10.1109/34.476009
   KENDALL DG, 1984, B LONDON MATH SOC, V16
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040
   Kimmel R, 1998, IEEE T ROBOTIC AUTOM, V14, P427, DOI 10.1109/70.678452
   KIMMEL R, 1997, LECT NOTES COMPUTER
   Koenderink J. J., 1990, Solid shape
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   LE HL, 1993, ANN STAT, V21, P1225, DOI 10.1214/aos/1176349259
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   MALLADI R, 1996, P MATH METH BIOM IM, P21
   MARDIA KV, 1989, ADV APPL PROBAB, V21, P742, DOI 10.2307/1427764
   MILLER MI, 1999, GROUP ACTION DIFFEOM
   NASTAR C, 1996, P 4 EUR C COMP VIS E
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PENNEC X, 1996, IMAGE FUSION SHAPE V, P178
   Rangarajan A., 1999, Energy Minimization Methods in Computer Vision and Pattern Recognition. Second International Workshop, EMMCVPR'99. Proceedings (Lecture Notes in Computer Science Vol.1654), P237
   SAMSON C, 1999, THEORIES COMPUTER VI, P306
   SIDDIQI K, 1998, SHOCK GRAPHS SHAPE M
   Thompson P, 1996, IEEE T MED IMAGING, V15, P402, DOI 10.1109/42.511745
   VELTKAMP RC, 1999, UUCS199927
   Weickert J., 1997, Scale-Space Theoryin Computer Vision. Scale-Space 1997, V1252
   Yezzi AJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P59, DOI 10.1109/ICCV.2001.937499
   YOUNES L, 1998, SIAM J APPL MAT
   YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59
   ZHU S, 1995, INT C COMP VIS, P416
NR 40
TC 3
Z9 4
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2006
VL 24
IS 3
BP 271
EP 277
DI 10.1016/j.imavis.2005.07.021
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 031PI
UT WOS:000236716100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tan, S
   Dale, J
   Anderson, A
   Johnston, A
AF Tan, S
   Dale, J
   Anderson, A
   Johnston, A
TI Inverse perspective mapping and optic flow: A calibration method and a
   quantitative analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE inverse perspective mapping; optic flow; calibration methods
ID RIGID MOTION; COMPUTATION; OBSTACLE
AB In most imaging devices (including the human eye), the mechanisms that govern the projection of a 3D scene onto a 2D surface render the extraction Of useful 3D information difficult. We investigate the effects of perspective on optic flow in a driver assistance application in which a camera is mounted on the wing mirror in order to observe a driver's so called 'blind spot'. A car travelling toward the camera appears to increase in speed and size on the projected image although its real speed and size are constant. We show that the inverse perspective mapping, previously used for obstacle detection, can also help in the problem of extracting real world speed front 2D optic flow data. We provide a quantitative analysis that shows precisely to what degree speed uniformity in the 3D world can be recovered by the mapping. To determine some mapping parameters, we devised a calibration method adapted to our specific situation that can be performed on-line and unsupervised. Its simplicity lends itself to fast software or hardware implementation. (c) 2005 Published by Elsevier B.V.
C1 UCL, Dept Psychol, London WC1E 6BT, England.
C3 University of London; University College London
RP UCL, Dept Psychol, Gower St, London WC1E 6BT, England.
EM sovira.tan@ucl.ac.uk
RI Johnston, Alan/B-5393-2008
OI Johnston, Alan/0000-0001-9026-1199
CR BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   Bertozzi M, 1998, IMAGE VISION COMPUT, V16, P585, DOI 10.1016/S0262-8856(97)00093-0
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Garcia C, 2002, IMAGE VISION COMPUT, V20, P793, DOI 10.1016/S0262-8856(02)00088-4
   Gibson J.J., 1950, PERCEPTION VISUAL WO
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   HARTLEY R, 2000, MULTILE VIEW GEOMETR
   HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130
   Johnston A, 1999, P ROY SOC B-BIOL SCI, V266, P509, DOI 10.1098/rspb.1999.0666
   LEE DN, 1976, PERCEPTION, V5, P437, DOI 10.1068/p050437
   LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057
   MALLOT HA, 1991, BIOL CYBERN, V64, P177, DOI 10.1007/BF00201978
   MEYER FG, 1994, IEEE T ROBOTIC AUTOM, V10, P792, DOI 10.1109/70.338534
   MOTA S, 2004, EARL COGN VIS WORKSH
   Ogale AS, 2005, IEEE T PATTERN ANAL, V27, P988, DOI 10.1109/TPAMI.2005.123
   PAUWELS K, 2005, P IEEE C COMP VIS PA
   PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077
   Zhang T, 2002, INT J COMPUT VISION, V46, P51, DOI 10.1023/A:1013248231976
NR 22
TC 24
Z9 28
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 153
EP 165
DI 10.1016/j.imavis.2005.09.023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900005
DA 2024-07-18
ER

PT J
AU Jang, SW
   Pomplun, M
   Kim, GY
   Choi, HI
AF Jang, SW
   Pomplun, M
   Kim, GY
   Choi, HI
TI Adaptive robust estimation of affine parameters from block motion
   vectors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE affine parameters; robust estimation; motion vectors; Outlier rejection
ID CAMERA PARAMETERS; SEARCH ALGORITHM; IMAGE SEQUENCE
AB In this paper, we propose an affine parameter estimation algorithm from block motion vectors for extracting accurate motion information with the assumption that the undergoing motion can be characterized by an affine model. The motion may be caused either by a moving camera or a moving object. The proposed method first extracts motion vectors from a sequence of images by using size-variable block matching and then processes them by adaptive robust estimation to estimate affine parameters. Typically, a robust estimation filters out outliers (velocity vectors that do not fit into the model) by fitting velocity vectors to a predefined model. To filter out potential outliers, our adaptive robust estimation defines a continuous weight function based on a Sigmoid function. During the estimation process, we tune the Sigmoid function gradually to its hard-limit as the errors between the model and input data are decreased, so that we can effectively separate non-outliers from outliers with the help of the finally tuned hard-limit form of the weight function. Experimental results show that the suggested approach is very effective in estimating affine parameters reliably. (C) 2005 Elsevier B.V. All rights reserved.
C1 Korea Inst Construct Technol, Construct CALS Res Ctr, Goyang 411712, Kyounggi Do, South Korea.
RP Jang, SW (corresponding author), Korea Inst Construct Technol, Construct CALS Res Ctr, 2311 Daewha Dong, Goyang 411712, Kyounggi Do, South Korea.
EM swjang@kict.re.kr
RI Pomplun, Marc/P-8858-2019
OI Jang, Seok-Woo/0000-0001-5580-4098
CR BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bayro-Corrochano E, 2002, PATTERN RECOGN, V35, P169, DOI 10.1016/S0031-3203(00)00182-5
   Davis J, 1998, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.1998.698630
   Jain R., 1995, MACHINE VISION
   Jang DS, 1997, PATTERN RECOGN, V30, P999, DOI 10.1016/S0031-3203(96)00128-8
   Jang SW, 2002, INT J INTELL SYST, V17, P965, DOI 10.1002/int.10058
   JANG SW, 2001, LECT NOTES ARTIF INT, V2005, P527
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   LIU B, 1994, IEEE T CIRCUITS SYST, V3, P438
   Moss S, 1997, IMAGE VISION COMPUT, V15, P637, DOI 10.1016/S0262-8856(97)00014-0
   PARK JI, 1994, IEEE T CIRC SYST VID, V4, P288, DOI 10.1109/76.305873
   Park JI, 1996, SIGNAL PROCESS-IMAGE, V9, P43, DOI 10.1016/S0923-5965(96)00009-4
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Sclaroff S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1146, DOI 10.1109/ICCV.1998.710860
   Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802
NR 16
TC 12
Z9 12
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 12
PY 2005
VL 23
IS 14
BP 1250
EP 1263
DI 10.1016/j.imavis.2005.09.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 997KJ
UT WOS:000234243800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, Y
   Teoh, EK
AF Wang, Y
   Teoh, EK
TI Dynamic B-snake model for complex objects segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE deformable model; active contour; snake; B-spline; B-snake; object
   segmentation; principal component analysis
ID ACTIVE SHAPE MODELS; IMAGES
AB A close-form B-Snake model using statistics information for 2D objects segmentation is presented in this paper. We called it Dynamic B-Snake Model (DBM). It is able to model the features of the object in training set and guide the B-Snake in the deforming procedure. Compared to other deformable models, the DBM maintains the smoothness of curve while still remain compact representation. Moreover, a method of Minimum Mean Square Error (MMSE) is developed to iteratively estimate the position of those control points in the B-Snake model. As it deforms the segments of the B-Spline at a time, instead of individual points, it is very robust against local minima. Furthermore, in order to use available statistical information about the desired object shape, the Principal Component Analysis (PCA) is applied to model the distribution of knot points of training samples. This allows the deformation of B-Snake to synthesize the shape similar to those in the training set. By applying the proposed B-Snake model to medical images, it is shown that our method is more robust and accurate in comparing with the traditional Snake and Active Shape Model(ASM). (c) 2005 Elsevier Ltd. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Elect & Elect Engn, Block S2,Nanyang Ave, Singapore 639798, Singapore.
EM s2633175g@ntu.edu.sg; eekteoh@ntu.edu.sg
CR [Anonymous], P BRIT MACH VIS C BM, DOI DOI 10.1007/978-1-4471-3201-1_2
   BAUMBERG A, 1994, EUR C COMP VIS, V1, P299
   Behiels G, 1999, LECT NOTES COMPUT SC, V1679, P128
   BUCHIIN S, 1983, AFFINE DIFFERENTIAL
   COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dunteman H G., 1989, Principal Component Analysis
   ECK M, 1996, MSRTR9601 MICR CORP
   Figueiredo MAT, 2000, IEEE T IMAGE PROCESS, V9, P1075, DOI 10.1109/83.846249
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Fred ALN, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P893, DOI 10.1109/ICIP.1997.648110
   GUAND Y, 2000, PATTERN RECOGN, V33, P1411
   Hamarneh G, 2000, COMPUT CARDIOL, V27, P115, DOI 10.1109/CIC.2000.898469
   HORACE H.S., 1998, Image and Vision Computing, V16, P135
   HUANG Z, 1996, IEEE T PATTERN ANAL, V5, P10
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Klein AK, 1997, IEEE T MED IMAGING, V16, P468, DOI 10.1109/42.640737
   PAULIK MJ, 1992, IEEE T SIGNAL PROCES, V40, P660, DOI 10.1109/78.120808
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Smyth P.P., 1996, PROCS BMVC96, P705
   Solloway S., 1996, Proc. 4th Eur. Conf. Computer Vision, P400
   STAMMBERGER T, 1998, T MOD FORC CEUR WORK, V12
   Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P846, DOI 10.1109/34.608288
   Vogelsang F, 2000, PROC SPIE, V3979, P1040, DOI 10.1117/12.387609
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
   WANG Y, 2001, INT C IM PROC ICIP 2, P769
   WANG Y, 1998, IAPR WORKSH MACH VIS, P27
   WANG Y, 2004, THESIS NANYANG TECHN
   WANG Y, 1999, IEEE INT C INF INT S
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
NR 30
TC 11
Z9 12
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2005
VL 23
IS 12
BP 1029
EP 1040
DI 10.1016/j.imavis.2005.07.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 971ZK
UT WOS:000232423400001
DA 2024-07-18
ER

PT J
AU Yu, WC
   Sommer, G
   Daniilidis, K
   Duncan, JS
AF Yu, WC
   Sommer, G
   Daniilidis, K
   Duncan, JS
TI Using skew Gabor filter in source signal separation and local spectral
   orientation analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE local spectral analysis; oriented structure; Gabor wavelets; skewness;
   filter design; source signal separation; higher order moment
   information; spectral resolution
ID REPRESENTATION; FREQUENCY; MOTION; CELLS
AB Responses of Gabor wavelets in the mid-frequency space build a local spectral representation scheme with optimal properties regarding the time-frequency uncertainty principle. However, when using Gabor wavelets we observe a skewness in the mid-frequency space caused by the unsymmetrically spreading effect of Gabor wavelets. Though in most current applications the skewness does not obstruct the sampling of the spectral domain, it affects the identification and separation of source Signals from the filter response in the mid-frequency space. In this paper, we present a modification of the original Gabor filter, the skew Gabor filter, which corrects skewness so that the filter response can be described with a sum-of-Gaussians model in the mid-frequency space. The correction further enables us to use higher order moment information to analytically separate different source signal components. This provides us with an elegant framework to de-blur the filter response which is not characterized by the limited spectral resolution of other local spectral representations. (C) 2004 Elsevier B.V. All rights reserved.
C1 Yale Univ, Dept Diagnost Radiol, New Haven, CT 06520 USA.
   Univ Kiel, Inst Comp Sci, D-24105 Kiel, Germany.
   Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA.
   Yale Univ, Dept Diagnost Radiol & Elect Engn, New Haven, CT 06520 USA.
C3 Yale University; University of Kiel; University of Pennsylvania; Yale
   University
RP Yu, WC (corresponding author), Yale Univ, Dept Diagnost Radiol, BML 325,POB 208042, New Haven, CT 06520 USA.
EM weichuan.yu@yale.edu; gs@ks.informati-k.uni-kiel.de;
   kostas@grasp.cis.upenn.edu; james.duncan@yale.edu
OI Yu, Weichuan/0000-0002-5510-6916; Daniilidis, Kostas/0000-0003-0498-0758
CR ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   [Anonymous], 1988, International journal of computer vision
   Beauchemin SS, 2000, IEEE T PATTERN ANAL, V22, P200, DOI 10.1109/34.825758
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Bracewell R. N, 1986, FOURIER TRANSFORM IT, V3rd
   Cardoso J.-F., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P2109, DOI 10.1109/ICASSP.1989.266878
   DAUBECHIES K, 1992, 10 LECT WAVELETS SOC
   Daugman G, 1990, COMPUTATIONAL NEUROS, P403
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAUGMAN JG, 1988, IEEE T AC SPEECH SPE, V36
   Farid H, 1999, J OPT SOC AM A, V16, P2136, DOI 10.1364/JOSAA.16.002136
   Fleet DavidJ., 1992, MEASUREMENT IMAGE VE
   FLEET DJ, 1994, VISION RES, V34, P3057, DOI 10.1016/0042-6989(94)90278-X
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   GRZYWACZ NM, 1990, PROC R SOC SER B-BIO, V239, P129, DOI 10.1098/rspb.1990.0012
   HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L
   Jahne B., 1993, Spatio-temporal image processing: theory and scientific applications
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MICHAELIS M, 1994, P 3 EUR C COMP VIS S, V1, P101
   POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326
   RADON J, 1986, IEEE T MED IMAGING, V5, P170, DOI 10.1109/TMI.1986.4307775
   SHIZAWA KM, 1991, IEEE C COMP VIS PATT, P289
   Simoncelli EP, 1996, IEEE T IMAGE PROCESS, V5, P1377, DOI 10.1109/83.535851
   Wurtz RP, 1997, IEEE T PATTERN ANAL, V19, P769, DOI 10.1109/34.598234
   Yu WC, 2002, IEEE T PATTERN ANAL, V24, P1286, DOI 10.1109/TPAMI.2002.1033220
   Yu WC, 2001, IEEE T IMAGE PROCESS, V10, P193, DOI 10.1109/83.902274
NR 30
TC 5
Z9 7
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2005
VL 23
IS 4
BP 377
EP 392
DI 10.1016/j.imavis.2004.09.006
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NR
UT WOS:000227222100002
DA 2024-07-18
ER

PT J
AU Ikonen, L
   Toivanen, P
AF Ikonen, L
   Toivanen, P
TI Shortest routes on varying height surfaces using gray-level distance
   transforms
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE distance transforms; gray-level distance transforms; shortest paths;
   minimal geodesics; obstacle avoidance
ID PATHS; IMAGES
AB The distance transform on curved space (DTOCS) and its locally Euclidean modification weighted DTOCS (WDTOCS) calculate distances along gray-level surfaces. This article presents the Route DTOCS algorithm for finding and visualizing the shortest route between two points on a gray-level height map, and also introduces new distance definitions producing more accurate global distances. The algorithm is very simple to implement, and finds all optimal paths between the two points at once. The Route DTOCS is an efficient 2D approach to finding routes on a 3D surface. It also provides a more flexible solution to obstacle avoidance problems than the constrained distance transform. (C) 2004 Elsevier B.V. All rights reserved.
C1 Lappeenranta Univ Technol, Dept Informat Technol, FIN-53851 Lappeenranta, Finland.
C3 Lappeenranta-Lahti University of Technology LUT
RP Lappeenranta Univ Technol, Dept Informat Technol, POB 20, FIN-53851 Lappeenranta, Finland.
EM leena.ikonen@lut.fi
CR BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Borgefors G, 1996, COMPUT VIS IMAGE UND, V64, P368, DOI 10.1006/cviu.1996.0065
   Borgefors G., 1994, Aspects of Visual Form Processing, P83
   Ikonen L, 2003, LECT NOTES COMPUT SC, V2886, P308
   IKONEN L, 2003, SCAND C IM AN SCIA, P305
   KIMMEL R, 1995, IEEE T PATTERN ANAL, V17, P635, DOI 10.1109/34.387512
   Kimmel R, 1996, INT J PATTERN RECOGN, V10, P643, DOI 10.1142/S0218001496000384
   KIRYATI N, 1993, PATTERN RECOGN, V26, P1623, DOI 10.1016/0031-3203(93)90018-R
   LIN PL, 1993, IEEE T SYST MAN CYB, V23, P825, DOI 10.1109/21.256552
   PIPER J, 1987, PATTERN RECOGN, V20, P599, DOI 10.1016/0031-3203(87)90030-6
   ROSENFEL.A, 1966, J ACM, V13, P471
   Saab Y, 1999, IEEE T SYST MAN CY A, V29, P139, DOI 10.1109/3468.736370
   Saha PK, 2002, COMPUT VIS IMAGE UND, V86, P171, DOI 10.1006/cviu.2002.0974
   Silvela J, 2001, IEEE T IMAGE PROCESS, V10, P1194, DOI 10.1109/83.935035
   SOILLE P, 1994, PATTERN RECOGN LETT, V15, P1235, DOI 10.1016/0167-8655(94)90113-9
   STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6
   Toivanen Pekka J., 1995, Finnish Signal Processing Symposium, FINSIG'95, P75
   TOIVANEN PJ, 1993, PATTERN RECOGN LETT, V14, P475, DOI 10.1016/0167-8655(93)90027-B
   Toivanen PJ, 1996, PATTERN RECOGN LETT, V17, P437, DOI 10.1016/0167-8655(96)00010-4
NR 19
TC 25
Z9 26
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 133
EP 141
DI 10.1016/j.imavis.2004.06.010
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800005
DA 2024-07-18
ER

PT J
AU Kawato, S
   Tetsutani, N
AF Kawato, S
   Tetsutani, N
TI Detection and tracking of eyes for gaze-camera control
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE blink detection; eye tracking; between-the-eyes; differences between
   successive frames; gaze-camera
AB A head-off gaze-camera needs eye location information for head-free usage. For this purpose, we propose new algorithms to extract and track the positions of eyes in a real-time video stream. For extraction of eye positions, we detect blinks based on the differences between successive images. However, eyelid regions are fairly small. To distinguish them from dominant head movement, we elaborate a head movement cancellation process. For eye-position tracking, we use a template of 'Between-the-Eyes,' which is updated frame-by-frame, instead of the eyes themselves. Eyes are searched based on the current position of 'Between-the-Eyes' and their geometrical relations to the position in the previous frame. The 'Between-the-Eyes' pattern is easier to locate accurately than eye patterns. We implemented the system on a PC with a Pentium III 866-MHz CPU. The system runs at 30 frames/s and robustly detects and tracks the eyes. (C) 2004 Elsevier B.V. All rights reserved.
C1 ATR Media Informat Sci Labs, Kyoto 6190288, Japan.
RP ATR Media Informat Sci Labs, 2-2-2 Hikaridai,Seikacho, Kyoto 6190288, Japan.
EM skawato@atr.jp; Tetsutam@atr.jp
CR Amarnag S, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P557
   [Anonymous], P CHI 2003
   BALA LP, 1997 PICT COD S
   Colombo C., 1995, Proceedings. CAMP '95 Computer Architectures for Machine Perception (Cat. No.95TB8093), P258, DOI 10.1109/CAMP.1995.521048
   Crowley JL, 1997, PROC CVPR IEEE, P640, DOI 10.1109/CVPR.1997.609393
   Eriksson M, 1997, IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P314, DOI 10.1109/ITSC.1997.660494
   Feng GC, 2001, PATTERN RECOGN, V34, P1033, DOI 10.1016/S0031-3203(00)00042-X
   Grauman K, 2001, PROC CVPR IEEE, P1010
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Kawaguchi T, 2000, IEEE IMAGE PROC, P49, DOI 10.1109/ICIP.2000.900889
   Kawato S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P40, DOI 10.1109/AFGR.2000.840610
   Matsumoto Y., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P499, DOI 10.1109/AFGR.2000.840680
   Morimoto CH, 2000, IMAGE VISION COMPUT, V18, P331, DOI 10.1016/S0262-8856(99)00053-0
   SAMAD S, 2001, P ISSPA, V2, P631
   SEZGIN M, 1995, P IECON 95, V2, P1360
   Sirohey SA, 2001, PATTERN RECOGN, V34, P1367, DOI 10.1016/S0031-3203(00)00082-0
   TIAN Y, 2000, P 4 IEEE INT C AUT F, P110
   ZHANG Z, 1992, 3D DYNAMICS SCENE AN
NR 18
TC 41
Z9 52
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 1031
EP 1038
DI 10.1016/j.imavis.2004.03.013
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800009
DA 2024-07-18
ER

PT J
AU Kussul, E
   Baidyk, T
AF Kussul, E
   Baidyk, T
TI Improved method of handwritten digit recognition tested on MNIST
   database
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE handwritten digit recognition; LImited Receptive Area neural classifier;
   MNIST database; microdevice assembly
AB We have developed a novel neural classifier LImited Receptive Area (LIRA) for the image recognition. The classifier LIRA contains three neuron layers: sensor, associative and output layers. The sensor layer is connected with the associative layer with no modifiable random connections and the associative layer is connected with the output layer with trainable connections. The training process converges sufficiently fast. This classifier does not use floating point and multiplication operations. The classifier was tested on two image databases. The first database is the MNIST database. It contains 60,000 handwritten digit images for the classifier training and 10,000 handwritten digit images for the classifier testing. The second database contains 441 images of the assembly microdevice. The problem under investigation is to recognize the position of the pin relatively to the hole. A random procedure was used for partition of the database to training and testing subsets. There are many results for the MNIST database in the literature. In the best cases, the error rates are 0.7, 0.63 and 0.42%. The classifier LIRA gives error rate of 0.61% as a mean value of three trials. In task of the pin-hole position estimation the classifier LIRA also shows sufficiently good results. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Nacl Autonoma Mexico, CCADET, Ctr Instrumentos, Mexico City 04510, DF, Mexico.
C3 Universidad Nacional Autonoma de Mexico
RP Univ Nacl Autonoma Mexico, CCADET, Ctr Instrumentos, Cd Univ,AP 70-186, Mexico City 04510, DF, Mexico.
EM ekussul@servidor.unam.mx; tbaidyk@aleph.cinstrum.unam.mx
OI Kussul, Ernst/0000-0002-2849-2532; Baydyk, Tetyana/0000-0002-3095-2032
CR [Anonymous], P 2 ALL UKR INT C UK
   [Anonymous], 1962, PRINCIPLES NEURODYNA
   [Anonymous], P 15 INT C VIS INT
   BAIDYK T, 2002, P INT JOINT C NEUR N, V1, P160
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Belongie S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P454, DOI 10.1109/ICCV.2001.937552
   CLARKE TJW, 1991, IEE PROC-F, V138, P25, DOI 10.1049/ip-f-2.1991.0005
   Ernst K, 2001, IEEE IJCNN, P1516, DOI 10.1109/IJCNN.2001.939589
   HOQUE MS, 2000, P 7 INT WORKSH FRONT, P595
   KIU CK, 2002, P IEEE 8 INT WORKSH, P320
   Kussul E. M., 1994, Cybernetics and Systems '94. Proceedings of the Twelfth European Meeting on Cybernetics and Systems Research, P1687
   KUSSUL EM, 1999, P IEEE INT JOINT C N, P450
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   OSOSKOV G, 2003, P INT C PHYS CONTR, V1, P242
   Vitabile S, 2002, IEEE IJCNN, P2315, DOI 10.1109/IJCNN.2002.1007503
NR 15
TC 102
Z9 118
U1 1
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 971
EP 981
DI 10.1016/j.imavis.2004.03.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800005
DA 2024-07-18
ER

PT J
AU Seo, Y
   Heyden, A
AF Seo, Y
   Heyden, A
TI Auto-calibration by linear iteration using the DAC equation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE auto-calibration; self-calibration; dual quadric
ID SELF-CALIBRATION; SEQUENCES; MOTION
AB This paper presents an iterative algorithm for auto-calibration. The proposed algorithm switches between linearly estimating the dual of the absolute conic and the intrinsic parameters, while also incorporating the rank-3 constraint on the intrinsic parameters. The proposed algorithm locates in-between of a non-linear optimization and initial linear computation, and provides robust and sufficiently accurate initial values for a bundle adjustment. The performance of the algorithm is shown for both simulated and real data, especially in the important case of natural (zero skew and unit aspect ratio) cameras. (C) 2004 Elsevier B.V. All rights reserved.
C1 Sogang Univ, Dept Media Technol, Grad Sch Media Commun, Seoul 121742, South Korea.
C3 Sogang University
RP Seo, Y (corresponding author), Sogang Univ, Dept Media Technol, Grad Sch Media Commun, Shin Su Dong 1, Seoul 121742, South Korea.
EM yndk@sogang.ac.kr; heyden@maths.lth.se
OI SEO, Yongduek/0000-0002-0570-2197
CR BOUGNOUX S, 1998, P 6 INT C COMP VIS M
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   HARTLEY R, 1999, P 7 INT C COMP VIS K
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P133, DOI 10.1109/34.574792
   Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5
   Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362
   HEYDEN A, 2001, P INT C COMP VIS
   HEYDEN A, 1999, P 7 INT C COMP VIS K
   HORAUD R, 1998, P INT C COMP VIS
   KAHL F, 1999, P IEEE C COMP VIS PA
   Kim T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P329, DOI 10.1109/ICCV.2001.937644
   MALIS E, 2000, P 6 EUR C COMP VIS D
   MENDONCA P, 1999, P IEEE C COMP VIS PA
   Pollefeys M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P349, DOI 10.1109/ICPR.1996.546047
   POLLEFEYS M, 1998, P 6 INT C COMP VIS M
   Pollefeys M., 1996, LNCS, V1064, P31, DOI [10.1007/BFb0015521, DOI 10.1007/BFB0015521]
   PONCE J, 2000, 2 WORKSH STRUCT MULT
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   SEO Y, 2001, P IEEE C COMP VIS PA
   SEO Y, 2000, IAPR WORKSH MACH VIS
   SEO Y, 2000, INT C PATT REC BARC
   SPARR G, 1996, P INT C PATT REC VIE
   Sturm P, 1997, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.1997.609467
   Sturm P., 1996, EUROPEAN C COMPUTER, P709, DOI DOI 10.1007/3-540-61123-1
   TRIGGS B, 1998, P EUR C COMP VIS
   Triggs B., 1997, P IEEE C COMP VIS PA
   TRIGGS B, 1999, LECT NOTES COMPUTER, V1883
   ZELLER C, 1996, 2793 INRIA
NR 28
TC 7
Z9 7
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2004
VL 22
IS 11
BP 919
EP 926
DI 10.1016/j.imavis.2004.05.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 847MJ
UT WOS:000223396600006
DA 2024-07-18
ER

PT J
AU Wong, KYK
   Mendonça, PRS
   Cipolla, R
AF Wong, KYK
   Mendonça, PRS
   Cipolla, R
TI Reconstruction of surfaces of revolution from single uncalibrated views
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE surface of revolution; silhouette; single view geometry; harmonic
   homology
ID HOMOGENEOUS GENERALIZED CYLINDERS; INVARIANT PROPERTIES; CONTOURS;
   IMAGE; SHAPE
AB This paper addresses the problem of recovering the 3D shape of a surface of revolution from a single uncalibrated perspective view. The algorithm introduced here makes use of the invariant properties of a surface of revolution and its silhouette to locate the image of the revolution axis, and to calibrate the focal length of the camera. The image is then normalized and rectified such that the resulting silhouette exhibits bilateral symmetry. Such a rectification leads to a simpler differential analysis of the silhouette, and yields a simple equation for depth recovery. It is shown that under a general camera configuration, there will be a 2-parameter family of solutions for the reconstruction. The first parameter corresponds to an unknown scale, whereas the second one corresponds to an unknown attitude of the object. By identifying the image of a latitude circle, the ambiguity due to the unknown attitude can be resolved. Experimental results on real images are presented. which demonstrate the quality of the reconstruction. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Hong Kong, Dept Comp Sci & Info Syst, Hong Kong, Hong Kong, Peoples R China.
   GE Co, Global Res Ctr, Schenectady, NY 12301 USA.
   Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
C3 University of Hong Kong; General Electric; University of Cambridge
RP Univ Hong Kong, Dept Comp Sci & Info Syst, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
EM kykwong@csis.hku.hk; niendonca@crd.ge.com; cipolla@eng.cam.ac.uk
RI Arandjelović, Ognjen/V-5255-2019; Wong, Kenneth Kwan Yee/C-1577-2009
OI Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla,
   Roberto/0000-0002-8999-2151; Wong, Kenneth Kwan Yee/0000-0001-8560-9007;
   Mendonca, Paulo/0000-0003-4025-4083
CR Barrow Harry, 1978, Comput. Vis. Syst, V2, P2
   Binford T.O., 1987, ENCY ARTIFICIAL INTE, P321
   BINFORD TO, 1971, UNP P IEEE C SYST CO
   BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682
   DHOME M, 1990, LECT NOTES COMPUT SC, V427, P475
   Gross AD, 1996, IEEE T PATTERN ANAL, V18, P161, DOI 10.1109/34.481541
   HORAUD R, 1988, ARTIF INTELL, V37, P333, DOI 10.1016/0004-3702(88)90059-8
   KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321
   LAVEST JM, 1998, P C COMP VIS PATT RE, P690
   Liu J., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P123, DOI 10.1109/CVPR.1993.341000
   Mendonça PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461
   PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498
   SATO H, 1993, CVGIP-IMAG UNDERSTAN, V57, P346, DOI 10.1006/ciun.1993.1023
   ULUPINAR F, 1995, IEEE T PATTERN ANAL, V17, P120, DOI 10.1109/34.368175
   Wong KYK, 2003, IEEE T PATTERN ANAL, V25, P147, DOI 10.1109/TPAMI.2003.1177148
   WONG KYK, 2001, THESIS U CAMBRIDGE
   Zerroug M, 1996, IEEE T PATTERN ANAL, V18, P237, DOI 10.1109/34.485553
   Zerroug M, 1996, INT J COMPUT VISION, V20, P11, DOI 10.1007/BF00144115
   ZISSERMAN A, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P183, DOI 10.1109/ICCV.1995.466788
NR 21
TC 22
Z9 24
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 829
EP 836
DI 10.1016/j.imavis.2004.02.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cheng, SC
AF Cheng, SC
TI Content-based image retrieval using moment-preserving edge detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE content-based image retrieval; edge feature; moment-preserving technique
ID COLOR; COMPRESSION; FEATURES
AB A content-based image retrieval algorithm based on a new edge detection technique is proposed. Both the query and database images are divided into non-overlapping square blocks and coded by the mean in each uniform block and by edge information in each non-uniform block. The coded blocks of a query image are then used to find matches from an image database. The edge feature in a given block is detected by applying the moment-preserving principle to the image data. The edge directions are approximated by multiples of 45degrees to speed up the matching process without introducing obvious distortion. For a larger database, a selective filtering strategy based on the visual-pattern histograms is also described to further speed up the retrieval process. The solution to the edge detection problem in a given block is also analytic. This algorithm can be performed very fast for large database applications with no need for special hardware. (C) 2003 Elsevier B.V. All rights reserved.
C1 Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung 824, Taiwan.
C3 National Kaohsiung University of Science & Technology
RP Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, 1 Univ Rd, Kaohsiung 824, Taiwan.
EM csc@ccms.nkfust.edu.tw
CR CHENG SC, 1994, PATTERN RECOGN, V27, P1439, DOI 10.1016/0031-3203(94)90123-6
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Faloutsos C, 1994, J INTELLIGENT SYSTEM, V1, P95
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   HUANG J, 1997, IEEE COMP SOC C COMP, P744, DOI DOI 10.1109/CVPR.1997.609412
   Iqbal Q, 2002, PATTERN RECOGN, V35, P1463, DOI 10.1016/S0031-3203(01)00139-X
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   JAIN K, 1991, FUNDAMENTALS DIGITAL
   LEE HC, 1991, IEEE T SIGNAL PROCES, V39, P1181, DOI 10.1109/78.80971
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mehtre BM, 1998, INFORM PROCESS MANAG, V34, P109, DOI 10.1016/S0306-4573(97)00049-6
   METHROTRA R, 1995, IEEE COMPUT, V28, P57
   Pei SC, 1999, IEEE T CIRC SYST VID, V9, P501, DOI 10.1109/76.754779
   Pei SC, 1999, IEEE T IMAGE PROCESS, V8, P614, DOI 10.1109/83.760310
   Pentland RP, 1994, SPIE C STOR RETR IM, P33
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502
   Trahanias PE, 1996, IEEE T SYST MAN CY B, V26, P135, DOI 10.1109/3477.484445
   TSAI WH, 1984, MOMENT PRESERVING TH, P377
   Wan X, 1998, IEEE T CIRC SYST VID, V8, P628, DOI 10.1109/76.718509
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang Z, 2000, IEE P-VIS IMAGE SIGN, V147, P9, DOI 10.1049/ip-vis:20000100
NR 24
TC 17
Z9 20
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2003
VL 21
IS 9
BP 809
EP 826
DI 10.1016/S0262-8856(03)00095-7
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 711QX
UT WOS:000184753500005
DA 2024-07-18
ER

PT J
AU Chen, YM
   Xu, JH
   An, ZL
   Zhuang, FZ
AF Chen, Yanming
   Xu, Jiahao
   An, Zhulin
   Zhuang, Fuzhen
TI Multi-scale conditional reconstruction generative adversarial network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Generative adversarial network; Unsupervised generation; Multi-scale
   instance; Reconstructed losses
AB Generative adversarial network has become the factual standard for high-quality image synthesis. However, modeling the distribution of complex datasets (e.g. ImageNet and COCO-Stuff) remains challenging in unsupervised approaches. This is partly due to the imbalance between the generator and the discriminator during training, the discriminator easily defeats the generator because of special views. In this paper, we propose a model called multi-scale conditional reconstruction GAN (MS-GAN). The core concept of MS-GAN is to model the local density implicitly using different scales of instance conditions. Instance conditions are extracted from the target images via a self-supervised learning model. In addition, we alignment the semantic features of the observed instances by adding an additional reconstruction loss to the generator. Our MS-GAN can aggregate instance features at different scales and maximize semantic features. This allows the generator to learn additional comparative knowledge from instance features, leading to a better feature representation, thus improving the performance of the generation task. Experimental results on the ImageNet dataset and the COCO-Stuff dataset show that our method matches or exceeds the original performance in both FID and IS scores compared to the ICGAN framework. Additionally, our precision score on the ImageNet dataset improved from 74.2% to 79.9%.
C1 [Chen, Yanming; Xu, Jiahao] Anhui Univ, Sch Compute Sci & Technol, Hefei, Peoples R China.
   [An, Zhulin] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Zhuang, Fuzhen] Beihang Univ, Inst Artificial Intelligence, Beijing, Peoples R China.
C3 Anhui University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Beihang University
RP An, ZL (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
EM anzhulin@ict.ac.cn
RI Chen, Yanming/AAA-6180-2022
OI Chen, Yanming/0000-0002-2747-6637
FU National Science Foundation of China (NSFC) [62262067]; Key Natural
   Science Foundation of Education Department of Anhui [KJ2021A0046]
FX This work is supported by the National Science Foundation of China
   (NSFC) under Grant 62262067, the Key Natural Science Foundation of
   Education Department of Anhui (KJ2021A0046) .
CR Al-Dujaili Abdullah, 2018, AAAI
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Armandpour M, 2021, PROC CVPR IEEE, P5095, DOI 10.1109/CVPR46437.2021.00506
   Berthelot D, 2017, Arxiv, DOI arXiv:1703.10717
   Brock A., 2018, INT C LEARN REPR
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Casanova A., 2021, ADV NEUR IN, V34, p27 517
   Casanova Arantxa, 2021, ICLR
   Chen SM, 2021, IEEE T EVOLUT COMPUT, V25, P986, DOI 10.1109/TEVC.2021.3068842
   Costa V, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P374, DOI 10.1145/3321707.3321746
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DeVries Terrance, 2020, Advances in Neural Information Processing Systems, V33, P13285
   Donahue Jeff, 2019, NIPS, V32
   Eghbal-Zadeh H, 2019, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2019.00597
   Flores D, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P367, DOI 10.1145/3512290.3528742
   Gao CY, 2020, PROC CVPR IEEE, P5173, DOI 10.1109/CVPR42600.2020.00522
   Ghosh A, 2018, PROC CVPR IEEE, P8513, DOI 10.1109/CVPR.2018.00888
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hoang Quan, 2018, INT C LEARN REPR
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huang ZL, 2022, IEEE T PATTERN ANAL, V44, P550, DOI 10.1109/TPAMI.2021.3062772
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Karnewar Animesh, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7796, DOI 10.1109/CVPR42600.2020.00782
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kynkäänniemi T, 2019, ADV NEUR IN, V32
   Grinblat GL, 2018, Arxiv, DOI arXiv:1709.07359
   Lehtinen J., 2020, Advances in Neural Information Processing Systems (NeurIPS), V33, P12104
   Li Sizhe, 2022, ICLR
   Li TH, 2023, PROC CVPR IEEE, P2142, DOI 10.1109/CVPR52729.2023.00213
   Liu Haozhe, 2023, CVPR, P16219
   Liu Steven, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14274, DOI 10.1109/CVPR42600.2020.01429
   Lu YZ, 2022, COMPUT ELECTRON AGR, V200, DOI 10.1016/j.compag.2022.107208
   Lucas T, 2018, PR MACH LEARN RES, V80
   Lucic M, 2019, PR MACH LEARN RES, V97
   Mangla Puneet, 2022, WACV, P451
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Miyato T, 2018, INT C LEARN REPR
   Niemeyer M, 2021, PROC CVPR IEEE, P11448, DOI 10.1109/CVPR46437.2021.01129
   Noroozi Mehdi, 2020, arXiv, P1
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Radford A., 2015, ARXIV
   Rangwani H, 2023, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR52729.2023.00580
   Sage A, 2018, PROC CVPR IEEE, P5879, DOI 10.1109/CVPR.2018.00616
   Salimans T, 2016, ADV NEUR IN, V29
   Schonfeld E., 2020, 2020 IEEECVF C COMPU, P8204, DOI 10.1109/CVPR42600.2020.00823
   Sun W, 2022, IEEE T PATTERN ANAL, V44, P5070, DOI 10.1109/TPAMI.2021.3078577
   Sylvain T, 2021, AAAI CONF ARTIF INTE, V35, P2647
   Tang H., 2020, P IEEE CVPR, P7870
   Touvron H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P854, DOI 10.1109/ICCV48922.2021.00091
   Wang GR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9485, DOI 10.1109/ICCV48922.2021.00937
   Wang Jianyuan, 2022, P IEEECVF C COMPUTER, P11285
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Zhao B, 2019, PROC CVPR IEEE, P8576, DOI 10.1109/CVPR.2019.00878
   Zhao Y., 2020, ICML, V119, P11376
NR 60
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104885
DI 10.1016/j.imavis.2023.104885
EA DEC 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FI5V0
UT WOS:001145154200001
DA 2024-07-18
ER

PT J
AU Du, HP
   Nguyen, AD
   Nguyen, DT
   Nguyen, HN
AF Du, Hanh P.
   Nguyen, Anh D.
   Nguyen, Dat T.
   Nguyen, Hoa N.
TI μPEWFace: Parallel ensemble of weighted deep convolutional neural
   networks with novel loss functions for face-based authentication
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Parallel ensemble learning; Deep learning; Deep convolutional neural
   network; Adaptive margin loss function; Face -based authentication
AB Training Deep Convolutional Neural Networks (DCNN) with large-scale face images takes a significant amount of processing resources and the tuning/optimization time cost for face-based authentication. It must continue to improve its accuracy and speed during the matching phase. In this study, we propose a method, mu PEWFace, that inherits not only the benefits of recent DCNNs with adaptive loss functions, such as MagFace, ElasticFace, and AdaFace, for boosting accuracy but also the means to reduce matching time. Consequently, our method expands on the weighted voting mechanism that leverages suboptimal trained models to improve the discriminative capabilities of face-based authentication, as opposed to searching for the best optimal model. In order to boost the efficiency of face-based authentication, we also propose performing the matching phase for each model in parallel. To demonstrate the speed and accuracy of our method, we conduct exhaustive experiments using a variety of well-known benchmarks, including LFW, CFP-FP, AgeDB-30, CALFW, CPLFW, and IJB-B. The experimental findings demonstrate that the proposed method for face-based authentication achieves state-of-the-art results and exhibits remarkable performance.(c) 2023 Published by Elsevier Ltd.
C1 [Du, Hanh P.; Nguyen, Anh D.; Nguyen, Dat T.; Nguyen, Hoa N.] VNU Univ Engn & Technol, Vietnam Natl Univ, Dept Informat Syst, Hanoi, Vietnam.
C3 Vietnam National University Hanoi
RP Nguyen, HN (corresponding author), VNU Univ Engn & Technol, Vietnam Natl Univ, Dept Informat Syst, Hanoi, Vietnam.
EM hanhdp@vnu.edu.vn; ducanh.ng@vnu.edu.vn; 19020126@vnu.edu.vn;
   hoa.nguyen@vnu.edu.vn
RI NGUYEN, Hoa N./AAD-9622-2019
OI NGUYEN, Hoa N./0000-0002-2565-281X; DU, Hanh/0000-0002-8993-1164;
   Nguyen, Duc-Anh/0000-0002-5097-2401
CR Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701
   Aoxue Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12573, DOI 10.1109/CVPR42600.2020.01259
   Boutros F, 2022, IEEE COMPUT SOC CONF, P1577, DOI 10.1109/CVPRW56347.2022.00164
   Chang S, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892065
   Daoudi S, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED ELECTRICAL ENGINEERING (ICAEE), DOI 10.1109/icaee47123.2019.9014783
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Drotár P, 2019, INFORM SCIENCES, V480, P365, DOI 10.1016/j.ins.2018.12.033
   Duan F, 2022, IEEE T NEUR NET LEAR, V33, P2070, DOI 10.1109/TNNLS.2021.3105595
   Gao Z, 2021, IEEE T AUTOM SCI ENG, V18, P19, DOI 10.1109/TASE.2019.2955397
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Insoo Kim, 2021, Computer Vision - ACCV 2020 15th Asian Conference on Computer Vision. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12626), P358, DOI 10.1007/978-3-030-69541-5_22
   Jiao JC, 2021, MULTIMED TOOLS APPL, V80, P25741, DOI 10.1007/s11042-021-10865-5
   Kim M, 2022, PROC CVPR IEEE, P18729, DOI 10.1109/CVPR52688.2022.01819
   Le H, 2022, INT J WEB GRID SERV, V18, P361, DOI 10.1504/IJWGS.2022.126117
   Le H, 2023, IEEE T INTELL TRANSP, V24, P2630, DOI 10.1109/TITS.2021.3122979
   Lei J., 2021, 2021 IEEE 19 INT C S, P1116, DOI [10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00173, DOI 10.1109/HPCC-DSS-SMARTCITY-DEPENDSYS53884.2021.00173]
   Liu BY, 2019, IEEE I CONF COMP VIS, P10051, DOI 10.1109/ICCV.2019.01015
   Liu H, 2019, PROC CVPR IEEE, P11939, DOI 10.1109/CVPR.2019.01222
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Liu WY, 2016, PR MACH LEARN RES, V48
   Liu ZH, 2021, IEEE IMAGE PROC, P2878, DOI 10.1109/ICIP42928.2021.9506428
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Nguyen A. D., 2022, 11 INT S INF COMM TE, P231, DOI DOI 10.1145/3568562.3568638
   Nguyen AD, 2022, LECT NOTES COMPUT SC, V13636, P101, DOI 10.1007/978-3-031-21756-2_8
   Nickolls J, 2010, IEEE MICRO, V30, P56, DOI 10.1109/MM.2010.41
   Oinar C, 2023, Arxiv, DOI [arXiv:2201.07394, 10.48550/arXiv.2201.07394, DOI 10.48550/ARXIV.2201.07394]
   Phuong-Hanh Du, 2018, Transactions on Computational Collective Intelligence XXIX. LNCS 10840, P182, DOI 10.1007/978-3-319-90287-6_10
   Ranjan R, 2017, Arxiv, DOI arXiv:1703.09507
   Sengupta S, 2016, IEEE WINT CONF APPL
   Shekhar S, 2021, 2021 IEEE ASIA-PACIFIC CONFERENCE ON COMPUTER SCIENCE AND DATA ENGINEERING (CSDE), DOI 10.1109/CSDE53843.2021.9718485
   Szmurlo R, 2021, 22TH INTERNATIONAL CONFERENCE COMPUTATIONAL PROBLEMS OF ELECTRICAL ENGINEERING (CPEE 2021), DOI 10.1109/CPEE54040.2021.9585253
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang XP, 2022, IEEE T AUTOM SCI ENG, V19, P2397, DOI 10.1109/TASE.2021.3083670
   Wang XB, 2022, IEEE T IMAGE PROCESS, V31, P2337, DOI 10.1109/TIP.2022.3154293
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87
   Wu GH, 2022, IEEE T EVOLUT COMPUT, V26, P646, DOI 10.1109/TEVC.2021.3110130
   Wu S., 2022, arXiv, DOI [10.48550/ARXIV.2210.04567, DOI 10.48550/ARXIV.2210.04567]
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P262, DOI 10.1109/TIP.2006.884939
   Yi D, 2014, Arxiv, DOI arXiv:1411.7923
   Zhang X, 2019, PROC CVPR IEEE, P10815, DOI 10.1109/CVPR.2019.01108
   Zhao K, 2019, PROC CVPR IEEE, P1136, DOI 10.1109/CVPR.2019.00123
   Zheng T., 2018, Tech. Rep 5, P6
   Zheng TY, 2017, Arxiv, DOI arXiv:1708.08197
   Zhong YY, 2021, IEEE T IMAGE PROCESS, V30, P2587, DOI 10.1109/TIP.2020.3048632
NR 48
TC 1
Z9 1
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104819
DI 10.1016/j.imavis.2023.104819
EA SEP 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA U6RS1
UT WOS:001086062300001
DA 2024-07-18
ER

PT J
AU Parashar, A
   Parashar, A
   Abate, AF
   Shekhawat, RS
   Rida, I
AF Parashar, Anubha
   Parashar, Apoorva
   Abate, Andrea F.
   Shekhawat, Rajveer Singh
   Rida, Imad
TI Real-time gait biometrics for surveillance applications: A review
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Gait recognition; Biometrics; Deep learning; Vision-based; Real-time
   surveillance
ID RECOGNITION; MOTION
AB Deep learning (DL) pipelines have evolved for over a decade now and are efficient at solving many challenging problems of image and signal processing applications. Designing deep learning pipelines for a particular application requires a good understanding of deep learning and various intermediate layers available. To develop a DL pipeline, one uses available dataset(s) suitable for an application, and the pipeline is refined by iterating over intermediate layers. A large amount of time and extensive thinking goes into these selections and validating the performance of each configuration. Thus, it is hard to choose the correct and robust DL pipeline that performs well on all relevant datasets. This review aims to aid researchers in understanding different gait sensing technologies and provide foundational knowledge of the deep learning concepts for faster solutions for a given problem. Gait recognition is more recent since it hasn't yet been used in a real-world situation. This article provides a comprehensive overview of gait biometrics suited to real-time surveillance applications. All the important parameters of deep learning pipelines are explained, along with their selection and implication for a given problem. Authors have reviewed important research articles recently on deep learning models and how these perform across different application datasets. The benefits and drawbacks of the approaches are elucidated to help arrive at the optimized pipeline derived from a fusion of available pipelines to achieve faster but accurate results for a given problem.
C1 [Parashar, Anubha] Manipal Univ Jaipur, Sch Comp & Informat Technol, Jaipur, Rajasthan, India.
   [Parashar, Apoorva] Mahindra Integrated Business Solut, Emerging Technol, Mumbai, India.
   [Abate, Andrea F.] Univ Salerno, Via Giovanni Paolo II 132, I-84084 Salerno, Italy.
   [Shekhawat, Rajveer Singh] Manipal Univ Jaipur, Jaipur, Rajasthan, India.
   [Rida, Imad] Univ Technol Compiegne, BMBI Lab, F-60200 Compiegne, France.
C3 Manipal University Jaipur; University of Salerno; Manipal University
   Jaipur; Universite de Technologie de Compiegne
RP Parashar, A (corresponding author), Manipal Univ Jaipur, Sch Comp & Informat Technol, Jaipur, Rajasthan, India.; Rida, I (corresponding author), Univ Technol Compiegne, BMBI Lab, F-60200 Compiegne, France.
EM anubhaparashar1025@gmail.com; abate@unisa.it
RI Rida, Imad/AAA-5044-2022; Parashar, Anubha/L-7545-2017
OI Rida, Imad/0000-0003-2789-5070; 
CR Abdulatif S., 2018, arXiv
   Abdulatif S, 2018, IEEE RAD CONF, P1043, DOI 10.1109/RADAR.2018.8378705
   Alharthi AS, 2019, IEEE SENS J, V19, P9575, DOI 10.1109/JSEN.2019.2928777
   An WZ, 2018, LECT NOTES COMPUT SC, V10996, P137, DOI 10.1007/978-3-319-97909-0_15
   Chen L, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3381012
   Connor P, 2018, COMPUT VIS IMAGE UND, V167, P1, DOI 10.1016/j.cviu.2018.01.007
   Costilla-Reyes O, 2019, IEEE T PATTERN ANAL, V41, P285, DOI 10.1109/TPAMI.2018.2799847
   Davarzani S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050796
   Dehzangi O, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122735
   Delgado-Escaño R, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105265
   Delgado-Escaño R, 2019, IEEE ACCESS, V7, P1897, DOI 10.1109/ACCESS.2018.2886899
   Fernandez-Lopez P, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19184054
   Gadaleta M, 2016, 2016 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP)
   Gadaleta M, 2018, PATTERN RECOGN, V74, P25, DOI 10.1016/j.patcog.2017.09.005
   Gálai B, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 6, P426, DOI 10.5220/0006124404260432
   Gao J, 2019, IEEE ACCESS, V7, P163180, DOI 10.1109/ACCESS.2019.2950254
   Giorgi Giacomo, 2017, Computer Safety, Reliability and Security, SAFECOMP 2017: Workshops ASSURE, DECSoS, SASSUR, TELERISE and TIPS. Proceedings: LNCS 10489, P384, DOI 10.1007/978-3-319-66284-8_32
   Giorgi Giacomo., 2018, IFIP International Conference on ICT Systems Security and Privacy Protection, P62, DOI DOI 10.1007/978-3-319-99828-2_5
   Gurbuz SZ, 2019, IEEE SIGNAL PROC MAG, V36, P16, DOI 10.1109/MSP.2018.2890128
   Hannink J, 2017, IEEE J BIOMED HEALTH, V21, P85, DOI 10.1109/JBHI.2016.2636456
   Hasan M.M., 2020, Int. J. Comput. Sci. Inf. Secur., V18
   Jun K, 2020, IEEE ACCESS, V8, P19196, DOI 10.1109/ACCESS.2020.2967845
   Jung D, 2019, IEEE ENG MED BIO, P3624, DOI [10.1109/EMBC.2019.8857872, 10.1109/embc.2019.8857872]
   Nguyen KT, 2017, LECT NOTES COMPUT SC, V10646, P197, DOI 10.1007/978-3-319-70004-5_14
   Kim D, 2019, IEEE ROBOT AUTOM LET, V4, P2501, DOI 10.1109/LRA.2019.2907431
   Kitic S, 2017, IEEE GLOB CONF SIG, P843, DOI 10.1109/GlobalSIP.2017.8309079
   Kumar P, 2019, IEEE T FUZZY SYST, V27, P956, DOI 10.1109/TFUZZ.2018.2870590
   Leal Tavares Henrique, 2019, 2019 XV Workshop de Visao Computacional (WVC) [2019 XV Computer Vision Workshop (WVC)]. Proceedings, P78, DOI 10.1109/WVC.2019.8876921
   Lee MC, 2019, LECT NOTES ARTIF INT, V11888, P389, DOI 10.1007/978-3-030-35231-8_28
   Li N, 2020, ARXIV
   Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069
   Limcharoen P, 2020, IEEE T INF FOREN SEC, V15, P3430, DOI 10.1109/TIFS.2020.2985535
   Liu S., 2001, IT Professional, V3, P27, DOI 10.1109/6294.899930
   Luo J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061646
   Luo J, 2020, IEEE ACCESS, V8, P32485, DOI 10.1109/ACCESS.2020.2973898
   Mao MG, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), DOI 10.1109/ijcb48548.2020.9304916
   Masupha L, 2015, 2015 International Conference on Computing, Communication and Security (ICCCS)
   Meng Z, 2020, AAAI CONF ARTIF INTE, V34, P849
   Parashar A, 2022, NEUROCOMPUTING
   Parashar A, 2023, ARTIF INTELL REV, V56, P8889, DOI 10.1007/s10462-022-10365-4
   Prabhu V., 2017, CVPR 2017 CV COPS Work, V1
   Prakash C, 2018, ARTIF INTELL REV, V49, P1, DOI 10.1007/s10462-016-9514-6
   Rida I, 2019, Arxiv, DOI arXiv:1904.01620
   Rida I, 2019, IET BIOMETRICS, V8, P14, DOI 10.1049/iet-bmt.2018.5063
   Rida I, 2017, SIGNAL PROC SEC TEC, P141, DOI 10.1007/978-3-319-47301-7_6
   Rida I, 2015, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2015.7362559
   Rida I, 2016, IEEE SIGNAL PROC LET, V23, P154, DOI 10.1109/LSP.2015.2507200
   Rida I, 2016, SIGNAL IMAGE VIDEO P, V10, P463, DOI 10.1007/s11760-015-0766-4
   Rida I, 2014, INT C MICROELECTRON, P40, DOI 10.1109/ICM.2014.7071801
   Rida Imad, 2015, IMAGE ANAL PROCESSIN
   Rida Imad, 2016, 2016 39 INT C TEL SI
   Saber S., 2021, IJCI. Int. J. Comput. Inf., V8, DOI 10.21608/ijci.2021.207824
   Sadeghzadehyazdi N., 2019, GlidarCo: gait recognition by 3D skeleton estimation and biometric feature correction of flash lidar data, P1
   Sheng WJ, 2020, NEUROCOMPUTING, V395, P86, DOI 10.1016/j.neucom.2020.01.098
   Singh JP, 2021, ARCH COMPUT METHOD E, V28, P107, DOI 10.1007/s11831-019-09375-3
   Sokolova A, 2019, IET BIOMETRICS, V8, P134, DOI 10.1049/iet-bmt.2018.5046
   Terrier P, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030774
   Topham Luke K., 2021, ACM COMPUT SURV
   Tran L, 2020, IEEE ACCESS, V8, P12364, DOI 10.1109/ACCESS.2020.2966142
   Turner A, 2019, IEEE T BIO-MED ENG, V66, P3136, DOI 10.1109/TBME.2019.2900863
   Wang YX, 2019, PROC CVPR IEEE, P6351, DOI 10.1109/CVPR.2019.00652
   Yuan W, 2018, COMM COM INF SC, V946, P119, DOI 10.1007/978-981-13-2853-4_10
   Zeng W, 2018, CHIN CONT DECIS CONF, P6280, DOI 10.1109/CCDC.2018.8408232
   Zhang X, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3393619
   Zhang ZY, 2019, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR.2019.00484
   Zhao PJ, 2019, IEEE INT CONF DISTR, P33, DOI 10.1109/DCOSS.2019.00028
   Zhao YJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030478
   Zhu Q, 2019, NEUROCOMPUTING, V355, P143, DOI 10.1016/j.neucom.2019.04.066
   Zou Q, 2020, IEEE T INF FOREN SEC, V15, P3197, DOI 10.1109/TIFS.2020.2985628
NR 69
TC 7
Z9 7
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104784
DI 10.1016/j.imavis.2023.104784
EA AUG 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA R8IP0
UT WOS:001066740900001
DA 2024-07-18
ER

PT J
AU Pastore, VP
   Ciranni, M
   Bianco, S
   Fung, JC
   Murino, V
   Odone, F
AF Pastore, Vito Paolo
   Ciranni, Massimiliano
   Bianco, Simone
   Fung, Jennifer Carol
   Murino, Vittorio
   Odone, Francesca
TI Efficient unsupervised learning of biological images with compressed
   deep features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised learning; Transfer learning; Biological images analysis;
   Pre -trained features; Model ensembling
ID CLASSIFICATION; IDENTIFICATION
AB Machine learning has significantly impacted the analysis of biological images and is now an important part of many biological data analysis pipelines. A variety of biological and biomedical domain-related tasks is gaining benefit from image analysis and pattern recognition tools developed currently. Applications include diagnostic histopathology, environmental monitoring, synthetic biology, genomics, and proteomics. Particularly in the last decade, several deep learning and advanced computer vision methods such as convolutional neural networks (CNNs), typically trained in a supervised fashion, have started to be largely employed in biological image classification. Moreover, the advancement of automatic acquisition systems has been generating a massive amount of biological data, which requires to be analyzed by domain experts. However, the cost of manual annotation of such data has become a bottleneck, impairing the application of supervised machine learning algorithms. Biological images generally have an intrinsic high variability, whose identity is sometimes hard to assign and strongly dependent on the annotator's expertise. In this context, a limited number of annotation-free (i.e., unsupervised) learning solutions have been proposed, typically based on hand-crafted features, specifically tailored for a certain biological domain. Nonetheless, a successful unsupervised learning approach must be accurate, and sufficiently robust to deal with different biological domains. This paper aims at providing a viable solution to these issues, proposing an unsupervised learning algorithm based on compressed deep features for image classification. We exploit features extracted from ImageNet pre-trained transformers and CNNs, further compressed with a customized & beta;-Variational AutoEncoder (& beta;-VAE), that we call reconstruction VAE (R-VAE). We test our algorithm on biological images coming from diverse domains characterized by high variability in shape and texture information and acquired with widely differing imaging platforms. Considered image datasets range from multi-cellular organisms (plankton, coral) to sub-cellular organelles (budding yeast vacuoles, human cells' nuclei, etc.). Our results show that the compressed deep features extracted from different pre-trained vision models establish new unsupervised learning state-of-the-art performances for the investigated datasets.
C1 [Pastore, Vito Paolo; Ciranni, Massimiliano; Odone, Francesca] Univ Genoa, MaLGa, Genoa, Italy.
   [Pastore, Vito Paolo; Ciranni, Massimiliano; Murino, Vittorio; Odone, Francesca] Univ Genoa, DIBRIS, Genoa, Italy.
   [Murino, Vittorio] Univ Verona, Verona, Italy.
   [Fung, Jennifer Carol] Univ Calif San Francisco, Dept Obstet Gynecol & Reprod Sci, San Francisco, CA USA.
   [Bianco, Simone] Altos Labs, Redwood City, CA USA.
C3 University of Genoa; University of Genoa; University of Verona;
   University of California System; University of California San Francisco
RP Pastore, VP (corresponding author), Univ Genoa, MaLGa, Genoa, Italy.
EM Vito.Paolo.Pastore@unige.it
RI Murino, Vittorio/A-5570-2011
OI Ciranni, Massimiliano/0009-0001-3728-9640; PASTORE, VITO
   PAOLO/0000-0002-5827-5571
FU NSF [DBI-1548297, DM 1062/2021]
FX JCF was supported by NSF Grant No. DBI-1548297. VPP was supported by FSE
   REACT-EU-PON 2014-2020, DM 1062/2021.
CR Alfano PD, 2022, INT C PATT RECOG, P1314, DOI 10.1109/ICPR56361.2022.9956360
   Alfano PD, 2023, Arxiv, DOI arXiv:2209.07932
   Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254
   Blaschko MB, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P79
   Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen X, 2005, J BIOMED BIOTECHNOL, P87, DOI 10.1155/JBB.2005.87
   Ciompi F, 2015, MED IMAGE ANAL, V26, P195, DOI 10.1016/j.media.2015.08.001
   d'Ascoli S, 2021, PR MACH LEARN RES, V139, DOI 10.1088/1742-5468/ac9830
   Dai J., 2016, OCEANS 2016-Shanghai, P1, DOI 10.1109/OCEANSAP.2016.7485680
   Dana K., 1997, Columbia-utrecht reflectance and texture database"
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Elsken T, 2019, J MACH LEARN RES, V20
   Gómez-Ríos A, 2019, EXPERT SYST APPL, V118, P315, DOI 10.1016/j.eswa.2018.10.010
   Gorsky G, 2010, J PLANKTON RES, V32, P285, DOI 10.1093/plankt/fbp124
   Grosjean P, 2004, ICES J MAR SCI, V61, P518, DOI 10.1016/j.icesjms.2004.03.012
   Hamilton NA, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-110
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Higgins I., 2017, P 5 INT C LEARN REPR, V2, P1
   Hornik K, 2012, J STAT SOFTW, V50, P1
   Hu B, 2019, IEEE J BIOMED HEALTH, V23, P1316, DOI 10.1109/JBHI.2018.2852639
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang K, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P1139
   Hughes AJ, 2018, NAT METHODS, V15, P587, DOI 10.1038/s41592-018-0069-0
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Kyathanahally SP, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21910-0
   Libbrecht MW, 2015, NAT REV GENET, V16, P321, DOI 10.1038/nrg3920
   Liu D, 2016, COMPUT BIOL MED, V72, P185, DOI 10.1016/j.compbiomed.2016.03.010
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZC, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104523
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Lumini A., 2020, Applied Computing & Informatics, V19, P265, DOI [DOI 10.1016/J.ACI.2019.11.004, 10.1016/j.aci.2019.11.004]
   Lumini A, 2023, APPL COMPUT INFORM, V19, P265, DOI 10.1016/j.aci.2019.11.004
   Lumini A, 2019, ECOL INFORM, V51, P33, DOI 10.1016/j.ecoinf.2019.02.007
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Moen E, 2019, NAT METHODS, V16, P1233, DOI 10.1038/s41592-019-0403-1
   Nguyen LD, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351550
   Olson RJ, 2007, LIMNOL OCEANOGR-METH, V5, P195, DOI 10.4319/lom.2007.5.195
   Orenstein EC, 2017, IEEE WINT CONF APPL, P1082, DOI 10.1109/WACV.2017.125
   Ouyang P, 2016, 2016 IEEE INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P132, DOI 10.1109/ITNEC.2016.7560334
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pastore VP, 2022, bioRxiv, DOI [10.1101/2022.03.17.484826, 10.1101/2022.03.17.484826, DOI 10.1101/2022.03.17.484826]
   Pastore VP, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68662-3
   Pastore VP, 2019, PROC SPIE, V10881, DOI 10.1117/12.2511065
   Pastore VP, 2022, LECT NOTES COMPUT SC, V13232, P599, DOI 10.1007/978-3-031-06430-2_50
   Pastore Vito Paolo, 2022, Scientific Reports, V12, P1
   Paszke A, 2019, ADV NEUR IN, V32
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Radivojevic T, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18008-4
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salvesen E, 2022, PROC SPIE, V12084, DOI 10.1117/12.2622489
   Saraswat M, 2014, MICRON, V65, P20, DOI 10.1016/j.micron.2014.04.001
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]
   Schröder SM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113060
   Shamir L, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000974
   Shihavuddin ASM, 2013, REMOTE SENS-BASEL, V5, P1809, DOI 10.3390/rs5041809
   Shihavuddin Asm, 2017, Mendeley Data, V2, DOI 10.17632/86y667257h.2
   Sosik HM, 2007, LIMNOL OCEANOGR-METH, V5, P204, DOI 10.4319/lom.2007.5.204
   T. maintainers and contributors, 2016, TORCHVISION PYTORCHS
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   van Timmeren JE, 2020, INSIGHTS IMAGING, V11, DOI 10.1186/s13244-020-00887-2
   Wightman Ross, 2023, Zenodo
   Xing FY, 2018, IEEE T NEUR NET LEAR, V29, P4550, DOI 10.1109/TNNLS.2017.2766168
   Yao K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50010-9
   Zhao F, 2010, NEUROCOMPUTING, V73, P1853, DOI 10.1016/j.neucom.2009.12.033
   Zheng HY, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1954-8
   Zhuang FZ, 2020, Arxiv, DOI [arXiv:1911.02685, DOI 10.1109/JPROC.2020.3004555]
   Zoph B, 2017, Arxiv, DOI [arXiv:1611.01578, DOI 10.48550/ARXIV.1611.01578]
NR 75
TC 3
Z9 3
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104764
DI 10.1016/j.imavis.2023.104764
EA JUL 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P2IP0
UT WOS:001048930300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Xu, BL
AF Xu, Bolei
TI Region selection for occluded person re-identification via policy
   gradient
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Occlusion; Policy gradient
AB Person re-identification (re-id) has attracted lots of attention in the past few years. However, most of work in this area focus on the re-identification of the holistic pedestrian images. In the real application scenarios, the task of re-identification is usually influenced by the occlusion problems. Most of previous work tackle occlusion problem through pose estimation, human parsing or manually labelling occlusion objects. Such reliance on additional an- notation information severely limits the generalization ability on practical usage. To address this problem, we propose a novel region selection learning strategy based on the policy gradient to remove irrelevant parts with- out using any extra information outside dataset. A transformer-based feature extractor is also constructed to learn discriminate features with self-attention mechanism. We evaluate the performance of the proposed method on three occluded re-identification datasets. The experiments show that we achieve 87%, 85.2% and 68.3% in Rank-1 accuracy on Occluded-REID, Partial-REID and Occluded-Duke datasets respectively.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Xu, Bolei] Shenzhen Univ, Coll Informat Engn, Shenzhen, Peoples R China.
C3 Shenzhen University
RP Xu, BL (corresponding author), Shenzhen Univ, Coll Informat Engn, Shenzhen, Peoples R China.
EM xubolei@gmail.com
RI Xu, Bolei/O-8493-2016
FU National Natural Science Founda-tion of China [61902253]
FX This work was supported by the National Natural Science Founda-tion of
   China under Grants No. 61902253.
CR Chen PX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11813, DOI 10.1109/ICCV48922.2021.01162
   Cho Y., 2022, CVPR, P7308
   Dai ZZ, 2021, Arxiv, DOI [arXiv:2103.11568, 10.48550/arXiv.2103.11568]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Huang HJ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102789
   Kaiwei Zeng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13654, DOI 10.1109/CVPR42600.2020.01367
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Lingxiao He, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P357, DOI 10.1007/978-3-030-58604-1_22
   Liu J., 2022, PROC IEEECVF C COMPU, P19366
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Qiu G., 2016, ASIAN C COMPUTER VIS, P301
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang YC, 2018, PROC CVPR IEEE, P1470, DOI 10.1109/CVPR.2018.00159
   Wang Z., 2022, P IEEE CVF C COMP VI, P4754
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu GL, 2020, AAAI CONF ARTIF INTE, V34, P12362
   Yang Z., 2022, P IEEECVF C COMPUTER
   Zhang X., 2022, P IEEE CVF C COMP VI, P7369
   Zhao CR, 2020, IEEE T MULTIMEDIA, V22, P3180, DOI 10.1109/TMM.2020.2972125
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P72, DOI 10.1007/978-3-030-58621-8_5
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 36
TC 2
Z9 2
U1 4
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2023
VL 132
AR 104648
DI 10.1016/j.imavis.2023.104648
EA MAR 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 9Y3TZ
UT WOS:000950383900001
DA 2024-07-18
ER

PT J
AU Patil, C
   Abhyankar, A
AF Patil, Charulata
   Abhyankar, Aditya
TI Decoupled contributed attribute-object composition detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Compositional zero shot learning; Composite representation learning;
   Attribute detection; Computer vision
AB Object recognition is quite a well known task in computer vision. Objects are often associated with attributes. It becomes further challenging to correctly classify the object and associated attribute as a composition. Most of the methods for attribute-object pair detection involve discriminating approach that detects the attribute and object separately. Such approaches fail to consider some important facts regarding the composition viz. appearance of attributes is dependent on object and that of an object changes with the attribute. Making use of this interdepen-dence, we propose a model, ContribNet to learn attribute-object composition representation. The model uses the semantic linguistic features to learn robust visual composition while highlighting the importance of component features in identifying its counterpart of the composition. The factors responsible for model performance are also discussed.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Patil, Charulata; Abhyankar, Aditya] Savitribai Phule Pune Univ, Pune, India.
C3 Savitribai Phule Pune University
RP Patil, C (corresponding author), Savitribai Phule Pune Univ, Pune, India.
EM cpatil@unipune.ac.in; aditya.abhyankar@unipune.ac.in
CR Atzmon Y., 2020, ADV NEUR IN
   Chen S., 2022, IEEE C COMPUTER VISI
   Chen S., 2022, P 36 AAAI C ART INT, P330
   Chen SJ, 2023, INT J ENVIRON HEAL R, V33, P1254, DOI 10.1080/09603123.2022.2083090
   Huynh D, 2020, PROC CVPR IEEE, P4482, DOI 10.1109/CVPR42600.2020.00454
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Hudson D.A., 2018, INT C LEARNING REPRE
   Isola P., 2015, IEEE C COMPUTER VISI
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li, 2020, IEEE C COMPUTER VISI
   Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142
   Liang K., 2015, INT C COMPUTER VISIO
   Mancini M., 2021, IEEE C COMPUTER VISI
   Misra I, 2017, PROC CVPR IEEE, P1160, DOI 10.1109/CVPR.2017.129
   Naeem MF, 2021, PROC CVPR IEEE, P953, DOI 10.1109/CVPR46437.2021.00101
   Nagarajan Tushar., 2018, EUROPEAN C COMPUTER
   Nan Z., 2019, RECOGNIZING UNSEEN A
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]
   Purushwalkam S, 2019, IEEE I CONF COMP VIS, P3592, DOI 10.1109/ICCV.2019.00369
   Wang X, 2019, IEEE C COMPUTER VISI, P0
   Wei K, 2019, IEEE I CONF COMP VIS, P3740, DOI 10.1109/ICCV.2019.00384
   Xian Y., 2018, IEEE C COMPUTER VISI
   Yang M., 2020, IEEE C COMPUTER VISI
   Yu A, 2017, IEEE I CONF COMP VIS, P5571, DOI 10.1109/ICCV.2017.594
   Zellers R., 2018, IEEE C COMPUTER VISI
NR 30
TC 0
Z9 0
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2023
VL 131
AR 104630
DI 10.1016/j.imavis.2023.104630
EA FEB 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 8T8TP
UT WOS:000929527600001
DA 2024-07-18
ER

PT J
AU Cheng, DQ
   Li, JH
   Kou, QQ
   Zhao, K
   Liu, RH
AF Cheng, Deqiang
   Li, Jiahan
   Kou, Qiqi
   Zhao, Kai
   Liu, Ruihang
TI H-net: Unsupervised domain adaptation person re-identification network
   based on hierarchy
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised domain adaptation; Person re-identification; Hierarchical;
   Hardest sample
ID SIMILARITY
AB Due to the high cost of manual labeling for supervised person re-identification (re-ID), unsupervised domain adaptation (UDA) person re-ID has been attracting the attention of many scholars. In this research, target domain datasets and source domain datasets are two indispensable datasets, and although there are many different pictures of the same person in the target domain, these pictures are precious to the network in different degrees. However, the existing UDA person re-ID algorithms does not treat different samples in the target domain differently, they just treat positive samples as indistinguishable samples. Not only that, although the triplet loss has been re-identified by unsupervised person re-ID, the noise of the hardest sample hasn't been carried out well. In this paper, a novel and robust network model named unsupervised domain adaptation hierarchical person re-identification network (H-Net) is proposed, which not only effectively reduces the impact of inaccurate identification of the hardest sample but also treats different positive samples differently by hierarchical feature collection. Numerous experimental results on Market-1501 and DukeMTMC-reID demonstrate that the proposed H-Net outperforms the existing methods and can significantly improve the accuracy of person re-ID.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Cheng, Deqiang; Li, Jiahan; Zhao, Kai; Liu, Ruihang] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
   [Kou, Qiqi] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Kou, QQ (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
EM kouqiqi@cumt.edu.cn
RI SUN, YANLING/JTT-9082-2023; Wu, Jiale/JQV-3750-2023; wang,
   jiajun/JRW-6032-2023; Yang, Tian/JFB-1008-2023; Cheng,
   Deqiang/HDO-0132-2022
FU National Natural Science Founda-tion of China [51774281]; Postgraduate
   Research & Prac-tice Innovation Program of Jiangsu Province
   [KYCX21_2245]
FX Aknowledgement This work was supported by the National Natural Science
   Founda-tion of China under Grants 51774281. This work was also supported
   by the Postgraduate Research & Prac-tice Innovation Program of Jiangsu
   Province (Grant KYCX21_2245)
CR [Anonymous], 2006, PROC IEEE COMPUT SOC
   Bak S, 2018, LECT NOTES COMPUT SC, V11217, P193, DOI 10.1007/978-3-030-01261-8_12
   Bousmalis K, 2016, ADV NEUR IN, V29
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Dong HS, 2018, NEUROCOMPUTING, V307, P25, DOI 10.1016/j.neucom.2018.04.013
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ge Y., 2020, ARXIV 200306650
   Ge Y., 2020, P NIPS, V33, P11309
   Ge Y., ARXIV PREPRINT ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Huang Y, 2019, IEEE I CONF COMP VIS, P9526, DOI 10.1109/ICCV.2019.00962
   Kou QQ, 2019, IEEE SIGNAL PROC LET, V26, P129, DOI 10.1109/LSP.2018.2881544
   Li JH, 2021, IEEE SIGNAL PROC LET, V28, P379, DOI 10.1109/LSP.2021.3055116
   Li YL, 2018, PROC CVPR IEEE, P5997, DOI 10.1109/CVPR.2018.00628
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin Shan, 2018, 2018 IEEE 36 VLSI TE
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu JW, 2019, PROC CVPR IEEE, P7195, DOI 10.1109/CVPR.2019.00737
   Liu Xiaobin, 2020, P 28 ACM INT C MULT, P547
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2905, DOI 10.1109/TMM.2020.2965491
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Song LC, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107173
   Sun WC, 2019, PROCEEDINGS OF THE 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND TECHNOLOGY APPLICATIONS (ICCTA 2019), P117, DOI 10.1145/3323933.3324091
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang Y., 2016, ARXIV161002984
   Wang Z, 2019, IEEE T MULTIMEDIA, V21, P2376, DOI 10.1109/TMM.2019.2898753
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Yang FX, 2020, IEEE T MULTIMEDIA, V22, P2444, DOI 10.1109/TMM.2019.2957928
   Yang Qize, 2019, CVPR
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Yuan Y, 2020, IEEE COMPUT SOC CONF, P1454, DOI 10.1109/CVPRW50498.2020.00185
   Zhu YX, 2020, NEUROCOMPUTING, V386, P97, DOI 10.1016/j.neucom.2019.12.100
   Zhang XY, 2019, IEEE I CONF COMP VIS, P8221, DOI 10.1109/ICCV.2019.00831
   Zhao ZW, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3491225
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zhong Z, 2017, ARXIV 170804896
   Zhong Z., 2018, PROC EUR C COMPUT VI, P1
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313
NR 54
TC 8
Z9 10
U1 3
U2 58
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104493
DI 10.1016/j.imavis.2022.104493
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800010
DA 2024-07-18
ER

PT J
AU Wang, YY
   Huang, YH
   Chen, XM
   Li, LD
   Shi, GM
AF Wang, Yuanyang
   Huang, Yihua
   Chen, Xiumin
   Li, Leida
   Shi, Guangming
TI Modeling content-attribute preference for personalized image esthetics
   assessment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image esthetics assessment; Esthetic preference; Personality
AB Personalized image esthetics assessment (PIAA) models user's personalized esthetic preference and predicts a unique esthetic score for the user, which has become a hot topic due to its usefulness in social media, album curation, etc. People's esthetic preference is typically determined by a mixture of diversified factors, which makes it extremely challenging to model. Intuitively, people with different personalities have distinct preferences for various photographic contents, while image content and esthetic attributes are always tightly coupled. Motivated by this, this paper presents a content-attribute preference (CAP) framework for PIAA, which models the intricate relationship between user personality and image "content-attribute" coupling features. Specifically, a multi-task learning network is utilized to extract "content-attribute" coupling features, and another parallel network is used to extract personality features. Then, a personalized esthetic prior model is trained to represent the content-attribute preferences of people with different personalities based on the cross attention mechanism. Finally, a PIAA model is obtained by fine-tuning the esthetic prior model using target user data. Extensive experiments on three public databases demonstrate that the proposed CAP model outperforms the state-of-the-arts in terms of both prediction performance and generalization ability.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Wang, Yuanyang; Li, Leida; Shi, Guangming] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.
   [Huang, Yihua; Chen, Xiumin] China Telecom Res Inst, Guangzhou 510630, Peoples R China.
C3 Xidian University
RP Li, LD (corresponding author), Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.
EM ldli@xidian.edu.cn
RI li, li/HII-4157-2022; Li, Li/AEM-3636-2022; Yang, Yufei/JXX-6325-2024;
   Huang, YH/KHZ-6459-2024
FU Guangdong Provincial Key Research and Development Program
   [2021B0101400002]; National Natural Science Foundation of China
   [62171340, 61991451 and61771473]; OPPO Research Fund [20JY024]; Key
   Project of Shaanxi Provincial Department of Education
FX Acknowledgement This work was supported in part by the Guangdong
   Provincial Key Research and Development Program (2021B0101400002) , the
   National Natural Science Foundation of China (62171340, 61991451
   and61771473) , the OPPO Research Fund, and the Key Project of Shaanxi
   Provincial Department of Education (20JY024) .
CR Aslan S, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104163
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chaudhuri U, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104003
   Cui CR, 2020, INFORM SCIENCES, V512, P780, DOI 10.1016/j.ins.2019.10.011
   Dai Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.007
   Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467
   Guntuku SC, 2018, IEEE T AFFECT COMPUT, V9, P130, DOI 10.1109/TAFFC.2016.2581168
   Hosu V., P IEEE C COMPUTER VI, P9375
   Kim WH, 2020, IEEE T AFFECT COMPUT, V11, P493, DOI 10.1109/TAFFC.2018.2809752
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li L., P IEEE INT C MULTIME, P1
   Li LD, 2020, IEEE T IMAGE PROCESS, V29, P3898, DOI 10.1109/TIP.2020.2968285
   Lv P, 2023, IEEE T MULTIMEDIA, V25, P736, DOI 10.1109/TMM.2021.3130752
   Lv P, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1328, DOI 10.1145/3240508.3240635
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   O'Donovan P., 2014, Proceedings of the Workshop on Computational Aesthetics, P33
   Ren J, 2017, IEEE I CONF COMP VIS, P638, DOI 10.1109/ICCV.2017.76
   Risko EF, 2012, COGNITION, V122, P86, DOI 10.1016/j.cognition.2011.08.014
   Segalin C, 2017, IEEE T AFFECT COMPUT, V8, P268, DOI 10.1109/TAFFC.2016.2516994
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang XO, 2013, IEEE T MULTIMEDIA, V15, P1930, DOI 10.1109/TMM.2013.2269899
   Wang WN, 2019, IEEE IMAGE PROC, P1875, DOI [10.1109/icip.2019.8803119, 10.1109/ICIP.2019.8803119]
   Wu H, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104123
   Zhang B., P BRIT MACHINE VISIO, P1
   Zhu HC, 2022, IEEE T CYBERNETICS, V52, P1798, DOI 10.1109/TCYB.2020.2984670
   Zhu HC, 2023, IEEE T MULTIMEDIA, V25, P179, DOI 10.1109/TMM.2021.3123468
   Zhu HC, 2020, NEURAL PROCESS LETT, V51, P2105, DOI 10.1007/s11063-019-09987-7
   Zhu XG, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104289
NR 29
TC 1
Z9 1
U1 4
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104505
DI 10.1016/j.imavis.2022.104505
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800008
DA 2024-07-18
ER

PT J
AU Fan, B
   Dai, YC
   Zhang, ZY
   Wang, K
AF Fan, Bin
   Dai, Yuchao
   Zhang, Zhiyuan
   Wang, Ke
TI Differential SfM and image correction for a rolling shutter stereo rig
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Rolling shutter stereo rig; Differential SfM; Motion estimation; Image
   correction; 3D reconstruction
ID ALGORITHM
AB Most modern consumer-grade cameras are equipped with an electronic rolling shutter (RS), leading to image distortions when the camera moves during image acquisition. We explore the first structure and motion estima-tion problem of a dynamic generalized RS stereo camera. Such a general configuration is commonplace in robots and autonomous driving applications. We propose a tractable RS stereo differential structure from motion (SfM) algorithm, taking into account the RS effect during consecutive imaging, which effectively compensates for the RS-stereo image distortion by a linear scaling operation on each optical flow. We further propose embedding the cheirality into RANSAC and develop a robust RS-stereo-aware full-motion estimation framework. We demon-strate that the RS stereo motion and depth map refined by our non-linear optimization schemes within the max-imum likelihood criterion can be used for image correction to recover high-quality global shutter (GS) stereo images. Moreover, using the proposed generalized RS stereo differential SfM pipeline, the corrected images pro-duce an accurate 3D scene structure as the ground-truth structure. Extensive experiments on both synthetic and real RS stereo data demonstrate the effectiveness of our model and method in various configurations. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Fan, Bin; Dai, Yuchao; Zhang, Zhiyuan; Wang, Ke] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
C3 Northwestern Polytechnical University
RP Dai, YC (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
EM daiyuchao@nwpu.edu.cn
RI Dai, Yuchao/F-7832-2015; zhang, ZY/HJH-6535-2023; zhang,
   zhiyuan/GRS-2141-2022; zhang, zhiyuan/JCD-8906-2023; zhang,
   zhi/HPH-4905-2023
OI Dai, Yuchao/0000-0002-4432-7406; 
FU National Key Research and Development Program of China [2018AAA0102803];
   National Natural Science Foundation of China [61871325]; Innovation
   Foundation for Doctor Dissertation of Northwestern Polytechnical
   University [CX2022046]
FX This work was supported partly by the National Key Research and
   Development Program of China under Grant 2018AAA0102803, the National
   Natural Science Foundation of China under Grant 61871325, and the
   Innovation Foundation for Doctor Dissertation of Northwestern
   Polytechnical University under Grant CX2022046. We would like to thank
   DJI for the support of this work.
CR Ait-Aider O, 2009, IEEE I CONF COMP VIS, P1835, DOI 10.1109/ICCV.2009.5459408
   Albl C, 2020, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR42600.2020.00258
   Albl C, 2020, IEEE T PATTERN ANAL, V42, P1439, DOI 10.1109/TPAMI.2019.2894395
   Albl C, 2016, PROC CVPR IEEE, P3355, DOI 10.1109/CVPR.2016.365
   Albl C, 2016, LECT NOTES COMPUT SC, V9909, P36, DOI 10.1007/978-3-319-46454-1_3
   Albl C, 2015, PROC CVPR IEEE, P2292, DOI 10.1109/CVPR.2015.7298842
   [Anonymous], 2012, P 2012 IEEE INT C CO
   Bai F., 2022, P C COMPUTER VISION
   Baker S, 2010, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2010.5539932
   Bingbing Zhuang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P243, DOI 10.1007/978-3-030-58571-6_15
   Cheong LF, 2013, INT J COMPUT VISION, V101, P45, DOI 10.1007/s11263-012-0544-5
   Dai YC, 2016, PROC CVPR IEEE, P4132, DOI 10.1109/CVPR.2016.448
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Engel J, 2015, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2015.7353631
   Fan B., 2021, P IEEECVF INT C COMP, P4228
   Fan B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4521, DOI 10.1109/ICCV48922.2021.00450
   Fan B, 2021, IEEE SIGNAL PROC LET, V28, P1550, DOI 10.1109/LSP.2021.3099350
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forssén PE, 2010, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.2010.5540173
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611
   Häne C, 2017, IMAGE VISION COMPUT, V68, P14, DOI 10.1016/j.imavis.2017.07.003
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448
   Hedborg J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P17, DOI 10.1109/ICCVW.2011.6130217
   Hedborg J, 2012, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2012.6247831
   Im S, 2019, IEEE T PATTERN ANAL, V41, P775, DOI 10.1109/TPAMI.2018.2819679
   Ito E, 2017, PROC CVPR IEEE, P4512, DOI 10.1109/CVPR.2017.480
   Jae-Hak Kim, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5148, DOI 10.1109/ICRA.2017.7989602
   Kim JH, 2016, IEEE INT CONF ROBOT, P1308, DOI 10.1109/ICRA.2016.7487263
   Klingner B, 2013, IEEE I CONF COMP VIS, P953, DOI 10.1109/ICCV.2013.122
   Kukelova Zuzana, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P698, DOI 10.1007/978-3-030-58558-7_41
   Kukelova Zuzana, 2018, P ASIAN C COMPUTER V, P265
   Lao YZ, 2021, IEEE T PATTERN ANAL, V43, P2780, DOI 10.1109/TPAMI.2020.2977644
   Lao YZ, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01368-1
   Lao YZ, 2018, PROC CVPR IEEE, P4795, DOI 10.1109/CVPR.2018.00504
   Liu PD, 2020, PROC CVPR IEEE, P5940, DOI 10.1109/CVPR42600.2020.00598
   LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057
   Ma Y, 2000, INT J COMPUT VISION, V36, P71, DOI 10.1023/A:1008124507881
   Meingast Marci, 2005, ARXIVCS0503076
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Purkait P, 2018, IEEE WINT CONF APPL, P903, DOI 10.1109/WACV.2018.00104
   Purkait P, 2017, IEEE I CONF COMP VIS, P882, DOI 10.1109/ICCV.2017.101
   Rengarajan V, 2017, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2017.252
   Rengarajan V, 2016, PROC CVPR IEEE, P2773, DOI 10.1109/CVPR.2016.303
   Ringaby E, 2012, INT J COMPUT VISION, V96, P335, DOI 10.1007/s11263-011-0465-8
   Saurer O, 2016, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2016.363
   Saurer O, 2015, IEEE INT C INT ROBOT, P1328, DOI 10.1109/IROS.2015.7353540
   Saurer O, 2013, IEEE I CONF COMP VIS, P465, DOI 10.1109/ICCV.2013.64
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schubert D, 2019, IEEE INT C INT ROBOT, P2462, DOI [10.1109/IROS40897.2019.8968539, 10.1109/iros40897.2019.8968539]
   Schubert D, 2018, LECT NOTES COMPUT SC, V11212, P699, DOI 10.1007/978-3-030-01237-3_42
   Teed Zachary, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P402, DOI 10.1007/978-3-030-58536-5_24
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   Vasu S, 2018, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2018.00073
   Wang K, 2020, IEEE IMAGE PROC, P463, DOI 10.1109/ICIP40778.2020.9191254
   Zhao CH, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-019-2690-0
   Zhong Z., 2021, P IEEE CVF C COMP VI, P9219
   Zhou YL, 2020, ISPRS J PHOTOGRAMM, V160, P51, DOI 10.1016/j.isprsjprs.2019.11.020
   Zhuang BB, 2019, PROC CVPR IEEE, P4546, DOI 10.1109/CVPR.2019.00468
   Zhuang BB, 2017, IEEE I CONF COMP VIS, P948, DOI 10.1109/ICCV.2017.108
NR 62
TC 5
Z9 5
U1 5
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104492
DI 10.1016/j.imavis.2022.104492
EA JUN 2022
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800002
DA 2024-07-18
ER

PT J
AU Pai, GT
   Bronstein, A
   Talmon, R
   Kimmel, R
AF Pai, Gautam
   Bronstein, Alex
   Talmon, Ronen
   Kimmel, Ron
TI Deep Isometric Maps
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multidimensional scaling; Manifold learning; Non-linear dimensionality
   reduction; Neural networks
ID NONLINEAR DIMENSIONALITY REDUCTION; NEURAL-NETWORKS; EIGENMAPS;
   REPRESENTATIONS
AB Isometric feature mapping is an established time-honored algorithm in manifold learning and non-linear dimensionality reduction. Its prominence can be attributed to the output of a coherent global low-dimensional representation of data by preserving intrinsic distances. In order to enable an efficient and more applicable isometric feature mapping, a diverse set of sophisticated advancements have been proposed to the original algorithm to incorporate important factors like sparsity of computation, conformality, topological constraints and spectral geometry. However, a significant shortcoming of most approaches is the dependence on large-scale dense-spectral decompositions and the inability to generalize to points far away from the sampling of the manifold.In this paper, we explore an unsupervised deep learning approach for computing distance-preserving maps for non-linear dimensionality reduction. We demonstrate that our framework is general enough to incorporate all previous advancements and show a significantly improved local and non-local generalization of the isometric mapping. Our approach involves training with only a few landmark points and avoids the need for population of dense matrices as well as computing their spectral decomposition.(c) 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Pai, Gautam] Eindhoven Univ Technol TU e, Eindhoven, Netherlands.
   [Pai, Gautam; Bronstein, Alex; Talmon, Ronen; Kimmel, Ron] Technion Israel Inst Technol, Haifa, Israel.
   [Pai, Gautam] Eindhoven Univ Technol, Eindhoven, Netherlands.
C3 Eindhoven University of Technology; Technion Israel Institute of
   Technology; Eindhoven University of Technology
RP Pai, GT (corresponding author), Eindhoven Univ Technol, Eindhoven, Netherlands.
EM g.pai@tue.nl; bron@cs.technion.ac.il; ronen@ee.technion.ac.il;
   ron@cs.technion.ac.il
FU Israel Ministry of Science [3-14719]; Technion Hiroshi Fujiwara Cyber
   Security Research Center; Israel Cyber Directorate; Hiroshi Fujiwara
   Cyber Security Research Center at the Technion
FX This research is partially supported by the Israel Ministry of Science,
   grant number 3-14719, the Technion Hiroshi Fujiwara Cyber Security
   Research Center and the Israel Cyber Directorate. The first author was
   supported by a fellowship from the Hiroshi Fujiwara Cyber Security
   Research Center at the Technion. The authors thank anonymous reviewers
   for insightful feedback, especially for highlighting recent advances in
   non-linear dimensionality reduction from axiomatic [54,55] as well as a
   learning [56,57] point of view and applicable to other challenging
   datasets like hyperspectral images.
CR Aflalo Y, 2015, SIAM J IMAGING SCI, V8, P1141, DOI 10.1137/140977680
   Aflalo Y, 2013, P NATL ACAD SCI USA, V110, P18052, DOI 10.1073/pnas.1308708110
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   [Anonymous], 2015, P 2015 EUR WORKSH 3D
   [Anonymous], 2003, Advances in Neural Informaiton Processing Systems
   Atzmon M., 2021, ARXIV200609289
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bengio Y, 2004, ADV NEUR IN, V16, P177
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Boyarski A, 2017, LECT NOTES COMPUT SC, V10302, P681, DOI 10.1007/978-3-319-58771-4_54
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1
   Bronstein MM, 2006, NUMER LINEAR ALGEBR, V13, P149, DOI 10.1002/nla.475
   Budninskiy M, 2019, SIAM J APPL ALGEBR G, V3, P266, DOI 10.1137/18M1196133
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chui C. K., 2018, FRONT APPL MATH STAT, V4, P12, DOI [DOI 10.3389/FAMS.2018.00012, DOI 10.3389/fams.2018.00012]
   Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102
   De Leeuw J., 2021, MULTIDIMENSIONAL SCA
   de Ridder D, 1997, PATTERN RECOGN LETT, V18, P1307, DOI 10.1016/S0167-8655(97)00093-7
   Dohm S, 2020, J CHEM THEORY COMPUT, V16, P2002, DOI 10.1021/acs.jctc.9b01266
   Donoho DL, 2005, J MATH IMAGING VIS, V23, P5, DOI 10.1007/s10851-005-4965-4
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Elad A, 2001, PROC CVPR IEEE, P168
   Gong H., 2006, BMVC, P227
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grossmann R, 2002, IEEE T PATTERN ANAL, V24, P433, DOI 10.1109/34.993552
   Hermans A., 2021, ARXIV170307737
   HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hong DF, 2021, IEEE GEOSC REM SEN M, V9, P52, DOI 10.1109/MGRS.2021.3064051
   Hong DF, 2021, IEEE T CYBERNETICS, V51, P3602, DOI 10.1109/TCYB.2020.3028931
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2019, ISPRS J PHOTOGRAMM, V158, P35, DOI 10.1016/j.isprsjprs.2019.09.008
   Kingma D., INT C LEARN REPR, P2021
   Kingma D.P, 2021, ARXIV13126114
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   LeVeque R.J, 2021, FINITE DIFFERENCE ME
   MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296, DOI 10.1109/72.363467
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Mishne G, 2019, APPL COMPUT HARMON A, V47, P259, DOI 10.1016/j.acha.2017.08.007
   Pai G, 2019, IEEE WINT CONF APPL, P819, DOI 10.1109/WACV.2019.00092
   Pai Gautam, 2017, INT C LEARNING REPRE
   Paszke Adam, 2017, Pytorch
   Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147
   Rosman G., 2008, FAST MULTIDIMENSIONA
   Rosman G, 2010, INT J COMPUT VISION, V89, P56, DOI 10.1007/s11263-010-0322-1
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678
   Schwartz A, 2019, SIAM J IMAGING SCI, V12, P1347, DOI 10.1137/18M1198752
   SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506
   Shamai G, 2015, IEEE I CONF COMP VIS, P2255, DOI 10.1109/ICCV.2015.260
   SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P125, DOI 10.1007/BF02289630
   Silva V.D., 2004, Technical Report
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Torgerson WS, 1952, PSYCHOMETRIKA, V17, P401
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   WOLFSON E, 1989, IEEE T PATTERN ANAL, V11, P1001, DOI 10.1109/34.35505
   Young G, 1938, PSYCHOMETRIKA, V3, P19, DOI 10.1007/BF02287916
   Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671
NR 59
TC 2
Z9 2
U1 3
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104461
DI 10.1016/j.imavis.2022.104461
EA MAY 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L9ND
UT WOS:000799606300005
OA hybrid
DA 2024-07-18
ER

PT J
AU Behera, NKS
   Sa, PK
   Bakshi, S
   Padhy, RP
AF Behera, Nayan Kumar Subhashis
   Sa, Pankaj Kumar
   Bakshi, Sambit
   Padhy, Ram Prasad
TI Person re-identification: A taxonomic survey and the path ahead
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Visual surveillance; Computer vision
ID TRACKING; PEOPLE; NETWORKS; CLASSIFICATION; ILLUMINATION; RECOGNITION;
   FRAMEWORK; CAMERAS; MODEL; VIEWS
AB Person re-identification (PRId) is one of the most challenging tasks in automated video surveillance and has been an area of intense research spanning the past decade. PRId aims at finding a person who has previously been identified using some unique descriptor of the person. This survey comprises a wide spectrum of PRId methods spanning from traditional to deep learning-based being analyzed and compared. This survey also discusses different PRId frameworks on the basis of machine learning and deep learning. It offers a multi-dimensional taxonomy to classify the most pertinent researches according to different perspectives and tries to unify the categorization of PRId methods and fill the gap between the recently published surveys. This study highlights the challenges in building PRId systems. It presents a critical overview of recent progress and the state-of-the-art approaches to solving some major challenges of existing PRId systems. Furthermore, we discuss the performance comparisons of the various state-of-the-art in different datasets. Finally, we discuss several open issues and directions for future studies. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Behera, Nayan Kumar Subhashis; Sa, Pankaj Kumar; Bakshi, Sambit] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Orissa 769008, India.
   [Padhy, Ram Prasad] Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Kancheepuram 600127, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Indian Institute of Information Technology, Design
   & Manufacturing, Kancheepuram
RP Bakshi, S (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Orissa 769008, India.
EM sambitbaksi@gmail.com
RI K, Pankaj/A-9362-2017; Gandhiraman, Ram P./B-7004-2013; Bakshi,
   Sambit/JDC-3355-2023
OI Bakshi, Sambit/0000-0002-6107-114X; PATURI, RAM
   PRASAD/0000-0002-1233-6930
FU Project titled "Deep learning applications for computer vision task" -
   NITROAA; NVIDIA Corporation; NVIDIA; Project titled "Establishment of
   Bioinformatics and Computational Biology Centre: Animal Bioinformatics
   -BIC at National Institute of Technology Rourkela" by Department of
   Biotechnology, Ministry of Science and Technology, Government of India
FX This research is partially supported by he following projects: 1.
   Project titled "Deep learning applications for computer vision task"
   funded by NITROAA with support of Lenovo P920 and Dell Inception 7820
   workstation and NVIDIA Corporation with support of NVIDIA Titan V and
   Quadro RTX 8000 GPU. 2. Project titled "Establishment of Bioinformatics
   and Computational Biology Centre: Animal Bioinformatics -BIC at National
   Institute of Technology Rourkela" by Department of Biotechnology,
   Ministry of Science and Technology, Government of India.
CR Ali T., P ICCV IEEE 2019, P285, DOI [10.1016/j.patcog.2018.11.025, DOI 10.1016/J.PATCOG.2018.11.025]
   Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583
   Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], 2014, CONT AW VIS US IM BA
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-11024-6_46
   [Anonymous], 2014, QUEEN MARY RES ONLIN, DOI DOI 10.5244/C.28.48
   [Anonymous], 2012, DICTA
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P1, DOI 10.1109/AVSS.2010.68
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bak S., P ECCV 2012, P806, DOI [10.1007/978-3-642-33712-3_58, DOI 10.1007/978-3-642-33712-3_58]
   Bak S, 2017, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR.2017.171
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   Baltieri D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1817, DOI 10.1109/ICCVW.2011.6130469
   Barbosa IB, 2012, LECT NOTES COMPUT SC, V7583, P433, DOI 10.1007/978-3-642-33863-2_43
   Barman A., 2021, US Patent, Patent No. [11,176,382, 11176382]
   Bauml M., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P291, DOI 10.1109/AVSS.2011.6027339
   Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Bedagkar-Gala A, 2012, PATTERN RECOGN LETT, V33, P1908, DOI 10.1016/j.patrec.2011.09.005
   Bedagkar-Gala A., P ICCV 2011, P1721, DOI [10.1109/iccvw.2011.6130457, DOI 10.1109/ICCVW.2011.6130457]
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Behera NKS, 2021, PATTERN RECOGN LETT, V151, P163, DOI 10.1016/j.patrec.2021.08.007
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berdugo G, 2010, EUR SIGNAL PR CONF, P1806
   Bialkowski A., P DICTA 2013, P1, DOI [10.1109/dicta.2013.6691512, DOI 10.1109/DICTA.2013.6691512]
   Cai Y, 2010, INT C COMP VIS, DOI [10.1007/978-3-642-22822-3_21, DOI 10.1007/978-3-642-22822-3_21]
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chang XY, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107569
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Chen H., 2018, P IEEE 4 INT C MULT, P1, DOI DOI 10.1109/BIGMM.2018.8499067
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Cheng D, 2018, PATTERN RECOGN, V82, P94, DOI 10.1016/j.patcog.2018.05.007
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cheng Y.M., P ICISP 2009, P1, DOI [10.1109/cisp.2009.5304391, DOI 10.1109/CISP.2009.5304391]
   Cong DNT, 2010, SIGNAL PROCESS, V90, P2362, DOI 10.1016/j.sigpro.2009.09.005
   Cosar S, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 4, P389, DOI 10.5220/0006155403890397
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22
   de Oliveira IO, 2009, EIGHTH IEEE INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P461, DOI 10.1109/DASC.2009.33
   De Vleeschouwer C., 2008, NEM SUMMIT, V8, DOI [10.1016/j.patcog.2017.01.006, DOI 10.1016/J.PATCOG.2017.01.006]
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Detmold H., P ICDSC 2007, P195, DOI [10.1109/icdsc.2007.4357524, DOI 10.1109/ICDSC.2007.4357524]
   Dick AR, 2004, LECT NOTES ARTIF INT, V3339, P160
   Dikmen M., P ACCV 2010, P501, DOI [10.1007/978-3-642-19282-1_40, DOI 10.1007/978-3-642-19282-1_40]
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Ellis T., P VSPETS 2003, P165
   Ferreira L., ADV ARITIFICIAL INTE, P276
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Figueira D., 2014, COMPUTER VISION ECCV, P241
   Forssen P.-E., 2007, IEEE International Conference on Computer Vision (ICCV), P1, DOI DOI 10.1109/CVPR.2007.383120
   Gallagher AC, 2008, PROC CVPR IEEE, P1073
   Gandhi T, 2007, MACH VISION APPL, V18, P207, DOI 10.1007/s00138-006-0063-x
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gou MR, 2017, IEEE COMPUT SOC CONF, P1425, DOI 10.1109/CVPRW.2017.185
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   Hamdoun O, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P140
   Hashemi A, 2021, INT J MACH LEARN CYB, V12, P459, DOI 10.1007/s13042-020-01180-w
   He L., 2021, ARXIV PREPRINT ARXIV
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hosmer P, 2006, CAR C SECUR, P75
   Hu J., P CVPR 2015, P325, DOI [10.1109/cvpr.2015.7298629, DOI 10.1109/CVPR.2015.7298629]
   Hu L, 2018, MACH VISION APPL, V29, P947, DOI 10.1007/s00138-018-0915-1
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Hu Y, 2013, IEEE COMPUT SOC CONF, P794, DOI 10.1109/CVPRW.2013.119
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Iodice S, 2015, PATTERN RECOGN, V48, P1074, DOI 10.1016/j.patcog.2014.09.011
   Islam K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103970
   Javed O, 2005, PROC CVPR IEEE, P26
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Jeong K, 2008, MACH VISION APPL, V19, P443, DOI 10.1007/s00138-007-0079-x
   Jia JR, 2016, NEUROCOMPUTING, V205, P92, DOI 10.1016/j.neucom.2016.05.003
   Jiang XK, 2021, AAAI CONF ARTIF INTE, V35, P1691
   Jing XY, 2015, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2015.7298669
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Kang JM, 2004, INT C PATT RECOG, P759, DOI 10.1109/ICPR.2004.1333883
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Kawanishi Y., 2014, P FCV, V5
   Kodirov E., 2015, BMVC, DOI DOI 10.5244/C.29.44
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kuo CH, 2010, LECT NOTES COMPUT SC, V6311, P383
   Lan X, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108514
   Lantagne M., 2003, VIP VISION TOOL COMP
   Lavi B., 2018, ARXIV PREPRINT ARXIV
   Layne R, 2015, LECT NOTES COMPUT SC, V8927, P225, DOI 10.1007/978-3-319-16199-0_16
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li JP, 2020, IEEE T CYBERNETICS, V50, P3281, DOI [10.1109/TPAMI.2019.2929036, 10.1109/TCYB.2019.2904052]
   Li Jiwei, 2017, P 2017 C EMP METH NA, P2157, DOI DOI 10.18653/V1/D17-1230
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429
   Li YY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2115, DOI 10.1145/3343031.3350982
   Li Y, 2022, IEEE SIGNAL PROC LET, V29, P264, DOI 10.1109/LSP.2021.3132286
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liao WT, 2017, IEEE INT CONF COMP V, P385, DOI 10.1109/ICCVW.2017.52
   Lin SC, 2022, NEUROCOMPUTING, V471, P1, DOI 10.1016/j.neucom.2021.11.009
   Lisanti G., 2014, Proceedings of the International Conference on Distributed Smart Cameras, p10:1
   Liu C., IEEE 2020, P6887, DOI [10.1109/cvpr42600.2020.00692, DOI 10.1109/CVPR42600.2020.00692]
   Liu GQ, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104068
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu H, 2017, CAAI T INTELL TECHNO, V2, P48, DOI 10.1016/j.trit.2017.04.001
   Liu HM, 2021, NEUROCOMPUTING, V423, P57, DOI 10.1016/j.neucom.2020.10.019
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499
   Lopes DPF, 2018, L N COMPUT VIS BIOME, V27, P689, DOI 10.1007/978-3-319-68195-5_75
   Loy C.C., P ICIP 2013, P3567, DOI [10.1109/icip.2013.6738736, DOI 10.1109/ICIP.2013.6738736]
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma L., 2016, ARXIV160502464
   Ma LQ, 2017, ADV NEUR IN, V30
   Madden C, 2007, MACH VISION APPL, V18, P233, DOI 10.1007/s00138-007-0070-6
   Mansouri N, 2021, NEURAL COMPUT APPL, V33, P12827, DOI 10.1007/s00521-021-05936-5
   Martinel N., 2012, 2012 IEEE COMPUTER S, P31, DOI 10.1109/CVPRW.2012.6239203
   Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Mazzon R, 2012, PATTERN RECOGN LETT, V33, P1828, DOI 10.1016/j.patrec.2012.02.014
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Ming Z., 2021, ARXIV PREPRINT ARXIV, V110, DOI [10.1016/j.patcog.2020.107424, DOI 10.1016/J.PATCOG.2020.107424]
   Mogelmose A, 2013, IEEE COMPUT SOC CONF, P301, DOI 10.1109/CVPRW.2013.52
   Munaro M, 2014, IEEE INT CONF ROBOT, P5644, DOI 10.1109/ICRA.2014.6907689
   Munaro M, 2014, IEEE INT CONF ROBOT, P4512, DOI 10.1109/ICRA.2014.6907518
   Nanda A, 2019, MULTIMED TOOLS APPL, V78, P3885, DOI 10.1007/s11042-017-4875-7
   Nanda A, 2019, J AMB INTEL HUM COMP, V10, P13, DOI 10.1007/s12652-017-0580-7
   Nanda A, 2017, ENG SCI TECHNOL, V20, P1041, DOI 10.1016/j.jestch.2017.03.001
   Nanda AJ, 2017, IEEE ACCESS, V5, P6471, DOI 10.1109/ACCESS.2017.2686438
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Paisitkriangkrai S, 2017, COMPUT VIS IMAGE UND, V156, P51, DOI 10.1016/j.cviu.2016.10.015
   Pala F, 2016, IEEE T CIRC SYST VID, V26, P788, DOI 10.1109/TCSVT.2015.2424056
   Palmero C, 2016, INT J COMPUT VISION, V118, P217, DOI 10.1007/s11263-016-0901-x
   Pan HH, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107300
   Park U, 2006, INT C PATT RECOG, P1204
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Pòiesi F, 2013, COMPUT VIS IMAGE UND, V117, P1257, DOI 10.1016/j.cviu.2012.08.008
   Porikli F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P133
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Prosser Bryan James, 2008, P BMVC, V8, P74
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Rahimi A., 2004, P CVPR, V1, DOI [10.1109/CVPR.2004.1315031,ii, DOI 10.1109/CVPR.2004.1315031,II]
   Raj S, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108287
   Riccardo S., P SBPR 2011, P275, DOI [10.1007/978-3-642-24471-1_20, DOI 10.1007/978-3-642-24471-1_20]
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Roy S, 2018, PROC CVPR IEEE, P7064, DOI 10.1109/CVPR.2018.00738
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Satta R., P ICIAP 2011, P140, DOI [10.1007/978-3-642-24088-1_15, DOI 10.1007/978-3-642-24088-1_15]
   Satta R, 2012, PATTERN RECOGN LETT, V33, P1838, DOI 10.1016/j.patrec.2012.03.026
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Sharma C., 2021, ARXIV PREPRINT ARXIV
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Shen YT, 2018, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2018.00241
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Simi Wang, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1876, DOI 10.1109/ICCVW.2011.6130477
   Simonnet D., P ECCV 2012, P423, DOI [10.1007/978-3-642-33863-2_42, DOI 10.1007/978-3-642-33863-2_42]
   Sivic Josef., 2006, British Machine Vision Conference, P909
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081
   Su C, 2018, IEEE T PATTERN ANAL, V40, P1167, DOI 10.1109/TPAMI.2017.2679002
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Su C, 2018, PATTERN RECOGN, V75, P77, DOI 10.1016/j.patcog.2017.07.005
   Su C, 2017, PATTERN RECOGN, V66, P4, DOI 10.1016/j.patcog.2017.01.006
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Takala V., P ICPR 2012, P1387
   Tan DL, 2006, INT C PATT RECOG, P1000
   Teixeira LF, 2009, PATTERN RECOGN LETT, V30, P157, DOI 10.1016/j.patrec.2008.04.001
   Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607
   Truong C.D.N., P IPTTA 2010, P60, DOI [10.1109/ipta.2010.5586809, DOI 10.1109/IPTA.2010.5586809]
   Tsai R.Y., P CVPR 1986, P364
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang H., 2016, P BMVC, DOI [10.5244/c.30.134, DOI 10.5244/C.30.134]
   Wang HX, 2016, IEEE IMAGE PROC, P769, DOI 10.1109/ICIP.2016.7532461
   Wang HY, 2021, PATTERN RECOGN LETT, V146, P77, DOI 10.1016/j.patrec.2021.03.002
   Wang J., 2022, IEEE ACCESS, V30, DOI [10.1117/1.JEI.30.3.033014, DOI 10.1117/1.JEI.30.3.033014]
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang KJ, 2018, CAAI T INTELL TECHNO, V3, P219, DOI 10.1049/trit.2018.1001
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418
   Wang W., 2021, US Patent, Patent No. [11,100,370, 11100370]
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wang YC, 2018, PROC CVPR IEEE, P1470, DOI 10.1109/CVPR.2018.00159
   Wei LH, 2019, IEEE T MULTIMEDIA, V21, P986, DOI 10.1109/TMM.2018.2870522
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wieczorek M., 2021, INT C NEUR INF PROC, P212
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Wu GL, 2020, AAAI CONF ARTIF INTE, V34, P12362
   Wu L., 2016, ARXIV160107255
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Wu S., 2021, ARXIV PREPRINT ARXIV
   Wu WY, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107424
   Wu Y, 2012, LECT NOTES COMPUT SC, V7574, P497, DOI 10.1007/978-3-642-33712-3_36
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Wu Z, 2014, IEEE COMPUT SOC CONF, P201, DOI 10.1109/CVPRW.2014.39
   Xiao T., 2016, ARXIV PREPRINT ARXIV, V1
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xin XM, 2019, PATTERN RECOGN, V88, P285, DOI 10.1016/j.patcog.2018.11.025
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yaghoubi E, 2021, PATTERN RECOGN LETT, V145, P23, DOI 10.1016/j.patrec.2021.01.035
   Yaghoubi E, 2021, PATTERN RECOGN LETT, V143, P50, DOI 10.1016/j.patrec.2020.12.017
   Yan YC, 2020, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR42600.2020.00297
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yang Z, 2018, MACH VISION APPL, V29, P1019, DOI 10.1007/s00138-018-0917-z
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yin Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1100
   Ying Zhang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P368, DOI 10.1109/ICIG.2011.40
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang CY, 2019, NEUROCOMPUTING, V340, P259, DOI 10.1016/j.neucom.2019.01.093
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng L., P CVPR 2017, P1367, DOI [10.1007/s11263-009-0275-4, DOI 10.1007/S11263-009-0275-4]
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng W.S., P CVPR 2012, P2650, DOI [10.1109/cvpr.2012.6247985, DOI 10.1109/CVPR.2012.6247985]
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
   Zheng Z., P CVPR IEEE 2019, P2138, DOI [10.1016/j.patcog.2018.11.025, DOI 10.1016/J.PATCOG.2018.11.025]
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou JH, 2018, PROC CVPR IEEE, P5373, DOI 10.1109/CVPR.2018.00563
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 257
TC 8
Z9 8
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104432
DI 10.1016/j.imavis.2022.104432
EA APR 2022
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1F1NU
UT WOS:000794942300008
DA 2024-07-18
ER

PT J
AU Yu, L
   Qiao, BJ
   Zhang, HL
   Yu, JY
   He, X
AF Yu, Lang
   Qiao, Baojun
   Zhang, Huanlong
   Yu, Junyang
   He, Xin
TI LTST: Long-term segmentation tracker with memory attention network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Long-term tracking; Object segmentation; Memory network; Attention
   mechanism
AB Recent interest in the combination of visual object tracking (VOT) and video object segmentation (VOS) has yielded rapid progress. However, existing segmentation methods are still restricted to the target model created in the first frame, which leads to the lack of long-term adaptability. To overcome this limitation, we propose a novel long-term segmentation tracker LTST leveraging memory attention network to achieve the effect of online learning without additional training. Specifically, we first combine a discriminative correlation filter with a matching-based paradigm for the segmentation task, then we develop a memory attention network based on partial cost volume to extract relevant historical information and dynamically reform the segmentation template. Moreover, we extend our LTST for long-term tracking by introducing a multi-scale verification network to identify tracking failures, and a global detector to re-locate the missing target. Experimental results on VOT-LT2018, VOT-LT2019, LaSOT and TLP benchmarks show that our proposed tracker achieves comparable performance to the state-of-the-art long-term tracking algorithms.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yu, Lang; Yu, Junyang; He, Xin] Henan Univ, Sch Software, Kaifeng 475000, Peoples R China.
   [Qiao, Baojun] Henan Univ, Sch Comp Sci, Kaifeng 475000, Peoples R China.
   [Zhang, Huanlong] Zhengzhou Univ Light Ind, Sch Elect & Informat Engn, Zhengzhou 450000, Peoples R China.
C3 Henan University; Henan University; Zhengzhou University of Light
   Industry
RP Qiao, BJ (corresponding author), Henan Univ, Sch Comp Sci, Kaifeng 475000, Peoples R China.
EM 17839235516@163.com
OI Yu, Lang/0000-0002-9083-5313
FU Key Technologies Research and Development Program of Henan
   [212102210078, 201300210400]; Elite Postgraduate Students Program of
   Henan Univer-sity [SYL20060174]; National Natural Science Foundation
   [61873246]; Natural Science Foundation of Henan [202300410495]
FX Acknowledgements This work was supported in part by the Key Technologies
   Research and Development Program of Henan under Grant (212102210078,
   201300210400) , the Elite Postgraduate Students Program of Henan
   Univer-sity (SYL20060174) , the National Natural Science Foundation
   (61873246) , and the Natural Science Foundation of Henan (202300410495)
   .
CR Abbass MY, 2021, VISUAL COMPUT, V37, P993, DOI 10.1007/s00371-020-01848-y
   Bhat G., P IEEE CVF INT C COM, P6182
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Caelles S., P IEEE C COMP VIS PA, P221
   Chaudhuri D, 2007, PATTERN RECOGN, V40, P1981, DOI 10.1016/j.patcog.2006.08.003
   Chen BaoXin., 2019, Fast visual object tracking with rotated bounding boxes
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Choi J, 2020, ACCV
   Cui Y., 2020, FULLY CONVOLUTIONAL
   Dai KN, 2020, PROC CVPR IEEE, P6297, DOI 10.1109/CVPR42600.2020.00633
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Dodge J., 2016, P 2016 C EMPIRICAL M
   Dong XP, 2021, IEEE T PATTERN ANAL, V43, P1515, DOI 10.1109/TPAMI.2019.2956703
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Han W., 2021, PROC IEEECVF C COMPU, P16570
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4
   Huang LH, 2020, AAAI CONF ARTIF INTE, V34, P11037
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M., 2019, P IEEE CVF INT C COM
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lukezic A, 2020, PROC CVPR IEEE, P7131, DOI 10.1109/CVPR42600.2020.00716
   Lukezic A, 2019, LECT NOTES COMPUT SC, V11362, P595, DOI 10.1007/978-3-030-20890-5_38
   Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Pont-Tuset J., 2017, ARXIV170400675
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Seoung Wug Oh, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P9225, DOI 10.1109/ICCV.2019.00932
   Sukhbaatar S., 2015, End-To-End Memory Networks
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Voigtlaender P., 2017, 2017 DAVIS CHALLENGE, V5
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Xingping Dong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P378, DOI 10.1007/978-3-030-58565-5_23
   Xu N., 2018, ARXIV180903327
   Yan B, 2019, IEEE I CONF COMP VIS, P2385, DOI 10.1109/ICCV.2019.00247
   Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680
   Yao R, 2019, IEEE T CIRC SYST VID, V29, P1687, DOI 10.1109/TCSVT.2018.2848358
   Yu L, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104181
   Zhang ZP, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P941, DOI 10.1145/3240508.3240638
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 55
TC 6
Z9 6
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104374
DI 10.1016/j.imavis.2022.104374
EA JAN 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400011
DA 2024-07-18
ER

PT J
AU Han, B
   Zhang, XY
   Ren, S
AF Han, Bing
   Zhang, Xinyun
   Ren, Shuang
TI PU-GACNet: Graph Attention Convolution Network for Point Cloud
   Upsampling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Point cloud upsampling; Graph attention convolution; Feature extraction;
   Edge-aware nodeshuffie; Feature expansion
AB ABSTR A C T Real-scanned point clouds are often sparse and non-uniform. To conquer the problem, researchers propose point cloud upsampling techniques, whose efficiency and effectiveness heavily rely on their feature extractors and fea-ture expanders used therein. Therefore, in this paper, to capture the global and local structured features of point clouds, we first design a Graph Attention Convolution (GAC) module as a feature extractor by assigning different attentional weights to combine spatial positions and feature attributes dynamically. Furthermore, we propose an Edge-aware NodeShuffie (ENS) module as a feature expander to upsampling point features smoothly, in an effort to better preserve local geometric details and emphasize local edges. Finally, we combine GAC module with ENS module into a novel point cloud upsampling pipeline, named as PU-GACNet. Extensive experiments as well as theoretical analysis demonstrate this pipeline significantly outperforms previous methods in network perfor-mance for 3D point cloud upsampling, to obtain more efficient inference with much fewer parameters.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Han, Bing; Zhang, Xinyun; Ren, Shuang] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Ren, S (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
EM bhan0458@bjtu.edu.cn; xy.zhang@bjtu.edu.cn; sren@bjtu.edu.cn
OI Han, Bing/0000-0001-8312-0881
FU National Natural Science Foundation of China [62072025]; Fundamental
   Research Funds for the Central Universities [2021YJS039]
FX This research is supported by two foundation items including National
   Natural Science Foundation of China (No. 62072025) and Fundamental
   Research Funds for the Central Universities (No. 2021YJS039).
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cui P, 2019, IEEE T KNOWL DATA EN, V31, P833, DOI 10.1109/TKDE.2018.2849727
   Funkhouser T.A., 2015, P COMP VIS PATT REC
   Gehring J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P123, DOI 10.18653/v1/P17-1012
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Han WK, 2020, AAAI CONF ARTIF INTE, V34, P10925
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Komarichev A, 2019, PROC CVPR IEEE, P7413, DOI 10.1109/CVPR.2019.00760
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li RH, 2021, PROC CVPR IEEE, P344, DOI 10.1109/CVPR46437.2021.00041
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Li YZ, 2018, ADV NEUR IN, V31
   Lian Z., 2015, P EUROGRAPHICS WORKS, P257
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276405
   Luo Luqing, 2021, P IEEE CVF INT C COM, P16208
   Mao JG, 2019, IEEE I CONF COMP VIS, P1578, DOI 10.1109/ICCV.2019.00166
   Pan L, 2020, IEEE INT CONF ROBOT, P1113, DOI [10.1109/icra40945.2020.9197499, 10.1109/ICRA40945.2020.9197499]
   Pan L, 2020, IEEE ROBOT AUTOM LET, V5, P4392, DOI 10.1109/LRA.2020.2994483
   Pan L, 2019, IEEE ROBOT AUTOM LET, V4, P4035, DOI 10.1109/LRA.2019.2927948
   Preiner R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601172
   Qi CR, 2017, ADV NEUR IN, V30
   Qian GC, 2021, PROC CVPR IEEE, P11678, DOI 10.1109/CVPR46437.2021.01151
   Qian Yue, 2020, P EUROPEAN C COMPUTE, P1
   Shen YR, 2018, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2018.00478
   Uy MA, 2019, IEEE I CONF COMP VIS, P1588, DOI 10.1109/ICCV.2019.00167
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818073
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xu Y, 2018, ADV SOC SCI EDUC HUM, V284, P87
   Ye Shuquan, 2021, IEEE T VISUAL COMPUT, V14, P1
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Zhou H, 2019, IEEE I CONF COMP VIS, P1961, DOI 10.1109/ICCV.2019.00205
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
NR 41
TC 14
Z9 16
U1 3
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2022
VL 118
AR 104371
DI 10.1016/j.imavis.2021.104371
EA JAN 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0F3OZ
UT WOS:000777273700006
DA 2024-07-18
ER

PT J
AU Cao, PP
   Chen, PP
   Niu, Q
AF Cao, Pingping
   Chen, Pengpeng
   Niu, Qiang
TI Multi-label image recognition with two-stream dynamic graph convolution
   networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-label image recognition; Two streams; Reconstructing graph feature
   nodes; Dynamic graph convolution networks
AB Recent studies use Graph Convolution Networks (GCN) to model label correlation for multi-label images because of the outstanding performance of GCN in relational modeling tasks. However, the traditional GCN has low generalization, and the current state-of-the-arts' accuracy is poor. Therefore, we propose a Two-Stream Dynamic Graph Convolution Network (2S-DGCN) to improve the performance of multi-label image recognition. In 2SDGCN, we first obtain the Up Confidence Score of prediction categories (UCS), the content-aware category and the label discriminant vector by a Semantic Attention Module (SAM) and a Dynamic Graph Convolution Network (DGCN) in upstream. Then fed the new graph feature nodes reconstructed by lateral embedding the content aware category and the label discriminant vector into a DGCN to produce the Down Confidence Score of prediction categories (DCS) in downstream. Finally, the Final Confidence Score of prediction categories (FCS) for multi-label image recognition is synthesized by fusing the UCS and DCS. Extensive experiments on the public multi-label benchmarks achieve mAPs of 85.6% on MS-COCO and 95.4% on VOC 2007. The results of compared experiment and visualization demonstrate that our method has better performance than the current state-ofthe-art methods. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Cao, Pingping; Chen, Pengpeng; Niu, Qiang] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221006, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Niu, Q (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221006, Jiangsu, Peoples R China.
EM niuqiangkd@163.com
RI chen, peng/HMD-1278-2023
OI pp, Cao/0000-0001-7524-2387
FU National Natural Science Foundation of China [51674255]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 51674255.
CR Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139
   Ge Z., ARXIV PREPRINT ARXIV
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He DL, 2019, AAAI CONF ARTIF INTE, P8401
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jain H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P935, DOI 10.1145/2939672.2939756
   Jin Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P649, DOI 10.1007/978-3-030-58589-1_39
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95
   Kipf T.N., 2017, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Li C, 2016, IEEE LATAMER CONF
   Li Q, 2016, PROC CVPR IEEE, P2977, DOI 10.1109/CVPR.2016.325
   Li X, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P430
   Li YN, 2016, LECT NOTES COMPUT SC, V9910, P684, DOI 10.1007/978-3-319-46466-4_41
   Lin RC, 2019, LECT NOTES COMPUT SC, V11132, P206, DOI 10.1007/978-3-030-11018-5_19
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu LC, 2019, INT CONF ACOUST SPEE, P1682, DOI 10.1109/ICASSP.2019.8683665
   Maas A.L., 2013, P 30 INT C MACH LEAR, V30, P3
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tommasi T, 2017, ADV COMPUT VIS PATT, P37, DOI 10.1007/978-3-319-58347-1_2
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang Y, 2020, AAAI CONF ARTIF INTE, V34, P12265
   Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58
   Wu CY, 2019, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2019.00037
   Yang XT, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P963, DOI 10.1145/2733373.2806375
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 39
TC 3
Z9 4
U1 9
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104238
DI 10.1016/j.imavis.2021.104238
EA JUN 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900006
DA 2024-07-18
ER

PT J
AU Tan, J
   Zhang, TP
   Zhao, LC
   Luo, XL
   Tang, YY
AF Tan, Jin
   Zhang, Taiping
   Zhao, Linchang
   Luo, Xiaoliu
   Tang, Yuan Yan
TI A robust image representation method against illumination and occlusion
   variations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Geometrical structure; Sparse coding; Illumination analysis; Occlusion
ID FACE RECOGNITION; DICTIONARY; REGRESSION; SPARSITY
AB Matrix data has arised in many field, especially in the field of image processing and computer vision. In traditional approaches, the original images need to be vectorized to one-dimension vectors, which may destroy the inherent structure of images. A novel geometrical sparse representation (GSR) model with single image is introduced in this paper that solves a model to measure the similarity between the input image and the single dictionary image. Unlike the traditional sparse representation model, the proposed model does not need to vectorize the image, so as to preserve the inherent geometrical structure of the image. We further introduce a binary coding method to preserve the local patterns of the image and enhance the sparsity of the GSR coefficients. Our method is used for face images with variations of structural noise (occlusion, illumination, etc.), extensive experiments show that our method can be competitive with or even superior to the baseline methods. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Tan, Jin; Zhang, Taiping; Zhao, Linchang; Luo, Xiaoliu] Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
   [Tan, Jin] Chongqing Jiaotong Univ, Sch Informat Sci & Engn, Chongqing, Peoples R China.
   [Tang, Yuan Yan] Zhuhai UM Sci & Technol Res Inst, Zhuhai, Peoples R China.
C3 Chongqing University; Chongqing Jiaotong University
RP Zhang, TP (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
EM tpzhang@cqu.edu.cn
FU National Natural Science Foundation of China [62076043]; Humanities and
   Social Sciences projects of the Ministry of Education, China
   [20YJAZH132]; Science and Technology Research Project of Chongqing
   Municipal Education Commission of China P.R. [KJZD-K201800701]; 2018
   Team Building Project for Graduate Tutors in Chongqing [JDDSTD2018001]
FX The authors would like to thank the anonymous reviewers for their
   comments and constructive suggestions that helped improve this paper.
   This work was supported in part by the National Natural Science
   Foundation of China under Grant 62076043, in part by the Humanities and
   Social Sciences projects of the Ministry of Education, China under Grant
   20YJAZH132, in part by the the Science and Technology Research Project
   of Chongqing Municipal Education Commission of China P.R. under Grant
   KJZD-K201800701, and in part by the 2018 Team Building Project for
   Graduate Tutors in Chongqing under Grant JDDSTD2018001.
CR Ahonen T., 2008, 19th Intl. Conf. on Pattern Recognition, P1, DOI DOI 10.1109/ICPR.2008.4761847
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Berthold KP, 1974, Comput. Graph. Image Process., V3, P277, DOI [DOI 10.1016/0146-664X(74)90022-7, 10.1016/0146-664X(74)90022-7]
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gao SH, 2014, IEEE T IMAGE PROCESS, V23, P623, DOI 10.1109/TIP.2013.2290593
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Han H, 2013, PATTERN RECOGN, V46, P1691, DOI 10.1016/j.patcog.2012.11.022
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Heinsohn D, 2019, IMAGE VISION COMPUT, V85, P46, DOI 10.1016/j.imavis.2019.02.012
   Hou CP, 2017, IEEE T IMAGE PROCESS, V26, P4255, DOI 10.1109/TIP.2017.2713948
   Huang G.B., NIPS 2012, P764
   Lai J, 2013, INT CONF ACOUST SPEE, P2979, DOI 10.1109/ICASSP.2013.6638204
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Naseem I, 2012, PATTERN RECOGN, V45, P104, DOI 10.1016/j.patcog.2011.07.003
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Qian JJ, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107204
   Qian JJ, 2015, PATTERN RECOGN, V48, P3145, DOI 10.1016/j.patcog.2015.04.017
   Ren CX, 2014, IEEE T IMAGE PROCESS, V23, P725, DOI 10.1109/TIP.2013.2292560
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Rigamonti R, 2014, COMPUT VIS IMAGE UND, V125, P115, DOI 10.1016/j.cviu.2014.03.009
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Sivalingam R, 2014, IEEE T PATTERN ANAL, V36, P592, DOI 10.1109/TPAMI.2013.143
   Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun YB, 2014, IEEE T IMAGE PROCESS, V23, P3816, DOI 10.1109/TIP.2014.2331760
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Trigueros DS, 2018, IMAGE VISION COMPUT, V79, P99, DOI 10.1016/j.imavis.2018.09.011
   Wan WT, 2017, IEEE IMAGE PROC, P3795, DOI 10.1109/ICIP.2017.8296992
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wang HT, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P819
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie JC, 2017, IEEE T IMAGE PROCESS, V26, P2286, DOI 10.1109/TIP.2017.2662213
   Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218
   Yang M, 2013, IEEE T NEUR NET LEAR, V24, P900, DOI 10.1109/TNNLS.2013.2245340
   Yu YF, 2017, PATTERN RECOGN, V67, P201, DOI 10.1016/j.patcog.2017.02.004
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang WM, 2019, IEEE T PATTERN ANAL, V41, P611, DOI 10.1109/TPAMI.2018.2803179
   Zhang YMZ, 2013, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2013.93
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
NR 46
TC 5
Z9 5
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104212
DI 10.1016/j.imavis.2021.104212
EA MAY 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100008
DA 2024-07-18
ER

PT J
AU Awan, M
   Shin, J
AF Awan, Mehwish
   Shin, Jitae
TI Semantic video segmentation with dynamic keyframe selection and
   distortion-aware feature rectification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic video segmentation; Feature warping; Distortion-aware feature
   correction; Policy network; Dynamic keyframe selection scheme;
   Reinforcement learning; Deep learning
AB The per-frame segmentation methods have a high computational cost, thereby, these methods are insufficient to cope with the fast inference need of semantic video segmentation. To efficaciously reuse the extracted features by feature propagation, in this paper, we present distortion-aware feature rectification and online selection of keyframes for fast and accurate video segmentation. The proposed dynamic keyframe scheduling scheme is based on the extent of temporal variations using reinforcement learning. We employ policy gradient reinforcement strategy to learn policy function for maximizing the expected reward. The policy network has two actions (key and non-key) in the action space. State information is derived from the element-wise difference frame of the current frame and the warped current frame generated by the propagated previous frame. Afterward, an adaptive partial feature rectification with distortion-aware corrections is performed for the warped features of the non-key frames. Precise feature propagation is a critical task to uphold the temporal updates in the video sequence since it enormously affects the accuracy as well as the throughput of the whole video analysis framework. The distorted feature maps are revised with the light-weight feature extractor by the guidance of the distortion map while the correctly propagated features are not influenced. Deep feature flow approach is adopted for feature propagation. We evaluate our scheme on the Cityscapes and CamVid datasets with DeepLabv3 as segmentation network and LiteFlowNet for computing flow fields. Experimental results show that the proposed method outperforms the previous state-of-the-art methods significantly both in terms of accuracy and throughput. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Awan, Mehwish] Sungkyunkwan Univ, Dept Elect & Comp Engn, Suwon 16419, South Korea.
   [Shin, Jitae] Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 16419, South Korea.
C3 Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU)
RP Shin, J (corresponding author), Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 16419, South Korea.
EM jtshin@skku.edu
FU National Research Foundation of Korea (NRF) - Korea Government (MSIT)
   [2020R1F1A1065626]; SIT (Ministry of Science and ICT), Korea, under the
   Information Technology Research Center (ITRC) support program
   [IITP-2021-2018-0-01798]
FX This work was partly supported by the National Research Foundation of
   Korea (NRF) grant funded by the Korea Government (MSIT) (No.
   2020R1F1A1065626) and was partly supported by the SIT (Ministry of
   Science and ICT), Korea, under the Information Technology Research
   Center (ITRC) support program (IITP-2021-2018-0-01798) supervised by the
   Institute for Information & communications Technology Promotion (IITP).
CR Awan Mehwish, 2020, PROC IEEE INT C CONS, P1
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Feng J., 2020, IEEE T PATTERN ANAL
   Gadde R, 2017, IEEE I CONF COMP VIS, P4463, DOI 10.1109/ICCV.2017.477
   He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2012, NEURAL NETWORKS MACH, V14, P8
   Hu P., 2020, CVPR, P8818
   Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936
   Jain S, 2019, PROC CVPR IEEE, P8858, DOI 10.1109/CVPR.2019.00907
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li JY, 2019, IEEE ACCESS, V7, P140680, DOI 10.1109/ACCESS.2019.2943365
   Li YL, 2018, PROC CVPR IEEE, P5997, DOI 10.1109/CVPR.2018.00628
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shuai B, 2016, PROC CVPR IEEE, P3620, DOI 10.1109/CVPR.2016.394
   Wang HJ, 2020, Cambria Sinophone Wo, P111, DOI 10.1109/CVPRW50498.2020.00020
   Wang YJ, 2020, PROC CVPR IEEE, P6957, DOI 10.1109/CVPR42600.2020.00699
   Xu YS, 2018, PROC CVPR IEEE, P6556, DOI 10.1109/CVPR.2018.00686
   Yifan Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P352, DOI 10.1007/978-3-030-58607-2_21
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441
   Zhuang JF, 2021, IEEE T CIRC SYST VID, V31, P3128, DOI 10.1109/TCSVT.2020.3037234
NR 33
TC 5
Z9 5
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104184
DI 10.1016/j.imavis.2021.104184
EA APR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700009
DA 2024-07-18
ER

PT J
AU Tan, JG
   Wang, KR
   Chen, LL
   Zhang, GH
   Li, JM
   Zhang, XL
AF Tan, Jingang
   Wang, Kangru
   Chen, Lili
   Zhang, Guanghui
   Li, Jiamao
   Zhang, Xiaolin
TI HCFS3D: Hierarchical coupled feature selection network for 3D semantic
   and instance segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Point clouds; Semantic segmentation; Instance segmentation; Feature
   selection; Mutual assistance; Conditional random fields
AB Semantic segmentation and instance segmentation based on 3D point clouds involve significant challenges, specifically in the task of joint semantic and instance segmentation. The efficient and effective mutual assistance between semantic and instance segmentation is rarely considered and still remains an unaddressed research problem. To address this, herein, a novel and robust 3D point cloud segmentation framework employing hierarchical coupled feature selection, named HCFS3D, is proposed; this framework can jointly and reciprocally perform semantic and instance segmentation. The framework is designed to promote these two tasks to exploit beneficial information from each other, on a shallow as well as a deep level. Moreover, to prevent the network from overfitting and to improve performance, we designed a loss function called the Adaptive Smooth Loss, which can adaptively assign different weights to samples that are difficult to segment. Furthermore, joint semantic and instance conditional random fields are included in the proposed framework to further improve its performance. Extensive experiments based on different datasets and various backbone networks demonstrate that HCFS3D outperforms other state-of-the-art methods. (c) 2021 Published by Elsevier B.V.
C1 [Tan, Jingang; Wang, Kangru; Chen, Lili; Zhang, Guanghui; Li, Jiamao; Zhang, Xiaolin] Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Shanghai 200050, Peoples R China.
   [Tan, Jingang; Chen, Lili; Zhang, Guanghui; Li, Jiamao; Zhang, Xiaolin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Zhang, Xiaolin] ShanghaiTech Univ, Shanghai 201210, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Institute of Microsystem &
   Information Technology, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS; ShanghaiTech University
RP Chen, LL (corresponding author), Chinese Acad Sci, Biovis Syst Lab, Shanghai Inst Microsyst & Informat Technol, Shanghai 200050, Peoples R China.
EM lilichen@mail.sim.ac.cn
OI Zhang, Guanghui/0000-0003-0432-7329
FU National Key R&D Plan of the Ministry of Science and Technology [2017Y
   FC0805502]; National Natural Science Foundation of China [61806189];
   Shanghai Municipal Science and Technology Major Project [2018 SHZDZX01]
FX This work was supported by the National Key R&D Plan of the Ministry of
   Science and Technology (Grant No. 2017Y FC0805502) , the National
   Natural Science Foundation of China (Grant No. 61806189) , and Shanghai
   Municipal Science and Technology Major Project (Grant No. 2018 SHZDZX01,
   ZHANGJIANG LAB) .
CR [Anonymous], 2017, CVPR
   [Anonymous], 2015, NIPS
   [Anonymous], 2017, ICCV
   [Anonymous], 2015, P 2015 IEEE C COMPUT
   [Anonymous], 2018, CVPR
   [Anonymous], 2016, ARXIV160308678
   [Anonymous], 2019, CVPR
   [Anonymous], 2018, CVPR
   [Anonymous], 2017, NEURIPS
   Armeni I, 2016, PROC CVPR IEEE, P1534, DOI 10.1109/CVPR.2016.170
   Arnay R., 2014, IVC
   Aung AT, 2020, PHYTOKEYS, P3, DOI 10.3897/phytokeys.138.38674
   Ba LJ, 2015, 2015 IEEE International Conference on Applied Superconductivity and Electromagnetic Devices (ASEMD), P3, DOI 10.1109/ASEMD.2015.7453438
   Bolya D., 2019, ARXIV PREPRINT
   Bruna J., 2013, SPECTRAL NETWORKS LO
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen S., 2019, ICIP
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   De Brabandere B., 2017, SEMANTIC INSTANCE SE
   Du L., 2020, ICRA
   Du L., 2018, WEAKLY SUPERVISED DE
   Du L, 2019, IEEE I CONF COMP VIS, P982, DOI 10.1109/ICCV.2019.00107
   Enewold Lindsey, 2020, Journal of the National Cancer Institute Monographs, P3, DOI 10.1093/jncimonographs/lgz029
   Engelmann F., 2017, ICCV
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guanghui Z., 2020, IROS
   He J., 2019, CVPR
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Hou J, 2019, PROC CVPR IEEE, P4416, DOI 10.1109/CVPR.2019.00455
   Hu Q., 2020, CVPR
   Hu YH, 2019, EURASIP J INF SECUR, DOI 10.1186/s13635-019-0086-2
   Huang J., 2016, ICPR
   Huang QG, 2018, PROC CVPR IEEE, P2626, DOI 10.1109/CVPR.2018.00278
   Komarichev A, 2019, PROC CVPR IEEE, P7413, DOI 10.1109/CVPR.2019.00760
   Lahoud J., 2019, 3D INSTANCE SEGMENTA
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Lei H., 2019, CVPR
   Li H., 2019, CVPR
   Li YY, 2018, ADV NEUR IN, V31
   LIU C, 2019, MASC MULTISCALE AFFI
   Liu Y., 2019, CVPR
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Ma Y., 2017, EFFICIENT ROTATION E
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Meng G., 2019, ICCV
   Pham Q.H., 2019, Jsis3d: Joint semantic-instance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields
   Pujol-Miro A., 2019, CORRES MATCHING UNOR
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Ren M., 2018, CVPR
   Ren MY, 2017, PROC CVPR IEEE, P293, DOI 10.1109/CVPR.2017.39
   Rethage D., 2018, ECCV
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tan J., 2020, SASO JOINT 3D SEMANT
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Toldo M., 2020, UNSUPERVISED IMAGE S
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P56, DOI 10.1007/978-3-030-01225-0_4
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang W., 2020, POINT CLOUD CLASSIFI
   Wang X., 2019, ASSOCIATIVELY SEGMEN
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang Z., 2019, VOXSEGNET VOLUMETRIC
   Wolf D, 2015, IEEE INT CONF ROBOT, P4867, DOI 10.1109/ICRA.2015.7139875
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Xu Y, 2018, ADV SOC SCI EDUC HUM, V284, P87
   Yang B, 2019, R RES LANDSCAPE ENV, P3
   Ye X., 2018, ECCV
   Yi L., 2016, SCALABLE ACTIVE FRAM
   Yi L, 2019, PROC CVPR IEEE, P3942, DOI 10.1109/CVPR.2019.00407
   Zhang Y., 2020, DEEP MULTIMODAL FUSI
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhuo W., 2017, CVPR
NR 77
TC 2
Z9 3
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104129
DI 10.1016/j.imavis.2021.104129
EA MAR 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600002
DA 2024-07-18
ER

PT J
AU Jia, FW
   Wang, X
   Guan, J
   Li, HL
   Qiu, C
   Qi, SH
AF Jia, Fengwei
   Wang, Xuan
   Guan, Jian
   Li, Huale
   Qiu, Chen
   Qi, Shuhan
TI WRGPruner: A new model pruning solution for tiny salient object
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Model compression; Model pruning; Salient objects detection; Small
   objects detection; Computer vision
AB The model pruning is one of the predominant model compression tasks to decrease the demands in computing power and memory footprint. However, most existing pruning methods have overly broad application areas, which defects in a sub-optimal solution specifically to solve certain specified difficult problems in the tasks of salient object detection. In this paper, we propose a novel solution, dubbed as WRGPruner, based on the concept of salient energy level (SEL) for tiny salient object detection. The concept of SEL defines the level of assessing the distinguishing ability of parameters in the trained model between background and salient objects. To exploit the SEL, the WRGPruner is proposed, which considers three factors for model compression including the weight in the filter, the mathematical rank of the feature map matrix, and the gradient in the backward propagation. We mathematically prove the effectiveness of the WRGPruner for tiny salient objects. Besides, a tiny salient object dataset (TSOD) is constructed for evaluation. Extensive experiments show that WRGPruner reduces 60% of parameters with slight enhancement in terms of six accuracy metrics for VGG16 on TSOD. This demonstrates that the SEL is suitable for measure parameters and the effectiveness of WRGPruner.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Jia, Fengwei; Wang, Xuan; Li, Huale; Qiu, Chen; Qi, Shuhan] Harbin Inst Technol, Comp Applicat Res Ctr, Shenzhen 518055, Peoples R China.
   [Guan, Jian] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 155100, Peoples R China.
C3 Harbin Institute of Technology; Harbin Engineering University
RP Qi, SH (corresponding author), Harbin Inst Technol, Comp Applicat Res Ctr, Shenzhen 518055, Peoples R China.
EM qishuhanhit@foxmail.com
FU National Key-Research and Development Program of China [2020YFB2104003];
   National Natural Science Foundation of China [61902093]; Natural Science
   Foundation of Guangdong [2020A1515010652]; Shenzhen Foundational
   Research Funding Under Grant [JCYJ20180306171938767]
FX This research was funded by National Key-Research and Development
   Program of China (No. 2020YFB2104003), National Natural Science
   Foundation of China (No. 61902093), Natural Science Foundation of
   Guangdong (No. 2020A1515010652), Shenzhen Foundational Research Funding
   Under Grant (No. JCYJ20180306171938767).
CR [Anonymous], 2016, PRUNING CONVOLUTIONA
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Chen TY, 2004, LECT NOTES COMPUT SC, V3321, P320
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Einhäuser W, 2003, EUR J NEUROSCI, V17, P1089, DOI 10.1046/j.1460-9568.2003.02508.x
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Frankle J., 2018, ARXIV180303635
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Ghosh S, 2019, IEEE IMAGE PROC, P3915, DOI [10.1109/icip.2019.8803505, 10.1109/ICIP.2019.8803505]
   Gong Y., 2014, INT C LEARN REPR ICL
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Hanson S. J., 1989, Advances in Neural Information Processing Systems, P177
   Hassibi B., 1993, P ADV NEUR INF PROC, P164
   He J, 2020, NEUROCOMPUTING, V390, P248, DOI 10.1016/j.neucom.2019.07.103
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Ignatov A, 2020, IEEE COMPUT SOC CONF, P1676, DOI 10.1109/CVPRW50498.2020.00217
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kaveti P., 2020, ARXIV200311076
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lee N., 2019, ARXIV190606307
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liebenwein L., 2019, ARXIV191107412
   Lin MB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P673
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Lin Tao, 2020, ARXIV200607253
   Liu Ning, 2019, ARXIV190703141
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z., 2018, INT C LEARN REPR
   Malach E., 2020, ICML
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Parra-Arnau J, 2017, INFORM SCIENCES, V385, P96, DOI 10.1016/j.ins.2016.12.036
   Renda Alex, 2020, INT C LEARN REPR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shu H, 2019, IEEE I CONF COMP VIS, P3234, DOI 10.1109/ICCV.2019.00333
   Simonyan K., 2014, 14091556 ARXIV
   Singh P, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103857
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Touretzky David S, 1996, Advances in Neural Information Processing Systems 8: Proceedings of the 1995 Conference, V8
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang M., 2019, P ICLR 2020 8 INT C
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhou H., 2019, ADV NEUR IN
NR 50
TC 4
Z9 4
U1 2
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104143
DI 10.1016/j.imavis.2021.104143
EA MAR 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600004
DA 2024-07-18
ER

PT J
AU Ma, YC
   Liu, YJ
   Xie, Q
   Xiong, SW
   Bai, LH
   Hu, AS
AF Ma, Yanchun
   Liu, Yongjian
   Xie, Qing
   Xiong, Shengwu
   Bai, Lihua
   Hu, Anshu
TI A Tibetan Thangka data set and relative tasks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image data set; Thangka data set; Tibetan culture; Semantic content
   analysis; Image processing
AB Data set of high quality is the cornerstone of the current data-driven machine learning models, and plays an important role in promoting the development of various application areas. At present, image analysis and processing techniques have intensively involved into the tasks of inheriting and protecting culture resources. However, currently there are few effective image data sets about the traditional Chinese Tibetan culture. In this work, we provided a small data set referred as CYTKv1(Chomo Yarlung Tibet version 1) which includes 1700+ Thangka images (an important and representative carrier of Chinese Tibetan culture), and the main objects in each image are manually labeled and bounding-boxed with semantic words. In addition, we shared a list of tasks of processing and analyzing the Thangkas to enlighten researchers about the challenges and potential applications on this data set. At last, we tested several famous deep learning models for the purpose of validating the annotation task on the new data set and presented the results of them, and finally selected the best one as the baseline for the annotation task.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Ma, Yanchun; Liu, Yongjian; Xie, Qing; Xiong, Shengwu; Bai, Lihua; Hu, Anshu] Wuhan Univ Technol, Sch Comp Sci & Technol, 122 Luoshi Rd, Wuhan, Hubei, Peoples R China.
   [Hu, Anshu] Chomo Yarlung Tibet Ltd, 1F Bldg 12, Lhasa, Tibet, Peoples R China.
C3 Wuhan University of Technology
RP Xie, Q (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Technol, 122 Luoshi Rd, Wuhan, Hubei, Peoples R China.
EM mayanchun@whut.edu.cn; liuyj@whut.edu.cn; felixxq@whut.edu.cn;
   xiongsw@whut.edu.cn; bailh@whut.edu.cn; huanshu@yarlung.cn
RI Xiong, Shou-Mei/A-4225-2009
FU Fundamental Research Funds for the Central Universities [WUT:2017YB028]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (WUT:2017YB028) .
CR [Anonymous], 2020, DANBOORU2019 LARGE S
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Griffin G., 2007, CALTECH 256 OBJECT C
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou F, 2020, IEEE T VIS COMPUT GR, V26, P1361, DOI 10.1109/TVCG.2018.2867478
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Rajpurkar P, 2017, 171206957 ARXIV
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang Yang, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P418
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
NR 18
TC 6
Z9 6
U1 2
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104125
DI 10.1016/j.imavis.2021.104125
EA FEB 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600005
DA 2024-07-18
ER

PT J
AU Pasqualino, G
   Furnari, A
   Signorello, G
   Farinella, GM
AF Pasqualino, Giovanni
   Furnari, Antonino
   Signorello, Giovanni
   Farinella, Giovanni Maria
TI An unsupervised domain adaptation scheme for single-stage artwork
   recognition in cultural sites
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Cultural sites; First person vision; Unsupervised
   domain adaptation
ID RETRIEVAL
AB Recognizing artworks in a cultural site using images acquired from the user's point of view (First Person Vision) allows to build interesting applications for both the visitors and the site managers. However, current object detection algorithms working in fully supervised settings need to be trained with large quantities of labeled data, whose collection requires a lot of times and high costs in order to achieve good performance. Using synthetic data generated from the 3D model of the cultural site to train the algorithms can reduce these costs. On the other hand, when these models are tested with real images, a significant drop in performance is observed due to the differences between real and synthetic images. In this study we consider the problem of Unsupervised Domain Adaptation for object detection in cultural sites. To address this problem, we created a new dataset containing both synthetic and real images of 16 different artworks. We hence investigated different domain adaptation techniques based on one-stage and two-stage object detector, image-to-image translation and feature alignment. Based on the observation that single-stage detectors are more robust to the domain shift in the considered settings, we proposed a new method which builds on RetinaNet and feature alignment that we called DA-RetinaNet. The proposed approach achieves better results than compared methods on the proposed dataset and on Cityscapes. To support research in this field we release the dataset at the following link https://iplab.dmi.unict.it/EGO-CH-OBJUDA/ and the code of the proposed architecture at https://github.com/fpv-iplab/DA-RetinaNet.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Pasqualino, Giovanni; Furnari, Antonino; Farinella, Giovanni Maria] Univ Catania, Dept Math & Comp Sci, Catania, Italy.
   [Signorello, Giovanni; Farinella, Giovanni Maria] Univ Catania, CUTGANA, Catania, Italy.
   [Farinella, Giovanni Maria] CNR, ICAR CNR, Palermo, Italy.
C3 University of Catania; University of Catania; Consiglio Nazionale delle
   Ricerche (CNR); Istituto di Calcolo e Reti ad Alte Prestazioni
   (ICAR-CNR)
RP Farinella, GM (corresponding author), Univ Catania, Dept Math & Comp Sci, Catania, Italy.
EM gfarinella@dmi.unict.it
RI Signorello, Giovanni/L-7627-2015; Farinella, Giovanni Maria/L-8555-2015
FU project VALUE Visual Analysis for Localization and Understanding of
   Environments - PO FESR 2014/2020 - Azione 1.1.5 [08CT6209090207 - CUP
   G69J18001060007]; Piano di incentivi per la ricerca di Ateneo 2020/2022
   (Pia.ce.ri.) Linea 2 University of Catania; MIUR AIMAttrazione e
   Mobilita Internazionale Linea 1 [AIM1893589 - CUP E64118002540007]
FX This research is supported by the project VALUEVisual Analysis for
   Localization and Understanding of Environments (N. 08CT6209090207 - CUP
   G69J18001060007) - PO FESR 2014/2020 - Azione 1.1.5., by Piano di
   incentivi per la ricerca di Ateneo 2020/2022 (Pia.ce.ri.) Linea
   2University of Catania, and by MIUR AIMAttrazione e Mobilita
   Internazionale Linea 1 - AIM1893589 - CUP E64118002540007.
CR Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI [10.1109/ICRA.2019.8794387, 10.1109/icra.2019.8794387]
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cucchiara R, 2014, IEEE MULTIMEDIA, V21, P74, DOI 10.1109/MMUL.2014.19
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ganin Y., 2015, ICML
   Gonzalezgarcia A., 2018, ADV NEURAL INFORM PR, P1287
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2006, Adv Neural Inf Process Syst, V19
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503
   Kim T, 2019, PROC CVPR IEEE, P12448, DOI 10.1109/CVPR.2019.01274
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Murez Z, 2018, PROC CVPR IEEE, P4500, DOI 10.1109/CVPR.2018.00473
   Orlando SA, 2020, PATTERN RECOGN LETT, V133, P17, DOI 10.1016/j.patrec.2020.02.014
   Pasqualino G.M.F. Giovanni, 2020, INT C PATT REC ICPR
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Portaz M, 2017, IEEE INT CONF COMP V, P2383, DOI 10.1109/ICCVW.2017.281
   Ragusa F, 2020, PATTERN RECOGN LETT, V131, P150, DOI 10.1016/j.patrec.2019.12.016
   Ragusa F, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P381, DOI 10.5220/0007365503810392
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rozantsev Artem, 2018, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Saito K, 2019, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR.2019.00712
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Seidenari L, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092832
   Sun BC, 2017, ADV COMPUT VIS PATT, P153, DOI 10.1007/978-3-319-58347-1_8
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Varma S, 2013, 2013 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P299, DOI 10.1109/RAICS.2013.6745491
   Wu Y., 2019, DETECTRON2
   Xie RC, 2019, IEEE INT CONF COMP V, P3213, DOI 10.1109/ICCVW.2019.00401
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, P2223, DOI DOI 10.1109/ICCV.2017.244
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 40
TC 13
Z9 13
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104098
DI 10.1016/j.imavis.2021.104098
EA JAN 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RD1DC
UT WOS:000633227000007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, B
   Hu, H
   Zhang, CX
AF Wang, Bo
   Hu, Hao
   Zhang, Caixia
TI New insights on multi-solution distribution of the P3P problem
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE P3P problem; Multi-solution phenomenon; Root-solution relation; Toroid
ID POSE; VIEW
AB Traditionally, the P3P problemis solved by firstly transforming its 3 quadratic equations into a quartic one, then by locating the roots of the resulting quartic equation and verifying whether a root does really correspond to a true solution of the P3P problem itself. It is well known that a root of the quartic equation could correspond to 2, or 1, or even null solution at all to the P3P problem, and up to now, no explicit relationship between the P3P solution and the root of its quartic equation is available in the literature. In thiswork, we showthat when the optical center is outside of all the 6 toroids defined by the control point triangle, each positive root of the Grunert's quartic equationmust correspond to a true solution of the P3P problem, and the corresponding P3P problemcannot have a unique solution, it must have either 2 positive solutions or 4 positive solutions. In addition, we show that when the optical center passes through any one of the 3 toroids among these 6 toroids (except possibly for two concentric circles), the number of the solutions of the corresponding P3P problem always changes by 1, either increased by 1 or decreased by 1. Furthermore we showthat such changed solutions always locate in a small neighborhood of control points, hence the 3 toroids are critical surfaces of the P3P problem and the 3 control points are 3 singular points of solutions. A notable example is that when the optical center passes through the outer surface of the union of the 6 toroids from the outside to inside, the number of the solutions must always decrease by 1. Our results are the first in the literature to give an explicit and geometrically intuitive relationship between the P3P solutions and the roots of its quartic equation, aside its academic values, it could also act as some theoretical guidance for P3P practitioners to properly arrange their control points to avoid undesirable solutions. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Wang, Bo] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Hu, Hao] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90007 USA.
   [Zhang, Caixia] North China Univ Technol, Sci Coll, Beijing 100041, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; University of
   Southern California; North China University of Technology
RP Zhang, CX (corresponding author), North China Univ Technol, Sci Coll, Beijing 100041, Peoples R China.
EM zhangcx@ncut.edu.cn
FU National Key R&D Program of China [2016YFD0700100]; National Natural
   Science Foundation of China (NSFC) [61873264, 61421004, 61333015,
   61403373, 61503004]
FX This work was supported by National Key R&D Program of China under grant
   No.2016YFD0700100 and National Natural Science Foundation of China
   (NSFC) under grantNo.s (61873264, 61421004, 61333015, 61403373,
   61503004).
CR Faugere J.C., 2008, P TWENTYFIRST INT S, P79
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao XS, 2006, J MATH IMAGING VIS, V25, P79, DOI 10.1007/s10851-006-5149-6
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Grunert JA., 1841, Grunerts Archiv fur Mathematik und Physik, V1, P238
   HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352
   Jia Qingxuan, 2006, 2006 4th IEEE International Conference on Industrial Informatics, P1385
   Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Li SQ, 2011, INT J PATTERN RECOGN, V25, P627, DOI 10.1142/S0218001411008774
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   McGlove C., 2004, Manual of photogrametry
   Nistér D, 2007, J MATH IMAGING VIS, V27, P67, DOI 10.1007/s10851-006-0450-y
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Rieck Michael Q., 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P335
   Rieck MQ, 2018, J MATH IMAGING VIS, V60, P737, DOI 10.1007/s10851-018-0788-y
   Rieck MQ, 2014, J MATH IMAGING VIS, V48, P499, DOI 10.1007/s10851-013-0425-8
   Rieck MQ, 2012, J MATH IMAGING VIS, V42, P92, DOI 10.1007/s10851-011-0278-y
   Sun Feng-Mei, 2010, Acta Automatica Sinica, V36, P1213, DOI 10.3724/SP.J.1004.2010.01213
   Tang JL, 2008, LECT NOTES COMPUT SC, V5226, P422, DOI 10.1007/978-3-540-87442-3_53
   Wang B., 2015, T CASIA NLPR RV 2015
   Wolfe W. J., 2008, SPECIAL CASE SOLUTIO
   WOLFE WJ, 1991, IEEE T PATTERN ANAL, V13, P66, DOI 10.1109/34.67632
   Wu YH, 2006, J MATH IMAGING VIS, V24, P131, DOI 10.1007/s10851-005-3617-z
   Zhang Cai-Xia, 2007, Journal of Software, V18, P2100, DOI 10.1360/jos182100
   Zhang Cai-Xia, 2006, Acta Automatica Sinica, V32, P504
   Zhang CX, 2005, J COMPUT SCI TECH-CH, V20, P836, DOI 10.1007/s11390-005-0836-0
   Zhang M, 2009, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2009, P138
NR 28
TC 4
Z9 4
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104009
DI 10.1016/j.imavis.2020.104009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tiong, LCO
   Kim, ST
   Ro, YM
AF Tiong, Leslie Ching Ow
   Kim, Seong Tae
   Ro, Yong Man
TI Multimodal facial biometrics recognition: Dual-stream convolutional
   neural networks with multi-feature fusion layers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multimodal facial biometrics recognition; Deep multimodal learning;
   Dual-stream convolutional neural network; Network fusion layers
AB Facial recognition for surveillance applications still remains challenging in uncontrolled environments, especially with the appearances of masks/veils and different ethnicities effects. Multimodal facial biometrics recognition becomes one of the major studies to overcome such scenarios. However, to cooperate with multimodal facial biometrics, many existing deep learning networks rely on feature concatenation or weight combination to construct a representation layer to perform its desired recognition task. This concatenation is often inefficient, as it does not effectively cooperate with the multimodal data to improve on recognition performance. Therefore, this paper proposes using multi-feature fusion layers for multi modal facial biometrics, thereby leading to significant and informative data learning in dual-stream convolutional neural networks. Specifically, this network consists of two progressive parts with distinct fusion strategies to aggregate RGB data and texture descriptors for multimodal facial biometrics. We demonstrate that the proposed network offers a discriminative feature representation and benefits from the multi-feature fusion layers for an accuracy-performance gain. We also introduce and share a new dataset for multimodal facial biometric data, namely the Ethnic-facial dataset for benchmarking. In addition, four publicly accessible datasets, namely AR. FaceScrub, IMDB_WIKI, and YouTube Face datasets are used to evaluate the proposed network. Through our experimental analysis, the proposed network outperformed several competing networks on these datasets for both recognition and verification tasks. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Tiong, Leslie Ching Ow] Korea Inst Sci & Technol KIST, Computat Sci Res Ctr, 5 Hwarang Ro,14 Gil Seongbuk Gu, Seoul 02792, South Korea.
   [Kim, Seong Tae] Tech Univ Munich, Comp Aided Med Procedures, Boltzmanstr 3, D-85748 Garching, Germany.
   [Ro, Yong Man] Korea Adv Inst Sci & Technol KAIST, Image & Video Syst Lab, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Institute of Science & Technology (KIST); Technical University of
   Munich; Korea Advanced Institute of Science & Technology (KAIST)
RP Ro, YM (corresponding author), Korea Adv Inst Sci & Technol KAIST, Image & Video Syst Lab, 291 Daehak Ro, Daejeon 34141, South Korea.
EM ymro@kaist.ac.kr
RI Kim, Seong Tae/N-8137-2019; Ro, Yong Man/ABF-6817-2020; Tiong,
   Leslie/AAC-8535-2021
OI Kim, Seong Tae/0000-0002-2132-6021; Ro, Yong Man/0000-0001-5306-6853;
   Tiong, Leslie/0000-0003-3786-2117
FU Brain Korea 21 Plus Project
FX This work was supported by the Brain Korea 21 Plus Project.
CR [Anonymous], 1998, TECH REP
   [Anonymous], 2018, CASE STUDY IMPETUS C
   [Anonymous], 2018, ETHNIC FACIAL DATASE
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/d15-1303, 10.18653/v1/D15-1303]
   Anwer RM, 2018, ISPRS J PHOTOGRAMM, V138, P74, DOI 10.1016/j.isprsjprs.2018.01.023
   Bharati MH, 2004, CHEMOMETR INTELL LAB, V72, P57, DOI 10.1016/j.chemolab.2004.02.005
   Chen YR, 2016, EXPERT SYST APPL, V64, P93, DOI 10.1016/j.eswa.2016.07.009
   Chen ZH, 2018, ADV CIV ENG, V2018, DOI [10.1155/2018/4064362, 10.1109/EMBC.2018.8513089]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Goswami G, 2016, INFORM FUSION, V32, P3, DOI 10.1016/j.inffus.2015.06.007
   Grother P., 2018, TECH REP, DOI [10.6028/NISTNIR.8238., DOI 10.6028/NISTNIR.8238]
   Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu G., 2015, ICCV, P4321
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Kahou SE, 2016, J MULTIMODAL USER IN, V10, P99, DOI 10.1007/s12193-015-0195-2
   Klontz JC, 2013, COMPUTER, V46, P91, DOI 10.1109/MC.2013.377
   Koo JH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093040
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Latonero M., 2019, Digital identity in the migration refugee context: Italy case study
   Levi G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P503, DOI 10.1145/2823327.2823333
   Liu Y, 2018, MULTIMED TOOLS APPL, V77, P29407, DOI 10.1007/s11042-018-5691-4
   McKone E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49202-0
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Rhee SC, 2012, AESTHET PLAST SURG, V36, P1236, DOI 10.1007/s00266-012-9937-7
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   del Rio JS, 2016, COMPUT SECUR, V62, P49, DOI 10.1016/j.cose.2016.07.001
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonovsky Martin, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9902, P10, DOI 10.1007/978-3-319-46726-9_2
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Soleymani S, 2018, INT C PATT RECOG, P3469, DOI 10.1109/ICPR.2018.8545061
   Srivastava Neelam., 2012, The Postcolonial Gramsci, P1
   Struc V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/847680
   Tiong LCO, 2019, MULTIMED TOOLS APPL, V78, P22743, DOI 10.1007/s11042-019-7618-0
   Wang Y, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P239, DOI 10.1109/ICIVC.2017.7984553
   Wang ZX, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P370, DOI 10.1145/3078971.3078973
   White D, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139827
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Zablocki M., 2014, Journal of Theoretical and Applied Computer Science, V8, P13
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhang Q, 2018, IEEE T INF FOREN SEC, V13, P2897, DOI 10.1109/TIFS.2018.2833033
NR 45
TC 23
Z9 25
U1 2
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103977
DI 10.1016/j.imavis.2020.103977
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700007
DA 2024-07-18
ER

PT J
AU Raj, SS
   Prasad, MVNK
   Balakrishnan, R
AF Raj, S. Sridhar
   Prasad, Munaga V. N. K.
   Balakrishnan, Ramadoss
TI Deep manifold clustering based optimal pseudo pose representation
   (DMC-OPPR) for unsupervised person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Clustering; Pose estimation; Representation;
   Computer vision; Deep learning
ID NETWORK
AB Person re-identification (re-ID) is highly complex in a diverse surveillance environment. The existing person re ID methods are evaluated as a closed set problem with limited environmental variation. It is highly challenging to estimate the diverse poses of a dynamically crowded environment using the traditional unsupervised person re ID methods. To resolve this issue of handling complex diverse poses and camera angles, a contextual incremental multi-clustering based unsupervised person re-ID method have been proposed. Cam-pose based optimal similarity distance threshold is determined to label the unlabeled person re-ID images efficiently. Frequent intra and inter-camera pseudo pose sequences are represented with optimal distance threshold. This resolves the over fitting issue created by the dominant samples of an identity and reduces the source-target domain gap. The experimental results show the supremacy of our proposed method over the existing unsupervised person re-ID methods in handling complex poses and camera angles in an incremental self-learning diverse surveillance environment. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Raj, S. Sridhar; Balakrishnan, Ramadoss] Natl Inst Technol, Tiruchirappalli, Tamil Nadu, India.
   [Raj, S. Sridhar; Prasad, Munaga V. N. K.] Inst Dev & Res Banking Technol, Hyderabad, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Raj, SS (corresponding author), Natl Inst Technol, Tiruchirappalli, Tamil Nadu, India.; Raj, SS (corresponding author), Inst Dev & Res Banking Technol, Hyderabad, India.
EM sridharselva394@gmail.com; mvnkprasad@idrbt.ac.in; brama@nitt.edu
RI S, Sridhar Raj/AAV-5279-2021
OI S, Sridhar Raj/0000-0002-7609-4176; Balakrishnan,
   Ramadoss/0000-0003-3817-1510; Prasad, MVNK/0000-0002-5560-7649
CR Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Cho YJ, 2016, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2016.151
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Ge Y., 2020, ABS200306650 ARXIV, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Lavi D, 2018, ALTERNATIVE DISPUTE RESOLUTION AND DOMESTIC VIOLENCE: WOMEN, DIVORCE AND ALTERNATIVE JUSTICE, P1
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Liu HJ, 2020, NEUROCOMPUTING, V398, P11, DOI 10.1016/j.neucom.2020.01.089
   Liu JW, 2019, PROC CVPR IEEE, P7195, DOI 10.1109/CVPR.2019.00737
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Lu J, 2019, IEEE SIGNAL PROC LET, V26, P933, DOI 10.1109/LSP.2019.2913020
   Niu K, 2020, IEEE T IMAGE PROCESS, V29, P5542, DOI 10.1109/TIP.2020.2984883
   Peeters R, 2017, ANN COMPUT SECURITY, P1, DOI 10.1145/3134600.3134613
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Wan F., 2020, ARXIV PREPRINT ABS20, P1
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P3416, DOI 10.1109/TIP.2019.2959923
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Xian YQ, 2018, IET COMPUT VIS, V12, P1219, DOI 10.1049/iet-cvi.2018.5103
   Xiong F., 2018, ABS180711042 ARXIV, P1
   Xiong F, 2019, PROC SPIE, V11069, DOI 10.1117/12.2524386
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang Z, 2020, IEEE T FUZZY SYST, V28, P2875, DOI 10.1109/TFUZZ.2019.2949758
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao YR, 2020, NEUROCOMPUTING, V388, P246, DOI 10.1016/j.neucom.2019.12.115
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, ARXIV
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 39
TC 4
Z9 4
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2020
VL 101
AR 103956
DI 10.1016/j.imavis.2020.103956
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NP4HG
UT WOS:000570137900003
DA 2024-07-18
ER

PT J
AU Hong, DS
   Chen, HH
   Hsiao, PY
   Fu, LC
   Siao, SM
AF Hong, Dza-Shiang
   Chen, Hung-Hao
   Hsiao, Pei-Yung
   Fu, Li-Chen
   Siao, Siang-Min
TI CrossFusion net: Deep 3D object detection based on RGB images and point
   clouds in autonomous driving
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; 3D object detection; Data fusion; Autonomous driving
AB In recent years, accurate 3D detection plays an important role in a lot of applications. Autonomous driving, for instance, is one of typical representatives. This paper aims to design an accurate 3D detector that takes both LiDAR point clouds and RGB images as inputs according to the fact that both LiDAR and camera have their own merits. A deep novel end-to-end two-stream learnable architecture, CrossFusion Net, is designed to exploit features from both LiDAR point clouds as well as RGB images through a hierarchical fusion structure. Specifically, CrossFusion Net utilizes bird's eye view (BEV) of point clouds through projection. Besides, these two feature maps of different streams are fused through the newly introduced CrossFusion(CF) layer. The proposed CF layer transforms feature maps of one stream to another based on the spatial relationship between the BEV and RGB images. Additionally, we apply attention mechanism on the transformed feature map and the original one to automatically decide the importance of the two feature maps from the two sensors. Experiments on the challenging KITTI car 3D detection benchmark and BEV detection benchmark show that the presented approach outperforms the other state-of-the-art methods in average precision(AP), specifically, as well as outperforms UberATG-ContFuse [3] of 8% AP in moderate 3D car detection. Furthermore, the proposed network learns an effective representation in perception of circumstances via RGB feature maps and BEV feature maps. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Hong, Dza-Shiang; Chen, Hung-Hao; Fu, Li-Chen] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Hsiao, Pei-Yung] Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
   [Siao, Siang-Min] Automot Res & Testing Ctr, Touliu, Yunlin, Taiwan.
C3 National Taiwan University; National University Kaohsiung
RP Hsiao, PY (corresponding author), Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
EM pyhsiao@nuk.edu.tw
FU Ministry of Science and Technology (MOST), Taiwan ROC
   [108-2634-F-002-016, 108-2634-F-002-017, 105-2221-E-390-024-MY3,
   108-2221-E-390-019-MY3]; Center for AI & Advanced Robotics, National
   Taiwan University; Joint Research Center for AI Technology underMOST;
   All Vista Healthcare underMOST
FX This work was partially sponsored by the Ministry of Science and
   Technology (MOST), Taiwan ROC, under Project 108-2634-F-002-016,
   108-2634-F-002-017, 105-2221-E-390-024-MY3 and 108-2221-E-390-019-MY3.
   This research was also supported in part by the Center for AI & Advanced
   Robotics, National Taiwan University and the Joint Research Center for
   AI Technology and All Vista Healthcare underMOST.
CR [Anonymous], 2017, P IEEE C COMP VIS PA
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Chen XZ, 2015, ADV NEUR IN, V28
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Geiger A., 2012, CVPR
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Ku J, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P16, DOI 10.1109/CRV.2018.00013
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mousavian A, 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simony M., 2020, P EUR C COMP VIS ECC, P197
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826
   Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yao Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P764
   Yu SL, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON SAFETY, SECURITY AND RESCUE ROBOTICS (SSRR), P102, DOI 10.1109/SSRR.2017.8088147
   Zhou Y, 2017, ASIA CONTROL CONF AS, P1906, DOI 10.1109/ASCC.2017.8287465
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 31
TC 10
Z9 11
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2020
VL 100
AR 103955
DI 10.1016/j.imavis.2020.103955
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA MY9GX
UT WOS:000558728800008
DA 2024-07-18
ER

PT J
AU Liu, J
   Li, Q
   Cao, R
   Tang, WM
   Qiu, GP
AF Liu, Jun
   Li, Qing
   Cao, Rui
   Tang, Wenming
   Qiu, Guoping
TI A contextual conditional random field network for monocular depth
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Monocular depth estimation; Deep neural network; Skip connection;
   Conditional random field
AB Monocular depth estimation plays a crucial role in understanding 3D scene geometry and is a challenging computer vision task. Recently, deep convolutional neural networks have been applied to solve this problem. However, existing methods either directly exploiting RGB pixels which can introduce much noise into the depth map or utilizing over smoothed internal representation features which can cause blur in the depth map. In this paper, we propose a contextual CRF network (CCN) to tackle these issues. The new CCN adopts the popular encoder-decoder architecture with a new contextual CRF module (CCM) which is guided by the depth features and regularizes the information flow from the encoder layer to the corresponding layer in the decoder, thus can reduce the mismatch between the RGB pixel and the depth map cue while at the same time retain detail features to output a fine-grained depth map. Moreover, we propose a depth-guided loss function which pays a balanced attention to near and far pixels thus addressing the long-tailed distribution of depth information. We have conducted extensive experiments on three public datasets for monocular depth estimation. Results demonstrate that our proposed CCN achieves superior performances in terms of visual quality and competitive quantitative results when compared with state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Liu, Jun; Li, Qing; Cao, Rui; Tang, Wenming; Qiu, Guoping] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen, Peoples R China.
   [Liu, Jun; Li, Qing; Cao, Rui; Tang, Wenming; Qiu, Guoping] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.
   [Liu, Jun; Li, Qing; Cao, Rui; Tang, Wenming; Qiu, Guoping] Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen, Peoples R China.
   [Qiu, Guoping] Univ Nottingham, Sch Comp Sci, Nottingham, England.
C3 Shenzhen University; Shenzhen University; Shenzhen Institute of
   Artificial Intelligence & Robotics for Society; University of Nottingham
RP Qiu, GP (corresponding author), Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen, Peoples R China.
EM guoping.qiu@nottingham.ac.uk
RI Cao, Rui/AAL-3946-2020
OI Cao, Rui/0000-0002-1440-4175; Qiu, Guoping/0000-0002-5877-5648
CR [Anonymous], 2011, ADV NEURAL INF PROCE
   [Anonymous], ARXIV180504777
   [Anonymous], ARXIV161203928
   Cao YZH, 2018, IEEE T CIRC SYST VID, V28, P3174, DOI 10.1109/TCSVT.2017.2740321
   Chen W, 2016, ADV NEUR IN, V29
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Lafferty John, 2001, INT C MACH LEARN ICM
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Li B, 2018, PATTERN RECOGN, V83, P328, DOI 10.1016/j.patcog.2018.05.029
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu MM, 2014, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2014.97
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma FC, 2018, IEEE INT CONF ROBOT, P4796
   Pagliari D, 2015, SENSORS-BASEL, V15, P27569, DOI 10.3390/s151127569
   Pilzer A, 2018, INT CONF 3D VISION, P587, DOI 10.1109/3DV.2018.00073
   Puscas MM, 2019, INT CONF 3D VISION, P18, DOI 10.1109/3DV.2019.00012
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Xu D., 2017, NIPS, P3961, DOI [DOI 10.48550/ARXIV.1801.00524, 10.48550/arXiv.1801.00524]
   Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412
   Xu D, 2017, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2017.25
   Zhang ZY, 2018, LECT NOTES COMPUT SC, V11214, P238, DOI 10.1007/978-3-030-01249-6_15
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zoran D, 2015, IEEE I CONF COMP VIS, P388, DOI 10.1109/ICCV.2015.52
NR 44
TC 4
Z9 4
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2020
VL 98
AR 103922
DI 10.1016/j.imavis.2020.103922
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR9US
UT WOS:000536040700004
DA 2024-07-18
ER

PT J
AU Yang, AM
   Liu, HX
   Chen, YJ
   Zhang, CY
   Yang, K
AF Yang, Aimin
   Liu, Huixiang
   Chen, Yongjie
   Zhang, Chunying
   Yang, Ke
TI Digital video intrusion intelligent detection method based on narrowband
   Internet of Things and its application
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE NB-IoT; Video intrusion detection; Support vector machines
ID FEATURE-EXTRACTION; FACE RECOGNITION; SYSTEM; TECHNOLOGY; ALGORITHM;
   FRAMEWORK; NETWORK
AB This paper proposes a digital video intrusion detection method based on Narrow Band Internet of Things (NB-IoT), and establishes a digital video intrusion detection system based on NB-IoT network and SVM intelligent classification algorithm. Firstly, the image is preprocessed by gradation processing and threshold transformation to extract the HOG feature extraction of human intrusion behavior in digital video frame images. Then, combined with the human intrusion HOG feature data, the SVM intelligent algorithm is used to classify the human intrusion behavior, so as to accurately classify the movements of walking, jumping, running and waving in video surveillance. Finally, the performance analysis of the algorithm finds that the classification time, classification accuracy and classification false positive rate of the model are tested. The classification time is 40.8 s, the shortest is 27 s, the classification accuracy is 87.65%, and the lowest is 83.7%. The false detection rate is up to 15%, both of which are less than 20%, indicating that the classification method has good accuracy and stability. Comparing the algorithm with other algorithms, the intrusion sensitivity, intrusion specificity and training speed of the model are 93.6%, 94.3%, and 19 s, respectively, which are better than other methods, which indicates that the model has good detection performance in the experimental stage. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Yang, Aimin; Liu, Huixiang; Chen, Yongjie; Yang, Ke] North China Univ Sci & Technol, Key Lab Engn Calculat Tangshan City, Tangshan 063210, Peoples R China.
   [Yang, Aimin; Liu, Huixiang; Zhang, Chunying] North China Univ Sci & Technol, Coll Sci, Tangshan 063210, Peoples R China.
C3 North China University of Science & Technology; North China University
   of Science & Technology
RP Zhang, CY (corresponding author), North China Univ Sci & Technol, Coll Sci, Tangshan 063210, Peoples R China.
EM zchunying@ncst.edu.cn
RI Chen, Xupeng/KFA-5959-2024
FU National Natural Science Foundation of China [51674121]; Natural Science
   Foundation of Hebei Province [E2017209178]; Outstanding Youth Fund
   Project of North China University of Science and Technology [JQ201705]
FX This work was supported by the National Natural Science Foundation of
   China (No. 51674121), the Natural Science Foundation of Hebei Province
   (No. E2017209178) and the Outstanding Youth Fund Project of North China
   University of Science and Technology (No. JQ201705).
CR Alham NK, 2013, COMPUT MATH APPL, V66, P1920, DOI 10.1016/j.camwa.2013.07.015
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Beyene YD, 2017, IEEE WIREL COMMUN, V24, P26, DOI 10.1109/MWC.2017.1600418
   Chen PY, 2014, IEEE T INTELL TRANSP, V15, P656, DOI 10.1109/TITS.2013.2284666
   Cho Y, 2010, IEEE T CONSUM ELECTR, V56, P1997, DOI 10.1109/TCE.2010.5606357
   De-la-Torre M, 2015, PATTERN RECOGN, V48, P3385, DOI 10.1016/j.patcog.2015.05.008
   Ergin S, 2014, COMPUT BIOL MED, V51, P171, DOI 10.1016/j.compbiomed.2014.05.008
   Foody GM, 2004, REMOTE SENS ENVIRON, V93, P107, DOI 10.1016/j.rse.2004.06.017
   Fu HL, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10072488
   Han Y, 2018, COMPLEXITY, DOI 10.1155/2018/8079697
   Hasan R, 2017, IEEE INT SYMP CIRC S, P64
   Held C, 2012, COMPUTER, V45, P83, DOI 10.1109/MC.2012.97
   Hu PZ, 2010, MULTIMEDIA SYST, V16, P243, DOI 10.1007/s00530-010-0191-z
   Li J, 2019, J INTERNET TECHNOL, V20, P545, DOI 10.3966/160792642019032002021
   Ning ZL, 2018, IEEE INTERNET THINGS, V5, P1527, DOI 10.1109/JIOT.2017.2777480
   Passieux JC, 2015, INT J NUMER METH ENG, V102, P1670, DOI 10.1002/nme.4868
   Santamaria A. F, 2019, COOPERATIVE VIDEO SU
   Tan HL, 2014, IET COMPUT VIS, V8, P224, DOI 10.1049/iet-cvi.2012.0302
   Wei W, 2019, COMPUT NETW, V161, P210, DOI 10.1016/j.comnet.2019.04.017
   Wei W, 2019, PATTERN RECOGN, V92, P64, DOI 10.1016/j.patcog.2019.03.009
   Wei W, 2019, J INTERNET TECHNOL, V20, P39, DOI 10.3966/160792642019012001004
   Wei W, 2018, TELECOMMUN SYST, V67, P63, DOI 10.1007/s11235-017-0321-4
   Wu JH, 2018, COMPLEXITY, DOI 10.1155/2018/4824350
   Yang AM, 2018, IEEE ACCESS, V6, P63976, DOI 10.1109/ACCESS.2018.2877428
   Yang AM, 2019, J INTERNET TECHNOL, V20, P563, DOI 10.3966/160792642019032002023
   Yang AM, 2019, IEEE ACCESS, V7, P24204, DOI 10.1109/ACCESS.2019.2897131
   Yang AM, 2018, CHAOS SOLITON FRACT, V117, P215, DOI 10.1016/j.chaos.2018.09.028
   Yang AM, 2018, IEEE ACCESS, V6, P50187, DOI 10.1109/ACCESS.2018.2868951
   Yang JJ, 2014, ADV MATER RES-SWITZ, V889-890, P671, DOI 10.4028/www.scientific.net/AMR.889-890.671
   Zhang BL, 2006, ACTA PHYS SIN-CH ED, V55, P6399, DOI 10.7498/aps.55.6399
   Zhang L, 2017, IEEE COMMUN LETT, V21, P2206, DOI 10.1109/LCOMM.2017.2705710
NR 36
TC 9
Z9 9
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2020
VL 97
AR 103914
DI 10.1016/j.imavis.2020.103914
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR7TU
UT WOS:000535899900005
DA 2024-07-18
ER

PT J
AU Park, H
   Kim, D
AF Park, Hyunsung
   Kim, Daijin
TI A complementary regression network for accurate face alignment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial landmark detection; Complementary regression network;
   Coordinate-to-heatmap transform; Heatmap-to-coordinate transform
AB This paper proposes a complementary regression network (CRN) that combines global and local regression methods to align faces. A global regression network (GRN) generates the coordinates of facial landmark points directly such that all facial feature points are fitted to the input face on the whole and a local regression network (LRN) generates the heatmap of facial landmark points such that each channel localizes the detail of its facial landmark point well. The CRN converts the GRN's coordinates to another heatmap, then uses with the LRN's heatmap to get the final facial landmark points. The CRN works complementarily such that the GRN's overall fitting tendency compensates for the LRN's poor alignment caused by missing local information, whereas the LRN's detailed representation compensates for the GRN's poor alignment caused by global miss-fitting. We conducted several experiments on the 300-W public dataset, the 300-W private dataset, and the Menpo dataset and the proposed CRN achieved 3.14%, 3.74%, and 1.996% the-state-of-art face alignment accuracy in terms of percentage of normalized mean error, respectively. (C) 2020 Published by Elsevier B.V.
C1 [Park, Hyunsung; Kim, Daijin] POSTECH, Dept Comp Sci & Engn, San 31, Pohang 790784, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Kim, D (corresponding author), POSTECH, Dept Comp Sci & Engn, San 31, Pohang 790784, South Korea.
EM hyusung@postech.ac.kr; dkim@postech.ac.kr
FU MSIT (Ministry of Science, ICT), Korea, under the SW Starlab support
   program [IITP2017-0-00897]; National Research Foundation of Korea (NRF)
   - Korea government (MSIP) [2018R1A2B2002218]
FX This research was partially supported by the MSIT (Ministry of Science,
   ICT), Korea, under the SW Starlab support program (IITP2017-0-00897)
   supervised by the IITP (Institute for Information & Communications
   Technology Promotion). This work was also supported by the National
   Research Foundation of Korea (NRF) grant funded by the Korea government
   (MSIP) (No. 2018R1A2B2002218).
CR [Anonymous], 2016, P BRIT MACH VIS C
   [Anonymous], 2017, P CVPR FAC IN THE WI
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Baltrusaitis T, 2014, LECT NOTES COMPUT SC, V8692, P593, DOI 10.1007/978-3-319-10593-2_39
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Bulat A, 2017, IEEE I CONF COMP VIS, P3726, DOI 10.1109/ICCV.2017.400
   Bulat A, 2016, LECT NOTES COMPUT SC, V9914, P616, DOI 10.1007/978-3-319-48881-3_43
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dong X., 2018, C COMP VIS PATT REC, V2, P6
   Dong XY, 2018, PROC CVPR IEEE, P360, DOI 10.1109/CVPR.2018.00045
   Feng ZH, 2018, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2018.00238
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jin X, 2017, COMPUT VIS IMAGE UND, V162, P1, DOI 10.1016/j.cviu.2017.08.008
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2018, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2018.00052
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Merget D, 2018, PROC CVPR IEEE, P781, DOI 10.1109/CVPR.2018.00088
   Miao X, 2018, PROC CVPR IEEE, P5040, DOI 10.1109/CVPR.2018.00529
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tang ZQ, 2018, LECT NOTES COMPUT SC, V11207, P348, DOI 10.1007/978-3-030-01219-9_21
   Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453
   Valle R, 2018, LECT NOTES COMPUT SC, V11218, P609, DOI 10.1007/978-3-030-01264-9_36
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang J, 2017, IEEE COMPUT SOC CONF, P2025, DOI 10.1109/CVPRW.2017.253
   Yu HY, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1014, DOI 10.1109/ICInfA.2014.6932798
   Zafeiriou S, 2017, IEEE COMPUT SOC CONF, P2116, DOI 10.1109/CVPRW.2017.263
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhu X, 2014, GREEN CHEM SUSTAIN T, P1, DOI 10.1007/978-3-642-54646-4_1
NR 37
TC 4
Z9 4
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103883
DI 10.1016/j.imavis.2020.103883
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000005
DA 2024-07-18
ER

PT J
AU Wu, ZH
   Lin, GS
   Cai, JF
AF Wu, Zhonghua
   Lin, Guosheng
   Cai, Jianfei
TI Keypoint based weakly supervised human parsing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human parsing; Weakly supervise; Iterative refinement; Keypoint;
   Skeleton; Correlation network
AB Fully convolutional networks (FCN) have achieved great success in human parsing in recent years. In conventional human parsing tasks, pixel-level labeling is required for guiding the training, which usually involve enormous human labeling efforts. To ease the labeling efforts, we propose a novel weakly supervised human parsing method which only requires simple object keypoint annotations for learning. We develop an itertive learning method to generate pseudo part segmentation masks from keypoint labels. With these pseud masks, we train a FCN network to output pixel-level human parsing predictions. Furthermore, we develop correlation network to perform joint prediction of part and object segmentation masks and improve the segmentation performance. The experiment results show that our weakly supervised method is able to achies very competitive human parsing results. Despite that our method only uses simple keypoint annotatior for learning, we are able to achieve comparable performance with fully supervised methods which use the expensive pixel-level annotations. (C) 2019 Elsevier B.V. All rights reservesed
C1 [Wu, Zhonghua; Lin, Guosheng; Cai, Jianfei] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [Cai, Jianfei] Monash Univ, Fac IT, Clayton, Vic, Australia.
C3 Nanyang Technological University; Monash University
RP Wu, ZH (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
EM zhonghua001@e.ntu.edu.sg; gslin@ntu.edu.sg; Jianfei.cai@monash.edu
RI Wu, Zhonghua/AAI-9921-2020; Lin, Guosheng/Q-4024-2017; Cai,
   Jianfei/A-3691-2011
OI Lin, Guosheng/0000-0002-0329-7458; Cai, Jianfei/0000-0002-9444-3763
FU National Research Foundation, Singapore; Infocomm Media Development
   Authority, Singapore; MOE Tier-1 Grant of Singapore [ZG28/18]; National
   Research Foundation Singapore under its Al Singapore Programme
   [AISG-RP-2018-0031]; National Research Foundation Singapore under MOE
   Tier-1 research grant [2G126/17 (S)]
FX This research was partially carried out at the Rapid-Rich Object Search
   (ROSE) Lab at the Nanyang Technological University, Singapore. The ROSE
   Lab is supported by the National Research Foundation, Singapore, and the
   Infocomm Media Development Authority, Singapore. This research is also
   supported by MOE Tier-1 Grant ZG28/18) of Singapore. G. Lin's
   participation was supported by the National Research Foundation
   Singapore under its Al Singapore Programme [AISG-RP-2018-0031 and the
   MOE Tier-1 research grant [2G126/17 (S)].
CR [Anonymous], 2015, 3 INT C LEARN REPR I, DOI 10.3390/antiox4010068
   [Anonymous], ICCV
   Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen X., 2013, CVPR
   Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191
   Fang HS, 2018, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2018.00015
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Li J., 2018, ACM MULTIMEDIA
   Li R., CVPR
   Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Nguyen TV, 2015, IEEE T CIRC SYST VID, V25, P1565, DOI 10.1109/TCSVT.2014.2382982
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Shen T., 2017, BMVC
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tripathi S., ARXIV170401152
   Tsogkas S., 2013, ARXIV150502438
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vernaza P., 2017, CVPR, V3
   Wu Z., 2019, ACM MULT C MULT C
   Xia FT, 2017, PROC CVPR IEEE, P6080, DOI 10.1109/CVPR.2017.644
   Xia FT, 2016, LECT NOTES COMPUT SC, V9909, P648, DOI 10.1007/978-3-319-46454-1_39
   Xiu Y., 180200977 ARXIV
   Zhang T., ARXIV E PRINTS
NR 33
TC 13
Z9 14
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2019
VL 91
AR 103801
DI 10.1016/j.imavis.2019.08.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU3YI
UT WOS:000501614200007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shamsolmoali, P
   Zareapoor, M
   Zhang, JH
   Yang, J
AF Shamsolmoali, Pourya
   Zareapoor, Masoumeh
   Zhang, Junhao
   Yang, Jie
TI Image super resolution by dilated dense progressive network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image supper resolution; Dense network; Dilated convolution
ID SUPERRESOLUTION; REGRESSION
AB Image super-resolution (SR) is an interesting topic in computer vision. However, it remains challenging to achieve high-resolution image from the corresponding low-resolution version due to inherent variability, high dimensionality, and small ground targets images. In this paper, a new model based on dilated convolutional neural network is proposed to improve the image resolution. Recently, deep learning methods have led to significant improvements and completely outpace other models. However, these methods have not fully exploited all the features of the original low-resolution image, because of complex imaging conditions and the degradation process. To address this issue, we proposed an effective model based on dilated dense network operations to accelerate deep networks for image SR, which support the exponential growth of the receptive field parallel by increasing the filter size. In particular, residual network and skip connections are used for deep recovery. The experimental evaluations on several datasets prove the efficiency and stability of the proposed model. The proposed model not only achieves state-of-the-art performance but also has more efficient computation. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Shamsolmoali, Pourya; Zareapoor, Masoumeh; Zhang, Junhao; Yang, Jie] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM jieyang@sjtu.edu.cn
RI Zareapoor, Dr. Masoumeh/AAE-6067-2019; Yang, Jie/JCD-9867-2023
OI Zareapoor, Dr. Masoumeh/0000-0002-3991-0584; Zareapoor,
   Masoumeh/0000-0002-7569-9018
FU NSFC, China [61572315, 6151101179]; 973 Program, China [2015CB856004]
FX This research is partly supported by NSFC, China (Nos: 61572315,
   6151101179) and 973 Program, China (No. 201503856004).
CR Agustsson E., 2017, CVPRW
   Akhtar N., 2018, IEEE T PATTERN ANAL, V14
   Akhtar N, 2015, PROC CVPR IEEE, P3631, DOI 10.1109/CVPR.2015.7298986
   [Anonymous], 2017, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2012, BMVC
   [Anonymous], 2016, CVPR
   [Anonymous], 2013, MICCAI
   [Anonymous], ICIP
   [Anonymous], 2017, CVPRW
   [Anonymous], 2011, AISTATS
   [Anonymous], 2017, CVPR
   [Anonymous], 2018, ECCV
   [Anonymous], 2017, PROC IEEE C COMPUTER
   [Anonymous], 2016, ECCV
   [Anonymous], 2014, P EUR C COMP VIS ZUR
   [Anonymous], 2001, ICCV
   [Anonymous], 2010, ICML
   [Anonymous], 2018, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, CVPR
   Chen HG, 2018, SIGNAL PROCESS-IMAGE, V66, P1, DOI 10.1016/j.image.2018.04.012
   Chen H, 2017, IEEE T MED IMAGING, V36, P2524, DOI 10.1109/TMI.2017.2715284
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Cui P, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P901
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fisher Y, 2016, ICLR
   Galliani S., 2017, ARXIV170309470
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Jiang K, 2018, IEEE SIGNAL PROC LET, V25, P1630, DOI 10.1109/LSP.2018.2870536
   Lai W.-S., 2018, CVPR
   Ledig C., 2017, P IEEE C COMP VIS PA, P4681
   Mei SH, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111139
   Romano Y, 2017, IEEE T COMPUT IMAG, V3, P110, DOI 10.1109/TCI.2016.2629284
   Romera E, 2017, IEEE INT VEH SYM, P1789, DOI 10.1109/IVS.2017.7995966
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tong T, 2017, ICCV
   Wang P., 2017, Understanding Convolution for Semantic Segmentation
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao JS, 2017, SIGNAL PROCESS-IMAGE, V50, P21, DOI 10.1016/j.image.2016.11.001
   Zareapoor M, 2019, SIGNAL PROCESS-IMAGE, V74, P191, DOI 10.1016/j.image.2019.02.008
   Zeyde R, 2010, P 7 INT C CURV SURF
   Zhang CP, 2018, SIGNAL PROCESS-IMAGE, V67, P79, DOI 10.1016/j.image.2018.06.001
   Zhang Y., 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00262
   Zhu H, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020498
NR 45
TC 41
Z9 42
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 9
EP 18
DI 10.1016/j.imavis.2019.03.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400002
DA 2024-07-18
ER

PT J
AU Fu, K
   Xie, YJ
   Jing, HL
   Zhu, JP
AF Fu, Keren
   Xie, Yijiang
   Jing, Hailong
   Zhu, Jiangping
TI Fast spatial-temporal stereo matching for 3D face reconstruction under
   speckle pattern projection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face reconstruction; Stereo matching; Structured light; Speckle
   projection; Integral image
ID 3-DIMENSIONAL SHAPE MEASUREMENT; COST AGGREGATION
AB Three-dimensional (3D) face reconstruction can be tackled in either measurement-based means or model-based means. The former requires special hardwares or devices, such as structured light setups. This paper addresses 3D face reconstruction by measurement-based means, more specifically a special kind of structured light called space-time speckle projection. Under such a setup, we propose a novel and efficient spatial-temporal stereo scheme towards fast and accurate 3D face recovery. To improve the overall computational efficiency, our scheme consists of a series of optimization strategies including face-cropping-based stereo matching, coarse-to-fine stereo matching strategy applied to face areas, and spatial-temporal integral image (STII) for accelerating the matching cost computation. Based on the results, the proposed scheme is able to reconstruct a 3D face in hundreds of milliseconds on a normal PC, and its performance is validated both qualitatively and quantitatively. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Fu, Keren] Sichuan Univ, Coll Comp Sci, Chengdu, Sichuan, Peoples R China.
   [Xie, Yijiang; Jing, Hailong; Zhu, Jiangping] Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu, Sichuan, Peoples R China.
C3 Sichuan University; Sichuan University
RP Jing, HL (corresponding author), Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu, Sichuan, Peoples R China.
EM fkrsuper@scu.edu.cn
RI Fu, Keren/HPG-4742-2023
OI Fu, Keren/0000-0002-3195-2077
FU National Science Foundation of China [61703077]; Fundamental Research
   Funds for the Central Universities [YJ201755]; National Key Scientific
   Instrument and Equipment Development Projects of China [2013YQ490879];
   Sichuan Science and Technology Major Projects [2018GZDZX0029]
FX This research is partly supported by the National Science Foundation of
   China, under No. 61703077, the Fundamental Research Funds for the
   Central Universities No. YJ201755, the National Key Scientific
   Instrument and Equipment Development Projects of China (2013YQ490879),
   and the Sichuan Science and Technology Major Projects (2018GZDZX0029).
CR [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 2000, BMVC
   [Anonymous], 2012, PROC IEEE C COMPUTER
   [Anonymous], 2015, C COMP VIS PATT REC
   [Anonymous], P AS C COMP VIS, DOI DOI 10.1007/978-3-642-19315-6_3
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Chen YS, 2003, APPL OPTICS, V42, P1958, DOI 10.1364/AO.42.001958
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Dai JF, 2017, OPT EXPRESS, V25, P10384, DOI 10.1364/OE.25.010384
   Davis J., 2003, COMP VIS PATT REC 20, V2, P11
   Dellaert F, 2000, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2000.854916
   Fan X, 2016, CHIN OPT LETT, V14, DOI 10.3788/COL201614.081101
   Favaro P, 2005, IEEE T PATTERN ANAL, V27, P406, DOI 10.1109/TPAMI.2005.43
   Favaro P, 2008, IEEE T PATTERN ANAL, V30, P518, DOI 10.1109/TPAMI.2007.1175
   Finn N, 2010, PROCEEDING OF THE THIRD WORLD CONFERENCE ON 3D FABRICS AND THEIR APPLICATIONS, P29
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   Harendt B, 2014, APPL OPTICS, V53, P7507, DOI 10.1364/AO.53.007507
   Heist S, 2017, APPL OPTICS, V56, P2162, DOI 10.1364/AO.56.002162
   Hirschmüller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421
   Liu F, 2016, LECT NOTES COMPUT SC, V9909, P545, DOI 10.1007/978-3-319-46454-1_33
   Liu K, 2015, CHIN OPT LETT, V13, DOI 10.3788/COL201513.081101
   Loop C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P125, DOI 10.1109/CVPR.1999.786928
   Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13
   Mei X, 2013, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2013.47
   Mei X, 2011, PROC CVPR IEEE, P1257
   Parodi P, 1996, IEEE T PATTERN ANAL, V18, P211, DOI 10.1109/34.481545
   Peris M, 2012, INT C PATT RECOG, P1038
   Salvi J, 2010, PATTERN RECOGN, V43, P2666, DOI 10.1016/j.patcog.2010.03.004
   Schaffer M, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.11.112205
   Schaffer M, 2010, APPL OPTICS, V49, P3622, DOI 10.1364/AO.49.003622
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Wang GJ, 2013, APPL OPTICS, V52, P516, DOI 10.1364/AO.52.000516
   Wiegmann A, 2006, OPT EXPRESS, V14, P7692, DOI 10.1364/OE.14.007692
   Xue J., 2015, INT C EXP MECH
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Zeng D, 2017, IMAGE VISION COMPUT, V58, P193, DOI 10.1016/j.imavis.2016.03.001
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang K, 2014, PROC CVPR IEEE, P1590, DOI 10.1109/CVPR.2014.206
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 47
TC 24
Z9 24
U1 7
U2 58
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2019
VL 85
BP 36
EP 45
DI 10.1016/j.imavis.2019.02.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HZ9DE
UT WOS:000469155200004
DA 2024-07-18
ER

PT J
AU Mahbub, U
   Sarkar, S
   Chellappa, R
AF Mahbub, Upal
   Sarkar, Sayantan
   Chellappa, Rama
TI Partial face detection in the mobile domain
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial segment-based face detection; Deep convolutional neural network;
   Face proposal generation
ID USER AUTHENTICATION
AB Face detection algorithms do not perform well in the mobile domain due to significant presence of occluded and partially visible faces. One promising technique for handling the challenge of partial faces is to design face detectors based on facial segments. In this paper two different approaches of facial segment-based face detection are discussed, namely, proposal-based detection and detection by end-to-end regression. Methods that follow the first approach rely on generating face proposals that contain facial segment information. The three detectors following this approach, namely Facial Segment-based Face Detection (FSFD), SegFace and DeepSegFace, discussed in this paper, perform binary classification on each proposal based on features learned from facial segments. The process of proposal generation, however, needs to be handled separately, which can be very time consuming, and may not be necessary given the nature of the active authentication problem. Hence a novel algorithm, Deep Regression-based User Image Detector (DRUID) is proposed, which shifts from the classification to the regression paradigm, thus avoiding the proposal generation step. DRUID has an unique network architecture with customized loss functions, is trained using a relatively small amount of data by utilizing a novel data augmentation scheme and is fast since it outputs the bounding boxes of a face and its segments in a single pass. Being robust to occlusion by design, the facial segment-based face detection methods, especially DRUID show superior performance over other state-of-the-art face detectors in terms of precision-recall and ROC curve on two mobile face datasets. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Mahbub, Upal; Sarkar, Sayantan; Chellappa, Rama] Univ Maryland, UMIACS, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
   [Mahbub, Upal; Sarkar, Sayantan; Chellappa, Rama] Univ Maryland, UMIACS, Ctr Automat Res, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park;
   University System of Maryland; University of Maryland College Park
RP Mahbub, U (corresponding author), Univ Maryland, UMIACS, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
EM umahbub@umiacs.umd.edu; ssarkar2@umiacs.umd.edu; rama@umiacs.umd.edu
RI Mahbub, Upal/A-6550-2018; Chellappa, Rama/AAV-8690-2020
OI Mahbub, Upal/0000-0002-1861-8031; 
FU Google Advanced Technology and Projects (ATAP) [FA8750-13-2-0279]; DARPA
FX This work was done in partnership with and supported by Google Advanced
   Technology and Projects (ATAP), a Skunk Works inspired team chartered to
   deliver breakthrough innovations with end-to-end product development
   based on cutting edge research and a cooperative agreement
   FA8750-13-2-0279 from DARPA. The authors would also like to thank Rajeev
   Ranjan of University of Maryland, College Park, USA for providing the
   results for Hyper face and All-In-One networks and for his thoughtful
   suggestions and comments on the paper.
CR [Anonymous], 2010, SURVEY RECENT ADV FA
   Bileschi SM, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P149
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chan H., 1965, A man-machine facial recognition system: Some preliminary results
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Ge SM, 2017, PROC CVPR IEEE, P426, DOI 10.1109/CVPR.2017.53
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Li HX, 2014, PROC CVPR IEEE, P1843, DOI 10.1109/CVPR.2014.238
   Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67
   Li YZ, 2016, LECT NOTES COMPUT SC, V9907, P420, DOI 10.1007/978-3-319-46487-9_26
   Liao Shengcai, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P211, DOI 10.1109/TPAMI.2015.2448075
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mahbub U., 2016, 2016 IEEE 8th international conference on biometrics theory, applications and systems (BTAS)
   Mahbub U, 2017, IEEE INT CONF AUTOMA, P634, DOI 10.1109/FG.2017.80
   Mahbub U, 2016, IEEE IMAGE PROC, P2991, DOI 10.1109/ICIP.2016.7532908
   Marin-Jimenez MJ, 2014, INT J COMPUT VISION, V106, P282, DOI 10.1007/s11263-013-0655-7
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   McCool C., 2012, IEEE ICME WORKSH HOT
   Neverova N., ABS151103908 CORR
   Opitz M, 2016, LECT NOTES COMPUT SC, V9907, P386, DOI 10.1007/978-3-319-46487-9_24
   Patel VM, 2016, IEEE SIGNAL PROC MAG, V33, P49, DOI 10.1109/MSP.2016.2555335
   Ranjan R., ABS160301249 CORR
   Ranjan R., ABS161100851 CORR
   Ranjan Rajeev, 2017, Proceedings of the Indian National Science Academy Part B Biological Sciences, V87, P377, DOI 10.1007/s40011-015-0618-6
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S, 2015, FASTER R CNN REAL TI, P91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sakai T., 1973, SEMINAR, P55
   Samangouei P, 2016, INT CONF BIOMETR THE
   Sarkar P, 2016, 2016 INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL POWER AND INSTRUMENTATION (ICICPI), P1, DOI 10.1109/ICICPI.2016.7859662
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   van de Sande Koen E. A., 2011, IEEE I CONF COMP VIS
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   yeephycho, 2017, YEEPHYCHO TENSORFLOW
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhang H, 2015, IEEE WINT CONF APPL, P207, DOI 10.1109/WACV.2015.35
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 45
TC 7
Z9 7
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2019
VL 82
BP 1
EP 17
DI 10.1016/j.imavis.2018.12.003
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HU1RT
UT WOS:000465050200001
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Kumar, A
   Alavi, A
   Chellappa, R
AF Kumar, Amit
   Alavi, Azadeh
   Chellappa, Rama
TI KEPLER: Simultaneous estimation of keypoints and 3D pose of
   unconstrained faces in a unified framework by learning efficient H-CNN
   regressors
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Face alignment; Keypoints; Landmarks; Deep networks; Convolution Neural
   Networks
ID ALIGNMENT
AB Keypoint detection is one of the most important pre-processing steps in tasks such as face modeling, recognition and verification. In this paper, we present an iterative method for Keypoint Estimation and Pose prediction of unconstrained faces by Learning Efficient H-CNN Regressors (KEPLER) for addressing the unconstrained face alignment problem. Recent state-of-the-art methods have shown improvements in facial keypoint detection by employing Convolution Neural Networks (CNNs). Although a simple feed forward neural network can learn the mapping between input and output spaces, it does not learn the inherent structural dependencies that well. We present a novel architecture called H-CNN (Heatmap-CNN) acting on an N-dimensional input image which captures informative structured global and local features and thus favors accurate keypoint detecion in in-the wild face images. H-CNN is jointly trained on the visibility, fiducials and 3D-pose of the face. As the iterations proceed, the error decreases making the gradients small and thus requiring efficient training of deep networks to mitigate this. KEPLER performs global corrections in pose and fiducials for the first four iterations followed by local corrections at a later stage. As a byproduct, KEPLER also provides robust estimate of 3D pose (pitch, yaw and roll) of the face. We also show that without using any 3D information, KEPLER outperforms recent state-of-the-art methods for alignment on challenging datasets such as AFW [1] and AFLW [12]. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Kumar, Amit; Alavi, Azadeh; Chellappa, Rama] Univ Maryland, UMIACS, Ctr Automat Res, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Kumar, A (corresponding author), Univ Maryland, UMIACS, Ctr Automat Res, College Pk, MD 20742 USA.
EM akumar14@umiacs.umd.edu; azadeh@umiacs.umd.edu; rama@umiacs.umd.edu
RI Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012; Alavi,
   Azadeh/AAY-9063-2020
OI Alavi, Azadeh/0000-0002-9565-217X
FU Office of the Director of National Intelligence (ODNI), Intelligence
   Advanced Research Projects Activity (IARPA), via IARPA RD
   [2014-14071600012]
FX This research is based upon a work supported by the Office of the
   Director of National Intelligence (ODNI), Intelligence Advanced Research
   Projects Activity (IARPA), via IARPA R&D contract no. 2014-14071600012.
   The views and conclusions contained herein are those of the authors and
   should not be interpreted as necessarily representing the official
   policies or endorsements, either expressed or implied, of the ODNI,
   IARPA, or the U.S. Government. The U.S. Government is authorized to
   reproduce and distribute reprints for Governmental purposes
   notwithstanding any copyright annotation thereon.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2016, CVPR
   [Anonymous], ICCV
   [Anonymous], 1 IEEE INT WORKSH BE
   [Anonymous], CVPR 2014
   [Anonymous], FACE ALIGNMENT COARS
   [Anonymous], 2017, CORR
   [Anonymous], 2013, Pose-free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model
   [Anonymous], 2017, INT C COMP VIS
   [Anonymous], 2015, HUMAN POSE ESTIMATIO
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2015, Deep Residual Learning for Image Recognition
   [Anonymous], 2013, CORR
   [Anonymous], CVPR 2012 IEEE C
   [Anonymous], 2014, CVPR
   [Anonymous], 2009, CVPRO9
   [Anonymous], 2015, PUSHING FRONTIERS UN
   [Anonymous], CVPR
   [Anonymous], 2015, CORR
   [Anonymous], IEEE C COMP VIS PATT
   Antonakos E., 2016, P IEEE INT C IM PROC
   Antonakos E, 2015, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2015.7299182
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Hsu GS, 2015, IEEE I CONF COMP VIS, P3855, DOI 10.1109/ICCV.2015.439
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kabkab Maya., 2016, CoRR
   Kumar A., 2016, FACE ALIGNMENT LOCAL
   Kumar A., 2017, CORR
   Lee D, 2015, PROC CVPR IEEE, P4204, DOI 10.1109/CVPR.2015.7299048
   Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6
   Liu F, 2016, LECT NOTES COMPUT SC, V9909, P545, DOI 10.1007/978-3-319-46454-1_33
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Simonyan K., 2014, CORR
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Trigeorgis G., 2016, CVPR
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Valle R, 2016, LECT NOTES COMPUT SC, V9756, P24, DOI 10.1007/978-3-319-41778-3_3
   Wu Y, 2015, IEEE I CONF COMP VIS, P3658, DOI 10.1109/ICCV.2015.417
   Xiong X., 2015, CVPR
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhu Shizhan., 2015, CoRR
NR 47
TC 8
Z9 9
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 49
EP 62
DI 10.1016/j.imavis.2018.09.009
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800005
OA Bronze
DA 2024-07-18
ER

PT J
AU Firouznia, M
   Faez, K
   Amindavar, H
   Koupaei, JA
AF Firouznia, Marjan
   Faez, Karim
   Amindavar, Hamidreza
   Koupaei, Javad Alikhani
TI Three-step-ahead prediction for object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-step ahead prediction; Fractal theory; Grey theory; Pseudo-orbit;
   Object tracking
ID ROBUST VISUAL TRACKING; PARTICLE FILTER; SYSTEM; CHAOS
AB In this paper, a three-step-ahead prediction method is introduced using chaotic dynamics for state estimation in object tracking The nonlinear movement of an object is embedded into a low-dimensional state space to utilize the short-term predictions of chaotic systems. The computational architecture of the method is structured as follows. A pseudo-orbit methodology is presented to embed the high dimensional observations of non-linear movement into the pseudo trajectory in the state space with chaotic characteristics. After the Grey theory is applied into the pseudo trajectory in order to reduce the dimension of trajectory, the fractal method is used for three state predictions of the object's movement. For state correction, ensemble members are used to select the best state based on the likelihood function of the color model of candidates. In order to evaluate the efficiency of the chaotic tracker, we compare the chaotic tracker against tracking by detection and stochastic methods. The numerical results demonstrate that the method predicts the target in full occlusions and abrupt motion with a high level of accuracy. Thus, the chaos-based method for making target prediction is vastly superior to existing trackers. The tracker can localize small targets in video sequences accurately. The proposed algorithm is about two times faster than the particle filter method while the error of the particle filter is more than the error of the proposed tracker. The limitations of the proposed method are also illustrated in clutter background and complex scene. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Firouznia, Marjan; Faez, Karim; Amindavar, Hamidreza] Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.
   [Firouznia, Marjan; Koupaei, Javad Alikhani] Payamenoor Univ, Math Dept, POB 19395-3697, Tehran, Iran.
C3 Amirkabir University of Technology
RP Firouznia, M (corresponding author), Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.; Firouznia, M (corresponding author), Payamenoor Univ, Math Dept, POB 19395-3697, Tehran, Iran.
EM Marjan.abdechiri@aut.ac.ir
RI faez, karim/K-5117-2019; Firouznia, Marjan/AAW-8217-2020; Hamidreza,
   Hamidreza/ABC-1981-2021
OI faez, karim/0000-0002-1159-4866; Firouznia, Marjan/0000-0001-6491-2955;
   Hamidreza, Hamidreza/0000-0002-0954-0674
CR Abdechiri M, 2018, MULTIDIM SYST SIGN P, V29, P1643, DOI 10.1007/s11045-017-0521-9
   Abdechiri M, 2017, SIGNAL PROCESS-IMAGE, V54, P23, DOI 10.1016/j.image.2017.02.004
   Abdechiri M, 2017, NEUROCOMPUTING, V247, P16, DOI 10.1016/j.neucom.2017.03.032
   Abdechiri M, 2017, NONLINEAR DYNAM, V87, P2597, DOI 10.1007/s11071-016-3213-3
   Abdelali HA, 2016, MOD SIMUL ENG, V2016, DOI 10.1155/2016/2592368
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Cai ZB, 2016, MULTIMED TOOLS APPL, V75, P2393, DOI 10.1007/s11042-014-2411-6
   Casdagli M., 1992, MODELING COMPLEX PHE, P131
   Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145
   Chiranjeevi P, 2016, IEEE T FUZZY SYST, V24, P695, DOI 10.1109/TFUZZ.2015.2471811
   Ciobanu Adrian, 2014, 2014 INT C DEV APPL
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   De Freitas A, 2016, AUTOMATICA, V69, P380, DOI 10.1016/j.automatica.2016.03.009
   Del Bimbo A, 2011, COMPUT VIS IMAGE UND, V115, P771, DOI 10.1016/j.cviu.2011.01.004
   Ding JW, 2016, IEEE T CIRC SYST VID, V26, P319, DOI 10.1109/TCSVT.2015.2406231
   Dou JF, 2015, OPTIK, V126, P1449, DOI 10.1016/j.ijleo.2015.04.031
   Du HL, 2014, J ATMOS SCI, V71, P483, DOI 10.1175/JAS-D-13-033.1
   Fan ZH, 2015, SIGNAL PROCESS-IMAGE, V36, P140, DOI 10.1016/j.image.2015.07.001
   Firouznia M, 2018, J VIS COMMUN IMAGE R, V53, P1, DOI 10.1016/j.jvcir.2018.02.014
   Firouznia M, 2017, DIGIT SIGNAL PROCESS, V70, P94, DOI 10.1016/j.dsp.2017.07.024
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Karami AH, 2015, ENG APPL ARTIF INTEL, V37, P307, DOI 10.1016/j.engappai.2014.09.018
   Kayacan E, 2010, EXPERT SYST APPL, V37, P1784, DOI 10.1016/j.eswa.2009.07.064
   Kim DH, 2014, IEEE T CIRC SYST VID, V24, P1288, DOI 10.1109/TCSVT.2014.2305514
   Koupaei JA, 2015, CHAOS SOLITON FRACT, V81, P233, DOI 10.1016/j.chaos.2015.09.027
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Leonardi Mary L, 1997, PREDICTION GEOMETRY
   Li WY, 2016, SIGNAL PROCESS-IMAGE, V43, P28, DOI 10.1016/j.image.2016.01.001
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Pan P, 2011, IEEE SIGNAL PROC LET, V18, P51, DOI 10.1109/LSP.2010.2091406
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Su YY, 2014, PATTERN RECOGN, V47, P1826, DOI 10.1016/j.patcog.2013.11.028
   Sugandi B, 2010, ARTIF LIFE ROBOT, V15, P41, DOI 10.1007/s10015-010-0762-2
   Sun J, 2016, APPL MATH SER B, V31, P177, DOI 10.1007/s11766-016-3378-z
   Sun X, 2014, SIGNAL IMAGE VIDEO P, V8, pS95, DOI 10.1007/s11760-014-0674-z
   Wu J, 2009, ENVIRON MODELL SOFTW, V24, P632, DOI 10.1016/j.envsoft.2008.10.004
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao JJ, 2016, IEEE SENS J, V16, P2639, DOI 10.1109/JSEN.2016.2514704
   YAO QW, 1994, PHILOS T R SOC A, V348, P357, DOI 10.1098/rsta.1994.0096
   Yi SY, 2015, SIGNAL PROCESS, V110, P178, DOI 10.1016/j.sigpro.2014.09.020
   Yin S, 2011, COMPUT VIS IMAGE UND, V115, P885, DOI 10.1016/j.cviu.2011.02.010
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang LH, 2016, IEEE T IMAGE PROCESS, V25, P840, DOI 10.1109/TIP.2015.2509244
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang YQ, 2017, INFORM FUSION, V34, P55, DOI 10.1016/j.inffus.2016.06.007
   Zhou ZY, 2016, OPTIK, V127, P613, DOI 10.1016/j.ijleo.2015.10.038
NR 50
TC 2
Z9 2
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2018
VL 75
BP 11
EP 20
DI 10.1016/j.imavis.2018.03.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GM3LM
UT WOS:000438006100002
DA 2024-07-18
ER

PT J
AU Coscia, P
   Castaldo, F
   Palmieri, FAN
   Alahi, A
   Savarese, S
   Ballan, L
AF Coscia, Pasquale
   Castaldo, Francesco
   Palmieri, Francesco A. N.
   Alahi, Alexandre
   Savarese, Silvio
   Ballan, Lamberto
TI Long-term path prediction in urban scenarios using circular
   distributions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Long-term path prediction; Circular distribution; Human-scene
   interaction; Stochastic model
ID MOTION; TRACKING; MODEL
AB Human ability to foresee the near future plays a key role in everyone's life to prevent potentially dangerous situations. To be able to make predictions is crucial when people have to interact with the surrounding environment. Modeling such capability can lead to the design of automated warning systems and provide moving robots with an intelligent way of interaction with changing situation. In this work we focus on a typical urban human-scene where we aim at predicting an agent's behavior using a stochastic model. In this approach, we fuse the various factors that would contribute to a human motion in different contexts. Our method uses previously observed trajectories to build point-wise circular distributions that after combination, provide a statistical smooth prediction towards the most likely areas. More specifically, a ray launching procedure, based on a semantic segmentation, gives a coarse scene representation for collision avoidance; a nearly-constant velocity dynamic model smooths the acceleration progression and knowledge of the agent's destination may further steer the path prediction. Experimental results in structured scenes, validate the effectiveness of the method in predicting paths in comparison to actual trajectories. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Coscia, Pasquale; Castaldo, Francesco; Palmieri, Francesco A. N.] Univ Campania Luigi Vanvitelli, Dipartimento Ingn Ind & Informaz, Via Roma 29, I-81031 Aversa, Italy.
   [Savarese, Silvio] Stanford Univ, Dept Comp Sci, 353 Serra Mall, Stanford, CA 94305 USA.
   [Alahi, Alexandre] Ecole Polytech Fed Lausanne, Sch Architecture Civil & Environm Engn, Batiment GC, CH-1015 Lausanne, Switzerland.
   [Ballan, Lamberto] Univ Padua, Dept Math Tullio Levi Civita, Via Trieste 63, I-35121 Padua, Italy.
C3 Universita della Campania Vanvitelli; Stanford University; Swiss Federal
   Institutes of Technology Domain; Ecole Polytechnique Federale de
   Lausanne; University of Padua
RP Coscia, P (corresponding author), Univ Campania Luigi Vanvitelli, Dipartimento Ingn Ind & Informaz, Via Roma 29, I-81031 Aversa, Italy.
EM pasquale.coscia@unicampania.it; francesco.castaldo@unicampania.it;
   francesco.palmieri@unicampania.it; alexandre.alahi@epfl.ch;
   ssilvio@stanford.edu; lamberto.ballan@unipd.it
RI Coscia, Pasquale/JCE-5118-2023; Coscia, Pasquale/AAU-1579-2020; Alahi,
   Alexandre/AAP-5936-2021; Ballan, Lamberto/B-3450-2008; Castaldo,
   Francesco/O-9788-2014
OI Alahi, Alexandre/0000-0002-5004-1498; Ballan,
   Lamberto/0000-0003-0819-851X; Coscia, Pasquale/0000-0003-4726-3409;
   Castaldo, Francesco/0000-0003-3779-496X; Palmieri, Francesco A.
   N./0000-0003-3777-3501
FU Italian MIUR through the CNIT (Consorzio Interuniversitario per le
   Telecomunicazioni) [PON 03PE-00185-1,2]; EU Marie partially Curie
   Fellowship [623930]
FX This project has been sponsored by a grant from the Italian MIUR through
   the CNIT (Consorzio Interuniversitario per le Telecomunicazioni), PON
   03PE-00185-1,2 (MAR.TE.). L. Ballan was supported by an EU Marie
   partially Curie Fellowship (No. 623930).
CR Andrikoula M, 2009, CLIMACTERIC, V12, P3, DOI 10.1080/13697130802556296
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2014, 17 INT C INF FUS FUS
   Ballan L., 2016, P EUR C COMP VIS ECC
   Bartolini I., 2008, IMAGINATION EXPLOITI, P32
   Bera A, 2016, IEEE INT CONF ROBOT, P5528, DOI 10.1109/ICRA.2016.7487768
   Chen Z, 2011, PATTERN RECOGN, V44, P2902, DOI 10.1016/j.patcog.2011.04.022
   Coscia P., 2016, P IEEE INT C INF FUS
   Dubuisson M-P, 1994, P INT C PATT REC ICP
   Ferrer G, 2014, PATTERN RECOGN LETT, V44, P134, DOI 10.1016/j.patrec.2013.08.013
   Fouhey D. F., 2014, P IEEE INT C COMP VI
   Goldhammer M, 2014, INT C PATT RECOG, P4110, DOI 10.1109/ICPR.2014.704
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hentschel M., 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P1645, DOI 10.1109/ITSC.2010.5625092
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Hu WM, 2004, IEEE T SYST MAN CY B, V34, P1618, DOI 10.1109/TSMCB.2004.826829
   Ikeda Tetsushi, 2013, 2012 Robotics: Science and Systems, P137
   Junejo IN, 2004, INT C PATT RECOG, P716, DOI 10.1109/ICPR.2004.1334359
   Kitani K, 2012, P EUR C COMP VIS ECC
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Li XR, 2003, IEEE T AERO ELEC SYS, V39, P1333, DOI 10.1109/TAES.2003.1261132
   Macek K, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4375, DOI 10.1109/IROS.2006.282013
   Madriga F, 2015, IEEE INT CONF ROBOT, P720, DOI 10.1109/ICRA.2015.7139258
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mantini P., 2014, P 2014 IND C COMP VI
   Mehran R, 2009, P IEEE INT C COMP VI
   Okal B, 2016, IEEE INT CONF ROBOT, P2889, DOI 10.1109/ICRA.2016.7487452
   Pitre RR, 2005, PROC SPIE, V5809, P549, DOI 10.1117/12.609681
   Rehder E., 2015, P IEEE INT C COMP VI
   Robicquet A., 2016, P EUR C COMP VIS ECC
   Vasquez D., 2006, INTENTIONAL MOTION O, P305
   Vasquez D, 2014, IEEE INT C INT ROBOT, P1341, DOI 10.1109/IROS.2014.6942731
   Walker J., 2014, P IEEE INT C COMP VI
   WANG CL, 2009, 2009 IEEE COMP SOC C, V57, P1903, DOI DOI 10.1109/TCOMM.2009.07.070156
   Xie D., 2013, P IEEE INT C COMP VI
   Yamaguchi K., 2011, P IEEE INT C COMP VS
   Yan X, 2014, PATTERN RECOGN, V47, P1626, DOI 10.1016/j.patcog.2013.10.019
   Yan X., 2014, WHAT DO I SEE MODELI, P314
   Yoo Y., 2016, P IEEE INT C COMP VI
   Ziebart BD, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3931, DOI 10.1109/IROS.2009.5354147
NR 40
TC 25
Z9 28
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 81
EP 91
DI 10.1016/j.imavis.2017.11.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Morel, M
   Achard, C
   Kulpa, R
   Dubuisson, S
AF Morel, Marion
   Achard, Catherine
   Kulpa, Richard
   Dubuisson, Severine
TI Automatic evaluation of sports motion: A generic computation of spatial
   and temporal errors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dynamic Time Warping; Evaluation; Multidimensional features; Synchrony;
   Motion capture
ID REPRESENTATION; RECOGNITION
AB In this paper, we propose an innovative automatic evaluation process for any sport motions. Based on a 2-level Dynamic Time Warping, the process allows the evaluation of both spatial and temporal errors of a novice motion based on an experts' motion database and without any prior knowledge on the sport. This new methodology is evaluated with regards to coaches' assessment on two different kinds of motions: tennis serves and karate tsuki. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Morel, Marion; Achard, Catherine; Dubuisson, Severine] Univ Paris 06, CNRS, UPMC, Sorbonne Univ,ISIR,UMR 7222, F-75005 Paris, France.
   [Morel, Marion; Kulpa, Richard] Univ Rennes 2, ENS Rennes, M2S Lab, Ave Robert Schuman, F-35170 Bruz, France.
C3 Centre National de la Recherche Scientifique (CNRS); Sorbonne
   Universite; Ecole Normale Superieure de Rennes (ENS Rennes); Universite
   Rennes 2
RP Morel, M (corresponding author), Univ Paris 06, CNRS, UPMC, Sorbonne Univ,ISIR,UMR 7222, F-75005 Paris, France.; Morel, M (corresponding author), Univ Rennes 2, ENS Rennes, M2S Lab, Ave Robert Schuman, F-35170 Bruz, France.
RI Achard, Catherine/AAK-2130-2021
OI Achard, Catherine/0000-0002-5790-0830
FU ENS ParisSaclay
FX This study was partially supported by the funding of ENS ParisSaclay.
   Some data used in this project were obtained from both tennis and karate
   projects carried out in the M2S laboratory. The authors thank Pierre
   Touzard, Caroline Martin, Anthony Sorel and Anne -Marie Burns for these
   supplies.
CR Anguera X, 2013, INTERSPEECH, P1
   [Anonymous], 2007, INFORM RETRIEVAL MUS
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], 2012, 2012 IEEE COMPUTER S, DOI DOI 10.1109/CVPRW.2012.6239231
   [Anonymous], 2016, 2016 IEEE GLOBAL COM
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   BURNS A, 2013, THESIS
   Gong D, 2014, IEEE T PATTERN ANAL, V36, P1414, DOI 10.1109/TPAMI.2013.244
   Heloir A, 2006, COMPUT ANIMAT VIRT W, V17, P347, DOI 10.1002/cav.138
   Hofstad EF, 2013, SURG ENDOSC, V27, P854, DOI 10.1007/s00464-012-2524-9
   Kahol K, 2004, INT C PATT RECOG, P946, DOI 10.1109/ICPR.2004.1334685
   Keogh E.J., 2001, 1 SIAM INT C DAT MIN
   Komura T, 2006, LECT NOTES COMPUT SC, V4181, P239
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   Maes PJ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-35
   Martin C, 2013, THESIS
   Martin C., 2013, MED SCI SPORTS EXERC
   Martin C, 2014, AM J SPORT MED, V42, P2751, DOI 10.1177/0363546514547173
   Parameswaran V., 2003, P IEEE C COMP VIS PA, V66, P83
   Pazhoumand-Dar H, 2015, J VIS COMMUN IMAGE R, V30, P10, DOI 10.1016/j.jvcir.2015.03.002
   Pham MT, 2010, IEEE ENG MED BIO, P6345, DOI 10.1109/IEMBS.2010.5627632
   Ramakrishnan AjaySundar., 2013, Proceedings of the 2013 international conference on Autonomous agents and multi-agent systems, P1249
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Reiley CE, 2011, SURG ENDOSC, V25, P356, DOI 10.1007/s00464-010-1190-z
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Sakurai K, 2014, INT C CONTR AUTOMAT, P1368, DOI 10.1109/ICCAS.2014.6987769
   Sie M.-S., 2004, IEEE INT C SIGN PROC, P326
   Sorel A, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413500237
   Veeraraghavan A., 2006, FUNCTION SPACE ACTIV, P959
   Wang S.B., 2006, P IEEE COMP SOC C CO
   Ward RachelEvelyn., 2012, BIOMECHANICAL PERSPE
   Yinlai Jiang, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P805, DOI 10.1109/ICINFA.2010.5512464
   Zhong S, 2002, IEEE IJCNN, P1154, DOI 10.1109/IJCNN.2002.1007657
   Zhou F., 2009, P ADV NEURAL INFORM, VVolume 22
   Zhou F, 2015, P INT C COMP INF TEL, V99, P1
NR 36
TC 8
Z9 8
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2017
VL 64
BP 67
EP 78
DI 10.1016/j.imavis.2017.05.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FH0ZW
UT WOS:000410870200006
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Huang, S
   Elgammal, A
   Yang, D
AF Huang, Sheng
   Elgammal, Ahmed
   Yang, Dan
TI On the effect of hyperedge weights on hypergraph learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hypergraph learning; Transductive learning; Graph learning; Image
   clustering; Image classification
ID COLLABORATIVE REPRESENTATION; SPARSE REPRESENTATION; FACE RECOGNITION
AB Hypergraph is a powerful representation for several computer vision, machine learning, and pattern recognition problems. In the last decade, many researchers have been keen to develop different hypergraph models. In contrast, no much attention has been paid to the design of hyperedge weighting schemes. However, many studies on pairwise graphs showed that the choice of edge weight can significantly influence the performances of such graph algorithms. We argue that this also applies to hypergraphs. hi this paper, we empirically study the influence of hyperedge weights on hypergraph learning via proposing three novel hyperedge weighting schemes from the perspectives of geometry, multivariate statistical analysis, and linear regression. Extensive experiments on ORL, COIL20, JAFFE, Sheffield, Scenel 5 and Caltech256 datasets verified our hypothesis for both classification and clustering problems. For each of these claSses of problems, our empirical study concludes with suggesting a suitable hypergraph weighting scheme. Moreover, the experiments also demonstrate that the combinations of such weighting schemes and conventional hyper graph models can achieve competitive classification and clustering performances in comparison with some recent state-of-the-art algorithms. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Huang, Sheng; Yang, Dan] Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Huang, Sheng; Yang, Dan] Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
   [Elgammal, Ahmed] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
C3 Chongqing University; Rutgers University System; Rutgers University New
   Brunswick
RP Huang, S (corresponding author), Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.; Huang, S (corresponding author), Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
EM huangsheng@cqu.edu.cn
RI YANG, Dan/HHD-2733-2022
OI Huang, Sheng/0000-0001-5610-0826; Elgammal, Ahmed/0000-0003-2761-4822
FU National Natural Science Foundation of China [61602068]; Natural Science
   Foundation of Chongqing [cstc2016jcyjA0458]; Fundamental Research Funds
   for the Central Universities [106112015CDJRC09110]
FX This work has been partially funded by the National Natural Science
   Foundation of China (Grant no. 61602068), Natural Science Foundation of
   Chongqing (Grant no. cstc2016jcyjA0458) and Fundamental Research Funds
   for the Central Universities (Grant no. 106112015CDJRC09110). The
   authors would like to thank the reviewers for their useful comments.
CR Agarwal S, 2005, PROC CVPR IEEE, P838
   Agarwal S., 2006, P 23 INT C MACH LEAR, P17, DOI DOI 10.1145/1143844.1143847
   [Anonymous], HYPERGRAPH CLUSTERIN
   [Anonymous], IEEE WORKSH APPL COM
   [Anonymous], J ELECT IMAGING
   [Anonymous], 2014, REGISTRATION RECOGNI
   [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2008, P 14 ACM SIGKDD INT
   [Anonymous], NATO ASI F
   [Anonymous], ARXIV14085093
   [Anonymous], 2012, BIRTISH MACHINE VISI
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], DISCRET MATH
   [Anonymous], KNOWL INF SYST
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia
   [Anonymous], 2014, ICMEW
   [Anonymous], AAAI C ART INT AAAI
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bergamo Alessandro., 2011, NIPS, P2088
   Breiman L., 2001, Mach. Learn., V45, P5
   Bulò SR, 2013, IEEE T PATTERN ANAL, V35, P1312, DOI 10.1109/TPAMI.2012.226
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chen G, 2009, PROC CVPR IEEE, P1658, DOI 10.1109/CVPRW.2009.5206813
   Chen X, 2016, PATTERN RECOGN, V53, P116, DOI 10.1016/j.patcog.2015.11.016
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dailey MN, 2010, EMOTION, V10, P874, DOI 10.1037/a0020019
   Duchenne O., 2008, IEEE COMPUTER VISION, P1, DOI DOI 10.1109/CVPR.2008.4587419
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110
   Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   GRITZMANN P, 1994, NATO ADV SCI INST SE, V440, P373
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hein Matthias, 2013, ADV NEURAL INFORM PR, V26
   Hofmann M, 2013, PROC CVPR IEEE, P3650, DOI 10.1109/CVPR.2013.468
   Huang S, 2015, SIGNAL PROCESS, V116, P38, DOI 10.1016/j.sigpro.2015.04.018
   Huang S, 2014, IEEE COMPUT SOC CONF, P15, DOI 10.1109/CVPRW.2014.8
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   Kannan K, 2010, IMAGE VISION COMPUT, V28, P1329, DOI 10.1016/j.imavis.2010.01.013
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leordeanu M, 2011, IEEE I CONF COMP VIS, P2274, DOI 10.1109/ICCV.2011.6126507
   Li Pu, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P410, DOI 10.1007/978-3-642-33460-3_32
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Nene S. A., 1996, COLUMBIA OBJECT IMAG
   Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728
   Panagopoulos A, 2013, IEEE T PATTERN ANAL, V35, P437, DOI 10.1109/TPAMI.2012.110
   Rodríguez JA, 2003, LINEAR MULTILINEAR A, V51, P285, DOI 10.1080/0308108031000084374
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Timofte R, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.61
   Wang YQ, 2014, SIGNAL PROCESS, V105, P258, DOI 10.1016/j.sigpro.2014.05.032
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou Dengyong, 2006, 19 INT C NEURAL INFO, V19, P1601
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zien JY, 1999, IEEE T COMPUT AID D, V18, P1389, DOI 10.1109/43.784130
NR 65
TC 17
Z9 20
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 89
EP 101
DI 10.1016/j.imavis.2016.10.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cadoni, M
   Lagorio, A
   Grosso, E
AF Cadoni, Marinella
   Lagorio, Andrea
   Grosso, Enrico
TI Large scale face identification by combined iconic features and 3D joint
   invariant signatures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multimodal face recognition; Face identification; Iconic features; Joint
   invariant signatures
ID RECOGNITION
AB In this paper, we present a 2D/3D multimodal face identification system. A set of iconic fiducial points and descriptors is first extracted from the images of the faces and a preliminary correspondence between the points is established on the basis of the descriptor content. Subsequently, the points are mapped on the scans and used to calculate 3D joint differential invariant vectors that define a signature of the face. Since a correspondence between the invariants is inherited from the 2D feature point matching, the signatures of the faces can be efficiently compared by evaluating the distance between corresponding vectors, thus validating the 2D matching hypothesis. This methodology guarantees an effective and fast alignment of the 3D scans, avoids iterative registration procedures and provides a simple similarity measure for face identification. Extensive tests were carried out on the FRGCv2 and on the Bosphorus databases, which both contain 3D and texture information of faces. Results show that the method is robust to expressions provided the images are of good quality, and that it is particularly suited to identification tasks in the cases of medium to large databases with multiple gallery enrolment. Indeed, in these scenarios, the performance was superior or comparable to state of the art methods, with execution times often faster by several orders of magnitude. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Cadoni, Marinella; Lagorio, Andrea; Grosso, Enrico] Univ Sassari, Polcoming Dept, Viale Mancini 5, I-07100 Sassari, Italy.
C3 University of Sassari
RP Cadoni, M (corresponding author), Univ Sassari, Polcoming Dept, Viale Mancini 5, I-07100 Sassari, Italy.
EM maricadoni@uniss.it; lagorio@uniss.it; grosso@uniss.it
OI LAGORIO, Andrea/0000-0001-9113-6103
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0
   [Anonymous], 2005, CVPR WORKSH
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001
   Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bicego M., 2006, COMP VIS PATT REC WO, P35, DOI DOI 10.1109/CVPRW.2006.149
   Boehnen C, 2009, LECT NOTES COMPUT SC, V5558, P12, DOI 10.1007/978-3-642-01793-3_2
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Cadoni M., IEEE 6 INT C BIOM TH
   Cadoni M, 2014, INT C PATT RECOG, P4612, DOI 10.1109/ICPR.2014.789
   Cadoni M, 2009, LECT NOTES COMPUT SC, V5558, P279, DOI 10.1007/978-3-642-01793-3_29
   Cartan E., METHODE REPERE MOBIL
   Chang K., 2003, MULTIMODAL USER AUTH, P25
   Chang K., P IEEE COMP VIS PATT
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Cox IJ, 1996, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.1996.517076
   Do Carmo M., 1976, Differential Geometry of Curves and Surfaces
   Evans C., 2009, CSTR09001 U BRIST
   Faltemier TC, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P19
   Ghorbel F, 2013, ANN TELECOMMUN, V68, P219, DOI 10.1007/s12243-012-0335-6
   Huang D, 2012, IEEE T INF FOREN SEC, V7, P1551, DOI 10.1109/TIFS.2012.2206807
   Huang Di., 2011, CVPR 2011 WORKSHOPS, P1
   Huang G.B., 2008, PROC WORKSHOP FACES
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Li HB, 2015, INT J COMPUT VISION, V113, P128, DOI 10.1007/s11263-014-0785-6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213
   Ocegueda O, 2013, IEEE T PATTERN ANAL, V35, P728, DOI 10.1109/TPAMI.2012.126
   Olver P., 1999, Regular and Chaotic Dynamics, V4, P3
   Phillips P. J., 2003, 2003 IEEE International Workshop on Analysis and Modeling of Faces and Gestures
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   SAMARIA F, 1994, IMAGE VISION COMPUT, V12, P537, DOI 10.1016/0262-8856(94)90007-8
   Samir C, 2009, INT J COMPUT VISION, V82, P80, DOI 10.1007/s11263-008-0187-8
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P.A., INT J COMPUT VIS, V57
   Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 52
TC 8
Z9 8
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 42
EP 55
DI 10.1016/j.imavis.2016.05.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400004
DA 2024-07-18
ER

PT J
AU Domingo, J
   Simó, A
   Ibáñez, MV
   Dura, E
   Ayala, G
   Alemany, S
AF Domingo, J.
   Simo, A.
   Ibanez, M. V.
   Dura, E.
   Ayala, G.
   Alemany, S.
TI Towards a mean body for apparel design
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Mean set; Confidence set; Apparel design; Anthropometric survey
ID RANDOM SETS; SHAPES
AB This paper focuses on shape average with applications to the apparel industry. Apparel industry uses a consensus sizing system; its major concern is to fit most of the population into it. Since anthropometric measures do not grow linearly, it is important to find prototypes to accurately represent each size. This is done using random compact mean sets, obtained from a cloud of 3D points given by a scanner and applying to the sample a previous definition of mean set. Additionally, two approaches to define confidence sets are introduced. The methodology is applied to data obtained from a real anthropometric survey. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Domingo, J.] Sch Engn, Dept Informat, Avda Univ S-N, Valencia 46100, Spain.
   [Simo, A.; Ibanez, M. V.] Univ Jaume 1, Dept Math IMAC, Castellon de La Plana, Spain.
   [Dura, E.] Univ Valencia, Dept Informat, Valencia, Spain.
   [Ayala, G.] Univ Valencia, Dept Stat & Operat Res, E-46003 Valencia, Spain.
   [Alemany, S.] Univ Politecn Valencia, Inst Biomech, Valencia, Spain.
C3 Universitat Jaume I; University of Valencia; University of Valencia;
   Universitat Politecnica de Valencia
RP Domingo, J (corresponding author), Sch Engn, Dept Informat, Avda Univ S-N, Valencia 46100, Spain.
EM Juan.Domingo@uv.es; simo@uji.es; mibanez@uji.es; esther.dura@uv.es;
   Guillermo.Ayala@uv.es; sandra.alemany@ibv.upv.es
RI Ayala, Guillermo/N-5766-2019; Ayala, Guillermo/A-8077-2008; Simó,
   Amelia/D-6321-2017; Alemany, Susana/J-6307-2014; Gual, Maria Victoria
   Ibáñez/AAG-1438-2020; Domingo, Juan/E-9709-2018
OI Simó, Amelia/0000-0001-5507-2907; Gual, Maria Victoria
   Ibáñez/0000-0001-7043-8233; Domingo, Juan/0000-0003-4728-6256; Alemany,
   Sandra/0000-0003-1899-4165; Dura, Esther/0000-0002-2603-5549
FU Spanish Ministry of Economy and Competitiveness [TIN2009-14392-C02-01,
   TIN2009-14392-C02-02, DPI2013-45742-R]; FEDER funds
FX This paper has been partially supported by the following grants:
   TIN2009-14392-C02-01, TIN2009-14392-C02-02 and DPI2013-45742-R from the
   Spanish Ministry of Economy and Competitiveness with FEDER funds.
CR Alemany S., 2010, INPR 2010 INT C 3D B, P307
   [Anonymous], 1984, mean-measure modelling
   ARTSTEIN Z, 1975, ANN PROBAB, V3, P879, DOI 10.1214/aop/1176996275
   Ashdown S.P., 2006, CLOTH TEXT RES J, V24, P121, DOI DOI 10.1177/0887302X0602400206
   Ashdown S.P., 2006, INT TEXTILE APPAREL, V24, P137
   AUMANN RJ, 1965, J MATH ANAL APPL, V12, P1, DOI 10.1016/0022-247X(65)90049-1
   Baddeley A, 1998, J MATH IMAGING VIS, V8, P79, DOI 10.1023/A:1008214317492
   Ben Azouz Z, 2006, VISUAL COMPUT, V22, P302, DOI 10.1007/s00371-006-0006-6
   Bhattacharya R, 2003, ANN STAT, V31, P1
   Blanchonett P., 2010, AR014672 AIR OP DIV
   Chung MJ, 2007, INT J IND ERGONOM, V37, P707, DOI 10.1016/j.ergon.2007.05.004
   Cressie N., 1993, STAT SPATIAL DATA
   Domingo J, 2014, EXPERT SYST APPL, V41, P6224, DOI 10.1016/j.eswa.2014.04.014
   Duffy V.G., 2009, HDB DIGITAL HUMAN MO
   European Committee for Standardization, 2002, 134022 EN EUR COMM S
   Fan J., 2004, CLOTHING APPEARANCE
   Faust ME, 2009, TEXT RES J, V79, P1446, DOI 10.1177/0040517508099394
   Gillies M., 2004, J WSCG, V12, P129
   González-Rodríguez G, 2009, PROCEEDINGS OF THE JOINT 2009 INTERNATIONAL FUZZY SYSTEMS ASSOCIATION WORLD CONGRESS AND 2009 EUROPEAN SOCIETY OF FUZZY LOGIC AND TECHNOLOGY CONFERENCE, P1433
   Griffey J.V., 2006, CLOTH TEXT RES J, V24, P112, DOI DOI 10.1177/0887302X0602400205
   Jankowski H, 2012, SCAND J STAT, V39, P340, DOI 10.1111/j.1467-9469.2011.00753.x
   Jankowski HK, 2010, J MATH IMAGING VIS, V36, P291, DOI 10.1007/s10851-009-0186-6
   Lewis T, 1999, PATTERN RECOGN, V32, P1615, DOI 10.1016/S0031-3203(99)00024-2
   Mann HB, 1943, ANN MATH STAT, V14, P217, DOI 10.1214/aoms/1177731415
   Matheron G., 1975, Random sets and integral geometry
   Molchanov I., 2005, THEORY RANDOM SETS P, P145
   Pengcheng Xi, 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P196, DOI 10.1109/3DIMPVT.2011.32
   Raeve A.D., 2012, 3rd Global Fashion International Conference, Madrid, P1
   Rissiek A., 2010, INPR 2010 INT C 3D B, P269
   Seo Hyewon., 2003, Proceedings of the 2003 Symposium on Interactive 3D Graphics, P19, DOI [10.1145/641480.641487, DOI 10.1145/641480.641487]
   Seri R, 2004, LECT NOTES COMPUT SC, V3045, P298
   Simmons K.P., 2008, J TEXT APPAREL TECHN, V4
   Simó A, 2004, J MATH IMAGING VIS, V20, P209, DOI 10.1023/B:JMIV.0000024039.27561.b9
   Stoyan D., 1994, Fractals, random shapes, and point fields: methods of geometrical statistics
   Stoyan D., 1995, Stochastic Geometry and Its Applications, V2
   Sul IH, 2010, INT J CLOTH SCI TECH, V22, P248, DOI 10.1108/09556221011048286
   UK National Sizing Survey, 2004, TECHNICAL REPORT
   van der Meulen P, 2007, LECT NOTES COMPUT SC, V4561, P1008
   Wang CCL, 2005, COMPUT AIDED DESIGN, V37, P83, DOI 10.1016/j.cad.2004.05.001
NR 39
TC 1
Z9 1
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 88
EP 96
DI 10.1016/j.imavis.2016.04.016
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400007
DA 2024-07-18
ER

PT J
AU Rim, D
   Honari, S
   Hasan, MK
   Pal, CJ
AF Rim, David
   Honari, Sina
   Hasan, Md Kamrul
   Pal, Christopher J.
TI Improving facial analysis and performance driven animation through
   disentangling identity and expression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Factorization techniques; Emotion recognition; Graphical models;
   Performance driven animation; Facial expression analysis
ID FACE IMAGES; MODELS; RECOGNITION
AB We present techniques for improving performance driven facial animation, emotion recognition, and facial key-point or landmark prediction using learned identity invariant representations. Established approaches to these problems can work well if sufficient examples and labels for a particular identity are available and factors of variation are highly controlled. However, labeled examples of facial expressions, emotions and key-points for new individuals are difficult and costly to obtain. In this paper we improve the ability of techniques to generalize to new and unseen individuals by explicitly modeling previously seen variations related to identity and expression. We use a weakly-supervised approach in which identity labels are used to learn the different factors of variation linked to identity separately from factors related to expression. We show how probabilistic modeling of these sources of variation allows one to learn identity-invariant representations for expressions which can then be used to identity-normalize various procedures for facial expression analysis and animation control. We also show how to extend the widely used techniques of active appearance models and constrained local models through replacing the underlying point distribution models which are typically constructed using principal component analysis with identity-expression factorized representations. We present a wide variety of experiments in which we consistently improve performance on emotion recognition, markerless performance-driven facial animation and facial key-point tracking. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Rim, David; Hasan, Md Kamrul; Pal, Christopher J.] Ecole Polytech, Dept Genie Informat & Genie Logiciel, Montreal, PQ H3T 1J4, Canada.
   [Honari, Sina] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada.
C3 Universite de Montreal; Polytechnique Montreal; Universite de Montreal
RP Pal, CJ (corresponding author), Ecole Polytech, Dept Genie Informat & Genie Logiciel, Montreal, PQ H3T 1J4, Canada.
EM daverim@gmail.com; sina.honari@umontreal.ca; md-kamrul.hasan@polymtl.ca;
   christopher.pal@polymtl.ca
RI Hasan, Kamrul/AAY-6295-2020
OI Hasan, Kamrul/0000-0001-9099-5424
FU Ubisoft; Natural Sciences and Engineering Research Council of Canada
   (NSERC); Fonds de recherche du Quebec - Nature et technologies (FRQNT)
   [B2]
FX We thank Ubisoft for both financial support and for providing the helmet
   camera video data used for our high quality animation control
   experiments. We also thank the Natural Sciences and Engineering Research
   Council of Canada (NSERC) for financial support under the CRD and
   Discovery grant programs and the Fonds de recherche du Quebec - Nature
   et technologies (FRQNT) for a Doctoral research scholarships (B2) grant
   to SH. We thank Yoshua Bengio for his comments and suggestions regarding
   this work.
CR [Anonymous], 2011, Handbook of face recognition
   [Anonymous], 2006, BMVC
   Bach Francis R., 2005, PROBABILISTIC INTERP
   Bartlett MS, 1999, PSYCHOPHYSIOLOGY, V36, P253, DOI 10.1017/S0048577299971664
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293
   Cheng F, 2010, IEEE T NEURAL NETWOR, V21, P1685, DOI 10.1109/TNN.2010.2064176
   Cohn JF, 2010, BEHAV RES METHODS, V42, P1079, DOI 10.3758/BRM.42.4.1079
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Del Bue A, 2012, IEEE T PATTERN ANAL, V34, P1496, DOI 10.1109/TPAMI.2011.238
   Du YZ, 2003, PATTERN RECOGN LETT, V24, P2923, DOI 10.1016/S0167-8655(03)00153-3
   Edwards GJ, 1998, IMAGE VISION COMPUT, V16, P203, DOI 10.1016/S0262-8856(97)00069-3
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Essa I., 1996, Proceedings. Computer Animation '96, P68, DOI 10.1109/CA.1996.540489
   Everingham M., 2006, P BRIT MACH VIS C, P899, DOI [DOI 10.5244/C.20.92, 10.5244/C.20.92]
   Freeman WT, 1997, PROC CVPR IEEE, P554, DOI 10.1109/CVPR.1997.609380
   FREY B.J., 1999, Estimating mixture models of images and inferring spatial transformations using the EM algorithm, P416
   GOUDEAUX K, 2001, P ICASSP 01, V3, P1501
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Hasan MK, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P362, DOI 10.1109/ICCVW.2013.55
   Honari S., 2016, INPR IEEE C COMP VIS
   Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858
   Jeni LA, 2012, IMAGE VISION COMPUT, V30, P785, DOI 10.1016/j.imavis.2012.02.003
   Kroon D.-J., ACTIVE SHAPE MODEL A
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   Liao P, 2004, J COMPUT SCI TECH-CH, V19, P684, DOI 10.1007/BF02945595
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M., AUT FAC GEST REC 199, P200
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Pighin Frederic., 1999, The Proceedings of the Seventh IEEE International Conference on, V1, P143
   Prince S., 2011, PATTERN ANAL MACHINE, VPP, P1
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Saragih J, 2009, PATTERN RECOGN, V42, P2628, DOI 10.1016/j.patcog.2009.04.014
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Sibbing Dominik, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1778, DOI 10.1109/ICCVW.2009.5457498
   Sun Y., COMP VIS PATT REC CV, P3476
   Suwa M., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P408
   TISTARELLI M., 2009, Lecture Notes in Computer Science, V5558
   VALSTAR M., 2005, COMPUTER VISION PATT, P76, DOI DOI 10.1109/CVPR.2005.457
   Valstar M.F., 2010, 2010 IEEE INT C AUT, P921
   Van Der Maaten L., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops. IEEE, P34
   Vasilescu MAO, 2002, LECT NOTES COMPUT SC, V2350, P447
   Vezzaro L., 2012, ICAAM INVERSE COMPOS
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   Yin L., 2008, A high-resolution 3D dynamic facial expression database
   ZHANG L., 2007, Data-Driven 3D Facial Animation, P248
   Zhou C, 2005, PATTERN RECOGN LETT, V26, P2611, DOI 10.1016/j.patrec.2005.06.007
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 55
TC 3
Z9 4
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 125
EP 140
DI 10.1016/j.imavis.2016.04.017
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tribou, MJ
   Wang, DWL
   Waslander, SL
AF Tribou, Michael J.
   Wang, David W. L.
   Waslander, Steven L.
TI Degenerate motions in multicamera cluster SLAM with non-overlapping
   fields of view
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE SLAM; Computer vision; Multicamera cluster; Non-overlapping FOV;
   Degeneracy analysis; Critical motions
AB An analysis of the relative motion and point feature model configurations leading to solution degeneracy is presented, for the case of a Simultaneous Localization and Mapping system using multicamera clusters with non-overlapping fields-of-view. The SLAM optimization system seeks to minimize image space reprojection error and is formulated for a cluster containing any number of component cameras, observing any number of point features over two keyframes. The measurement Jacobian is transformed to expose a reduced-dimension representation such that the degeneracy of the system can be determined by the rank of a dense submatrix. A set of relative motions sufficient for degeneracy are identified for certain cluster configurations, independent of target model geometry. Furthermore, it is shown that increasing the number of cameras within the cluster and observing features across different cameras over the two keyframes reduces the size of the degenerate motion sets significantly. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Tribou, Michael J.] Aeryon Labs Inc, 575 Kumpf Dr, Waterloo, ON N2V 1K3, Canada.
   [Wang, David W. L.] Univ Waterloo, Dept Elect & Comp Engn, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada.
   [Waslander, Steven L.] Univ Waterloo, Dept Mech & Mechatron Engn, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo; University of Waterloo
RP Tribou, MJ (corresponding author), Aeryon Labs Inc, 575 Kumpf Dr, Waterloo, ON N2V 1K3, Canada.
EM mjtribou@aeryon.com; dwang@uwaterloo.ca; stevenw@uwaterloo.ca
RI Waslander, Steven/C-5850-2015
OI Waslander, Steven/0000-0003-4217-4415
FU National Sciences and Engineering Research Council of Canada (NSERC)
   [CRDPJ 397768-10]; NSERC Canadian Field Robotics Network (NCFRN); NSERC
   through the Alexander Graham Bell Canada Graduate Scholarship - Doctoral
   (CGS-D) award
FX This work was partially funded by the National Sciences and Engineering
   Research Council of Canada (NSERC) under Grant No. CRDPJ 397768-10 and
   supported through the NSERC Canadian Field Robotics Network (NCFRN).
   Partial funding also comes from the NSERC through the Alexander Graham
   Bell Canada Graduate Scholarship - Doctoral (CGS-D) award.
CR [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2009, BMVC, DOI DOI 10.5244/C.23.57.8,11
   [Anonymous], P WORKSH OMN VIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], INT J ROBOT RES
   Baker P, 2001, PROC CVPR IEEE, P576
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276
   Clipp B., 2008, P IEEE WORKSHOP APPL, P1
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Dorst L., 2010, Geometric Algebra for Computer Science: An Object-Oriented Approach to Geometry
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   HERMANN R, 1977, IEEE T AUTOMAT CONTR, V22, P728, DOI 10.1109/TAC.1977.1101601
   Kaess M, 2010, COMPUT VIS IMAGE UND, V114, P286, DOI 10.1016/j.cviu.2009.07.006
   Kazik T, 2012, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2012.6247843
   Kim JH, 2010, PATTERN RECOGN, V43, P2265, DOI 10.1016/j.patcog.2009.12.015
   Kim JS, 2010, J MATH IMAGING VIS, V37, P40, DOI 10.1007/s10851-010-0191-9
   Klein George, 2007, P1
   Li HF, 2008, CURR MED RES OPIN, V24, P1, DOI 10.1088/0256-307X/24/3/072
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu Y, 2004, IEEE T SYST MAN CY C, V34, P532, DOI 10.1109/TSMCC.2004.829300
   Montiel JMM, 2006, IEEE INT CONF ROBOT, P1917, DOI 10.1109/ROBOT.2006.1641986
   Mouragnon E, 2009, IMAGE VISION COMPUT, V27, P1178, DOI 10.1016/j.imavis.2008.11.006
   Murray RM, 1994, MATH INTRO ROBOTIC M
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Schneider J., 2012, ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences, V3, P75
   Sturm P, 2005, PROC CVPR IEEE, P206
   Thrun S., 2005, PROBABILISTIC ROBOTI
   Tribou MJ, 2014, COMPUT VIS IMAGE UND, V126, P53, DOI 10.1016/j.cviu.2014.06.001
   WHITE NL, 1994, J INTELL ROBOT SYST, V11, P91, DOI 10.1007/BF01258296
NR 30
TC 6
Z9 7
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2016
VL 50
BP 27
EP 41
DI 10.1016/j.imavis.2016.01.005
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4KP
UT WOS:000378465100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pazouki, E
   Rahmati, M
AF Pazouki, Ehsan
   Rahmati, Mohammad
TI A variational based model for estimating true tracklets in wide area
   surveillances
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Variational model; Wide area surveillance; True tracklet estimation;
   Multi-object tracking; Camera network tracking
ID MULTITARGET TRACKING; ROBUST
AB In many wide area surveillance applications, tracking objects is usually accomplished by using network of cameras. A common approach to any multi-objects tracking algorithm in a network of cameras comprises of two main steps. First, the movement trajectory of each object, within the field of view of a camera, is extracted and is called object tracklet. Then, the set of tracklets are used to determine the persistent trace of each object. In this paper, we assume that the tracklets are extracted by a conventional tracking algorithm. The occurrence of occlusion between objects, within the viewing scene, leads to various types of errors on the extracted tracklets. If these erroneous tracklets are used in a multi-object tracking algorithm and ignoring the correction phase, then the errors are propagated and affect the results of tracking algorithm. Therefore the true tracklets have to be estimated from the erroneous tracklets. In this paper, we propose a variational model for estimating the true tracklets. The variational principle proposed in this model is established by first introducing a variational energy function. Then the erroneous tracklets are used to estimate the true tracklets through optimizing the energy function. The proposed method is evaluated on two well known datasets and a synthetic dataset which is particularly developed to demonstrate the performance of our algorithm under challenging scenarios. The 10 common metrics, which are used in other multi-objects tracking applications, are used for quantitative evaluations. Our experimental results illustrate that our proposed model estimates the true tracklets which improves the overall association performances. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Pazouki, Ehsan; Rahmati, Mohammad] Amirkabir Univ Technol, Dept Comp Engn, Tehran 158754413, Iran.
C3 Amirkabir University of Technology
RP Rahmati, M (corresponding author), Amirkabir Univ Technol, Dept Comp Engn, Tehran 158754413, Iran.
EM ehsan.pazouki@aut.ac.ir; rahmati@aut.ac.ir
RI Pazouki, Ehsan/AAP-1512-2020
OI Pazouki, Ehsan/0000-0002-4567-6800; Rahmati,
   Mohammad/0000-0002-0591-6910
CR Ablavsky V, 2011, IEEE T PATTERN ANAL, V33, P1758, DOI 10.1109/TPAMI.2011.43
   [Anonymous], 2001, NUMERICAL METHODS EN
   [Anonymous], 2002, COMPUTATIONAL METHOD
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   [Anonymous], IMAGE PROCESSING ANA
   [Anonymous], CALCULUS VARIATIONS
   [Anonymous], 11 IEEE INT WORKSH P
   Baltieri D., P 1 INT ACM WORKSH M, P59
   Baltieri D., 2010, P EUR IT CHAPT C GEN
   Baltieri D, 2011, LECT NOTES COMPUT SC, V6978, P197, DOI 10.1007/978-3-642-24085-0_21
   Bar-Shalom Y., 1988, TRACKING DATA ASS
   Castnn Gregory, 2011, 2011 AER C, P1
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Faugeras N., 2006, HDB MATH MODELS COMP
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   Jiang MF, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/436281
   Kamal AT, 2012, IEEE DECIS CONTR P, P2732, DOI 10.1109/CDC.2012.6426886
   Kamal AT, 2013, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2013.311
   Liese F, 2008, SPRINGER SER STAT, P1, DOI 10.1007/978-0-387-73194-0_1
   Liu CX, 2011, J MATH IMAGING VIS, V41, P194, DOI 10.1007/s10851-011-0269-z
   Makris D, 2004, PROC CVPR IEEE, P205
   Pan J, 2008, IEEE T CIRC SYST VID, V18, P223, DOI 10.1109/TCSVT.2007.913975
   Papadakis N, 2011, IEEE T PATTERN ANAL, V33, P144, DOI 10.1109/TPAMI.2010.56
   Pazouki E, 2016, J INTELL DATA ANAL, V20
   Pless R., 2009, 2009 IEEE APPL IM PA, P1, DOI DOI 10.1109/AIPR.2009.5466307
   Roy-Chowdhury A.K., 2012, Camera Networks: The Acquisition and Anal- ysis of Videos over Wide Areas. Synthesis Lectures on Computer Vision
   Sandell NF, 2008, IEEE DECIS CONTR P, P1085, DOI 10.1109/CDC.2008.4739066
   Silogic, 2006, INTERNAL TECHNICAL N
   Song B., 2011, VISUAL ANAL HUMANS, P1, DOI DOI 10.1007/978-0-85729-997-0
   Song B., 2010, P EUR C COMP VIS 1
   Song B, 2008, IEEE J-STSP, V2, P582, DOI 10.1109/JSTSP.2008.925992
   Stauffer C, 2003, PROC CVPR IEEE, P259
   Strikwerda J. C., 2004, FINITE DIFFERENCE SC
   Unal G, 2004, PROC CVPR IEEE, P172
   Wen LY, 2014, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2014.167
   Yang ML, 2014, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2014.169
   Yang T, 2013, IEEE T CIRC SYST VID, V23, P1461, DOI 10.1109/TCSVT.2013.2242553
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
NR 40
TC 0
Z9 1
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR-MAY
PY 2016
VL 48-49
BP 42
EP 56
DI 10.1016/j.imavis.2016.02.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO4GS
UT WOS:000377740400005
DA 2024-07-18
ER

PT J
AU Adeli-Mosabbeb, E
   Fathy, M
AF Adeli-Mosabbeb, Ehsan
   Fathy, Mahmood
TI Non-negative matrix completion for action detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Matrix completion; Multi-label classification; Weakly supervised
   classification; Human activity recognition; Alternating direction
   method; Convex optimization
ID ACTION RECOGNITION; MOTION; ALGORITHM; LOCALIZATION
AB With the increasing number of videos all over the Internet and the increasing number of cameras looking at people around the world, one of the most interesting applications would be human activity recognition in videos. Many researches have been conducted in the literature for this purpose. But, still recognizing activities in a video with unrestricted conditions is a challenging problem. Moreover, finding the spatio-temporal location of the activity in the video is another issue. In this paper, we present a method based on a non-negative matrix completion framework, that learns to label videos with activity classes, and localizes the activity of interest spatio-temporally throughout the video. This approach has a multi-label weakly supervised setting for activity detection, with a convex optimization procedure. The experimental results show that the proposed approach is competitive with the state-of-the-art methods. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Adeli-Mosabbeb, Ehsan; Fathy, Mahmood] Iran Univ Sci & Technol, Dept Comp Engn, Tehran 1648613114, Iran.
C3 Iran University Science & Technology
RP Adeli-Mosabbeb, E (corresponding author), Iran Univ Sci & Technol, Dept Comp Engn, Tehran 1648613114, Iran.
EM eadeli@iust.ac.ir; mahfathy@iust.ac.ir
RI Fathy, Mahmood/I-8166-2016
OI Adeli, Ehsan/0000-0002-0579-7763; Fathy, Mahmood/0000-0003-0852-5488
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Andreani R, 2005, J OPTIMIZ THEORY APP, V125, P473, DOI 10.1007/s10957-004-1861-9
   Andrews Stuart, 2002, PROC 25 ANN C NEURAL, P561
   [Anonymous], RECOGNISING REALISTI
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2002, THESIS STANFORD U
   [Anonymous], 10 IEEE INT C AUT FA
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE T PAMI
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2011, CVPR 2011
   [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], WORKSH APPL COMP VIS
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2008, C COMP VIS PATT REC
   [Anonymous], 2008, IEEE INT C COMP VIS
   [Anonymous], 2013, IEEE INT C COMP VIS
   [Anonymous], 2010, ADV NEURAL INFORM PR
   Bergeron C, 2012, IEEE T PATTERN ANAL, V34, P1068, DOI 10.1109/TPAMI.2011.194
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Cabral R, 2015, IEEE T PATTERN ANAL, V37, P121, DOI 10.1109/TPAMI.2014.2343234
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875
   Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dai YC, 2010, LECT NOTES COMPUT SC, V6314, P396
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Du Tran, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3321, DOI 10.1109/CVPR.2011.5995416
   Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279
   Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65
   Goldberg A. B., 2010, Advances in Neural Information Processing Systems, P757
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hoai M, 2014, PATTERN RECOGN, V47, P1523, DOI 10.1016/j.patcog.2013.09.028
   Khokhar S, 2013, IMAGE VISION COMPUT, V31, P603, DOI 10.1016/j.imavis.2013.06.004
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Leibe Bastian, 2004, WORKSH STAT LEARN CO
   Lin Z., 2009, U ILLINOIS URBANACHA
   Maron O, 1998, ADV NEUR IN, V10, P570
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Ryu J, 2012, IEEE ICC
   Savarese S., 2008, P 2008 IEEE WORKSHOP, P1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shui XG, 2012, IEEE C EVOL COMPUTAT
   Siva P, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.65
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Wang H., 2009, BMVC
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wu SD, 2011, IEEE I CONF COMP VIS, P1419, DOI 10.1109/ICCV.2011.6126397
   Xu YY, 2012, FRONT MATH CHINA, V7, P365, DOI 10.1007/s11464-012-0194-5
   Yang JF, 2013, MATH COMPUT, V82, P301
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60
NR 67
TC 12
Z9 13
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2015
VL 39
BP 38
EP 51
DI 10.1016/j.imavis.2015.04.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CM2WQ
UT WOS:000357543400004
DA 2024-07-18
ER

PT J
AU Mhamdi, MAA
   Ziou, D
AF Mhamdi, Mohammed Ayoub Alaoui
   Ziou, Djemel
TI A local approach for 3<i>D</i> object recognition through a set of size
   functions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D model description; Object recognition; Object categorization; Shape
   classification
ID SHAPE REPRESENTATION; RETRIEVAL; MODELS
AB In this paper, a local approach for 3D object recognition is presented. It is based on the topological invariants provided by the critical points of the 3D object. The critical points and the links between them are represented by a set of size functions obtained after splitting the 3D object into portions. A suitable similarity measure is used to compare the sets of size functions associated with the 3D objects. In order to validate our approach's recognition performance, we used different collections of 3D objects. The obtained scores are favourably comparable to the related work. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Mhamdi, Mohammed Ayoub Alaoui; Ziou, Djemel] Univ Sherbrooke, Sherbrooke, PQ J1K 2R1, Canada.
   [Ziou, Djemel] Univ Sherbrooke, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada.
C3 University of Sherbrooke; University of Sherbrooke
RP Mhamdi, MAA (corresponding author), Univ Sherbrooke, 2500 Blvd Univ, Sherbrooke, PQ J1K 2R1, Canada.
EM Mohammed.Ayoub.Alaoui.Mhamdi@USherbrooke.ca; Djemel.Ziou@usherbrooke.ca
FU computer science department, Faculty of science at the Universite de
   Sherbrooke; Natural Sciences and Engineering Research Council of Canada
   (NSERC)
FX The completion of this research was made possible thanks to the research
   scholarship of the computer science department, Faculty of science at
   the Universite de Sherbrooke, and the Natural Sciences and Engineering
   Research Council of Canada (NSERC).
CR [Anonymous], 2000, CVPRIP ALGORITHMS 3
   [Anonymous], SICE ICASE INT JOINT
   [Anonymous], P SPIE
   [Anonymous], P INT COMP S
   [Anonymous], SIGGRAPH COURSE NOTE
   [Anonymous], 2011, Analysis, Restoration, and Reconstruction of Ancient Artworks
   [Anonymous], 3D SHAP BENCHM
   [Anonymous], SPRINGER SERIES STAT
   [Anonymous], P ACM SIGGRAPH COURS
   [Anonymous], P IEEE WORKSH LEARN
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], AUTODESK 3DS MAX 8 R
   [Anonymous], KLUWER INT SERIES AD
   [Anonymous], AUTOCAD SECRETS EVER
   [Anonymous], COMPUTING SURVEYS
   [Anonymous], THESIS U N CAROLINA
   Arampatzis A, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P524, DOI 10.1145/1571941.1572031
   Assfalg J, 2006, MULTIMED TOOLS APPL, V31, P29, DOI 10.1007/s11042-006-0034-2
   Attene M, 2010, VISUAL COMPUT, V26, P1393, DOI 10.1007/s00371-010-0416-3
   Baeza-Yates R, 2000, SPIRE 2000: SEVENTH INTERNATIONAL SYMPOSIUM ON STRING PROCESSING AND INFORMATION RETRIEVAL - PROCEEDINGS, P28, DOI 10.1109/SPIRE.2000.878177
   Bagci U, 2012, IEEE T MED IMAGING, V31, P777, DOI 10.1109/TMI.2011.2180920
   BAREQUET G, 1995, COMPUT AIDED GEOM D, V12, P207, DOI 10.1016/0167-8396(94)00011-G
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Beis JS, 1999, IEEE T PATTERN ANAL, V21, P1000, DOI 10.1109/34.799907
   Biasotti S, 2008, J MATH IMAGING VIS, V32, P161, DOI 10.1007/s10851-008-0096-z
   Biasotti S, 2008, PATTERN RECOGN, V41, P2855, DOI 10.1016/j.patcog.2008.02.003
   Borodin P, 2002, ADVANCES IN MODELLING, ANIMATION AND RENDERING, P201
   Bosché F, 2010, ADV ENG INFORM, V24, P107, DOI 10.1016/j.aei.2009.08.006
   Bustos B, 2007, IEEE COMPUT GRAPH, V27, P22, DOI 10.1109/MCG.2007.80
   Chen Xiaofeng, 2012, 2012 Third International Conference on Digital Manufacturing and Automation (ICDMA), P1, DOI 10.1109/ICDMA.2012.1
   d'Amico M, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P1155
   d'Amico M, 2010, ACTA APPL MATH, V109, P527, DOI 10.1007/s10440-008-9332-1
   DICKINSON SJ, 2009, OBJECT CATEGORIZATIO
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Ferri M., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P223, DOI 10.1109/ACV.1994.341314
   Flitton Greg, 2010, BMVC, DOI [DOI 10.5244/C.24.11, 10.5244/C.24.11]
   FREEMAN JJ, 1969, PATTERN RECOGN, V1, P207, DOI 10.1016/0031-3203(69)90004-1
   Frosini P, 1999, INT J COMPUT MATH, V70, P505, DOI 10.1080/00207169908804771
   Frosini P., 1999, Pattern Recognition and Image Analysis, V9, P596
   Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Handouyahia M., 1999, Proceedings Vision Interface '99, P210
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Ion Adrian, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563032
   Laga H, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P75
   Lian ZH, 2012, PROC CVPR IEEE, P119, DOI 10.1109/CVPR.2012.6247666
   Liu R, 2007, COMPUT GRAPH FORUM, V26, P385, DOI 10.1111/j.1467-8659.2007.01061.x
   Lorensen W. E., 1987, COMPUT GRAPH, V21
   Mahmoudi S, 2002, INT C PATT RECOG, P457, DOI 10.1109/ICPR.2002.1048337
   Mamou K, 2009, IEEE IMAGE PROC, P3501, DOI 10.1109/ICIP.2009.5414068
   Merrell P., 2007, IEEE 11 INT C COMPUT, P1
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Obdr?zalek S., 2005, PROC 16 BRIT MACHINE, V1, P1
   Olson D.L., 2008, ADV DATA MINING TECH, DOI https://doi.org/10.1007/978-3-540-76917-0
   Pan X, 2009, PATTERN RECOGN LETT, V30, P11, DOI 10.1016/j.patrec.2008.08.014
   Pérez E, 2008, LECT NOTES COMPUT SC, V5259, P742, DOI 10.1007/978-3-540-88458-3_67
   Ponce J., 2006, Toward Category-Level Object Recognition
   Rabin J, 2010, LECT NOTES COMPUT SC, V6315, P771, DOI 10.1007/978-3-642-15555-0_56
   Terrades OR, 2009, IEEE T PATTERN ANAL, V31, P1630, DOI 10.1109/TPAMI.2008.224
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Sansoni G, 2009, SENSORS-BASEL, V9, P568, DOI 10.3390/s90100568
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Suresh S, 2008, INFORM SCIENCES, V178, P2621, DOI 10.1016/j.ins.2008.02.009
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Tung T., 2005, International Journal of Shape Modeling, V11, P91, DOI 10.1142/S0218654305000748
   Valero E, 2012, SENSORS-BASEL, V12, P5705, DOI 10.3390/s120505705
   Veltkamp RC, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P188, DOI 10.1109/SMA.2001.923389
   VERRI A, 1993, BIOL CYBERN, V70, P99, DOI 10.1007/BF00200823
   Verri A, 1996, IMAGE VISION COMPUT, V14, P189, DOI 10.1016/0262-8856(95)01056-4
   Villani C., 2003, TOPICS OPTIMAL TRANS
   Vrani D.V., 2001, P ECMCS 2001 3 EURAS, P271
   VRANIC DV, 2004, THESIS U LEIPZIG
   Wessel Raoul., 2009, Eurographics 2009 Workshop on 3D Object Retrieval, P53
   Zheng N, 2009, ADV PATTERN RECOGNIT, P1, DOI 10.1007/978-1-84882-312-9
   Zimmer H, 2013, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2013.280
NR 78
TC 7
Z9 7
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1030
EP 1044
DI 10.1016/j.imavis.2014.08.015
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600006
DA 2024-07-18
ER

PT J
AU He, J
   Zhang, DJ
   Balzano, L
   Tao, T
AF He, Jun
   Zhang, Dejiao
   Balzano, Laura
   Tao, Tao
TI Iterative Grassmannian optimization for robust image alignment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Robust subspace learning; Grassmannian optimization; Image alignment;
   ADMM (alternating direction method of multipliers)
AB Robust high-dimensional data processing has witnessed an exciting development in recent years. Theoretical results have shown that it is possible using convex programming to optimize data fit to a low-rank component plus a sparse outlier component. This problem is also known as robust PCA, and it has found application in many areas of computer vision. In image and video processing and face recognition, the opportunity to process massive image databases is emerging as people upload photo and video data online in unprecedented volumes. However, data quality and consistency is not controlled in any way, and the massiveness of the data poses a serious computational challenge. In this paper we present t-GRASTA, or "Transformed GRASTA (Grassmannian robust adaptive subspace tracking algorithm)". t-GRASTA iteratively performs incremental gradient descent constrained to the Grassmann manifold of subspaces in order to simultaneously estimate three components of a decomposition of a collection of images: a low-rank subspace, a sparse part of occlusions and foreground objects, and a transformation such as rotation or translation of the image. We show that t-GRASTA is 4x faster than state-of-the-art algorithms, has half the memory requirement, and can achieve alignment for face images as well as jittered camera surveillance images. (C) 2014 Elsevier B.V. All rights reserved.
C1 [He, Jun; Zhang, Dejiao; Tao, Tao] Nanjing Univ Informat Sci & Technol, Sch Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China.
   [Balzano, Laura] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
C3 Nanjing University of Information Science & Technology; University of
   Michigan System; University of Michigan
RP He, J (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China.
EM jhe@nuist.edu.cn; dejiao@umich.edu; girasole@umich.edu
RI He, Jun/B-4797-2008; , lantong/AAR-7206-2020
FU NSFC [61203273]; 3M
FX This work of Jun He is supported by NSFC (61203273). Laura Balzano would
   like to acknowledge 3M for generously supporting her Ph.D. studies.
CR Babwin Don., 2010, Cameras Make Chicago Most Closely Watched U.S. City
   Balzano L., 2010, 2010 48th Annual Allerton Conference on Communication, Control, and Computing (Allerton), P704, DOI 10.1109/ALLERTON.2010.5706976
   Bertsekas D. P., 2004, Nonlinear Programming
   Bertsekas Dimitri P., 2010, LIDSP2848 MIT LAB IN
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Boyd S., 2004, CONVEX OPTIMIZATION
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chandrasekaran V, 2011, SIAM J OPTIMIZ, V21, P572, DOI 10.1137/090761793
   COMON P, 1990, P IEEE, V78, P1327, DOI 10.1109/5.58320
   Cox M, 2009, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2009.5459430
   Cox MM, 2008, CRIT REV BIOCHEM MOL, V43, P1, DOI 10.1080/10409230801966713
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   He J., 2013, FAC GEST REC FG 2013
   He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848
   He Jun, 2011, ARXIV11093827
   Huang G. B., 2008, P EUR C COMP VIS WOR
   Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858
   Instagram, YEAR REV 2011 NUMB
   Jodoin PM, 2008, IEEE IMAGE PROC, P229, DOI 10.1109/ICIP.2008.4711733
   Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34
   Li RN, 2013, IEEE T PATTERN ANAL, V35, P697, DOI 10.1109/TPAMI.2012.144
   Mateos G, 2010, CONF REC ASILOMAR C, P1925, DOI 10.1109/ACSSC.2010.5757875
   McCahill M., 2002, WORKING PAPER, P6
   Odio S., MAKING FACEBOOK PHOT
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138
   Puglisi G, 2011, IEEE T CIRC SYST VID, V21, P1390, DOI 10.1109/TCSVT.2011.2162689
   Simonson K. M., 2009, SAND20095546, P1
   Sivalingam R., 2011, ROB AUT ICRA 2011 IE, P4234
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878
   Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x
NR 33
TC 38
Z9 43
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 800
EP 813
DI 10.1016/j.imavis.2014.02.015
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Elamsy, T
   Habed, A
   Boufama, B
AF Elamsy, Tarik
   Habed, Adlane
   Boufama, Boubakeur
TI Self-calibration of stationary non-rotating zooming cameras
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camera auto/self-calibration; Zooming cameras; Plane at infinity;
   Parallel planes; 3D reconstruction
ID RECONSTRUCTION
AB This paper proposes a new method for self-calibrating a set of stationary non-rotating zooming cameras. This is a realistic configuration, usually encountered in surveillance systems, in which each zooming camera is physically attached to a static structure (wall, ceiling, robot, or tripod). In particular, a linear, yet effective method to recover the affine structure of the observed scene from two or more such stationary zooming cameras is presented. The proposed method solely relies on point correspondences across images and no knowledge about the scene is required. Our method exploits the mostly translational displacement of the so-called principal plane of each zooming camera to estimate the location of the plane at infinity. The principal plane of a camera, at any given setting of its zoom, is encoded in its corresponding perspective projection matrix from which it can be easily extracted. As a displacement of the principal plane of a camera under the effect of zooming allows the identification of a pair of parallel planes, each zooming camera can be used to locate a line on the plane at infinity. Hence, two or more such zooming cameras in general positions allow the obtainment of an estimate of the plane at infinity making it possible, under the assumption of zero-skew and/or known aspect ratio, to linearly calculate the camera's parameters. Finally, the parameters of the camera and the coordinates of the plane at infinity are refined through a nonlinear least-squares optimization procedure. The results of our extensive experiments using both simulated and real data are also reported in this paper. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Elamsy, Tarik; Boufama, Boubakeur] Univ Windsor, Windsor, ON N9B 3P4, Canada.
   [Habed, Adlane] Univ Strasbourg, ICube CNRS, Illkirch Graffenstaden, France.
C3 University of Windsor; Universites de Strasbourg Etablissements
   Associes; Universite de Strasbourg
RP Elamsy, T (corresponding author), Univ Windsor, Windsor, ON N9B 3P4, Canada.
EM elamsy@uwindsor.ca; habed@unistra.fr; boufama@uwindsor.ca
FU National Science and Engineering Research Council of Canada (NSERC)
FX This work has been partly supported by the National Science and
   Engineering Research Council of Canada (NSERC).
CR Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694
   [Anonymous], THESIS CARNEGIE MELL
   Boyd S., 2004, CONVEX OPTIMIZATION
   Chandraker M, 2010, INT J COMPUT VISION, V90, P236, DOI 10.1007/s11263-009-0305-2
   Chandraker Manmohan., 2007, IEEE Int'l Conf. on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383288
   Gherardi R, 2010, LECT NOTES COMPUT SC, V6311, P790, DOI 10.1007/978-3-642-15549-9_57
   Habed A, 2012, LECT NOTES COMPUT SC, V7577, P710, DOI 10.1007/978-3-642-33783-3_51
   Habed A, 2010, IEEE IMAGE PROC, P4249, DOI 10.1109/ICIP.2010.5651899
   Hartley R. I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P510, DOI 10.1109/ICCV.1999.791264
   Hartley R.I., 2004, MULTIPLE VIEW GEOMET, V2nd, P238
   Hartley RI, 1997, INT J COMPUT VISION, V22, P5, DOI 10.1023/A:1007957826135
   Hartley RI, 2002, LECT NOTES COMPUT SC, V2351, P433
   Hayman E, 2003, IEEE T PATTERN ANAL, V25, P1015, DOI 10.1109/TPAMI.2003.1217605
   Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362
   Hu ZY, 2003, PATTERN RECOGN LETT, V24, P2909, DOI 10.1016/S0167-8655(03)00123-5
   Ji Q, 2004, IEEE T ROBOTIC AUTOM, V20, P1, DOI 10.1109/TRA.2003.820921
   Kahl F, 2000, J MATH IMAGING VIS, V13, P131, DOI 10.1023/A:1026524030731
   Li H., 2006, P IEEE INT C VID SIG
   Li MX, 1996, IEEE T PATTERN ANAL, V18, P1105, DOI 10.1109/34.544080
   Nistér D, 2004, INT J COMPUT VISION, V60, P165, DOI 10.1023/B:VISI.0000029667.76852.a1
   Pollefeys M, 1999, IEEE T PATTERN ANAL, V21, P707, DOI 10.1109/34.784285
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   Pollefeys M., 1996, Proceedings of the European Conference on Computer Vision, P31
   Rothwell C. A., 1995, EUR CHIN WORKSH GEOM
   Sturm P., 1995, Computer Analysis of Images and Patterns. 6th International Conference, CAIP'95. Proceedings, P838
   Szeliski R., 2014, COMPUTER VISION ALGO
   Valdés A, 2006, INT J COMPUT VISION, V66, P283, DOI 10.1007/s11263-005-3677-y
   Yongduek Seo, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P183, DOI 10.1109/ICCV.1999.791216
NR 28
TC 7
Z9 10
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2014
VL 32
IS 3
BP 212
EP 226
DI 10.1016/j.imavis.2014.01.003
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AE3CG
UT WOS:000333854000005
DA 2024-07-18
ER

PT J
AU Huang, L
   Yin, F
   Chen, QH
   Liu, CL
AF Huang, Liang
   Yin, Fei
   Chen, Qing-Hu
   Liu, Cheng-Lin
TI Keyword spotting in unconstrained handwritten Chinese documents using
   contextual word model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Keyword spotting; Chinese handwritten documents; Word similarity;
   Contextual word model
ID RETRIEVAL; SHAPE; SEGMENTATION; RECOGNITION; ONLINE
AB This paper proposes a method for keyword spotting in off-line Chinese handwritten documents using a contextual word model, which measures the similarity between the query word and every candidate word in the document by combining a character classifier and the geometric context as well as linguistic context. The geometric context model characterizes the single-character likeliness and between-character relationship. The linguistic model utilizes the dependency of the word with the external adjacent characters. The combining weights are optimized on training documents. Experiments on a large handwriting database CASIA-HWDB demonstrate the effectiveness of the proposed method and justify the benefits of geometric and linguistic contexts. Compared to transcription-based text search, the proposed method can provide higher recall rate, and for spotting words of four characters, the proposed method provides both higher precision and recall rate. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Huang, Liang; Chen, Qing-Hu] Wuhan Univ, Sch Elect Informat, Wuhan 430079, Hubei, Peoples R China.
   [Yin, Fei; Liu, Cheng-Lin] Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China.
C3 Wuhan University; Chinese Academy of Sciences; Institute of Automation,
   CAS
RP Liu, CL (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
EM liucl@nlpr.ia.ac.cn
RI Liu, Cheng-Lin/JCO-6642-2023
FU National Basic Research Program of China (973 Program) [2012CB316302];
   National Natural Science Foundation of China (NSFC) [60933010, 60825301]
FX This work was supported in part by the National Basic Research Program
   of China (973 Program) Grant 2012CB316302, the National Natural Science
   Foundation of China (NSFC) Grants 60933010 and 60825301.
CR Cao HG, 2009, PATTERN RECOGN, V42, P3374, DOI 10.1016/j.patcog.2009.02.003
   Cheng-Lin Liu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3328, DOI 10.1109/ICPR.2010.813
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Doermann D, 1998, COMPUT VIS IMAGE UND, V70, P287, DOI 10.1006/cviu.1998.0692
   Fei Yin, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P7, DOI 10.1109/ICFHR.2010.9
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Gillick L, 1997, INT CONF ACOUST SPEE, P879, DOI 10.1109/ICASSP.1997.596076
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Heng Zhang, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P271, DOI 10.1109/ICFHR.2010.49
   Howe NR, 2009, PATTERN RECOGN, V42, P3338, DOI 10.1016/j.patcog.2009.01.012
   Huang L, 2011, PROC INT CONF DOC, P78, DOI 10.1109/ICDAR.2011.25
   Jawahar CV, 2009, PATTERN RECOGN, V42, P1445, DOI 10.1016/j.patcog.2008.08.017
   Jin XB, 2010, PATTERN RECOGN, V43, P2428, DOI 10.1016/j.patcog.2010.01.013
   Kameshiro T., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P597, DOI 10.1109/ICDAR.2001.953859
   Kameshiro T., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P681, DOI 10.1109/ICDAR.1999.791879
   Kesidis AL, 2011, INT J DOC ANAL RECOG, V14, P131, DOI 10.1007/s10032-010-0134-4
   Khurshid K, 2012, PATTERN RECOGN, V45, P2598, DOI 10.1016/j.patcog.2011.10.013
   Kolcz A, 2000, PATTERN ANAL APPL, V3, P153, DOI 10.1007/s100440070020
   KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482
   Leydier Y, 2007, PATTERN RECOGN, V40, P3552, DOI 10.1016/j.patcog.2007.04.024
   Liu CL, 2007, IEEE T PATTERN ANAL, V29, P1465, DOI 10.1109/TPAMI.2007.1090
   Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17
   Liu CL, 2005, PATTERN RECOGN, V38, P2242, DOI 10.1016/j.patcog.2005.04.019
   Liu CL, 2002, IEEE T PATTERN ANAL, V24, P1425, DOI 10.1109/TPAMI.2002.1046151
   Lopresti D., 1994, P 4 INT WORKSH FRONT, P156
   Lu SJ, 2008, IEEE T PATTERN ANAL, V30, P1913, DOI 10.1109/TPAMI.2008.89
   Lu Y, 2004, INT J PATTERN RECOGN, V18, P229, DOI 10.1142/S0218001404003137
   Mangasarian OL, 1999, IEEE T NEURAL NETWOR, V10, P1032, DOI 10.1109/72.788643
   Mitra M., 2004, INF RETR, V2, P141
   Nagasaki T, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P280, DOI 10.1109/IWFHR.2004.36
   Oda H, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P545, DOI 10.1109/IWFHR.2004.9
   Rath T.M., 2004, 27 ANN INT ACM SIGIR
   Rath TM, 2003, PROC CVPR IEEE, P521
   Rodríguez-Serrano JA, 2009, PATTERN RECOGN, V42, P2106, DOI 10.1016/j.patcog.2009.02.005
   Saykol E, 2004, IEEE T IMAGE PROCESS, V13, P314, DOI 10.1109/TIP.2003.821114
   Senda S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P541, DOI 10.1109/ICDAR.1993.395677
   Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264
   Yaodong He, 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P685, DOI 10.1109/ICDAR.1999.791880
   Yin F, 2009, PATTERN RECOGN, V42, P3146, DOI 10.1016/j.patcog.2008.12.013
   Zhang B, 2004, PROC SPIE, V5296, P45
   Zhuang YT, 2004, LECT NOTES COMPUT SC, V3331, P17
NR 42
TC 8
Z9 13
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2013
VL 31
IS 12
BP 958
EP 968
DI 10.1016/j.imavis.2013.10.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 282DU
UT WOS:000329151300006
DA 2024-07-18
ER

PT J
AU Dong, FF
   Chen, ZS
   Wang, JW
AF Dong, Fangfang
   Chen, Zengsi
   Wang, Jinwei
TI A new level set method for inhomogeneous image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Level set method; Inhomogeneous image segmentation; Local image
   information; Global image information
ID ACTIVE CONTOURS; BIAS FIELD; MUMFORD; FRAMEWORK; EVOLUTION; ENERGY;
   MODEL
AB Intensity inhomogeneity often appears in medical images, such as X-ray tomography and magnetic resonance (MR) images, due to technical limitations or artifacts introduced by the object being imaged. It is difficult to segment such images by traditional level set based segmentation models. In this paper, we propose a new level set method integrating local and global intensity information adaptively to segment inhomogeneous images. The local image information is associated with the intensity difference between the average of local intensity distribution and the original image, which can significantly increase the contrast between foreground and background. Thus, the images with intensity inhomogeneity can be efficiently segmented. What is more, to avoid the re-initialization of the level set function and shorten the computational time, a simple and fast level set evolution formulation is used in the numerical implementation. Experimental results on synthetic images as well as real medical images are shown in the paper to demonstrate the efficiency and robustness of the proposed method. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Dong, Fangfang] Zhejiang Gongshang Univ, Sch Math & Stat, Hangzhou 310018, Zhejiang, Peoples R China.
   [Chen, Zengsi] Zhejiang Chinese Med Univ, Coll Pharmaceut Sci, Hangzhou 310053, Zhejiang, Peoples R China.
   [Wang, Jinwei] Zhejiang Univ, Ctr Math Sci, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang Chinese Medical University;
   Zhejiang University
RP Dong, FF (corresponding author), Zhejiang Gongshang Univ, Sch Math & Stat, Hangzhou 310018, Zhejiang, Peoples R China.
EM fangdong06@gmail.com
RI Dong, Fangfang/JGE-5095-2023
OI Dong, Fangfang/0000-0003-2914-3227
FU National Natural Science Foundation of China [11101365, 11001239]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 11101365 and 11001239).
CR AMBROSIO L, 1992, B UNIONE MAT ITAL, V6B, P105
   [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   [Anonymous], 2003, Geometric Level Set Methods in Imaging, Vision, and Graphics
   [Anonymous], 2004, Int. J. Numer. Anal. Model
   Awate SP, 2006, LECT NOTES COMPUT SC, V3952, P494
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen Y., 2011, NEUROCOMPUTING, DOI DOI 10.1016/INEUC0M2011.06.006
   Esedoglu S, 2006, J COMPUT PHYS, V211, P367, DOI 10.1016/j.jcp.2005.05.027
   EVANS LC, 1992, COMMUN PUR APPL MATH, V45, P1097, DOI 10.1002/cpa.3160450903
   Fedkiw R., 2003, LEVEL SET METHODS DY
   Guillemaud R, 1997, IEEE T MED IMAGING, V16, P238, DOI 10.1109/42.585758
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Li CM, 2009, LECT NOTES COMPUT SC, V5636, P288
   Li CM, 2008, LECT NOTES COMPUT SC, V5242, P1083
   Li CM, 2005, PROC CVPR IEEE, P430
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   MERRIMAN B, 1992, 9218 CAM UCLA
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Piovano J, 2007, LECT NOTES COMPUT SC, V4485, P709
   Sethian J., 1999, LEVEL SET METHODS FA
   Shah J, 1996, PROC CVPR IEEE, P136, DOI 10.1109/CVPR.1996.517065
   Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174
   Tai X.-C., 2005, 0524 CAM UCLA
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P885, DOI 10.1109/42.811268
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang L, 2008, LECT NOTES COMPUT SC, V5241, P384, DOI 10.1007/978-3-540-85988-8_46
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Wang XF, 2009, LECT NOTES ARTIF INT, V5755, P670, DOI 10.1007/978-3-642-04020-7_72
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   Yu Y, 2010, LECT NOTES COMPUT SC, V6165, P163
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang Y, 2008, MEDIVIS 2008: FIFTH INTERNATIONAL CONFERENCE BIOMEDICAL VISUALIZATION - INFORMATION VISUALIZATION IN MEDICAL AND BIOMEDICAL INFORMATICS, PROCEEDINGS, P71, DOI 10.1109/MediVis.2008.12
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
   Zhu GP, 2007, OPT ENG, V46, DOI 10.1117/1.2740762
NR 39
TC 66
Z9 83
U1 0
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 809
EP 822
DI 10.1016/j.imavis.2013.08.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900011
DA 2024-07-18
ER

PT J
AU Jelaca, V
   Pizurica, A
   Niño-Castañeda, JO
   Frías-Velazquez, A
   Philips, W
AF Jelaca, Vedran
   Pizurica, Aleksandra
   Nino-Castaneda, Jorge Oswaldo
   Frias-Velazquez, Andres
   Philips, Wilfried
TI Vehicle matching in smart camera networks using image projection
   profiles at multiple instances
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-camera tracking; Feature extraction; Appearance modeling; Object
   recognition; Traffic surveillance
ID TRACKING; RECOGNITION
AB Tracking vehicles using a network of cameras with non-overlapping views is a challenging problem of great importance in traffic surveillance. One of the main challenges is accurate vehicle matching across the cameras. Even if the cameras have similar views on vehicles, vehicle matching remains a difficult task due to changes of their appearance between observations, and inaccurate detections and occlusions, which often occur in real scenarios. To be executed on smart cameras the matching has also to be efficient in terms of needed data and computations. To address these challenges we present a low complexity method for vehicle matching robust against appearance changes and inaccuracies in vehicle detection. We efficiently represent vehicle appearances using signature vectors composed of Radon transform like projections of the vehicle images and compare them in a coarse-to-fine fashion using a simple combination of 1-D correlations. To deal with appearance changes we include multiple observations in each vehicle appearance model. These observations are automatically collected along the vehicle trajectory. The proposed signature vectors can be calculated in low-complexity smart cameras, by a simple scan-line algorithm of the camera software itself, and transmitted to the other smart cameras or to the central server. Extensive experiments based on real traffic surveillance videos recorded in a tunnel validate our approach. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Jelaca, Vedran; Pizurica, Aleksandra; Nino-Castaneda, Jorge Oswaldo; Frias-Velazquez, Andres; Philips, Wilfried] Univ Ghent, Dept Telecommun & Informat Proc, TELIN IPI IBBT, B-9000 Ghent, Belgium.
C3 Ghent University
RP Jelaca, V (corresponding author), Univ Ghent, Dept Telecommun & Informat Proc, TELIN IPI IBBT, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM vedranjelaca@telin.ugent.be
RI Pizurica, Aleksandra/ISU-9519-2023; Pizurica, Aleksandra/AAG-4687-2021;
   Frias-Velazquez, Andres/A-8292-2010
OI Pizurica, Aleksandra/0000-0002-9322-4999; Pizurica,
   Aleksandra/0000-0002-9322-4999; Frias-Velazquez,
   Andres/0000-0003-4706-7950
FU Flemish Interdisciplinary Institute for Broadband Technology (IBBT)
FX This research has been supported by the Flemish Interdisciplinary
   Institute for Broadband Technology (IBBT).
CR [Anonymous], COMP VIS PATT REC WO
   [Anonymous], P INT JOINT C ART IN
   [Anonymous], IMAGE PROCESSING LIN
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Betke M, 2000, MACH VISION APPL, V12, P69, DOI 10.1007/s001380050126
   Bischof H, 2004, COMPUT VIS IMAGE UND, V95, P86, DOI 10.1016/j.cviu.2004.01.002
   Collins R., 2001, P IEEE, V89, P7
   Guo YL, 2007, IEEE T PATTERN ANAL, V29, P824, DOI 10.1109/TPAMI.2007.1052
   Hou T., 2010, INT C COMP VIS PATT
   Hou T, 2009, PROC CVPR IEEE, P290
   Javed O, 2005, PROC CVPR IEEE, P26
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   Kettnaker V., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P253, DOI 10.1109/CVPR.1999.784638
   Lee S., 2007, INT C COMP VIS PATT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Porikli F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P133
   Rios-Cabrera R, 2012, COMPUT VIS IMAGE UND, V116, P742, DOI 10.1016/j.cviu.2012.02.006
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951
   Shan Y, 2005, IEEE I CONF COMP VIS, P378
   Shan Y, 2008, IEEE T PATTERN ANAL, V30, P700, DOI 10.1109/TPAMI.2007.70728
   Sidla O, 2004, ITSC 2004: 7TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P531
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
NR 24
TC 16
Z9 16
U1 0
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2013
VL 31
IS 9
BP 673
EP 685
DI 10.1016/j.imavis.2013.06.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220EG
UT WOS:000324564300008
OA Green Published
DA 2024-07-18
ER

PT J
AU Nayak, NM
   Zhu, YY
   Roy-Chowdhury, AK
AF Nayak, Nandita M.
   Zhu, Yingying
   Roy-Chowdhury, Amit K.
TI Vector field analysis for multi-object behavior modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optical flow; Helmholtz decomposition; Complex activity recognition
ID RECOGNITION
AB This paper proposes an end-to-end system to recognize multi-person behaviors in video, unifying different tasks like segmentation, modeling and recognition within a single optical flow based motion analysis framework We show how optical flow can be used for analyzing activities of individual actors, as opposed to dense crowds, which is what the existing literature has concentrated on mostly. The algorithm consists of two steps - identification of motion patterns and modeling of motion patterns. Activities are analyzed using the underlying motion patterns which are formed by the optical flow field over a period of time. Streaklines are used to capture these motion patterns via integration of the flow field. To recognize the regions of interest, we utilize the Helmholtz decomposition to compute the divergence potential. The extrema or critical points of this potential indicates regions of high activity in the video, which are then represented as motion patterns by clustering the streaklines. We then present a method to compare two videos by measuring the similarity between their motion patterns using a combination of shape theory and subspace analysis. Such an analysis allows us to represent, compare and recognize a wide range of activities. We perform experiments on state-of-the-art datasets and show that the proposed method is suitable for natural videos in the presence of noise, background clutter and high intra class variations. Our method has two significant advantages over recent related approaches - it provides a single framework that takes care of both low-level and high-level visual analysis tasks, and is computationally efficient. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Nayak, Nandita M.; Zhu, Yingying; Roy-Chowdhury, Amit K.] Univ Calif Riverside, Riverside, CA 92521 USA.
C3 University of California System; University of California Riverside
RP Roy-Chowdhury, AK (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.
EM nandita.nayak@email.ur.edu; yzhu001@ucr.edu; amitrc@ee.ucr.edu
RI zhu, yingying/K-8170-2018
OI Roy-Chowdhury, Amit/0000-0001-6690-9725
FU NSF [IIS-0905671]; DARPA VIRAT program; Direct For Computer & Info Scie
   & Enginr [0905671] Funding Source: National Science Foundation; Div Of
   Information & Intelligent Systems [0905671] Funding Source: National
   Science Foundation
FX This work has been partially supported by NSF grant IIS-0905671 and the
   DARPA VIRAT program.
CR [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], INT C COMP VIS
   [Anonymous], INT C COMP VIS
   Bissacco A., 2005, COMPUT VISION PATTER, V2
   Blank M., 2011, INT C COMP VIS
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Brendel W, 2011, PROC CVPR IEEE
   Chaudhary R., 2009, COMPUTER VISION PATT
   Doretto G., 2003, DYNAMIC TEXTURES
   Efros A., 2003, INT C COMP VIS
   Ghosh P, 2010, IEEE T IMAGE PROCESS, V19, P478, DOI 10.1109/TIP.2009.2033983
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Hu M., 2008, INT C PATT REC
   Ke Y., 2005, INT C COMP VIS
   Kuettel D., 2010, COMPUTER VISION PATT
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2006, LECT NOTES COMPUT SC, V3667, P91
   Lee MW, 2009, IEEE T PATTERN ANAL, V31, P27, DOI 10.1109/TPAMI.2008.35
   Mehran R., 2010, EUR C COMP VIS
   Oh S., 2011, COMPUTER VISION PATT
   PARK S, 2003, ACM SIGMM INT WORKSH
   Ryoo M., 2006, COMPUTER VISION PATT
   Ryoo M. S., 2010, INT C PATT REC
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Theisel H., 2002, INT C CENTR EUR COMP
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Vaswani N., 2003, COMPUTER VISION PATT
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Wada T, 2000, IEEE T PATTERN ANAL, V22, P873, DOI 10.1109/34.868687
NR 29
TC 7
Z9 7
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2013
VL 31
IS 6-7
BP 460
EP 472
DI 10.1016/j.imavis.2012.08.011
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 172UH
UT WOS:000321029900005
DA 2024-07-18
ER

PT J
AU Penne, T
   Tilmant, C
   Chateau, T
   Barra, V
AF Penne, Thomas
   Tilmant, Christophe
   Chateau, Thierry
   Barra, Vincent
TI Markov Chain Monte Carlo Modular Ensemble Tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object tracking; Classification; Boosting; Feature spaces; Particle
   filtering
ID PARTICLE FILTER; OBJECT MOTION; MCMC; CUES
AB Recent years have been characterized by the overgrowth of video-surveillance systems and by automation of the processing they integrate. Object Tracking has become a recurrent problem in video-surveillance and is a very important domain in computer vision. It was recently approached using classification techniques and still more recently using boosting methods.
   We propose in this paper a new machine learning based strategy to build the observation model of tracking systems. The global observation function results of a linear combination of several simplest observation functions so-called modules (one per visual cue). Each module is built using a Adaboost-like algorithm, derived from the Ensemble Tracking Algorithm. The importance of each module is estimated using an original probabilistic sequential filtering framework with a joint state model composed by both the spatial object parameters and the importance parameters of the observation modules.
   Our system is tested on challenging sequences which prove its performance for tracking and scaling on fix and mobile cameras and we compare the robustness of our algorithm with the state of the art. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Penne, Thomas] Prynel, RD Corpeau 974, F-21190 Meursault, France.
   [Barra, Vincent] Univ Blaise Pascal, Clermont Univ, LIMOS, F-63000 Clermont Ferrand, France.
   [Tilmant, Christophe; Chateau, Thierry] Univ Blaise Pascal, Clermont Univ, Inst Pascal, F-63000 Clermont Ferrand, France.
   [Tilmant, Christophe; Chateau, Thierry] CNRS, UMR 6602, Inst Pascal, F-63173 Aubiere, France.
   [Barra, Vincent] CNRS, UMR 6158, LIMOS, F-63173 Aubiere, France.
C3 Universite Clermont Auvergne (UCA); Centre National de la Recherche
   Scientifique (CNRS); Universite Clermont Auvergne (UCA); Centre National
   de la Recherche Scientifique (CNRS); Centre National de la Recherche
   Scientifique (CNRS); Universite Clermont Auvergne (UCA); CNRS -
   Institute for Engineering & Systems Sciences (INSIS); Centre National de
   la Recherche Scientifique (CNRS); Universite Clermont Auvergne (UCA)
RP Barra, V (corresponding author), CNRS, UMR 6158, LIMOS, F-63173 Aubiere, France.
EM vincent.barra@univ-bpclermont.fr
RI Barra, Vincent/KGL-8172-2024; Barra, Vincent/AAS-8453-2021
OI Barra, Vincent/0000-0002-8975-222X
CR Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116
   [Anonymous], BRIT MASCH VIS C
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Berzuini C, 1997, J AM STAT ASSOC, V92, P1403, DOI 10.2307/2965410
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Brasnett P, 2007, IMAGE VISION COMPUT, V25, P1217, DOI 10.1016/j.imavis.2006.07.017
   BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755
   Chateau T., 2006, ECCV 06 WORKSH DYN V, P218
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Godec M., 2009, P WORKSH AUSTR AUSTR, P234
   Goldberg AB, 2011, P 25 AAAI C ART INT
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hu W., 2006, IMPLEMENTATION DISCU
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Khan Z, 2004, LECT NOTES COMPUT SC, V2034, P279
   Leichter I, 2010, COMPUT VIS IMAGE UND, V114, P400, DOI 10.1016/j.cviu.2009.12.006
   MacCormick J., 2000, IEEE European Conference on Computer Vision, P3, DOI DOI 10.1007/3-540-45053-X1
   MAGGIO E., 2011, VIDEO TRACKING THEOR
   Nickel K, 2008, LECT NOTES COMPUT SC, V5305, P514, DOI 10.1007/978-3-540-88693-8_38
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Penne T., 2010, 2 INT C IM PROC THEO, P363
   Platt JC, 2000, ADV NEUR IN, P61
   Stalder Severin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1409, DOI 10.1109/ICCVW.2009.5457445
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Williams O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P353
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 36
TC 2
Z9 2
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2013
VL 31
IS 6-7
BP 434
EP 447
DI 10.1016/j.imavis.2012.09.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 172UH
UT WOS:000321029900003
DA 2024-07-18
ER

PT J
AU Salti, S
   Di Stefano, L
AF Salti, Samuele
   Di Stefano, Luigi
TI On-line Support Vector Regression of the transition model for the Kalman
   filter
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Adaptive transition model; Visual tracking; Support Vector Regression;
   Kalman filter; Interacting Multiple Models
ID TRACKING
AB Recursive Bayesian Estimation (RBE) is a widespread solution for visual tracking as well as for applications in other domains where a hidden state is estimated recursively from noisy measurements. From a practical point of view, deployment of RBE filters is limited by the assumption of complete knowledge on the process and measurement statistics. These missing tokens of information lead to an approximate or even uninformed assignment of filter parameters. Unfortunately, the use of the wrong transition or measurement model may lead to large estimation errors or to divergence, even when the otherwise optimal filter is deployed. In this paper on-line learning of the transition model via Support Vector Regression is proposed. The specialization of this general framework for linear/Gaussian filters, which we dub Support Vector Kalman (SVK), is then introduced and shown to outperform a standard, non adaptive Kalman filter as well as a widespread solution to cope with unknown transition models such as the Interacting Multiple Models (IMM) filter. (C) 2012 Elsevier B.V. All rights reserved.
RP Salti, S (corresponding author), Via Risorgimento 2, I-40135 Bologna, Italy.
EM samuele.salti@unibo.it; luigi.distefano@unibo.it
OI Salti, Samuele/0000-0001-5609-426X
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Avidan S, 2005, PROC CVPR IEEE, P494
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Burlet J., 2006, IEEE INT TRANSP SYST, P462
   Cao L., 2002, INTELL DATA ANAL, V6, P67, DOI DOI 10.3233/IDA-2002-6105
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chu W, 2004, IEEE T NEURAL NETWOR, V15, P29, DOI 10.1109/TNN.2003.820830
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Farmer ME, 2002, INT C PATT RECOG, P20, DOI 10.1109/ICPR.2002.1048226
   Gao JB, 2002, MACH LEARN, V46, P71, DOI 10.1023/A:1012494009640
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Harville M, 2004, PROC CVPR IEEE, P398
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Liang Y, 2004, SIGNAL PROCESS, V84, P2175, DOI 10.1016/j.sigpro.2004.06.021
   Lin C.J., 2004, TECHNICAL REPORT
   Mazor E, 1998, IEEE T AERO ELEC SYS, V34, P103, DOI 10.1109/7.640267
   MEHRA RK, 1972, IEEE T AUTOMAT CONTR, VAC17, P693, DOI 10.1109/TAC.1972.1100100
   Oussalah M., 2000, P INT C NOISE VIBRAT, P1225
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Platt John C., FAST TRAINING SUPPOR, P185
   Poggio T., 2001, 198AI CBCL MIT ART I
   Pontil M., 1998, On the noise model of support vector machine regression
   Ristic B., 2003, Beyond the Kalman Filter: Particle Filters for Tracking Applications
   Salti S., P 2 INT WORKSH MACH
   Salti S, 2012, IEEE T IMAGE PROCESS, V21, P4334, DOI 10.1109/TIP.2012.2206035
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   Weng SK, 2006, J VIS COMMUN IMAGE R, V17, P1190, DOI 10.1016/j.jvcir.2006.03.004
   Smola A., 1998, TUTORIAL SUPPORT VEC
   Zhang Y., P IEEE INT C INF ACQ, P11
NR 31
TC 10
Z9 11
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2013
VL 31
IS 6-7
BP 487
EP 501
DI 10.1016/j.imavis.2012.09.008
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 172UH
UT WOS:000321029900007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Glasner, D
   Galun, M
   Alpert, S
   Basri, R
   Shakhnarovich, G
AF Glasner, Daniel
   Galun, Meirav
   Alpert, Sharon
   Basri, Ronen
   Shakhnarovich, Gregory
TI Viewpoint-aware object detection and continuous pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Viewpoint-aware; Object detection; Pose estimation; 3D model; Viewpoint
   estimation; Structure from motion
ID MODEL
AB We describe an approach to category-level detection and viewpoint estimation for rigid 3D objects from single 2D images. In contrast to many existing methods, we directly integrate 3D reasoning with an appearance-based voting architecture. Our method relies on a nonparametric representation of a joint distribution of shape and appearance of the object class. Our voting method employs a novel parameterization of joint detection and viewpoint hypothesis space, allowing efficient accumulation of evidence. We combine this with a re-scoring and refinement mechanism, using an ensemble of view-specific support vector machines. We evaluate the performance of our approach in detection and pose estimation of cars on a number of benchmark datasets. Finally we introduce the "Weizmann Cars ViewPoint" (WCVP) dataset, a benchmark for evaluating continuous pose estimation. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Glasner, Daniel; Galun, Meirav; Alpert, Sharon; Basri, Ronen] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.
   [Shakhnarovich, Gregory] Toyota Technol Inst, Chicago, IL USA.
C3 Weizmann Institute of Science; Toyota Technological Institute - Chicago
RP Glasner, D (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.
EM daniel.glasner@weizmann.ac.il; meirav.galun@weizmann.ac.il;
   sharon.alpert@weizmann.ac.il; ronen.basri@weizmann.ac.il;
   gregory@ttic.edu
FU Israeli Ministry of Science and Technology [3-8700]; Israel Science
   Foundation [628/08]; Vulcan Consortium; Magnet Program of the Israeli
   Ministry of Commerce, Trade and Labor, Chief Scientist Office; Moross
   Laboratory for Vision Research and Robotics
FX Research supported in part by the Israeli Ministry of Science and
   Technology, grant number 3-8700, by the Israel Science Foundation grant
   number 628/08 and by the Vulcan Consortium funded by the Magnet Program
   of the Israeli Ministry of Commerce, Trade and Labor, Chief Scientist
   Office. The vision group at the Weizmann Institute is supported in part
   by the Moross Laboratory for Vision Research and Robotics.
CR [Anonymous], NONPARAMETRIC VOTING
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2005, Learning Task-Specific Similarity
   [Anonymous], 2008, Proc. IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2008, MESHLAB OPEN SOURCE, DOI DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], COMP VIS PATT REC CV
   Arie-Nachimson M, 2009, IEEE I CONF COMP VIS, P1341, DOI 10.1109/ICCV.2009.5459310
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Glasner D, 2011, IEEE I CONF COMP VIS, P1275, DOI 10.1109/ICCV.2011.6126379
   Gu CH, 2010, LECT NOTES COMPUT SC, V6315, P408
   Hao S, 2009, IEEE I CONF COMP VIS, P213, DOI 10.1109/ICCV.2009.5459168
   Hu WZ, 2010, PROC CVPR IEEE, P2273, DOI 10.1109/CVPR.2010.5539910
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Maji S, 2009, PROC CVPR IEEE, P1038, DOI 10.1109/CVPRW.2009.5206693
   Mount D., 1997, CGC 2 ANN FALL WORKS
   Nister David, 2006, CVPR
   Özuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633
   Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342
   Pepik B, 2012, PROC CVPR IEEE, P3362, DOI 10.1109/CVPR.2012.6248075
   Savarese S, 2007, IEEE I CONF COMP VIS, P1245
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Sun M, 2010, LECT NOTES COMPUT SC, V6315, P658, DOI 10.1007/978-3-642-15555-0_48
   Sun M, 2009, PROC CVPR IEEE, P1247, DOI 10.1109/CVPRW.2009.5206723
   Thomas Alexander., 2006, CVPR (2), P1589
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Villamizar M., 2011, BRIT MACHINE VISION, P1
   Yan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2466, DOI 10.1109/CVPRW.2009.5206799
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zia M. Z., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P569, DOI 10.1109/ICCVW.2011.6130294
NR 39
TC 24
Z9 27
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 923
EP 933
DI 10.1016/j.imavis.2012.09.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, S
   Ruan, QQ
   Wang, CT
   An, GY
AF Liu, Shuai
   Ruan, Qiuqi
   Wang, Chuantao
   An, Gaoyun
TI Tensor rank one differential graph preserving analysis for facial
   expression recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dimensionality reduction; Differential graph preserving; Rank-one
   tensor; Tensor rank-one decomposition; Facial expression recognition
ID MULTILINEAR DISCRIMINANT-ANALYSIS; CLASSIFICATION
AB This paper presents a new dimensionality reduction algorithm for multi-dimensional data based on the tensor rank-one decomposition and graph preserving criterion. Through finding proper rank-one tensors, the algorithm effectively enhances the pairwise inter-class margins and meanwhile preserves the intra-class local manifold structure. In the algorithm, a novel marginal neighboring graph is devised to describe the pairwise inter-class boundaries, and a differential formed objective function is adopted to ensure convergence. Furthermore, the algorithm has less computation in comparison with the vector representation based and the tensor-to-tensor projection based algorithms. The experiments for the basic facial expressions recognition show its effectiveness, especially when it is followed by a neural network classifier. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Liu, Shuai; Ruan, Qiuqi; An, Gaoyun] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Liu, Shuai; Ruan, Qiuqi; An, Gaoyun] Key Lab Adv Informat Sci & Network Technol, Beijing 100044, Peoples R China.
   [Wang, Chuantao] Beijing Univ Civil Engn & Architecture, Sch Mech Elect & Automobile Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing University of Civil Engineering &
   Architecture
RP Liu, S (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM sliu012@gmail.com; qqruan@center.njtu.edu.cn; wangchuantao000@gmail.com;
   gyan@bjtu.edu.cn
FU National Natural Science Foundation of China [60973060, 61003114];
   Fundamental Research Funds for the Central Universities [2011JBM020]
FX This paper was supported by the National Natural Science Foundation of
   China (Grant No. 60973060), the National Natural Science Foundation of
   China (61003114), and the Fundamental Research Funds for the Central
   Universities (2011JBM020).
CR Abboud B, 2004, INT C PATT RECOG, P163, DOI 10.1109/ICPR.2004.1333729
   [Anonymous], THESIS U CALIFORNIA
   [Anonymous], P INT WORKSH AN MOD
   [Anonymous], P ICCV WORKSH HCI
   [Anonymous], 2006, P 21 NAT C ART INT
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Ekman P., 2003, UNMASKING FACE GUIDE
   Gang Hua, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Guo GD, 2005, IEEE T SYST MAN CY B, V35, P477, DOI 10.1109/TSMCB.2005.846658
   Haykin S., 1994, NEURAL NETWORKS COMP
   He X., 2003, ADV NEURAL INFORM PR, P153
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kolda TG, 2001, SIAM J MATRIX ANAL A, V23, P243, DOI 10.1137/S0895479800368354
   Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536
   Liang D, 2005, PATTERN RECOGN LETT, V26, P2374, DOI 10.1016/j.patrec.2005.04.011
   Liu S, 2010, INT CONF SIGN PROCES, P1410, DOI 10.1109/ICOSP.2010.5656924
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004
   Lu HP, 2009, IEEE T NEURAL NETWOR, V20, P103, DOI 10.1109/TNN.2008.2004625
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shashua A, 2001, PROC CVPR IEEE, P42
   Tao DC, 2008, NEUROCOMPUTING, V71, P1866, DOI 10.1016/j.neucom.2007.08.036
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Wang H, 2008, NEUROCOMPUTING, V71, P1889, DOI 10.1016/j.neucom.2007.10.022
   Wang HC, 2004, INT C PATT RECOG, P44, DOI 10.1109/ICPR.2004.1334001
   Wang HC, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P958, DOI 10.1109/ICCV.2003.1238452
   Wang J, 2007, COMPUT VIS IMAGE UND, V108, P19, DOI 10.1016/j.cviu.2006.10.011
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan SC, 2005, PROC CVPR IEEE, P526
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Ye J, 2004, ADV NEURAL INFORM PR, P1569
   Zafeiriou S, 2009, IEEE T NEURAL NETWOR, V20, P217, DOI 10.1109/TNN.2008.2005293
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
   Zhao Li-Zhuang, 1999, Chinese Journal of Computers, V22, P627
NR 42
TC 13
Z9 13
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 535
EP 545
DI 10.1016/j.imavis.2012.05.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100014
DA 2024-07-18
ER

PT J
AU Wang, ZJ
   Ben Salah, M
   Zhang, H
   Ray, N
AF Wang, Zhijie
   Ben Salah, Mohamed
   Zhang, Hong
   Ray, Nilanjan
TI Shape based appearance model for kernel tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object tracking; Appearance model; Shape cue
ID VISUAL TRACKING; OBJECT TRACKING; ACTIVE CONTOURS
AB This paper investigates kernel based tracking using shape information. A kernel based tracker typically models an object with a primitive geometric shape, and then estimates the object state by fitting the kernel such that the appearance model is optimized. Most of the appearance models in kernel based tracking utilize the textural information within the kernel, although a few of them also make use of the gradient information along the kernel boundary. Interestingly, shape information of a general form has never been fully exploited in kernel tracking, despite the fact that shape has been widely used in silhouette tracking at the cost of intensive computation. In this paper, we propose an original way to incorporate shape knowledge into the appearance model of kernel based trackers while preserving their computational advantage versus silhouette based trackers. Experimental results demonstrate that kernel tracking is strongly improved by exploiting the proposed shape cue through comparisons to both kernel and silhouette trackers. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Wang, Zhijie; Ben Salah, Mohamed; Zhang, Hong; Ray, Nilanjan] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
C3 University of Alberta
RP Wang, ZJ (corresponding author), Univ Alberta, Dept Comp Sci, 221 Athabasca Hall, Edmonton, AB T6G 2E8, Canada.
EM zhijie@ualberta.ca
CR [Anonymous], PATTERN RECOGNITION
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Branson K, 2005, PROC CVPR IEEE, P1039
   Brasnett P, 2005, PROC SPIE, V5685, P430, DOI 10.1117/12.585882
   Brasnett P, 2007, IMAGE VISION COMPUT, V25, P1217, DOI 10.1016/j.imavis.2006.07.017
   CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871
   Chang Wen-Yan, 2006, INT C PATT REC HONG, V3, P83
   Charmi MA, 2008, PATTERN RECOGN LETT, V29, P897, DOI 10.1016/j.patrec.2008.01.011
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161
   Davis Jesse, 2006, P 23 INT C MACH LEAR, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]
   Du W, 2008, LECT NOTES COMPUT SC, V5303, P225, DOI 10.1007/978-3-540-88688-4_17
   Freedman D, 2004, IEEE T IMAGE PROCESS, V13, P518, DOI 10.1109/TIP.2003.821445
   Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Kwon J, 2009, PROC CVPR IEEE, P991, DOI 10.1109/CVPRW.2009.5206501
   Leichter I, 2009, IEEE T PATTERN ANAL, V31, P164, DOI 10.1109/TPAMI.2008.194
   Leichter I, 2006, INT J COMPUT VISION, V67, P343, DOI 10.1007/s11263-006-5568-2
   Li M, 2010, PROC CVPR IEEE, P1315, DOI 10.1109/CVPR.2010.5539815
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374
   Maggio E, 2005, INT CONF ACOUST SPEE, P221
   Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621
   MEYER Y., 1993, SOC IND APPL MATH
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   Nilufar S, 2009, IEEE IMAGE PROC, P861, DOI 10.1109/ICIP.2009.5414312
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ponsa D, 2009, PATTERN RECOGN, V42, P2372, DOI 10.1016/j.patcog.2009.04.007
   Ristic B., 2003, Beyond the Kalman Filter: Particle Filters for Tracking Applications
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145
   Schoenemann T., 2008, CVPR, P1
   Sethian J., 1999, LEVEL SET METHODS FA
   Shi JC, 2009, IEEE IMAGE PROC, P2385, DOI 10.1109/ICIP.2009.5414517
   Stoyan D., 1995, Fractals, Random Shapes and Point Fields
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
   Wang ZJ, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P14, DOI 10.1109/ICAPR.2009.52
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang Hong., 2008, IEEE SIGNAL PROC MAG, V25, P198
NR 48
TC 2
Z9 3
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2012
VL 30
IS 4-5
BP 332
EP 344
DI 10.1016/j.imavis.2012.03.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 964WF
UT WOS:000305726700006
DA 2024-07-18
ER

PT J
AU Lucey, P
   Cohn, JF
   Prkachin, KM
   Solomon, PE
   Chew, S
   Matthews, I
AF Lucey, Patrick
   Cohn, Jeffrey F.
   Prkachin, Kenneth M.
   Solomon, Patricia E.
   Chew, Sien
   Matthews, Iain
TI Painful monitoring: Automatic pain monitoring using the UNBC-McMaster
   shoulder pain expression archive database
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Pain; Active Appearance Models (AAMs); Action Units (AUs); FACS
ID VALIDITY
AB In intensive care units in hospitals, it has been recently shown that enormous improvements in patient outcomes can be gained from the medical staff periodically monitoring patient pain levels. However, due to the burden/stress that the staff are already under, this type of monitoring has been difficult to sustain so an automatic solution could be an ideal remedy. Using an automatic facial expression system to do this represents an achievable pursuit as pain can be described via a number of facial action units (AUs). To facilitate this work, the "University of Northern British Columbia-McMaster Shoulder Pain Expression Archive Database" was collected which contains video of participant's faces (who were suffering from shoulder pain) while they were performing a series of range-of-motion tests. Each frame of this data was AU coded by certified FACS coders, and self-report and observer measures at the sequence level were taken as well. To promote and facilitate research into pain and augmentcurrent datasets, we have publicly made available a portion of this database, which includes 200 sequences across 25 subjects, containing more than 48,000 coded frames of spontaneous facial expressions with 66-point AMM tracked facial feature landmarks. In addition to describing the data distribution, we give baseline pain and AU detection results on a frame-by-frame basis at the binary-level (i.e. AU vs. no-AU and pain vs. no-pain) using our AAM/SVM system. Another contribution we make is classifying pain intensities at the sequence-level by using facial expressions and 3D head pose changes. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Lucey, Patrick; Matthews, Iain] Disney Res Pittsburgh, Pittsburgh, PA USA.
   [Lucey, Patrick; Cohn, Jeffrey F.] Univ Pittsburgh, Dept Psychol, Pittsburgh, PA 15260 USA.
   [Lucey, Patrick; Cohn, Jeffrey F.; Matthews, Iain] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   [Solomon, Patricia E.] McMaster Univ, Sch Rehabil Sci, Hamilton, ON, Canada.
   [Chew, Sien] Queensland Univ Technol, SAIVT Lab, Brisbane, Qld 4001, Australia.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh; Carnegie Mellon University; McMaster University;
   Queensland University of Technology (QUT)
RP Lucey, P (corresponding author), Disney Res Pittsburgh, Pittsburgh, PA USA.
EM pjlucey@gmail.com
OI Solomon, Patricia/0000-0002-5014-0795
CR Anastasi A., 1997, Psychological testing, V7e
   Ashraf AB, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P9
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cortes C, 2004, ADV NEUR IN, V16, P313
   Craig K.D., 2001, HDB PAIN ASSESSMENT, P153
   Ekman P, 1978, FACIAL ACTION CODING
   Gawande A., 2010, The checklist manifesto: how to get things right
   HEFT MW, 1980, PAIN, V9, P363, DOI 10.1016/0304-3959(80)90050-0
   Hsu Chih-Wei., 2005, A practical guide to support vector classification
   Lucey P., P INT C AFF COMP INT, P1
   Lucey S., 2007, FACE RECOGNITION BOO
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Matthews I., 2010, IEEE T SYST MAN CY B
   Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010
   PRKACHIN KM, 1992, PAIN, V51, P297, DOI 10.1016/0304-3959(92)90213-U
   PRKACHIN KM, 1989, PAIN, V39, P257, DOI 10.1016/0304-3959(89)90038-9
   Turk D.C., 2001, HDB PAIN ASSESSMENT
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Williams ACD, 2000, PAIN, V85, P457, DOI 10.1016/S0304-3959(99)00299-7
   Wong D L, 1988, Pediatr Nurs, V14, P9
   Xiao J., P IEEE C COMP VIS PA, P535
NR 24
TC 103
Z9 112
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 197
EP 205
DI 10.1016/j.imavis.2011.12.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000008
DA 2024-07-18
ER

PT J
AU Srikrishnan, V
   Chaudhuri, S
AF Srikrishnan, V.
   Chaudhuri, Subhasis
TI Adaptive smoothness based robust active contours
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active contours; Segmentation; Tracking; Space varying smoothness term
ID SNAKES; SHAPE
AB Active contours are a popular class of variational models used in computer vision for tracking and segmentation. The variational model consists of a data-fitting and a regularisation term. Depending on the data-fitting term, active contour models are classified as either gradient or region based models. An often overlooked but crucial aspect of these models is that these two terms are weighted by a manually set constant weight. This constant weight often leads to incorrect segmentation, particularly for gradient based energies. This failure rate is high in the presence of strong gradients nearby the target or when the object gradient is not uniformly strong. In such circumstances, setting the weight becomes a critical and often unsatisfying task. In this work, we propose a new spatially varying and dynamic curve evolution term for robust segmentation of gradient based models. In contrast to the majority of the existing work in literature which focuses on defining new data-fitting terms, the evolution term proposed here is related to the regularisation of evolution. The intuition here is that in images although object boundaries are generally continuous, the magnitude of the gradient map so generated is not uniformly strong. Therefore, any energy formulation which fixes the weights of the data-fitting and regularisation term will run into the problems mentioned above. In this work, we propose an energy term which defines the regularisation term in a spatially varying manner. The advantage of this term is that it is independent of the image based data-fitting energy term and hence can be plugged into the vast variety of the existing gradient based active contour models. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Srikrishnan, V.; Chaudhuri, Subhasis] Indian Inst Technol, Vis & Image Proc Lab, Dept Elect Engn, Bombay 400076, Maharashtra, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bombay
RP Srikrishnan, V (corresponding author), Indian Inst Technol, Vis & Image Proc Lab, Dept Elect Engn, Bombay 400076, Maharashtra, India.
EM v.srikrishnan@gmail.com; sc@ee.iitb.ac.in
RI Srikrishnan, Vivek/J-1966-2015
FU Naval Research Board, India
FX The authors are grateful to Sheshadri Thiruvenkadam (GE Global Research)
   for his comments during the preparation of the manuscript. The authors
   are also thankful to the reviewers for their constructive comments.
   Financial support from Naval Research Board, India is gratefully
   acknowledged.
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], CAVIAR DATABASE
   Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CHAN T, SIAM J APPL MATH, V62
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Charpiat G, 2007, INT J COMPUT VISION, V73, P325, DOI 10.1007/s11263-006-9966-2
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Cong G, 1998, INT C PATT RECOG, P708, DOI 10.1109/ICPR.1998.711242
   Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4
   Delingette H, 2001, COMPUT VIS IMAGE UND, V83, P140, DOI 10.1006/cviu.2001.0920
   Fantoni C, 2003, J VISION, V3, P281, DOI 10.1167/3.4.4
   Fua P., 1990, Machine Vision and Applications, V3, P45, DOI 10.1007/BF01211451
   GRAYSON M, 1987, J DIFFER GEOM, V23, P69
   Kaniza G., 1971, ITAL J PSYCH, V1, P93
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417
   LI C, 2005, CVPR 05, V1, P162
   NGOI KP, 1996, ECCV 96 P 4 EUR C CO, V2, P335
   OLIVIER NP, 2001, IEEE INT C COMP VIS, P67
   Osher S., 2003, LEVEL SET METHOD DYN
   Paragios N, 2005, COMPUT VIS IMAGE UND, V97, P259, DOI 10.1016/j.cviu.2003.04.001
   Rochery M, 2006, INT J COMPUT VISION, V69, P27, DOI 10.1007/s11263-006-6851-y
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562
   Sarti A, 2002, INT J COMPUT VISION, V46, P201, DOI 10.1023/A:1014028906229
   Schoenemann Thomas, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Sethian J., 1999, LEVEL SET METHODS FA
   Sharon E, 2000, IEEE T PATTERN ANAL, V22, P1117, DOI 10.1109/34.879792
   Srikrishnan V, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P417, DOI 10.1109/ICAPR.2009.18
   Xie XH, 2008, IEEE T PATTERN ANAL, V30, P632, DOI 10.1109/TPAMI.2007.70737
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 2000, CONF REC ASILOMAR C, P483, DOI 10.1109/ACSSC.2000.911003
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 35
TC 3
Z9 4
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2011
VL 29
IS 5
BP 317
EP 328
DI 10.1016/j.imavis.2010.12.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 751FT
UT WOS:000289603600003
DA 2024-07-18
ER

PT J
AU Doshi, A
   Bors, AG
AF Doshi, Ashish
   Bors, Adrian G.
TI Smoothing of optical flow using robustified diffusion kernels
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Anisotropic diffusion; Robust statistics; Optical flow smoothing
ID EDGE-DETECTION; SEGMENTATION; REGULARIZATION; IMAGES; PDES
AB This paper proposes a new optical flow smoothing methodology combining vector diffusion and robust statistics. Vector smoothing using diffusion preserves moving object boundaries and the main motion discontinuities. According to a study provided in the paper, diffusion does not remove the outliers but spreads them out, introducing a bias in the neighbourhood. In this paper robust statistics operators such as the median and alpha-trimmed mean are considered for robustifying the diffusion kernels. The robust diffusion smoothing process is extended to 3-D lattices as well. The proposed algorithms are applied for smoothing artificially generated vector fields as well as the optical flow estimated from image sequences. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Doshi, Ashish; Bors, Adrian G.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
C3 University of York - UK
RP Bors, AG (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
EM adrian.bors@cs.york.ac.uk
RI Doshi, Ashish/A-6438-2013; Bors, Adrian G./T-3618-2019
OI Bors, Adrian G./0000-0001-7838-0021; Doshi, Ashish/0000-0002-5831-5844
CR ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Bors AG, 1998, IEEE T IMAGE PROCESS, V7, P693, DOI 10.1109/83.668026
   Bors AG, 2000, IEEE T IMAGE PROCESS, V9, P1441, DOI 10.1109/83.855440
   Bors AG, 2003, IEEE T PATTERN ANAL, V25, P974, DOI 10.1109/TPAMI.2003.1217602
   Bors AG, 1999, IEEE T IMAGE PROCESS, V8, P1744, DOI 10.1109/83.806620
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Doshi A, 2006, IEEE IMAGE PROC, P1225, DOI 10.1109/ICIP.2006.312546
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hummel R. A., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P668
   HUMMEL RA, 1987, COMPUT VISION GRAPH, V38, P66, DOI 10.1016/S0734-189X(87)80153-6
   James G., 2001, MODERN ENG MATH, V3rd
   Kanazawa Y, 2003, ELECTRON COMM JPN 3, V86, P1, DOI 10.1002/ecjc.10042
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057
   Lucas B. D., 1981, P IJCAI, P674
   Luck BL, 2005, IEEE T IMAGE PROCESS, V14, P1265, DOI 10.1109/TIP.2005.852460
   Mémin E, 2002, INT J COMPUT VISION, V46, P129, DOI 10.1023/A:1013539930159
   Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Roth S, 2005, IEEE I CONF COMP VIS, P42
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Tschumperlé D, 2002, INT J COMPUT VISION, V50, P237, DOI 10.1023/A:1020870207168
   Unal G, 2002, IEEE T IMAGE PROCESS, V11, P1405, DOI 10.1109/TIP.2002.804568
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Widder D.V., 1975, The Heat Equation
   YAU ST, 1999, DIFFERENTIAL GEOMETR, V5
NR 29
TC 14
Z9 16
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1575
EP 1589
DI 10.1016/j.imavis.2010.04.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300001
DA 2024-07-18
ER

PT J
AU Lughofer, E
AF Lughofer, Edwin
TI On-line evolving image classifiers and their application to surface
   inspection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Evolving image classifiers; Incremental learning; Evolving vector
   quantization; Evolving fuzzy classifiers; On-line surface inspection
   systems
ID CLASSIFICATION; IDENTIFICATION
AB In this paper, we present image classifiers which are able to adapt and evolve themselves at an on-line machine vision system. These classifiers are initially trained on some pre-labelled training data and further updated based on newly recorded samples, for instance during a production process. The evolution and adaptation mechanism is necessary in order to guarantee a process-save on-line system as usually the pre-labelled data does not cover all possible operating conditions, system states or image classes. It is also recommended for a refinement of the classifiers during the on-line mode in order to boost predictive performance with more loaded samples. We will present two types of on-line evolving image classifiers: The first one is a clustering-based classification approach, which exploits conventional vector quantization, forming an incremental evolving variant around it and extending it to the supervised classification case. The second one is an evolving fuzzy classifier approach which comes with two model architectures, classical single model and a novel multi-model architecture, the later exploiting indicator matrices/vectors for training. The approaches are evaluated in three different on-line surface inspection systems dealing with CD imprint inspection, egg inspection and inspection of metal rotor parts. The evaluation will show the impact of on-line evolved versus 'static' classifiers kept fixed during the whole on-line process. (C) 2009 Elsevier B.V. All rights reserved.
C1 Johannes Kepler Univ Linz, Dept Knowledge Based Math Syst, A-4040 Linz, Austria.
C3 Johannes Kepler University Linz
RP Lughofer, E (corresponding author), Johannes Kepler Univ Linz, Dept Knowledge Based Math Syst, Altenbergerstr 69, A-4040 Linz, Austria.
EM edwin.lughofer@jku.at
OI Lughofer, Edwin/0000-0003-1560-5136
FU EC [016429]; Project DynaVis; Upper Austrian Technology and Research
   Promotion
FX This work was funded by the EC under Grant No. 016429, project DynaVis
   and the Upper Austrian Technology and Research Promotion. It reflects
   only the authors' views.
CR Angelov PP, 2004, IEEE T SYST MAN CY B, V34, P484, DOI 10.1109/TSMCB.2003.817053
   [Anonymous], 1995, SELF ORG MAPS
   [Anonymous], HDB BRAIN THEORY NEU
   [Anonymous], 1996, P AAAI INT C KNOWL D
   [Anonymous], P 6 INT S SIGN PROC
   Awad M, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P134
   Bosch A, 2007, IMAGE VISION COMPUT, V25, P778, DOI 10.1016/j.imavis.2006.07.015
   Breiman L., 1993, METRIKA
   Caleb-Solly P, 2007, IMAGE VISION COMPUT, V25, P1058, DOI 10.1016/j.imavis.2006.04.023
   Draper N. R., 2014, Applied regression analysis
   Eitzinger C, 2008, LECT NOTES COMPUT SC, V5008, P445
   El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569
   Friedman J., 2001, ELEMENTS STAT LEARNI, V1, DOI DOI 10.1007/978-0-387-84858-7
   GAYUBO F, 2006, P 18 INT C PATT REC
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   GRUNDITZ C, 2005, P INT JOINT C NEUR N
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hotta K, 2008, IMAGE VISION COMPUT, V26, P1490, DOI 10.1016/j.imavis.2008.04.008
   Iivarinen J, 1998, INT C PATT RECOG, P117, DOI 10.1109/ICPR.1998.711094
   KIM CW, 1994, PATTERN RECOGN LETT, V15, P713, DOI 10.1016/0167-8655(94)90076-0
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Lewis D.D., 1994, MACH LEARN P 1994, P148
   Li WH, 2000, J PROCESS CONTR, V10, P471, DOI 10.1016/S0959-1524(00)00022-6
   Lughofer E, 2008, PATTERN RECOGN, V41, P995, DOI 10.1016/j.patcog.2007.07.019
   Mohammed S, 2004, 1ST CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P172, DOI 10.1109/CCCRV.2004.1301441
   Nakashima T, 2007, FUZZY SET SYST, V158, P284, DOI 10.1016/j.fss.2006.10.011
   Nauck D, 1998, BT TECHNOL J, V16, P180, DOI 10.1023/A:1009610822227
   Ng WWY, 2007, PATTERN RECOGN, V40, P19, DOI 10.1016/j.patcog.2006.07.002
   Nixon M.S., 2002, FEATURE EXTRACTION I
   Papari G, 2005, LECT NOTES COMPUT SC, V3704, P497, DOI 10.1007/11565123_48
   Piegat A, 2001, Fuzzy Modeling and Control
   QINA L, 2008, IMAGE VISION COMPUT, V26, P647
   Raghavan H, 2006, J MACH LEARN RES, V7, P1655
   Raiser S, 2010, MACH VISION APPL, V21, P627, DOI 10.1007/s00138-009-0205-z
   Roubos JA, 2003, INFORM SCIENCES, V150, P77, DOI 10.1016/S0020-0255(02)00369-9
   Shackelford AK, 2003, IEEE T GEOSCI REMOTE, V41, P2354, DOI 10.1109/TGRS.2003.815972
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Varma M, 2004, IMAGE VISION COMPUT, V22, P1175, DOI 10.1016/j.imavis.2004.03.012
   WANG LX, 1992, IEEE T NEURAL NETWOR, V3, P807, DOI 10.1109/72.159070
   WANG LX, 1992, P IEEE INT C FUZZ SY, P1163, DOI DOI 10.1109/FUZZY.1992.258721
   Yang CY, 2005, IMAGE VISION COMPUT, V23, P427, DOI 10.1016/j.imavis.2004.11.004
NR 43
TC 27
Z9 30
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2010
VL 28
IS 7
SI SI
BP 1065
EP 1079
DI 10.1016/j.imavis.2009.07.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 603UP
UT WOS:000278233900002
DA 2024-07-18
ER

PT J
AU Pronobis, A
   Jie, L
   Caputo, B
AF Pronobis, Andrzej
   Jie, Luo
   Caputo, Barbara
TI The more you learn, the less you store: Memory-controlled incremental
   SVM for visual place recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Incremental learning; Knowledge transfer; Support vector machines; Place
   recognition; Visual robot localization
ID LOCALIZATION; APPEARANCE; SLAM
AB The capability to learn from experience is a key property for autonomous cognitive systems working in realistic settings. To this end, this paper presents an SVM-based algorithm, capable of learning model representations incrementally while keeping under control memory requirements. We combine an incremental extension of SVMs [43] with a method reducing the number of support vectors needed to build the decision function without any loss in performance [15] introducing a parameter which permits a user-set trade-off between performance and memory. The resulting algorithm is able to achieve the same recognition results as the original incremental method while reducing the memory growth. Our method is especially suited to work for autonomous systems in realistic settings. We present experiments on two common scenarios in this domain: adaptation in presence of dynamic changes and transfer of knowledge between two different autonomous agents, focusing in both cases on the problem of visual place recognition applied to mobile robot topological localization. Experiments in both scenarios clearly show the power of our approach. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Pronobis, Andrzej] Royal Inst Technol KTH, CAS CVAP, SE-10044 Stockholm, Sweden.
   [Jie, Luo; Caputo, Barbara] Idiap Res Inst, CH-1920 Martigny, Switzerland.
   [Jie, Luo] Swiss Fed Inst Technol Lausanne EPFL, CH-1015 Lausanne, Switzerland.
C3 Royal Institute of Technology; Swiss Federal Institutes of Technology
   Domain; Ecole Polytechnique Federale de Lausanne
RP Pronobis, A (corresponding author), Royal Inst Technol KTH, CAS CVAP, SE-10044 Stockholm, Sweden.
EM pronobis@csc.kth.se; jluo@idiap.ch; bcaputo@idiap.ch
RI Caputo, Barbara/F-3928-2011; Hajra, Suvadeep/L-8460-2015; Caputo,
   Barbara/J-8976-2015
OI Caputo, Barbara/0000-0001-7169-0158
FU EU [IST-027787 DIRAC]; Swedish Research Council [2005-3600-Complex]; EU
   [IST-027787 DIRAC]; Swedish Research Council [2005-3600-Complex]
FX This work was sponsored by the EU FP7 Project CogX (A. Pronobis) and
   IST-027787 DIRAC (B. Caputo, L. Jie), and the Swedish Research Council
   Contract 2005-3600-Complex (A. Pronobis). The support is gratefully
   acknowledged.
CR [Anonymous], P IEEE INT C ROB AUT
   [Anonymous], 1999, P WORKSH SUPP VECT M
   [Anonymous], P EUR C MOB ROB ECMR
   [Anonymous], P IEEE RSJ INT C INT
   [Anonymous], 2007, P IEEE RSJ INT C INT
   [Anonymous], P IEEE INT C ROB AUT
   Artac M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1025, DOI 10.1109/ROBOT.2002.1013490
   Belongie S, 2002, LECT NOTES COMPUT SC, V2352, P531
   Caputo B, 2005, IEEE I CONF COMP VIS, P1597, DOI 10.1109/iccv.2005.54
   Cauwenberghs G, 2001, ADV NEUR IN, V13, P409
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   *COGNIRON, COGN ROB COMP
   *COSY, COGN SYST COGN ASS
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381
   Domeniconi C, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P589, DOI 10.1109/ICDM.2001.989572
   Dorko Gyuri., 2005, Object Class Recognition Using Discriminative Local Features
   DOWNS T, 2002, J MACHINE LEARNING R, V2
   Folkesson J, 2005, IEEE INT CONF ROBOT, P30
   FRITZ M, 2005, P INT C COMP VIS ICC
   Golub Gene H, 2012, MATRIX COMPUTATIONS
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Jogan M, 2003, ROBOT AUTON SYST, V45, P51, DOI 10.1016/S0921-8890(03)00064-2
   Konidaris G., 2006, ACM INT C P SERIES, V148, DOI [10.1145/1143844.1143906, DOI 10.1145/1143844.1143906]
   KORTENKAMP D, 1994, P 12 NAT C ART INT S
   Kruijff G.-J., 2007, Int. J. of Advanced Robotic Systems, V4
   KUIPERS B, 2002, P 18 NAT C ART INT A
   Lazaric A., 2008, P 25 INT C MACHINE L, P544, DOI DOI 10.1145/1390156.1390225
   Linde O, 2004, INT C PATT RECOG, P1, DOI 10.1109/ICPR.2004.1333965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LUO J, 2006, 304 CVAP KTH
   MALAK RJ, 2001, P 2001 IEEE INT C RO
   MIKOLAJCZYK K, 2001, P 8 IEEE INT C COMP
   Mitchell T M, 2006, DISCIPLINE MACHINE L, V9
   MOZOS O, 2007, ROBOTICS AUTONOMOUS, V55
   Murillo AC, 2008, ROBOT AUTON SYST, V56, P512, DOI 10.1016/j.robot.2008.03.003
   NOURBAKHSH I, 1995, AI MAG, V16, P53
   ORABONA F, 2007, 18 BRIT MACH VIS C B
   PRONOBIS A, 2005, THESIS KUNGLIGA TEKN
   Pronobis A, 2008, P IEEE INT C ROB AUT
   PRONOBIS A, 2007, P IEEE RSJ INT C INT
   PRONOBIS A, 2009, INT J ROBOTICS RES I, V28
   Pronobis A., 2006, P IEEE RSJ INT C INT
   Skocaj D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1494
   TAPUS A, 2005, P IEEE RSJ INT C INT
   THRUN S, 1998, ARTIFICIAL INTELLIGE, V1999
   Thrun Sebastian, 1995, ROBOTICS AUTONOMOUS, V15
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   WALLRAVEN C, 2003, P 9 IEEE INT C COMP
   Wolf J, 2005, IEEE T ROBOT, V21, P208, DOI 10.1109/TRO.2004.835453
NR 51
TC 29
Z9 33
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2010
VL 28
IS 7
SI SI
BP 1080
EP 1097
DI 10.1016/j.imavis.2010.01.015
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 603UP
UT WOS:000278233900003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pan, H
   Jin, LZ
   Yuan, XH
   Xia, SY
   Xia, LZ
AF Pan, Hong
   Jin, Li-Zuo
   Yuan, Xiao-Hui
   Xia, Si-Yu
   Xia, Liang-Zheng
TI Context-based embedded image compression using binary wavelet transform
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Binary wavelet transform; Context modeling; Embedded image compression
ID PREDICTION; EFFICIENT
AB Binary wavelet transform (BWT) has several distinct advantages over the real wavelet transform (RWT), such as the conservation of alphabet size of wavelet coefficients, no quantization introduced during the transform and the simple Boolean operations involved. Thus, less coding passes are engaged and no sign bits are required in the compression of transformed coefficients. However, the use of BWT for the embedded grayscale image compression is not well established. This paper proposes a novel Context-based Binary Wavelet Transform Coding approach (CBWTC) that combines the BWT with a high-order context-based arithmetic coding scheme to embedded compression of grayscale images. In our CBWTC algorithm, BWT is applied to decorrelate the linear correlations among image coefficients without expansion of the alphabet size of symbols. In order to match up with the CBWTC algorithm, we employ the gray code representation (GCR) to remove the statistical dependencies among bi-level bitplane images and develop a combined arithmetic coding scheme. In the proposed combined arithmetic coding scheme, three high-pass BWT coefficients at the same location are combined to form an octave symbol and then encoded with a ternary arithmetic coder. In this way, the compression performance of our CBWTC algorithm is improved in that it not only alleviate the degradation of predictability caused by the BWT, but also eliminate the correlation of BWT coefficients in the same level subbands. The conditional context of the CBWTC is properly modeled by exploiting the characteristics of the BWT as well as taking advantages of non-causal adaptive context modeling. Experimental results show that the average coding performance of the CBWTC is superior to that of the state-of-the-art grayscale image coders, and always outperforms the JBIG2 algorithm and other BWT-based binary coding technique for a set of test images with different characteristics and resolutions. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Pan, Hong; Jin, Li-Zuo; Yuan, Xiao-Hui; Xia, Si-Yu; Xia, Liang-Zheng] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Pan, H (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
EM enhpan@seu.edu.cn
RI Xia, Siyu/AAB-6524-2020; Yuan, Xiaohui/AAQ-1172-2020
OI Pan, Hong/0000-0002-0539-7997
FU National Natural Science Foundation of China [60805002, 90820009];
   Foundation for Eminent Young Scholars of Southeast University
   [4008001015]; State Scholarship Fund of China
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 60805002 and 90820009. Foundation for
   Eminent Young Scholars of Southeast University under Grant 4008001015
   and the State Scholarship Fund of China.
CR Adams MD, 2000, IEEE T IMAGE PROCESS, V9, P1010, DOI 10.1109/83.846244
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   COOKLEV T, 1994, P AS PAC C CIRC SYST, P260
   EGGER O, 1995, P IEEE, V83, P272, DOI 10.1109/5.364462
   Gerek ON, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P899, DOI 10.1109/ICIP.1996.561050
   Hamming R. W., 1986, Coding and Information Theory
   Hankerson D., 1998, Introduction to Information Theory and Data Compression
   *ISO IEC, 1999, N1359 ISOIEC JTC1SC2
   *ISO IEC, 2000, 1575 ISOIEC JTC 1SC
   Kamstra L, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P241
   Kamstra L, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P593, DOI 10.1109/ICIP.2002.1039040
   LANGDON GG, 1981, IEEE T COMMUN, V29, P858, DOI 10.1109/TCOM.1981.1095052
   Law NF, 2007, SIGNAL PROCESS, V87, P2850, DOI 10.1016/j.sigpro.2007.05.022
   Pan H, 2007, IET IMAGE PROCESS, V1, P353, DOI 10.1049/iet-ipr:20060195
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Phoong SM, 1997, IEEE T SIGNAL PROCES, V45, P1443, DOI 10.1109/78.599956
   Reavy MD, 2001, IEEE T IMAGE PROCESS, V10, P669, DOI 10.1109/83.918560
   RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Singh R, 2007, IEEE T IMAGE PROCESS, V16, P1937, DOI 10.1109/TIP.2007.901246
   Swanson MD, 1996, IEEE T IMAGE PROCESS, V5, P1637, DOI 10.1109/83.544571
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   TITU T., 1993, INF TECHN COD REPR P
   Wu X., 1997, P 31 ASILOMAR C SIGN, V2, P1378, DOI DOI 10.1109/DCC.1997.582047
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Zhang N, 2006, IEEE T IMAGE PROCESS, V15, P1379, DOI 10.1109/TIP.2005.871116
   Zhang Y, 2008, IEEE T IMAGE PROCESS, V17, P924, DOI 10.1109/TIP.2008.920772
NR 29
TC 7
Z9 8
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 991
EP 1002
DI 10.1016/j.imavis.2009.11.013
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200013
DA 2024-07-18
ER

PT J
AU Thomaz, CE
   Giraldi, GA
AF Thomaz, Carlos Eduardo
   Giraldi, Gilson Antonio
TI A new ranking method for principal components analysis and its
   application to face image analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Principal components analysis; Separating hyperplanes; High dimensional
   problems; Face image analysis
ID DIMENSION REDUCTION; FEATURE-EXTRACTION; DISCRIMINANT
AB In this work, we investigate a new ranking method for principal component analysis (PCA). Instead of sorting the principal components in decreasing order of the corresponding eigenvalues, we propose the idea of using the discriminant weights given by separating hyperplanes to select among the principal components the most discriminant ones. The method is not restricted to any particular probability density function of the sample groups because it can be based on either a parametric or non-parametric separating hyperplane approach. In addition, the number of meaningful discriminant directions is not limited to the number of groups, providing additional information to understand group differences extracted from high-dimensional problems. To evaluate the discriminant principal components, separation tasks have been performed using face images and three different databases. Our experimental results have shown that the principal components selected by the separating hyperplanes allow robust reconstruction and interpretation of the data, as well as higher recognition rates using less linear features in situations where the differences between the sample groups are subtle and consequently most difficult for the standard and state-of-the-art PCA selection methods. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Thomaz, Carlos Eduardo] FEI, Dept Elect Engn, Sao Paulo, Brazil.
   [Giraldi, Gilson Antonio] LNCC, Dept Comp, Rio De Janeiro, Brazil.
C3 Centro Universitario da FEI; Laboratorio Nacional de Computacao
   Cientifica (LNCC)
RP Thomaz, CE (corresponding author), FEI, Dept Elect Engn, Sao Paulo, Brazil.
EM cet@fei.edu.br
RI Thomaz, Carlos/AAF-1878-2019; Giraldi, Gilson Antonio/AAS-7135-2020
OI Thomaz, Carlos/0000-0001-5566-1963; Giraldi, Gilson
   Antonio/0000-0003-0623-9461
FU PCI-LNCC; FAPESP [2005/02899-4]; CNPq [473219/04-2, 472386/2007-7];
   CAPES [094/2007]; Fundacao de Amparo a Pesquisa do Estado de Sao Paulo
   (FAPESP) [05/02899-4] Funding Source: FAPESP
FX We thank all the reviewers for the very constructive comments, which
   helped us a lot to improve this work. Particularly, we are very grateful
   to the careful and insightful changes suggested by one of the reviewers,
   who contributed important mathematical equations to clarify this paper.
   Also, we thank Dr. Paulo Sergio Silva Rodrigues for providing the first
   version of the SVM code used in this work, which is based on the
   quadratic programming solution created by Alex J. Smola. In addition,
   the authors thank the support provided by PCI-LNCC, FAPESP (grant
   2005/02899-4), CNPq (grants 473219/04-2 and 472386/2007-7) and CAPES
   (grant 094/2007).
CR Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cook RD, 2001, AUST NZ J STAT, V43, P147, DOI 10.1111/1467-842X.00164
   Davatzikos C, 2004, NEUROIMAGE, V23, P17, DOI 10.1016/j.neuroimage.2004.05.010
   DEVIJVER P, 1982, PATTERN CLASSIFICATI
   Friedman J., 2001, ELEMENTS STAT LEARNI, V1, DOI DOI 10.1007/978-0-387-84858-7
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Johnson A.R., 1998, Applied multivariate statistical analysis
   Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Martínez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Thomaz C.E., 2006, Journal of the Brazilian Computer Society, V12, P7
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vladimir N. V., 1998, Statistical Learning Theory
   Zhu M, 2003, J COMPUT GRAPH STAT, V12, P101, DOI 10.1198/1061860031220
   Zhu M., 2006, IEEE C COMPUTER VISI, V1, P132, DOI DOI 10.1109/CVPR.2006.271
   Zhu ML, 2008, IEEE T NEURAL NETWOR, V19, P148, DOI 10.1109/TNN.2007.904040
   Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172
   Zhu M, 2006, BIOMETRIKA, V93, P1018, DOI 10.1093/biomet/93.4.1018
NR 21
TC 384
Z9 411
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 902
EP 913
DI 10.1016/j.imavis.2009.11.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200006
DA 2024-07-18
ER

PT J
AU Lázaro, J
   Martín, JL
   Arias, J
   Astarloa, A
   Cuadrado, C
AF Lazaro, Jesus
   Luis Martin, Jose
   Arias, Jagoba
   Astarloa, Armando
   Cuadrado, Carlos
TI Neuro semantic thresholding using OCR software for high precision OCR
   applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Thresholding; Binarization; GRNN; Semantic description; OCR
ID SEGMENTATION; PERFORMANCE; HISTOGRAM; NETWORKS; ENTROPY; BINARIZATION;
   EXTRACTION; PREDICTION; IMAGES
AB This paper describes a novel approach to binarization techniques. It presents a way of obtaining a threshold that depends both on the image and the final application using a semantic description of the histogram and a neural network. The intended applications of this technique are high precision OCR algorithms over a limited number of document types.
   The input image histogram is smoothed and its derivative is found. Using a polygonal Version of the derivative and the smoothed histogram, a new description of the histogram is calculated. Using this description and a training set, a general neural network is capable of obtaining an Optimum threshold for our application. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Lazaro, Jesus; Luis Martin, Jose; Arias, Jagoba; Astarloa, Armando; Cuadrado, Carlos] Univ Basque Country, Dept Elect & Telecommun, Bilbao 48013, Spain.
C3 University of Basque Country
RP Lázaro, J (corresponding author), Univ Basque Country, Dept Elect & Telecommun, Alameda Urquijo S-N, Bilbao 48013, Spain.
EM jesus.lazaro@ehu.es
RI Martin, Jose Luis/AFY-8101-2022; Lázaro, Jesús/K-2666-2017; Martin, Jose
   Luis/K-7385-2014; Cuadrado, Carlos/L-7280-2014; Astarloa,
   Armando/K-9164-2014
OI Martin, Jose Luis/0000-0002-5738-6376; Lázaro,
   Jesús/0000-0002-7483-3609; Martin, Jose Luis/0000-0002-5738-6376;
   Astarloa, Armando/0000-0002-6330-1922; CUADRADO VIANA,
   CARLOS/0000-0002-4990-5842
FU Basque Government [IE08-221]
FX This research is supported by the Basque Government under the Etortek
   program through TEReTRANS IE08-221 Grant.
CR ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0
   Astarloa A, 2008, LECT NOTES COMPUT SC, V5060, P603
   AVIAD Z, 1987, PATTERN RECOGN LETT, V5, P321, DOI 10.1016/0167-8655(87)90073-0
   BASU S, 1987, PATTERN RECOGN, V20, P497, DOI 10.1016/0031-3203(87)90077-X
   Bowden GJ, 2006, MATH COMPUT MODEL, V44, P469, DOI 10.1016/j.mcm.2006.01.006
   Celikoglu HB, 2006, MATH COMPUT MODEL, V44, P640, DOI 10.1016/j.mcm.2006.02.002
   Chang CY, 2001, IMAGE VISION COMPUT, V19, P669, DOI 10.1016/S0262-8856(01)00039-7
   Cheng HD, 1999, PATTERN RECOGN, V32, P825, DOI 10.1016/S0031-3203(98)00080-6
   Chung KL, 2003, PATTERN RECOGN, V36, P2793, DOI 10.1016/S0031-3203(03)00138-9
   Erkmen B, 2008, EXPERT SYST APPL, V35, P472, DOI 10.1016/j.eswa.2007.07.021
   GLASBEY CA, 1993, CVGIP-GRAPH MODEL IM, V55, P532, DOI 10.1006/cgip.1993.1040
   Goirizelaia H, 2004, LECT NOTES COMPUT SC, V3287, P470
   Gupta MR, 2007, PATTERN RECOGN, V40, P389, DOI 10.1016/j.patcog.2006.04.043
   HUANG LK, 1995, PATTERN RECOGN, V28, P41, DOI 10.1016/0031-3203(94)E0043-K
   Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kim B, 2003, VACUUM, V71, P497, DOI 10.1016/S0042-207X(03)00075-7
   Kim BW, 2004, APPL SURF SCI, V222, P17, DOI 10.1016/S0169-4332(03)00963-2
   KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443
   LAZARO J, 2004, ICIT
   Lázaro J, 2006, PATTERN RECOGN LETT, V27, P1991, DOI 10.1016/j.patrec.2006.06.011
   LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X
   Lee WY, 2004, APPL ENERG, V77, P153, DOI 10.1016/S0306-2619(03)00107-7
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Mahmoud MA, 2003, ENERG CONVERS MANAGE, V44, P3207, DOI 10.1016/S0196-8904(03)00105-5
   Medina-Carnicer R, 2008, PATTERN RECOGN, V41, P2337, DOI 10.1016/j.patcog.2007.12.007
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Palumbo P. W., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V697, P278, DOI 10.1117/12.976229
   Papamarkos N, 2000, IMAGE VISION COMPUT, V18, P213, DOI 10.1016/S0262-8856(99)00015-3
   Pikaz A, 1996, PATTERN RECOGN, V29, P829, DOI 10.1016/0031-3203(95)00126-3
   Polat Ö, 2008, EXPERT SYST APPL, V34, P845, DOI 10.1016/j.eswa.2006.10.032
   Polat Ö, 2008, EXPERT SYST APPL, V34, P2444, DOI 10.1016/j.eswa.2007.04.006
   ROSENFELD A, 1983, IEEE T SYST MAN CYB, V13, P231, DOI 10.1109/TSMC.1983.6313118
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sang N, 2007, IMAGE VISION COMPUT, V25, P1263, DOI 10.1016/j.imavis.2006.07.026
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   SHANBHAG AG, 1994, CVGIP-GRAPH MODEL IM, V56, P414, DOI 10.1006/cgip.1994.1037
   Shayler PJ, 2000, ENG APPL ARTIF INTEL, V13, P147, DOI 10.1016/S0952-1976(99)00048-2
   Sifre-Maunier L, 2006, IMAGE VISION COMPUT, V24, P1080, DOI 10.1016/j.imavis.2006.03.004
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511
   Yan CX, 2003, PATTERN RECOGN LETT, V24, P2935, DOI 10.1016/S0167-8655(03)00154-5
   Zhang LX, 2003, POLYMER, V44, P1751, DOI 10.1016/S0032-3861(03)00021-1
   Zheng H, 2006, SENSOR ACTUAT B-CHEM, V119, P449, DOI 10.1016/j.snb.2006.01.001
NR 45
TC 13
Z9 14
U1 3
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 571
EP 578
DI 10.1016/j.imavis.2009.09.011
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600003
DA 2024-07-18
ER

PT J
AU Levi, D
   Ullman, S
AF Levi, Dan
   Ullman, Shimon
TI Learning to classify by ongoing feature selection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Online learning; Object recognition
AB Existing classification algorithms use a set of training examples to select classification features, which are then used for all future applications of the classifier. A major problem with this approach is the selection of a training set: a small set will result in reduced performance, and a large set will require extensive training. In addition, class appearance may change over time requiring an adaptive classification system. In this paper, we propose a solution to these basic problems by developing an on-line feature selection method, which continuously modifies and improves the features used for classification based on the examples provided so far. The method is used for learning a new class, and to continuously improve classification performance as new data becomes available. In ongoing learning, examples are continuously presented to the system, and new features arise from these examples. The method continuously measures the value of the selected features using mutual information, and uses these values to efficiently update the set of selected features when new training information becomes available. The problem is challenging because at each stage the training process uses a small subset of the training data. Surprisingly, with sufficient training data the on-line process reaches the same performance as a scheme that has a complete access to the entire training data. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Levi, Dan; Ullman, Shimon] Weizmann Inst Sci, Dept Math & Comp Sci, IL-76100 Rehovot, Israel.
C3 Weizmann Institute of Science
RP Levi, D (corresponding author), Weizmann Inst Sci, Dept Math & Comp Sci, IL-76100 Rehovot, Israel.
EM danml@weizmann.ac.il; shimon.ullman@weizmann.ac.il
FU IMOS [3-992]; EU IST [FP6-2005-015803]
FX This work was supported by IMOS Grant 3-992 and EU IST Grant
   FP6-2005-015803, and conducted at the Moross Laboratory for Vision and
   Motor Control.
CR Battiti Roberto., 1994, IEEE Transactions on Neural Networks 1994, V5
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Fano R.M., 1961, Transmission of information, P793
   Fergus R, 2003, PROC CVPR IEEE, P264
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pearl J., 1988, PROBABILISTIC REASON
   Perkins S., 2003, PROC 20 INT C MACHIN, P21
   Principe J., 1999, UNSUPERVISED ADAPTIV
   Thuleen N., 1999, NTHULEENCOM
   Vasconcelos N, 2004, PROC CVPR IEEE, P770
   Vidal-Naquet M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P281
NR 15
TC 14
Z9 14
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 715
EP 723
DI 10.1016/j.imavis.2008.10.010
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600016
DA 2024-07-18
ER

PT J
AU Labati, RD
   Scotti, F
AF Labati, Ruggero Donida
   Scotti, Fabio
TI Noisy iris segmentation with boundary regularization and reflections
   removal
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris segmentation; Boundary Regularization; Outliers removal;
   Reflections identification
ID RECOGNITION
AB The paper presents an innovative algorithm for the segmentation of the iris in noisy images, with boundaries regularization and the removal of the possible existing reflections. In particular, the method aims to extract the iris pattern from the eye image acquired at the visible wavelength, in an uncontrolled environment where reflections and occlusions can also be present, on-the-move and at variable distance. The method achieves the iris segmentation by the following three main steps. The first step locates the centers of the pupil and the iris in the input image. Then two image strips containing the iris boundaries are extracted and linearizated. The last step locates the iris boundary points in the strips and it performs a regularization operation by achieving the exclusion of the outliers and the interpolation of missing points. The obtained curves are then converted into the original image space in order to produce a first segmentation output. Occlusions such as reflections and eyelashes are then identified and removed from the final area of the segmentation. Results indicate that the presented approach is effective and suitable to deal with the iris acquisition in noisy environments. The proposed algorithm ranked seventh in the international Noisy Iris Challenge Evaluation (NICE.I). (C) 2009 Elsevier B.V. All rights reserved.
C1 [Labati, Ruggero Donida; Scotti, Fabio] Univ Milan, Dept Informat Technol, I-26013 Crema, CR, Italy.
C3 University of Milan
RP Scotti, F (corresponding author), Univ Milan, Dept Informat Technol, Via Bramante 65, I-26013 Crema, CR, Italy.
EM fabio.scotti@unimi.it
RI Labati, Ruggero Donida/L-4524-2013; Scotti, Fabio/C-7405-2009
OI Labati, Ruggero Donida/0000-0002-2636-086X; Scotti,
   Fabio/0000-0002-4277-3701
CR [Anonymous], 2003, Recognition of Human Iris Patterns for Biometric Identification
   [Anonymous], P IEEE 1 INT C BIOM
   Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573
   Broussard RP, 2007, IEEE IJCNN, P1283, DOI 10.1109/IJCNN.2007.4371143
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Gonzales R., 2007, DIGITAL IMAGE PROCES, V3rd
   He X, 2007, PATTERN RECOGN, V40, P1326, DOI 10.1016/j.patcog.2006.08.009
   Heijmans HJAM, 1997, IEEE T IMAGE PROCESS, V6, P713, DOI 10.1109/83.568928
   Huang JZ, 2004, IEEE IMAGE PROC, P869
   Ives RW, 2005, 2005 39TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, VOLS 1 AND 2, P859
   JAIN AK, 2007, BIOMETRICS PERSONAL
   Jang J, 2003, LECT NOTES COMPUT SC, V2756, P301
   Kong WK, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P263, DOI 10.1109/ISIMP.2001.925384
   Park W, 2007, IEEE T IMAGE PROCESS, V16, P1946, DOI 10.1109/TIP.2007.899190
   Phillips PJ, 2007, IEEE T PATTERN ANAL, V29, P1869, DOI [10.1109/TPAMI.2007.1137, 10.1109/TPAMI.2007.1137.]
   Ross AA., 2006, International series on biometrics, P1, DOI DOI 10.1109/BCC.2006.4341625
   Scott F, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P84, DOI 10.1109/CIMSA.2007.4362544
   Wei Z., 2005, LNCS, V3832, P464
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Xu GZ, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P871
NR 21
TC 55
Z9 60
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2010
VL 28
IS 2
SI SI
BP 270
EP 277
DI 10.1016/j.imavis.2009.05.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 538GR
UT WOS:000273173100009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Grailu, H
   Lotfizad, M
   Sadoghi-Yazdi, H
AF Grailu, Hadi
   Lotfizad, Mojtaba
   Sadoghi-Yazdi, Hadi
TI 1-D chaincode pattern matching for compression of Bi-level printed farsi
   and arabic textual images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pattern matching; Bi-level text image; Image compression; Chain code;
   Farsi and Arabic text images
ID JBIG2
AB In some scripts, especially the Farsi/Arabic script, letters normally attach together and produce many different patterns, some of which are fully or partially similar. Detecting such patterns and exploiting them to reduce the library size, has a rather great effect on the compression ratio.
   In this paper, a lossy/lossless compression method is proposed for bi-level printed text images in archiving applications. For this, we propose a new 1-D pattern matching technique in the chain coding domain that uses the proposed technique of detecting the repetitive sub-signals in order to detect the fully or partially similar patterns.
   Experimental results show that the compression performance of the proposed method is considerably better than those of the existing bi-level printed text image compression methods as high as 1.8-4.2 times in the lossy case and 1.6-3.8 times in the lossless case at 300 dpi. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Grailu, Hadi; Lotfizad, Mojtaba] Tarbiat Modares Univ, Dept Elect Engn, Tehran, Iran.
   [Sadoghi-Yazdi, Hadi] Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Iran.
C3 Tarbiat Modares University; Ferdowsi University Mashhad
RP Lotfizad, M (corresponding author), Tarbiat Modares Univ, Dept Elect Engn, Tehran, Iran.
EM grailu@modares.ac.ir; lotfizad@modares.ac.ir; sadoghi@sttu.ac.ir
RI yazdi, hadi sadoghi/R-5887-2019; sadoghiyazdi, hadi/T-9515-2019
FU Iranian Telecommunication Research Center (ITRC)
FX This work was supported by the Iranian Telecommunication Research Center
   (ITRC).
CR [Anonymous], 1993, 11544 ISOIEC
   [Anonymous], 2007, J CHEM INF MODEL, DOI DOI 10.1017/CBO9781107415324.004
   ASCHER RN, 1974, IEEE T COMPUT, VC 23, P1174, DOI 10.1109/T-C.1974.223826
   Bell T. C., 1990, TEXT COMPRESSION
   Bottou L, 1998, J ELECTRON IMAGING, V7, P410, DOI 10.1117/1.482609
   BRICKMAN NF, 1982, IBM J RES DEV, V26, P681, DOI 10.1147/rd.266.0681
   Fisher Y., 1995, Fractal Image Compression: Theory and Application
   Freeman H., 1961, PROC NATL ELECT C, V17, P421
   Gersho A., 2003, Vector Quantization and Signal Compression
   Holt M.J., 1986, ICL TECHNICAL J, P123
   HOLT MJJ, 1988, LECT NOTES COMPUT SC, V301, P230
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   Howard PG, 1997, COMPUT J, V40, P146, DOI 10.1093/comjnl/40.2_and_3.146
   Jahne B., 2005, Digital Image Processing: Concepts, Algorithms, and Scientific Applications, Vsixth
   JOHNSEN O, 1983, AT&T TECH J, V62, P2513, DOI 10.1002/j.1538-7305.1983.tb03192.x
   Kanungo T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P730, DOI 10.1109/ICDAR.1993.395633
   Keller P.E., 1982, Algorithms for Graphics and Image Processing, V42, P709, DOI 10.1109/23.467888
   Kia OE, 1998, COMPUT VIS IMAGE UND, V70, P335, DOI 10.1006/cviu.1998.0682
   Kia OE, 2000, IEEE T IMAGE PROCESS, V9, P961, DOI 10.1109/83.846239
   MOFFAT A, 1991, P IEEE DATA COMPRESS, P382
   PRATT WK, 1980, P IEEE, V68, P786, DOI 10.1109/PROC.1980.11744
   Pu IM, 2006, FUNDAMENTAL DATA COMPRESSION, P1
   Salomon D., 2008, A Concise Introduction to Data Compression
   Sayood K., 2003, Lossless Compression Handbook
   Witten I.H., 1999, Managing Gigabytes: Compressing and Indexing Documents and Images
   WITTEN IH, 1994, P IEEE, V82, P878, DOI 10.1109/5.286192
   Yang YB, 2000, PATTERN RECOGN, V33, P1277, DOI 10.1016/S0031-3203(99)00112-0
   Ye Y, 2003, IEEE T IMAGE PROCESS, V12, P944, DOI 10.1109/TIP.2003.815253
   Ye Y, 2001, IEEE T IMAGE PROCESS, V10, P818, DOI 10.1109/83.923278
NR 29
TC 3
Z9 3
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1615
EP 1625
DI 10.1016/j.imavis.2009.04.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800018
DA 2024-07-18
ER

PT J
AU Jung, C
   Liu, Q
   Kim, J
AF Jung, Cheolkon
   Liu, Qifeng
   Kim, Joongkyu
TI Accurate text localization in images based on SVM output scores
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Text localization; SVM output score; Text line refinement; Classifier
   fusion
ID VIDEO; RECOGNITION; EXTRACTION; TRACKING
AB In this paper, we propose a new approach for accurate text localization in images based on SVM (support vector machine) output scores. In general, SVM output scores for the verification of text candidates provide a measure of the closeness to the text. Up to the present, most researchers used the score for verifying the text candidate region whether it is text or not. However, we use the output score for refining the initial localized text lines and selecting the best localization result from the different pyramid levels. By means of the proposed approach, we can obtain more accurate text localization results. Our method has three modules: (1) text candidate detection based on edge-CCA (connected component analysis), (2) text candidate verification based on the classifier fusion of N-gray (normalized gray intensity) and CGV (constant gradient variance), and (3) text line refinement based on the SVM output score, color distribution and prior geometric knowledge. By means of experiments on a large news database, we demonstrate that our method achieves impressive performance with respect to the accuracy, robustness and efficiency. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Jung, Cheolkon; Kim, Joongkyu] Sungkyunkwan Univ, Sch Informat & Commun Engn, Suwon 440746, Kyunggido, South Korea.
   [Liu, Qifeng] Samsung Adv Inst Technol, Yongin 446712, Kyunggido, South Korea.
C3 Sungkyunkwan University (SKKU); Samsung
RP Jung, C (corresponding author), Sungkyunkwan Univ, Sch Informat & Commun Engn, 300 Cheoncheon Dong, Suwon 440746, Kyunggido, South Korea.
EM ckjung@ece.skku.ac.kr; qfliu1976@yahoo.com.cn; jkkim@skku.edu
OI , QIFENG/0000-0001-6191-076X
CR Chang F, 2005, MULTIMEDIA SYST, V10, P344, DOI 10.1007/s00530-004-0159-y
   Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001
   Chen XR, 2004, PROC CVPR IEEE, P366
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Dimitrova N, 2002, IEEE MULTIMEDIA, V9, P42, DOI 10.1109/MMUL.2002.1022858
   HUA X, 2001, ACM MULT WORKSH MULT
   Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3
   Jung C, 2008, INT CONF ACOUST SPEE, P1945, DOI 10.1109/ICASSP.2008.4518017
   Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Kim KI, 2001, PATTERN RECOGN, V34, P527, DOI 10.1016/S0031-3203(00)00095-9
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   LIENHART R, 1998, TR98009 U MANNH
   LIENHART R, 1996, P SPIE IMAGE VIDEO P, V4, P2666
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   SATO T, 1998, ACM MULTIMEDIA SYST, V7, P385
   Vapnik V., 1999, NATURE STAT LEARNING
   WANG HL, 2000, CHIN ANIM QUANRANTIN, V17, P36
   Wang KQ, 2001, PROC INT CONF DOC, P210, DOI 10.1109/ICDAR.2001.953785
   Wolf C, 2003, PATTERN ANAL APPL, V6, P309, DOI 10.1007/s10044-003-0197-7
   Wu V, 1999, IEEE T PATTERN ANAL, V21, P1224, DOI 10.1109/34.809116
   YASSIN M, 2000, IEEE T IMAGE PROCESS, V9, P1978
   Ye QX, 2005, IMAGE VISION COMPUT, V23, P565, DOI 10.1016/j.imavis.2005.01.004
   Zheng YF, 2004, IEEE T PATTERN ANAL, V26, P337, DOI 10.1109/TPAMI.2004.1262324
   ZHU K, 2005, P INT WORKSH CAM BAS, P52
NR 26
TC 24
Z9 29
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1295
EP 1301
DI 10.1016/j.imavis.2008.11.012
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200006
DA 2024-07-18
ER

PT J
AU Zhu, YH
   Liu, J
   Chen, SC
AF Zhu, Yuhan
   Liu, Jun
   Chen, Songcan
TI Semi-random subspace method for face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Random subspace method (RSM); Semi-random subspace method (Semi-RS);
   Recognition robustness; Small sample size (SSS); Sub-image method; Face
   recognition; Kappa-error diagram
ID IMAGE; EIGENFACES; PCA
AB The small sample size (SSS) and the sensitivity to variations such as illumination, expression and occlusion are two challenging problems in face recognition. In this paper, we propose a novel method, called semi-random subspace (Semi-RS), to simultaneously address the two problems. Different from the traditional random subspace method (RSM) which samples features from the whole pattern feature set in a completely random way, the proposed Semi-RS randomly samples features on each local region (or a sub-image) partitioned from the original face image. More specifically, we first divide a face image into several sub-images in a deterministic way, then construct a set of base classifiers on different randomly sampled feature sets from each sub-image set, and finally combine all base classifiers for the final decision. Experimental results on five face databases (AR, Extended YALE, FERET, Yale and ORL) show that the proposed Semi-RS method is effective, relatively robust to illumination and occlusion, etc., and also suitable to slight variations in pose angle and the scenario of one training sample per person. In addition, kappa-error diagram, which is used to analyze the diversity of algorithm, reveals that Semi-RS constructs more diverse base classifiers than other methods, and also explains why Semi-RS can yield better performance than RSM and V-SpPCA. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Zhu, Yuhan; Liu, Jun; Chen, Songcan] Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Jiangsu, Peoples R China.
   [Zhu, Yuhan; Chen, Songcan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University
RP Chen, SC (corresponding author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Jiangsu, Peoples R China.
EM s.chen@nuaa.edu.cn
FU National Natural Science Foundations of China [60773060, 60773061];
   Natural Science Foundations of Jiangsu Province [BK2008381, BK2006187]
FX This work was supported by National Natural Science Foundations of China
   (60773060 and 60773061) and Natural Science Foundations of Jiangsu
   Province (BK2008381 and BK2006187). We also thank Prof. Xiaoyang Tan for
   beneficial discussion.
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Beveridge JR, 2005, MACH VISION APPL, V16, P128, DOI 10.1007/s00138-004-0144-7
   Chawla NV, 2005, PROC CVPR IEEE, P582
   Chen SC, 2004, PATTERN RECOGN, V37, P1081, DOI 10.1016/j.patcog.2003.09.004
   FUKUNAGE K, 1990, INTRO STAT PATTERN R
   Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee RE, 2005, CONTEMP FAM THER, V27, P1, DOI 10.1007/s10591-004-1967-0
   Margineantu D.D., 1997, ICML, V97, P211
   Martinez A., 1998, AR FACE DATABASE
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rodríguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211
   Srivastava A, 2006, IMAGE VISION COMPUT, V24, P291, DOI 10.1016/j.imavis.2005.07.023
   SU GD, 2002, ELECTRON LETT, V38, P1564
   Tan KR, 2005, NEUROCOMPUTING, V64, P505, DOI 10.1016/j.neucom.2004.10.113
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   TUMER K, 1996, CONNECT SCI, V8, P384
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang XG, 2005, PROC CVPR IEEE, P574
   Wang XG, 2004, PROC CVPR IEEE, P259
   Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
   Zhang XX, 2007, PATTERN RECOGN, V40, P2585, DOI 10.1016/j.patcog.2006.12.002
   Zhou ZH, 2005, IEEE T SYST MAN CY B, V35, P725, DOI 10.1109/TSMCB.2005.845396
NR 30
TC 41
Z9 49
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1358
EP 1370
DI 10.1016/j.imavis.2008.12.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200012
DA 2024-07-18
ER

PT J
AU Abolghasemi, V
   Ahmadyfard, A
AF Abolghasemi, Vahid
   Ahmadyfard, Ahreza
TI An edge-based color-aided method for license plate detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE License plate recognition; Edge analysis; Morphological processing;
   Color analysis
ID RECOGNITION; SYSTEM
AB In this paper, the problem of license plate detection is considered. Low quality images due to severe illumination conditions, vehicle motion, viewpoint and distance changes, complex background, etc. are some of popular problems which have to be considered. In order to alleviate these problems, two different image enhancement methods (using intensity variance and edge density) are proposed. The aim is to increase contrast of plate-like regions to avoid missing plate location especially in poor quality images. Furthermore, a novel match filter is designed to detect candidate regions as plate. This filter models the vertical edge density of plate region regarding its neighborhood. As the filtering procedure is simple, this approach can be used for real-time applications. In the proposed method, we also use colored texture in the plate as a cue for plate detection. This feature is preserved under viewpoint change. In order to characterize the color information in plate, the MNS (multimodal neighborhood signature) method is used. A well-organized database, consisting of car images with different known distances and viewing angels have been prepared to verify the performance of plate detection algorithm. This database can be used to establish a precise evaluation of the proposed method and any other related work. The results of experiments on different type of car images in complex scenes confirm the robustness of proposed method against severe imaging conditions. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Abolghasemi, Vahid; Ahmadyfard, Ahreza] Shahrood Univ Technol, Fac Elect Engn & Robot, Shahrood, Iran.
C3 Shahrood University of Technology
RP Abolghasemi, V (corresponding author), Shahrood Univ Technol, Fac Elect Engn & Robot, Shahrood, Iran.
EM abolghasemiv@cardiff.ac.uk
RI Abolghasemi, Vahid/AAC-8242-2020
OI Abolghasemi, Vahid/0000-0002-2151-5180
CR [Anonymous], P INT C RES INN VIS
   Chang S.L., 2004, IEEE T INTELLIGENT T, V5
   DLAGNEKOVIN L, 2004, THESIS U CALIFORNIA
   Draghici S, 1997, INT J NEURAL SYST, V8, P113, DOI 10.1142/S0129065797000148
   Hsieh CT, 2005, AINA 2005: 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 2, P389
   Kahraman F, 2003, LECT NOTES COMPUT SC, V2869, P381
   Kim KI, 2002, LECT NOTES COMPUT SC, V2388, P293
   KOUBAROULIS D, 1999, VSSPTR699 U SURR
   KUMAR S, 2005, P 8 INT C DOC AN REC
   LEE ER, 1994, IEEE IMAGE PROC, P301, DOI 10.1109/ICIP.1994.413580
   LI G, 2006, 1 INT C INN COMP INF
   Mahini H, 2006, INT C PATT RECOG, P841
   NIKOLAOS EC, 2006, IEEE T INTELLIGENT T, V7
   PARISI R, 1998, IEEE INT S CIRC SYST, V3, P195
   Shi XF, 2005, LECT NOTES COMPUT SC, V3483, P1159
   Wang SZ, 2003, 2003 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, VOLS. 1 & 2, P979
   Zheng D, 2005, PATTERN RECOGN LETT, V26, P2431, DOI 10.1016/j.patrec.2005.04.014
NR 17
TC 86
Z9 99
U1 1
U2 47
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1134
EP 1142
DI 10.1016/j.imavis.2008.10.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000014
DA 2024-07-18
ER

PT J
AU Metzen, JH
   Kröger, T
   Schenk, A
   Zidowitz, S
   Peitgen, HO
   Jiang, XY
AF Metzen, Jan Hendrik
   Kroeger, Tim
   Schenk, Andrea
   Zidowitz, Stephan
   Peitgen, Heinz-Otto
   Jiang, Xiaoyi
TI Matching of anatomical tree structures for registration of medical
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Tree matching; Image registration; Maximum clique
ID MAXIMAL CLIQUES; LOCAL SEARCH
AB Many medical applications require a registration of different images of the same organ. In many cases, such a registration is accomplished by manual placement of landmarks in the images. In this paper, we propose a method which is able to find reasonable landmarks automatically. To achieve this, bifurcations of the vessel systems, which have been extracted from the images by a segmentation algorithm, are assigned by the so-called association graph method and the coordinates of these matched bifurcations can be used as landmarks for a non-rigid registration algorithm. Several constraints to be used in combination with the association graph method are proposed and evaluated on a ground truth consisting of anatomical trees from liver and lung. Furthermore, a method for preprocessing (tree pruning) as well as for postprocessing (clique augmentation) are proposed and evaluated on this ground truth. The proposed method achieves promising results for anatomical trees of liver and lung and for medical images obtained with different modalities and at different points in time. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Metzen, Jan Hendrik] German Res Ctr Artificial Intelligence DFKI, Robot Lab, D-28359 Bremen, Germany.
   [Kroeger, Tim; Schenk, Andrea; Zidowitz, Stephan; Peitgen, Heinz-Otto] MeVis Res GmbH, D-28359 Bremen, Germany.
   [Jiang, Xiaoyi] Univ Munster, Fac Math & Comp Sci, D-48149 Munster, Germany.
C3 German Research Center for Artificial Intelligence (DFKI); University of
   Munster
RP Metzen, JH (corresponding author), German Res Ctr Artificial Intelligence DFKI, Robot Lab, Hooke Str 5, D-28359 Bremen, Germany.
EM jhm@informatik.uni-bremen.de; tim.kroeger@mevis.de;
   andrea.schenk@mevis.de; stephan.zidowitz@mevis.de; peitgen@mevis.de;
   xjiang@math.uni-muenster.de
RI Jiang, Xiaoyi/AAA-3532-2022; Schenk, Andrea/AAF-1323-2021; Peitgen,
   Heinz-Otto/ABG-2100-2021
OI Jiang, Xiaoyi/0000-0001-7678-9528; Schenk, Andrea/0000-0003-1806-8380; 
CR Abu-Khzam FN, 2006, ALGORITHMICA, V45, P269, DOI 10.1007/s00453-006-1214-1
   BARTOLI M, 2000, ICPR, V2, P2133
   Battiti R, 2001, ALGORITHMICA, V29, P610, DOI 10.1007/s004530010074
   Bulò SR, 2007, LECT NOTES COMPUT SC, V4538, P61
   Bulow T., 2006, P SOC PHOTO-OPT INS, V6143, P225
   Charnoz A, 2005, LECT NOTES COMPUT SC, V3434, P183
   CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156
   Couinaud L., 1957, FOIE ETUDES ANATOMIQ, P71
   Fischer B, 2003, PROC SPIE, V5032, P1037, DOI 10.1117/12.480118
   GRAHAM MW, 2006, P SOC PHOTO-OPT INS, V6144, P373
   Graham RT, 2006, J ROY SOC INTERFACE, V3, P109, DOI 10.1098/rsif.2005.0082
   Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201
   Kaftan JensN., 2006, SPIE Med. Im, V6143, P215
   Karp R, 1972, COMPLEXITY COMPUTER, V40, P85, DOI 10.1007/978-3-540-68279-08
   LOHE T, 2007, THESIS MUNSTER
   Lohe T, 2007, LECT NOTES COMPUT SC, V4901, P224
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   METZEN JH, 2006, THESIS U MUNSTER
   Modersitzki J., 2004, NUMER MATH SCI COMP
   MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6
   Pan Y, 2005, P SOC PHOTO-OPT INS, V5746, P453, DOI 10.1117/12.596617
   Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034
   Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105
   Pelillo M, 2002, IEEE T PATTERN ANAL, V24, P1535, DOI 10.1109/TPAMI.2002.1046176
   PELILLO M, 2001, IWVF, V4, P583
   Pullan W, 2006, J ARTIF INTELL RES, V25, P159, DOI 10.1613/jair.1815
   Richter S, 2007, LECT NOTES ARTIF INT, V4667, P412
   SELLE D, IEEE T MED IMAGING, V21
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Tschirren J, 2005, IEEE T MED IMAGING, V24, P1540, DOI 10.1109/TMI.2005.857653
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 31
TC 28
Z9 30
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 923
EP 933
DI 10.1016/j.imavis.2008.04.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300010
DA 2024-07-18
ER

PT J
AU Marinakis, D
   Dudek, G
AF Marinakis, Dimitri
   Dudek, Gregory
TI Self-calibration of a vision-based sensor network
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Sensor networks; Perception; Self-calibration; Topology; Learning;
   Markov chain monte carlo; Expectation maximization
ID OBJECT IDENTIFICATION
AB When a network of vision-based sensors is emplaced in an environment for applications such as surveillance or monitoring the spatial relationships between the sensing units must be inferred or computed for self-calibration purposes. In this paper we describe a technique to solve one aspect of this self-calibration problem: automatically determining the topology and connectivity information of a network of cameras based on a statistical analysis of observed motion in the environment. While the technique can use labels from reliable cameras systems, the algorithm is powerful enough to function using ambiguous tracking data. The method requires no prior knowledge of the relative locations of the cameras and operates under very weak environmental assumptions. Our approach stochastically samples plausible agent trajectories based on a delay model that allows for transitions to and from sources and sinks in the environment. The technique demonstrates considerable robustness both to sensor error and non-trivial patterns of agent motion. The output of the method is a Markov model describing the behavior of agents in the system and the underlying traffic patterns. The concept is demonstrated with simulation data for systems containing up to 10 agents and verified with experiments conducted on a six camera sensor network. (C) 2006 Elsevier B.V. All rights reserved.
C1 [Marinakis, Dimitri; Dudek, Gregory] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.
C3 McGill University
RP Marinakis, D (corresponding author), McGill Univ, Ctr Intelligent Machines, 3480 Univ St, Montreal, PQ H3A 2A7, Canada.
EM dmarinak@cim.mcgill.ca; dudek@cim.mcgill.ca
RI Dudek, Gregory L/H-3567-2012
CR Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116
   [Anonymous], P 2 INT WORKSH INF P
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   [Anonymous], 7 ACM ANN INT C MOB
   [Anonymous], 1996, Springer Series in Operations Research
   Bar-Shalom Y., 1992, MULTITARGET MULTISEN, VII
   Burgard W, 1999, MACHINE LEARNING, PROCEEDINGS, P67
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   ELLIS TJ, 2003, JOINT IEEE WORKSH VI, P165
   Fisher RB, 2002, LECT NOTES COMPUT SC, V2353, P146
   Huang T, 1997, INT JOINT CONF ARTIF, P1276
   Huang T, 1998, ARTIF INTELL, V103, P77, DOI 10.1016/S0004-3702(98)00067-8
   JAVED O, 2003, 9 IEEE INT C COMP VI
   Makris Dimitrios, 2004, IEEE C COMP VIS PATT
   MOORE D, 2004, P 2 ACM C EMB NETW S
   PASULA H, 1999, IJCAI 99
   RAHIMI A, 2004, CVPR 2004 JUN, V1, P187
   RASMUSSEN C, 2001, IEEE T PATT AN MACH
   Rekleitis IM, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P676, DOI 10.1109/ROBOT.1999.770053
   ROSENCRANTZ M, 2003, 2 INT JOINT C AUT AG, P233
   Shatkay H, 1997, INT JOINT CONF ARTIF, P920
   Shin J, 2003, LECT NOTES COMPUT SC, V2634, P223
   Stauffer C, 2003, PROC CVPR IEEE, P259
   Stein G. P., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P521, DOI 10.1109/CVPR.1999.786987
   Tanner MA, 1996, Tools for Statistical Inference: Methods for the Exploration of Posterior Distributions and Likelihood Functions, V3rd
   WEI GCG, 1990, J AM STAT ASSOC, V85, P699, DOI 10.2307/2290005
NR 26
TC 8
Z9 8
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 116
EP 130
DI 10.1016/j.imavis.2006.06.009
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lin, L
   Zhu, LT
   Yang, FG
   Jiang, TZ
AF Lin, Lei
   Zhu, Litao
   Yang, Faguo
   Jiang, Tianzi
TI A novel pixon-representation for image segmentation based on Markov
   random field
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image segmentation; pixon-representation; Markov random field; region
   labeling
ID GIBBS RANDOM-FIELDS; RECONSTRUCTION; INFORMATION
AB In this paper, a pixon-based image representation is proposed, which is a set of disjoint regions with variable shape and size, named pixon. These pixons combined with their attributes and adjacencies construct a graph, which represents the observed image. A Markov random field (MRF) model-based image segmentation approach using pixon-representation is then proposed, Compared with previous work on region-based and pixon-based segmentation methods, the present method has some remarkable improvements over them. Firstly, a set of significant attributes of pixons and edges are introduced into the pixon-representation. These attributes are integrated into the MRF model and the Bayesian framework to obtain a weighted pixon-based algorithm. Secondly, a criterion of GOOD pixon-representation is presented and a fast QuadTree combination (FQTC) algorithm is proposed to extract the good pixon-representation. The experimental results demonstrate that our pixon-based algorithm performs fairly well while reduces the computational cost sharply compared with the pixel-based method. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Lin, Lei] Zhejiang Univ, Dept Math, Hangzhou 310027, Zhejiang, Peoples R China.
   [Lin, Lei; Zhu, Litao; Yang, Faguo; Jiang, Tianzi] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
C3 Zhejiang University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Jiang, TZ (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM jiangtz@nlpr.ia.ac.cn
RI Jiang, Tianzi/I-4256-2012; cai, bo/G-1491-2010
FU Natural Science Foundation of China [30425004, 30730035]; National Key
   Basic Research and Development Program (973) [2003CB716100]
FX This work was partially supported by the Natural Science Foundation of
   China, Grant Nos. 30425004, 30730035, and the National Key Basic
   Research and Development Program (973) Grant No. 2003CB716100.
CR Andrey P, 1998, IEEE T PATTERN ANAL, V20, P252, DOI 10.1109/34.667883
   Berthod M, 1996, IMAGE VISION COMPUT, V14, P285, DOI 10.1016/0262-8856(95)01072-6
   BESAG J, 1974, ACAD ROYAL STAT SOC, V36, P721
   Borsotti M, 1998, PATTERN RECOGN LETT, V19, P741, DOI 10.1016/S0167-8655(98)00052-X
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871
   Descombes X, 1999, IEEE T PATTERN ANAL, V21, P482, DOI 10.1109/34.771311
   ELFADEL IM, 1994, IEEE T PATTERN ANAL, V16, P24, DOI 10.1109/34.273719
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Hammersley J., 1971, Markov fields on finite graphs and lattices
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kato Z, 1999, PATTERN RECOGN, V32, P591, DOI 10.1016/S0031-3203(98)00104-6
   Kim IY, 1996, IEEE T PATTERN ANAL, V18, P69, DOI 10.1109/34.476014
   KIM IY, 1994, PATTERN RECOGN LETT, V15, P969, DOI 10.1016/0167-8655(94)90028-0
   LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443
   LIU JQ, 1994, IEEE T PATTERN ANAL, V16, P689, DOI 10.1109/34.297949
   Metcalf TR, 1996, ASTROPHYS J, V466, P585, DOI 10.1086/177533
   MODESTINO JW, 1992, IEEE T PATTERN ANAL, V14, P606, DOI 10.1109/34.141552
   PAPPAS TN, 1992, IEEE T SIGNAL PROCES, V40, P901, DOI 10.1109/78.127962
   PINA RK, 1993, PUBL ASTRON SOC PAC, V105, P630, DOI 10.1086/133207
   Puetter RC, 1996, P SOC PHOTO-OPT INS, V2827, P12, DOI 10.1117/12.255082
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   WON CS, 1992, COMPUT VIS GRAPH IMA, V4, P308
   Xu C., 2000, HDB MEDICAL IMAGING, P129
   Yang FG, 2003, IEEE T IMAGE PROCESS, V12, P1552, DOI 10.1109/TIP.2003.817242
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 27
TC 14
Z9 17
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1507
EP 1514
DI 10.1016/j.imavis.2008.04.013
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000006
DA 2024-07-18
ER

PT J
AU Lin, HY
   Li, KJ
   Chang, CH
AF Lin, Huei-Yung
   Li, Kun-Jhih
   Chang, Chia-Hong
TI Vehicle speed detection from a single motion blurred image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE speed measurement; motion blur; motion analysis
ID RESTORATION; IDENTIFICATION; PARAMETERS
AB An image-based method for vehicle speed detection is presented. Conventional speed measurement techniques use radar- or laser-based devices, which are usually more expensive compared to a passive camera system. In this work, a single image captured with vehicle motion is used for speed measurement. Due to the relative motion between the camera and a moving object during the camera exposure time, motion blur occurs in the dynamic region of the image. It provides a visual cue for the speed measurement of a moving object. An approximate target region is first segmented and blur parameters are estimated from the motion blurred subimage. The image is then deblurred and used to derive other parameters. Finally, the vehicle speed is calculated according to the imaging geometry, camera pose, and blur extent in the image. Experiments have shown the estimated speeds within 5% of actual speeds for both local and highway traffic. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Lin, Huei-Yung; Li, Kun-Jhih; Chang, Chia-Hong] Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 62107, Taiwan.
C3 National Chung Cheng University
RP Lin, HY (corresponding author), Natl Chung Cheng Univ, Dept Elect Engn, 168 Univ Rd, Chiayi 62107, Taiwan.
EM lin@ee.ccu.edu.tw
RI Lin, Huei-Yung/H-2949-2012
FU National Science Council of Taiwan [NSC94-2213-E-194-041]
FX The support of this work in part by the National Science Council of
   Taiwan, R.O.C. under Grant NSC94-2213-E-194-041 is gratefully
   acknowledged.
CR Andrews H.C., 1977, DIGITAL IMAGE RESTOR
   Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   BASCLE B, 1996, EUR C COMP VIS, V2, P573
   Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1
   Brostow GJ, 2001, COMP GRAPH, P561, DOI 10.1145/383259.383325
   CANNON M, 1976, IEEE T ACOUST SPEECH, V24, P58, DOI 10.1109/TASSP.1976.1162770
   CHANG MM, 1991, IEEE T SIGNAL PROCES, V39, P2323, DOI 10.1109/78.91207
   CHEN C, 1999, INT C COMP VIS, P30
   Chen WG, 1996, IEEE T PATTERN ANAL, V18, P412, DOI 10.1109/34.491622
   Dailey D. J., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P98, DOI 10.1109/6979.880967
   FABIAN R, 1991, CVGIP-GRAPH MODEL IM, V53, P403, DOI 10.1016/1049-9652(91)90025-F
   FAVARO P, 2004, IEEE COMPUTER VISION, V1, P631
   FOX J, 1988, IEEE COMPUTER VISION, P360
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   MAYNTZ C, 1999, INT C IM PROC, p26PP5
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   OZKAN MK, 1994, IEEE T IMAGE PROCESS, V3, P450, DOI 10.1109/83.298398
   Potmesil M., 1983, Computer Graphics, V17, P389, DOI 10.1145/964967.801169
   Rav-Acha A, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P22, DOI 10.1109/WACV.2000.895398
   REKLEITIS IM, 1996, INT C IM PROC
   Sang Kyu Kang, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P376, DOI 10.1109/ICIP.1999.821634
   Sawicki D., 2002, TRAFFIC RADAR HDB CO
   Schoepflin TN, 2003, IEEE T INTELL TRANSP, V4, P90, DOI 10.1109/TITS.2003.821213
   SLEPIAN D, 1967, AT&T TECH J, V46, P2353, DOI 10.1002/j.1538-7305.1967.tb02461.x
   SONDHI MM, 1972, PR INST ELECTR ELECT, V60, P842, DOI 10.1109/PROC.1972.8783
   Trussell HJ, 1992, IEEE T IMAGE PROCESS, V1, P123, DOI 10.1109/83.128039
   Tull DL, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P85, DOI 10.1109/ICIP.1996.560375
   Tull DL, 1996, OPT ENG, V35, P3460, DOI 10.1117/1.601108
   Wang YP, 1998, IEEE VTC P, P1029, DOI 10.1109/VETEC.1998.686396
   Yitzhaky Y, 1997, GRAPH MODEL IM PROC, V59, P310, DOI 10.1006/gmip.1997.0435
   Yitzhaky Y, 1998, J OPT SOC AM A, V15, P1512, DOI 10.1364/JOSAA.15.001512
   Yitzhaky Y, 2000, OPT ENG, V39, P2083, DOI 10.1117/1.1305319
   ZHU Z, 1996, WACV96, P162
NR 33
TC 57
Z9 62
U1 2
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1327
EP 1337
DI 10.1016/j.imavis.2007.04.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700003
DA 2024-07-18
ER

PT J
AU Dagher, I
   El Tom, K
AF Dagher, Issam
   El Tom, Kamal
TI WaterBalloons: A hybrid watershed Balloon Snake segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE watershed; active contour model; snake balloon; segmentation;
   WaterBalloons
ID ACTIVE CONTOUR MODELS; IMAGE SEGMENTATION
AB In this paper, a new image segmentation technique called WaterBalloons is introduced. It combines both watershed segmentation and the active contour model known as Balloon Snake. The watershed transform has a major problem of over-segmentation. Solutions like region merging, use of markers, use of multi-scales have been proposed. These approaches led to other problems such as under-segmentation. The Balloon Snake in an innovative approach that detects salient objects in an image. But in general snakes are very sensitive to initialization and need user interactions and a priori knowledge of objects to segment. WaterBalloons provide the advantage of reducing watershed over-segmentation problems while preventing under-segmentation and ensure automatic initialization of traditional snakes. In addition, a method for parameter optimization of the proposed hybrid snake is introduced based on energy transitions tracking. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Dagher, Issam; El Tom, Kamal] Univ Balamand, Dept Comp Engn, Elkoura, Lebanon.
C3 University Balamand
RP Dagher, I (corresponding author), Univ Balamand, Dept Comp Engn, POB 100, Elkoura, Lebanon.
EM dagheri@balamand.edu.lb
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   ANDRADE MC, 1997, P SPIE NONL IM PROC, V8, P164
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   Bleau A, 2000, COMPUT VIS IMAGE UND, V77, P317, DOI 10.1006/cviu.2000.0822
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Gauch JM, 1999, IEEE T IMAGE PROCESS, V8, P69, DOI 10.1109/83.736688
   Gonzales R.C., 2002, Digital image processing
   Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KIRAN V, 2003, WATERSNAKE INTEGRATI
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254
   NGUYEN HT, 2003, IEEE T PAMI, V25
   NILANJAN R, 2003, IEEE T MED IMAGING, V22
   PARK J, 2001, IEEE T PAMI, V23
   Serra J., 1983, IMAGE ANAL MATH MORP
   Tek H, 1997, COMPUT VIS IMAGE UND, V65, P246, DOI 10.1006/cviu.1996.0579
   Vanhamel I, 2003, IEEE T IMAGE PROCESS, V12, P617, DOI 10.1109/TIP.2003.811490
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   [No title captured]
NR 21
TC 37
Z9 49
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 905
EP 912
DI 10.1016/j.imavis.2007.10.010
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800005
DA 2024-07-18
ER

PT J
AU Lu, CH
   Lu, ZY
AF Lu Chenhong
   Lu Zhaoyang
TI Local feature extraction for iris recognition with automatic scale
   selection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE biometric identification; iris recognition; multi-scales representation;
   automatic scale selection
AB This paper presents an iris recognition system using automatic scale selection algorithm for iris feature extraction. The proposed system first filters the given iris image adopting a bank of Laplacian of Gaussian (LoG) filters with many different scales and computes the normalized response of every filter. The parameter gamma used to normalize the filter responses, is derived by analyzing the scale-space maxima of the blob feature detector responses. Then the maxima normalized response over scales for each point are selected together as the optimal filter outputs of the given iris image and the binary codes for iris feature representation are achieved by encoding these optimal outputs through a zero threshold. Comparison experiment results clearly demonstrate an efficient performance of the proposed algorithm. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Lu Chenhong; Lu Zhaoyang] Xidian Univ, State Key Lab ISN, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Lu, CH (corresponding author), Xidian Univ, State Key Lab ISN, Xian 710071, Shaanxi, Peoples R China.
EM lu_chenh@hotmail.com; zhylu@vip.sina.com
CR Chin CS, 2006, COMPUT VIS IMAGE UND, V102, P169, DOI 10.1016/j.cviu.2006.01.002
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Miyazawa K, 2006, LECT NOTES COMPUT SC, V3832, P356
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Zhu Y, 2000, INT C PATT RECOG, P801, DOI 10.1109/ICPR.2000.906197
NR 8
TC 8
Z9 12
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 935
EP 940
DI 10.1016/j.imavis.2007.10.011
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800007
DA 2024-07-18
ER

PT J
AU Zhou, W
   Kambhamettu, C
AF Zhou, Wei
   Kambhamettu, Chandra
TI A unified framework for scene illuminant estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE light source estimation; illumination; ray tracing; source type
   determination
ID SHAPE
AB Most existing illuminant estimation algorithms work with assumptions of specific source types (e.g. directional light source or point light source). The assumptions bring up two main limitations which significantly restrict their applicabilities: first, the prior knowledge about Source types is needed; second, it can not handle complex scenes where multiple source types co-exist. In this paper, we develop a general light source model which is designed to model arbitrary light sources. With the general source model, we are able to estimate multiple illuminants of different types within a single unified framework. We use a plastic sphere to probe both diffuse and specular reflections of a scene. With specular reflections, we estimate geometric parameters of the illuminants by a novel ray tracing and matching algorithm. The diffuse reflections are used to estimate photometric parameters of the illuminants. We also notice that common source types are degenerate cases of the general source model under certain conditions. Therefore, we can approximate light sources with common source types by checking the conditions. The approximations serve as type determinations of light sources, which makes our framework extremely useful for lighting related algorithms which need prior knowledge about light sources. Experiment results on a variety of real images demonstrate the efficiency and accuracy of our algorithm. (c) 2006 Elsevier B.V. All rights reserved.
C1 [Zhou, Wei; Kambhamettu, Chandra] Univ Delaware, Dept Comp & Informat Sci, VIMS Lab, Newark, DE 19716 USA.
C3 University of Delaware
RP Zhou, W (corresponding author), Univ Delaware, Dept Comp & Informat Sci, VIMS Lab, Newark, DE 19716 USA.
EM wzhou@cis.udel.edu; chandra@cis.udel.edu
RI zhou, wei/B-5832-2019
OI zhou, wei/0000-0003-0659-7824
CR [Anonymous], ACM SIGGRAPH 1998 C
   Brooks M.J., 1985, P IJCAI 9 ANGELES CA, P932
   Debevec P., 1997, P ACM SIGGRAPH, P369, DOI DOI 10.1145/258734.258884
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Langer MS, 1997, PROC CVPR IEEE, P172, DOI 10.1109/CVPR.1997.609316
   LEE CH, 1985, ARTIF INTELL, V26, P125, DOI 10.1016/0004-3702(85)90026-8
   LEE SW, 1992, IMAGE VISION COMPUT, V10, P643, DOI 10.1016/0262-8856(92)90009-R
   LENSCH HPA, 2003, ACM T GRAPHICS, V5
   LI Y, 2003, IEEE P 9 INT C COMP, V2
   PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Powell MW, 2001, IEEE T PATTERN ANAL, V23, P1022, DOI 10.1109/34.955114
   POWELL MW, 2000, IEEE P COMPUTER VISI, V2, P263
   Sato I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P875, DOI 10.1109/ICCV.1999.790314
   SATO I, 1999, IEEE T VISUALIZATION, V5
   Shafer S. A., 1985, COLOR RES APPL
   Takai T, 2004, PROC CVPR IEEE, P98
   Wang Y, 2003, GRAPH MODELS, V65, P185, DOI 10.1016/S1524-0703(03)00043-2
   WANG Y, 2002, 7 EUR C COMP VIS 3, P272
   YANG Y, 1991, IEEE P COMP VIS PATT, P534
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   ZHANG Y, 2000, IEEE COMPUT VISION P, V1, P269
   ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658
   ZHOU W, 2002, 7 EUR C COMP VIS 4, P206
   ZHOU W, 2004, 17 INT C PATT REC AU
   ZHOU W, 2004, 15 BRIT MACH VIS C S
NR 26
TC 27
Z9 33
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 415
EP 429
DI 10.1016/j.imavis.2006.12.003
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500010
DA 2024-07-18
ER

PT J
AU Rajashekhara
   Chaudhuri, S
AF Rajashekhara
   Chaudhuri, Subhasis
TI Segmentation and region of interest based image retrieval in low depth
   of field observations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE contrast; EM algorithm; low depth of field; ROI; color histogram;
   precision; recall
AB In this paper we address the problem of extracting the focused region and its use in retrieving similar images from a low depth of field image database. We compute the histogram of the local contrast at each pixel and model it as a mixture of two exponential distributions - one for the focused and the other for the defocused region. Unlike the mixture of Gaussian distributions, a mixture of exponential distributions overlaps with same monotonicity over the entire range in [0, infinity) and it is difficult to separate into components. We estimate the parameters of these distributions using the EM algorithm. This is followed by a hypothesis testing which segments the focused region in the low depth of field image. A content-based retrieval scheme is now confined to the detected region for a proper retrieval. Experimental results for both segmentation and image retrieval using a database consisting of 4986 images are presented to show the efficacy of the suggested scheme. (c) 2007 Elsevier B.V. All rights reserved.
C1 GE Healthcare Technol, Global Diagnost Xray Engn, Bangalore 560066, Karnataka, India.
   Indian Inst Technol, Dept Elect Engn, Vis & Image Proc Lab, Bombay 400076, Maharashtra, India.
C3 General Electric; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Bombay
RP Rajashekhara (corresponding author), GE Healthcare Technol, Global Diagnost Xray Engn, Bangalore 560066, Karnataka, India.
EM raja.shekhara@ge.com; sc@ee.iitb.ac.in
CR [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   ARDIZZONI S, 1999, 10 INT WORKSH DAT EX, P167
   ARNOLD TG, 2000, IEEE T IMAGE PROCESS, V9, P102
   Balboa RM, 2003, VISION RES, V43, P2527, DOI 10.1016/S0042-6989(03)00471-1
   Banerjee M, 2003, PATTERN RECOGN, V36, P2649, DOI 10.1016/S0031-3203(03)00174-2
   Bimbo AD, 2001, VISUAL INFORM RETRIE
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   CHANG NS, 1980, IEEE T SOFTWARE ENG, V6, P519, DOI 10.1109/TSE.1980.230801
   Chaudhuri S., 1999, DEPTH DEFOCUS REAL A
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Gudivada V.N., 1995, IEEE COMPUTER, V28, P18
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jain A. K., 1995, P 2 AS C COMP VIS SI, P529
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   KUMAR S, 2000, P IEEE INT C IM PROC
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lipson P, 1997, PROC CVPR IEEE, P1007, DOI 10.1109/CVPR.1997.609453
   LUI TY, 2003, IEEE INT C IM PROC B
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   MARTINEZ A, 1996, P IEEE WORKSH CONT B, P25
   NILBACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   PASS G, 1996, P 4 ACM C MULT BOST
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   PONCE J, 1996, LECT NOTES COMPUTER
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SHETTINI R, 2001, COLOR IMAGING SCI EX
   SHIM S, 2002, IEEE INT C IM PROC R, V3, P957
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885
   Veltkamp RemcoC., 2002, Content-based image retrieval systems, DOI 10.1007/978-1-4615-0987-5_5
   Wang JZ, 2000, J AM MED INFORM ASSN, P883
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
NR 33
TC 4
Z9 5
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1709
EP 1724
DI 10.1016/j.imavis.2006.12.020
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900002
DA 2024-07-18
ER

PT J
AU Monga, O
AF Monga, Olivier
TI Defining and computing stable representations of volume shapes from
   discrete trace using volume primitives: Application to 3D image analysis
   in soil science
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D segmentation; volume approximation; 3D volume image; computed
   tomography; soil images; functional minimization
AB This paper presents an innovative approach for defining and computing stable (intrinsic) representations describing volume shapes from discrete traces without any a priori information. We assume that the discrete trace of the volume shape is defined by a binary 3D image where all marked points define the shape. Our basic idea is to describe the corresponding volume using a set of patches of volume primitives (bowls, cylinders, cones...). The volume primitives representation is assumed to optimize a criterion ensuring its stability and including a characterization of its scale (trade-off. fitting errors/number of patches). Our criterion takes also into account the preservation of topological properties of the initial shape representation (number of connected components, adjacency relationships...). We propose an efficient computing way to optimize this criterion using optimal region growing in an adjacency valuated graph representing the primitives and their adjacency relationships. Our method is applied to the modelling of porous media from 3D soil images. This new geometrical and topological representation of the pore network can be used to characterize soil properties. (C) 2006 Elsevier B.V. All rights reserved.
C1 Ctr IRD Dakar, Lab MAT, UCAD2, IRD, Dakar 18524, Senegal.
C3 Institut de Recherche pour le Developpement (IRD); University Cheikh
   Anta Diop Dakar
RP Monga, O (corresponding author), Ctr IRD Dakar, Lab MAT, UCAD2, IRD, BP 1386, Dakar 18524, Senegal.
EM Olivier.Monga@ird.sn
RI Monga, Olivier/I-5660-2015
OI Monga, Olivier/0000-0003-4528-5997
CR [Anonymous], 1987, INT J PATTERN RECOGN, DOI [DOI 10.1142/S0218001487000242, 10.1142/s0218001487000242]
   Ayache N, 2003, IEEE T MED IMAGING, V22, P1185, DOI 10.1109/TMI.2003.812863
   Baillard C, 2000, INT C PATT RECOG, P991, DOI 10.1109/ICPR.2000.905632
   Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290
   Bricault I, 1997, COMPUT VIS IMAGE UND, V67, P24, DOI 10.1006/cviu.1996.0501
   CAUMON, MATH GEOL, V36, P405
   Caumon G, 2005, COMPUT GEOSCI-UK, V31, P671, DOI 10.1016/j.cageo.2005.01.020
   Delerue JF, 2002, COMPUT GEOSCI-UK, V28, P1041, DOI 10.1016/S0098-3004(02)00020-1
   DELERUE JF, 1998, CGIM 98 COMP GRAPH I
   DELERUE JF, 1997, WORKSH 3D COMP VIS H
   DELERUE JF, 2001, THESIS U PARIS 11 OR
   FAUGERAS OD, 1984, COMPUT VISION GRAPH, V25, P169, DOI 10.1016/0734-189X(84)90101-4
   FROMENT J, MEGAWAVE 2 FREE IMAG
   GEORGE PL, TETRAHEDRAL MESH GEN
   Gregory PJ, 2003, PLANT SOIL, V255, P351, DOI 10.1023/A:1026179919689
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   MASSE D, 2006, MIOR DODELE INDIVIDU
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   MUMFORD D, 1985, IEEE C COMP VIS PATT
   PASCAL J, 2001, 0253 INRIA
   Peres G., 2003, IDENTIFICATION QUANT
   SCHMITT M, 1994, MORPHOLOGIE MATH EMA
   TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659
   Timmerman A, 1999, MODELLING OF TRANSPORT PROCESSES IN SOILS, P121
   Vogel HJ, 2001, ADV WATER RESOUR, V24, P233, DOI 10.1016/S0309-1708(00)00055-5
   WILLIAM EL, 1987, P SIGGRAPH, V21, P163
   WILLIAMS JWJ, 1964, COMMUN ACM, V7, P347
NR 27
TC 11
Z9 11
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1134
EP 1153
DI 10.1016/j.imavis.2006.06.012
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300011
DA 2024-07-18
ER

PT J
AU Nakamae, K
   Chikahisa, M
   Fujioka, H
AF Nakamae, Koji
   Chikahisa, Masaki
   Fujioka, Hiromu
TI Estimation of electron probe profile from SEM image through wavelet
   multiresolution analysis for inline SEM inspection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE wavelet multiresolution analysis; SEM image; probe profile estimation;
   electron probe; inline SEM inspection
AB We propose an analytical estimation method of the electron probe profile from an SEM image through the wavelet analysis of the multiscale information for inline SEM inspection. Defocused electron probe profiles are calculated based on wave optical theory. The calculated profiles are well approximated with the distributions composed of several Gaussian distributions with different center positions and variances. Analytical equations to estimate standard deviations of blurring Gaussian functions included in the defocused electron probe profile from a sequence of wavelet transform modulus maxima are derived. By using a noisy blurred step edge signal, the estimation accuracy was evaluated as a function of SNR with the standard deviation of blurring Gaussian function as a parameter. The accuracy of better than 15% is obtained when the SNR becomes larger than 10. Our analytical estimation method is applied to the simulated secondary electron intensity profile blurred with the defocused electron probe profile. The probe profile similar to the calculated one is estimated. (C) 2006 Elsevier BN. All rights reserved.
C1 Osaka Univ, Grad Sch Informat Sci & Technol, Dept Informat Syst Engn, Suita, Osaka 5650871, Japan.
   Fukui Univ Technol, Dept Management & Informat Sci, Fukui 9108505, Japan.
C3 Osaka University; Fukui University of Technology
RP Nakamae, K (corresponding author), Osaka Univ, Grad Sch Informat Sci & Technol, Dept Informat Syst Engn, 2-1 Yamada Oka, Suita, Osaka 5650871, Japan.
EM nakamae@ist.osaka-u.ac.jp
CR ALEXANDRESCU M, 1995, J GEOPHYS RES-SOL EA, V100, P12557, DOI 10.1029/95JB00314
   Chikahisa M, 2003, PROC SPIE, V5011, P275, DOI 10.1117/12.474010
   COLLIEX C., 1984, QUANTITATIVE ELECT M, P149
   FUJIOKA H, 1985, J PHYS E SCI INSTRUM, V18, P598, DOI 10.1088/0022-3735/18/7/014
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   Nowak RD, 1999, IEEE T IMAGE PROCESS, V8, P1408, DOI 10.1109/83.791966
   Nozoe M, 2000, P SOC PHOTO-OPT INS, V3998, P599, DOI 10.1117/12.386512
   Ose Y, 1999, PROC SPIE, V3677, P930, DOI 10.1117/12.350781
   Semiconductor Industry Association, 2001, INT TECHN ROADM SEM
   Takafuji A, 2000, MICROELECTRON ENG, V53, P649, DOI 10.1016/S0167-9317(00)00397-X
   YANO F, 1993, SCANNING, V15, P19, DOI 10.1002/sca.4950150103
NR 11
TC 6
Z9 7
U1 1
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1117
EP 1123
DI 10.1016/j.imavis.2006.07.024
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300009
DA 2024-07-18
ER

PT J
AU Xu, KL
   Luger, GF
AF Xu, Kanglin
   Luger, George F.
TI The model for optimal design of robot vision systems based on kinematic
   error correction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE active vision system; differential transformation; pose estimation;
   design for manufacturing (DFM)
AB An active vision system is a robot device for controlling the optics and mechanical structure of cameras based on visual information to simplify the processing for computer vision. In this paper, we present a kinematic model for the optimal design of such active vision systems. We first build a generic kinematic model for robot structure error analysis using a Denavit-Hartenberg transformation matrix, differential changes for this transformation matrix and link parameters. We then extend it to analyze an active vision system using algorithms for estimating depth using stereo cameras. This model is generic and is suitable for analysis of any active vision system. Since we can employ it to analyze errors based on variations of link parameters when we use an active vision system to estimating depth, we can combine it with a cost-tolerance model to implement an optimal design for active vision systems. In this way, we can not only save manufacturing cost and implement design for manufacturing (DFM) but reduce or avoid calibration work for an active vision system. Our algorithm also works for a binocular head and on even more complex tasks. Based on our approach, we have created a software tool that functions as a C++ class library. We also demonstrate how to use this software model to analyze a real system TRICLOPS, which is a significant proof of concept. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA.
C3 University of New Mexico
RP Xu, KL (corresponding author), Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA.
EM klxu@cs.umn.edu; luger@cs.unm.edu
CR ALBERT J, 1995, P 2 AS C COMP VIS AC
   Dong Z., 1990, Manufacturing Review, V3, P262
   Evans D. H., 1974, Journal of Quality Technology, V6, P188
   FIALA JC, 1994, INT J COMPUT VISION, V12, P2
   Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972
   Lawson C.L., 1995, CLASSICS APPL MATH
   PAUL RP, 1981, ROBOT MAIPULATORS MA
   Shih SW, 1998, IEEE T SYST MAN CY A, V28, P426, DOI 10.1109/3468.686704
   WU CH, 1984, INT J ROBOT RES, V3, P58, DOI 10.1177/027836498400300105
NR 9
TC 2
Z9 2
U1 2
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1185
EP 1193
DI 10.1016/j.imavis.2006.04.020
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300015
DA 2024-07-18
ER

PT J
AU Rovetta, S
   Masulli, F
AF Rovetta, Stefano
   Masulli, Francesco
TI Vector quantization and fuzzy ranks for image reconstruction
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE vector quantization; neural gas; fuzzy ranks
ID CLUSTERING ALGORITHMS; PATTERN-RECOGNITION
AB The problem of clustering is often addressed with techniques based on a Voronoi partition of the data space. Vector quantization is based on a similar principle, but it is a different technical problem. We analyze some approaches to the synthesis of a vector quantization codebook, and their similarities with corresponding clustering algorithms. We outline the role of fuzzy concepts in these algorithms, both in data representation and in training. Then we propose an alternative way to use fuzzy concepts as a modeling tool for physical vector quantization systems, Neural Gas with a fuzzy rank function. We apply this method to the problem of quality enhancement in lossy compression and reconstruction of images with vector quantization. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Genoa, Dept Comp & Informat Sci, I-16146 Genoa, Italy.
   Univ Pisa, Dept Comp Sci, I-56127 Pisa, Italy.
C3 University of Genoa; University of Pisa
RP Rovetta, S (corresponding author), Univ Genoa, Dept Comp & Informat Sci, Via Dodecaneso 35, I-16146 Genoa, Italy.
EM ste@disi.unige.it
RI Masulli, Francesco/V-9719-2017; Rovetta, Stefano/AAC-1987-2020; Rovetta,
   Stefano/H-5718-2012
OI Rovetta, Stefano/0000-0003-3865-2613; Masulli,
   Francesco/0000-0002-6612-0932
CR Ancona F, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, P1804, DOI 10.1109/ICNN.1997.614171
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Baraldi A, 1999, IEEE T SYST MAN CY B, V29, P786, DOI 10.1109/3477.809033
   Baraldi A, 1999, IEEE T SYST MAN CY B, V29, P778, DOI 10.1109/3477.809032
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   BORTOLAN G, 1985, FUZZY SET SYST, V15, P1, DOI 10.1016/0165-0114(85)90012-0
   CARRATO S, 1996, NNSP 96 P 6 IEEE WOR
   COHN D, 1994, IEEE T PATTERN ANAL, V16, P54, DOI 10.1109/34.273717
   CORANA A, 1987, ACM T MATH SOFTWARE, V13, P262, DOI 10.1145/29380.29864
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GERSHO A, 1982, IEEE T INFORM THEORY, V28, P157, DOI 10.1109/TIT.1982.1056457
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   HOFFMANN T, 1996, P INT C ART NEUR NET, P151
   Jain A K, 1988, ALGORITHMS CLUSTERIN
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kohonen T. K., 2001, SELF ORG MAPS, V3rd ed.
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311
   MOODY J, 1990, P INT JOINT C NEUR N, V2, P233
   Nasraoui O, 1996, FUZZ-IEEE '96 - PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P1031, DOI 10.1109/FUZZY.1996.552320
   Ridella S, 2001, IEEE T NEURAL NETWOR, V12, P371, DOI 10.1109/72.914531
   Ridella S, 2000, IEEE T CIRCUITS-II, V47, P1378, DOI 10.1109/82.899630
   Ridella S, 1998, NEURAL COMPUT APPL, V7, P37, DOI 10.1007/BF01413708
   RITTER H, 1991, NEURONALE NETZE
   Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788
   Rovetta S, 1999, IEEE T CIRCUITS-II, V46, P688, DOI 10.1109/82.769777
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Wang XH, 2001, FUZZY SET SYST, V118, P375, DOI 10.1016/S0165-0114(99)00062-7
   Wang XZ, 2001, FUZZY SET SYST, V118, P387, DOI 10.1016/S0165-0114(99)00063-9
   Zunino R, 2000, IEEE T IND ELECTRON, V47, P159, DOI 10.1109/41.824138
NR 34
TC 5
Z9 5
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 204
EP 213
DI 10.1016/j.imavis.2006.01.028
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700009
DA 2024-07-18
ER

PT J
AU Cheng, SC
   Wu, TL
AF Cheng, Shyi-Chyi
   Wu, Tian-Luu
TI Speeding up the similarity search in high-dimensional image database by
   multiscale filtering and dynamic programming
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE high-dimensional image database; content-based image retrieval;
   multiscale filtering; dynamic programming; spatial layout
ID COLOR
AB This paper presents a scalable content-based image indexing and retrieval system based on a new multiscale filter. Image databases often represent the image objects as high-dimensional feature vectors and access them via the feature vectors and similarity measure. A similarity measure based on the proposed multiscale filtering technique is defined to reduce the computational complexity of the similarity search in high-dimensional image database. Moreover, a special attention is paid to solve the problem of feature value correlation by dynamic programming. This problem arises from changes of images due to database updating or considering spatial layout in constructing feature vectors. The computational complexity of similarity measure in high-dimensional image database is very huge and the applications of image retrieval are restricted to certain areas. To demonstrate the effectiveness of the proposed algorithm, we conducted extensive experiments and compared the performance with the IBM's query by image content (QBIC) and Jain and Vailaya's methods. The experimental results demonstrate that the proposed method outperforms both of the methods in retrieval accuracy and noise immunity. The execution speed of the proposed method is much faster than that of QBIC method and it can achieve good results in terms of retrieval accuracy compared with Jain's method and QBIC method. (C) 2006 Elsevier B.V. All rights reserved.
C1 Natl Taiwan Ocean Univ, Dept Comp Sci, Chilung 202, Taiwan.
   Yung Ta Inst Technol & Commerce, Dept Elect Engn, Pingtung 909, Taiwan.
C3 National Taiwan Ocean University
RP Cheng, SC (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci, 2 Pei Ning Rd, Chilung 202, Taiwan.
EM csc@cs.ntou.edu.tw
RI cai, bo/G-1491-2010
CR Banham MR, 1996, IEEE T IMAGE PROCESS, V5, P619, DOI 10.1109/83.491338
   BANHAM MR, 1994, IEEE C, V3, P187
   Cha GH, 2002, IEEE T MULTIMEDIA, V4, P76
   CHANDRASEKARAN S, 1997, CVGIP GRAPH MODELS I
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923
   CHANG SK, 2002, P IEEE C PATTERN REC, V4, P130
   CHENG SC, IN PRESS IEE P IM VI
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   HU J, 2002, P IEEE C PATT REC, V3, P948
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Lu GJ, 2002, IEEE T MULTIMEDIA, V4, P372, DOI 10.1109/TMM.2002.802831
   NG R, 1996, P SPIE STOR RETR IM
   Pei SC, 1999, IEEE T CIRC SYST VID, V9, P501, DOI 10.1109/76.754779
   Popovici V, 2002, INT C PATT RECOG, P132, DOI 10.1109/ICPR.2002.1048255
   SCIASCIO ED, 2002, PATTERN RECOGN, V23, P1599
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SMITH J, 1994, P IEEE INT C IM P
   Spiegel M.R., 1981, MATH HDB FORMULAS TA
   WANG JZ, 2001, IEEE T PAMI, V23
   WEBBER R, 1998, P INT C VER LARG DAT, P194
   Winston P.H., 1984, Artificial Intelligence
   Zhou XM, 2001, PATTERN RECOGN LETT, V22, P469, DOI 10.1016/S0167-8655(00)00123-9
NR 23
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 424
EP 435
DI 10.1016/j.imavis.2006.01.014
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600003
DA 2024-07-18
ER

PT J
AU Wu, YH
   Li, XJ
   Wu, FC
   Hu, ZY
AF Wu, Yihong
   Li, Xinju
   Wu, Fuchao
   Hu, Zhanyi
TI Coplanar circles, quasi-affine invariance and calibration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE associated lines with two coplanar circles; projective invariance;
   quasi-affine invariance; circular points; camera calibration
AB We define the lines associated with two coplanar circles, and give the distributions of any two coplanar circles and their associated lines. Further we prove that the distribution of two coplanar circles with no real intersection and their associated lines is a quasi-affine invariance. Then the results are applied to calibrating a camera. The calibration method has the advantages: (1) it is based on conic fitting; (2) it does not need any matching. Experiments with two separate circles validate our quasi-affine invariance and show that the estimated camera intrinsic parameters are as good as those obtained by Zhang's (2000) method. (c) 2005 Elsevier B.V. All rights reserved.
C1 Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Wu, YH (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, POB 2728,95 E Rd Zhong Guan Cun, Beijing 100080, Peoples R China.
EM yhwu@nlpr.ia.ac.cn; xjli@nlpr.ia.ac.cn; fcwu@nlpr.ia.ac.cn;
   huzy@nlpr.ia.ac.cn
RI cai, bo/G-1491-2010
CR [Anonymous], 1991, Oriented Projective Geometry: A Framework for Geometric Computations
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley R. I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P510, DOI 10.1109/ICCV.1999.791264
   Hartley RI, 1998, INT J COMPUT VISION, V26, P41, DOI 10.1023/A:1007984508483
   HARTLEY RI, 1994, LNCS SERIES, V825, P237
   JIANG G, 2002, SINGLE AXIS GEOMETRY, P537
   LAVEAU S, 1996, LECT NOTES COMPUTER, V1064, P147
   MENG XQ, 2000, P 11 BRIT MACH VIS C, P496
   Nistér D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P116, DOI 10.1109/ICCV.2001.937612
   ROBERT L, 1993, P INT C COMP VIS BER, P540
   SEMPLE JG, 1952, ALGEBRAIC PROJECTIVE
   WERNER T, 1998, PATTERN RECOGN, P245
   Wu YH, 2005, PATTERN RECOGN LETT, V26, P1192, DOI 10.1016/j.patrec.2004.11.020
   Wu YH, 2004, LECT NOTES COMPUT SC, V3021, P190
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 16
TC 32
Z9 47
U1 2
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2006
VL 24
IS 4
BP 319
EP 326
DI 10.1016/j.imavis.2005.11.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 049US
UT WOS:000238043500001
DA 2024-07-18
ER

PT J
AU Bouchafa, S
   Zavidovique, B
AF Bouchafa, S
   Zavidovique, B
TI Efficient cumulative matching for image registration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE registration; level-lines; primitive matching
AB A new level-line registration technique is proposed for image transform estimation. This approach is robust towards contrast changes, does not require any estimate of the unknown transformation between images and tackles very challenging situations that usually lead to pairing ambiguities, like repetitive patterns in the images. The registration by itself is performed through efficient level-line cumulative matching based on a multi-stage primitive election procedure. Each stage provides a coarse estimate of the transformation that the next stage gets to refine. Even if we deal in this paper with similarity transform (rotation, scale and translation), our approach can be adapted to more general transformations. (C) 2005 Elsevier B.V. All rights reserved.
C1 Univ Paris 11, Inst Elect Fondamentale, F-91405 Orsay, France.
C3 Universite Paris Saclay
RP Bouchafa, S (corresponding author), Univ Paris 11, Inst Elect Fondamentale, F-91405 Orsay, France.
EM bouchafa@ief.u-psud.fr
OI Bouchafa, Samia/0000-0002-2860-8128
CR [Anonymous], 1982, Digital Picture Processing
   Baird H.S., 1985, MODEL BASED IMAGE MA
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923
   BOUCHAFA S, 1998, THESIS U PARIS 6
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Caselles V, 1999, INT J COMPUT VISION, V33, P5, DOI 10.1023/A:1008144113494
   DMITRY F, 2002, LINE REGISTATION DEM
   FROMENT J, 2001, WAVELETS SIGNAL IMAG
   GOSHTASBY A, 1986, IEEE T GEOSCI REMOTE, V24, P390, DOI 10.1109/TGRS.1986.289597
   GUICHARD F, 2000, CHANGE DETECTOR BASE
   Gusfield D., 1989, STABLE MARRIAGE PROB
   KANAL LN, 1981, P INT C CYB SOC
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X
   LEGUILLOUX Y, 1986, IEEE P 8 INT C PATT
   LI ZN, 2000, IEEE C MULT EXP
   Maintz J.B., 1998, Medical image analysis, V2
   MEDIONI G, 1984, IEEE T PATTERN ANAL, V6, P675, DOI 10.1109/TPAMI.1984.4767592
   Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532
   MORAVEC H, 1981, ROVER VISUAL OBSTACL, P785
   NACK ML, 1977, P MACH PROC REM SENS, P12
   Paragios NK, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1139, DOI 10.1109/ICCV.1998.710859
   PELIZZARI CA, 1989, J COMPUT ASSIST TOMO, V13, P20, DOI 10.1097/00004728-198901000-00004
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   ROMENT J, 1999, LECT NOTES COMPUTER, V1682, P152
   SHAPIRO LG, 1990, SYNTACTIC STRUCTURAL
   STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240
   SZELISKI R, 1994, P IEEE WORKSH APPL C
   ZEMIRLI K, 2000, IEEE JCIS 2000 ATL C
NR 29
TC 18
Z9 21
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 70
EP 79
DI 10.1016/j.imavis.2005.09.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200007
DA 2024-07-18
ER

PT J
AU Yeo, NC
   Lee, KH
   Venkatesh, YV
   Ong, SH
AF Yeo, NC
   Lee, KH
   Venkatesh, YV
   Ong, SH
TI Colour image segmentation using the self-organizing map and adaptive
   resonance theory
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE adaptive resonance theory; colour image segmentation neural networks;
   lateral control; network plasticity; network stability; self-organizing
   map
ID PATTERN-RECOGNITION; FUZZY ART; QUANTIZATION; NETWORK
AB We propose a new competitive-learning neural network model for colour image segmentation. The model, which is based on the adaptive resonance theory (ART) of Carpenter and Grossberg and on the self-organizing map (SOM) of Kohonen, overcomes the limitations of (i) the stability-plasticity trade-offs in neural architectures that employ ART; and (ii) the lack of on-line learning property in the SOM. In order to explore the generation of a growing feature map using ART and to motivate the main contribution, we first present a preliminary experimental model, SOMART, based on Fuzzy ART. Then we propose the new model, SmART, that utilizes a novel lateral control of plasticity to resolve the stability-plasticity problem. SmART has been experimentally found to perform well in RGB colour space, and is believed to be more coherent than Fuzzy ART. (c) 2005 Elsevier Ltd. All rights reserved.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
C3 National University of Singapore
RP Natl Univ Singapore, Dept Elect & Comp Engn, 10 Kent Ridge Crescent, Singapore 119260, Singapore.
EM eleongsh@nus.edu.sg
RI Ong, Sim-Heng/R-9244-2019
OI Ong, Sim-Heng/0000-0003-2766-8150
CR [Anonymous], P 1991 INT C ART NEU
   [Anonymous], 1997, SELF ORG MAPS, DOI DOI 10.1007/978-3-642-56927-2
   CAO DM, 1996, THESIS NAT U SINGAPO
   CARPENTER GA, 1988, COMPUTER, V21, P77, DOI 10.1109/2.33
   CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B
   CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2
   CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919
   DEKKER AH, 1994, NETWORK-COMP NEURAL, V5, P351, DOI 10.1088/0954-898X/5/3/003
   Frank T, 1998, IEEE T NEURAL NETWOR, V9, P544, DOI 10.1109/72.668896
   FRITZKE B, 1992, P INT ART NEUR NETW, P1051
   GHOSAL S, 1992, P INT JOINT C NEUR N, P297
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Lampinen J., 1992, Journal of Mathematical Imaging and Vision, V2, P261, DOI 10.1007/BF00118594
   MOORE B, 1988, P 1988 CONN MOD SUMM, P174
   Ong SH, 2002, IMAGE VISION COMPUT, V20, P279, DOI 10.1016/S0262-8856(02)00021-5
   Papamarkos N, 2002, IEEE T SYST MAN CY B, V32, P44, DOI 10.1109/3477.979959
   SCHALKOFF RJ, 1992, STAT STRUCTURAL NEUR
   SCHUEMANN S, 1998, P IEEE INT C NEUR NE, P707
   Traven H. G. C., 1989, Proceedings of 6th Scandinavian Conference on Image Analysis, P128
   UCHIYAMA T, 1994, IEEE T PATTERN ANAL, V16, P1197, DOI 10.1109/34.387488
   Vlajic N, 2001, IEEE T NEURAL NETWOR, V12, P1147, DOI 10.1109/72.950143
   YEO NC, 1998, THESIS NATL U SINGAP
NR 22
TC 34
Z9 38
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2005
VL 23
IS 12
BP 1060
EP 1079
DI 10.1016/j.imavis.2005.07.008
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 971ZK
UT WOS:000232423400004
DA 2024-07-18
ER

PT J
AU Yuen, SY
   Lam, HS
   Fong, CK
   Chen, SF
   Chow, CK
AF Yuen, SY
   Lam, HS
   Fong, CK
   Chen, SF
   Chow, CK
TI A robust iterative hypothesis testing design of the repeated genetic
   algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE repeated genetic algorithm; probability of success; free form object
   registration
AB The genetic algorithm is a simple and interesting optimization method for a wide variety of computer vision problems. However, its performance is often brittle and degrades drastically with increasing input problem complexity. While this problem is difficult to overcome due to the stochastic nature of the algorithm, this paper shows that a robust statistical design using sequential sampling, repeated independent trials and hypothesis testing can be used to greatly alleviate the degradation. The working principle is as follows: The probability of success P of a stochastic algorithm A (in this case A is the genetic algorithm) can be estimated by running N copies of A simultaneously or running A repeatedly N times. Such a scheme is generally referred to as the parallel or repeated (genetic) algorithm. By hypothesis testing, P can be tested with a required figure of merit (i.e. the level of significance). This is used in turn to adjust N in an iterative scheme to maintain a constant P-repeated, achieving a robust feedback loop. Experimental results on both synthetic and real images are reported on the application of this novel algorithm to an affine object detection problem and a free form 3D object registration problem. (c) 2005 Elsevier B.V. All rights reserved.
C1 City Univ Hong Kong, Dept Comp Engn & Informat Technol, Kowloon, Hong Kong, Peoples R China.
   City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong; City University of Hong Kong
RP City Univ Hong Kong, Dept Comp Engn & Informat Technol, Kowloon, Hong Kong, Peoples R China.
EM itkelvin@cityu.edu.hk
RI Yuen, Shiu Yin/B-7569-2008
OI YUEN, Shiu Yin Kelvin/0000-0002-5889-8808
CR Bebis G, 2002, IEEE T EVOLUT COMPUT, V6, P132, DOI 10.1109/4235.996013
   Cantú-Paz E, 2000, COMPUT METHOD APPL M, V186, P221, DOI 10.1016/S0045-7825(99)00385-0
   Chow CK, 2004, PATTERN RECOGN, V37, P105, DOI 10.1016/S0031-3203(03)00222-X
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   GRANT EL, 1988, STAT QUALIY CONTROL
   He J, 2003, ARTIF INTELL, V145, P59, DOI 10.1016/S0004-3702(02)00381-8
   HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5
   LEHMAN EL, 1986, TESTING STAT HYPOTHE, P89
   Li JP, 2002, EVOL COMPUT, V10, P207, DOI 10.1162/106365602760234081
   Masuda T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P879, DOI 10.1109/ICPR.1996.546150
   Reeves C.R., 2003, GENETIC ALGORITHMS P
   ROTH G, 1994, IEEE T PATTERN ANAL, V16, P901, DOI 10.1109/34.310686
   Rucklidge WJ, 1997, INT J COMPUT VISION, V24, P251, DOI 10.1023/A:1007975324482
   Rudolph G., 1998, Fundamenta Informaticae, V35, P67
   SEKULER R, 1990, PERCEPTION, P129
   Tsang PWM, 1997, IMAGE VISION COMPUT, V15, P819, DOI 10.1016/S0262-8856(97)00028-0
   Vitányi P, 2000, THEOR COMPUT SCI, V241, P3, DOI 10.1016/S0304-3975(99)00263-7
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yamany S. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1098, DOI 10.1109/ICCV.1999.790402
   Yuen SY, 2000, PATTERN RECOGN, V33, P1949, DOI 10.1016/S0031-3203(99)00189-2
   Yuen SY, 2001, IMAGE VISION COMPUT, V19, P551, DOI 10.1016/S0262-8856(00)00100-1
   YUEN SY, 2001, LECT NOTES COMPUTER, V2124, P668
   YUEN SY, IEEE T EVOLUTIONARY
NR 23
TC 3
Z9 3
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2005
VL 23
IS 11
BP 972
EP 980
DI 10.1016/j.imavis.2005.07.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 973KF
UT WOS:000232520600004
DA 2024-07-18
ER

PT J
AU Fu, J
   Caulfield, HJ
   Bond, AJ
AF Fu, J
   Caulfield, HJ
   Bond, AJ
TI Artificial and biological color band design as spectral compression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE artificial color; spectral bands; hyperspectral imaging
ID MINIMUM DESCRIPTION LENGTH; VISION; PRINCIPLE
AB The incredibly complex spectral information available to animals is far too detailed to be measured or used by those animals. What nature has evolved is a way of compressing the spectral information into a few signals that are easily detected and readily used for robust discrimination among objects or events of importance to the animal. The spectral discriminants human brains compute from those measurements and attribute to perceived objects in the world are what we call colors. Artificial Color uses the same approach to accomplish machine perception. In both Artificial and Biological Color, the number and spectral details of the spectral bands used to compress the available spectral information represent a complex tradeoff among multiple factors: Domain Coverage, Band Number, Discrimination Utility, and Manufacturability. In Biological Color, there are multiple objectives (from the viewpoint of population survival of a species) and those objectives are not equally weighted; so no single number can be defined as a figure of merit to be optimized. Artificial Color nearly always has the advantage of having very narrowly defined objectives, so it can often be much better for that purpose than the general Biological Color. We explore the criteria used to compare choices of spectral bands and the tradeoffs among those choices. We then discuss some of the solutions nature has evolved and some of the means open to Artificial Color that are not open to Biological Color. (c) 2005 Elsevier B.V. All rights reserved.
C1 Alabama A&M Univ, Dept Comp Sci, Normal, AL 35762 USA.
   Alabama A&M Univ, Inst Res, Normal, AL 35762 USA.
   Alabama A&M Univ, Sch Engn & Technol, Normal, AL 35762 USA.
C3 Alabama A&M University; Alabama A&M University; Alabama A&M University
RP Fu, J (corresponding author), Alabama A&M Univ, Dept Comp Sci, Normal, AL 35762 USA.
EM jian.fu@email.aamu.edu
CR Barnard K, 1997, COMPUT VIS IMAGE UND, V65, P311, DOI 10.1006/cviu.1996.0567
   Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554
   Brown RO, 1997, CURR BIOL, V7, P844, DOI 10.1016/S0960-9822(06)00372-1
   Caulfield HJ, 2004, INFORM SCIENCES, V167, P1, DOI 10.1016/j.ins.2003.09.027
   Caulfield HJ, 2003, NEUROCOMPUTING, V51, P463, DOI 10.1016/S0925-2312(02)00698-7
   Caulfield HJ, 1996, IEEE T FUZZY SYST, V4, P206, DOI 10.1109/91.493914
   CAULFIELD HJ, 1999, FUZZY SYSTEM THEORY, V2, P747
   DAVISSON LD, 1976, DATA COMPRESSION BEN
   DOROTHEA J, 1968, J OPT SOC AM, V49, P890
   FINLAYSON G, 2000, P BR MACH VIS C, P303
   Fu J, 2004, J ELECTRON IMAGING, V13, P553, DOI 10.1117/1.1760081
   GOLDSMITH TH, 1990, Q REV BIOL, V65, P281, DOI 10.1086/416840
   Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398
   Jacobs G., 1981, COMP COLOR VISION
   NUBOER JFW, 1986, NETH J ZOOL, V36, P344
   Parker A., 2003, BLINK EYE
   THOMPSON E, 1992, BEHAV BRAIN SCI, V15, P1, DOI 10.1017/S0140525X00067248
   Zarándy A, 1999, IEEE T CIRCUITS-I, V46, P229, DOI 10.1109/81.747190
NR 18
TC 11
Z9 12
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2005
VL 23
IS 8
BP 761
EP 766
DI 10.1016/j.imavis.2005.05.009
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VD
UT WOS:000231400500008
DA 2024-07-18
ER

PT J
AU Huynh, DQ
   Heyden, A
AF Huynh, DQ
   Heyden, A
TI Scene point constraints in camera auto-calibration: an implementational
   perspective
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE auto-calibration; bundle adjustment; scene constraints; projective
   factorization; Euclidean reconstruction
ID PROJECTIVE STRUCTURE; MOTION; SHAPE
AB We present a scheme for incorporating scene constraints into the auto-calibration process for the structure and motion recovery problem. The steps covered by the scheme include projective factorization of the joint image measurement matrix, recovery of the absolute dual quadric, the upgrade from projective structure to its Euclidean counterpart, and incorporation of constraints from orthogonal scene planes into bundle adjustment. The focus of the paper is on the implementation details of all these steps and discussion of the various issues that arose. We have tested the scheme on both synthetic and real image data and found that it is more advantageous to incorporate into camera auto-calibration and bundle adjustment as many scene constraints as are available rather than performing auto-calibration and bundle adjustment alone. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Western Australia, Sch Comp Sci & Software Engn, Crawley, WA 6009, Australia.
   Malmo Univ, Sch Technol & Soc, Malmo, Sweden.
C3 University of Western Australia; Malmo University
RP Univ Western Australia, Sch Comp Sci & Software Engn, Crawley, WA 6009, Australia.
EM du@csse.uwa.edu.au; heyden@ts.mah.se
RI Huynh, Du/C-5440-2013
OI Huynh, Du/0000-0003-3080-9655
CR [Anonymous], 1981, Practical Optimization
   ASTROM K, 1999, P INT C COMP VIS, V1, P285
   BARTOLI A, 2001, 4236 INRIA
   Berthilsson R, 1997, PROC CVPR IEEE, P444, DOI 10.1109/CVPR.1997.609363
   Chen GQ, 2001, PROC CVPR IEEE, P717
   FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564
   GONG R, 2004, P AS C COMP VIS, V1, P372
   GONG R, 2004, P AS C COMP VIS, V1, P509
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P882, DOI 10.1109/ICCV.1995.466843
   HARTLEY RI, 1992, LECT NOTES COMPUT SC, V588, P579
   Heyden A, 2002, INT C PATT RECOG, P631, DOI 10.1109/ICPR.2002.1048381
   Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5
   Heyden A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P350, DOI 10.1109/ICCV.1999.791241
   HEYDEN A, 1996, P 13 INT C PATT REC, V1, P339
   HEYDEN A, 1997, SCAND C IM AN, P1058
   Huynh DQ, 2001, PROC CVPR IEEE, P695
   HUYNH DQ, 2002, P AS C COMP VIS MELB, V2, P436
   Kahl F, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P761, DOI 10.1109/ICCV.1998.710803
   Liebowitz D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P293, DOI 10.1109/ICCV.1999.791233
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991
   Mahamud S, 2001, PROC CVPR IEEE, P1018
   Mahamud S, 2000, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2000.854872
   McLauchlan PF, 1999, IEEE WORKSHOP ON MULTI-VIEW MODELING & ANALYSIS OF VISUAL SCENES (MVIEW'99). PROCEEDINGS, P37, DOI 10.1109/MVIEW.1999.781081
   MCLAUCHLAN PF, 1999, LECT NOTE COMPUTER S, P183
   MOHR R, 1991, PATTERN RECOGN LETT, V12, P39, DOI 10.1016/0167-8655(91)90026-I
   Morris DD, 2001, PROC CVPR IEEE, P343
   OLIENSIS J, 1999, P INT C COMP VIS, V1, P745
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705
   Pollefeys M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P349, DOI 10.1109/ICPR.1996.546047
   Quan L, 1996, IEEE T PATTERN ANAL, V18, P151, DOI 10.1109/34.481540
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   SPARR G, 1996, P INT C PATT REC, V1, P328
   SPARR G, 1994, P 4 EUR C COMP VIS C, P471
   Sturm P., 1996, EUROPEAN C COMPUTER, P709, DOI DOI 10.1007/3-540-61123-1
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 44
TC 5
Z9 7
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2005
VL 23
IS 8
BP 747
EP 760
DI 10.1016/j.imavis.2005.05.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VD
UT WOS:000231400500007
DA 2024-07-18
ER

PT J
AU Bergman, L
   Verikas, A
   Bacauskiene, M
AF Bergman, L
   Verikas, A
   Bacauskiene, M
TI Unsupervised colour image segmentation applied to printing quality
   assessment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE colour image segmentation; fuzzy clustering; quality inspection; colour
   printing
ID ALGORITHM
AB We present an option for colour image segmentation applied to printing quality assessment in offset lithographic printing by measuring an average ink dot size in halftone pictures. The segmentation is accomplished in two stages through classification of image pixels. In the first stage, rough image segmentation is performed. The results of the first segmentation stage are then utilized to collect a balanced training data set for learning refined parameters of the decision rules. The developed software is successfully used in a printing shop to assess the ink dot size on paper and printing plates. (C) 2004 Elsevier B.V. All rights reserved.
C1 Halmstad Univ, Integrated Syst Lab, S-30118 Halmstad, Sweden.
   Kaunas Univ Technol, Dept Appl Elect, LT-3031 Kaunas, Lithuania.
C3 Halmstad University; Kaunas University of Technology
RP Verikas, A (corresponding author), Halmstad Univ, Integrated Syst Lab, Box 823, S-30118 Halmstad, Sweden.
EM lars.bergman@ide.hh.se; antanas.ver-ikas@ide.hh.se;
   marija.bacauskiene@ktu.lt
CR Baraldi A, 2000, OPT ENG, V39, P907, DOI 10.1117/1.602467
   Chen TQ, 2002, PATTERN RECOGN, V35, P395, DOI 10.1016/S0031-3203(01)00050-4
   Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Gao JB, 2002, OPT ENG, V41, P608, DOI 10.1117/1.1432315
   Greenspan H, 2001, PATTERN RECOGN LETT, V22, P1525, DOI 10.1016/S0167-8655(01)00086-1
   Huang HY, 2002, J ELECTRON IMAGING, V11, P136, DOI 10.1117/1.1455007
   Hunt RW G., 1998, MEASURING COLOUR
   Johansson S.A., 1988, PIXE NOVEL TECHNIQUE
   Krishnapuram R, 2000, IEEE T FUZZY SYST, V8, P228, DOI 10.1109/91.842156
   Kristiansson P, 1997, NUCL INSTRUM METH B, V130, P303, DOI 10.1016/S0168-583X(97)00278-4
   Kurugollu F, 2001, IMAGE VISION COMPUT, V19, P915, DOI 10.1016/S0262-8856(01)00052-X
   Li CH, 2000, IEEE T MED IMAGING, V19, P1150, DOI 10.1109/42.896791
   Littmann E, 1997, IEEE T NEURAL NETWOR, V8, P175, DOI 10.1109/72.554203
   Mirmehdi M, 2000, IEEE T PATTERN ANAL, V22, P142, DOI 10.1109/34.825753
   OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6
   Onyango CM, 2001, IMAGE VISION COMPUT, V19, P523, DOI 10.1016/S0262-8856(00)00097-4
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559
   Papamarkos N, 2000, IMAGE VISION COMPUT, V18, P213, DOI 10.1016/S0262-8856(99)00015-3
   Saber E, 1997, IMAGE VISION COMPUT, V15, P769, DOI 10.1016/S0262-8856(97)00019-X
   TOMINAGA S, 1992, COLOR RES APPL, V17, P230, DOI 10.1002/col.5080170405
   Trahanias PE, 1996, IEEE T SYST MAN CY B, V26, P135, DOI 10.1109/3477.484445
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   TSAO CE, 1996, PATTERN RECOGN, V29, P757
   UCHIYAMA T, 1994, IEEE T PATTERN ANAL, V16, P1197, DOI 10.1109/34.387488
   Verikas A, 2000, NEURAL COMPUT APPL, V9, P227, DOI 10.1007/s005210070016
   VERIKAS A, 1994, P 4 EUR C ART NEUR N, V2, P847
   VERIKAS A, 1998, P 4 INT C ENG APPL N, P189
   Wyszecki G., 1982, Color science: Concepts and methods, quantitative data and formulae
   Xu L, 1999, IMAGE VISION COMPUT, V17, P65, DOI 10.1016/S0262-8856(98)00091-2
NR 32
TC 17
Z9 19
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2005
VL 23
IS 4
BP 417
EP 425
DI 10.1016/j.imavis.2004.11.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NR
UT WOS:000227222100005
DA 2024-07-18
ER

PT J
AU Wang, GH
   Tsui, HT
   Hu, ZY
   Wu, FC
AF Wang, GH
   Tsui, HT
   Hu, ZY
   Wu, FC
TI Camera calibration and 3D reconstruction from a single view based on
   scene constraints
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE camera calibration; 3D reconstruction; Absolute conic; circular points;
   single view modeling
ID POINTS; SHAPE
AB This paper mainly focuses on the problem of camera calibration and 3D reconstruction from a single view of structured scene. It is well known that three constraints on the intrinsic parameters of a camera can be obtained from the vanishing points of three mutually orthogonal directions. However, there usually exist one or several pairs of line segments, which are mutually orthogonal and lie in the pencil of planes defined by two of the vanishing directions in the structured scenes. It is proved in this paper that a new independent constraint to the image of the absolute conic can be obtained if the pair of line segments is of equal length or with known length ratio in space. The constraint is further studied both in terms of the vanishing points and the images of circular points. Hence, four independent constraints on a camera are obtained from one image, and the camera can be calibrated under the widely accepted assumption of zero-skew. This paper also presents a simple method for the recovery of camera extrinsic parameters and projection matrix with respect to a given world coordinate system. Furthermore, several methods are presented to estimate the positions and poses of space planar surfaces from the recovered projection matrix and scene constraints. Thus, a scene structure can be reconstructed by combining the planar patches. Extensive experiments on simulated data and real images, as well as a comparative test with other methods in the literature, validate our proposed methods. (C) 2004 Elsevier B.V. All rights reserved.
C1 Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
   Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China.
C3 Chinese University of Hong Kong; Chinese Academy of Sciences; Institute
   of Automation, CAS
RP Aviat Univ Airforce, Changchun 130022, Peoples R China.
EM ghwang@ee.cuhk.edu.hk
RI Wang, Guanghui/B-1080-2008; Hu, Zhanying/AAE-8790-2019
CR CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   Chen CY, 1999, PROCEEDINGS OF THE IEEE SIGNAL PROCESSING WORKSHOP ON HIGHER-ORDER STATISTICS, P30, DOI 10.1109/HOST.1999.778686
   Cipolla R., 1998, Proceedings of IAPR Workshop on Machine Vision Applications, P559
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Horry Y., 1997, SIGGRAPH 97, P225
   LIEBOWITZ D, 1999, P EUR, P39
   Liebowitz D., 1999, P INT C COMP VIS KEK, P285
   MCLEAN GF, 1995, IEEE T PATTERN ANAL, V17, P1090, DOI 10.1109/34.473236
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   SEMPLE JG, 1952, ALGEBRAIC PROJECTIVE
   SUPER BJ, 1995, IEEE T PATTERN ANAL, V17, P333, DOI 10.1109/34.385983
   van den Heuvel FA, 1998, ISPRS J PHOTOGRAMM, V53, P354, DOI 10.1016/S0924-2716(98)00019-7
   VANDENHEUVEL FA, 1998, INT ARCH PHOTOGRAMME, V32, P652
   Wang GH, 2002, PROC SPIE, V4875, P830, DOI 10.1117/12.477078
   WANG GH, 2004, J COMPUTER SCI TECHN, V19
   Wilczkowiak M, 2002, LECT NOTES COMPUT SC, V2353, P221
   Wilczkowiak M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P142, DOI 10.1109/ICCV.2001.937510
   Wu F., 2003, CHINESE J SOFTWARE, V14, P703
   ZHANG L, 1997, P COMP VIS PATT REC, P990
   Zisserman A, 1998, PHILOS T R SOC A, V356, P1193, DOI 10.1098/rsta.1998.0217
NR 23
TC 42
Z9 55
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2005
VL 23
IS 3
BP 311
EP 323
DI 10.1016/j.imavis.2004.07.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NO
UT WOS:000227221800004
DA 2024-07-18
ER

PT J
AU Arcelli, C
   di Baja, GS
   Svensson, S
AF Arcelli, C
   di Baja, GS
   Svensson, S
TI Computing and analysing convex deficiencies to characterise 3D complex
   objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE volume image; distance transform; watershed; topological erosion
ID SIMPLE POINTS; OPERATIONS; ALGORITHM; TOPOLOGY; IMAGES; TRANSFORMATIONS
AB Entities such as object components, cavities, tunnels and concavities in 3D digital images can be useful in the framework of object analysis. For each object component, we first identify its convex deficiencies, by subtracting the object component from a covering polyhedron approximating the convex hull. Watershed segmentation is then used to decompose complex convex deficiencies into simpler parts, corresponding to individual cavities, concavities and tunnels of the object component. These entities are finally described by means of a representation system accounting for the shape features characterising them. (C) 2004 Elsevier B.V. All rights reserved.
C1 CNR, Ist Cibernet E Caianiello, Naples, Italy.
   Ctr Image Anal, Uppsala, Sweden.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Cibernetica
   "Eduardo Caianiello" (ICIB-CNR)
RP CNR, Ist Cibernet E Caianiello, Naples, Italy.
EM car@imagm.cib.na.cnr.it; gsdb@imagm.cib.na.enr.it; stina@cb.uu.se
OI Sanniti di Baja, Gabriella/0000-0003-2218-0412
CR Aktouf Z, 2002, PATTERN RECOGN LETT, V23, P523, DOI 10.1016/S0167-8655(01)00152-0
   [Anonymous], 1979, P INT WORKSHOP IMAGE
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   ARCELLI C, 1988, COMPUT VISION GRAPH, V43, P361, DOI 10.1016/0734-189X(88)90089-8
   BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P169, DOI 10.1016/0167-8655(94)90046-9
   Borgefors G, 1996, COMPUT VIS IMAGE UND, V63, P145, DOI 10.1006/cviu.1996.0010
   Borgefors G, 1996, COMPUT VIS IMAGE UND, V64, P368, DOI 10.1006/cviu.1996.0065
   BORGEFORS G, 1994, P 5 BRIT MACH VIS C, P275
   KONG TY, 1989, COMPUT GRAPH, V13, P159, DOI 10.1016/0097-8493(89)90058-7
   KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3
   Meyer F, 2001, INT J PATTERN RECOGN, V15, P1089, DOI 10.1142/S0218001401001337
   PIPER J, 1987, PATTERN RECOGN, V20, P599, DOI 10.1016/0031-3203(87)90030-6
   ROSENFEL.A, 1966, J ACM, V13, P471
   ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7
   SAHA PK, 1994, IEEE T PATTERN ANAL, V16, P1028, DOI 10.1109/34.329007
   SUZUKI S, 1985, IEEE T PATTERN ANAL, V7, P638, DOI 10.1109/TPAMI.1985.4767720
   Svensson S, 2003, LECT NOTES COMPUT SC, V2886, P124
   Svensson S, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P342, DOI 10.1109/ICIAP.2003.1234073
   Svensson S, 2003, COMPUT VIS IMAGE UND, V90, P242, DOI 10.1016/S1077-3142(03)00061-4
   Svensson S, 2002, PATTERN RECOGN LETT, V23, P1419, DOI 10.1016/S0167-8655(02)00102-2
   THURFJELL L, 1992, CVGIP-GRAPH MODEL IM, V54, P357, DOI 10.1016/1049-9652(92)90083-A
   TORIWAKI J, 1979, IEEE T SYST MAN CYB, V9, P628, DOI 10.1109/TSMC.1979.4310092
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
NR 23
TC 4
Z9 4
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 203
EP 211
DI 10.1016/j.imavis.2004.06.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800011
DA 2024-07-18
ER

PT J
AU Yemez, Y
   Schmitt, F
AF Yemez, Y
   Schmitt, F
TI 3D reconstruction of real objects with high resolution shape and texture
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D object reconstruction; shape from silhouette; marching cubes; octree;
   surface particles; texture mapping
ID AUTOMATIC RECONSTRUCTION; CONSTRUCTION; OCTREES
AB We present a robust and accurate system for 3D reconstruction of real objects with high resolution shape and texture. Our reconstruction method is passive, the only information needed being 2D images obtained with a calibrated camera from different view angles as the object rotates on a turntable. The triangle surface model is obtained by a scheme combining octree construction and marching cubes algorithm, which is adapted to the shape from silhouette problem. We develop a texture mapping strategy based on surface particles to adequately address photography related problems such as inhomogeneous lighting, highlights and occlusion. Reconstruction results are included to demonstrate the attained quality. (C) 2004 Elsevier B.V. All rights reserved.
C1 Koc Univ, Dept Comp Engn, TR-34450 Istanbul, Turkey.
   Ecole Natl Super Telecommun Bretagne, CNRS, URA820, Signal & Image Proc Dept, F-75013 Paris, France.
C3 Koc University; IMT - Institut Mines-Telecom; IMT Atlantique; Centre
   National de la Recherche Scientifique (CNRS)
RP Koc Univ, Dept Comp Engn, TR-34450 Istanbul, Turkey.
EM yyemez@ku.edu.tr; francis.schmitt@enst.fr
CR [Anonymous], P EUR C COMP VIS
   [Anonymous], P 5 EUR C COMP VERS
   BRONIELSEN M, 1994, 3D MODELS OCCLUDING
   BUSCH H, 1989, SPIE P VIS COMM IM P, P356
   CHEN HH, 1988, COMPUT VISION GRAPH, V43, P409, DOI 10.1016/0734-189X(88)90092-8
   CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P100, DOI 10.1016/S0734-189X(86)80031-7
   CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P256, DOI 10.1016/0734-189X(86)90078-2
   Cross Geoffrey., 2000, CONFLUENCE COMPUTER, P25
   Eisert P, 2000, IEEE T CIRC SYST VID, V10, P261, DOI 10.1109/76.825726
   Esteban CH, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P46, DOI 10.1109/IM.2003.1240231
   Esteban CH, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P159, DOI 10.1109/TDPVT.2002.1024055
   Fitzgibbon A., 1998, LECT NOTES COMPUTER, V1506, P155
   FROMHERZ T, 1995, ISPRS INT WORKSH PIX, P186
   Kampel M, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P754, DOI 10.1109/TDPVT.2002.1024154
   KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441
   KOCH R, 1998, P EUR C COMP VIS, P55
   LAURENTINI A, 1995, IEEE T PATTERN ANAL, V17, P188, DOI 10.1109/34.368170
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   LIEDTKE CE, 1991, IEEE C COMP VIS PATT, P704
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Matsumoto K, 1999, LECT NOTES COMPUT SC, V1568, P177
   Matsumoto Y, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P197, DOI 10.1109/IM.1997.603866
   MENDONCA PRS, 1999, LNCS, V1883, P149
   Montani C., 1994, Visual Computer, V10, P353, DOI 10.1007/BF01900830
   MULAYIM AY, 1999, VIS MOD VIS VMW 99 E
   Niem W, 1999, IMAGE VISION COMPUT, V17, P125, DOI 10.1016/S0262-8856(98)00116-4
   POLLEFEYS M, 1998, P 10 IMDSP WORKSH 19, P195
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   RIOUX M, 2000, IEEE INT C ROB AUT, V1, P111
   Sato Y, 1996, GRAPH MODEL IM PROC, V58, P437, DOI 10.1006/gmip.1996.0036
   SCHMITT F, 1999, IEEE INT C IM PROC I, P102
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   Soucy M, 1996, VISUAL COMPUT, V12, P503, DOI 10.1007/s003710050082
   SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029
   SZELISKI R, 1992, COMP GRAPH, V26, P185, DOI 10.1145/142920.134037
   Tan P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P164, DOI 10.1109/ICCV.2003.1238333
   Tarini M, 2002, VISION MODELING, AND VISUALIZATION 2002, PROCEEDINGS, P283
   Tsai R., 1981, IEEE J ROBOTIC AUTOM, V24, P381
   WILHELMS J, 1992, ACM T GRAPHIC, V11, P201, DOI 10.1145/130881.130882
   Yemez Y, 2003, IEEE T VIS COMPUT GR, V9, P551, DOI 10.1109/TVCG.2003.1260748
   ZHENG JY, 1994, IEEE T PATTERN ANAL, V16, P163, DOI 10.1109/34.273734
NR 41
TC 47
Z9 56
U1 2
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2004
VL 22
IS 13
BP 1137
EP 1153
DI 10.1016/j.imavis.2004.06.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 862LY
UT WOS:000224493600005
DA 2024-07-18
ER

PT J
AU Rodrigues, R
   Fernandes, A
   van Overveld, K
   Ernst, F
AF Rodrigues, R
   Fernandes, A
   van Overveld, K
   Ernst, F
TI From spatiotemporal curves to reconstructed depth
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE depth reconstruction; spatiotemporal video analysis; spatiotemporal
   curves
AB We present a novel approach for 3D reconstruction based on a set of images taken from a static scene. Our solution is inspired by the spatiotemporal analysis of video sequences. The method is based on a best fitting scheme for spatiotemporal curves that allows us to compute 3D world coordinates of points within the scene. As opposed to a large number of current methods, our technique deals with random camera movements in a transparent way, and even performs better in these cases than with restrained motion such as pure translation. Robustness against occlusion and aliasing is inherent to the method as well. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Minho, Dept Informat, P-4710057 Braga, Portugal.
   Philips Res, Eindhoven, Netherlands.
C3 Universidade do Minho; Philips; Philips Research
RP Univ Minho, Dept Informat, Campus Gualtar, P-4710057 Braga, Portugal.
EM rpr@sim.di.uminho.pt; af@di.uminho.pt;
   overv@natlab.research.philips.com; fabian.ernst@philips.com
RI Rodrigues, Rui PA/B-4234-2012; Ramires Fernandes, Antonio/H-9284-2015
OI Rodrigues, Rui/0000-0003-4883-1375; Ramires Fernandes,
   Antonio/0000-0002-3680-572X
CR ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5
   CAPLIER A, 1995, LECT NOTES COMPUTER, V970, P246
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   DUC B, 1995, LECT NOTES COMPUTER, V970, P238
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1
   IMIYA A, 2001, LECT NOTES COMPUTER, V1998, P193
   Jebara T., 1999, IEEE SIGNAL PROCESSI, V16
   KIM Z, 1996, THESIS CS DEP KAIST
   MCMASTER RB, 1986, AM CARTOGRAPHER, V13, P103, DOI 10.1559/152304086783900059
   Moscheni F, 1998, IEEE T PATTERN ANAL, V20, P897, DOI 10.1109/34.713358
   OTSUKA K, 1997, CVPR97, P200
   PENG S, 1991, CVPR 91, P283
   PRESS WH, 1993, NUMERICAL RECPIES C
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Redert A, 1999, IEEE SIGNAL PROC MAG, V16, P29, DOI 10.1109/79.768571
   RODRIGUES R, 2002, VIS INT 2002 P CAN M, P252
   ROTE G, 1992, COMPUTING, V48, P337, DOI 10.1007/BF02238642
   Sonka M., 1993, IMAGE PROCESSING ANA
   WANG JYA, 1994, 262 MIT
   WHITE ER, 1985, AM CARTOGRAPHER, V12, P17, DOI 10.1559/152304085783914703
NR 22
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 959
EP 970
DI 10.1016/j.imavis.2004.03.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Boult, TE
   Gao, X
   Micheals, R
   Eckmann, M
AF Boult, TE
   Gao, X
   Micheals, R
   Eckmann, M
TI Omni-directional visual surveillance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE detection; tracking; background adaptation; real-time; frame-rate;
   hysteresis; connected-components; quasi-connected-components;
   omni-directional video
ID TRACKING; CALIBRATION; DISTORTION; SYSTEMS; CAMERA
AB Perimeter security generally requires watching areas that afford trespassers reasonable cover and concealment. By definition, such 'interesting' areas have limited visibility distance. Furthermore, targets of interest generally attempt to conceal themselves within the cover, sometimes adding camouflage to further reduce their visibility. Such targets are only visible while in motion. The combined result of limited visibility and target visibility severely reduces the usefulness of any approach using a standard Pan/Tilt/Zoom (PTZ) camera. As a result, these situations call for a very sensitive system with a wide field of view, and are a natural application for Omni-directional Video Surveillance and Monitoring.
   This paper describes a frame-rate, low-power, omni-directional tracking system (LOTS). The paper discusses related background work including resolution issues in omni-directional imaging. One of the novel system component details is quasi-connected-components (QCC). QCC combines gap filling, thresholding-with-hysteresis (TWH) and a novel region merging/cleaning approach. The multi-background modeling and dynamic thresholding make an ideal approach for difficult situations like outdoor tracking in high clutter. The paper also describes target geolocation and issues in the system user interface. The single viewpoint property of the omni-directional imaging system used simplifies the backprojection and unwarping. We end with a summary of an external evaluation of an early form of the system and comments about recent work and field tests. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Colorado, Colorado Springs, CO 80933 USA.
   Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA.
   Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18015 USA.
C3 University of Colorado System; University of Colorado at Colorado
   Springs; National Institute of Standards & Technology (NIST) - USA;
   Lehigh University
RP Univ Colorado, 1420 Austin Pluffs Pkwy, Colorado Springs, CO 80933 USA.
EM tboult@cs.uccs.edu
RI Boult, Terrance E./AAT-2134-2021
OI Boult, Terrance E./0000-0001-5007-2529
CR [Anonymous], ACTIVE VISION
   AYER A, 1994, COMPUTER ECCV STOCKH, V2, P316
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   BEYMER D, 1997, P IEEE C COMP VIS PA
   BLOSTEIN SD, 1991, IEEE T SIGNAL PROCES, V39, P1611, DOI 10.1109/78.134399
   BOGAERT M, 1996, PASSWORDS PROJECT, P1112
   Bogner S., 1995, IEEE SMC Conference, V54, P3100
   BOULT T, 1998, P IEEE WORKSH COMP V
   BOULT T, 1996, MACHINE GRAPHICS VIS
   Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337
   Boult TE, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P48
   CHARLES J, 1987, BUILD US ALL SKY CAM
   Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269
   DIONSCHWARZ C, 1998, DARPA VSAM WORKSH PI
   ELGAMMAL A, 1999, FRAME RATE WORKSH EL
   FLINCHBAUGH B, 1997, 25 AIPR WORKSH EM AP
   Foresti GL, 1998, OPT ENG, V37, P2550, DOI 10.1117/1.601777
   GAO X, 2002, COMPUTER VISION ECCV
   Gao X, 2000, P IEEE C COMP VIS PA
   GAO X, 2002, P INT S MATH MORPH S
   Greiffenhagen M, 2001, P IEEE, V89, P1498, DOI 10.1109/5.959343
   Greiffenhagen M, 2000, PROC CVPR IEEE, P335, DOI 10.1109/CVPR.2000.854840
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   HALL Z, 1986, 728 SPIE OPT ILL IM, P250
   HARALICK RM, 1993, COMPUTER ROBOT VISIO, V1
   HARITAOGLU D, 1998, COMPUTER VISION ECCV
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   ISHIGURO Hiroshi., 1998, PANORAMIC VISION, P433
   KANDE T, 1998, P DARPA IUW, P3
   KARUPPIAH D, 2001, ICVS, P201
   LIPTON A, 1998, P IEEE WORKSH APPL C
   LIPTON A, 1998, COMPUTER VISION ECCV
   Marcenaro L, 2001, P IEEE, V89, P1419, DOI 10.1109/5.959339
   MICHEALS R, 2000, P INT ASS SCI TECHN
   MURRAY D, 1994, IEEE T PATTERN ANAL, V16, P449, DOI 10.1109/34.291452
   Nalwa V., 1996, A true omnidirectional viewer
   NAYAR S, 1999, IEEE C COMP VIS PATT, P217
   Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369
   NAYAR SK, 1997, P DARPA IM UND WORKS
   NAYER SK, 1997, P DARPA IM UND WORKS
   Pavlidis A, 2001, P IEEE, V89, P1478, DOI 10.1109/5.959342
   POLANA R, 1994, WORKSH MOT NONR ART, P77
   Rees D W, 1970, United States Patent, Patent No. 3505465
   RIDDLER C, 1995, ADAPTIVE BACKGROUND, P193
   ROSIN P, 1991, P BMVC, P293
   ROWE S, 1995, P BRIT MACH VIS C WE
   SEDGWICK R, 1992, ALGORITHMS C PLUS PL
   Shah S, 1996, PATTERN RECOGN, V29, P1775, DOI 10.1016/0031-3203(96)00038-6
   SMITH SM, 1995, IEEE T PATTERN ANAL, V17, P814, DOI 10.1109/34.400573
   SOGO T, 2000, PANORAMIC VISION SEN
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   SVOBODA T, 2000, P CZECH PATT REC WOR, P63
   Toyama K., 1999, Wallower: Principles and practice of background maintenance, P255, DOI 10.1109/ICCV.1999.791228
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   YAGI Y, 1990, P IONT C ROBOTS SYST
   Yamazawa K., 1993, P INT C ROBOTS SYSTE
   Zhu ZG, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P29, DOI 10.1109/OMNVIS.2000.853800
NR 60
TC 57
Z9 67
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2004
VL 22
IS 7
BP 515
EP 534
DI 10.1016/j.imavis.2003.09.005
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RT
UT WOS:000221481000002
DA 2024-07-18
ER

PT J
AU Town, C
   Sinclair, D
AF Town, C
   Sinclair, D
TI Language-based querying of image collections on the basis of an
   extensible ontology
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image retrieval; query languages; ontologies; object recognition;
   language parsing
ID RETRIEVAL; SYSTEM
AB The design of a specialised query language for content based image retrieval provides a means of addressing many of the problems associated with commonly used query paradigms such as query-by-example and query-by-sketch. By basing such a language on an extensible ontology, which encompasses both high-level and low-level image properties and relations, one can go a long way towards bridging the semantic gap between user models of saliency and relevance and those employed by a retrieval system.
   This paper discusses these issues and illustrates the design and use of an ontological retrieval language through the example of the OQUEL query language. The retrieval process takes place entirely within the ontological domain defined by the syntax and semantics of the user query. Since the system does not rely on the pre-annotation of images with sentences in the language, the format of text queries is highly flexible. The language is also extensible to allow for the definition of higher-level terms such as 'cars', 'people', etc. on the basis of existing language constructs through the use of Bayesian inference networks. The matching process utilises automatically extracted image segmentation and classification information and can incorporate any other feature extraction mechanisms or contextual knowledge available at processing time to satisfy a given user request. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Cambridge, Comp Lab, Cambridge CB3 0FD, England.
   Waimara Ltd, Cambridge, England.
C3 University of Cambridge
RP Univ Cambridge, Comp Lab, 15 JJ Thomson Ave, Cambridge CB3 0FD, England.
EM cpt23@cam.ac.uk
CR ABELLA A, 1994, ARPA94 APR, V2, P909
   AIELLO M, 1999, P INT WORKSH DESCR L
   [Anonymous], TR9904 AT T LAB CAMB
   [Anonymous], P EUR C COMP VIS
   *AT T LAB CAMBR, ICON SYST
   BECHHOFER S, 1996, P WORKSH KNOWL REPR
   BOBICK A, 1986, CLASSIFYINH OBJECTS
   Campbell NW, 1997, PATTERN RECOGN, V30, P555, DOI 10.1016/S0031-3203(96)00112-4
   CARSON C, 1997, P IEEE WORKSH CONTR
   CHANG S, 1998, P WORKSH CONT BAS VI
   CHUA TS, 1996, INT C MULT MOD
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   DOBIE M, 1999, P 2 UK C IM RETR
   EVANS A, 1993, P BRIT MACH VIS C
   Fensel D, 2000, LECT NOTES ARTIF INT, V1937, P1
   FUNG CY, 1999, P 22 ANN INT ACM SIG, P301
   GLOCKNER I, 1997, TR9705 U BIELEFELD G
   Gruber T.R., 1993, Towards Principles for the Design of Ontologies Used for Knowledge Sharing
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   HACID MS, 1999, LECT NOTES ARTIF INT, V1609, P340
   Hsu CC, 1996, IEEE T KNOWL DATA EN, V8, P522, DOI 10.1109/69.536245
   HU W, 2001, P SCI2001 5 WORLD MU
   JAIMES A, 1999, P SPIE C STOR RETR I
   JONES KS, 1999, ARTIF INTELL, V114, P257
   KATO T, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P530, DOI 10.1109/ICPR.1992.201616
   KELLY PM, 1995, P SOC PHOTO-OPT INS, V2410, P238
   Lalmas M., 1998, Applications of uncertainty formalisms, P157
   LIM J, 1999, P ACM INT C DIG LIB
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   MILLS T, 1999, SHOEBOX DIGITAL PHOT
   MOJSILOVIC A, 2002, P SPIE HUM VIS EL IM
   Müller H, 2002, LECT NOTES COMPUT SC, V2383, P38
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   NEPAL S, 1999, 6 INT C DAT SYST ADV
   NIBLACK W, 1993, RJ9203 IBM
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Parsons S., 1998, Applications of uncertainty formalisms, P8
   Petrakis EGM, 2002, IMAGE VISION COMPUT, V20, P59, DOI 10.1016/S0262-8856(01)00077-4
   RODDEN K, 1999, BCS IRSG 21 ANN C IN
   ROUSSOPOULOS N, 1988, IEEE T SOFTWARE ENG, V14, P639, DOI 10.1109/32.6141
   RUCKLIDGE W, 1995, P INT C COMP VIS
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   SHEN H, 2000, P ACM MULT, P491
   Sinclair D, 2000, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2000.855845
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SMITH J, 1997, IMAGE VIDEO SEARCH E, P84
   TIEU K, 2000, P INT C COMP VIS
   Town C.P., 2001, MV01211 SOC MAN ENG
   VASCONCELOS N, 1998, P C COMP VIS PATT RE
   WENYIN L, 2001, P INT C HUM COMP INT
   WOOD M, 1998, P ACM MULTIMEDIA, V98, P13
NR 52
TC 17
Z9 20
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2004
VL 22
IS 3
BP 251
EP 267
DI 10.1016/j.imavis.2003.10.002
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 776RH
UT WOS:000189130100008
DA 2024-07-18
ER

PT J
AU Bedi, S
   Edirisinghe, EA
   Grecos, G
AF Bedi, S
   Edirisinghe, EA
   Grecos, G
TI Improvements to the JPEG-LS prediction scheme
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE JPEG-LS; lossless image coding; predictive coding; edge detection
ID LOSSLESS IMAGE COMPRESSION; GRAY-SCALE IMAGES
AB In JPEG-LS, simple edge detection techniques are used in determining the predictive value of each pixel. These techniques only detect horizontal/vertical edges and have only been optimized for the prediction of pixels in the locality of such edges. Thus, JPEG-LS produces large prediction errors in the locality of diagonal edges. We propose a low complexity technique that accurately detects diagonal edges and efficiently predicts pixels, based on the information available within the standard predictive template of JPEG-LS. We show that the proposed technique outperforms JPEG-LS in terms of predicted mean squared error, by margins of up to 15%. (C) 2003 Elsevier B.V. All rights reserved.
C1 Loughborough Univ Technol, Dept Comp Sci, Loughborough LE11 3TU, Leics, England.
   Loughborough Univ Technol, Dept Elect & Elect Engn, Loughborough LE11 3TU, Leics, England.
C3 Loughborough University; Loughborough University
RP Loughborough Univ Technol, Dept Comp Sci, Loughborough LE11 3TU, Leics, England.
EM e.a.edirisinghe@lboro.ac.uk
CR Edirisinghe E.A., 2001, P IASTED INT C VIS I, P340
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   Grecos C, 1999, ELECTRON LETT, V35, P2019, DOI 10.1049/el:19991396
   HOWARD P, 1993, P DAT COMPR C, P351
   JIANG J, 2000, IEE P VISION IMAGE S, V147
   LANGDON GG, 1995, P SOC PHOTO-OPT INS, V2418, P21, DOI 10.1117/12.204135
   MARTUCCI SA, 1990, P IEEE INT S CIRC SY, P1310
   MEMON ND, 1995, P SOC PHOTO-OPT INS, V2418, P8, DOI 10.1117/12.204127
   NETRAVALI AN, 1980, P IEEE, V68, P366, DOI 10.1109/PROC.1980.11647
   Rice R.F., 1991, Some practical universal noiseless coding techniques, part 3, module psl14, k+
   Said A, 1996, IEEE T IMAGE PROCESS, V5, P1303, DOI 10.1109/83.535842
   TAUBMAN D, 1999, P IEEE C IM PROC ICI
   TODD S, 1985, IBM J RES DEV, V29, P188, DOI 10.1147/rd.292.0188
   Weinberger MJ, 1996, IEEE T IMAGE PROCESS, V5, P575, DOI 10.1109/83.491334
   Weinberger MJ, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P140, DOI 10.1109/DCC.1996.488319
   1997, ISOIEC97
NR 16
TC 7
Z9 10
U1 1
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2004
VL 22
IS 1
BP 9
EP 14
DI 10.1016/S0262-8856(03)00139-2
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 763BB
UT WOS:000188048400002
DA 2024-07-18
ER

PT J
AU Ng, J
   Gong, SG
AF Ng, J
   Gong, SG
TI Leaming pixel-wise signal energy for understanding semantics
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE gaussian mixture models; deviant-event; quadrature filter pair; phase
   information; CONDENSATION-based trajectory matching; abnormal event
   detection
AB Visual interpretation of events requires both an appropriate representation of change occurring in the scene and the application of semantics for differentiating between different types of change. Conventional approaches for tracking objects and modelling object dynamics make use of either temporal region-correlation or pre-learnt shape or appearance models. We propose a new pixel-level approach for learning the temporal characteristics of change at individual pixels. Gaussian mixture models are used to model slow long-term changes in pixel distributions while pixel energy histories are used to extract fast-change signatures from short-term events and modelled by CONDENSATION matching. (C) 2003 Elsevier B.V. All rights reserved.
C1 Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England.
C3 University of London; Queen Mary University London
RP Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England.
EM jeffing@dcs.qmul.ac.uk
CR Adelson Edward H, 1991, PLENOPTIC FUNCTION E
   [Anonymous], IEEE INT C COMP VISI
   Black M.J., 1998, P EUROPEAN C COMPUTE, V1, P909
   Chomat O, 2000, LECT NOTES COMPUT SC, V1842, P487
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568
   Isard M., 1996, ECCV, P343
   Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Oppenheim A. V., 1975, Digital signal processing
   Raja Y, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P228, DOI 10.1109/AFGR.1998.670953
   Usher M, 1998, NATURE, V394, P179, DOI 10.1038/28166
NR 13
TC 8
Z9 8
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1183
EP 1189
DI 10.1016/j.imavis.2003.09.001
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100013
DA 2024-07-18
ER

PT J
AU Sánchez-Cruz, H
   Bribiesca, E
AF Sánchez-Cruz, H
   Bribiesca, E
TI A method of optimum transformation of 3D objects used as a measure of
   shape dissimilarity
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object transformation; principal axes; shape-of-object dissimilarity
ID RECOGNITION
AB In this work, we present a method which transforms an object into another. The computation of this transformation is used as a measure of shape-of-object dissimilarity. The considered objects are composed of voxels. Thus, the shape difference of two objects can be ascertained by counting how many voxels we have to move and how far to change one object into another. This work is based on the method presented in [Pattern Recognition 29 (1996) 1117], and our contributions to such a work are a method of optimum transformation of objects and a proposed method of principal axes, which is used to orientate objects. The proposed method is applied to global data. Finally, we present some results using objects of the real world. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Nacl Autonoma Mexico, Dept Comp Sci, Inst Invest Matemat Aplicadas & Sistemas, Mexico City 01000, DF, Mexico.
C3 Universidad Nacional Autonoma de Mexico
EM herssan@uxmcc2.iimas.unam.mx; ernesto@leibniz.iimas.unam.mx
RI Bribiesca, Ernesto/AAH-6842-2021; Sánchez-Cruz, Hermilo/B-2235-2016
OI Bribiesca, Ernesto/0000-0001-6663-9438; Sánchez-Cruz,
   Hermilo/0000-0001-9081-6449
CR Adán A, 2001, PATTERN RECOGN, V34, P1331, DOI 10.1016/S0031-3203(00)00101-1
   Ballard D.H., 1982, Computer Vision
   BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081
   Bondy J. A., 1976, GRAPH THEORY APPL, V290
   Borisenko A. I., 1979, Vector and tensor analysis with applications
   Bracewell RN, 1978, FOURIER TRANSFORM IT
   Bribiesca E, 1996, PATTERN RECOGN, V29, P1117, DOI 10.1016/0031-3203(95)00150-6
   Bribiesca E, 1998, GRAPH MODEL IM PROC, V60, P166, DOI 10.1006/gmip.1998.0463
   Brigham E. O., 1988, FAST FOURIER TRANSFO
   Bülow H, 2000, PATTERN RECOGN LETT, V21, P329, DOI 10.1016/S0167-8655(99)00163-4
   Cohen-Or D, 1998, ACM T GRAPHIC, V17, P116, DOI 10.1145/274363.274366
   DICKINSON SJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P130, DOI 10.1016/1049-9660(92)90013-S
   GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L
   HARALICK RM, 1991, PATTERN RECOGN, V24, P69, DOI 10.1016/0031-3203(91)90117-N
   Holden M, 2000, IEEE T MED IMAGING, V19, P94, DOI 10.1109/42.836369
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102
   Karush William., 1989, Webster's New World Dictionary of Mathematics
   LIN JC, 1993, PATTERN RECOGN, V26, P485, DOI 10.1016/0031-3203(93)90104-5
   Lohmann G., 1998, VOLUMETRIC IMAGE ANA
   Mokhtarian F, 2001, IMAGE VISION COMPUT, V19, P271, DOI 10.1016/S0262-8856(00)00076-7
   WECHSLER H, 1987, ADV ELECTRON EL PHYS, V69, P261
   Wolfram S., 1991, MATH SYSTEM DOING MA
   ZHANG S, 1993, IEEE T PATTERN ANAL, V15, P778
NR 24
TC 24
Z9 29
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2003
VL 21
IS 12
BP 1027
EP 1036
DI 10.1016/S0262-8856(03)00119-7
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 737UW
UT WOS:000186251000002
DA 2024-07-18
ER

PT J
AU Gleeson, R
   Grosshans, F
   Hirsch, M
   Williams, RM
AF Gleeson, R
   Grosshans, F
   Hirsch, M
   Williams, RM
TI Algorithms for the recognition of 2D images of <i>m</i> points and
   <i>n</i> lines in 3D
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image; recognition; rank; nullspace; image equations
ID 6 LINES; INVARIANTS
AB Let alpha be an ordered collection consisting of m points and n lines, m + n greater than or equal to 6, in three-dimensional space. Let beta be an ordered collection consisting of m points and n lines, m + n greater than or equal to 6, in two-dimensional space. Using alpha and beta, we construct a matrix M(alpha, beta) and, then, give two algorithms for determining whether beta is an image of a taken with a pinhole camera. These algorithms apply to any configuration, degenerate or not, consisting of points and lines. The first algorithm depends on the calculation of the nullspace of M(alpha, beta) and gives necessary and sufficient conditions for beta to be an image of alpha, if the data can be read exactly. The second algorithm depends only on the rank of M(alpha, beta) and can be used if errors arise in reading the data; this algorithm also gives equations which any image of a must satisfy. In the special case m + n = 6, there is a single equation J(alpha,beta) = 0 which must hold if beta is an image of alpha. We show that J(alpha, beta) is simply the determinant of M(alpha,beta). We conclude with a discussion of some computational aspects of the theory. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 W Chester Univ Penn, Dept Math, W Chester, PA 19383 USA.
   Coll New Jersey, Dept Phys, Ewing, NJ 08628 USA.
   Aerosp Mass Properties Anal Corp, N Wales, PA 19454 USA.
   USN, Miss Comp & Proc Branch, Air Warfare Ctr, Aircraft Div, Patuxent River, MD 20670 USA.
C3 Pennsylvania State System of Higher Education (PASSHE); West Chester
   University of Pennsylvania; College of New Jersey; United States
   Department of Defense; United States Navy; US Navy Naval Air Systems
   Command
RP Grosshans, F (corresponding author), W Chester Univ Penn, Dept Math, W Chester, PA 19383 USA.
CR EHRENBORG R, 1993, EUR J COMBIN, V14, P157, DOI 10.1006/eujc.1993.1022
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   GROSSHANS F, IN PRESS EQUATIONS R
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Lewis RH, 1999, MATH COMPUT SIMULAT, V49, P205, DOI 10.1016/S0378-4754(99)00050-6
   Maybank SJ, 1998, IMAGE VISION COMPUT, V16, P13, DOI 10.1016/S0262-8856(97)00048-6
   QUAN L, 1995, INVARIANT METHODS IN DISCRETE AND COMPUTATIONAL GEOMETRY, P223
   SCHWARTZ JT, 1980, J ACM, V27, P701, DOI 10.1145/322217.322225
   Vazzana DR, 2001, T AM MATH SOC, V353, P2673, DOI 10.1090/S0002-9947-01-02742-8
   Watkins D., 1991, FUNDAMENTALS MATRIX
NR 10
TC 2
Z9 2
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2003
VL 21
IS 6
BP 497
EP 504
DI 10.1016/S0262-8856(03)00029-5
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 688BA
UT WOS:000183411300003
DA 2024-07-18
ER

PT J
AU Konishi, S
   Yuille, A
   Coughlan, J
AF Konishi, S
   Yuille, A
   Coughlan, J
TI A statistical approach to multi-scale edge detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE Bayesian inference; edge detection; multi-scale processing; empirical
   evaluation
ID ORDER PARAMETERS; SCALE-SPACE
AB We propose a statistical approach to combining edge cues at multiple scales using data driven probability distributions. These distributions are learnt on the Sowerby and South Florida datasets which include the ground truth positions of edges. We evaluate our results using Chernoff information and conditional entropy. Our results demonstrate the effectiveness of multi-scale processing and validate previous heuristics such as coarse-to-fine edge tracking. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Smith Kettlewell Eye Res Inst, San Francisco, CA 94115 USA.
C3 The Smith-Kettlewell Eye Research Institute
RP Yuille, A (corresponding author), Smith Kettlewell Eye Res Inst, 2318 Fillmore St, San Francisco, CA 94115 USA.
EM konishi@ski.org; yuille@ski.org; coughlan@ski.org
OI Yuille, Alan L./0000-0001-5207-9249
CR [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 1988, SIGNAL DETECTION THE
   BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7
   Coughlan J, 1998, PROC CVPR IEEE, P747, DOI 10.1109/CVPR.1998.698687
   Cover Thomas A., 1991, ELEM INF THEORY, DOI 10.1002/047174882X
   Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006
   KERSTEN D, 2001, ANN M VIS SCI SOC AR
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Konishi S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P573, DOI 10.1109/CVPR.1999.786996
   KONISHI S, 2002, THESIS U CALIFORNIA
   KONISHI SM, 2003, IN PRESS PATTERN ANA
   Marr D., 1982, Vision
   Nitzberg M., 1993, Filtering, Segmentation and Depth
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ripley BD, 1996, PATTERN RECOGNITION
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Yuille AL, 2000, IEEE T PATTERN ANAL, V22, P160, DOI 10.1109/34.825754
   Yuille AL, 2001, INT J COMPUT VISION, V41, P9, DOI 10.1023/A:1011156931605
   YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI 10.1109/TPAMI.1986.4767748
NR 21
TC 24
Z9 29
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 37
EP 48
AR PII S0262-8856(02)00131-2
DI 10.1016/S0262-8856(02)00131-2
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800005
DA 2024-07-18
ER

PT J
AU Kumar, S
   Loui, AC
   Hebert, M
AF Kumar, S
   Loui, AC
   Hebert, M
TI An observation-constrained generative approach for probabilistic
   classification of image regions
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE image region classification; generative model; semantic interpretation;
   image segmentation
AB In this paper, we propose a probabilistic region classification scheme for natural scene images. In conventional generative methods, a generative model is learnt for each class using all the available training data belonging to that class. However, if an input image has been generated from only a subset of the model support, use of the full model to assign generative probabilities can produce serious artifacts in the probability assignments. This problem arises mainly when the different classes have multimodal distributions with considerable overlap in the feature space. We propose an approach to constrain the class generative probability of a set of newly observed data by exploiting the distribution of the new data itself and using linear weighted mixing. A Kullback-Leibler Divergence-based fast model selection procedure is also proposed for learning mixture models in a low dimensional feature space. The preliminary results on the natural scene images support the effectiveness of the proposed approach. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   Eastman Kodak Co, Image Sci & Technol Lab, Rochester, NY USA.
C3 Carnegie Mellon University; Eastman Kodak
RP Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM sanjiv@andrew.cmu.edu; alexander.loui@kodak.com; hebert@ri.cmu.edu
OI Loui, Alexander/0000-0002-7427-1503
CR [Anonymous], THESIS CARNEGIE MELL
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   CAMPBELL NW, 1996, INT C ENG APPL NEUR, P339
   CARSON C, 1997, CVPR 97 WORKSH CONT
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FARLEY C, 1998, 329 U WASH DEP STAT
   HANSEN MH, 1998, JASA 96, P746
   HECKERMAN D, 1996, MSRTR9612
   Konishi S, 2000, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.2000.855809
   KUMAR S, 2002, ECCV WORKSH GEN MOD, P91
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   RICKERT T, 1999, P IEEE INT C COMP VI, P1046
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181
   STORRING M., 1999, P 7 S INTELLIGENT RO, P187
   Strat T.M., 1992, Natural Object Recognition
   Tanner MA, 1996, Tools for Statistical Inference: Methods for the Exploration of Posterior Distributions and Likelihood Functions, V3rd
   TORRALBA A, 2001, P INT C COMP VIS ICC
   VAILAYA A, 2000, THESIS MICHIGAN STAT
NR 21
TC 14
Z9 17
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 87
EP 97
AR PII S0262-8856(02)00125-7
DI 10.1016/S0262-8856(02)00125-7
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800010
DA 2024-07-18
ER

PT J
AU Zhao, JQ
   Wang, HZ
   Zhou, Y
   Yao, R
   Zhang, LX
   El Saddik, A
AF Zhao, Jiaqi
   Wang, Hanzheng
   Zhou, Yong
   Yao, Rui
   Zhang, Lixu
   El Saddik, Abdulmotaleb
TI Context-aware and part alignment for visible-infrared person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross -modality person re -identification; Attention mechanism; Image
   retrieval; Part -based model
AB Visible-infrared person re-identification (VI-ReID) is a challenging problem of matching a person from visible and infrared modalities. Existing researches adopt the last convolutional layer features of the off-the-shelf backbone network as the representation to refine, which is unable to represent the heterogeneous cross-modality features with discriminant information. In this paper, we propose a novel graph-based aggregation learning network (GALNet) with visual Transformer embedding to mine both multi-layer features and part-level contextual cues for VI-ReID. We propose a novel feature memory module (FMM) to reserve global discriminative features of the low layers with the correlation modeling ability of the graph convolution network (GCN) which is supplemented to the final person representation. To learn more discriminant part-level features, an attentive part aggregation module (PAM) is designed to mine part relationships, leveraging the self-attention mechanism of the Transformer. By fusing these components, the global-level, and part-level discriminant information can be utilized. Extensive experiments on SYSU-MM01 and RegDB benchmarks demonstrate the effectiveness of our proposed methods compared with several state-of-the-art methods.
C1 [Zhao, Jiaqi; Wang, Hanzheng; Zhou, Yong; Yao, Rui] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
   [Zhao, Jiaqi; Wang, Hanzheng; Zhou, Yong; Yao, Rui] Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Peoples R China.
   [Zhao, Jiaqi] Disaster Intelligent Prevent & Control & Emergency, Xuzhou 221116, Peoples R China.
   [Zhang, Lixu] Jiangsu Junsheng Wanbang Holding Grp Co Ltd, Xuzhou 221116, Peoples R China.
   [El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
C3 China University of Mining & Technology; University of Ottawa
RP Zhou, Y (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
EM yzhou@cumt.edu.cn
FU National Natural Science Foundation of China [62272461, 62172417];
   Natural Science Foundation of Jiangsu Province [BK20201346]; "Double
   FirstClass" Project of China University of Mining and Technology for
   Independent Innovation and Social Service [2022ZZCX06]; Six Talent Peaks
   Project in Jiangsu Province [2015-DZXX-010, 2018-XYDXX-044]
FX This work was supported by the National Natural Science Foundation of
   China (No.62272461, 62172417), and the Natural Science Foundation of
   Jiangsu Province (No. BK20201346), the "Double FirstClass" Project of
   China University of Mining and Technology for Independent Innovation and
   Social Service under Grant 2022ZZCX06, and the Six Talent Peaks Project
   in Jiangsu Province (No. 2015-DZXX-010, 2018-XYDXX-044).
CR Aggarwal A.K., 2023, Int. J. Biol. Biomed, V7
   Bao LQ, 2019, IEEE COMPUT SOC CONF, P1496, DOI 10.1109/CVPRW.2019.00191
   Cai X, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2021.106772
   Chen A, 2022, BIOCYBERN BIOMED ENG, V42, P204, DOI 10.1016/j.bbe.2021.12.010
   Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402
   Cheng Y., 2021, 2021 IEEE INT S CIRC, P1
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A., 2023, An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Guo M, 2023, NAT PROD RES, V37, P1411, DOI 10.1080/14786419.2021.2011271
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hu WP, 2022, IEEE T CIRC SYST VID, V32, P5095, DOI 10.1109/TCSVT.2022.3147813
   Huang H., 2018, arXiv
   Kipf T.N., 2017, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Kniaz VV, 2019, LECT NOTES COMPUT SC, V11134, P606, DOI 10.1007/978-3-030-11024-6_46
   Kulwa F, 2022, ENVIRON SCI POLLUT R, V29, P51909, DOI 10.1007/s11356-022-18849-0
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu HJ, 2021, IEEE T MULTIMEDIA, V23, P4414, DOI 10.1109/TMM.2020.3042080
   Liu MJ, 2022, MULTIMED TOOLS APPL, V81, P21939, DOI 10.1007/s11042-022-12510-1
   Nguyen BX, 2021, IEEE COMPUT SOC CONF, P3487, DOI 10.1109/CVPRW53098.2021.00388
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Parmar N, 2018, PR MACH LEARN RES, V80
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Shen F, 2023, IEEE T IMAGE PROCESS, V32, P1039, DOI 10.1109/TIP.2023.3238642
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun J, 2021, NEUROCOMPUTING, V440, P1, DOI 10.1016/j.neucom.2021.01.073
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   Xiang XZ, 2019, IEEE SENS J, V19, P11706, DOI 10.1109/JSEN.2019.2936916
   Xu WJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9961, DOI 10.1109/ICCV48922.2021.00983
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yang JR, 2020, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR42600.2020.00335
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2021, IEEE T INF FOREN SEC, V16, P728, DOI 10.1109/TIFS.2020.3001665
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Yuan K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P559, DOI 10.1109/ICCV48922.2021.00062
   Yuan Y, 2020, IEEE COMPUT SOC CONF, P1454, DOI 10.1109/CVPRW50498.2020.00185
   Zhu YX, 2020, NEUROCOMPUTING, V386, P97, DOI 10.1016/j.neucom.2019.12.100
   Zhang JH, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107885
   Zhang L, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3473341
   Zhang LY, 2021, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3085978
   Zhang P, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104118
   Zhang Q, 2021, IEEE T IMAGE PROCESS, V30, P8019, DOI 10.1109/TIP.2021.3112035
   Zhang SZ, 2021, IEEE T IMAGE PROCESS, V30, P8861, DOI 10.1109/TIP.2021.3120881
   Zhang Z, 2021, PROC CVPR IEEE, P12131, DOI 10.1109/CVPR46437.2021.01196
   Zhao H., 2020, P IEEE CVF C COMP VI, V2020, P10076, DOI 10.1109/CVPR42600.2020.01009
   Zhao YB, 2019, IET IMAGE PROCESS, V13, P2897, DOI 10.1049/iet-ipr.2019.0699
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zhong X, 2022, IEEE T CIRC SYST VID, V32, P1418, DOI 10.1109/TCSVT.2021.3072171
   Zhou DQ, 2021, Arxiv, DOI [arXiv:2103.11886, 10.48550/arXiv.2103.11886, DOI 10.48550/ARXIV.2103.11886]
NR 63
TC 1
Z9 1
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104791
DI 10.1016/j.imavis.2023.104791
EA AUG 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA R2IG2
UT WOS:001062626600001
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Shu, QY
   Shi, X
   Zhan, J
AF Zhao, Yu
   Shu, Qiaoyuan
   Shi, Xi
   Zhan, Jian
TI Unsupervised person re-identification by dynamic hybrid contrastive
   learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised person re -identification; Contrastive learning;
   Intra-category similarity; Inter -instance discrimination
ID NETWORK; GAN
AB Unsupervised person re-identification (re-ID) aims at cross-camera pedestrian retrieval without manual annotation. Recently, the contrastive learning has been introduced into the field of unsupervised person re-ID. However, existing methods usually focus only on mining the intra-category similarity and neglect the negative effects of clustering noise, which limits the performance in unsupervised person re-ID. In this paper, we propose a Dynamic Hybrid Contrastive Learning (DHCL) method for unsupervised person re-ID. Specifically, we perform the clustering algorithm and the dynamic refinement policy to divide the unlabeled training dataset into two subsets, i.e., clustered samples with pseudo labels and un-clustered independent instances, at each training epoch. Then, the proposed DHCL guides the feature extraction network to mine the intra-category similarity from the clustered samples by applying attraction within samples of the same cluster. Meanwhile, the inter-instance discrimination is also mined by pushing away different instances. Besides, we integrate the two levels of contrastive learning into an end-to-end framework and exploit the complementarity between them to improve the separability of the feature space. To reduce the negative effect of over-focusing on positive samples, a penalty item is added to the hybrid contrastive loss. Extensive experiments demonstrate the effectiveness of the proposed method in unsupervised person re-ID.
C1 [Zhao, Yu; Shi, Xi] Chongqing Univ Educ, Sch Artificial Intelligence, Chongqing 400065, Peoples R China.
   [Shu, Qiaoyuan; Zhan, Jian] Chongqing Univ Educ, Sch Math & Big Data, Chongqing 400065, Peoples R China.
C3 Chongqing University of Education; Chongqing University of Education
RP Zhao, Y (corresponding author), Chongqing Univ Educ, Sch Artificial Intelligence, Chongqing 400065, Peoples R China.
EM zhaoyu@cque.edu.cn
FU Natural Science Foundation Project of Chongqing, Chongqing Science and
   Technology Commission [cstc2020jcyj-msxmX0023]; Science and Technology
   Research Program of Chongqing Municipal Education Commission
   [KJQN202101612]; Scientific Research Project of Chongqing University of
   Education [KY202115C]
FX This work was supported by the Natural Science Foundation Project of
   Chongqing, Chongqing Science and Technology Commission (Grant No.
   cstc2020jcyj-msxmX0023) , the Science and Technology Research Program of
   Chongqing Municipal Education Commission (Grant No. KJQN202101612) , and
   the Scientific Research Project of Chongqing University of Education
   (Grant No. KY202115C) .
CR Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Chen H., 2022, IEEE T PATTERN ANAL, V45, P7494
   Chen H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14940, DOI 10.1109/ICCV48922.2021.01469
   Chen H, 2021, PROC CVPR IEEE, P2004, DOI 10.1109/CVPR46437.2021.00204
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Cho Y, 2022, PROC CVPR IEEE, P7298, DOI 10.1109/CVPR52688.2022.00716
   Dai CQ, 2020, MULTIMED TOOLS APPL, V79, P12597, DOI 10.1007/s11042-019-08604-y
   Dai Z., 2022, P ASIAN C COMPUTER V, P1142
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Ge Y., 2020, P NIPS, V33, P11309
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ji HXY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3641, DOI 10.1109/ICCV48922.2021.00364
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kaiwei Zeng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13654, DOI 10.1109/CVPR42600.2020.01367
   Li MK, 2022, IEEE T IMAGE PROCESS, V31, P3606, DOI 10.1109/TIP.2022.3173163
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Li YF, 2021, AAAI CONF ARTIF INTE, V35, P8547
   Liao SC, 2022, PROC CVPR IEEE, P7349, DOI 10.1109/CVPR52688.2022.00721
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Lin YT, 2020, IEEE T IMAGE PROCESS, V29, P5481, DOI 10.1109/TIP.2020.2982826
   Liu WF, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107658
   Liu XK, 2020, IEEE T CIRC SYST VID, V30, P3446, DOI 10.1109/TCSVT.2019.2957539
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Ming ZQ, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104394
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Ni H., 2022, P IEEECVF C COMPUTER, P2487
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Qian XL, 2020, IEEE T PATTERN ANAL, V42, P371, DOI 10.1109/TPAMI.2019.2928294
   Raj S, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108287
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shengcai Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P456, DOI 10.1007/978-3-030-58621-8_27
   Si TZ, 2023, IEEE T MULTIMEDIA, V25, P4323, DOI 10.1109/TMM.2022.3174414
   Si TZ, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108462
   Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081
   Sun J, 2021, IEEE T IMAGE PROCESS, V30, P2935, DOI 10.1109/TIP.2021.3056889
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang XD, 2021, PROC CVPR IEEE, P12581, DOI 10.1109/CVPR46437.2021.01240
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu GL, 2020, AAAI CONF ARTIF INTE, V34, P12362
   Wu JL, 2019, IEEE INT CON MULTI, P886, DOI 10.1109/ICME.2019.00157
   Wu YK, 2023, PSYCHOL MED, DOI [10.1145/3609703.3609704, 10.1017/S0033291723002453, 10.1109/TBIOM.2022.3184525, 10.1109/ICASSP49357.2023.10095969]
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xie JH, 2022, INT J COMPUT VISION, V130, P2994, DOI 10.1007/s11263-022-01681-x
   Xie QK, 2021, IEEE T MULTIMEDIA, V23, P597, DOI 10.1109/TMM.2020.2985525
   Xuan SY, 2021, PROC CVPR IEEE, P11921, DOI 10.1109/CVPR46437.2021.01175
   Yang F, 2021, IEEE T MULTIMEDIA, V23, P1681, DOI 10.1109/TMM.2020.3001522
   Yang FX, 2020, AAAI CONF ARTIF INTE, V34, P12597
   Ye M, 2019, PROC CVPR IEEE, P6203, DOI 10.1109/CVPR.2019.00637
   Yin J., 2023, IEEE T IMAGE PROCESS, V32
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Zeng KW, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103913
   Zhang H, 2021, IEEE T IMAGE PROCESS, V30, P5287, DOI 10.1109/TIP.2021.3082298
   Zhang X, 2021, PROC CVPR IEEE, P3435, DOI 10.1109/CVPR46437.2021.00344
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8351, DOI 10.1109/ICCV48922.2021.00826
   Zheng Y, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3501404
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhu J, 2021, IEEE T MULTIMEDIA, V23, P2614, DOI 10.1109/TMM.2020.3013531
   Zilong Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P20, DOI 10.1007/978-3-030-58604-1_2
NR 75
TC 1
Z9 1
U1 6
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104786
DI 10.1016/j.imavis.2023.104786
EA JUL 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P5IX9
UT WOS:001051023400001
DA 2024-07-18
ER

PT J
AU Xu, Q
   Zhang, MQ
   Li, Y
   Tao, ZF
AF Xu, Qin
   Zhang, Mengquan
   Li, Yun
   Tao, Zhifu
TI Learning more discriminative clues with gradual attention for
   fine-grained visual categorization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fine-grained visual categorization; Convolutional neural network; Visual
   attention; Self -calibrated convolution
ID IMAGE CLASSIFICATION; NETWORK; MODEL; CNN
AB Fine-grained visual categorization, which aims to identify the different subcategories of images within the same category, is a very challenging task due to the large intra-class differences and subtle inter-class variances. The existing methods mostly focus on the salient local regions and ignore other features which probably help to recognize the images more precisely. To address this issue, in this paper, we propose a novel end-to-end network composed of the self-calibrated convolution, gradual attention module and feature inverse module for fine-grained visual categorization. To extract the salient features, the self-calibrated convolution is exploited which can avoid the influence of irrelevant information and locate salient regions more accurately. In aiming to extract the discriminative features, we propose the gradual attention module which consists of alternate channel-spatial attention and hierarchical feature grouping. The gradual attention module can extract the subtle discriminative features gradually even when the semantic information of shallow stages is not rich. Moreover, we design the feature inverse module which forces the next stage of network to search for other different useful features by feature inverse. The gradual attention module combined with the feature inverse module is capable of finding more detailed regions and of benefit to improving classification performance. Finally, the stage features and fused features are jointly used for classification. The proposed method is evaluated on three classical fine-grained image datasets and compared with a number of state-of-the-art methods. Our method achieves 89.5%, 95.2% and 93.9% accuracies on CUB-200-2011, Stanford Cars and FGVC-Aircraft datasets respectively. The experimental results demonstrate the effectiveness and superiority of the proposed method.
C1 [Xu, Qin; Zhang, Mengquan; Li, Yun] Anhui Univ, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei 230601, Peoples R China.
   [Xu, Qin; Zhang, Mengquan; Li, Yun] Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Peoples R China.
   [Tao, Zhifu] Anhui Univ, Sch Big Data & Stat, Hefei 230601, Peoples R China.
C3 Anhui University; Anhui University; Anhui University
RP Xu, Q (corresponding author), Anhui Univ, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei 230601, Peoples R China.
EM xuqin@ahu.edu.cn; zhangmengquan0216@163.com; 2624476171@qq.com;
   jeff.tao@ahu.edu.cn
FU National Natural Science Foundation of China [72071001]; Natural Science
   Foundation of Anhui Province [2008085MG226, 2008085QG334]; Natural
   Science Foundation for the Higher Education Institutions of Anhui
   Province [KJ2021A0038]
FX The authors would like to thank the anonymous referees for their
   constructive comments which have helped improve the paper. The research
   is supported by the National Natural Science Foundation of China (Nos.
   72071001) , Natural Science Foundation of Anhui Province (Nos.
   2008085MG226, 2008085QG334) , Natural Science Foundation for the Higher
   Education Institutions of Anhui Province (No. KJ2021A0038) .
CR Bargal SA, 2021, IEEE T PATTERN ANAL, V43, P4196, DOI [10.1109/TPAMI.2021.3054303, 10.1109/TPAMI.2020.3054303]
   Cai SJ, 2017, IEEE I CONF COMP VIS, P511, DOI 10.1109/ICCV.2017.63
   Chen JM, 2021, COMPUT VIS IMAGE UND, V206, DOI 10.1016/j.cviu.2021.103184
   Chen JP, 2022, NEUROCOMPUTING, V501, P359, DOI 10.1016/j.neucom.2022.06.041
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding Y, 2022, IEEE T CIRC SYST VID, V32, P1353, DOI 10.1109/TCSVT.2021.3069835
   Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670
   Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Fukui H, 2019, PROC CVPR IEEE, P10697, DOI 10.1109/CVPR.2019.01096
   Gao Y, 2020, AAAI CONF ARTIF INTE, V34, P10818
   Gao Z, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377876
   Gao Z, 2020, NEURAL NETWORKS, V125, P290, DOI 10.1016/j.neunet.2020.02.017
   Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315
   Guo JQ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10232987
   Hanselmann H, 2020, IEEE WINT CONF APPL, P1236, DOI [10.1109/WACV45572.2020.9093601, 10.1109/wacv45572.2020.9093601]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He MQ, 2022, IEEE ACCESS, V10, P35814, DOI 10.1109/ACCESS.2022.3163302
   He XT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P741
   He XT, 2019, IEEE T CIRC SYST VID, V29, P1394, DOI 10.1109/TCSVT.2018.2834480
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YT, 2021, IEEE T CIRC SYST VID, V31, P301, DOI 10.1109/TCSVT.2020.2978115
   Huang HX, 2022, IEEE T CIRC SYST VID, V32, P853, DOI 10.1109/TCSVT.2021.3065693
   Huang R, ARXIV
   Huang SL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P600, DOI 10.1109/ICCV48922.2021.00066
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Ioannou Y, 2017, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2017.633
   Jiang-Jiang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10093, DOI 10.1109/CVPR42600.2020.01011
   Karri M, 2022, COMPUT BIOL MED, V151, DOI 10.1016/j.compbiomed.2022.106231
   Ke X, 2022, COMPUT VIS IMAGE UND, V218, DOI 10.1016/j.cviu.2022.103408
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lai DY, 2019, PATTERN RECOGN, V88, P547, DOI 10.1016/j.patcog.2018.12.002
   Laishram A, 2022, INT J INTERACT MULTI, V7, P69, DOI 10.9781/ijimai.2021.10.009
   Li PH, 2018, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2018.00105
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu CX, 2021, IEEE T CIRC SYST VID, V31, P2480, DOI 10.1109/TCSVT.2020.3020079
   Liu CB, 2020, AAAI CONF ARTIF INTE, V34, P11555
   Liu X, 2017, AAAI CONF ARTIF INTE, P4190
   Luo W, 2019, IEEE I CONF COMP VIS, P8241, DOI 10.1109/ICCV.2019.00833
   Ma NN, 2021, PROC CVPR IEEE, P8028, DOI 10.1109/CVPR46437.2021.00794
   Maji S, 2013, Arxiv, DOI arXiv:1306.5151
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Raitoharju J, 2018, IMAGE VISION COMPUT, V78, P73, DOI 10.1016/j.imavis.2018.06.005
   Ruyi Ji, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10465, DOI 10.1109/CVPR42600.2020.01048
   Shu XB, 2018, IEEE T CIRC SYST VID, V28, P454, DOI 10.1109/TCSVT.2016.2607345
   Song JW, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534004
   Sun GL, 2020, AAAI CONF ARTIF INTE, V34, P12047
   Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49
   Sun T, 2017, IMAGE VISION COMPUT, V64, P47, DOI 10.1016/j.imavis.2017.06.003
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Ukwuoma C.C., 2023, INT J INTERACT MULTI, P1
   Wah C., CALTECH UCSD BIRDS20
   Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang QL, 2017, PROC CVPR IEEE, P6507, DOI 10.1109/CVPR.2017.689
   Wang WY, 2020, NEURAL COMPUT APPL, V32, P14613, DOI 10.1007/s00521-020-05148-3
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131
   Wang ZH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1851, DOI 10.1145/3343031.3350976
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xin DJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051681
   Xu S., 2021, 2021 IEEE 31 INT WOR, P1
   Yan TT, 2022, IEEE T CIRC SYST VID, V32, P5319, DOI 10.1109/TCSVT.2022.3144186
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Yao HT, 2017, IMAGE VISION COMPUT, V63, P24, DOI 10.1016/j.imavis.2017.05.003
   Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35
   Zhang H, 2018, AAAI CONF ARTIF INTE, P7542
   Zhang LB, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108219
   Zhang LB, 2019, IEEE I CONF COMP VIS, P8330, DOI 10.1109/ICCV.2019.00842
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang QL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2235, DOI 10.1109/ICASSP39728.2021.9414568
   Zhang T, 2021, IEEE I C VI COM I PR, DOI 10.1109/VCIP53242.2021.9675376
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zhao PP, 2023, NEUROCOMPUTING, V518, P533, DOI 10.1016/j.neucom.2022.10.004
   Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515
   Zheng HL, 2020, IEEE T IMAGE PROCESS, V29, P476, DOI 10.1109/TIP.2019.2921876
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhihui Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9746, DOI 10.1109/CVPR42600.2020.00977
   Zhou MH, 2020, PROC CVPR IEEE, P11771, DOI 10.1109/CVPR42600.2020.01179
   Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130
NR 87
TC 0
Z9 0
U1 4
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104753
DI 10.1016/j.imavis.2023.104753
EA JUL 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N0BN2
UT WOS:001033775200001
DA 2024-07-18
ER

PT J
AU Fu, ZX
   Chen, XY
   Liu, DZ
   Qu, XY
   Dong, JF
   Zhang, XH
   Ji, SL
AF Fu, Zhixiao
   Chen, Xinyuan
   Liu, Daizong
   Qu, Xiaoye
   Dong, Jianfeng
   Zhang, Xuhong
   Ji, Shouling
TI Multi-level feature disentanglement network for cross-dataset face
   forgery detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face forgery detection; Cross-dataset evaluation; Multi -level
   representation; Feature disentangling; Adversarial learning
AB Synthesizing videos with forged faces is a fundamental yet important safety-critical task that has caused severe security issues in recent years. Although many existing face forgery detection methods have achieved superior performance on such synthetic videos, they are severely limited by the domain-specific training data and gener-ally perform unsatisfied when transferred to the cross-dataset scenario due to the domain gaps. Based on this ob-servation, in this paper, we propose a multi-level feature disentanglement network to be robust to this domain bias induced by the different types of fake artifacts in different datasets. Specifically, we first detect the face image and transform it into both color-aware and frequency-aware inputs for multi-modal contextual represen-tation learning. Then, we introduce a novel feature disentangling module that mainly utilizes a pair of comple-mentary attention maps, to disentangle the synthetic features into separate realistic features and the features of fake artifacts. Since the features of fake artifacts are indirectly obtained from the latent features instead of the dataset-specific distribution, our forgery detection model is robust to the dataset-specific domain gaps. By ap-plying the disentangling module to multi-levels of the feature extraction network with multi-modal inputs, we can obtain more robust feature representations. In addition, a realistic-aware adversary loss and a domain -aware adversary loss are adopted to facilitate the network for better feature disentanglement and extraction. Ex-tensive experiments on four datasets verify the generalization of our method and present the state-of-the-art performance.(c) 2023 Published by Elsevier B.V.
C1 [Fu, Zhixiao; Zhang, Xuhong; Ji, Shouling] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Xinyuan] Shanghai Artificial Intelligence Lab, Shanghai, Peoples R China.
   [Liu, Daizong] Peking Univ, Beijing, Peoples R China.
   [Qu, Xiaoye] Huawei Technol Ltd, Shenzhen, Peoples R China.
   [Dong, Jianfeng] Zhejiang Gongshang Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Peking University; Huawei Technologies; Zhejiang
   Gongshang University
RP Dong, JF (corresponding author), Zhejiang Gongshang Univ, Hangzhou, Zhejiang, Peoples R China.
EM dongjf24@gmail.com
FU NSFC [62102360]; Public Welfare Technology Research Project of Zhejiang
   Province [LGF21F020010]; Open Project of Key Laboratory of Public
   Security Information Application Based on Big -Data Architecture,
   Ministry of Public Security [2021DSJSYS001]; Fundamental Research Funds
   for the Provincial Universities of Zhejiang
FX This work was partly supported by the NSFC (No. 62102360) , the Public
   Welfare Technology Research Project of Zhejiang Province (No.
   LGF21F020010) , the Open Project of Key Laboratory of Public Security
   Information Application Based on Big -Data Architecture, Ministry of
   Public Security (No. 2021DSJSYS001) , and the Fundamental Research Funds
   for the Provincial Universities of Zhejiang.
CR Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dang H., P IEEE CVF C COMP VI, P5781
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Dong J., 2012, IEEE T IMAGE PROCESS, V30, P8410
   Dong JF, 2022, IEEE T PATTERN ANAL, V44, P4065, DOI 10.1109/TPAMI.2021.3059295
   Dong JF, 2021, NEUROCOMPUTING, V440, P207, DOI 10.1016/j.neucom.2021.01.114
   Dong Jianfeng, 2022, arXiv
   Frank Joel, 2020, INT C MACH LEARN, P3247
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fu ZX, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1685, DOI 10.1109/ICASSP39728.2021.9414436
   Gao GG, 2021, PROC CVPR IEEE, P3403, DOI 10.1109/CVPR46437.2021.00341
   github, FACESWAP
   github, DEEPFAKES
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   googleblog, DEEPFAKEDETECTION
   Gu ZH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3473, DOI 10.1145/3474085.3475508
   Jiang L., P IEEE CVF C COMP VI, P2889
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Khalid H, 2020, IEEE COMPUT SOC CONF, P2794, DOI 10.1109/CVPRW50498.2020.00336
   Kim H, 2018, PR MACH LEARN RES, V80
   Kingma D. P., 2014, arXiv
   Li D, 2018, AAAI CONF ARTIF INTE, P3490
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Liu DZ, 2022, AAAI CONF ARTIF INTE, P1683
   Liu HG, 2021, PROC CVPR IEEE, P772, DOI 10.1109/CVPR46437.2021.00083
   Luo YC, 2021, PROC CVPR IEEE, P16312, DOI 10.1109/CVPR46437.2021.01605
   Natsume R., ACM SIGGRAPH 2018 PO, P1
   Natsume R, 2019, LECT NOTES COMPUT SC, V11366, P117, DOI 10.1007/978-3-030-20876-9_8
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pan X., 2012, 2012 IEEE INT C COMP, P1
   Park S, 2021, AAAI CONF ARTIF INTE, V35, P2403
   Qi H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4318, DOI 10.1145/3394171.3413707
   Qu X, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2496
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sun K, 2022, AAAI CONF ARTIF INTE, P2316
   Sun ZK, 2021, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR46437.2021.00361
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Wang H., P IEEE CVF C COMP VI, P3527
   Wu X, 2019, AAAI CONF ARTIF INTE, P9005
   Yang X, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1, DOI 10.1145/3404835.3462823
   Yang X, 2022, IEEE T IMAGE PROCESS, V31, P1204, DOI 10.1109/TIP.2022.3140611
   Yang X, 2018, IEEE T IMAGE PROCESS, V27, P791, DOI 10.1109/TIP.2017.2765836
   Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830
   Yuezun Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P3204, DOI 10.1109/CVPR42600.2020.00327
   Yuyang Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P86, DOI 10.1007/978-3-030-58610-2_6
   Zhai ZH, 2021, AAAI CONF ARTIF INTE, V35, P3278
   Zhao HQ, 2021, PROC CVPR IEEE, P2185, DOI 10.1109/CVPR46437.2021.00222
   Zheng YT, 2021, PROC CVPR IEEE, P3916, DOI 10.1109/CVPR46437.2021.00391
   Zhu H., 2020, P ADV NEURAL INF PRO, V33, P21699
   Zou ZK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2185, DOI 10.1145/3474085.3475377
NR 54
TC 1
Z9 1
U1 4
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104686
DI 10.1016/j.imavis.2023.104686
EA MAY 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA I7HN2
UT WOS:001004460500001
DA 2024-07-18
ER

PT J
AU Li, ZX
   Wei, JH
   Huang, FC
   Ma, HF
AF Li, Zhixin
   Wei, Jiahui
   Huang, Feicheng
   Ma, Huifang
TI Modeling graph-structured contexts for image captioning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image captioning; Transformer; Scene graph; Reinforcement learning;
   Attention mechanism
ID ATTENTION
AB The performance of image captioning has been significantly improved recently through deep neural network ar-chitectures combining with attention mechanisms and reinforcement learning optimization. Exploring visual re-lationships and interactions between different objects appearing in the image, however, is far from being investigated. In this paper, we present a novel approach that combines scene graphs with Transformer, which we call SGT, to explicitly encode available visual relationships between detected objects. Specifically, we pretrain an scene graph generation model to predict graph representations for images. After that, for each graph node, a Graph Convolutional Network (GCN) is employed to acquire relationship knowledge by aggregating the informa-tion of its local neighbors. As we train the captioning model, we feed the potential relation-aware information into the Transformer to generate descriptive sentence. Experiments on the MSCOCO dataset and the Flickr30k dataset validate the superiority of our SGT model, which can realize state-of-the-art results in terms of all the standard evaluation metrics.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Li, Zhixin; Wei, Jiahui; Huang, Feicheng] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Ma, Huifang] Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Peoples R China.
C3 Guangxi Normal University; Northwest Normal University - China
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM lizx@gxnu.edu.cn
RI Ma, Huifang/JTV-4982-2023; Li, Zhixin/ABI-9264-2022
OI Ma, Huifang/0000-0002-5104-8982; Li, Zhixin/0000-0002-5313-6134
FU National Natural Science Foundation of China [62276073, 61966004];
   Guangxi Natural Science Foundation [2019GXNSFDA245018]; Guangxi "Bagui
   Scholar" Teams for Innovation and Research Project; Guangxi
   Collaborative Innovation Center of Multi-source Information Integration
   and Intelligent Processing
FX This work is supported by National Natural Science Foundation of China
   (Nos. 62276073, 61966004), Guangxi Natural Science Foundation (No.
   2019GXNSFDA245018), Guangxi "Bagui Scholar" Teams for Innovation and
   Research Project, and Guangxi Collaborative Innovation Center of
   Multi-source Information Integration and Intelligent Processing.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Bengio S, 2015, ADV NEUR IN, V28
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Dai B, 2017, IEEE I CONF COMP VIS, P2989, DOI 10.1109/ICCV.2017.323
   Fu K, 2017, IEEE T PATTERN ANAL, V39, P2321, DOI 10.1109/TPAMI.2016.2642953
   Gao LL, 2019, AAAI CONF ARTIF INTE, P8320
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herdade S, 2020, Arxiv, DOI arXiv:1906.05963
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Hu JC, 2024, Arxiv, DOI [arXiv:2208.06551, DOI 10.48550/ARXIV.2208.06551]
   Huang FC, 2020, MACH LEARN, V109, P2313, DOI 10.1007/s10994-020-05919-y
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Ji JY, 2021, AAAI CONF ARTIF INTE, V35, P1655
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li LH, 2017, AAAI CONF ARTIF INTE, P4133
   Li X., 2020, P EUR C COMP VIS, DOI DOI 10.1007/978-3-030-58577-8_8
   Liang XD, 2017, PROC CVPR IEEE, P4408, DOI 10.1109/CVPR.2017.469
   Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo YP, 2021, Arxiv, DOI arXiv:2101.06462
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Nie WZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4510, DOI 10.1145/3474085.3475604
   Papineni K., 2002, P ACL, P311
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Ranzato M, 2016, Arxiv, DOI [arXiv:1511.06732, 10.48550/arXiv.1511.06732]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O., 2014, ARXIV14114555
   Wang WX, 2019, AAAI CONF ARTIF INTE, P8957
   Wang XM, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P312, DOI 10.1145/3460426.3463637
   Wang Y., 2022, arXiv
   Wei HY, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3439734
   Wei J, 2022, APPL INTELL, P1
   Xian TT, 2022, IEEE T CIRC SYST VID, V32, P5762, DOI 10.1109/TCSVT.2022.3155795
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Yu LT, 2022, IEEE T MULTIMEDIA, V24, P1775, DOI 10.1109/TMM.2021.3072479
   Yu RC, 2017, IEEE I CONF COMP VIS, P1068, DOI 10.1109/ICCV.2017.121
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
NR 60
TC 8
Z9 8
U1 3
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104591
DI 10.1016/j.imavis.2022.104591
EA DEC 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7S6FQ
UT WOS:000910848000002
DA 2024-07-18
ER

PT J
AU Zheng, TY
   Wang, Q
   Shen, Y
   Ma, X
   Lin, XT
AF Zheng, Tianyou
   Wang, Qiang
   Shen, Yue
   Ma, Xiang
   Lin, Xiaotian
TI Batch covariance neural network for image recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CNN; BCovNN; Batch covariance; Illumination intensity; Feature
   interaction
AB Recent work has shown that convolutional neural networks (CNN) can achieve state of the art if the datasets are well built. However, the existing convolutional layer is affected by various datasets with the inevitable problems of local abnormal features, i.e., illumination intensity and feature interaction. This paper replaces the convolutional layer with a batch covariance layer (BCL) to locate the category-related region unaffected by the problems. The BCL is regarded as a 3D covariance operation, which calculates the correlation between the kernels and feature maps in kernel size of all channels. Forward propagation, backward propagation, gradient updating, and testing procedure of the BCL are described. The comparison between BCL and convolutional layer shows the ability of BCL to reduce the influence of illumination intensity and feature interaction for discriminating and generating tasks. Complexity analysis shows that BCL can improve the accuracy with a thimbleful time consumption increase. Besides, the batch covariance neural network (BCovNN) is extended from the CNN by replacing the convolutional layer with BCL. Ablation experiment verifies the improvement of BCovNN is provided by BCL separately. BCovNN is evaluated on several popular datasets (i.e., MNIST, STL-10, CIFAR-10, and ImageNet) for image recognition and PASCAL VOC (2007 and 2012) datasets for object localization. Experimental results reveal that BCovNN achieves significant improvements over the corresponding CNN. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Zheng, Tianyou; Wang, Qiang; Shen, Yue; Ma, Xiang; Lin, Xiaotian] Harbin Inst Technol, Dept Control Sci & Engn, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Zheng, TY; Wang, Q (corresponding author), Harbin Inst Technol, Dept Control Sci & Engn, Harbin, Heilongjiang, Peoples R China.
EM drenego@hit.edu.cn; wangqiang@hit.edu.cn; yueshen@hit.edu.cn;
   xiaotian.lin@hit.edu.cn
RI Wang, Qiang/B-1053-2012
OI Wang, Qiang/0000-0002-9654-0268; Zheng, Tianyou/0000-0002-2310-2988
FU National Natural Science Foundation of China [61876054, 61973098]
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant No.61876054, No.61973098).
CR Abu Mallouh A, 2019, IMAGE VISION COMPUT, V88, P41, DOI 10.1016/j.imavis.2019.05.001
   Agustsson Eirikur, 2017, INT C COMPUTER VISIO
   [Anonymous], INT C MACH LEARN
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Choi H.S, 2019, IMAGE VISION COMPUT, V91
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Huang G., EUROPEAN C COMPUTER, P646
   Ioffe S., INT C MACHINE LEARNI, P448
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Le, 2015, ARXIV150400941, P1, DOI DOI 10.1109/72.279181
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ledig C., INT C COMPUTER VISIO, P4681
   Lee C.-Y., INT C ARTIFICIAL INT, P562
   Lin T.Y., EUROPEAN C COMPUTER, P740
   Martin D., INT C COMPUTER VISIO, P416
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Masci J, 2012, IEEE IJCNN
   Mesbah A, 2019, IMAGE VISION COMPUT, V88, P76, DOI 10.1016/j.imavis.2019.04.010
   Molchanov P., 2017, INT C LEARN REPR ICL, P1, DOI DOI 10.1002/9781118786352.WBIEG1156
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava R. K., 2015, Advances in Neural Information Processing Systems, P2377
   Wager S., 2013, Advances in Neural Information Processing Systems
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie L., INT C COMPUTER VISIO, P4753
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zong M, 2019, IMAGE VISION COMPUT, V107, P104
NR 34
TC 2
Z9 2
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104446
DI 10.1016/j.imavis.2022.104446
EA APR 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1F1NU
UT WOS:000794942300001
DA 2024-07-18
ER

PT J
AU Liang, ZX
   Yin, M
   Gao, JL
   He, YC
   Huang, WT
AF Liang, Zixi
   Yin, Ming
   Gao, Junli
   He, Yicheng
   Huang, Weitian
TI View knowledge transfer network for multi-view action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Deep learning; Multi-view learning; Generative
   adversarial network; Late fusion
AB As many data in practical applications occur or can be captured in multiple views form, multi-view action recognition has received much attention recently, due to utilizing certain complementary and heterogeneous information in various views to promote the downstream task. However, most existing methods assume that multi-view data is complete, which may not always be met in real-world applications.To this end, in this paper, a novel View Knowledge Transfer Network (VKTNet) is proposed to handle multi-view action recognition, even when some views are incomplete. Specifically, the view knowledge transferring is utilized using conditional generative adversarial network(cGAN) to reproduce each view's latent representation, conditioning on the other view's information. As such, the high-level semantic features are effectively extracted to bridge the semantic gap between two different views. In addition, in order to efficiently fuse the decision result achieved by each view, a Siamese Scaling Network(SSN) is proposed instead of simply using a classifier. Experimental results show that our model achieves the superiority performance, on three public datasets, against others when all the views are available. Meanwhile, the degradation of performance is avoided under the case that some views are missing. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liang, Zixi; Yin, Ming; Gao, Junli; He, Yicheng] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China.
   [Huang, Weitian] South China Univ Technol, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology; South China University of Technology
RP Yin, M (corresponding author), Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China.
EM yiming@gdut.edu.cn
RI Huang, Weitian/GZG-9765-2022; Liang, zixi/HGU-1392-2022
OI Huang, Weitian/0000-0001-8848-4801
FU National Natural Science Foundation of China [61876042]; Guangdong Basic
   and Ap-plied Basic Research Foundation [2020A1515011493]
FX Acknowledgments This work was supported in part by the National Natural
   Science Foundation of China Grant 61876042, and the Guangdong Basic and
   Ap-plied Basic Research Foundation (No. 2020A1515011493) .
CR Akilan T, 2017, IEEE SYS MAN CYBERN, P566, DOI 10.1109/SMC.2017.8122666
   [Anonymous], 2014, Advances in neural information processing systems
   Azad R, 2019, IEEE T CIRC SYST VID, V29, P1729, DOI 10.1109/TCSVT.2018.2855416
   Chen Rui, P CVPR 2021, P846
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Girdhar Rohit, P IEEE C COMP VIS PA, P971
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Huang Y, 2015, IEEE T MULTIMEDIA, V17, P1923, DOI 10.1109/TMM.2015.2476658
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kardas K, 2017, EXPERT SYST APPL, V89, P343, DOI 10.1016/j.eswa.2017.07.051
   Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708
   Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906
   Lin Yan-Ching, P 20 ACM INT C MULT, P1053
   Liu L., 2013, 23 INT JOINT C ART I
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Nie FP, 2020, IEEE T KNOWL DATA EN, V32, P2389, DOI 10.1109/TKDE.2019.2920985
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2408
   Nie Feiping, P IJCAI 2016, P1881
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ortis A, 2017, PATTERN RECOGN, V72, P207, DOI 10.1016/j.patcog.2017.07.010
   Peters J, 2017, ADAPT COMPUT MACH LE
   Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Song Y, 2015, IEEE SIGNAL PROC LET, V22, P426, DOI 10.1109/LSP.2014.2361901
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vyas Mubarak Shah Shruti, 2020, P ECCV, V12372
   Wang L., 2016, P ECCV
   Wang LC, 2019, IEEE I CONF COMP VIS, P6221, DOI 10.1109/ICCV.2019.00631
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang JF, 2018, IEEE T VEH TECHNOL, V67, P7620, DOI 10.1109/TVT.2018.2833388
   Yin M, 2020, AAAI CONF ARTIF INTE, V34, P6688
   Yin QY, 2017, PATTERN RECOGN, V67, P313, DOI 10.1016/j.patcog.2017.01.035
   Yunyu Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P318, DOI 10.1007/978-3-030-58568-6_19
   Zhang CQ, 2022, IEEE T PATTERN ANAL, V44, P2402, DOI 10.1109/TPAMI.2020.3037734
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao R, 2019, PROC CVPR IEEE, P7725, DOI 10.1109/CVPR.2019.00792
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 46
TC 8
Z9 8
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2022
VL 118
AR 104357
DI 10.1016/j.imavis.2021.104357
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0F3OZ
UT WOS:000777273700008
DA 2024-07-18
ER

PT J
AU Yucel, MK
   Cinbis, R
   Duygulu, P
AF Yucel, Mehmet Kerim
   Cinbis, RamazanGokberk
   Duygulu, Pinar
TI How robust are discriminatively trained zero-shot learning models?
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Zero-shot learning; Robust generalization; Adversarial robustness
AB Data shift robustness has been primarily investigated from a fully supervised perspective, and robustness of zero shot learning (ZSL) models have been largely neglected. In this paper, we present novel analyses on the robustness of discriminative ZSL to image corruptions. We subject several ZSL models to a large set of common corruptions and defenses. In order to realize the corruption analysis, we curate and release the first ZSL corruption robustness datasets SUN-C, CUB-C and AWA2-C. We analyse our results by taking into account the dataset characteristics, class imbalance, class transitions between seen and unseen classes and the discrepancies between ZSL and GZSL performances. Our results show that discriminative ZSL suffers from corruptions and this trend is further exacerbated by the severe class imbalance and model weakness inherent in ZSL methods. We then combine our findings with those based on adversarial attacks in ZSL, and highlight the different effects of corruptions and adversarial examples, such as the pseudo-robustness effect present under adversarial attacks. We also obtain new strong baselines for both models with the defense methods. Finally, our experiments show that although existing methods to improve robustness somewhat work for ZSL models, they do not produce a tangible effect. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Yucel, Mehmet Kerim; Duygulu, Pinar] Hacettepe Univ, Grad Sch Sci & Engn, TR-06800 Ankara, Turkey.
   [Cinbis, RamazanGokberk] Middle East Tech Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Hacettepe University; Middle East Technical University
RP Yucel, MK (corresponding author), Hacettepe Univ, Grad Sch Sci & Engn, TR-06800 Ankara, Turkey.
EM mkerimyucel@hacettepe.edu.tr; gcinbis@ceng.metu.edu.tr;
   pinar@cs.hacettepe.edu.tr
RI Cinbis, Ramazan Gokberk/AAQ-6929-2020
OI Cinbis, Ramazan Gokberk/0000-0003-0962-7101; Yucel, Mehmet
   Kerim/0000-0003-1645-0877
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   Benz P, 2021, IEEE WINT CONF APPL, P494, DOI 10.1109/WACV48630.2021.00054
   Bhattad Anand, 2020, INT C LEARN REPR
   Bucher M, 2017, IEEE INT CONF COMP V, P2666, DOI 10.1109/ICCVW.2017.308
   Calian D.A., ARXIV210401086, V2021
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chen L, 2018, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2018.00115
   Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Geirhos Robert, 2018, ICLR
   Goibert M., 2020, ADVERSARIAL ROBUSTNE
   Gui S., 2019, ABS191010994 ARXIV
   Guo C., 2018, 6 INT C LEARN REPR I
   Hazan T., 2016, Perturbations, Optimization, and Statistics
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D., 2018, INT C LEARN REPR
   Hendrycks D, 2021, PROC CVPR IEEE, P15257, DOI 10.1109/CVPR46437.2021.01501
   Hendrycks D, 2019, ADV NEUR IN, V32
   Hendrycks Dan, 2019, ARXIV190312261
   Jiang HJ, 2019, IEEE I CONF COMP VIS, P9764, DOI 10.1109/ICCV.2019.00986
   Kireev Klim, 2021, ARXIV210302325
   Kurakin A., 2016, WORKSHOP TRACK P
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li Y, 2018, PROC CVPR IEEE, P7463, DOI 10.1109/CVPR.2018.00779
   Lin H, 2021, PROC CVPR IEEE, P11023, DOI 10.1109/CVPR46437.2021.01088
   Liu Y, 2019, IEEE I CONF COMP VIS, P6697, DOI 10.1109/ICCV.2019.00680
   Lu JJ, 2017, IEEE I CONF COMP VIS, P446, DOI 10.1109/ICCV.2017.56
   Mu N., ARXIV190602337
   Naseer M, 2020, PROC CVPR IEEE, P259, DOI 10.1109/CVPR42600.2020.00034
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Paszke A, 2019, ADV NEUR IN, V32
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Ros AS, 2018, AAAI CONF ARTIF INTE, P1660
   Rusak Evgenia, 2020, P EUR C COMP VIS
   Sariyildiz MB, 2019, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2019.00227
   Schmidt L., 2018, Adv. Neural Inform. Process. Syst, P5014, DOI DOI 10.48550/ARXIV.1804.11285
   Shaham Uri, 2018, ARXIV180310840
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Sumbul G, 2019, IEEE T GEOSCI REMOTE, V57, P4929, DOI 10.1109/TGRS.2019.2894425
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Verma VK, 2018, PROC CVPR IEEE, P4281, DOI 10.1109/CVPR.2018.00450
   Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xiao CW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3905
   Xie N., 2020, EXPLANABLE DEEP LEAR
   Xu WL, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23198
   Xu X, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P41, DOI 10.1145/3078971.3078977
   Ye M, 2017, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR.2017.542
   Yu YL, 2018, ADV NEUR IN, V31
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Yucel Mehmet Kerim, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12535), P3, DOI 10.1007/978-3-030-66415-2_1
   Zhang HF, 2019, IEEE T IMAGE PROCESS, V28, P506, DOI 10.1109/TIP.2018.2869696
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
NR 63
TC 7
Z9 7
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104392
DI 10.1016/j.imavis.2022.104392
EA FEB 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nibali, A
   Millward, J
   He, Z
   Morgan, S
AF Nibali, Aiden
   Millward, Joshua
   He, Zhen
   Morgan, Stuart
TI ASPset: An outdoor sports pose video dataset with 3D keypoint
   annotations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Markerless motion capture; Human pose estimation; Triangulation; Camera
   calibration
AB Recent advances in deep learning approaches to computer vision problems have led to renewed interest in the task of predicting 3D human joint locations from raw image data, with application areas including sports analysis, human-computer interaction, and physical rehabilitation. Although supervised learning of deep neural networks has proven to be effective for pose estimation, it requires a wealth of varied data to generalise well to previously unseen examples. Consequently, progress in 3D human pose estimation has been slowed by the fact that 3D keypoint annotations are notoriously difficult to obtain, traditionally requiring a large array of cameras and/or the use of wearable markers/sensors. In this paper we describe a methodology for obtaining 3D human pose annotations using only three video cameras and without any wearables. We apply this methodology to construct ASPset-510 (Australian Sports Pose Dataset), a large collection of natural sports-related video with 3D pose annotations. Using ASPset-510 as an additional source of training examples, we found that we could improve pose model generalisation on the established MPI-INF-3DHP benchmark. We make ASPset-510 publicly available, and provide strong baseline results for future work to compare against.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Nibali, Aiden; Millward, Joshua; He, Zhen] La Trobe Univ, Dept Comp Sci & IT, Bundoora, Vic 3086, Australia.
   [Millward, Joshua; Morgan, Stuart] Australian Inst Sport, Leverrier St, Bruce, ACT 2617, Australia.
C3 La Trobe University; Australian Institute of Sport
RP Nibali, A (corresponding author), La Trobe Univ, Dept Comp Sci & IT, Bundoora, Vic 3086, Australia.
EM a.nibali@latrobe.edu.au
RI Morgan, Stuart W/B-9850-2017
OI Nibali, Aiden/0000-0002-1352-9910
CR [Anonymous], 2000, DR DOBBS J SOFTWARE
   [Anonymous], 2010, BMVC
   [Anonymous], 2014, P CVPR
   [Anonymous], 2017, P ICLR
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.90
   Azevedo C.L., 2014, TRANSP RES PROCEDIA, P3
   Baptista R., ARXIV200409989
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Chen WZ, 2016, INT CONF 3D VISION, P479, DOI 10.1109/3DV.2016.58
   Dabral R., 2017, ARXIV171109250
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hossain M.R.I., P ECCV 2018, P68
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743
   Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500
   Lee K., P ECCV 2018, P119
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L., 2020, P ICLR
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Loshchilov I., 2018, P ICLR
   Luvizon D. C., 2017, ARXIV171002322
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nibali A, 2019, IEEE WINT CONF APPL, P1477, DOI 10.1109/WACV.2019.00162
   Nishikawa Y., 2018, 2018 IEEE International Conference on Consumer Electronics (ICCE), P1
   Ohashi T, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104028
   Paszke A, 2019, ADV NEUR IN, V32
   Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Pullen K, 2002, ACM T GRAPHIC, V21, P501
   Rogez G, 2017, PROC CVPR IEEE, P1216, DOI 10.1109/CVPR.2017.134
   Sarandi I., P FG 2020, P677
   Schmid H.J.D, 2008, P ECCV
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Sun X., 2017, P ICCV, V2
   Trumble M., 2017, BMVC, V2, P3
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37
   Wandt B, 2019, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2019.00797
   Wang JB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P374, DOI 10.1145/3343031.3350910
   Zhang M.R., 2019, P NEURIPS
   Zhang WC, 2017, IMAGE VISION COMPUT, V61, P22, DOI 10.1016/j.imavis.2017.02.002
NR 49
TC 8
Z9 9
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104196
DI 10.1016/j.imavis.2021.104196
EA MAY 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700007
DA 2024-07-18
ER

PT J
AU Sharma, H
   Jalal, AS
AF Sharma, Himanshu
   Jalal, Anand Singh
TI Visual question answering model based on graph neural network and
   contextual attention
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual question answering; Computer vision; Natural language processing;
   Attention
AB Visual Question Answering (VQA) has recently appeared as a hot research area in the field of computer vision and natural language processing. A VQA model uses both image and question features and fuses them to predict an answer for a given natural question related to an image. However, most VQA approaches using attention mechanism mainly concentrate on extraction of visual information from regions of interests for answer prediction and ignore the relation between the regions of interests together with the reasoning among these regions. Apart from this limitation, VQA approaches also ignore the regions which are previously attended for answer generation. These regions which are attended in past can guide the selection of the subsequent regions of attention. In this paper, a novel VQA model is presented and formulated that utilizes this relationship between the regions and employs visual context based attention that takes into account the previously attended visual content. Experimental results demonstrate that the proposed VQA model boosts the accuracy of answer prediction on publically available datasets VQA 1.0 and VQA 2.0.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Sharma, Himanshu; Jalal, Anand Singh] GLA Univ Mathura, Dept Comp Engn & Applicat, Mathura, India.
C3 GLA University
RP Sharma, H (corresponding author), GLA Univ Mathura, Dept Comp Engn & Applicat, Mathura, India.
EM himanshu.sharma@gla.ac.in; asjalal@gla.ac.in
OI Jalal, Anand/0000-0002-7469-6608; Sharma, Himanshu/0000-0002-3745-7616
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], Simple baseline for visual question answering
   [Anonymous], 2016, ARXIV160401485
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X
   Chen J., 2020, IEEE T MULTIMEDIA
   Cho K., 2014, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)
   Choi MJ, 2012, IEEE T PATTERN ANAL, V34, P240, DOI 10.1109/TPAMI.2011.119
   Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Galleguillos C, 2008, PROC CVPR IEEE, P3552
   Gao LL, 2020, NEUROCOMPUTING, V391, P227, DOI 10.1016/j.neucom.2018.11.102
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Han YH, 2020, IEEE T CIRC SYST VID, V30, P875, DOI 10.1109/TCSVT.2019.2897604
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hosseinabad SH, 2021, VISUAL COMPUT, V37, P119, DOI 10.1007/s00371-019-01786-4
   Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279
   Kazemi V., 2017, ARXIV170403162
   Kim D.C., 2017, ICLR
   Kim O.K., 2017, HADAMARD PRODUCT LOW
   Kipf TN, 2017, INT C LEARN REPR
   Li RY, 2018, AAAI CONF ARTIF INTE, P3546
   Li Y., 2016, ICLR, P1, DOI DOI 10.48550/ARXIV.1511.05493
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu JS, 2016, ADV NEUR IN, V29
   Mitchell M, 2015, INT J COMPUT VISION
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Pennington S.R., 2014, GLOVE GLOBAL VECTORS
   Ramanathan V., 2015, P IEEE C COMP VIS PA
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Sharma H, 2020, MOD PHYS LETT B, V34, DOI 10.1142/S0217984920503157
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang W.Q, 2017, P IEEE C COMP VIS PA
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wu AM, 2020, IEEE T CIRC SYST VID, V30, P4299, DOI 10.1109/TCSVT.2019.2956593
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Yu Z., 2018, IEEE T NEUR NET LEAR, V99
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zemel R., NIPS 2015, P2953
   Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331
   Zhang L, 2019, INFORM FUSION, V50, P20, DOI 10.1016/j.inffus.2018.09.015
   Zhang W., 2020, INFO FUSION, V55
   Zhang W., 2020, KNOWL-BASED SYST
   Zhang WF, 2018, NEURAL PROCESS LETT, V48, P1503, DOI 10.1007/s11063-017-9753-9
   Zhu C, 2017, IEEE I CONF COMP VIS, P1300, DOI 10.1109/ICCV.2017.145
NR 64
TC 33
Z9 33
U1 0
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104165
DI 10.1016/j.imavis.2021.104165
EA APR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700006
DA 2024-07-18
ER

PT J
AU Zhou, K
   Hui, B
   Wang, JF
   Wang, CY
   Wu, TT
AF Zhou, Kai
   Hui, Bei
   Wang, Junfeng
   Wang, Chunyu
   Wu, Tingting
TI A study on attention-based LSTM for abnormal behavior recognition with
   variable pooling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Abnormal behavior; Attention; LSTM; Variable pooling
AB Behavior recognition is a well-known computer vision mobile technology. It has been used in many applications such as video surveillance, motion detection on devices, human-computer interaction and sports video, etc. How-ever, most of the existing works ignored the depth and spatio-temporal information so that they resulted in over-fitting and inferior performance. Consequently, a novel framework for behavior recognition is proposed in this paper. In this framework, we propose a target depth estimation algorithm to calculate the 3D spatial position in-formation of the target, and take this information as the input of the behavior recognition model. Simultaneously, in order to obtain more Spatio-temporal information and better handle long-term video, combining with the idea of attention mechanism, we propose a skeleton behavior recognition model which is based on spatio-temporal convolution and attention-based LSTM (ST-CNN & ATT-LSTM). The deep spatial information is merged into each segment, and the model focuses on the key information extraction, which is essential for improving behav-ior recognition performance. Meanwhile, we use a feature compression method based on variable pooling to solve the problem of inconsistent input sizes caused by multi-person behavior recognition, so that the network can flexibly recognize multi-person skeleton sequences. Finally, the proposed framework is evaluated with real-world surveillance video data, and the results indicate that our framework is superior to existing methods.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhou, Kai; Wang, Junfeng] Sichuan Univ, Chengdu, Peoples R China.
   [Hui, Bei; Wang, Chunyu; Wu, Tingting] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Hui, Bei] Trusted Cloud Comp & Big Data Key Lab Sichuan Pro, Chengdu, Peoples R China.
   [Zhou, Kai] Sichuan Publ Secur Res Ctr, Chengdu, Peoples R China.
   [Zhou, Kai] Sichuan Prov Publ Secur Dept, Chengdu, Peoples R China.
C3 Sichuan University; University of Electronic Science & Technology of
   China
RP Hui, B (corresponding author), Univ Elect Sci & Technol China, Chengdu, Peoples R China.
EM hui_uestc@163.com
RI wu, tingting/H-8032-2012; Wang, Chunyu/HPC-0200-2023
FU National Key R&D Program of China [2018YFC0807500]; National Natural
   Science Foundation of?China [U19A2059]; Ministry of Science and
   Technology of Sichuan Province Program [2018GZDZX0048, 20ZDYF0343]
FX This work was supported by the National Key R&D Program of China (No.
   2018YFC0807500) , by National Natural Science Foundation of?China (No.
   U19A2059) , and by Ministry of Science and Technology of Sichuan
   Province Program (No. 2018GZDZX0048, 20ZDYF0343) .
CR [Anonymous], 2019, IEEE T NEURAL NETWOR
   [Anonymous], 2014, IEEE INT C COMP VIS
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2017, P AAAI C ART INT
   [Anonymous], 2012, CVPRW
   [Anonymous], 2015, ABS150702159 CORR
   Caetano C., 2019, 32 SIBGRAPI C GRAPH
   Caetano C., 2019, 2019 16 IEEE INT C
   Cai ZP, 2019, INT CON DISTR COMP S, P144, DOI 10.1109/ICDCS.2019.00023
   Cai ZP, 2019, PROC INT CONF DATA, P506, DOI 10.1109/ICDE.2019.00052
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chatfield K., 2014, CORR ABS14053531
   Cheng X., 2011, COMP ENG APPL, V202, P535
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2017, IEEE I CONF COMP VIS, P3745, DOI 10.1109/ICCV.2017.402
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Edwards M., 2016, GRAPH CONV NEUR NETW
   Efros Alexei A, 2008, P 9 IEEE INT C COMP
   Graves A., STUDIES COMPUTATIONA, V385, P2021
   Hu Y., 2018, 2018 15 INT C CONTR
   Hussein M.E., 2013, P 23 INT JOINT C ART
   Ji S., 2015, 12 ANN IEEE INT C SE
   Jia XF, 2012, INT C PATT RECOG, P3001
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Krizhevsky Alex., 2012, u International Conference on Neural Information Processing Systems - Volume, V1
   Li C., 2018, P 27 INT JOINT C ART
   Li KY, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P745, DOI 10.1145/3340531.3411970
   Liang Y, 2018, IEEE NETWORK, V32, P8, DOI 10.1109/MNET.2018.1700349
   Lipton ZC, 2015, ARXIV PREPRINT ARXIV
   Liu J., 2016, SPATIO TEMPORAL LSTM
   Ng Y.H., 2015, IEEE C COMP VIS PATT
   Ouyang X, 2019, IEEE ACCESS, V7, P40757, DOI 10.1109/ACCESS.2019.2906654
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Qin Y, 2020, VISUAL COMPUT, V36, P621, DOI 10.1007/s00371-019-01644-3
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Sharma S., 2015, NEURAL INFORM PROCES
   Shou Z., 2017, 2017 IEEE C COMP VIS
   Simonyan K., 2014, INT C NEUR INF PROC
   Tan T, 2018, P EUR C COMP VIS ECC
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Xiong Q.H. Zuobin, 2019, 19 IEEE INT C DAT MI
   Xiong ZB, 2021, IEEE T IND INFORM, V17, P6200, DOI 10.1109/TII.2020.3032352
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yeung S, 2018, INT J COMPUT VISION, V126, P375, DOI 10.1007/s11263-017-1013-y
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhao R., 2017, IEEE RSJ INT C INT R
   Zhe L., 2010, 2009 IEEE 12 INT C C
   Zheng X, 2019, INFORM SCIENCES, V493, P91, DOI 10.1016/j.ins.2019.04.036
   Zhong Q., 2017, IEEE INT C MULT EXP
NR 58
TC 10
Z9 10
U1 2
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104120
DI 10.1016/j.imavis.2021.104120
EA FEB 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600006
DA 2024-07-18
ER

PT J
AU Romero-Ramirez, FJ
   Muñoz-Salinas, R
   Medina-Carnicer, R
AF Romero-Ramirez, Francisco J.
   Munoz-Salinas, Rafael
   Medina-Carnicer, Rafael
TI Tracking fiducial markers with discriminative correlation filters
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Discriminative correlation filter; Squared fiducial markers; Marker
   mapping SLAM
ID POSE ESTIMATION; LOCALIZATION
AB In the last few years, squared fiducial markers have become a popular and efficient tool to solve monocular local-ization and tracking problems at a very low cost. Nevertheless, marker detection is affected by noise and blur: small camera movements may cause image blurriness that prevents marker detection.
   The contribution of this paper is two-fold. First, it proposes a novel approach for estimating the location of markers in images using a set of Discriminative Correlation Filters (DCF). The proposed method outperforms state-of-the-art methods for marker detection and standard DCFs in terms of speed, precision, and sensitivity. Our method is robust to blur and scales very well with image resolution, obtaining more than 200fps in HD im-ages using a single CPU thread.
   As a second contribution, this paper proposes a method for camera localization with marker maps employing a predictive approach to detect visible markers with high precision, speed, and robustness to blurriness. The method has been compared to the state-of-the-art SLAM methods obtaining, better accuracy, sensitivity, and speed. The proposed approach is publicly available as part of the ArUco library.
   (c) 2020 Elsevier B.V. All rights reserved.
C1 [Romero-Ramirez, Francisco J.; Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Univ Cordoba, Dept Informat & Anal Numer, Edificio Einstein,Campus Rabanales, Cordoba 14071, Spain.
   [Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Inst Maimonides Invest Biomed IMIBIC, Ave Menendez Pidal S-N, Cordoba 14004, Spain.
C3 Universidad de Cordoba
RP Muñoz-Salinas, R (corresponding author), Univ Cordoba, Dept Informat & Anal Numer, Edificio Einstein,Campus Rabanales, Cordoba 14071, Spain.
EM fj.romero@uco.es; in1musar@uco.es; rmedina@uco.es
RI Romero-Ramirez, Francisco J./JVE-2018-2024; Medina-Carnicer,
   Rafael/G-3401-2015
OI Romero-Ramirez, Francisco J./0000-0002-9572-0128; Medina-Carnicer,
   Rafael/0000-0003-4481-0614
FU (ISCIII) of Spain Ministry of Economy, Industry and Competitiveness
   [TIN2019-75279-P, IFI16/00033]; FEDER
FX This project has been funded under projects TIN2019-75279-P and
   IFI16/00033 (ISCIII) of Spain Ministry of Economy, Industry and
   Competitiveness, and FEDER.
CR [Anonymous], 2004, Technical Report
   [Anonymous], 2007, Proc. CVWW '07
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bergamasco F, 2011, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2011.5995544
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bonnard Q., 2013, Chilitags 2: Robust fiducial markers for augmented reality and robotics
   Bradski G., 2013, LEARNING OPENCV COMP, V2nd
   Calvet L, 2016, PROC CVPR IEEE, P562, DOI 10.1109/CVPR.2016.67
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   DeGol J, 2018, LECT NOTES COMPUT SC, V11207, P281, DOI 10.1007/978-3-030-01219-9_17
   Degol J, 2017, IEEE I CONF COMP VIS, P1481, DOI 10.1109/ICCV.2017.164
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Duan HB, 2015, IEEE T INSTRUM MEAS, V64, P2468, DOI 10.1109/TIM.2014.2343392
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Fiala M, 2010, IEEE T PATTERN ANAL, V32, P1317, DOI 10.1109/TPAMI.2009.146
   Gao X, 2018, IEEE INT C INT ROBOT, P2198, DOI 10.1109/IROS.2018.8593376
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Grabner H., 2006, BMVC, P47
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kanithi PK, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010023
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Knyaz V.A., 1998, 3D Surface Measurements, International Archives of Photogrammetry and Remote Sensing., VXXXII, P80
   Lasser T., 2015, IEEE NUCL SCI S MED
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   Marut A, 2019, IEEE METROL AEROSPAC, P261, DOI [10.1109/metroaerospace.2019.8869572, 10.1109/MetroAeroSpace.2019.8869572]
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Muñoz-Salinas R, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2019.107193
   Muñoz-Salinas R, 2019, PATTERN RECOGN, V86, P156, DOI 10.1016/j.patcog.2018.09.003
   Muñoz-Salinas R, 2018, PATTERN RECOGN, V73, P158, DOI 10.1016/j.patcog.2017.08.010
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Naimark L, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P27, DOI 10.1109/ISMAR.2002.1115065
   Nakawala H, 2018, ARTIF INTELL MED, V84, P50, DOI 10.1016/j.artmed.2017.10.004
   Olson E, 2011, IEEE INT CONF ROBOT
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Polvara R, 2017, 2017 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR)
   Romero-Ramire FJ, 2019, IEEE ACCESS, V7, P169908, DOI 10.1109/ACCESS.2019.2951204
   Romero-Ramirez FJ, 2018, IMAGE VISION COMPUT, V76, P38, DOI 10.1016/j.imavis.2018.05.004
   Sani MF, 2017, 2017 FIRST INTERNATIONAL CONFERENCE ON COMPUTER AND DRONE APPLICATIONS (ICONDA), P102, DOI 10.1109/ICONDA.2017.8270408
   Sattar J, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P165, DOI 10.1109/CRV.2007.34
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
NR 50
TC 8
Z9 8
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104094
DI 10.1016/j.imavis.2020.104094
EA JAN 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RD1DC
UT WOS:000633227000004
DA 2024-07-18
ER

PT J
AU Chiang, SH
   Wang, TP
   Chen, YF
AF Chiang, Sheng-Ho
   Wang, Tsaipei
   Chen, Yi-Fu
TI Efficient pedestrian detection in top-view fisheye images using
   compositions of perspective view patches
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pedestrian detection; Fisheye cameras; Omnidirectional cameras
ID SURVEILLANCE
AB Pedestrian detection in images is a topic that has been studied extensively, but existing detectors designed for perspective images do not perform as successfully on images taken with top-view fisheye cameras, mainly due to the orientation variation of people in such images. In our proposed approach, several perspective views are generated from a fisheye image and then concatenated to form a composite image. As pedestrians in this composite image are more likely to be upright, existing detectors designed and trained for perspective images can be applied directly without additional training. We also describe a new method of mapping detection bounding boxes from the perspective views to the fisheye frame. The detection performance on several public datasets compare favorably with state-of-the-art results. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Chiang, Sheng-Ho; Wang, Tsaipei] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Chen, Yi-Fu] Chunghwa Telecom Labs, Taoyuan, Taiwan.
C3 National Yang Ming Chiao Tung University; Chunghwa Telecom
RP Wang, TP (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM wangts@cs.nctu.edu.tw
RI CHEN, YIFU/T-1027-2016
FU Ministry of Science and Technology of R.O.C, Taiwan
   [MOST-107-2622-8-009-020]
FX This work is supported by the Ministry of Science and Technology of
   R.O.C, Taiwan. under grant MOST-107-2622-8-009-020.
CR CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Chiang A.-T., 2014, ICME WORKSH, P1
   Cinaroglu I, 2014, SIG PROCESS COMMUN, P2275, DOI 10.1109/SIU.2014.6830719
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Demirkus M, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P141, DOI 10.5220/0006094701410148
   Demiroz B. E., 2012, 2012_5th_International Symposium_on_Communications,_Control_and_Signal_Processing, P1
   Dollar P., 2010, BMVC 2010, DOI DOI 10.5244/C.24.68
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Kim H, 2015, I SYMP CONSUM ELECTR, P505, DOI 10.1109/ICCE.2015.7066501
   Krams O, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Kubo Y., 2007, SICE ANN C
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li J, 2020, ADV MATER INTERFACES, V7, DOI 10.1002/admi.202000508
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Meinel L, 2014, I SYMP CONSUM ELECTR, P398
   Qian YQ, 2020, IEEE T MULTIMEDIA, V22, P421, DOI 10.1109/TMM.2019.2929949
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saito Mamoru, 2011, SICE ANN C, P2
   SCHWALBE E, 2005, P 2 PAN PHOT WORKSH, V36
   Seidel R., 2018, ARXI180508503
   Tamura M, 2019, IEEE WINT CONF APPL, P1989, DOI 10.1109/WACV.2019.00216
   Nguyen VT, 2016, I C INF COMM TECH CO, P840, DOI 10.1109/ICTC.2016.7763311
   Vandewiele F., 2013, INT C DISTR SMART CA, P1
   Wang T, 2020, PHARM DEV TECHNOL, V25, P76, DOI 10.1080/10837450.2019.1673774
   Wang T, 2017, I S INTELL SIG PROC, P719, DOI 10.1109/ISPACS.2017.8266570
NR 31
TC 21
Z9 21
U1 2
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104069
DI 10.1016/j.imavis.2020.104069
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Song, GX
   Zheng, JM
   Cai, JF
   Cham, TJ
AF Song, Guoxian
   Zheng, Jianmin
   Cai, Jianfei
   Cham, Tat-Jen
TI Recovering facial reflectance and geometry from multi-view images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D facial reconstruction; Specular estimation; Multi-view capture
AB While the problem of estimating shapes and diffuse reflectances of human faces from images has been extensively studied, there is relatively less work done on recovering the specular albedo. This paper presents a lightweight solution for inferring photorealistic facial reflectance and geometry. Our system processes video streams from two views of a subject, and outputs two reflectance maps for diffuse and specular albedos, as well as a vector map of surface normals. A model-based optimization approach is used, consisting of the three stages of multi-view face model fitting, facial reflectance inference and facial geometry refinement. Our approach is based on a novel formulation built upon the 3D morphable model (3DMM) for representing 3D textured faces in conjunction with the Blinn-Phong reflection model. It has the advantage of requiring only a simple setup with two video streams, and is able to exploit the interaction between the diffuse and specular reflections across multiple views as well as timeframes. As a result, the method is able to reliably recover high-fidelity facial reflectance and geometry, which facilitates various applications such as generating photorealistic facial images under new viewpoints or illumination conditions. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Song, Guoxian; Zheng, Jianmin; Cai, Jianfei; Cham, Tat-Jen] Nanyang Technol Univ, Singapore, Singapore.
   [Cai, Jianfei] Monash Univ, Clayton, Vic, Australia.
C3 Nanyang Technological University; Monash University
RP Song, GX (corresponding author), Nanyang Technol Univ, Singapore, Singapore.
EM guoxian001@e.ntu.edu.sg; ASJMZheng@ntu.edu.sg; asjfcai@ntu.edu.sg;
   astjcham@ntu.edu.sg
RI Cai, Jianfei/A-3691-2011; Song, Guoxian/AAS-8496-2021; Zheng,
   Jianmin/A-3717-2011
OI Zheng, Jianmin/0000-0002-5062-6226
FU Singtel Cognitive and Artificial Intelligence Lab for Enterprises at NTU
FX Wewould like to thank YudongGuo and Juyong Zhang fromtheUniversity of
   Science and Technology of China for providing comparison result. And we
   also thank Chuanxia Zhen, Yujun Cai, Zhijie Zhang, Ayan Kumar Bhunia,
   etc. for their data collection. This research is supported by Singtel
   Cognitive and Artificial Intelligence Lab for Enterprises at NTU.
CR Bajcsy R., INT J COMPUT VIS
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz Volker, 1999, P C COMP GRAPH INT T
   Blinn J. F., SIGGRAPH COMPUT GRAP
   Bulat A, 2017, IEEE I CONF COMP VIS, P3726, DOI 10.1109/ICCV.2017.400
   Cao C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766943
   Cook S, 2013, CUDA PROGRAMMING: A DEVELOPER'S GUIDE TO PARALLEL COMPUTING WITH GPUS, P1, DOI 10.1016/B978-0-12-415933-4.00001-6
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Edwards G.J., 1998, P 3 INT C FAC GEST R
   Ekman P., 1978, Facial action coding system
   Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493
   Ghosh A., ACM T GRAPH
   Hu L., ACM T GRAPH
   Kim H., 2013, P IEEE C COMP VIS PA
   KingmaD P BaJ, 2015, P ICLR, P13
   Kumar R., IEEE T PATTERN ANAL
   Li H., ACM T GRAPHICS P SIG, V34
   Ma Wan-Chun, 2007, P 18 EUR C REND TECH
   Magda S., 2001, P INT C COMP VIS ICC
   Olszewski K., ACM T GRAPHICS P SIG, V35
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317
   Saito S., 2016, P IEEE C COMP VIS PA
   Sloan Peter-Pike., 2008, GAME DEVELOPERS C, V9, P42
   Smith W. A., INT J COMPUT VIS
   Smith W. A. P., IEEE T PATTERN ANAL
   Song G., 2018, P 26 ACM INT C MULT
   Tan F., 2017, P 2017 ACM MULT C MM
   Tan R. T., IEEE T PATTERN ANAL
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Turk M., J COGNITIVE NEUROSCI
   Yamaguchi S., ACM T GRAPH
   Yang Q., 2010, P EUR C COMP VIS ECC
   Yu RC, 2017, IEEE I CONF COMP VIS, P1068, DOI 10.1109/ICCV.2017.121
   Zhang C, IEEE T PATTERN ANAL
   ZHOU S, 2014, IEEE T VISUALIZATION, P413
NR 36
TC 4
Z9 4
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2020
VL 96
AR 103897
DI 10.1016/j.imavis.2020.103897
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YN
UT WOS:000527905200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Toldo, M
   Michieli, U
   Agresti, G
   Zanuttigh, P
AF Toldo, Marco
   Michieli, Umberto
   Agresti, Gianluca
   Zanuttigh, Pietro
TI Unsupervised domain adaptation for mobile semantic segmentation based on
   cycle consistency and feature alignment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised domain adaptation; Semantic segmentation; Adversarial
   learning; Transfer learning; Image-to-image translation
AB The supervised training of deep networks for semantic segmentation requires a huge amount of labeled real world data. To solve this issue, a commonly exploited workaround is to use synthetic data for training, but deep networks show a critical performance drop when analyzing data with slightly different statistical properties with respect to the training set. In this work, we propose a novel Unsupervised Domain Adaptation (UDA) strategy to address the domain shift issue between real world and synthetic representations. An adversarial model, based on the cycle consistency framework, performs the mapping between the synthetic and real domain. The data is then fed to a MobileNet-v2 architecture that performs the semantic segmentation task. An additional couple of discriminators, working at the feature level of the MobileNet-v2, allows to better align the features of the two domain distributions and to further improve the performance. Finally, the consistency of the semantic maps is exploited. After an initial supervised training on synthetic data, the whole UDA architecture is trained end-to-end considering all its components at once. Experimental results show how the proposed strategy is able to obtain impressive performance in adapting a segmentation network trained on synthetic data to real world scenarios. The usage of the lightweight MobileNet-v2 architecture allows its deployment on devices with limited computational resources as the ones employed in autonomous vehicles. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Toldo, Marco; Michieli, Umberto; Agresti, Gianluca; Zanuttigh, Pietro] Univ Padua, Dept Informat Engn, I-35131 Padua, Italy.
C3 University of Padua
RP Toldo, M (corresponding author), Univ Padua, Dept Informat Engn, I-35131 Padua, Italy.
EM marco.toldo.3@phd.unipd.it
RI Toldo, Marco/HPF-7540-2023; Zanuttigh, Pietro/AAB-9555-2019; Michieli,
   Umberto/KLC-7487-2024
OI Toldo, Marco/0000-0003-0954-1201; Zanuttigh, Pietro/0000-0002-9502-2389;
   Michieli, Umberto/0000-0003-2666-4342
FU Italian Minister for Education (MIUR) under the "Departments of
   Excellence" initiative; University of Padova
FX Our work was in part supported by the Italian Minister for Education
   (MIUR) under the "Departments of Excellence" initiative (Law 232/2016)
   and by the University of Padova Strategic Research Infrastructure Grant
   2017: "CAPRI: Calcolo ad Alte Prestazioni per la Ricerca e
   l'Innovazione".
CR Agresti G, 2019, PROC CVPR IEEE, P5569, DOI 10.1109/CVPR.2019.00573
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2014, ABS14123474 CORR
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   Biasetton M., 2019, P IEEE C COMP VIS PA
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dundar Aysegul, 2018, ARXIV PREPRINT ARXIV
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hoffman J., 2016, FCNS WILD PIXELLEVEL
   Hoffman J., 2018, P 35 INT C MACH LEAR
   Hung WC, 2018, ARXIV PREPRINT ARXIV
   Kingma D. P, 2015, International Conference on Learning Representations
   Lian Q, 2019, IEEE I CONF COMP VIS, P6757, DOI 10.1109/ICCV.2019.00686
   Liu Ming Yu, 2016, ADV NEURAL INF PROCE, P469
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Long M, 2015, AUST HUMANIT REV, P93
   Luo YW, 2019, IEEE I CONF COMP VIS, P6777, DOI 10.1109/ICCV.2019.00688
   Michieli U, 2020, IEEE T INTELL VEHICL, V5, P508, DOI 10.1109/TIV.2020.2980671
   Murez Z, 2018, PROC CVPR IEEE, P4500, DOI 10.1109/CVPR.2018.00473
   Pizzati Fabio, 2020, P IEEE WINT C APPL C
   Ren Z., 2018, PROC CVPR IEEE, P762, DOI DOI 10.1109/CVPR.2018.00104
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wu Z., 2019, ARXIV190406268
   Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 40
TC 31
Z9 31
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103889
DI 10.1016/j.imavis.2020.103889
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Alvarez-Gila, A
   Galdran, A
   Garrote, E
   van de Weijer, J
AF Alvarez-Gila, Aitor
   Galdran, Adrian
   Garrote, Estibaliz
   van de Weijer, Joost
TI Self-supervised blur detection from synthetically blurred scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Blur detection; Defocus blur; Motion blur; Deep learning;
   Self-supervised learning; Synthetic
ID DEFOCUS MAP ESTIMATION; IMAGE
AB Blur detection aims at segmenting the blurred areas of a given image. Recent deep learning-based methods approach this problem by learning an end-to-end mapping between the blurred input and a binary mask representing the localization of its blurred areas. Nevertheless, the effectiveness of such deep models is limited due to the scarcity of datasets annotated in terms of blur segmentation, as blur annotation is labor intensive. In this work, we bypass the need for such annotated datasets for end-to-end learning, and instead rely on object proposals and a model for blur generation in order to produce a dataset of synthetically blurred images. This allows us to perform self-supervised learning over the generated image and ground truth blur mask pairs using CNNs, defining a framework that can be employed in purely self-supervised, weakly supervised or semi-supervised configurations. Interestingly, experimental results of such setups over the largest blur segmentation datasets available show that this approach achieves state of the art results in blur segmentation, even without ever observing any real blurred image. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Alvarez-Gila, Aitor; Garrote, Estibaliz] TECNALIA, Derio, Spain.
   [Alvarez-Gila, Aitor; van de Weijer, Joost] Univ Autonoma Barcelona, CVC, Barcelona, Spain.
   [Galdran, Adrian] Ecole Technol Super, Montreal, PQ, Canada.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); University of Quebec; Ecole de Technologie Superieure - Canada
RP Alvarez-Gila, A (corresponding author), TECNALIA, Derio, Spain.; Alvarez-Gila, A (corresponding author), Univ Autonoma Barcelona, CVC, Barcelona, Spain.
EM aitor.alvarez@tecnalia.com; adrian.galdran-cabello.1@ens.etsmtl.ca;
   estibaliz.garrote@tecnalia.com; joost@cvc.uab.es
RI van de Weijer, Joost/A-1643-2009
OI van de Weijer, Joost/0000-0002-9656-9706; Galdran,
   Adrian/0000-0002-5992-1520; Garrote, Estibaliz/0000-0002-0268-0391
FU Department of Economic Development and Infrastructure, Basque
   Government, under the ELKARTEK program's project ONKOIKER
   [KK-2018/00090]; Spanish Government [TIN2016-79717-R]
FX This research was partially funded by the Department of Economic
   Development and Infrastructure, Basque Government, under the ELKARTEK
   program's project ONKOIKER under agreement KK-2018/00090. We thank the
   Spanish Government (project TIN2016-79717-R) and mention Generalitat de
   Catalunya CERCA Program.
CR Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   Chakrabarti A, 2010, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2010.5539954
   Chen DJ, 2016, IEEE IMAGE PROC, P3962, DOI 10.1109/ICIP.2016.7533103
   Chen L.-C., 2015, ARXIV 1412 7062
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen SJ, 2015, IEEE T IMAGE PROCESS, V24, P4433, DOI 10.1109/TIP.2015.2465162
   Ding XY, 2019, IEEE T MULTIMEDIA, V21, P124, DOI 10.1109/TMM.2018.2851389
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Favaro P, 2008, IEEE T PATTERN ANAL, V30, P518, DOI 10.1109/TPAMI.2007.1175
   Gast J, 2016, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2016.204
   Golestaneh S. A., 2017, IEEE C COMPUT VIS PA, P5800
   Gur S, 2019, PROC CVPR IEEE, P7675, DOI 10.1109/CVPR.2019.00787
   He Kaiming, 2017, P INT C COMP VIS
   Jenni S, 2018, PROC CVPR IEEE, P2733, DOI 10.1109/CVPR.2018.00289
   Kim B, 2018, COMPUT GRAPH FORUM, V37, P277, DOI 10.1111/cgf.13567
   Krähenbühl P, 2015, PROC CVPR IEEE, P1574, DOI 10.1109/CVPR.2015.7298765
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Ledig C., 2016, ARXIV160904802CS
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lopez XM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082710
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P5155, DOI 10.1109/TIP.2018.2847421
   Maheshwari S, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3009982
   Mao LM, 2008, I C WIREL COMM NETW, P10001
   Novotny D, 2018, PROC CVPR IEEE, P3637, DOI 10.1109/CVPR.2018.00383
   Pan JS, 2016, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2016.56
   Pang YW, 2016, IEEE T CYBERNETICS, V46, P2220, DOI 10.1109/TCYB.2015.2472478
   Pang YW, 2016, IEEE T IND ELECTRON, V63, P5592, DOI 10.1109/TIE.2016.2564938
   Park J., 2017, PROC IEEE C COMPUT V, P1736
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pertuz S, 2015, COMPUT VIS IMAGE UND, V133, P66, DOI 10.1016/j.cviu.2014.09.009
   Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI [10.1109/TPAMI.2015.2481406, 10.1109/TPAMI.2016.2537320]
   Purohit K, 2018, IEEE IMAGE PROC, P2202, DOI 10.1109/ICIP.2018.8451765
   Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Tang C, 2016, IEEE SIGNAL PROC LET, V23, P1652, DOI 10.1109/LSP.2016.2611608
   Tang C, 2013, OPT LETT, V38, P1706, DOI 10.1364/OL.38.001706
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Yi X, 2016, IEEE T IMAGE PROCESS, V25, P1626, DOI 10.1109/TIP.2016.2528042
   Yu F., 2015, ARXIV
   Zeng K, 2019, IEEE T IMAGE PROCESS, V28, P2107, DOI 10.1109/TIP.2018.2881830
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang SH, 2018, PROC CVPR IEEE, P6586, DOI 10.1109/CVPR.2018.00689
   Zhang XX, 2016, J VIS COMMUN IMAGE R, V35, P257, DOI 10.1016/j.jvcir.2016.01.002
   Zhao WD, 2018, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2018.00325
   Zhao Y, 2019, PHOSPHORUS CHEMISTRY: THE ROLE OF PHOSPHORUS IN PREBIOTIC CHEMISTRY, P1
   Zhou CY, 2009, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2009.5459268
   Zhou CY, 2010, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2010.5540090
   Zhu T, 2016, IEEE IMAGE PROC, P2673, DOI 10.1109/ICIP.2016.7532844
   Zhu X, 2013, IEEE T IMAGE PROCESS, V22, P4879, DOI 10.1109/TIP.2013.2279316
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 55
TC 3
Z9 4
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2019
VL 92
AR 103804
DI 10.1016/j.imavis.2019.08.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JW2JO
UT WOS:000502884200008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bhowmik, MK
   Debnath, T
   Bhattacharjee, D
   Dutta, P
AF Bhowmik, Mrinal Kanti
   Debnath, Tathagata
   Bhattacharjee, Debotosh
   Dutta, Paramartha
TI EF-Index: Determining number of clusters (<i>K</i>) to estimate number
   of segments (<i>S</i>) in an image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Clustering; Cluster-indexing; Segmentation; Electrostatic Force Image
   (EF-image); Force Influence Image; Electrostatic Force Index (EF-Index)
ID VISUAL ASSESSMENT; NORMALIZED CUTS; TENDENCY; ALGORITHMS
AB Estimation of number of segments in an image attracts a formidable interest among the research community. The number of segments in an image is estimated by calculating the number of clusters present in the pixels of that image. The present work offers an unsupervised method, named "Electrostatic Force Index (EF-Index)", to estimate the number of clusters inherent in an image, reporting of which is very rare in literature. The proposed approach is inspired by Coulomb's law of electrostatics. The EF-Index explores the mutual influence of an arbitrary pixel on another, by considering them similar to point charges. Our proposed cluster indexing method, viz. EF-Index is capable of determining the number of clusters present in an image. It has a strong resemblance to the way the electrostatic force is operative between a pair of static point charges in a closed system as per Coulomb's principle. In order to justify the effectiveness of the proposed approach, we have compared EF-Index of a given image with DB-Index, I-Index, CVNN-Index, DOE-AND-SCA and Sym-Index of the same image. Experimental results show that EF-Index is same as other state-of-the-art indices, whereas EF-Index does not require any clustering algorithm. To establish the applicability of the EF-Index, the same is applied for image segmentation considering Berkeley Segmentation Dataset and Stanford Background Dataset. We observe the results obtained conform to the ground truth and results achieved by applying existing well-established segmentation techniques on the same datasets. The efficacy of the proposed approach is further substantiated in terms of its reduced computational overhead in comparison to the state-of-the-art segmentation algorithms. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Bhowmik, Mrinal Kanti; Debnath, Tathagata] Tripura Univ, Dept Comp Sci & Engn, Agartala 799022, India.
   [Bhattacharjee, Debotosh] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, W Bengal, India.
   [Dutta, Paramartha] Visva Bharati Univ, Dept Comp & Syst Sci, Santini Ketan 731235, W Bengal, India.
C3 Tripura University; Jadavpur University; Visva Bharati University
RP Bhowmik, MK (corresponding author), Tripura Univ, Dept Comp Sci & Engn, Agartala 799022, India.
EM mrinalkantibhowmik@tripurauniv.in; tirtha.debnath@gmail.com;
   debotosh@ieee.org; paramartha@ieee.org
RI Dutta, Paramartha/AAD-1635-2021; Bhattacharjee, Debotosh/Q-4065-2019;
   Dutta, Paramartha/AAP-9966-2020; Bhattacharjee, Debotosh/L-8521-2015;
   Bhowmik, Mrinal Kanti/AAY-8356-2020
OI Dutta, Paramartha/0000-0003-3946-2440; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Bhowmik, Mrinal Kanti/0000-0003-3451-191X;
   Debnath, Tathagata/0000-0001-6445-275X
CR Bandyopadhyay S, 2007, IEEE T GEOSCI REMOTE, V45, P1506, DOI 10.1109/TGRS.2007.892604
   Banks S.P., 1990, SIGNAL PROCESSING IM
   Berkhin P., 2002, SURVEY CLUSTERING DA
   Bezdek JC, 2007, IEEE T FUZZY SYST, V15, P890, DOI 10.1109/TFUZZ.2006.889956
   BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873, DOI 10.1109/TSMC.1987.6499296
   Bezdek JC, 2002, IEEE IJCNN, P2225, DOI 10.1109/IJCNN.2002.1007487
   Cattell R, 1944, PSYCHOMETRIKA, V9, P169, DOI 10.1007/BF02288721
   Chen JY, 2018, IEEE ACCESS, V6, P20764, DOI 10.1109/ACCESS.2018.2805365
   Claycomb J. R., 2010, APPL ELECTROMAGNETIC, V81
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Evangelou I. E., 2001, WORKSH COMPL REAS GE
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FLOODGATE GD, 1963, J GEN MICROBIOL, V30, P237, DOI 10.1099/00221287-30-2-237
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Ghamisi Pedram, 2014, IEEE Transactions on Geoscience and Remote Sensing, V52, P2382, DOI 10.1109/TGRS.2013.2260552
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Hathaway RJ, 2006, PATTERN RECOGN, V39, P1315, DOI 10.1016/j.patcog.2006.02.011
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791
   Huband JM, 2005, PATTERN RECOGN, V38, P1875, DOI 10.1016/j.patcog.2005.03.018
   Jain A., 1989, FUNDAMENTALS DIGITAL, V83
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Krishnapuram R, 2001, IEEE T FUZZY SYST, V9, P595, DOI 10.1109/91.940971
   Kumar D, 2016, IEEE T CYBERNETICS, V46, P2372, DOI 10.1109/TCYB.2015.2477416
   Kumar MP, 2010, PROC CVPR IEEE, P3217, DOI 10.1109/CVPR.2010.5540072
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Lagrange M, 2008, IEEE T AUDIO SPEECH, V16, P278, DOI 10.1109/TASL.2007.909260
   Li Y, 2012, IEEE ENG MED BIO, P5867, DOI 10.1109/EMBC.2012.6347328
   LING RF, 1973, COMMUN ACM, V16, P355, DOI 10.1145/362248.362263
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu YC, 2013, IEEE T CYBERNETICS, V43, P982, DOI 10.1109/TSMCB.2012.2220543
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Ma J, 2012, IEEE T SYST MAN CY A, V42, P784, DOI 10.1109/TSMCA.2011.2172205
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Mignotte M, 2008, IEEE T IMAGE PROCESS, V17, P780, DOI 10.1109/TIP.2008.920761
   Munson DC, 1996, IEEE T IMAGE PROCESS, V5, P3, DOI 10.1109/TIP.1996.8100841
   Park LAF, 2016, IEEE T KNOWL DATA EN, V28, P3409, DOI 10.1109/TKDE.2016.2608821
   Saha S, 2008, IEEE GEOSCI REMOTE S, V5, P166, DOI 10.1109/LGRS.2008.915595
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang L, 2009, IEEE T KNOWL DATA EN, V21, P335, DOI 10.1109/TKDE.2008.158
   Yang A. Y., 2007, COMPUT VIS IMAGE UND, P212
   [No title captured]
NR 46
TC 2
Z9 2
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 29
EP 40
DI 10.1016/j.imavis.2019.04.009
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400004
DA 2024-07-18
ER

PT J
AU Zhao, K
   Wiliem, A
   Chen, SK
   Lovell, BC
AF Zhao, Kun
   Wiliem, Arnold
   Chen, Shaokang
   Lovell, Brian C.
TI Convex class model on symmetric positive definite manifolds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convex models; SPD manifolds
ID CLASSIFICATION; RECOGNITION; APPEARANCE; SPACE
AB The effectiveness of Symmetric Positive Definite (SPD) manifold features has been proven in various computer vision tasks. However, due to the non-Euclidean geometry of these features, existing Euclidean machineries cannot be directly used. In this paper, we tackle the classification tasks with limited training data on SPD manifolds. Our proposed framework, named Manifold Convex Class Model, represents each class on SPD manifolds using a convex model, and classification can be performed by computing distances to the convex models. We provide three methods based on different metrics to address the optimization problem of the smallest distance of a point to the convex model on SPD manifold. The efficacy of our proposed framework is demonstrated both on synthetic data and several computer vision tasks including object recognition, texture classification, person re-identification and traffic scene classification. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Zhao, Kun; Wiliem, Arnold; Chen, Shaokang; Lovell, Brian C.] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
C3 University of Queensland
RP Zhao, K (corresponding author), Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
EM kun.zhao@uq.net.au
OI Lovell, Brian/0000-0001-6722-1754
FU Sullivan Nicolaides Pathology, Australia; Australian Research Council
   (ARC) Linkage Projects [LP130100230, LP160101797]; Advance Queensland
   Early-Career Research Fellowship; Australian Research Council
   [LP130100230] Funding Source: Australian Research Council
FX This work has been partly funded by Sullivan Nicolaides Pathology,
   Australia and the Australian Research Council (ARC) Linkage Projects
   [Grant numbers LP130100230, LP160101797]. Arnold Wiliem is funded by the
   Advance Queensland Early-Career Research Fellowship.
CR [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2009, AISTATS
   [Anonymous], 2008, INT ARCH PHOTOGRAMM
   [Anonymous], 2012, ECCV
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 2013, CONVEX FUNCTIONS OPT
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Baktashmotlagh M, 2014, IEEE T PATTERN ANAL, V36, P2353, DOI 10.1109/TPAMI.2014.2339851
   Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349
   Birgin EG, 2001, ACM T MATH SOFTWARE, V27, P340, DOI 10.1145/502800.502803
   Cevikalp Hakan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P101, DOI 10.1109/ICCVW.2009.5457713
   Cevikalp H., 2008, P 25 INT C MACH LEAR, P120
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Chan AB, 2005, PROC CVPR IEEE, P846
   Chen J, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON INFORMATION, ELECTRONIC AND COMPUTER SCIENCE, VOLS I AND II, P570
   Chen SK, 2014, IEEE WINT CONF APPL, P1074, DOI 10.1109/WACV.2014.6835985
   Chen SK, 2013, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2013.65
   Cherian A, 2014, LECT NOTES COMPUT SC, V8691, P299, DOI 10.1007/978-3-319-10578-9_20
   Derpanis K. G., 2011, 2011 IEEE Workshop on Applications of Computer Vision (WACV), P606, DOI DOI 10.1109/WACV.2011.5711560
   Ess A, 2007, IEEE I CONF COMP VIS, P2065
   Feragen A, 2015, PROC CVPR IEEE, P3032, DOI 10.1109/CVPR.2015.7298922
   Fletcher PT, 2011, LECT NOTES COMPUT SC, V6844, P386, DOI 10.1007/978-3-642-22300-6_33
   Ginestet CE, 2012, STAT PROBABIL LETT, V82, P1859, DOI 10.1016/j.spl.2012.06.001
   Harandi M. T., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P433, DOI 10.1109/WACV.2012.6163005
   Harandi M, 2015, INT J COMPUT VISION, V114, P113, DOI 10.1007/s11263-015-0833-x
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Huang ZW, 2015, PR MACH LEARN RES, V37, P720
   Jayasumana S, 2013, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2013.17
   Kai Guo, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P188, DOI 10.1109/AVSS.2010.71
   Kalunga EmmanuelK., 2015, STAMLINS
   Lawson J, 2011, MATH ANN, V351, P267, DOI 10.1007/s00208-010-0603-6
   Leibe B, 2003, PROC CVPR IEEE, P409
   Moakher M, 2005, SIAM J MATRIX ANAL A, V26, P735, DOI 10.1137/S0895479803436937
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Sankaranarayanan AC, 2010, LECT NOTES COMPUT SC, V6311, P129, DOI 10.1007/978-3-642-15549-9_10
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Shroff N, 2010, PROC CVPR IEEE, P1911, DOI 10.1109/CVPR.2010.5539864
   Sivalingam R, 2010, LECT NOTES COMPUT SC, V6314, P722, DOI 10.1007/978-3-642-15561-1_52
   Sra S, 2016, P AM MATH SOC, V144, P2787, DOI 10.1090/proc/12953
   Takahashi T, 2011, PATTERN RECOGN LETT, V32, P2224, DOI 10.1016/j.patrec.2011.06.020
   Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49
   Terán P, 2006, J THEOR PROBAB, V19, P875, DOI 10.1007/s10959-006-0043-0
   Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Vemulapalli R, 2013, PROC CVPR IEEE, P1782, DOI 10.1109/CVPR.2013.233
   Vincent P, 2002, ADV NEUR IN, V14, P985
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie Yuchen, 2013, JMLR Workshop Conf Proc, V28, P1480
   Yang ZW, 1999, IEEE T IMAGE PROCESS, V8, P934, DOI 10.1109/83.772236
   Yin M, 2016, PROC CVPR IEEE, P5157, DOI 10.1109/CVPR.2016.557
   Zhao K, 2016, IEEE IMAGE PROC, P251, DOI 10.1109/ICIP.2016.7532357
   Zhou BL, 2014, ADV NEUR IN, V27
NR 53
TC 5
Z9 5
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2019
VL 87
BP 57
EP 67
DI 10.1016/j.imavis.2019.04.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IF3NV
UT WOS:000472988400006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Latorre-Carmona, P
   Traver, VJ
   Sánchez, JS
   Tajahuerce, E
AF Latorre-Carmona, Pedro
   Javier Traver, V
   Salvador Sanchez, J.
   Tajahuerce, Enrique
TI Online reconstruction-free single-pixel image classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Single-pixel imaging; Image classification; Recognition-delay trade-off;
   Sparse representations
AB In single-pixel imaging, a series of illumination patterns are projected onto an object and the reflected or transmitted light from the object is integrated by a photodetector (the single-pixel detector). Then, from the set of received photodetector signals, the image of the object can ultimately be reconstructed. However, this reconstruction is not only computationally expensive, but also unnecessary for purposes such as image classification tasks. This work proposes a reconstruction-free multi-class image classification framework that, unlike most of the existing approaches, exploits the sequential nature of the problem. Indeed, by accumulating evidence of the sequence of scalar values, a decision is made after each measurement on whether already classifying the object being imaged, or waiting for more measurements. This online decision relies on a mechanism to achieve a recognition-delay trade-off that induces behaviours within the conservative-to-aggressive spectrum, which suit distinct requirements in different applications. Additionally, the presentation order of the illumination patterns makes a difference in terms of the reconstruction quality (if required) and classification performance when a limited number of patterns is used. Nevertheless, in many cases, simple data- and task-agnostic orders, such as random or frequency-based orders, are commonly used. To address this, a novel sparse-representation-based strategy is presented that sorts the patterns according to their general and discriminability utilities. Both, the online classification framework including the recognition-delay trade-off mechanism, and the data- and task-aware pattern ordering proposed, are experimentally assessed, with encouraging results, on the MNIST digits and CalTech 101 Silhouettes data sets. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Latorre-Carmona, Pedro; Javier Traver, V; Salvador Sanchez, J.] Univ Jaume 1, Inst New Imaging Technol, Campus Riu Sec S-N, Castellon De La Plana 12071, Spain.
   [Tajahuerce, Enrique] Univ Jaume 1, Inst New Imaging Technol, GROC UJI, Campus Riu Sec S-N, Castellon De La Plana 12071, Spain.
C3 Universitat Jaume I; Universitat Jaume I
RP Latorre-Carmona, P (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Campus Riu Sec S-N, Castellon De La Plana 12071, Spain.
EM latorre@uji.es
RI Traver, V. Javier/F-8865-2016; Carmona, Pedro Latorre/F-4685-2012;
   Sánchez, J. S./F-9767-2016; Tajahuerce, Enrique/F-6665-2016
OI Traver, V. Javier/0000-0002-1596-8466; Tajahuerce,
   Enrique/0000-0003-1655-4393; Latorre Carmona, Pedro/0000-0001-6984-5173
FU Spanish Ministerio de Economia y Competitividad [FIS2016-75618-R];
   Generalitat Valenciana [PROMETEO 2016-079]; Universitat Jaume I
   [UJI.B2018-68, UJI-B2018-49]
FX Enrique Tajahuerce would like to acknowledge Spanish Ministerio de
   Economia y Competitividad (project FIS2016-75618-R), Generalitat
   Valenciana (project PROMETEO 2016-079) and Universitat Jaume I (project
   UJI.B2018-68). Pedro Latorre-Carmona and J. Salvador Sanchez would like
   to acknowledge project UJI-B2018-49.
CR Adler A., 2016, COMPRESSED LEARNING: A DEEP NEURAL NETWORK APPROACH
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2010, J. Mach. Learn. Res.
   [Anonymous], 2009, TECH REP
   Baheti PK, 2009, APPL OPTICS, V48, P5225, DOI 10.1364/AO.48.005225
   Davenport MA, 2007, PROC SPIE, V6498, DOI 10.1117/12.714460
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Duin RPW, 2012, PATTERN RECOGN LETT, V33, P826, DOI 10.1016/j.patrec.2011.04.019
   Edgar MP, 2019, NAT PHOTONICS, V13, P13, DOI 10.1038/s41566-018-0300-7
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P1, DOI 10.1007/978-1-4419-7011-4
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Jauregui-Sanchez Y., 2018, SINGLE PIXEL IMAGING
   Jiao S., 2018, DESIGN OPTIMAL ILLUM
   Jiao S., 2018, FAST OBJECT CLASSIFI
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li CG, 2013, NEUROCOMPUTING, V115, P192, DOI 10.1016/j.neucom.2013.02.005
   Li Y., 2015, J OPTICS, V17
   Lohit S, 2016, IEEE IMAGE PROC, P1913, DOI 10.1109/ICIP.2016.7532691
   Nishi H, 2016, PROC IEEE COOL CHIPS
   Reboredo H, 2016, IEEE T SIGNAL PROCES, V64, P5778, DOI 10.1109/TSP.2016.2599496
   Renna F, 2014, IEEE T SIGNAL PROCES, V62, P2265, DOI 10.1109/TSP.2014.2309560
   Rubinstein R., 2013, OMP BOX V10 MATLAB T
   Sankaranarayanan AC, 2016, IEEE SIGNAL PROC MAG, V33, P81, DOI 10.1109/MSP.2016.2581846
   WALD A, 1945, ANN MATH STAT, V16, P117, DOI 10.1214/aoms/1177731118
   Wang LM, 2016, INT CONF ACOUST SPEE, P4239, DOI 10.1109/ICASSP.2016.7472476
NR 25
TC 24
Z9 26
U1 0
U2 18
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2019
VL 86
BP 28
EP 37
DI 10.1016/j.imavis.2019.03.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IC8DN
UT WOS:000471206600003
OA Green Published
DA 2024-07-18
ER

PT J
AU Peng, YQ
   Liu, X
   Wang, WH
   Zhao, XS
   Wei, M
AF Peng, Yuqing
   Liu, Xuan
   Wang, Weihua
   Zhao, Xiaosong
   Wei, Ming
TI Image caption model of double LSTM with scene factors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image caption; Deep neural network; Scene recognition; Semantic
   information
AB In this paper, an image semantic understanding model combining scene factors is proposed to solve the problem that the accuracy rate of the description sentence is low in the current image semantic understanding model which is incorrect or ignores the scene recognition. This model first identifies the corresponding theme (scene information) through the text volume of the LDA analysis corpus. We get the vocabulary used in this scene. Then we use the ResNet to extract the global feature of the image, and use the Places365-CNNs to extract the feature of the deep scene. Finally, the model uses the picture scene information and the corpus scene information. In the description statement of the picture generation, it uses the words related to the picture scene in large probability and in the statement. In the process of generation, double LSTM is used to adjust the parameters to improve the accuracy of statement generation. This model is trained and tested in the Flickr8K, Flickr30K and MSCOCO image sets. The model is verified with different evaluation methods. The experimental results show that the proposed model can effectively improve the image language compared with other models. The accuracy of meaning understanding can solve these problems effectively. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Peng, Yuqing; Liu, Xuan; Wang, Weihua; Zhao, Xiaosong; Wei, Ming] Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
C3 Hebei University of Technology
RP Peng, YQ (corresponding author), Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
EM pengyuqing@scse.hebut.edu.cn
FU National Natural Science Foundation of China [U1813222]; Natural Science
   Foundation of Hebei Province [F2017202145]
FX This paper is supported by the National Natural Science Foundation of
   China (U1813222) and Natural Science Foundation of Hebei Province
   (F2017202145).
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   FU K, 2015, IEEE T PATTERN ANAL, P15
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   You HH, 2017, WASTE MANAGE, V68, P186, DOI 10.1016/j.wasman.2017.03.044
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 15
TC 16
Z9 20
U1 1
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2019
VL 86
BP 38
EP 44
DI 10.1016/j.imavis.2019.03.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IC8DN
UT WOS:000471206600004
DA 2024-07-18
ER

PT J
AU Wang, M
   Liu, XW
   Jin, HP
AF Wang, Meng
   Liu, Xingwang
   Jin, Huaiping
TI A generative image fusion approach based on supervised deep convolution
   network driven by weighted gradient flow
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep convolution neural network; Deep generative model; Image fusion;
   Dual-CNN; Differential gradient flow
AB In recent times, convolution neural networks (CNNs) have been utilized to generate desired images benefiting from the layered features. However, few studies have focused on integrating these features gained from multiple sources to obtain a high-quality image. In this paper, we propose a generative fusion approach using a supervised CNN framework with analysis and synthesis modules. According to it, the salient feature maps obtained from the analysis module are integrated to yield output generation by iteratively back-propagating gradients. Furthermore, a differential fusion strategy based on weighted gradient flow is embedded into the end-to-end fusion procedure. To transfer previous network configurations to current fusion tasks, the proposed network is fine-tuned according to the pretrained network such as VGG16, VGG19 and ResNet50. The experimental results indicate superior evaluations of the proposed approach compared with other state-of-the-art schemes in various fusion scenes, and also verify that the CNN features are adaptable and expressive to be aligned to generate fused images. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Wang, Meng; Liu, Xingwang; Jin, Huaiping] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology
RP Wang, M (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
EM vicong@live.com
RI liu, xingwang/KCY-1277-2024; Jin, Huaiping/A-3065-2015
FU National Natural Science Foundation of China [61563025,61562053]; Yunnan
   Department of Science and Technology Project [2016FB109]; Scientific
   Research Foundation of Yunnan Provincial Department of Education
   [2017ZZX149]
FX This research was funded by National Natural Science Foundation of China
   (61563025,61562053),Yunnan Department of Science and Technology Project
   (2016FB109) and Scientific Research Foundation of Yunnan Provincial
   Department of Education (2017ZZX149).
CR Broussard RP, 1999, IEEE T NEURAL NETWOR, V10, P554, DOI 10.1109/72.761712
   Chen H, 2007, INFORM FUSION, V8, P193, DOI 10.1016/j.inffus.2005.10.001
   Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Elad M, 2009, IEEE T INFORM THEORY, V55, P4701, DOI 10.1109/TIT.2009.2027565
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Gallo G, 2016, RMD OPEN, V2, DOI 10.1136/rmdopen-2015-000186
   Gatys Leon A, 2016, ARXIV PREPRINT ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim M, 2016, INFORM FUSION, V27, P198, DOI 10.1016/j.inffus.2015.03.003
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KUMAR BKS, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI DOI 10.1007/S11760-012-0361-X
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Li HF, 2016, SIGNAL PROCESS, V128, P474, DOI 10.1016/j.sigpro.2016.05.015
   Li HF, 2016, INFRARED PHYS TECHN, V76, P174, DOI 10.1016/j.infrared.2016.02.005
   Li MJ, 2014, APPL MECH MATER, V525, P715, DOI 10.4028/www.scientific.net/AMM.525.715
   Li ST, 2008, PATTERN RECOGN LETT, V29, P1295, DOI 10.1016/j.patrec.2008.02.002
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Li ST, 2012, IEEE T BIO-MED ENG, V59, P3450, DOI 10.1109/TBME.2012.2217493
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Y, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1070
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Sahoo SK, 2013, IEEE SIGNAL PROC LET, V20, P587, DOI 10.1109/LSP.2013.2258912
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stathaki T., 2008, IMAGE FUSION ALGORIT, P367
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Uniyal N., 2014, INT J COMPUT APPL, V95, P34
   Wang KP, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19070306
   Wencheng Wang, 2011, Journal of Computers, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Xu KP, 2018, KSII T INTERNET INF, V12, P2253, DOI 10.3837/tiis.2018.05.019
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yin HP, 2016, NEUROCOMPUTING, V216, P216, DOI 10.1016/j.neucom.2016.07.039
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao W., 2018, IEEE T MULTIMED, P1
   Zhong J., 2017, CHIN C PATT REC
NR 49
TC 19
Z9 23
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2019
VL 86
BP 1
EP 16
DI 10.1016/j.imavis.2019.02.011
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IC8DN
UT WOS:000471206600001
DA 2024-07-18
ER

PT J
AU Bhagat, PK
   Choudhary, P
AF Bhagat, P. K.
   Choudhary, P.
TI Image annotation: Then and now
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image annotation; Automatic image annotation; Multi-label
   classification; Image labeling; Image tagging; Annotation dataset;
   Annotation performance evaluation; Image features; Image retrieval
ID MULTI-LABEL CLASSIFICATION; MANIFOLD REGULARIZATION; SEMANTIC
   ANNOTATION; RETRIEVAL; EFFICIENT; FEATURES; SCALE; SEGMENTATION; MODEL;
   GRAPH
AB Automatic image annotation (AIA) plays a vital role in dealing with the exponentially growing digital images. Image annotation helps in effective retrieval, organization, classification, auto-illustration, etc. of the image. It started in early 1990. However, in the last three decades, there has been extensive research in AIA, and various new approaches have been advanced. In this article, we review more than 200 references related to image annotation proposed in the last three decades. This paper is an attempt to discuss predominant approaches, its constraints and ways to deal. Each segment of the article exhibits a discourse to expound the finding and future research directions and their hurdles. This paper also presents performance evaluation measures with relevant and influential image annotation database. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Bhagat, P. K.; Choudhary, P.] Natl Inst Technol Manipur, Imphal 795001, Manipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur
RP Bhagat, PK (corresponding author), Natl Inst Technol Manipur, Imphal 795001, Manipur, India.
EM pkbhagat@nitmanipur.ac.in; choudharyprakash@nitmanipur.ac.in
RI Choudhary, Dr. Prakash/ABE-2494-2021
OI Choudhary, Dr. Prakash/0000-0003-4337-7273; Bhagat, P
   K/0000-0001-5134-4477
CR [Anonymous], 2004, P 12 ANN ACM INT C M, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   [Anonymous], 2013, ACM MM
   [Anonymous], CLEF 2013 EV LAB WOR
   [Anonymous], 2011, Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-220
   [Anonymous], 2006, Book Annosearch: Image auto-annotation by search, DOI DOI 10.1109/CVPR.2006.58
   [Anonymous], 2010, Proceedings of the Eighteenth ACM International Conference on Multimedia, DOI DOI 10.1145/1873951.1873959
   [Anonymous], 2009, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2009.5206800
   [Anonymous], 2005, LEARNING MULTIPLE VI
   [Anonymous], 2007, THESIS
   [Anonymous], 2006, P 2006 IEEE COMPUTER, DOI DOI 10.1109/CVPR.2006.167
   [Anonymous], 2010, 2010 IEEE COMPUTER S, DOI DOI 10.1109/CVPRW.2010.5543189
   [Anonymous], ARXIV14094627
   [Anonymous], INT J REMOTE SENS
   Bahrololoum A, 2017, PATTERN RECOGN, V61, P169, DOI 10.1016/j.patcog.2016.07.034
   Ballan Lamberto, 2014, P INT C MULT RETR IC, P73
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bratasanu D, 2011, IEEE J-STARS, V4, P193, DOI 10.1109/JSTARS.2010.2081349
   Briggs F, 2012, P 18 ACM SIGKDD INT, P534, DOI [DOI 10.1145/2339530.2339616, 10.1145/2339530.2339616]
   Brodatz P., 1981, TEXTURES PHOTOGRAPHI
   Bucak S. S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2801, DOI 10.1109/CVPR.2011.5995734
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cao LL, 2009, IEEE T MULTIMEDIA, V11, P208, DOI 10.1109/TMM.2008.2009693
   Carneiro G., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P559, DOI 10.1145/1076034.1076129
   Carneiro G, 2005, PROC CVPR IEEE, P163
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang  J., 2009, ADV NEURAL INFORM PR, P288, DOI DOI 10.5555/2984093.2984126
   Chen G, 2009, PROC CVPR IEEE, P1658, DOI 10.1109/CVPRW.2009.5206813
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng QM, 2018, PATTERN RECOGN, V79, P242, DOI 10.1016/j.patcog.2018.02.017
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Cusano C, 2004, PROC SPIE, V5304, P330
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Daubechies I., 1992, Ten lectures on wavelets, DOI [DOI 10.1137/1.9781611970104, 10.1137/1.9781611970104]
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Ding XM, 2016, IEEE T MULTIMEDIA, V18, P1616, DOI 10.1109/TMM.2016.2572000
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fakhari A, 2013, APPL SOFT COMPUT, V13, P1292, DOI 10.1016/j.asoc.2012.10.019
   Fan JP, 2008, IEEE T IMAGE PROCESS, V17, P407, DOI 10.1109/TIP.2008.916999
   Fan Jianping., 2004, ACM International Conference on Multimedia, P540, DOI [DOI 10.1145/1027527, DOI 10.1145/1027527.1027660]
   Feng LN, 2016, IEEE T PATTERN ANAL, V38, P785, DOI 10.1109/TPAMI.2015.2469281
   Feng S.L., 2004, P 2004 IEEE COMP SOC, V2, pII
   Feng SH, 2018, MULTIDIM SYST SIGN P, V29, P1351, DOI 10.1007/s11045-017-0505-9
   Feng ZY, 2013, IEEE I CONF COMP VIS, P1609, DOI 10.1109/ICCV.2013.203
   Gao SH, 2014, IEEE T MULTIMEDIA, V16, P762, DOI 10.1109/TMM.2014.2299516
   Goh KS, 2005, IEEE T KNOWL DATA EN, V17, P1333, DOI 10.1109/TKDE.2005.170
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hardoon D. R., 2003, 3 INT WORKSH C UNPUB
   Hariharan B, 2012, MACH LEARN, V88, P127, DOI 10.1007/s10994-012-5291-x
   He JJ, 2012, MACH LEARN, V88, P273, DOI 10.1007/s10994-012-5283-x
   Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601
   Hu MQ, 2017, IEEE T IMAGE PROCESS, V26, P4871, DOI 10.1109/TIP.2017.2717185
   Huang S., 2013, ABS13102049 CORR
   Im DH, 2015, MULTIMED TOOLS APPL, V74, P2273, DOI 10.1007/s11042-014-1855-z
   Ivasic-Kos M, 2016, PATTERN RECOGN, V52, P287, DOI 10.1016/j.patcog.2015.10.017
   Jabid T., 2010, Digest of Technical Papers Int. Conf. Consumer Electronics, P329, DOI DOI 10.1109/ICCE.2010.5418801
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Ji P, 2017, NEUROCOMPUTING, V236, P48, DOI 10.1016/j.neucom.2016.09.108
   Jia X, 2017, NEUROCOMPUTING, V219, P518, DOI 10.1016/j.neucom.2016.09.052
   Jianping Fan, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P361
   Jin C, 2016, J VIS COMMUN IMAGE R, V34, P167, DOI 10.1016/j.jvcir.2015.10.017
   Jin JR, 2016, INT C PATT RECOG, P2452, DOI 10.1109/ICPR.2016.7900004
   Jin R., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P892, DOI DOI 10.1145/1027527.1027732
   Jing XY, 2016, IEEE T IMAGE PROCESS, V25, P2712, DOI 10.1109/TIP.2016.2549459
   Jiu MY, 2017, IEEE T IMAGE PROCESS, V26, P1820, DOI 10.1109/TIP.2017.2666038
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   JULESZ B, 1975, SCI AM, V232, P34, DOI 10.1038/scientificamerican0475-34
   Kabir Md Hasanul, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P526, DOI 10.1109/AVSS.2010.9
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Kang F., 2006, CVPR, V2, P1719
   Ke X, 2017, PATTERN RECOGN, V71, P60, DOI 10.1016/j.patcog.2017.05.020
   Ko BC, 2012, J DIGIT IMAGING, V25, P454, DOI 10.1007/s10278-011-9443-5
   Kodituwakku S.R., 2010, Indian Journal of Computer Science and Engineering, V1, P207
   Kong DG, 2012, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2012.6247947
   Kovalev V, 1996, GRAPH MODEL IM PROC, V58, P187, DOI 10.1006/gmip.1996.0016
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2016, COMPUT MED IMAG GRAP, V49, P37, DOI 10.1016/j.compmedimag.2016.01.001
   Kuroda K, 2002, NEUROCOMPUTING, V43, P259, DOI 10.1016/S0925-2312(01)00344-7
   LEBOUCHER G, 1978, PATTERN RECOGN, V10, P351, DOI 10.1016/0031-3203(78)90006-7
   Lei CY, 2016, IEEE T MULTIMEDIA, V18, P687, DOI 10.1109/TMM.2015.2477277
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li K, 2018, PATTERN RECOGN, V73, P1, DOI 10.1016/j.patcog.2017.06.036
   Li T, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2856058
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Li YX, 2016, NEUROCOMPUTING, V204, P135, DOI 10.1016/j.neucom.2015.07.151
   Lin WC, 2016, IMAGING SCI J, V64, P94, DOI 10.1080/13682199.2016.1139290
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Lin ZJ, 2015, MULTIMED TOOLS APPL, V74, P4091, DOI 10.1007/s11042-013-1811-3
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   Liu F, 2017, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2017.443
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Liu JJ, 2007, PROCEEDINGS OF THE 2007 CHINESE CONTROL AND DECISION CONFERENCE, P605, DOI 10.1145/1291233.1291380
   Liu WF, 2016, NEUROCOMPUTING, V172, P3, DOI 10.1016/j.neucom.2014.06.096
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Liu Y., 2006, Proc. of Conference on Artificial Intelligence, P421
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LOWITZ GE, 1983, PATTERN RECOGN, V16, P141, DOI 10.1016/0031-3203(83)90017-1
   Luo Y, 2013, IEEE T NEUR NET LEAR, V24, P709, DOI 10.1109/TNNLS.2013.2238682
   Ma Z., 2011, Proc. 19th ACM Int'l Conf. Multimedia, P283, DOI DOI 10.1145/2072298.2072336
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Mayhew MB, 2016, IEEE IMAGE PROC, P2266, DOI 10.1109/ICIP.2016.7532762
   McAuley JJ, 2013, INT J COMPUT VISION, V104, P343, DOI 10.1007/s11263-012-0561-4
   Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35
   Mller H., 2010, IMAGECLEF EXPT EVALU
   Moehrmann Julia, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P266, DOI 10.1007/978-3-642-40246-3_33
   Mueen A, 2008, J DIGIT IMAGING, V21, P290, DOI 10.1007/s10278-007-9070-3
   Nguyen C, 2013, P 23 INT JOINT C ART, P1558
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Niyogi P, 2013, J MACH LEARN RES, V14, P1229
   Nowak S., 2010, P INT C MULT INF RET, P557, DOI [10.1145/1743384.1743478, DOI 10.1145/1743384.1743478]
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pedersen K.S., 2007, Gaussian Processes in Practice, P59
   Pellegrin L., 2015, INAOE UNAL IMAGECLEF
   Pellegrin L, 2017, MULTIMED TOOLS APPL, V76, P16389, DOI 10.1007/s11042-016-3918-9
   Pellegrin L, 2014, LECT NOTES ARTIF INT, V8856, P151, DOI 10.1007/978-3-319-13647-9_16
   PUTTHIVIDHYA D, 2010, PROC CVPR IEEE, P3408, DOI DOI 10.1109/CVPR.2010.5540000
   Qi XJ, 2007, PATTERN RECOGN, V40, P728, DOI 10.1016/j.patcog.2006.04.042
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rubinstein M, 2012, LECT NOTES COMPUT SC, V7574, P85, DOI 10.1007/978-3-642-33712-3_7
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rui X., 2007, Proc. 15th ACM intl. conf. on multimedia, P585, DOI DOI 10.1145/1291233.1291378
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sanchez-Oro J., 2012, URJC UNED IMAGECLEF
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   Sebe N, 2003, IMAGE VISION COMPUT, V21, P1087, DOI 10.1016/j.imavis.2003.08.012
   Shi ZY, 2017, IEEE T PATTERN ANAL, V39, P2525, DOI 10.1109/TPAMI.2016.2645157
   Shi Zuoqiang, 2015, CORR
   Shooroki HK, 2017, MULTIMED TOOLS APPL, V76, P9643, DOI 10.1007/s11042-016-3572-2
   Singh G, 2013, PROC CVPR IEEE, P3151, DOI 10.1109/CVPR.2013.405
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Song LY, 2016, NEUROCOMPUTING, V214, P162, DOI 10.1016/j.neucom.2016.06.005
   Stathopoulos S., 2014, CLEF 2014 EV LAB WOR
   Su F, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P403, DOI 10.1145/2671188.2749383
   Su JH, 2011, IEEE T MULTIMEDIA, V13, P530, DOI 10.1109/TMM.2011.2129502
   Sun CJ, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P518, DOI 10.1109/MVA.2015.7153244
   Sun L, 2014, PATTERN RECOGN, V47, P1361, DOI 10.1016/j.patcog.2013.10.015
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang J., 2006, 7 INT WORKSH IM AN M, P121
   Tang JY, 2007, IEEE T CIRC SYST VID, V17, P384, DOI 10.1109/TCSVT.2006.888941
   Tang JH, 2012, IEEE T IMAGE PROCESS, V21, P2354, DOI 10.1109/TIP.2011.2180916
   Tang JH, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899418
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Tao L, 2016, IMAGE VISION COMPUT, V54, P22, DOI 10.1016/j.imavis.2016.06.008
   Tornmasi T, 2008, PATTERN RECOGN LETT, V29, P1996, DOI 10.1016/j.patrec.2008.03.009
   Tsai CF, 2006, INFORM PROCESS MANAG, V42, P136, DOI 10.1016/j.ipm.2004.11.001
   Tuffield M., 2006, 1 INT WORKSH SEM WEB
   Ulges A, 2011, IEEE T MULTIMEDIA, V13, P330, DOI 10.1109/TMM.2010.2101051
   Uricchio T., 2013, P IM CLEF WORKSH VAL
   Uricchio T, 2017, PATTERN RECOGN, V71, P144, DOI 10.1016/j.patcog.2017.05.019
   Valkealahti K, 1998, IEEE T PATTERN ANAL, V20, P90, DOI 10.1109/34.655653
   Verbeek J., 2010, Proc. ACM Multimedia Information Retrieval, P537
   Verma Y, 2017, INT J COMPUT VISION, V121, P126, DOI 10.1007/s11263-016-0927-0
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Vezhnevets A, 2012, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2012.6247757
   Villegas M., 2013, CLEF 2013 EV LAB WOR
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang C., 2008, ACM SIGIR, P355, DOI DOI 10.1145/1390334.1390396
   Wang C., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383221
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Wang CH, 2009, PROC CVPR IEEE, P1643, DOI 10.1109/CVPRW.2009.5206866
   Wang H, 2011, PROC CVPR IEEE, P793, DOI 10.1109/CVPR.2011.5995379
   Wang H, 2009, IEEE I CONF COMP VIS, P2029, DOI 10.1109/ICCV.2009.5459447
   Wang JL, 2017, 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC), P14, DOI 10.1109/DSC.2017.48
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang Y, 2009, PATTERN RECOGN, V42, P259, DOI 10.1016/j.patcog.2008.05.010
   Wang ZX, 2012, LECT NOTES COMPUT SC, V7573, P230, DOI 10.1007/978-3-642-33709-3_17
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wong RCF, 2008, IEEE T PATTERN ANAL, V30, P1933, DOI 10.1109/TPAMI.2008.125
   Wu BY, 2015, PATTERN RECOGN, V48, P2279, DOI 10.1016/j.patcog.2015.01.022
   Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Wu Pengcheng., 2011, Proceedings of the Fourth 140 ACM International Conference on Web Search and Data Mining, WSDM, P197, DOI DOI 10.1145/1935826.1935865
   Xia S, 2017, NEUROCOMPUTING, V228, P11, DOI 10.1016/j.neucom.2016.09.087
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xiang Y, 2010, PROC CVPR IEEE, P3368, DOI 10.1109/CVPR.2010.5540015
   Xie B, 2011, IEEE T SYST MAN CY B, V41, P1088, DOI 10.1109/TSMCB.2011.2106208
   Xu C, 2013, ARXIV PREPRINT ARXIV
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu X, 2016, IEEJ T ELECTR ELECTR, V11, P73, DOI 10.1002/tee.22190
   Xu X, 2013, LECT NOTES COMPUT SC, V8156, P101
   Yang C., 2006, P IEEE INT C COMPUTE, P2057
   Yang H, 2016, LECT NOTES COMPUT SC, V9905, P835, DOI 10.1007/978-3-319-46448-0_50
   Yu HF, 2014, PR MACH LEARN RES, V32
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang G, 2018, MULTIMED TOOLS APPL, V77, P9849, DOI 10.1007/s11042-017-4788-5
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang ML, 2010, PROC INT C TOOLS ART, P207, DOI 10.1109/ICTAI.2010.102
   Zhang RF, 2005, IEEE I CONF COMP VIS, P846
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495
   Zheng S, 2014, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2014.411
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhou Y, 2011, ADV INTEL SOFT COMPU, V106, P19
   Zhou Z.-H., 2007, P ADV NEUR INF PROC, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019
   Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
   Zhu XF, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P223, DOI 10.1145/2600428.2609556
NR 226
TC 36
Z9 38
U1 3
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2018
VL 80
BP 1
EP 23
DI 10.1016/j.imavis.2018.09.017
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HF6VQ
UT WOS:000454376800001
DA 2024-07-18
ER

PT J
AU Georgopoulos, M
   Panagakis, Y
   Pantic, M
AF Georgopoulos, Markos
   Panagakis, Yannis
   Pantic, Maja
TI Modeling of facial aging and kinship: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Age estimation; Age progression; Age-invariant face recognition;
   Cross-age face verification; Kinship verification
ID HUMAN AGE ESTIMATION; FACE RECOGNITION; TEXTURE CLASSIFICATION; GABOR
   FEATURE; IMAGE; APPEARANCE; VERIFICATION; PERCEPTION; SHAPE; REGRESSION
AB Computational facial models that capture properties of facial cues related to aging and kinship increasingly attract the attention of the research community, enabling the development of reliable methods for age progression, age estimation, age-invariant facial characterization, and kinship verification from visual data. In this paper, we review recent advances in modeling of facial aging and kinship. In particular, we provide an up-to date, complete list of available annotated datasets and an in-depth analysis of geometric, hand-crafted, and learned facial representations that are used for facial aging and kinship characterization. Moreover, evaluation protocols and metrics are reviewed and notable experimental results for each surveyed task are analyzed. This survey allows us to identify challenges and discuss future research directions for the development of robust facial models in real-world conditions. (C) 2018 Published by Elsevier B.V.
C1 [Georgopoulos, Markos; Panagakis, Yannis; Pantic, Maja] Imperial Coll London, Dept Comp, London, England.
   [Georgopoulos, Markos] Middlesex Univ London, Dept Comp Sci, London, England.
C3 Imperial College London; Middlesex University
RP Georgopoulos, M (corresponding author), Imperial Coll London, Dept Comp, London, England.; Georgopoulos, M (corresponding author), Middlesex Univ London, Dept Comp Sci, London, England.
EM m.georgopoulos@imperial.ac.uk
RI Panagakis, Yannis/AAZ-8090-2020
OI Panagakis, Ioannis/0000-0003-0153-5210
FU EPSRC [EP/N007743/1]; EPSRC [EP/N007743/1] Funding Source: UKRI
FX This work has been funded by the EPSRC project EP/N007743/1 (FACER2VM).
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alnajar F, 2015, IEEE IMAGE PROC, P3987, DOI 10.1109/ICIP.2015.7351554
   [Anonymous], 2008, EUR C COMP VIS WORKS
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], PERCEPTION
   [Anonymous], HUM OBJ INT PROC HOI
   [Anonymous], EURASIP J ADV SIGNAL
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], SOCIAL APPL ASPECTS
   [Anonymous], VISION BASED HUMAN G
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, INT C LEARN REPR ICL
   [Anonymous], 2012, C PATT REC APPL METH
   [Anonymous], BROWN SISTERS 33 YEA
   [Anonymous], 2014, EUR C COMP VIS ECCV
   [Anonymous], IMAGE VIS COMPUT
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], 2017, P FG
   [Anonymous], LHI IMAGE DATABASE
   [Anonymous], 2014, Computer Science
   [Anonymous], 2014, P AS C COMP VIS
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], 2002, FG NET AGING DATABAS
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], PLASTIC VISCO ELASTI
   [Anonymous], PATTERN RECOGN
   [Anonymous], 2016, FAMILY WILD FIW LARG
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE T INF FORENSICS
   [Anonymous], 2006, BMVC
   [Anonymous], 2016, Int J. Comput. Vis.
   [Anonymous], 2017, Neurocomputing
   [Anonymous], SURVEY FACE RECOGNIT
   [Anonymous], THEORY DEV NEURON SE
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2015, DENSE IMAGE CORRES C, DOI DOI 10.1007/978-3-319-23048-1_2
   [Anonymous], USING RANKING CNN AG
   [Anonymous], 2014, IEEE T INF FORENSICS
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   [Anonymous], 2007, 0749 U MASS
   [Anonymous], IEEE T INF FORENSICS
   [Anonymous], AUT FAC GEST REC 200
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], P IEEE WINT C APPL C
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2017, CVPR
   [Anonymous], KINSHIP VERIFICATION
   [Anonymous], 2016, IEEE C COMP VIS PATT
   Bar-Hillel A., 2003, ICML, P11
   Bastanfard A, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P50
   Bauckhage C., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P392, DOI 10.1109/ICPR.2010.104
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bereta M, 2013, PATTERN RECOGN, V46, P2634, DOI 10.1016/j.patcog.2013.03.010
   Bhattarai B, 2016, INT CONF ACOUST SPEE, P1901, DOI 10.1109/ICASSP.2016.7472007
   Biswas S., 2008, IEEE INT C BIOMETRIC, P1
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   BOTTINOK A, 2015, AUT FAC GEST REC FG, V2, P1
   Bouchaffra D, 2015, IEEE T NEUR NET LEAR, V26, P1375, DOI 10.1109/TNNLS.2014.2341634
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Browner WS, 2004, AM J MED, V117, P851, DOI 10.1016/j.amjmed.2004.06.033
   Bruce V., 1998, In the eye of the beholder: the science of face perception
   BURT DM, 1995, P ROY SOC B-BIOL SCI, V259, P137, DOI 10.1098/rspb.1995.0021
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Chao WL, 2013, PATTERN RECOGN, V46, P628, DOI 10.1016/j.patcog.2012.09.011
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   Chen YL, 2013, IEEE T INF FOREN SEC, V8, P2164, DOI 10.1109/TIFS.2013.2286265
   Cheng-Ta Shen, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P123, DOI 10.1109/ISM.2011.28
   Duong N, 2015, PROC CVPR IEEE, P4786, DOI 10.1109/CVPR.2015.7299111
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cuixian Chen, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P200, DOI 10.1109/FG.2011.5771398
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Dehghan A, 2014, PROC CVPR IEEE, P1757, DOI 10.1109/CVPR.2014.227
   Dibeklioglu H, 2015, IEEE T IMAGE PROCESS, V24, P1928, DOI 10.1109/TIP.2015.2412377
   Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189
   Dibeklioglu H, 2012, LECT NOTES COMPUT SC, V7574, P525, DOI 10.1007/978-3-642-33712-3_38
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Dingman R.O., 1964, surgery of facial fractures
   Du L, 2015, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2015.7298846
   Duan XD, 2015, IEEE IMAGE PROC, P1573, DOI 10.1109/ICIP.2015.7351065
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Escalera S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P243, DOI 10.1109/ICCVW.2015.40
   EXLINE RV, 1963, J PERS, V31, P1, DOI 10.1111/j.1467-6494.1963.tb01836.x
   Fan N, 2011, IEEE I CONF COMP VIS, P249, DOI 10.1109/ICCV.2011.6126249
   Fang RG, 2013, IEEE IMAGE PROC, P2983, DOI 10.1109/ICIP.2013.6738614
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   Fazl-Ersi E, 2014, IEEE IMAGE PROC, P5891, DOI 10.1109/ICIP.2014.7026190
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Freiwald WA, 2009, NAT NEUROSCI, V12, P1187, DOI 10.1038/nn.2363
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fu SY, 2014, IEEE T PATTERN ANAL, V36, P2483, DOI 10.1109/TPAMI.2014.2321570
   Fu Y., 2007, IEEE C COMPUTER VISI, P1
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2006, IEEE T CIRC SYST VID, V16, P830, DOI 10.1109/TCSVT.2006.877398
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132
   Gao GY, 2016, IEEE CONF COMPUT
   GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2014, INT C PATT RECOG, P4465, DOI 10.1109/ICPR.2014.764
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Gong DH, 2015, PROC CVPR IEEE, P5289, DOI 10.1109/CVPR.2015.7299166
   Gong DH, 2013, IEEE I CONF COMP VIS, P2872, DOI 10.1109/ICCV.2013.357
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2012, STUD COMPUT INTELL, V385, P5
   Guo G., 2010, IEEE COMP SOC C COMP, P71, DOI DOI 10.1109/CVPRW.2010.5543609
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2014, PROC CVPR IEEE, P4257, DOI 10.1109/CVPR.2014.542
   Guo GD, 2012, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2012.6247972
   Guo GD, 2012, IEEE T INSTRUM MEAS, V61, P2322, DOI 10.1109/TIM.2012.2187468
   Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guo YH, 2014, INT C PATT RECOG, P4287, DOI 10.1109/ICPR.2014.735
   Guodong Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3392, DOI 10.1109/ICPR.2010.828
   Haibin Ling, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu J, 2017, IEEE INT SYMP CIRC S
   Hu Junlin., 2014, COMPUTER VISION ACCV, P252
   Hu ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3087, DOI 10.1109/TIP.2016.2633868
   Huang GL, 2017, IEEE ICC
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Hui Fang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P593, DOI 10.1109/ICPR.2010.150
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   Kohli N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P245, DOI 10.1109/BTAS.2012.6374584
   Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811
   Kong S, 2015, IEEE T IMAGE PROCESS, V24, P2404, DOI 10.1109/TIP.2015.2417502
   Kuang ZH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P338, DOI 10.1109/ICCVW.2015.52
   Kuang-Yu Chang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3396, DOI 10.1109/ICPR.2010.829
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Lanitis Andreas, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163157
   Lanitis A., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P391, DOI 10.1109/AFGR.2000.840664
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li CS, 2015, IEEE T CYBERNETICS, V45, P2522, DOI 10.1109/TCYB.2014.2376517
   Li CS, 2012, PROC CVPR IEEE, P2570, DOI 10.1109/CVPR.2012.6247975
   Li XS, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P1, DOI 10.1109/ICIICII.2015.88
   Li ZF, 2016, IEEE T IMAGE PROCESS, V25, P2146, DOI 10.1109/TIP.2016.2535284
   Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062
   Liu H, 2017, PATTERN RECOGN, V66, P82, DOI 10.1016/j.patcog.2016.10.026
   Liu H, 2016, IEEE IMAGE PROC, P3249, DOI 10.1109/ICIP.2016.7532960
   Liu H, 2016, INT CONF ACOUST SPEE, P2792, DOI 10.1109/ICASSP.2016.7472186
   Liu Ming Yu, 2016, ADV NEURAL INF PROCE, P469
   Liu XC, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1, DOI 10.1109/CompComm.2015.7387529
   Liu X, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P258, DOI 10.1109/ICCVW.2015.42
   Lock EF, 2013, ANN APPL STAT, V7, P523, DOI 10.1214/12-AOAS597
   López MB, 2016, IEEE T PATTERN ANAL, V38, P2342, DOI 10.1109/TPAMI.2016.2522416
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   Maronidis Anastasios, 2013, International Conference on Computer Vision Theory and Applications (VISAPP 2013). Proceedings, P663
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Moyse E, 2014, PSYCHOL BELG, V54, P255, DOI 10.5334/pb.aq
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Ni B., 2009, Proceedings of the 17th ACM international conference on Multimedia, P85
   Ni BB, 2011, IEEE T MULTIMEDIA, V13, P1217, DOI 10.1109/TMM.2011.2167317
   Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006
   O'Toole AJ, 1999, IMAGE VISION COMPUT, V18, P9, DOI 10.1016/S0262-8856(99)00012-8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Park JH, 2008, REV GEN PSYCHOL, V12, P215, DOI 10.1037/1089-2680.12.3.215
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Puthenputhussery A, 2016, IEEE IMAGE PROC, P2921, DOI 10.1109/ICIP.2016.7532894
   Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462
   Ramanathan N., 2006, 2006 IEEE COMP SOC C, V1, P387
   Ramanathan N., 2008, IEEE INT C WORKSHOPS, P1
   Ramanathan N, 2009, J VISUAL LANG COMPUT, V20, P131, DOI 10.1016/j.jvlc.2009.01.011
   Ranjan R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P351, DOI 10.1109/ICCVW.2015.54
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Robinson J. P., 2016, P 24 ACM INT C MULT, P242, DOI DOI 10.1145/2964284.2967219
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sagonas C, 2017, PROC CVPR IEEE, P5739, DOI 10.1109/CVPR.2017.608
   Sagonas C, 2016, INT C PATT RECOG, P4226, DOI 10.1109/ICPR.2016.7900297
   Salakhutdinov R., 2009, AISTATS
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Scherbaum K, 2007, COMPUT GRAPH FORUM, V26, P285, DOI 10.1111/j.1467-8659.2007.01050.x
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   Shao M., 2011, CVPR 2011 WORKSH, P60, DOI DOI 10.1109/CVPRW.2011.5981801
   Shen CT, 2014, J INF SCI ENG, V30, P1131
   Shu XB, 2016, PATTERN RECOGN, V59, P156, DOI 10.1016/j.patcog.2015.12.015
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Simonyan K., 2013, FISHER VECTOR FACES
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Somanath G., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P105, DOI 10.1109/BTAS.2012.6374564
   Somanath G, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130517
   Song Z, 2011, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2011.6126248
   Su Y, 2010, INT CONF ACOUST SPEE, P1270, DOI 10.1109/ICASSP.2010.5495414
   Suo JL, 2012, IEEE T PATTERN ANAL, V34, P2083, DOI 10.1109/TPAMI.2012.22
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Thukral P, 2012, INT CONF ACOUST SPEE, P1529, DOI 10.1109/ICASSP.2012.6288182
   Tiddeman B, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.946630
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042
   Vieira TF, 2014, VISUAL COMPUT, V30, P1333, DOI 10.1007/s00371-013-0884-3
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang SZ, 2016, IEEE T CYBERNETICS, V46, P827, DOI 10.1109/TCYB.2015.2416321
   Wang XL, 2014, IEEE IMAGE PROC, P5017, DOI 10.1109/ICIP.2014.7026016
   Wang YH, 2012, IEEE T SYST MAN CY B, V42, P1107, DOI 10.1109/TSMCB.2012.2187051
   Wu T, 2012, IEEE T INF FOREN SEC, V7, P1780, DOI 10.1109/TIFS.2012.2213812
   WU Y, 1995, J VISUAL COMP ANIMAT, V6, P195, DOI 10.1002/vis.4340060403
   Wu Y, 1999, VISUAL COMPUT, V15, P183, DOI 10.1007/s003710050171
   Xia BQ, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P5
   Xia S., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, P2539, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422
   Xia SY, 2012, INT C PATT RECOG, P549
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Xing E.P., Advances in neural information processing systems, 2003, P521
   Xing JH, 2017, PATTERN RECOGN, V66, P106, DOI 10.1016/j.patcog.2017.01.005
   Yan HB, 2017, IMAGE VISION COMPUT, V60, P91, DOI 10.1016/j.imavis.2016.08.009
   Yan HB, 2015, IEEE T CYBERNETICS, V45, P2535, DOI 10.1109/TCYB.2014.2376934
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Yang HY, 2016, IEEE T IMAGE PROCESS, V25, P2493, DOI 10.1109/TIP.2016.2547587
   Yang M, 2011, PROC CVPR IEEE, P505, DOI 10.1109/CVPR.2011.5995481
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zebrowitz LA, 2008, SOC PERSONAL PSYCHOL, V2, P1497, DOI 10.1111/j.1751-9004.2008.00109.x
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang ML, 2015, IEEE T PATTERN ANAL, V37, P107, DOI 10.1109/TPAMI.2014.2339815
   Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou SHK, 2005, IEEE I CONF COMP VIS, P541
   Zhou X., 2011, ACM Multimedia, P953
   Zhou X, 2016, IEEE IMAGE PROC, P2911, DOI 10.1109/ICIP.2016.7532892
   Zhu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P267, DOI 10.1109/ICCVW.2015.43
NR 258
TC 17
Z9 19
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2018
VL 80
BP 58
EP 79
DI 10.1016/j.imavis.2018.05.003
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA HF6VQ
UT WOS:000454376800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hameed, K
   Chai, D
   Rassau, A
AF Hameed, Khurram
   Chai, Douglas
   Rassau, Alexander
TI A comprehensive review of fruit and vegetable classification techniques
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Recognition; Classification; Fruit; Vegetable; Produce classification;
   Machine learning; Computer vision
ID OBJECT RECOGNITION; FIRMNESS MEASUREMENT; TEXTURE FEATURES; CHILLING
   INJURY; COLOR; SHAPE; VISION; SEGMENTATION; IMAGES; QUALITY
AB Recent advancements in computer vision have enabled wide-ranging applications in every field of life. One such application area is fresh produce classification, but the classification of fruit and vegetable has proven to be a complex problem and needs to be further developed. Fruit and vegetable classification presents significant challenges due to interclass similarities and irregular intraclass characteristics. Selection of appropriate data acquisition sensors and feature representation approach is also crucial due to the huge diversity of the field. Fruit and vegetable classification methods have been developed for quality assessment and robotic harvesting but the current state-of-the-art has been developed for limited classes and small datasets. The problem is of a multi-dimensional nature and offers significantly hyperdimensional features, which is one of the major challenges with current machine learning approaches. Substantial research has been conducted for the design and analysis of classifiers for hyperdimensional features which require significant computational power to optimise with such features. In recent years numerous machine learning techniques for example, Support Vector Machine (SVM), K-Nearest Neighbour (KNN), Decision Trees, Artificial Neural Networks (ANN) and Convolutional Neural Networks (CNN) have been exploited with many different feature description methods for fruit and vegetable classification in many real-life applications. This paper presents a critical comparison of different state-of-the-art computer vision methods proposed by researchers for classifying fruit and vegetable. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Hameed, Khurram; Chai, Douglas; Rassau, Alexander] Edith Cowan Univ, Sch Engn, 270 Joondalup Dr, Joondalup, WA 6027, Australia.
   [Hameed, Khurram; Chai, Douglas; Rassau, Alexander] ECU, Joondalup, WA, Australia.
C3 Edith Cowan University; Edith Cowan University
RP Hameed, K (corresponding author), Edith Cowan Univ, Sch Engn, 270 Joondalup Dr, Joondalup, WA 6027, Australia.; Hameed, K (corresponding author), ECU, Joondalup, WA, Australia.
EM k.hameed@ecu.edu.au; d.chai@ecu.edu.au; a.rassau@ecu.edu.au
RI Hameed, Khurram/AAX-4269-2020
OI Hameed, Khurram/0000-0003-2525-3568; Chai, Douglas/0000-0002-9004-7608
FU Islamia University of Bahawalpur (IUB) Pakistan
   [5-1/HRD/UECTP(Batch-V)/1182/2017/HEC]; Edith Cowan University (ECU)
   Australia; HEC, IUB Pakistan; ECU Australia; Higher Education Commission
   (HEC) Pakistan
FX This work was supported by Higher Education Commission (HEC) Pakistan,
   The Islamia University of Bahawalpur (IUB) Pakistan
   (5-1/HRD/UECTP(Batch-V)/1182/2017/HEC) and Edith Cowan University (ECU)
   Australia. The authors would like to thank HEC, IUB Pakistan and ECU
   Australia for PhD grant of first corresponding author of this paper.
CR Aboudaoud I, 2012, IOP CONF SER-MAT SCI, V42, DOI 10.1088/1757-899X/42/1/012038
   Aksoy EE, 2015, COMPUT ELECTRON AGR, V110, P78, DOI 10.1016/j.compag.2014.10.020
   Akter YA, 2017, INT CONF ADV ELECTR, P285, DOI 10.1109/ICAEE.2017.8255368
   Amiryousefi MR, 2018, FOOD SCI NUTR, V6, P18, DOI 10.1002/fsn3.475
   Andrearczyk V, 2016, PATTERN RECOGN LETT, V84, P63, DOI 10.1016/j.patrec.2016.08.016
   Andújar D, 2013, SENSORS-BASEL, V13, P14662, DOI 10.3390/s131114662
   [Anonymous], 2017, CHIN J OCEANOL LIMNO
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], TEXTURE ANAL
   Arakeria MP, 2016, PROCEDIA COMPUT SCI, V79, P426, DOI 10.1016/j.procs.2016.03.055
   Arivazhagan S., 2010, J. Emerg. Trends Comput. Inf. Sci, V1, P90
   Arlimatti S. R., 2012, INT J ENG RES APPL, V2, P1010
   Arora S, 2014, PR MACH LEARN RES, V32
   ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747
   Ashok V., 2014, INT J COMPUT ENG TEC, P11
   Ashok V, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P308, DOI 10.1109/IC3I.2014.7019807
   Bai X, 2014, IEEE T IMAGE PROCESS, V23, P3935, DOI 10.1109/TIP.2014.2336542
   Barnea E, 2016, BIOSYST ENG, V146, P57, DOI 10.1016/j.biosystemseng.2016.01.013
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Belsha N, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON SENSING, SIGNAL PROCESSING AND SECURITY (ICSSS), P83, DOI 10.1109/SSPS.2017.8071570
   Berrada F., 2011, INT C MULT COMP SYST, DOI [10.1109/ICMCS.2011.5945600, DOI 10.1109/ICMCS.2011.5945600]
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Bhargava A, 2021, J KING SAUD UNIV-COM, V33, P243, DOI 10.1016/j.jksuci.2018.06.002
   Blasco J, 2009, J FOOD ENG, V90, P27, DOI 10.1016/j.jfoodeng.2008.05.035
   Bolle RM, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P244, DOI 10.1109/ACV.1996.572062
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Caldera S., 2018, REV DEEP LEARNING ME, P1, DOI [10.20944/preprints201805.0484.vl, DOI 10.20944/PREPRINTS201805.0484.VL]
   Marchal PC, 2013, J FOOD ENG, V119, P220, DOI 10.1016/j.jfoodeng.2013.05.032
   Catoe P. T., 2014, SELF CHECKOUT SYSTEM
   Cavallo DP, 2018, J FOOD ENG, V223, P46, DOI 10.1016/j.jfoodeng.2017.11.042
   Cen HY, 2016, POSTHARVEST BIOL TEC, V111, P352, DOI 10.1016/j.postharvbio.2015.09.027
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng JH, 2017, MEAT SCI, V123, P182, DOI 10.1016/j.meatsci.2016.09.017
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0
   Dae Gwan Kim, 2009, International Journal of Agricultural and Biological Engineering, V2, P41, DOI 10.3965/j.issn.1934-6344.2009.03.041-050
   Danti A., 2012, Int. J. Image Process. Pattern Recognit, V5, P151
   de Groot TH, 2015, IEEE SENS J, V15, P3068, DOI 10.1109/JSEN.2014.2387573
   Sa JJD, 2015, INFORM SCIENCES, V305, P349, DOI 10.1016/j.ins.2015.01.027
   Demyelinated P., 1988, CYBERNETICS, V77, P73
   Devikar M.M., 2013, International Journal of Advances in Engineering Technology, V6, P225
   Dhankhar M., 2015, OBJECT RECOGNITION K
   Dimatira JBU, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2031, DOI 10.1109/TENCON.2016.7848382
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Dirami A., SIGNAL PROCESS, V93
   Dorj UO, 2017, COMPUT ELECTRON AGR, V140, P103, DOI 10.1016/j.compag.2017.05.019
   Drost B, 2010, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2010.5540108
   Dubey SR, 2015, J INTELL SYST, V24, P405, DOI 10.1515/jisys-2014-0079
   Edan Y, 2000, IEEE T ROBOTIC AUTOM, V16, P831, DOI 10.1109/70.897793
   Evans T. C., 2015, arXiv:0403007, DOI 10.1037/t24245-000, Patent No. [Pub. No.: US 2006/0222585, 0222585, US 2006 / 0222585 A1]
   Fan HD, 2017, COMPUT BIOL MED, V85, P75, DOI 10.1016/j.compbiomed.2017.03.025
   Faria F. A., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P252, DOI 10.1109/SIBGRAPI.2012.42
   Foerster J., 2010, Landtechnik, V65, P96
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Garcia-Garcia A, 2018, J REAL-TIME IMAGE PR, V14, P585, DOI 10.1007/s11554-016-0607-x
   Garcia-Lamont F, 2018, NEUROCOMPUTING, V292, P1, DOI 10.1016/j.neucom.2018.01.091
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224
   Gongal A, 2015, COMPUT ELECTRON AGR, V116, P8, DOI 10.1016/j.compag.2015.05.021
   Gorges N, 2010, IEEE INT CONF ROBOT, P2349, DOI 10.1109/ROBOT.2010.5509553
   Gothwal R., 2014, COLOR IMAGE SEGMENTA, P1
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Habib MT, 2020, J KING SAUD UNIV-COM, V32, P300, DOI 10.1016/j.jksuci.2018.06.006
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Hassan N. M. Hussain, 2018, MULTIDIM SYST SIGN P, P1, DOI [10.1007/511045-018-0573-5, DOI 10.1007/511045-018-0573-5]
   He C, 2013, IEEE T GEOSCI REMOTE, V51, P4576, DOI 10.1109/TGRS.2012.2236338
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Herwig N. C., 2014, METHOD APPARATUS RED
   Hossain MS, 2018, FUTURE GENER COMP SY, V88, P333, DOI 10.1016/j.future.2018.05.050
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   IIZUKA J., 2017, INFORM PROCESSING AP
   Imari, 2015, FRONT COMP VIS FCV 2, P1
   Ishikawa T., 2018, INT ARCH PHOTOGRAMM, VXLII, P4
   Jana S, 2017, PROCEEDINGS OF 2ND INTERNATIONAL CONFERENCE ON 2017 DEVICES FOR INTEGRATED CIRCUIT (DEVIC), P620, DOI 10.1109/DEVIC.2017.8074025
   Jawale D, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1080, DOI 10.1109/ICCSP.2017.8286542
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jeon WS, 2017, INT J FUZZY LOG INTE, V17, P26, DOI 10.5391/IJFIS.2017.17.1.26
   Jhuria M, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P521, DOI 10.1109/ICIIP.2013.6707647
   Jiang LX, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P587, DOI 10.1109/ROBIO.2013.6739523
   Jiménez A, 1999, PATTERN RECOGN, V32, P1719, DOI 10.1016/S0031-3203(98)00170-8
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Julesz B., 1962, INF THEORY IRE T, V49, P41, DOI [10.1007/BF00344749, DOI 10.1007/BF00344749]
   Kabbai L, 2017, IET IMAGE PROCESS, V11, P109, DOI 10.1049/iet-ipr.2016.0349
   Kapach K., 2012, International Journal of Computational Vision and Robotics, V3, P4, DOI [DOI 10.1504/IJCVR.2012.046419, 10.1504/IJCVR.2012.046419]
   Khan I., 2013, IOSR J ELECT ELECT E, V8, P43, DOI DOI 10.9790/1676-0834353
   Khanal S, 2017, COMPUT ELECTRON AGR, V139, P22, DOI 10.1016/j.compag.2017.05.001
   Khoje S., 2013, Int J Eng Technol, V5, P3251, DOI DOI 10.1016/J.POSTHARVBIO.2013.02.016
   Kopf S, 2005, PROC SPIE, V5682, P114, DOI 10.1117/12.587946
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang HL, 2018, NEUROCOMPUTING, V283, P241, DOI 10.1016/j.neucom.2017.12.057
   Kumar G.S, 2012, International Journal of Computer Applications, V975, P8878
   Kurnianggoro L, 2015, INT C INT COMP, V12, P51, DOI [10.1007/978-3-319-42294-7, DOI 10.1007/978-3-319-42294-7]
   Kurnianggoro L, 2018, NEUROCOMPUTING, V300, P1, DOI 10.1016/j.neucom.2018.02.093
   Kurtulmus F, 2014, PRECIS AGRIC, V15, P57, DOI 10.1007/s11119-013-9323-8
   Kus Z, 2018, STUD SYST DECIS CONT, V106, P23, DOI 10.1007/978-3-319-64674-9_2
   Lacey S, 2007, PERCEPTION, V36, P1513, DOI 10.1068/p5850
   Lashgari M, 2017, INT FOOD RES J, V24, P1075
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376
   Lee S, 2013, C IND ELECT APPL, P1331
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li BR, 2018, INT J AGR BIOL ENG, V11, P192, DOI 10.25165/j.ijabe.20181101.2899
   Li DH, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P264, DOI 10.1109/ICMA.2017.8015825
   Li LH, 2018, IEEE T INTELL TRANSP, V19, P1664, DOI 10.1109/TITS.2017.2724138
   Liming X, 2010, COMPUT ELECTRON AGR, V71, pS32, DOI 10.1016/j.compag.2009.09.013
   Lin TY, 2016, PROC CVPR IEEE, P2791, DOI 10.1109/CVPR.2016.305
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Lisin D, 2005, 2005 IEEE COMP SOC C, P47, DOI [10.1109/CVPR.2005.433, 10/c3854f, DOI 10.1109/CVPR.2005.433]
   Liu HP, 2018, IEEE T AUTOM SCI ENG, V15, P784, DOI 10.1109/TASE.2017.2692271
   Liu HP, 2017, IEEE T AUTOM SCI ENG, V14, P996, DOI 10.1109/TASE.2016.2549552
   Liu L., 2018, ARXIV180110324
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Lopez JJ, 2011, NEURAL COMPUT APPL, V20, P975, DOI 10.1007/s00521-010-0396-2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv JD, 2016, OPTIK, V127, P1354, DOI 10.1016/j.ijleo.2015.10.177
   Maghrebi W., 2007, SYSTEM HISTORIC DOCU, P114
   Makino Y., 2016, Agricultural Sciences, V7, P327, DOI 10.4236/as.2016.76033
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Gila DM, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1651, DOI 10.1109/ICIT.2015.7125334
   Materka A, 1998, COST B11 report, V10, P4968
   Mély DA, 2016, VISION RES, V120, P93, DOI 10.1016/j.visres.2015.11.007
   Perez RM, 2017, COMPUT ELECTRON AGR, V139, P231, DOI 10.1016/j.compag.2017.05.014
   Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011
   Moradi G., 2011, IEEE ELECTR ENG, P11
   Mújica-Vargas D, 2013, PATTERN RECOGN LETT, V34, P400, DOI 10.1016/j.patrec.2012.10.004
   Naik S, 2017, 2017 INTERNATIONAL CONFERENCE ON EMERGING TRENDS & INNOVATION IN ICT (ICEI), P15, DOI 10.1109/ETIICT.2017.7977003
   Nandi CS, 2016, IEEE SENS J, V16, P6387, DOI 10.1109/JSEN.2016.2580221
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Nasirahmadi A, 2017, BIOSYST ENG, V156, P51, DOI 10.1016/j.biosystemseng.2017.01.008
   Novak C. L., 1992, COMP VIS PATT REC 19
   Okamoto H, 2009, COMPUT ELECTRON AGR, V66, P201, DOI 10.1016/j.compag.2009.02.004
   Ong SH, 2002, IMAGE VISION COMPUT, V20, P279, DOI 10.1016/S0262-8856(02)00021-5
   Oo LM, 2018, BIOSYST ENG, V170, P96, DOI 10.1016/j.biosystemseng.2018.04.004
   Ortaç G, 2015, IEEE INT SYMP SIGNAL, P227, DOI 10.1109/ISSPIT.2015.7394332
   Oyallon E, 2015, PROC CVPR IEEE, P2865, DOI 10.1109/CVPR.2015.7298904
   Pan Y, 2016, PROCEEDINGS OF 2016 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), P749, DOI 10.1109/ICCSNT.2016.8070258
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Pawar M. M., 2012, INT J COMPUT APPL, V43, P30
   Pendneault N., 2017, 3D OBJECT RECOGNITIO
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Pham VanHuy., 2015, Vietnam Journal of Computer Science, V2, P25, DOI [DOI 10.1007/S40595-014-0028-3, 10.1007/s40595-014-0028-3]
   Pydipati R, 2006, COMPUT ELECTRON AGR, V52, P49, DOI 10.1016/j.compag.2006.01.004
   Quevedo R, 2002, J FOOD ENG, V53, P361, DOI 10.1016/S0260-8774(01)00177-7
   Qureshi WS, 2017, PRECIS AGRIC, V18, P224, DOI 10.1007/s11119-016-9458-5
   Rachmawati E, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTER SCIENCE AND INFORMATICS (EECSI), P198
   Radojevic RL, 2011, AFR J AGR RES, V6, P3131
   Rajaby E, 2016, DIGIT SIGNAL PROCESS, V51, P170, DOI 10.1016/j.dsp.2016.01.010
   Rashedi E, 2013, ENG APPL ARTIF INTEL, V26, P1322, DOI 10.1016/j.engappai.2012.10.002
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Rocha A, 2010, COMPUT ELECTRON AGR, V70, P96, DOI 10.1016/j.compag.2009.09.002
   Rueden C., 2017, IMAGEJ, V26, P1452
   Sakai Y, 2016, 2016 10TH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS), P189, DOI 10.1109/IMIS.2016.84
   Salahat E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1059, DOI 10.1109/ICIT.2017.7915508
   Pereira LFS, 2018, COMPUT ELECTRON AGR, V145, P76, DOI 10.1016/j.compag.2017.12.029
   Schmid C., 2003, PATTERN RECOGN, V27, P1265
   Schmitz A, 2014, IEEE-RAS INT C HUMAN, P1044, DOI 10.1109/HUMANOIDS.2014.7041493
   Schwarz M, 2018, INT J ROBOT RES, V37, P437, DOI 10.1177/0278364917713117
   Pérez DS, 2017, COMPUT ELECTRON AGR, V135, P81, DOI 10.1016/j.compag.2017.01.020
   Sendin K, 2018, FOOD CHEM, V243, P311, DOI 10.1016/j.foodchem.2017.09.133
   Sharma G, 2016, COMPUT VIS IMAGE UND, V142, P13, DOI 10.1016/j.cviu.2015.09.007
   Shih JL, 2002, IEE P-VIS IMAGE SIGN, V149, P370, DOI 10.1049/ip-vis:20020614
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh C, 2013, MULTIMEDIA SYST, V19, P339, DOI 10.1007/s00530-012-0288-7
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Skretting K, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/52561
   Sonka M., 1993, Image Processing, Analysis and Machine Vision, DOI [DOI 10.1007/978-1-4899-3216-7, 10.1007/978-1-4899-3216-7]
   Sun SY, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881417752820
   Sun Y, 2017, LWT-FOOD SCI TECHNOL, V75, P557, DOI 10.1016/j.lwt.2016.10.006
   Szegedy C., 2017, AAAI, V4, P12
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tao YT, 2017, COMPUT ELECTRON AGR, V142, P388, DOI 10.1016/j.compag.2017.09.019
   Tashiro T., 2009, TERMINAL SELF CHECKO
   Terrades OR, 2007, PROC INT CONF DOC, P227
   Unay D, 2006, POSTHARVEST BIOL TEC, V42, P271, DOI 10.1016/j.postharvbio.2006.06.010
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Vidal A, 2013, FOOD BIOPROCESS TECH, V6, P3412, DOI 10.1007/s11947-012-1015-2
   Vijayarekha K., 2008, IECON 2008 - 34th Annual Conference of IEEE Industrial Electronics Society, P1499, DOI 10.1109/IECON.2008.4758175
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Vogl M, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P1497, DOI 10.1109/CSE.2014.278
   von Kries J., 1905, HDB PHYSIOLOGIE MENS, V3, P109
   Wachs J., 2009, P 7 EUR C PREC AGR, V68
   Wajid A., 2018, 2018 international conference on computing, mathematics and engineering technologies (iCoMET), P1, DOI DOI 10.1109/ICOMET.2018.8346354
   Wan P, 2018, COMPUT ELECTRON AGR, V146, P43, DOI 10.1016/j.compag.2018.01.011
   Wang F, 2017, NEUROCOMPUTING, V253, P193, DOI 10.1016/j.neucom.2016.10.090
   Wang S., 2011, INT C MED IM COMP CO, P66, DOI [10.1016/j.cogdev.2010.08.003.Personal, DOI 10.1016/J.COGDEV.2010.08.003.PERSONAL]
   Wang SH, 2015, ENTROPY-SWITZ, V17, P5711, DOI 10.3390/e17085711
   Wang XG, 2014, PATTERN RECOGN, V47, P2116, DOI 10.1016/j.patcog.2013.12.008
   Wang Y., 2009, P SPIE, V7513
   Wen XH, 2018, SOFT COMPUT, V22, P3533, DOI 10.1007/s00500-018-3108-y
   Xia S, 2017, NEUROCOMPUTING, V228, P11, DOI 10.1016/j.neucom.2016.09.087
   Xie JW, 2015, INT J COMPUT VISION, V114, P91, DOI 10.1007/s11263-014-0757-x
   Xiong JT, 2018, BIOSYST ENG, V166, P44, DOI 10.1016/j.biosystemseng.2017.11.005
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Yahaya OKM, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON ELECTRONIC DESIGN (ICED), P230, DOI 10.1109/ICED.2014.7015804
   Yamamoto K, 2014, SENSORS-BASEL, V14, P12191, DOI 10.3390/s140712191
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang M., 2010, PATTERN RECOGN
   Yin Ylei., 2018, Cranial morphology of Sinovenator changii (Theropoda: Troodontidae) on the new material from the Yixian Formation of western Liaoning, China, P1, DOI [10.1007/510586-018-1695-0, DOI 10.1007/510586-018-1695-0]
   Yoiyod P., 2017, COMPLEX RELATIVE PER, P8
   Yu K, 2011, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2011.5995732
   Zaborowicz M, 2017, SCI HORTIC-AMSTERDAM, V218, P222, DOI 10.1016/j.scienta.2017.02.001
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng GX, 2017, 2017 IEEE 3RD INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC), P613, DOI 10.1109/ITOEC.2017.8122370
   Zhang CS, 2017, EXPERT SYST APPL, V82, P128, DOI 10.1016/j.eswa.2017.04.003
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang H, 2018, POSTHARVEST BIOL TEC, V138, P11, DOI 10.1016/j.postharvbio.2017.12.002
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang YD, 2014, J FOOD ENG, V143, P167, DOI 10.1016/j.jfoodeng.2014.07.001
   Zhang YD, 2016, EXPERT SYST, V33, P239, DOI 10.1111/exsy.12146
   Zhao YS, 2016, COMPUT ELECTRON AGR, V127, P311, DOI 10.1016/j.compag.2016.06.022
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhou F, 2019, VISUAL COMPUT, V35, P1583, DOI 10.1007/s00371-018-1559-x
   Zhu B, 2007, J FOOD ENG, V81, P741, DOI 10.1016/j.jfoodeng.2007.01.008
   Zhu SC, 2000, IEEE T PATTERN ANAL, V22, P554, DOI 10.1109/34.862195
NR 227
TC 90
Z9 97
U1 7
U2 109
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2018
VL 80
BP 24
EP 44
DI 10.1016/j.imavis.2018.09.016
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HF6VQ
UT WOS:000454376800002
DA 2024-07-18
ER

PT J
AU Sankaran, A
   Vatsa, M
   Singh, R
   Majumdar, A
AF Sankaran, Anush
   Vatsa, Mayank
   Singh, Richa
   Majumdar, Angshul
TI Group sparse autoencoder
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Supervised autoencoder; Group sparsity; Latent fingerprint; Minutia
   extraction
ID NEURAL-NETWORKS; DEEP
AB Unsupervised feature extraction is gaining a lot of research attention following its success to represent any kind of noisy data. Owing to the presence of a lot of training parameters, these feature learning models are prone to overfitting. Different regularization methods have been explored in the literature to avoid overfitting in deep learning models. In this research, we consider autoencoder as the feature learning architecture and propose l(2.1)-norm based regularization to improve its learning capacity, called as Group Sparse AutoEncoder (GSAE). l(2.1) -norm is based on the postulate that the features from the same class will have a common sparsity pattern in the feature space. We present the learning algorithm for group sparse encoding using majorization-minimization approach. The performance of the proposed algorithm is also studied on three baseline image datasets: MNIST, CIFAR-10, and SVHN. Further, using GSAE, we propose a novel deep learning based image representation for minutia detection from latent fingerprints. Latent fingerprints contain only a partial finger region, very noisy ridge patterns, and depending on the surface it is deposited, contain significant background noise. We formulate the problem of minutia extraction as a two-class classification problem and learn the descriptor using the novel formulation of GSAE. Experimental results on two publicly available latent fingerprint datasets show that the proposed algorithm yields state-of-the-art results for automated minutia extraction. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Sankaran, Anush; Vatsa, Mayank; Singh, Richa; Majumdar, Angshul] IIIT, Delhi, India.
C3 Indraprastha Institute of Information Technology Delhi
RP Vatsa, M (corresponding author), IIIT, Delhi, India.
EM anushs@iiitd.ac.in; mayank@iiitd.ac.in; rsingh@iiitd.ac.in;
   angshul@iiitd.ac.in
RI Sankaran, Anush/X-4877-2019; Vatsa, Mayank/AAR-7199-2020; Singh,
   Richa/M-9961-2017
OI Vatsa, Mayank/0000-0001-5952-2274; Singh, Richa/0000-0003-4060-4573
CR [Anonymous], 2013, ADV NEURAL INFORM PR
   [Anonymous], 2014, INT C MACH LEARN
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2014, INTELLIGENT DATA ANA
   [Anonymous], NIST SPEC DAT 14
   [Anonymous], 2016, INT C ART INT STAT
   [Anonymous], 2014, INT C LEARN REPR ICL
   [Anonymous], 2011, NEURAL INFORM PROCES
   [Anonymous], 2013, Maxout networks
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], INT C AC SPEECH SIGN
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Blumensath T, 2013, IEEE T INFORM THEORY, V59, P3466, DOI 10.1109/TIT.2013.2245716
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Burges C. J, 2010, MNIST HANDWRITTEN DI
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155
   Frazao X, 2014, LECT NOTES COMPUT SC, V8814, P282, DOI 10.1007/978-3-319-11758-4_31
   Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Jia XF, 2012, INT C PATT RECOG, P3001
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Majumdar A, 2012, INT CONF ACOUST SPEE, P3421, DOI 10.1109/ICASSP.2012.6288651
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Sankaran A., 2011, Biometrics (IJCB), 2011 International Joint Conference On, P1, DOI [10.1109/IJCB.2011.6117525, DOI 10.1109/IJCB.2011.6117525]
   Sankaran A, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Sankaran A, 2017, PATTERN RECOGN, V61, P674, DOI 10.1016/j.patcog.2016.04.014
   Sankaran A, 2015, IEEE ACCESS, V3, P653, DOI 10.1109/ACCESS.2015.2428631
   Sankaran A, 2014, IEEE ACCESS, V2, P982, DOI 10.1109/ACCESS.2014.2349879
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661
   Swersky Kevin, 2011, P 28 INT C MACH LEAR, P1201
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wan L, 2013, P 30 INT C MACH LEAR, P1058, DOI DOI 10.5555/3042817.3043055
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Zheng ZL, 2006, IMAGE VISION COMPUT, V24, P819, DOI 10.1016/j.imavis.2006.02.007
NR 48
TC 37
Z9 40
U1 0
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 64
EP 74
DI 10.1016/j.imavis.2017.01.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800008
DA 2024-07-18
ER

PT J
AU Hu, Y
   Sirlantzis, K
   Howells, G
AF Hu, Yang
   Sirlantzis, Konstantinos
   Howells, Gareth
TI A novel iris weight map method for less constrained iris recognition
   based on bit stability and discriminability
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris recognition; Less constrained environment; Iris weight map
AB In this paper, we propose and investigate a novel iris weight map method for iris matching stage to improve less constrained iris recognition. The proposed iris weight map considers both intra-class bit stability and inter-class bit discriminability of iris codes. We model the infra-class bit stability in a stability map to improve the infra-class matching. The stability map assigns more weight to the bits that have values more consistent with their noiseless and stable estimates obtained using a low rank approximation from a set of noisy training images. Also, we express the inter-class bit discriminability in a discriminability map to enhance the inter-class separation. We calculate the discriminability map using a 1-to-N strategy, emphasizing the bits with more discriminative power in iris codes. The final iris weight map is the combination of the stability map and the discriminability map. We conduct experimental analysis on four publicly available datasets captured in varying less constrained conditions. The experimental results demonstrate that the proposed iris weight map achieves generally improved identification and verification performance compared to state-of-the-art methods. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Hu, Yang; Sirlantzis, Konstantinos; Howells, Gareth] Univ Kent, Canterbury, Kent, England.
C3 University of Kent
RP Hu, Y (corresponding author), Univ Kent, Canterbury, Kent, England.
EM yh94@kent.ac.uk
OI Hu, Yang/0000-0003-2388-7719; Sirlantzis,
   Konstantinos/0000-0002-0847-8880
CR [Anonymous], NEURAL INF PROCESS S
   [Anonymous], P IEEE
   [Anonymous], 2013, P 2013 IEEE 78 VEH T
   [Anonymous], INT JOINT C BIOM
   [Anonymous], AAAI C ART INT
   [Anonymous], 2003, Matlab source code for a biometric identification system based on iris patterns
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Bowyer KW, 2012, PATTERN RECOGN LETT, V33, P965, DOI 10.1016/j.patrec.2011.11.024
   Connaughton R, 2012, IEEE T INF FOREN SEC, V7, P919, DOI 10.1109/TIFS.2012.2190575
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   De Marsico M, 2014, IMAGE VISION COMPUT, V32, P1161, DOI 10.1016/j.imavis.2013.12.014
   Dong WB, 2011, IEEE T PATTERN ANAL, V33, P1744, DOI 10.1109/TPAMI.2010.227
   He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183
   Hollingsworth KP, 2009, IEEE T PATTERN ANAL, V31, P964, DOI 10.1109/TPAMI.2008.185
   Hu Y, 2015, PATTERN RECOGN LETT, V57, P24, DOI 10.1016/j.patrec.2014.12.012
   Kalka ND, 2010, IEEE T SYST MAN CY A, V40, P509, DOI 10.1109/TSMCA.2010.2041658
   Kong AWK, 2010, IEEE T IMAGE PROCESS, V19, P522, DOI 10.1109/TIP.2009.2033427
   Kumar A., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P303, DOI 10.1109/ICB.2012.6199824
   Li PH, 2012, INT C PATT RECOG, P2420
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Pillai JK, 2014, IEEE T PATTERN ANAL, V36, P73, DOI 10.1109/TPAMI.2013.98
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Proença H, 2015, IEEE T INF FOREN SEC, V10, P321, DOI 10.1109/TIFS.2014.2371691
   Proença H, 2012, IEEE T INF FOREN SEC, V7, P798, DOI 10.1109/TIFS.2011.2177659
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1502, DOI 10.1109/TPAMI.2009.140
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   Tan CW, 2014, IEEE T IMAGE PROCESS, V23, P3962, DOI 10.1109/TIP.2014.2337714
   Tan CW, 2012, IEEE T IMAGE PROCESS, V21, P4068, DOI 10.1109/TIP.2012.2199125
   Viola P, 2001, P 2001 IEEE COMP SOC, pII
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Xiao LH, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), DOI 10.1109/BTAS.2013.6712752
   Xiao LH, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P246, DOI 10.1109/ACPR.2013.34
NR 34
TC 8
Z9 8
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 168
EP 180
DI 10.1016/j.imavis.2016.05.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700016
DA 2024-07-18
ER

PT J
AU Leng, MJ
   Moutafis, P
   Kakadiaris, IA
AF Leng, Mengjun
   Moutafis, Panagiotis
   Kakadiaris, Ioannis A.
TI Joint prototype and metric learning for image set classification:
   Application to video face identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image set classification; Metric learning; Prototype learning; Video
   face recognition
AB In this paper, we address the problem of image set classification, where each set contains a different number of images acquired from the same subject. In most of the existing literature, each image set is modeled using all its available samples. As a result, the corresponding time and storage costs are high. To address this problem, we propose a joint prototype and metric learning approach. The prototypes are learned to represent each gallery image set using fewer samples without affecting the recognition performance. A Mahalanobis metric is learned simultaneously to measure the similarity between sets more accurately. In particular, each gallery set is represented as a regularized affine hull spanned by the learned prototypes. The set-to-set distance is optimized via updating the prototypes and the Mahalanobis metric in an alternating manner. To highlight the importance of representing image sets using fewer samples, we analyzed the corresponding test time complexity with respect to the number of images used per set. Experimental results using YouTube Celebrity, YouTube Faces, and ETH-80 datasets illustrate the efficiency on the task of video face recognition, and object categorization. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Leng, Mengjun; Moutafis, Panagiotis; Kakadiaris, Ioannis A.] Univ Houston, Dept Comp Sci, Computat Biomed Lab, 4800 Calhoun Rd, Houston, TX 77004 USA.
C3 University of Houston System; University of Houston
RP Kakadiaris, IA (corresponding author), Univ Houston, Dept Comp Sci, Computat Biomed Lab, 4800 Calhoun Rd, Houston, TX 77004 USA.
EM ioannisk@uh.edu
OI Kakadiaris, Ioannis/0000-0002-0591-1079
FU U.S. Army Research Laboratory [W911NF-13-1-0127]; UH Hugh Roy and Lillie
   Cranz Cullen Endowment Fund
FX This research was funded in part by the U.S. Army Research Laboratory
   (W911NF-13-1-0127) and the UH Hugh Roy and Lillie Cranz Cullen Endowment
   Fund. All statements of fact, opinion or conclusions contained herein
   are those of the authors and should not be construed as representing the
   official views or policies of the sponsors.
CR [Anonymous], COVARIANCE DISCRIMIN
   [Anonymous], SET TO SET DISTANCE
   [Anonymous], P AS C COMP VIS SING
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], DICT LEARNING SPARSE
   Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Chen SK, 2013, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2013.65
   Fan W., 2006, CVPR
   Hadid A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P813, DOI 10.1109/AFGR.2004.1301634
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Harandi M, 2013, IEEE I CONF COMP VIS, P3120, DOI 10.1109/ICCV.2013.387
   Harandi MT, 2014, LECT NOTES COMPUT SC, V8690, P17, DOI 10.1007/978-3-319-10605-2_2
   HIGHAM NJ, 1988, LINEAR ALGEBRA APPL, V103, P103, DOI 10.1016/0024-3795(88)90223-6
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   Kim M., 2008, PROC IEEE INT C COMP, P1
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Köstinger M, 2013, IEEE I CONF COMP VIS, P3112, DOI 10.1109/ICCV.2013.386
   LEIBE B, 2003, P IEEE COMP SOC C CO, V2, P1
   Leng Mengjun., 2015, 2015 IEEE 7th International Conference on Biometrics Theory, Applications and Systems (BTAS), P1
   Lu JW, 2013, IEEE I CONF COMP VIS, P329, DOI 10.1109/ICCV.2013.48
   Moutafis P., 2016, IEEE T CYBERN, VPP, P1
   Ng A. Y., 2002, Advances in Neural Information Processing Systems, P1473
   Shakhnarovich G, 2002, LECT NOTES COMPUT SC, V2352, P851, DOI 10.1007/3-540-47977-5_56
   Wang R., 2008, PROC IEEE INT C COMP, P1
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Wang W, 2015, PROC CVPR IEEE, P3395, DOI 10.1109/CVPR.2015.7298816
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wu Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.134
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
   Yang D, 2013, IEEE INT WORKSH COMP, P13, DOI 10.1109/CAMAD.2013.6708080
   Zhu PF, 2013, IEEE I CONF COMP VIS, P2664, DOI 10.1109/ICCV.2013.331
   Zhu PF, 2014, IEEE T INF FOREN SEC, V9, P1120, DOI 10.1109/TIFS.2014.2324277
NR 36
TC 1
Z9 2
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 204
EP 213
DI 10.1016/j.imavis.2016.06.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700019
DA 2024-07-18
ER

PT J
AU Tsiotsios, C
   Davison, AJ
   Kim, TK
AF Tsiotsios, Chourmouzios
   Davison, Andrew J.
   Kim, Tae-Kyun
TI Near-lighting Photometric Stereo for unknown scene distance and medium
   attenuation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Underwater vision; Photometric Stereo; Near-lighting; Uncalibrated
ID VISIBILITY; ENHANCEMENT; RECOVERY; SURFACES
AB Photometric Stereo in murky water is subject to light attenuation and near-field illumination, and the resulting image formation model is complex. Apart from the scene normals and albedo, the incident illumination varies per-pixel and it depends on the scene depth and the attenuation coefficient of the medium. When these are unknown, e.g. in a realistic scenario where a robotic platform explores an underwater scene (unknown shape and distance) within the dynamic subsea environment (unknown scattering level), Photometric Stereo becomes ambiguous. Previous approaches have tackled the problem by assuming distant-lighting and resorting to external hardware for estimating the unknown model variables. In our work, we show that the Photometric Stereo problem can be determined as soon as some additional constraints regarding the scene albedo and the presence of pixels with local intensity maxima within the image are incorporated into the optimization framework. Our proposed solution leads to effective Photometric Stereo and yields detailed 3D reconstruction of objects in murky water when the scene distance and the medium attenuation are unknown. We evaluate our work using both numerical simulations and real experiments in the controlled environment of a water tank and real port water using a remotely operated vehicle. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Tsiotsios, Chourmouzios; Davison, Andrew J.] Imperial Coll London, Dept Comp, London SW7 2AZ, England.
   [Kim, Tae-Kyun] Imperial Coll London, Elect & Elect Engn Dept, London SW7 2AZ, England.
C3 Imperial College London; Imperial College London
RP Tsiotsios, C (corresponding author), Imperial Coll London, Dept Comp, London SW7 2AZ, England.
EM c.tsiotsios@imperial.ac.uk; a.davison@imperial.ac.uk;
   tIc.kim@imperial.ac.uk
RI Kim, Tae-Kyun/HTL-2208-2023
OI Kim, Tae-Kyun/0000-0002-7587-6053
FU European Communities FP7 (NOPTILUS) [270180]
FX This work was supported by the contract 270180 of the European
   Communities FP7 (NOPTILUS). We are very grateful to Underwater Systems
   and Technologies Laboratory (LSTS) and OceanScan in Porto for the access
   to the ROV and the help with the port-water experiments.
CR [Anonymous], IEEE OCEANS
   [Anonymous], PHOTOMETRIC STEREO S
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], 2007, P COMP VIS PATT REC
   [Anonymous], MITIGATION CONTRAST
   [Anonymous], ARXIV160408789
   [Anonymous], REINHARD IMAGE STAT
   [Anonymous], INT J COMPUTER INFOR
   [Anonymous], 2013, P BRIT MACH VIS C
   [Anonymous], 2015, IEEE T PATTERN ANAL
   Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898
   Byrd RH, 1999, SIAM J OPTIMIZ, V9, P877, DOI 10.1137/S1052623497325107
   Cronin TW, 2003, INTEGR COMP BIOL, V43, P549, DOI 10.1093/icb/43.4.549
   Favaro P, 2012, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2012.6247754
   Foresti GL, 2001, IEEE T SYST MAN CY B, V31, P691, DOI 10.1109/3477.956031
   GARCIA RicardoALONSO., 2011, Papeles de Derecho Europeo e Integracion Regional, P1, DOI DOI 10.1016/B978-0-12-818783-8.00003-7
   Gracias N, 2013, OCEANS-IEEE, DOI 10.1109/OCEANS-Bergen.2013.6608142
   Gupta M., 2008, Pratical Guide to Vegetable Oil Processing, P1
   Iwahori Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P83, DOI 10.1109/ICPR.1990.118069
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Jaffe JS, 2007, OCEANS 2007 - EUROPE, VOLS 1-3, P182
   KOLAGANI N, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1759, DOI 10.1109/ROBOT.1992.220125
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Narasimhan SG, 2005, IEEE I CONF COMP VIS, P420
   Nayar S. K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P583, DOI 10.1109/CVPR.1993.341071
   Negahdaripour S, 2002, OCEANS 2002 MTS/IEEE CONFERENCE & EXHIBITION, VOLS 1-4, CONFERENCE PROCEEDINGS, P1010
   Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Oakley JP, 1998, IEEE T IMAGE PROCESS, V7, P167, DOI 10.1109/83.660994
   Papadhimitri T., 2014, P BRIT MACH VIS C
   Sarafraz A, 2010, OCEANS-IEEE
   Schechner Y.Y., 2004, P 2004 IEEE COMP SOC, P89, DOI [10.1109/CVPR.2004.1315078, DOI 10.1109/CVPR.2004.1315078]
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Tan KK, 2001, J OPT SOC AM A, V18, P2460, DOI 10.1364/JOSAA.18.002460
   Treibitz T, 2012, IEEE T IMAGE PROCESS, V21, P4662, DOI 10.1109/TIP.2012.2208978
   Treibitz T, 2009, IEEE T PATTERN ANAL, V31, P385, DOI 10.1109/TPAMI.2008.85
   Tsiotsios C, 2014, PROC CVPR IEEE, P2259, DOI 10.1109/CVPR.2014.289
   Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55
   Zhang SM, 2002, IEEE J OCEANIC ENG, V27, P100, DOI 10.1109/48.989895
NR 39
TC 10
Z9 11
U1 2
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 44
EP 57
DI 10.1016/j.imavis.2016.10.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800004
DA 2024-07-18
ER

PT J
AU Yuan, Y
   Qi, L
   Lu, XQ
AF Yuan, Yuan
   Qi, Lei
   Lu, Xiaoqiang
TI Action recognition by joint learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Action recognition; Sparse coding; Multinomial logistic
   regression (MLR); Joint learning
AB Due to the promising applications including video surveillance, video annotation, and interaction gaming, human action recognition from videos has attracted much research interest. Although various works have been proposed for human action recognition, there still exist many challenges such as illumination condition, viewpoint, camera motion and cluttered background. Extracting discriminative representation is one of the main ways to handle these challenges. In this paper, we propose a novel action recognition method that simultaneously learns middle-level representation and classifier by jointly training a multinomial logistic regression (MLR) model and a discriminative dictionary. In the proposed method, sparse code of low-level representation, conducting as latent variables of MLR, can capture the structure of low-level feature and thus is more discriminate. Meanwhile, the training of dictionary and MLR model are integrated into one objective function for considering the information of categories. By optimizing this objective function, we can learn a discriminative dictionary modulated by MLR and a MLR model driven by sparse coding. The proposed method is evaluated on YouTube action dataset and HMDB51 dataset. Experimental results demonstrate that our method is comparable with mainstream methods. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Yuan, Yuan; Qi, Lei; Lu, Xiaoqiang] Chinese Acad Sci, State Key Lab Transient Opt & Photon, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
C3 State Key Laboratory of Transient Optics & Photonics; Chinese Academy of
   Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS
RP Lu, XQ (corresponding author), Chinese Acad Sci, State Key Lab Transient Opt & Photon, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
EM luxq666666@gmail.com
RI Yuan, Yuan/ABB-2379-2020; yuan, Yuan/ISA-0923-2023; Yuan,
   Yuan/GVS-5120-2022
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ali S., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.382977
   [Anonymous], STRUCTURE PRESERVING
   [Anonymous], C COMP VIS PATT REC
   Bay H., 2008, COMPUTER VISION ECCV, V3951, P404
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cawley G.C., 2007, ADV NEURAL INFORM PR, V19, P209
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Kaghyan S., 2012, Int. J. Inform. Models Anal. (IJIMA) ITHEA Int. Sci. Soc. Bulg, V1, P146
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu L., 2015, LEARNING SPATIO TEMP
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Oikonomopoulos A., IEEE T SYST MAN CY B, V36
   Packer B, 2012, PROC CVPR IEEE, P1378, DOI 10.1109/CVPR.2012.6247824
   Psorakis I, 2010, IEEE T NEURAL NETWOR, V21, P1588, DOI 10.1109/TNN.2010.2064787
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shao L., 2015, INT J COMPUT VIS
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shi F, 2013, PROC CVPR IEEE, P2595, DOI 10.1109/CVPR.2013.335
   Suk HI, 2011, IEEE T CIRC SYST VID, V21, P932, DOI 10.1109/TCSVT.2011.2133570
   Thurau C., 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587721
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yuan F., 2012, Trends and Topics in Computer Vision, P168
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
NR 40
TC 12
Z9 14
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 77
EP 85
DI 10.1016/j.imavis.2016.04.001
PN 2
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300005
DA 2024-07-18
ER

PT J
AU Hu, YL
   Song, R
   Li, YS
   Rao, P
   Wang, YL
AF Hu, Yinlin
   Song, Rui
   Li, Yunsong
   Rao, Peng
   Wang, Yangli
TI Highly accurate optical flow estimation on superpixel tree
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optical flow; Motion estimation; Cost volume filtering; Super pixel
AB Formulated as a pixel-labeling problem, optical flow estimation using efficient edge-aware filtering has shown great success recently. However, the typical challenge that restricts the range of applicability of this method is the computational complexity mainly caused by the testing of every hypothetical label in the whole label space, which is usually large in an optical flow estimation. In this paper, we present an effective and efficient two-level filter-based optical flow algorithm connected by an accurate non-local matching. With the key observation that the optical flow of the pixels from the same compact superpixels is highly coherent, we propose a novel superpixel tree representation of an image to obtain an accurate superpixel flow. We find that if filtered separately, the candidate label space of the pixels from each superpixel is drastically reduced with the known superpixel flow. We also suggest a refined label selection strategy that is more accurate than the usual winner-takes-all manner. The proposed method, called Highly Accurate flow on Superpixel Tree (HastFlow) is validated on Middlebury and MPI-Sintel, and outperforms all filter-based methods both in accuracy and efficiency. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Hu, Yinlin; Song, Rui; Li, Yunsong; Wang, Yangli] Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Peoples R China.
   [Song, Rui; Rao, Peng] Chinese Acad Sci, Shanghai Inst Tech Phys, Key Lab Infrared Syst Detect & Imaging Technol, Shanghai, Peoples R China.
C3 Xidian University; Chinese Academy of Sciences; Shanghai Institute of
   Technical Physics, CAS
RP Li, YS (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Peoples R China.
EM huyinlin@gmail.com; rsong@xidian.edu.cn; ysli@mail.xidian.edu.cn;
   peng_rao@mail.sitp.ac.cn; yliwang@mail.xidian.edu.cn
RI chen, bin/KBQ-8114-2024
OI chen, bin/0000-0002-3398-1314; Hu, Yinlin/0000-0003-2614-5200
FU NSFC Grant [61401337, 61222101]; 111 Project [B08038, B08028]; Program
   of Innovative Research Team in Shaanxi Province; Fundamental Research
   Funds for the Central Universities; Key Laboratory of Infrared System
   Detection and Imaging Technology, Shanghai Institute of Technical
   Physics, Chinese Academy of Sciences
FX This work was supported by NSFC Grant (No. 61401337 and No. 61222101),
   the 111 Project (B08038 and B08028), Program of Innovative Research Team
   in Shaanxi Province, Fundamental Research Funds for the Central
   Universities, and Key Laboratory of Infrared System Detection and
   Imaging Technology, Shanghai Institute of Technical Physics, Chinese
   Academy of Sciences.
CR Amat F., 2013, BIOINFORMATICS
   [Anonymous], 2009, ICCV
   [Anonymous], EUROGRAPHICS
   [Anonymous], 2009, SIGGRAPH
   [Anonymous], 2010, ECCV
   [Anonymous], 2009, CVPR
   [Anonymous], 2011, ICCV
   [Anonymous], CVPR
   [Anonymous], 2011, PAMI
   [Anonymous], 2010, ECCV
   [Anonymous], 1984, SIGGRAPH
   [Anonymous], 2012, PAMI
   [Anonymous], 2014, CVPR
   [Anonymous], 2013, ICCV
   [Anonymous], 2007, CVPR
   [Anonymous], 2012, ECCV
   [Anonymous], 2015, CVPR
   [Anonymous], PAMI
   [Anonymous], IJCV
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Chang H.-S., 2013, ICIP
   Chen Z., 2013, CVPR
   Cheriton D., 1976, SICOMP
   Donne S., 2015, ADV CONCEPT INTELL V
   Gkamas T., 2011, DIGITAL SIGNAL PROCE
   He Kaiming, 2012, CVPR
   Horn B. K. P., 1981, Artificial Intelligence
   Korman S., 2011, ICCV
   Leordeanu M., 2013, ICCV
   Lu J., 2012, CVPR
   Lu J., 2013, P CVPR
   Ranftl Rene<prime>, 2014, ECCV
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Sun D., 2014, CVPR
   SZELISKI R, 2008, PAMI
   Xu L., 2012, PAMI
   Yang Q., 2012, CVPR
   YOON K, 2006, PAMI
NR 38
TC 15
Z9 17
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 167
EP 177
DI 10.1016/j.imavis.2016.06.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400013
DA 2024-07-18
ER

PT J
AU Dimitriou, N
   Delopoulos, A
AF Dimitriou, Nikolaos
   Delopoulos, Anastasios
TI Incorporating higher order models for occlusion resilient motion
   segmentation in streaming videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Motion segmentation; Trajectories; Occlusion; Object leakage; Graph
   coloring
ID OBJECTS
AB Video segmentation is a fundamental problem in computer vision and aims to extract meaningful entities from a video. One of the most useful cues in this quest is motion as is described by the trajectories of tracked points. In this paper we present a motion segmentation method attempting to address some of the major issues in the area. Namely, we propose an efficient framework where more complex motion models can be seamlessly integrated both maintaining computational tractability and not penalizing non translational motion. Moreover, we expose in depth the problem of object leakage due to occlusion and highlight that motion segmentation could be treated as a graph coloring problem. Our algorithm uses an approach based on graph theory and resolves occlusion cases in a robust manner. To endow our method with scalability, we follow the previously presented subsequence architecture and test it in a streaming setup. Extensive experiments demonstrate the flexibility and robustness of the method. The segmentation results are competitive compared to the state of the art. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Dimitriou, Nikolaos; Delopoulos, Anastasios] Aristotle Univ Thessaloniki, Dept Elect & Comp Engn, Multimedia Understanding Grp, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Dimitriou, N (corresponding author), Fac Engn Bldg C, Thessaloniki 54124, Greece.
EM nikdim@mug.ee.auth.gr; adelo@eng.auth.gr
RI Delopoulos, Anastasios/B-2140-2013; Dimitriou, Nikolaos/AAF-4700-2020;
   Delopoulos, Anastasios/ABB-6127-2021
OI Dimitriou, Nikolaos/0000-0002-6650-7758; 
CR [Anonymous], EUR C COMP VIS
   Arora S, 2009, J ACM, V56, DOI 10.1145/1502793.1502794
   Bowman A., 1997, Applied Smoothing Techniques for Data Analysis: The Kernel Approach with S-Plus Illustrations
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Chin T.-J., 2009, NIPS, P333
   Chin TJ, 2009, IEEE I CONF COMP VIS, P413, DOI 10.1109/ICCV.2009.5459150
   Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999
   Cover Thomas M, 1999, Elements of information theory
   Dimitriou N, 2014, IEEE IMAGE PROC, P4398, DOI 10.1109/ICIP.2014.7025892
   Dimitriou N, 2013, IMAGE VISION COMPUT, V31, P593, DOI 10.1016/j.imavis.2013.06.005
   Elhamifar E., 2009, IEEE COMPUTER VISION
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Fragkiadaki K., 2012, IEEE COMPUTER VISION
   Fragkiadaki K, 2011, PROC CVPR IEEE
   Galasso F., 2014, IEEE COMPUTER VISION
   GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Julesz B., 2006, Foundations of cyclopean perception
   Karp Richard M, 1972, COMPLEXITY COMPUTER, P85, DOI DOI 10.1007/978-1-4684-2001-2_9
   Koffka K., 1935, Principles of gestalt psychology
   Liu G., 2010, P INT C MACH LEARN, P663
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085
   Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Ochs P., 2012, IEEE COMPUTER VISION
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418
   Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32
   Tron R., 2007, IEEE COMPUTER VISION
   Williamson D. P., 2011, DESIGN APPROXIMATION, DOI DOI 10.1017/CBO9780511921735
NR 34
TC 9
Z9 9
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2015
VL 36
BP 70
EP 82
DI 10.1016/j.imavis.2015.01.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CG2GV
UT WOS:000353093800007
DA 2024-07-18
ER

PT J
AU Jimenez, D
   Pizarro, D
   Mazo, M
AF Jimenez, David
   Pizarro, Daniel
   Mazo, Manuel
TI Single frame correction of motion artifacts in PMD-based time of flight
   cameras
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Time of flight (ToF); Motion artifacts (MoArt); Photonic mixer devices
   (PMD); Motion flow; Phase-shift algorithm
AB One of the leading time of flight imaging technologies for depth sensing is based on Photonic Mixer Devices (PMD). In PMD sensors each pixel samples the correlation between emitted and received light signals. Current PMD cameras compute eight correlation samples per pixel in four sequential stages to obtain depth with invariance to signal amplitude and offset variations. With motion, PMD pixels capture different depths at each stage. As a result, correlation samples are not coherent with a single depth, producing artifacts. We propose to detect and remove motion artifacts from a single frame taken by a PMD camera. The algorithm we propose is very fast, simple and can be easily included in camera hardware. We recover depth of each pixel by exploiting consistency of the correlation samples and local neighbors of the pixel. In addition, our method obtains the motion flow of occluding contours in the image from a single frame. The system has been validated in real scenes using a commercial low-cost PMD camera and high speed dynamics. In all cases our method produces accurate results and it highly reduces motion artifacts. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Jimenez, David; Mazo, Manuel] Univ Alcala, Geintra Res Grp, Madrid 28871, Spain.
   [Pizarro, Daniel] Univ Auvergne, ALCoV ISIT, F-63001 Clermont Ferrand, France.
C3 Universidad de Alcala; Universite Clermont Auvergne (UCA)
RP Pizarro, D (corresponding author), Univ Auvergne, ALCoV ISIT, F-63001 Clermont Ferrand, France.
EM david.jimenez@depeca.uah.es; dani.pizarro@gmail.com; mazo@depeca.uah.es
OI Pizarro, Daniel/0000-0003-0622-4884
FU Spanish Ministry of Economy and Competitiveness under project SPACES-UAH
   [TIN2013-47630-C2-1-R]
FX This work has been supported by the Spanish Ministry of Economy and
   Competitiveness under project SPACES-UAH (TIN2013-47630-C2-1-R). The
   authors would like to thank Professor Adrien Bartoli, from the Advanced
   Laparoscopy and Computer Vision group.
CR [Anonymous], P SPIE EL IM
   [Anonymous], IEEE T INSTRUM MEAS
   [Anonymous], THESIS SIEGEN U
   [Anonymous], SPIE DEFENCE SECURIT
   [Anonymous], IMAGE VISION COMPUTI
   [Anonymous], THESIS U HEIDELBERG
   [Anonymous], REAL TIME PROCESSING
   Hoegg Thomas, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P273, DOI 10.1007/978-3-642-44964-2_13
   Hussmann Stephan, 2010, 2010 IEEE International Instrumentation & Measurement Technology Conference - I2MTC 2010, P697, DOI 10.1109/IMTC.2010.5488283
   Hussmann S., 2013, Em: Recent Advances in Topography Research, V1, P303
   Hussmann S, 2013, IEEE T INSTRUM MEAS, V62, P991, DOI 10.1109/TIM.2012.2232476
   Hussmann S, 2010, IEEE T INSTRUM MEAS, V59, P1175, DOI 10.1109/TIM.2010.2040881
   Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448
   Lindner M, 2006, LECT NOTES COMPUT SC, V4292, P524
   Lindner M, 2009, LECT NOTES COMPUT SC, V5742, P16, DOI 10.1007/978-3-642-03778-8_2
   Lottner O., 2007, INT S SIGN CIRC SYST, V1, P1
   Mufti F, 2011, ISPRS J PHOTOGRAMM, V66, P720, DOI 10.1016/j.isprsjprs.2011.06.004
   Schmidt M, 2011, INT CONF 3D IMAG
NR 18
TC 9
Z9 11
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1127
EP 1143
DI 10.1016/j.imavis.2014.08.014
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600014
DA 2024-07-18
ER

PT J
AU Osia, N
   Bourlai, T
AF Osia, N.
   Bourlai, T.
TI A spectral independent approach for physiological and geometric based
   face recognition in the visible, middle-wave and long-wave infrared
   bands
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Visible; Middle-wave infrared; Long-wave infrared;
   Fiducial point extraction and matching
ID EIGENFACES; FEATURES
AB The difficulty of face recognition (FR) systems to operate efficiently in diverse operational environments, e.g. day and nighttime, is aided by employing sensors covering different spectral bands (i.e. visible and infrared). Biometric practitioners have identified a framework of band-specific algorithms, which can contribute to both assessment and intervention. While these motions are proven to achieve improvement of identification performance, they traditionally result in solutions that typically fail to work efficiently across multiple spectrums. In this work, we designed and developed an efficient, fully automated, direct matching-based FR approach, that is designed to operate efficiently when face data is captured using either visible or passive infrared (IR) sensors. Thus, it can be applied in both daytime and nighttime environments. First, input face images are geometrically normalized using our pre-processing pipeline prior to feature-extraction. Then, face-based features including wrinkles, veins, as well as edges of facial characteristics, are detected and extracted for each operational band (visible, MWIR, and LWIR). Finally, global and local face-based matching is applied, before fusion is performed at the score level. Our approach achieves a rank-1 identification rate of at least 99.43%, regardless of the spectrum of operation. This suggests that our approach results in better performance than other tested standard commercial and academic face-based matchers, on all spectral bands used. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Osia, N.; Bourlai, T.] W Virginia Univ, Morgantown, WV 26506 USA.
C3 West Virginia University
RP Osia, N (corresponding author), W Virginia Univ, POB 6201, Morgantown, WV 26506 USA.
EM nosia@mix.wvu.edu; Thirimachos.Bourlai@mail.wvu.edu
OI Bourlai, Thirimachos/0000-0001-8751-0836
FU Office of Naval Research (ONR) [N00014-09-C-0495]
FX This work is sponsored in part by a grant from the Office of Naval
   Research (ONR), contract N00014-09-C-0495. We would like to acknowledge
   Dr. L Hornak for his valuable input during the initial phase of this
   work. Special thanks to Cameron Whitelam and Zain Jafri for their
   valuable input and help in eye detection experiments, as well as all WVU
   faculty and students that contributed in various parts of this research
   effort.
CR [Anonymous], ADV BIOMETRICS SENSO
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], THESIS HONG KONG BAP
   [Anonymous], IEEE C AUT FAC GEST
   [Anonymous], THESIS COLORADO STAT
   [Anonymous], 2006, 2006 C COMP VIS PATT
   [Anonymous], IEEE P PATT RECOGN
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], P IEEE CS C COMP VIS
   [Anonymous], BIOM DAT DISTR
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   [Anonymous], SPIE BIOMETRIC TECH
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bolme DS, 2003, LECT NOTES COMPUT SC, V2626, P304
   Bourlai T., 2012, Proceedings of the 2012 IEEE International Conference on Intelligence and Security Informatics. Cyberspace, Border, and Immigration Securities (ISI 2012), P196, DOI 10.1109/ISI.2012.6284307
   Bourlai T., 2011, IEEE INT WORK INF FO, P1
   Buddharaju P, 2007, IEEE T PATTERN ANAL, V29, P613, DOI 10.1109/TPAMI.2007.1007
   Chen X, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P127
   Franc V., 2004, Statistical Pattern Recognition Toolbox for Matlab
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain A.K., 1999, Biometrics: Personal Identification in Networked Security, P103
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Méndez H, 2009, LECT NOTES COMPUT SC, V5558, P327, DOI 10.1007/978-3-642-01793-3_34
   Miller JohnLester., 1994, Principles of Infrared Technology: A Practical Guide to the State of the Art
   Osia N, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, P273, DOI 10.1109/THS.2012.6459861
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pietäinen M, 2005, LECT NOTES COMPUT SC, V3540, P115
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   SOCOLINSKY DA, 2001, PROC CVPR IEEE, P527
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vedaldi A., 2010, VLFeat: An open and portable library of computer vision algorithms, P1469
   Whitelam C., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P209, DOI 10.1109/ICPR.2010.60
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 39
TC 16
Z9 24
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 847
EP 859
DI 10.1016/j.imavis.2014.06.010
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900003
DA 2024-07-18
ER

PT J
AU Yang, T
   Zhang, YN
   Yu, R
   Zhang, XQ
   Chen, T
   Ran, LY
   Song, ZX
   Ma, WG
AF Yang, Tao
   Zhang, Yanning
   Yu, Rui
   Zhang, Xiaoqiang
   Chen, Ting
   Ran, Lingyan
   Song, Zhengxi
   Ma, Wenguang
TI Simultaneous active camera array focus plane estimation and occluded
   moving object imaging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camera array; Occluded object imaging; Focus plane estimation; Synthetic
   aperture imaging
ID TRACKING; PEOPLE
AB Automatically focusing and seeing occluded moving object in cluttered and complex scene is a significant challenging task for many computer vision applications. In this paper, we present a novel synthetic aperture imaging approach to solve this problem. The unique characteristics of this work include the following: (1) To the best of our knowledge, this work is the first to simultaneously solve camera array auto focusing and occluded moving object imaging problem. (2) A unified framework is designed to achieve seamless interaction between the focusing and imaging modules. (3) In the focusing module, a local and global constraint-based optimization algorithm is presented to dynamically estimate the focus plane of the moving object. (4) In the imaging module, a novel visibility analysis based active synthetic aperture imaging approach is proposed to remove the occluder and significantly improve the quality of occluded object imaging. An active camera array system has been set up and evaluated in challenging indoor and outdoor scenes. Extensive experimental results with qualitative and quantitative analyses demonstrate the superiority of the proposed approach compared with state-of-the-art approaches. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Yang, Tao; Zhang, Yanning; Zhang, Xiaoqiang; Chen, Ting; Ran, Lingyan; Song, Zhengxi; Ma, Wenguang] Northwestern Polytech Univ, Sch Comp Sci, ShaanXi Prov Key Lab Speech & Image Informat Proc, Xian 710072, Peoples R China.
   [Yu, Rui] UCL, Dept Comp Sci, London, England.
C3 Northwestern Polytechnical University; University of London; University
   College London
RP Yang, T (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, ShaanXi Prov Key Lab Speech & Image Informat Proc, Xian 710072, Peoples R China.
EM yangtaonwpu@163.com
OI Ran, Lingyan/0000-0002-3084-9860
FU Project of National Natural Science Foundation of China [61272288,
   61231016, 61301192]; Funding of China Scholarship Council
   [201303070083]; NPU Foundation for New People and New Directions
   [13GH014604]; NPU Foundation for Fundamental Research [JC201120]; NPU;
   Foundation for Plan of Soaring Star [12GH0311]
FX We are very appreciative to the editor and anonymous reviewers for the
   valuable suggestions. This work is supported by the Project of National
   Natural Science Foundation of China (No. 61272288, No. 61231016, No.
   61301192), Funding of China Scholarship Council (No. 201303070083), NPU
   Foundation for New People and New Directions (No. 13GH014604), NPU
   Foundation for Fundamental Research (No. JC201120), NPU and Foundation
   for Plan of Soaring Star (No. 12GH0311).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], CS20050821 UCSD
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Cheng K.-W., 2008, Radar Conference, P1
   Ding YY, 2011, IEEE I CONF COMP VIS, P2478, DOI 10.1109/ICCV.2011.6126533
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Eshel R., 2008, IEEE C COMPUT VIS PA, P1
   Eshel R, 2010, INT J COMPUT VISION, V88, P129, DOI 10.1007/s11263-009-0307-0
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Joshi N., 2007, IEEE INT C COMPUTER, P1
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102
   Lei C, 2009, IEEE I CONF COMP VIS, P1570, DOI 10.1109/ICCV.2009.5459357
   Levoy M, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.270
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maitre M., 2008, Proc. IEEE CVPR, P1
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Schuchert T, 2010, LECT NOTES COMPUT SC, V6314, P596, DOI 10.1007/978-3-642-15561-1_43
   Tao Yang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3409, DOI 10.1109/CVPR.2011.5995417
   Vaish V, 2004, PROC CVPR IEEE, P2
   Vaish V., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.244
   Wang XG, 2010, IEEE T PATTERN ANAL, V32, P56, DOI 10.1109/TPAMI.2008.241
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Yang J. C., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P77
   Yao Y., 2008, Proc. IEEE Comp. Soc. Conf. Computer Vision and Pattern Recognition, P1
NR 25
TC 10
Z9 11
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 510
EP 521
DI 10.1016/j.imavis.2014.05.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600006
DA 2024-07-18
ER

PT J
AU Chau, DP
   Thonnat, M
   Brémond, F
   Corvée, E
AF Chau, Duc Phu
   Thonnat, Monique
   Bremond, Francois
   Corvee, Etienne
TI Online parameter tuning for object tracking algorithms
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object tracking; Online parameter tuning; Controller; Self-adaptation;
   Machine learning
AB Object tracking quality usually depends on video scene conditions (e.g. illumination, density of objects, object occlusion level). In order to overcome this limitation, this article presents a new control approach to adapt the object tracking process to the scene condition variations. More precisely, this approach learns how to tune the tracker parameters to cope with the tracking context variations. The tracking context, or context, of a video sequence is defined as a set of six features: density of mobile objects, their occlusion level, their contrast with regard to the surrounding background, their contrast variance, their 2D area and their 2D area variance. In an offline phase, training video sequences are classified by clustering their contextual features. Each context cluster is then associated to satisfactory tracking parameters. In the online control phase, once a context change is detected, the tracking parameters are tuned using the learned values. The approach has been experimented with three different tracking algorithms and on long, complex video datasets. This article brings two significant contributions: (1) a classification method of video sequences to learn offline tracking parameters and (2) a new method to tune online tracking parameters using tracking context. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Chau, Duc Phu; Thonnat, Monique; Bremond, Francois; Corvee, Etienne] INRIA Sophia Antipolis Mediterranee, STARS Team, F-06902 Sophia Antipolis, France.
RP Chau, DP (corresponding author), INRIA Sophia Antipolis Mediterranee, STARS Team, 2004 Route Lucioles, F-06902 Sophia Antipolis, France.
EM Duc-Phu.Chau@inria.fr; Monique.Thonnat@inria.fr;
   Francois.Bremond@inria.fr; Etienne.Corvee@inria.fr
CR Alahi A., 2009, INT WORKSH PERF EV T
   Andriluka M., 2010, INT C COMP VIS PATT
   Andriyenko A., 2011, INT C COMP VIS PATT
   [Anonymous], INT C ADV VID SIGN B
   [Anonymous], 2011, INT C IM CRIM DET PR
   Arsic D., 2009, INT WORKSH PERF EV T
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Berclaz J., 2009, INT WORKSH PERF EV T
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Breitenstein M.D., 2009, INT WORKSH PERF EV T
   Caporossi A., 2004, WORKSH PERF EV TRACK
   Chau D.P., 2011, INT C COMP VIS THEOR
   Corvee E., 2010, INT C ADV VID SIGN B
   Everitt B., 2001, Cluster analysis
   Freund Y., 1997, J COMPUT SYST SCI, P522
   Ge W., 2009, INT WORKSH PERF EV T
   Georis B, 2007, MACH VISION APPL, V18, P189, DOI 10.1007/s00138-006-0053-z
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Hall D, 2006, IMAGE VISION COMPUT, V24, P870, DOI 10.1016/j.imavis.2006.02.011
   Henriques J.F., 2011, INT C COMP VIS ICCV
   Heyer LJ, 1999, GENOME RES, V9, P1106, DOI 10.1101/gr.9.11.1106
   Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Kim K., 2004, INT C IM PROC ICIP S
   Kuo C., 2011, INT C COMP VIS PATT
   Kuo C.H., 2010, INT C COMP VIS PATT
   Li Y., 2009, INT C COMP VIS PATT
   Nievergelt J., 2000, C CURR TRENDS THEOR
   Santner J., 2010, INT C COMP VIS PATT
   Sherrah J, 2010, LECT NOTES COMPUT SC, V6474, P414, DOI 10.1007/978-3-642-17688-3_39
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shitrit H.B., 2011, INT C COMP VIS ICCV
   Souded M., 2011, INT C IM CRIM DET PR
   Thonnat M., 1999, INT C COMP VIS SYST
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xing J., 2009, INT C COMP VIS PATT
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 37
TC 7
Z9 8
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2014
VL 32
IS 4
BP 287
EP 302
DI 10.1016/j.imavis.2014.02.003
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AG0MN
UT WOS:000335109700006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, BS
   Park, JY
   Gilbert, AC
   Savarese, S
AF Kim, Byung-soo
   Park, Jae Young
   Gilbert, Anna C.
   Savarese, Silvio
TI Hierarchical classification of images by sparse approximation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sparse approximation; Sparse sensing; Sparsity; Image classification;
   Hierarchy; Structured data classification
AB Using image hierarchies for visual categorization has been shown to have a number of important benefits. Doing so enables a significant gain in efficiency (e.g., logarithmic with the number of categories [16,12]) or the construction of a more meaningful distance metric for image classification [17]. A critical question, however, still remains controversial: would structuring data in a hierarchical sense also help classification accuracy? In this paper we address this question and show that the hierarchical structure of a database can be indeed successfully used to enhance classification accuracy using a sparse approximation framework. We propose a new formulation for sparse approximation where the goal is to discover the sparsest path within the hierarchical data structure that best represents the query object. Extensive quantitative and qualitative experimental evaluation on a number of branches of the Imagenet database [7] as well as on the Caltech-256 [12] demonstrate our theoretical claims and show that our approach produces better hierarchical categorization results than competing techniques. (C) 2013 Published by Elsevier B.V.
RP Kim, BS (corresponding author), EECS Bldg 4338,1301 Beal Ave, Ann Arbor, MI 48109 USA.
EM bsookim@umich.edu; jaeypark@umich.edu; annacg@umich.edu;
   silvio@eecs.umich.edu
CR [Anonymous], 2007, 2007 IEEE 11 INT C C
   [Anonymous], P 2008 IEEE C COMP V
   [Anonymous], 2004, WORKSH STAT LEARN CO
   [Anonymous], BAGS FEATURES SPATIA
   [Anonymous], P CVPR
   Baraniuk R.G., 2008, Model-based compressive sensing
   Binder A., 2003, EFFICIENT CLASSIFICA
   BLUMENSATH T, 2007, IEEE T INFORM THEORY, V2007, P30
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen S. S., 1996, SIAM J SCI COMPUT, V20
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Everingham M., 2006, WORKSH ECCV06 CIT MA
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Grauman K., 2005, The pyramid match kernel: Discriminative classification with sets of image features
   Griffin G., Caltech-256 object category dataset
   Hastie T, 1996, J ROY STAT SOC B, V58, P155
   La C., IEEE INT C IM PROC I, P1277
   Mairal J., 2009, J MACHINE LEARNING R, V11, P1
   Marszalek M., 2007, SEMANTIC HIERARCHIES
   Palmer S., 1999, VISION SCI PHOTONS P
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tsochantaridis I., 2004, ICML, P104
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
NR 23
TC 6
Z9 6
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2013
VL 31
IS 12
BP 982
EP 991
DI 10.1016/j.imavis.2013.10.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 282DU
UT WOS:000329151300008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Orozco, J
   Rudovic, O
   Gonzàlez, J
   Pantic, M
AF Orozco, Javier
   Rudovic, Ognjen
   Gonzalez, Jordi
   Pantic, Maja
TI Hierarchical On-line Appearance-Based Tracking for 3D head pose,
   eyebrows, lips, eyelids and irises
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE On-line appearance models; Levenberg-Marquardt algorithm; Line-search
   optimization; 3D face tracking; Facial action tracking; Eyelid tracking;
   Iris tracking
ID MODEL; RECOGNITION; FACE
AB In this paper, we propose an On-line Appearance-Based Tracker (OABT) for simultaneous tracking of 3D head pose, lips, eyebrows, eyelids and irises in monocular video sequences. In contrast to previously proposed tracking approaches, which deal with face and gaze tracking separately, our OABT can also be used for eyelid and iris tracking, as well as 3D head pose, lips and eyebrows facial actions tracking. Furthermore, our approach applies an on-line learning of changes in the appearance of the tracked target. Hence, the prior training of appearance models, which usually requires a large amount of labeled facial images, is avoided. Moreover, the proposed method is built upon a hierarchical combination of three OABTs, which are optimized using a Levenberg-Marquardt Algorithm (LMA) enhanced with line-search procedures. This, in turn, makes the proposed method robust to changes in lighting conditions, occlusions and translucent textures, as evidenced by our experiments. Finally, the proposed method achieves head and facial actions tracking in real-time. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Orozco, Javier; Rudovic, Ognjen; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
   [Pantic, Maja] Univ Twente, EEMCS, Twente, Netherlands.
   [Gonzalez, Jordi] Comp Vis Ctr, Barcelona, Spain.
C3 Imperial College London; University of Twente; Centre de Visio per
   Computador (CVC)
RP Orozco, J (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
EM forozcoc@imperial.ac.uk
RI Gonzàlez, Jordi/I-1812-2015
OI Gonzàlez, Jordi/0000-0001-8033-0306
FU European Research Council [ERC-2007-StG-203143]; European Community
   [231287]; Consolider-Ingenio [MIPRCV-CSD200700018]; Avanza I+D ViCoMo
   [TSI-020400-2009-133, DiCoMa TSI-020400-2011-55]; 
   [TIN2009-14501-C02-01];  [TIN2009-14501-C02-02]
FX This work has been supported by the European Research Council under the
   ERC starting grant agreement no. ERC-2007-StG-203143 (MAHNOB). The work
   of Javier Orozco was also supported in part by the European Community's
   7th Framework Programme [FP7/20072013] under grant agreement no. 231287
   (SSPNet). The work of Jordi Gonzalez was supported by the
   Consolider-Ingenio2010 MIPRCV-CSD200700018; Avanza I+D ViCoMo,
   TSI-020400-2009-133 and DiCoMa TSI-020400-2011-55; along with the
   Spanish projects TIN2009-14501-C02-01 and TIN2009-14501-C02-02.
CR Ahlberg J, 2002, EURASIP J APPL SIG P, V2002, P566, DOI 10.1155/S1110865702203078
   ALOIMONOS JY, 1990, IMAGE VISION COMPUT, V8, P179, DOI 10.1016/0262-8856(90)90064-C
   Andrei N., 2005, NEW GRADIENT DESCENT
   [Anonymous], 2004, Statistical Models of Appearance for Computer Vision
   [Anonymous], LITHISYR2326 DEP EL
   [Anonymous], 2012, IEEE T PATTERN ANAL
   Castet E, 2000, NAT NEUROSCI, V3, P177, DOI 10.1038/72124
   Cauchy M. A., 1847, Comp. Rend. Sci. Paris, V25, P536
   Clark D., 2000, INFORM SCI DISCUSSIO, V19, P1
   Cootes T., FGNETIST200026434
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dornaika F, 2007, J REAL-TIME IMAGE PR, V2, P35, DOI 10.1007/s11554-007-0032-2
   Ekman P, 1978, FACIAL ACTION CODING
   Gokturk SB, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P701, DOI 10.1109/ICCV.2001.937695
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Ishikawa Takahiro, 2004, CMURITR0408
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164, DOI [10.1090/QAM/10666, DOI 10.1090/QAM/10666]
   Liu H, 2002, P SOC PHOTO-OPT INS, V4875, P693, DOI 10.1117/12.477054
   Liu XM, 2010, IMAGE VISION COMPUT, V28, P1162, DOI 10.1016/j.imavis.2009.09.016
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Matthews I., 2002, CMURITR0302
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Moriyama T, 2006, IEEE T PATTERN ANAL, V28, P738, DOI 10.1109/TPAMI.2006.98
   Moriyama T, 2002, INT C PATT RECOG, P78, DOI 10.1109/ICPR.2002.1047404
   Nocedal J., 1999, NUMERICAL OPTIMIZATI
   Nuevo J, 2011, IMAGE VISION COMPUT, V29, P209, DOI 10.1016/j.imavis.2010.11.004
   Ong EJ, 2011, IEEE T PATTERN ANAL, V33, P1844, DOI 10.1109/TPAMI.2010.205
   Orozco J, 2009, MACH VISION APPL, V20, P353, DOI 10.1007/s00138-008-0130-6
   Rydfalk M., 1987, TECHNICAL REPORT
   Shewchuk J. R., 1994, INTRO CONJUGATE GRAD
   Sirohey S, 2002, PATTERN RECOGN, V35, P1389, DOI 10.1016/S0031-3203(01)00116-9
   Sung J, 2009, PATTERN RECOGN LETT, V30, P359, DOI 10.1016/j.patrec.2008.11.006
   Taylor JR, 1999, EXP NEUROL, V158, P214, DOI 10.1006/exnr.1999.7093
   Valenti R, 2012, INT J COMPUT VISION, V98, P324, DOI 10.1007/s11263-011-0511-6
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Wu YW, 2004, IEEE SYS MAN CYBERN, P604
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 44
TC 28
Z9 29
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2013
VL 31
IS 4
BP 322
EP 340
DI 10.1016/j.imavis.2013.02.001
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 136QV
UT WOS:000318379400003
OA Green Published
DA 2024-07-18
ER

PT J
AU Koelstra, S
   Patras, I
AF Koelstra, Sander
   Patras, Ioannis
TI Fusion of facial expressions and EEG for implicit affective tagging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Emotion classification; EEG; Facial expressions; Signal processing;
   Pattern classification; Affective computing
ID RECOGNITION; EMOTION
AB The explosion of user-generated, untagged multimedia data in recent years, generates a strong need for efficient search and retrieval of this data. The predominant method for content-based tagging is through slow, labor-intensive manual annotation. Consequently, automatic tagging is currently a subject of intensive research. However, it is clear that the process will not be fully automated in the foreseeable future. We propose to involve the user and investigate methods for implicit tagging, wherein users' responses to the interaction with the multimedia content are analyzed in order to generate descriptive tags.
   Here, we present a multi-modal approach that analyses both facial expressions and electroencephalography (EEG) signals for the generation of affective tags. We perform classification and regression in the valence-arousal space and present results for both feature-level and decision-level fusion. We demonstrate improvement in the results when using both modalities, suggesting the modalities contain complementary information. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Koelstra, Sander; Patras, Ioannis] QMUL, Sch Comp Sci & Elect Engn, London E1 4NS, England.
C3 University of London; Queen Mary University London
RP Koelstra, S (corresponding author), QMUL, Sch Comp Sci & Elect Engn, Mile End Rd, London E1 4NS, England.
EM sander.koelstra@eecs.qmul.ac.uk; i.patras@eecs.qmul.ac.uk
OI Patras, Ioannis/0000-0003-3913-4738
FU EPSRC [EP/G033935/1] Funding Source: UKRI
CR [Anonymous], P AFF BRAIN COMP INT
   Arapakis I., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P461, DOI DOI 10.1145/1631272.1631336
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Barry RJ, 2007, CLIN NEUROPHYSIOL, V118, P2765, DOI 10.1016/j.clinph.2007.07.028
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Chanel G, 2009, INT J HUM-COMPUT ST, V67, P607, DOI 10.1016/j.ijhcs.2009.03.005
   Cowell AJ, 2008, LECT NOTES ARTIF INT, V4650, P17, DOI 10.1007/978-3-540-89430-8_2
   Cuthbert BN, 2000, BIOL PSYCHOL, V52, P95, DOI 10.1016/S0301-0511(99)00044-7
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P., 2005, WHAT FACE REVEALS BA
   el Kaliouby R, 2005, REAL-TIME VISION FOR HUMAN-COMPUTER INTERACTION, P181
   Elsayed T., 2008, STUDYING FACIAL EXPR
   Gerson AD, 2006, IEEE T NEUR SYS REH, V14, P174, DOI 10.1109/TNSRE.2006.875550
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Hyvärinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Jiao J., 2010, P 2 INT WORKSH SOC S, P59
   Kapoor A., 2008, P IEEE C AUT FAC GES, P1, DOI DOI 10.1109/CVPR.2008.4587618
   Kim Y.E., 2008, ISMIR 08 P 2008 INT, P231
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Koelstra S, 2010, LECT NOTES ARTIF INT, V6334, P89, DOI 10.1007/978-3-642-15314-3_9
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Lang P. J., 2005, A6 U FLOR CTR RES PS
   Lee JS, 2008, IEEE T MULTIMEDIA, V10, P767, DOI 10.1109/TMM.2008.922789
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI [10.1162/neco.1992.4.3.415, 10.1162/neco.1992.4.3.448]
   Mandel M, 2008, J NEW MUSIC RES, V37, P151, DOI 10.1080/09298210802479300
   McDuff D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), P17, DOI [DOI 10.1109/CVPRW.2010.5543833, 10.1109/CVPRW.2010.5543833]
   Morris JD, 1995, J ADVERTISING RES, V35, P63
   Olofsson JK, 2008, BIOL PSYCHOL, V77, P247, DOI 10.1016/j.biopsycho.2007.11.006
   Onton J, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.061.2009
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M., 2007, MACHINE ANAL FACIAL
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Sebe N., 2005, HDB PATTERN RECOGNIT, P387, DOI DOI 10.1142/9789812775320_0021
   Soleymani M., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P803, DOI 10.1109/FG.2011.5771352
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Takahashi K, 2003, IEEE SYS MAN CYBERN, P1654
   Vinciarelli A, 2009, IEEE INT CON MULTI, P1428, DOI 10.1109/ICME.2009.5202770
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   VONAHN L, 2006, P SIGCHI C HUM FACT, P55, DOI DOI 10.1145/1124772.1124782
   Williams ACD, 2002, BEHAV BRAIN SCI, V25, P439, DOI 10.1017/S0140525X02000080
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 44
TC 138
Z9 155
U1 6
U2 61
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2013
VL 31
IS 2
BP 164
EP 174
DI 10.1016/j.imavis.2012.10.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 102KN
UT WOS:000315843600006
DA 2024-07-18
ER

PT J
AU Liu, YG
   Liu, BB
   Pu, YF
   Chen, XH
   Cheng, H
AF Liu, Yiguang
   Liu, Bingbing
   Pu, Yifei
   Chen, Xiaohui
   Cheng, Hong
TI Low-rank matrix decomposition in <i>L</i><sub>1</sub>-norm by dynamic
   systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Low-rank matrix approximation; Dynamic system; L-1 norm; Computational
   efficiency
ID FACTORIZATION; MOTION; SHAPE; EIGENVECTORS; EIGENVALUES; ALGORITHMS
AB Low-rank matrix approximation is used in many applications of computer vision, and is frequently implemented by singular value decomposition under L-2-norm sense. To resist outliers and handle matrix with missing entries, a few methods have been proposed for low-rank matrix approximation in L-1 norm. However, the methods suffer from computational efficiency or optimization capability. Thus, in this paper we propose a solution using dynamic system to perform low-rank approximation under L-1-norm sense. From the state vector of the system, two low-rank matrices are distilled, and the product of the two low-rank matrices approximates to the given measurement matrix with missing entries, in L-1 norm. With the evolution of the system, the approximation accuracy improves step by step. The system involves a parameter, whose influences on the computational time and the final optimized two low-rank matrices are theoretically studied and experimentally valuated. The efficiency and approximation accuracy of the proposed algorithm are demonstrated by a large number of numerical tests on synthetic data and by two real datasets. Compared with state-of-the-art algorithms, the newly proposed one is competitive. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Liu, Yiguang; Pu, Yifei] Sichuan Univ, Vis & Image Proc Lab, Coll Comp, Chengdu 610065, Peoples R China.
   [Liu, Yiguang; Chen, Xiaohui] China Three Gorges Univ, Coll Comp & Informat Technol, Yichang 443002, Peoples R China.
   [Cheng, Hong] Univ Elect Sci & Technol China, Pattern Recognit & Machine Intelligence Lab, Chengdu 611731, Peoples R China.
   [Liu, Bingbing] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.
C3 Sichuan University; China Three Gorges University; University of
   Electronic Science & Technology of China; Agency for Science Technology
   & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Liu, YG (corresponding author), Sichuan Univ, Vis & Image Proc Lab, Coll Comp, Chengdu 610065, Peoples R China.
EM liuyg@scu.edu.cn
RI Liu, Yiguang/C-6404-2011; Liu, Bingbing/B-7832-2012
OI Chen, XiaoHui/0000-0001-7292-3646; Liu, Bingbing/0000-0002-5272-3425
FU NSFC [61173182, 61179071]; Applied Basic Research Project [2011JY0124];
   International Cooperation and Exchange Project of Sichuan Province
   [2012HH0004]
FX This work was supported by NSFC under grants 61173182 and 61179071, as
   well as by Applied Basic Research Project (2011JY0124) and International
   Cooperation and Exchange Project (2012HH0004) of Sichuan Province.
CR [Anonymous], AUST ADV WORK COMPUT
   Buchanan AM, 2005, PROC CVPR IEEE, P316
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chen P, 2008, INT J COMPUT VISION, V80, P125, DOI 10.1007/s11263-008-0135-7
   Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Jia HJ, 2009, IEEE T PATTERN ANAL, V31, P841, DOI 10.1109/TPAMI.2008.122
   Ke QF, 2005, PROC CVPR IEEE, P739
   KHALIL H., 2014, Nonlinear Systems, V3rd
   Liu J, 2010, IEEE T NEURAL NETWOR, V21, P621, DOI 10.1109/TNN.2010.2040290
   Liu YG, 2005, NEURAL NETWORKS, V18, P1293, DOI 10.1016/j.neunet.2005.04.008
   Liu YG, 2006, THEOR COMPUT SCI, V367, P273, DOI 10.1016/j.tcs.2006.05.026
   Liu YG, 2011, IEEE T NEURAL NETWOR, V22, P1256, DOI 10.1109/TNN.2011.2153210
   Mandic DP, 2004, IEEE SIGNAL PROC LET, V11, P115, DOI 10.1109/LSP.2003.821649
   Morgan A. B., 2004, TECHNICAL REPORT
   Morita T, 1997, IEEE T PATTERN ANAL, V19, P858, DOI 10.1109/34.608289
   Okatani T, 2007, INT J COMPUT VISION, V72, P329, DOI 10.1007/s11263-006-9785-5
   Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138
   Toh KC, 2010, PAC J OPTIM, V6, P615
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752
   Wang GH, 2008, IEEE T SYST MAN CY B, V38, P90, DOI 10.1109/TSMCB.2007.910534
   Weickert J, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P3
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6
NR 25
TC 5
Z9 5
U1 2
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2012
VL 30
IS 11
BP 915
EP 921
DI 10.1016/j.imavis.2012.06.012
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 052CW
UT WOS:000312176300010
DA 2024-07-18
ER

PT J
AU Ming, Y
   Ruan, QQ
AF Ming, Yue
   Ruan, Qiuqi
TI Robust sparse bounding sphere for 3D face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face recognition; Robust sparse bounding sphere representation;
   Bounding sphere representation; Rank minimization; Robust group sparse
   regression model
ID EIGENFACES
AB A robust sparse bounding sphere representation (RSBSR) is proposed to analyze 3D facial data. There are many obstacles to distinguishing facial differences, such as large pose and expression variations, hair occlusions and noise corruptions. In our framework, 3D point clouds are first preprocessed to remove the irrelevant areas and to align with a frontal neutral face model for overcoming the influence of large pose variations based on axis-angle representation. Then, 3D facial models are projected on the bounding spheres to describe both the depth and 3D geometric shape information, referred to as bounding sphere representation (BSR). This descriptor has the potential of decreasing the influence of large expression and pose variations on each normalized face within the corresponding spherical domain. Next, a robust group sparse regression model (RGSRM) is proposed to estimate the regression matrix, which preserves the intrinsic discriminant information. By embedding the descriptors into the low dimensional regression matrix, hair occlusions and artifacts can be treated as corruptions and can be patched. Under the constraints of Spectral Regression and corruptions, noise corruptions can be removed and the remaining small variations can be further corrected. FRGC v2.0 and CASIA 3D face databases are introduced to examine the performance of our framework and the previous algorithms with different schemes, and the experimental results show our proposed framework has the performance of simple implementation, high accuracy and low computational complexity. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Ming, Yue; Ruan, Qiuqi] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Ming, Y (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM myname35875235@126.com
FU National Natural Science Foundation [60973060]; Research Fund for the
   Doctoral Program [20080004001]; Beijing Program [YB20081000401];
   Fundamental Research Funds for the Central Universities [2009YJS025]
FX This work is supported by National Natural Science Foundation
   (60973060), the Research Fund for the Doctoral Program (20080004001) and
   Beijing Program (YB20081000401) and the Fundamental Research Funds for
   the Central Universities (2009YJS025). Portions of the research in this
   paper use the CASIA 3D Face Database collected by The institute of
   Automatic, Chinese Academy of Science. The authors would like to thank
   Prof. Patrick Flynn for sharing with us the UND (University of Notre
   Dame) Biometrics database. The authors would like also thank the
   Associate Editor and the anonymous reviewers for their helpful comments.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alyüz N, 2010, IEEE T INF FOREN SEC, V5, P425, DOI 10.1109/TIFS.2010.2054081
   [Anonymous], P IJCAI
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2006, MODEL SELECTION ESTI
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   [Anonymous], UILUENG092215
   [Anonymous], 2009, ADV NEUR INF PROC SY
   [Anonymous], ORAL HLTH STATUS ORA
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Cai D., 2007, PROC IEEE 11 INT C C
   Candes E.J., 2009, FOUND COMPUT MATH, P1
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   Chen X.H., 2011, A Study on Sedimentary Facies and Sequence Lithofacies and Paleogeography of the Xujiahe Formation in the Western Sichuan Depression, P1
   Chen ZQ, 2008, ICMH 2008: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON MATERIAL HANDLING, P1
   Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640
   Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733
   Cook J., 2006, PROC BRIT MACHINE VI, P83
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Husken M., 2005, IEEE WORKSHOP FACE R, P174
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Liu GX, 2010, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INNOVATION AND MANAGEMENT, VOLS I AND II, P1
   Maurer T., 2005, P FACE RECOGNITION G, P154, DOI DOI 10.1109/CVPR.2005.581
   Meijering E, 2002, P IEEE, V90, P319, DOI 10.1109/5.993400
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Ming Y, 2011, INFORM-J COMPUT INFO, V35, P231
   Ocegueda O, 2011, PROC CVPR IEEE, P641, DOI 10.1109/CVPR.2011.5995613
   Passalis G., 2005, CVPR 05, P171
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204
   Llonch RS, 2010, PATTERN RECOGN, V43, P824, DOI 10.1016/j.patcog.2009.07.005
   Seshadri K, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P319
   Tanaka HT, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P372, DOI 10.1109/AFGR.1998.670977
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu CH, 2009, PATTERN RECOGN, V42, P1895, DOI 10.1016/j.patcog.2009.01.001
   Yue Z., 2008, EURASIP J ADV SIG PR, V2008, P1, DOI DOI 10.1155/2008/529480
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 48
TC 17
Z9 18
U1 3
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 524
EP 534
DI 10.1016/j.imavis.2012.05.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100013
DA 2024-07-18
ER

PT J
AU Piccinini, P
   Prati, A
   Cucchiara, R
AF Piccinini, Paolo
   Prati, Andrea
   Cucchiara, Rita
TI Real-time object detection and localization with SIFT-based clustering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pick-and-place applications; Machine vision for industrial applications;
   SIFT
ID SEGMENTATION; MODEL; RECOGNITION; FEATURES; TEXTURE
AB This paper presents an innovative approach for detecting and localizing duplicate objects in pick-and-place applications under extreme conditions of occlusion, where standard appearance-based approaches are likely to be ineffective. The approach exploits SIFT keypoint extraction and mean shift clustering to partition the correspondences between the object model and the image onto different potential object instances with real-time performance. Then, the hypotheses of the object shape are validated by a projection with a fast Euclidean transform of some delimiting points onto the current image. Moreover, in order to improve the detection in the case of reflective or transparent objects, multiple object models (of both the same and different faces of the object) are used and fused together. Many measures of efficacy and efficiency are provided on random disposals of heavily-occluded objects, with a specific focus on real-time processing. Experimental results on different and challenging kinds of objects are reported. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Prati, Andrea] Univ IUAV Venice, Dept Planning & Design Complex Environm, I-30135 Venice, Italy.
   [Piccinini, Paolo; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dept Informat Engn, I-41100 Modena, Italy.
C3 IUAV University Venice; Universita di Modena e Reggio Emilia
RP Prati, A (corresponding author), Univ IUAV Venice, Dept Planning & Design Complex Environm, Santa Croce 1957, I-30135 Venice, Italy.
EM paolo.piccinini@unimore.it; andrea.prati@iuav.it;
   rita.cucchiara@unimore.it
RI Prati, Andrea/B-7440-2014; Cucchiara, Rita/L-3006-2015
OI Prati, Andrea/0000-0002-1211-529X; Cucchiara, Rita/0000-0002-2239-283X
FU Marchesini Group SpA, Pianoro (BO), Italy
FX The authors wish to thank Marchesini Group SpA, Pianoro (BO), Italy, for
   the financial support for this project. The work presented here has been
   patented by Marchesini Group Spa in Italy and Europe. US patent pending.
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2006, WORKSH EDG COMP US N
   [Anonymous], P 6 IEEE RAS INT C H
   [Anonymous], P IAPR C MACH VIS AP
   [Anonymous], INT ROB SYST 2006 IE
   [Anonymous], INT ROB SYST 2000 IR
   [Anonymous], P IEEE INT C IM AN P
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Felzenszwalb P., 2008, PROC IEEE INT C COMP, P1
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hinterstoisser S, 2010, PROC CVPR IEEE, P2257, DOI 10.1109/CVPR.2010.5539908
   IKEUCHI K, 1987, INT J COMPUT VISION, V1, P145, DOI 10.1007/BF00123163
   KNOLL TF, 1986, IEEE T ROBOTIC AUTOM, V2, P3, DOI 10.1109/JRA.1986.1087031
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mueller M, 2004, PATTERN RECOGN, V37, P1619, DOI 10.1016/j.patcog.2004.03.001
   Rahardja K, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P1448, DOI 10.1109/IROS.1996.569005
   Sanz PJ, 1998, IEEE INT CONF ROBOT, P3018, DOI 10.1109/ROBOT.1998.680889
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 30
TC 45
Z9 55
U1 0
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 573
EP 587
DI 10.1016/j.imavis.2012.06.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100017
DA 2024-07-18
ER

PT J
AU Drew, MS
   Hel-Or, Y
   Malzbender, T
   Hajari, N
AF Drew, Mark S.
   Hel-Or, Yacov
   Malzbender, Tom
   Hajari, Nasim
TI Robust estimation of surface properties and interpolation of
   shadow/specularity components
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Polynomial texture mapping; Photometric stereo; Robust estimation;
   Shadows; Specular; Radial basis functions; Continuous interpolation
ID PHOTOMETRIC STEREO TECHNIQUE; REFLECTANCE; IMAGES; SHAPE
AB The Polynomial Texture Map framework (PTM) extends the simple model of image formation from the Lambertian variant of Photometric Stereo (PST) to more general reflectances and to more complex-shaped surfaces. It forms an alternative method for apprehending object color, albedo, and surface normals. Here we consider solving such a model in a robust version, not to date attempted for PTM, with the upshot that both shadows and specularities are identified automatically without the need for any thresholds. Instead of the linear model used in few-source PST for Lambertian surfaces, PTM adopts a higher degree polynomial model. PTM has two aims: interpolation of images for new lighting directions, and recovery of surface properties. Here we show that a robust approach is a good deal more accurate in recovering surface properties. For new-lighting interpolation, we demonstrate that a simple radial basis function interpolation can accurately interpolate specularities as well as attached and cast shadows even with a medium-sized image set, with no need for reflectance sharing across pixels or extremely large numbers of interpolation coefficients. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Drew, Mark S.; Hajari, Nasim] Simon Fraser Univ, Sch Comp Sci, Vancouver, BC V5A 1S6, Canada.
   [Hel-Or, Yacov] Interdisciplinary Ctr, Dept Comp Sci, Herzliyya, Israel.
   [Malzbender, Tom] Hewlett Packard Labs, Mobile & Immers Experience Lab, Palo Alto, CA USA.
C3 Simon Fraser University; Reichman University; Hewlett-Packard
RP Drew, MS (corresponding author), Simon Fraser Univ, Sch Comp Sci, 8888 Univ Dr, Vancouver, BC V5A 1S6, Canada.
EM mark@cs.sfu.ca; toky@idc.ac.il; tom.malzbender@hp.com; nha16@cs.sfu.ca
CR [Anonymous], IMAGE BASED EMPIRICA
   [Anonymous], 2002, Mesh free methods, moving beyond the finite element method
   [Anonymous], 2007, P 18 EUROGRAPHICS C, DOI [10.2312/EGWR/EGSR07/183-194., DOI 10.2312/EGWR/EGSR07/183-194.6]
   [Anonymous], 2006, 7 INT S VIRT REAL AR
   [Anonymous], 2004, P 15 EUROGRAPHICS C
   Argyriou V., 2008, P IEEE C COMPUTER VI, P1
   Argyriou V., 2008, P 19 BRIT MACH VIS C
   Barrow H. G., 1978, Computer Vision Systems, P3
   Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Chandraker Manmohan., 2007, IEEE Int'l Conf. on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383288
   COLEMAN E, 1982, COMP GRAPHICS IMAGE, V18, P308
   Coleman E., 1992, PHYSICSBASED VISION, P180
   Drew M., 2009, BMVC 2009 BRIT MACH
   Fuchs M, 2007, COMPUT GRAPH FORUM, V26, P447, DOI 10.1111/j.1467-8659.2007.01067.x
   Hammer Y., 2002, PALAEONTOLOGIA ELECT
   Happa J., 2009, VAST 09 10 INT S VIR
   Hernández C, 2008, LECT NOTES COMPUT SC, V5302, P290, DOI 10.1007/978-3-540-88682-2_23
   Holly E., 1997, P EUROGRAPHICS WORKS, P35
   HOLROYD M., 2008, ACM SIGGRAPH AS 2008, P133
   Julià C, 2008, IEEE IMAGE PROC, P1500, DOI 10.1109/ICIP.2008.4712051
   Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949
   Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320
   Miyazaki D., 2007, INT WORKSHOP PHOTOME, P325
   Morse BS, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P89, DOI 10.1109/SMA.2001.923379
   Mudge M., 2016, DATA SUSTAINABILITY
   Padfield J., 2005, 14 TRIENNIAL M HAGUE, V1, P504
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718
   Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627
   Sun J, 2007, IMAGE VISION COMPUT, V25, P1050, DOI 10.1016/j.imavis.2006.04.025
   Sunkavalli K, 2010, LECT NOTES COMPUT SC, V6312, P251, DOI 10.1007/978-3-642-15552-9_19
   Verbiest F., 2008, P IEEE C COMP VIS PA, P1
   Wenger A, 2005, ACM T GRAPHIC, V24, P756, DOI 10.1145/1073204.1073258
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Yuille A, 1997, PROC CVPR IEEE, P158, DOI 10.1109/CVPR.1997.609314
   Zickler T, 2006, IEEE T PATTERN ANAL, V28, P1287, DOI 10.1109/TPAMI.2006.170
   Zickler Todd., 2005, RENDERING TECHNIQUES, P253
NR 39
TC 19
Z9 23
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2012
VL 30
IS 4-5
BP 317
EP 331
DI 10.1016/j.imavis.2012.02.012
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 964WF
UT WOS:000305726700005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Verdicchio, F
   Andreopoulos, Y
AF Verdicchio, Fabio
   Andreopoulos, Yiannis
TI Distortion estimates for adaptive lifting transforms with noise
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Adaptive signal decompositions; Lifting scheme; Distortion estimation
ID SCALABLE VIDEO COMPRESSION; MOTION; SCHEME; PREDICTION; DESIGN
AB Multimedia analysis, enhancement and coding methods often resort to adaptive transforms that exploit local characteristics of the input source. Following the signal decomposition stage, the produced transform coefficients and the adaptive transform parameters can be subject to quantization and/or data corruption (e.g. due to transmission or storage limitations). As a result, mismatches between the analysis- and synthesis-side transform coefficients and adaptive parameters may occur, severely impacting the reconstructed signal and therefore affecting the quality of the subsequent analysis, processing and display task Hence, a thorough understanding of the quality degradation ensuing from such mismatches is essential for multimedia applications that rely on adaptive signal decompositions. This paper focuses on lifting-based adaptive transforms that represent a broad class of adaptive decompositions. By viewing the mismatches in the transform coefficients and the adaptive parameters as perturbations in the synthesis system, we derive analytic expressions for the expected reconstruction distortion. Our theoretical results are experimentally assessed using 1D adaptive decompositions and motion-adaptive temporal decompositions of video signals. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Verdicchio, Fabio] Univ Aberdeen, Sch Engn, Aberdeen AB24 3UE, Scotland.
   [Andreopoulos, Yiannis] UCL, Dept Elect & Elect Engn, London WC1E 7JE, England.
C3 University of Aberdeen; University of London; University College London
RP Verdicchio, F (corresponding author), Univ Aberdeen, Sch Engn, Fraser Noble Bldg, Aberdeen AB24 3UE, Scotland.
EM fverdicc@abdn.ac.uk; iandreop@ee.ucl.ac.uk
FU ST; EPSRC [EP/F020015/1]; EPSRC [EP/F020015/1] Funding Source: UKRI
FX This work was supported in part by ST and by EPSRC (Project
   EP/F020015/1).
CR Adami N, 2007, IEEE T CIRC SYST VID, V17, P1238, DOI 10.1109/TCSVT.2007.906828
   AGOSTINI MA, 2006, P EUR SIGN P C FLOR
   Amiri M, 2010, PATTERN RECOGN, V43, P2485, DOI 10.1016/j.patcog.2009.12.014
   Andreopoulos Y, 2004, SIGNAL PROCESS-IMAGE, V19, P653, DOI 10.1016/j.image.2004.05.007
   Andreopoulos Y, 2006, IEEE J SEL AREA COMM, V24, P2104, DOI 10.1109/JSAC.2006.881614
   Barbarien J, 2005, SIGNAL PROCESS-IMAGE, V20, P315, DOI 10.1016/j.image.2004.12.006
   Bottreau V, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P1017, DOI 10.1109/ICIP.2001.958669
   CHANG CL, 2005, P IEEE INT WORKSH MU
   Claypoole RL, 2003, IEEE T IMAGE PROCESS, V12, P1449, DOI 10.1109/TIP.2003.817237
   Flierl M, 2007, IEEE SIGNAL PROC MAG, V24, P66, DOI 10.1109/MSP.2007.905699
   Foo B, 2008, IEEE T SIGNAL PROCES, V56, P797, DOI 10.1109/TSP.2007.906685
   Girod B, 2005, IEEE SIGNAL PROC LET, V12, P150, DOI 10.1109/LSP.2004.840874
   Gouze A, 2004, IEEE T IMAGE PROCESS, V13, P1589, DOI 10.1109/TIP.2004.837556
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Leung R, 2009, IEEE T CIRC SYST VID, V19, P309, DOI 10.1109/TCSVT.2009.2017078
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   PARRILLI S, 2009, P IEEE INT WORKSH MU
   Parrilli S, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P200, DOI 10.1109/MMSP.2008.4665075
   Piella G, 2002, IEEE T SIGNAL PROCES, V50, P1620, DOI 10.1109/TSP.2002.1011203
   Piella G, 2006, J MATH IMAGING VIS, V25, P203, DOI 10.1007/s10851-006-6711-y
   Rusert T, 2004, SIGNAL PROCESS-IMAGE, V19, P617, DOI 10.1016/j.image.2004.05.005
   Secker A, 2003, IEEE T IMAGE PROCESS, V12, P1530, DOI 10.1109/TIP.2003.819433
   Secker A, 2004, IEEE T IMAGE PROCESS, V13, P1029, DOI 10.1109/TIP.2004.826089
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   TAKISHIMA Y, 1995, IEEE T COMMUN, V43, P158, DOI 10.1109/26.380026
   Tasmaz H, 2010, DIGIT SIGNAL PROCESS, V20, P1645, DOI 10.1016/j.dsp.2010.03.006
   Turaga DS, 2005, SIGNAL PROCESS-IMAGE, V20, P1, DOI 10.1016/j.image.2004.08.006
   VERDICCHIO F, SUPPORT DOCUMENT MAN
   Verdicchio F, 2006, IEEE T IMAGE PROCESS, V15, P3114, DOI 10.1109/TIP.2006.877495
   Wan S, 2007, IEEE T IMAGE PROCESS, V16, P1327, DOI 10.1109/TIP.2007.894230
   Wang MS, 2006, IEEE T SIGNAL PROCES, V54, P3505, DOI 10.1109/TSP.2006.879273
   Wu YJ, 2007, IEEE T CIRC SYST VID, V17, P790, DOI 10.1109/TCSVT.2007.894043
   Xiong RQ, 2007, IEEE T CIRC SYST VID, V17, P1256, DOI 10.1109/TCSVT.2007.905507
   Yang WX, 2006, IEEE T CIRC SYST VID, V16, P1385, DOI 10.1109/TCSVT.2006.884571
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zoubir AM, 1998, IEEE SIGNAL PROC MAG, V15, P56, DOI 10.1109/79.647043
NR 37
TC 0
Z9 0
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2011
VL 29
IS 11
BP 744
EP 758
DI 10.1016/j.imavis.2011.08.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 864EE
UT WOS:000298219000004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, ZZ
   Liang, M
   Li, YF
AF Wang, Zhaozhong
   Liang, Min
   Li, Y. F.
TI Using diagonals of orthogonal projection matrices for affine invariant
   contour matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Affine invariance; Contour matching; Shape descriptor; Orthogonal
   projection matrix; Perturbation analysis; Polar decomposition
ID FOURIER DESCRIPTORS; RECOGNITION; REPRESENTATION; CLASSIFICATION;
   RETRIEVAL; ALGORITHM
AB An efficient and rigorous algorithm is proposed for contour matching invariant to the full set of affine transformations. The algorithm is based on an invariant theory of orthogonal projection matrices derived from configuration matrices of point sets. Diagonals of the orthogonal projection matrices (DOPM) are used as contour descriptors and affinity measures are deduced to act as criteria for contour matching. Perturbation analysis is performed using the theory of polar decomposition, resulting in quantitative perturbation bounds for the affine-invariant descriptors and the affinity measures. A useful schema of outlier removal based upon the monotonic property of contour correspondence is also embedded in the algorithm. Experiments for synthetic and real-world data are provided to test the algorithm and compare it with the state-of-the-art methods, validating that the algorithm is fast, robust and able to match partial contours with occlusions and outliers under affine or more complex transformations. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Wang, Zhaozhong; Liang, Min] Beihang Univ, Image Proc Ctr, Beijing 100191, Peoples R China.
   [Li, Y. F.] City Univ Hong Kong, Dept Mfg Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
C3 Beihang University; City University of Hong Kong
RP Wang, ZZ (corresponding author), Beihang Univ, Image Proc Ctr, Beijing 100191, Peoples R China.
EM zwang@buaa.edu.cn; liangmin@sa.buaa.edu.cn; meyfli@cityu.edu.hk
RI Liu, Liu/JXM-8208-2024
OI LI, You Fu/0000-0002-5227-1326
FU National Natural Science Foundation of China [60803071]; Research Grants
   Council of Hong Kong [CityU117106]
FX We thank the anonymous reviewers for helpful comments to improve our
   work. This work was supported by the National Natural Science Foundation
   of China under Grant 60803071, and by the Research Grants Council of
   Hong Kong under Project CityU117106.
CR Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37
   [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI 10.1109/CVPR.2007.383018
   [Anonymous], 2007, CALTECH 256 OBJECT C
   [Anonymous], 1999, Shape and Shape Theory
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Bandera A, 2009, PATTERN RECOGN LETT, V30, P1310, DOI 10.1016/j.patrec.2009.06.004
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207
   Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7
   CHAKER F, 2007, IAPR C MACH VIS APPL, P291
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Chung F. R. K., 1997, Spectral graph theory
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Donoser Michael, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P281
   Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010
   Ha VHS, 2005, IEEE T IMAGE PROCESS, V14, P1687, DOI 10.1109/TIP.2005.857271
   Heikkilä J, 2004, PATTERN RECOGN, V37, P1825, DOI 10.1016/j.patcog.2004.03.005
   HIGHAM NJ, 1986, SIAM J SCI STAT COMP, V7, P1160, DOI 10.1137/0907079
   Horn R. A., 2012, MATRIX ANAL
   Iivarinen J, 1996, P SOC PHOTO-OPT INS, V2904, P25, DOI 10.1117/12.256280
   Kliot M, 1998, COMPUT VIS IMAGE UND, V71, P182, DOI 10.1006/cviu.1998.0709
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Li SZ., 1999, SHAPE ANAL, V6, P203
   LIN CC, 1987, IEEE T PATTERN ANAL, V9, P686, DOI 10.1109/TPAMI.1987.4767963
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Longbin Chen, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563078
   Mokhtarian F, 2001, PATTERN ANAL APPL, V4, P1, DOI 10.1007/PL00010984
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   Obdrzálek S, 2006, LECT NOTES COMPUT SC, V4170, P83
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rucklidge WJ, 1997, INT J COMPUT VISION, V24, P251, DOI 10.1023/A:1007975324482
   SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045
   SEKITA I, 1992, IEEE T PATTERN ANAL, V14, P489, DOI 10.1109/34.126809
   SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3
   Squire DM, 2000, COMPUT VIS IMAGE UND, V77, P284, DOI 10.1006/cviu.2000.0809
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   Wang HF, 2006, PATTERN RECOGN, V39, P1012, DOI 10.1016/j.patcog.2005.05.013
   Wang ZZ, 2010, IEEE SIGNAL PROC LET, V17, P803, DOI 10.1109/LSP.2010.2057506
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zass Ron., 2008, CVPR
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhaozhong Wang, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2482, DOI 10.1109/CVPRW.2009.5206510
NR 47
TC 17
Z9 19
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2011
VL 29
IS 10
BP 681
EP 692
DI 10.1016/j.imavis.2011.07.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 848YP
UT WOS:000297091300004
DA 2024-07-18
ER

PT J
AU Papari, G
   Petkov, N
AF Papari, Giuseppe
   Petkov, Nicolai
TI Edge and line oriented contour detection: State of the art
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Contour detection; Preprocessing; Local pattern analysis; Contour
   salience; Gestalt grouping; Closure; Scale-space; Performance evaluation
ID MONOGENIC SCALE-SPACE; HUMAN VISUAL-SYSTEM; ILL-POSED PROBLEMS; LEVEL
   SET METHODS; IMAGE SEGMENTATION; PERCEPTUAL ORGANIZATION; ACTIVE
   CONTOURS; THRESHOLD DETERMINATION; DIFFERENTIAL-EQUATIONS; ANISOTROPIC
   DIFFUSION
AB We present an overview of various edge and line oriented approaches to contour detection that have been proposed in the last two decades. By edge and line oriented we mean methods that do not rely on segmentation. Distinction is made between edges and contours. Contour detectors are divided in local and global operators. The former are mainly based on differential analysis, statistical approaches, phase congruency, rank order filters, and combinations thereof. The latter include computation of contour saliency, perceptual grouping, relaxation labeling and active contours. Important aspects are covered, such as preprocessing aimed to suppress texture and noise, multiresolution techniques, connections between computational models and properties of the human visual system, and use of shape priors. An overview of procedures and metrics for quantitative performance evaluation is also presented. Our main conclusion is that contour detection has reached high degree of sophistication, taking into account multimodal contour definition (by luminance, color or texture changes), mechanisms for reducing the contour masking influence of noise and texture, perceptual grouping, multiscale aspects and high-level vision information. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Papari, Giuseppe; Petkov, Nicolai] Univ Groningen, Johan Bernoulli Inst Math & Comp Sci, NL-9700 AK Groningen, Netherlands.
C3 University of Groningen
RP Papari, G (corresponding author), Univ Groningen, Johan Bernoulli Inst Math & Comp Sci, POB 407, NL-9700 AK Groningen, Netherlands.
EM g.papari@rug.nl; n.petkov@rug.nl
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934
   Ando S, 2000, IEEE T PATTERN ANAL, V22, P179, DOI 10.1109/34.825756
   ANIL JK, 1989, FUNDAMENTALS DIGITAL
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], INT J PATTERN RECOGN
   [Anonymous], 1993, A vision of the brain
   Ansia FM, 2000, INT C PATT RECOG, P486, DOI 10.1109/ICPR.2000.905382
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Bakker P., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P535, DOI 10.1109/CVPR.1999.786989
   Barash D, 2004, IMAGE VISION COMPUT, V22, P73, DOI 10.1016/j.imavis.2003.08.005
   BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839
   Ben-Shahar O, 2003, IEEE T PATTERN ANAL, V25, P401, DOI 10.1109/TPAMI.2003.1190568
   BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980
   BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Blake A., 1998, ACTIVE CONTOURS APPL
   Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180
   Boukerroui D, 2004, J MATH IMAGING VIS, V21, P53, DOI 10.1023/B:JMIV.0000026557.50965.09
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   BOYCE JF, 1987, PATTERN RECOGN LETT, V6, P225, DOI 10.1016/0167-8655(87)90081-X
   Boyer KL, 1999, COMPUT VIS IMAGE UND, V76, P1, DOI 10.1006/cviu.1999.0797
   Bresson X, 2006, INT J COMPUT VISION, V68, P145, DOI 10.1007/s11263-006-6658-x
   Brook A, 2003, J MATH IMAGING VIS, V18, P247, DOI 10.1023/A:1022895410391
   Burgeth B, 2005, LECT NOTES COMPUT SC, V3753, P84, DOI 10.1007/11577812_8
   BURGETH B, 2005, RELATIVISTIC SCALE S, P1
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CANNY J, 1983, P AAAI WASH, P54
   Casadei S, 1999, COMPUT VIS IMAGE UND, V76, P19, DOI 10.1006/cviu.1999.0790
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P269, DOI 10.1109/TIP.1998.661176
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chabrier S., 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1143
   Chaji N, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/21709
   Chambolle A., 1997, Numerische Mathematik, V76, P167, DOI 10.1007/s002110050258
   Chambolle A, 2001, IEEE T IMAGE PROCESS, V10, P993, DOI 10.1109/83.931093
   Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319, DOI 10.1109/83.661182
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P231, DOI 10.1109/83.902288
   CHEN G, 1995, IEEE T SYST MAN CYB, V25, P636, DOI 10.1109/21.370194
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Choi HI, 1997, PAC J MATH, V181, P57, DOI 10.2140/pjm.1997.181.57
   CHUANG ER, 1993, PATTERN RECOGN, V26, P1673, DOI 10.1016/0031-3203(93)90022-O
   CLARK JJ, 1988, IEEE T PATTERN ANAL, V10, P720, DOI 10.1109/34.6782
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   CORNELIUS H, 2006, WORKSH PERC ORG COMP, P191
   Cremers D., 2002, International Journal of Computer Vision, V50, P295, DOI 10.1023/A:1020826424915
   Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6
   Crevier D, 1999, COMPUT VIS IMAGE UND, V76, P36, DOI 10.1006/cviu.1999.0785
   Cufí X, 2002, ADV IMAG ELECT PHYS, V120, P1
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Demigny D, 1997, IEEE T PATTERN ANAL, V19, P1199, DOI 10.1109/34.632980
   Dobson DC, 1997, SIAM J NUMER ANAL, V34, P1779, DOI 10.1137/S003614299528701X
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Duits R, 2004, J MATH IMAGING VIS, V20, P267, DOI 10.1023/B:JMIV.0000024043.96722.aa
   DUITS R, 2003, ALPHA SCALE SPACES B, P494
   Duits RE, 2005, LECT NOTES COMPUT SC, V3753, P234, DOI 10.1007/11577812_21
   Dumitras A, 2001, IEEE T IMAGE PROCESS, V10, P1851, DOI 10.1109/83.974570
   ELDER J, 1994, VISION RES, V34, P3361, DOI 10.1016/0042-6989(94)90070-1
   Elder JH, 2002, J VISION, V2, DOI 10.1167/2.4.5
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   ELDER JH, 1996, LNCS, V1064, P399
   Engbers EA, 2003, IEEE T PATTERN ANAL, V25, P445, DOI 10.1109/TPAMI.2003.1190571
   Evans AN, 2006, IEEE T IMAGE PROCESS, V15, P1454, DOI 10.1109/TIP.2005.864164
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Felsberg M, 2005, INT J COMPUT VISION, V64, P187, DOI 10.1007/s11263-005-1843-x
   Felsberg M, 2004, J MATH IMAGING VIS, V21, P5, DOI 10.1023/B:JMIV.0000026554.79537.35
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q
   Florack L, 1996, INT J COMPUT VISION, V18, P61, DOI 10.1007/BF00126140
   Fontaine FL, 1998, INT J IMAG SYST TECH, V9, P356, DOI 10.1002/(SICI)1098-1098(1998)9:5<356::AID-IMA6>3.0.CO;2-9
   Ganesan L, 1997, IEEE T SYST MAN CY B, V27, P823, DOI 10.1109/3477.623235
   GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GHOSAL S, 1994, IEEE T IMAGE PROCESS, V3, P14, DOI 10.1109/83.265977
   GOSHTASBY A, 1994, IMAGE VISION COMPUT, V12, P247, DOI 10.1016/0262-8856(94)90078-7
   GREGSON PH, 1993, IEEE T PATTERN ANAL, V15, P682, DOI 10.1109/34.221169
   Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Gunn SR, 1997, IEEE T PATTERN ANAL, V19, P63, DOI 10.1109/34.566812
   Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119
   HANSEN PC, 1992, SIAM REV, V34, P561, DOI 10.1137/1034115
   HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475
   HARALICK RM, 1990, PATTERN RECOGN, V23, P1, DOI 10.1016/0031-3203(90)90045-M
   HARDIE RC, 1993, IEEE T SIGNAL PROCES, V41, P1061, DOI 10.1109/78.205713
   Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380
   Heath M, 1998, COMPUT VIS IMAGE UND, V69, P38, DOI 10.1006/cviu.1997.0587
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   Henstock PV, 1996, IEEE T IMAGE PROCESS, V5, P784, DOI 10.1109/83.499917
   HUANG JS, 1988, COMPUT VISION GRAPH, V43, P337, DOI 10.1016/0734-189X(88)90087-4
   HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Jackway PT, 1996, IEEE T PATTERN ANAL, V18, P38, DOI 10.1109/34.476009
   Jackway PT, 2001, ADV IMAG ELECT PHYS, V119, P123, DOI 10.1016/S1076-5670(01)80087-2
   Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Jalba AC, 2004, IEEE T PATTERN ANAL, V26, P1320, DOI 10.1109/TPAMI.2004.84
   Jiang XY, 2000, IEEE T PATTERN ANAL, V22, P1252, DOI 10.1109/34.888710
   Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kennedy LM, 1997, PATTERN RECOGN, V30, P2001, DOI 10.1016/S0031-3203(97)00014-9
   Kennedy LM, 1999, INT J PATTERN RECOGN, V13, P367, DOI 10.1142/S0218001499000215
   KISWORO M, 1994, IEEE T PATTERN ANAL, V16, P405, DOI 10.1109/34.277593
   KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758
   KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946
   Kostin A, 2005, PATTERN RECOGN LETT, V26, P381, DOI 10.1016/j.patrec.2004.10.020
   KOVACS I, 1993, P NATL ACAD SCI USA, V90, P7495, DOI 10.1073/pnas.90.16.7495
   Kovesi P., 1999, Videre, V1
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   LEE JSJ, 1987, IEEE T ROBOTIC AUTOM, V3, P142, DOI 10.1109/JRA.1987.1087088
   Lee MS, 1999, COMPUT VIS IMAGE UND, V76, P54, DOI 10.1006/cviu.1999.0787
   Leventon M., 2000, P IEEE C COMPUTER VI, P316, DOI DOI 10.1109/CVPR.2000.855835
   LI BC, 1994, PATTERN RECOGN, V27, P785, DOI 10.1016/0031-3203(94)90163-5
   Li H, 2007, IEEE T PATTERN ANAL, V29, P1, DOI 10.1109/TPAMI.2007.250595
   Li M, 1997, OPT ENG, V36, P1431, DOI 10.1117/1.601372
   LI SZ, 1994, P IEEE INT C PATT RE, V1, P488
   Li ZP, 1998, NEURAL COMPUT, V10, P903, DOI 10.1162/089976698300017557
   Liang JM, 2006, MED IMAGE ANAL, V10, P215, DOI 10.1016/j.media.2005.09.002
   Liang KH, 1997, PATTERN RECOGN, V30, P719, DOI 10.1016/S0031-3203(96)00121-5
   Liang KH, 1999, IEEE T SYST MAN CY B, V29, P291, DOI 10.1109/3477.752803
   LIM DH, 2002, STAT, V51, P21
   LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   LIU JQ, 1994, IEEE T PATTERN ANAL, V16, P689, DOI 10.1109/34.297949
   Liu W, 2006, ULTRASOUND MED BIOL, V32, P397, DOI 10.1016/j.ultrasmedbio.2005.11.011
   LU Y, 1989, IEEE T PATTERN ANAL, V11, P337, DOI 10.1109/34.19032
   Mahamud S, 2003, IEEE T PATTERN ANAL, V25, P433, DOI 10.1109/TPAMI.2003.1190570
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Marquina A, 2000, SIAM J SCI COMPUT, V22, P387, DOI 10.1137/S1064827599351751
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Marr D., 1982, Vision
   Marroquin JL, 1997, J OPT SOC AM A, V14, P779, DOI 10.1364/JOSAA.14.000779
   Martens JB, 1997, IEEE T IMAGE PROCESS, V6, P1103, DOI 10.1109/83.605408
   MARTIN D, 2002, NEUR INF PROC SYST C, P1255
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Martínez AM, 2004, COMPUT VIS IMAGE UND, V95, P72, DOI 10.1016/j.cviu.2004.01.003
   Matalas I, 1997, IEEE T PATTERN ANAL, V19, P328, DOI 10.1109/34.588006
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   Meese TS, 2007, J VISION, V7, DOI 10.1167/7.4.7
   MOHAN R, 1992, IEEE T PATTERN ANAL, V14, P616, DOI 10.1109/34.141553
   MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073
   MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4
   MORRONE MC, 1986, NATURE, V324, P250, DOI 10.1038/324250a0
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Mundhenk TN, 2005, BIOL CYBERN, V93, P188, DOI 10.1007/s00422-005-0577-8
   NACKEN PFM, 1993, IEEE T PATTERN ANAL, V15, P1312, DOI 10.1109/34.250848
   Nielsen M, 1997, J MATH IMAGING VIS, V7, P291, DOI 10.1023/A:1008282127190
   NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593
   Nitzberg M., 1993, LECT NOTES COMPUTER, V662
   Odet C, 2002, IEEE IMAGE PROC, P785
   Olson CF, 2000, IEEE T PATTERN ANAL, V22, P983, DOI 10.1109/34.877521
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   Osher S, 2001, J COMPUT PHYS, V169, P463, DOI 10.1006/jcph.2000.6636
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   PAPARI G, 2007, P EL IM IM P ALG SYS
   PAPARI G, 2006, P EL IM IM P ALG SYS
   Papari G, 2008, IEEE T IMAGE PROCESS, V17, P1950, DOI 10.1109/TIP.2008.2002306
   Papari G, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/71828
   Papari G, 2006, IEEE IMAGE PROC, P749, DOI 10.1109/ICIP.2006.312500
   Papari G, 2007, IEEE T IMAGE PROCESS, V16, P2449, DOI 10.1109/TIP.2007.903912
   Paragios N, 2004, IEEE T PATTERN ANAL, V26, P402, DOI 10.1109/TPAMI.2004.1262337
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Pardo XM, 2001, IMAGE VISION COMPUT, V19, P461, DOI 10.1016/S0262-8856(00)00092-5
   Pardo XM, 2000, PATTERN RECOGN LETT, V21, P559, DOI 10.1016/S0167-8655(00)00020-9
   PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445
   PARK DJ, 1995, PATTERN RECOGN, V28, P211, DOI 10.1016/0031-3203(94)00097-6
   PARK DJ, 1994, PATTERN RECOGN, V27, P765, DOI 10.1016/0031-3203(94)90161-9
   Park H, 2001, IEEE T CIRC SYST VID, V11, P252, DOI 10.1109/76.905991
   PAUWELS EJ, 1995, IEEE T PATTERN ANAL, V17, P691, DOI 10.1109/34.391411
   PELILLO M, 1994, IEEE T PATTERN ANAL, V16, P933, DOI 10.1109/34.310691
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petkov N, 2003, BIOL CYBERN, V88, P236, DOI 10.1007/s00422-002-0378-2
   PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047
   PETROU M, 1994, ADV ELECTRON EL PHYS, V88, P297
   PITAS I, 1992, P IEEE, V80, P1893, DOI 10.1109/5.192071
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Ponomaryov VI, 2005, J IMAGING SCI TECHN, V49, P205
   Qiu PH, 2007, J AM STAT ASSOC, V102, P745, DOI 10.1198/016214507000000301
   RAMAN SV, 1991, IEEE T MED IMAGING, V10, P109, DOI 10.1109/42.79468
   Ray N, 2001, PATTERN RECOGN, V34, P1483, DOI 10.1016/S0031-3203(00)00077-7
   Reisfeld D, 1996, PATTERN RECOGN LETT, V17, P1161, DOI 10.1016/0167-8655(96)00081-5
   Ren XF, 2005, IEEE I CONF COMP VIS, P1214
   Rivest J.-F., 1993, Journal of Electronic Imaging, V2, P326, DOI 10.1117/12.159642
   Robbins B, 1997, IMAGE VISION COMPUT, V15, P353, DOI 10.1016/S0262-8856(96)01137-7
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   RONSE C, 1993, IEEE T PATTERN ANAL, V15, P484, DOI 10.1109/34.211468
   ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519
   Rosin PL, 1997, MACH VISION APPL, V9, P139, DOI 10.1007/s001380050036
   Rousson M, 2008, INT J COMPUT VISION, V76, P231, DOI 10.1007/s11263-007-0054-z
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118
   SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339
   Sakalli M, 2006, IEEE T IMAGE PROCESS, V15, P1182, DOI 10.1109/TIP.2006.871401
   Salden AH, 2001, J MATH IMAGING VIS, V15, P127, DOI 10.1023/A:1012282305022
   SALDEN AH, 1999, ERCIM0299R067
   Sanfeliu A, 2002, PATTERN RECOGN, V35, P639, DOI 10.1016/S0031-3203(01)00066-8
   SANG N, 2007, JIMW, V47
   SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Sappa AD, 2006, IEEE T IMAGE PROCESS, V15, P377, DOI 10.1109/TIP.2005.860612
   SARKAR S, 1993, IEEE T SYST MAN CYB, V23, P382, DOI 10.1109/21.229452
   SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275
   Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006
   Saund E, 2003, IEEE T PATTERN ANAL, V25, P475, DOI 10.1109/TPAMI.2003.1190573
   Saund E, 1999, COMPUT VIS IMAGE UND, V76, P70, DOI 10.1006/cviu.1999.0789
   Scherzer O, 2003, ADV IMAG ELECT PHYS, V128, P445, DOI 10.1016/S1076-5670(03)80067-8
   SCHULZE MA, 1994, IEEE IMAGE PROC, P530, DOI 10.1109/ICIP.1994.413627
   SETHIAN J., 1996, LEVEL SET METHODS
   Shin MC, 2001, IEEE T SYST MAN CY B, V31, P589, DOI 10.1109/3477.938262
   Shroff H, 1999, IEEE T IMAGE PROCESS, V8, P1388, DOI 10.1109/83.791964
   Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653
   SJOBERG F, 1988, PATTERN RECOGN LETT, V7, P181, DOI 10.1016/0167-8655(88)90063-3
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Stahl JS, 2008, IEEE T PATTERN ANAL, V30, P395, DOI 10.1109/TPAMI.2007.1186
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429
   Sun JX, 2004, PATTERN RECOGN, V37, P1315, DOI 10.1016/j.patcog.2003.11.006
   Sundaramoorthi G, 2007, IEEE T IMAGE PROCESS, V16, P803, DOI 10.1109/TIP.2007.891071
   Suri JS, 2002, IEEE T INF TECHNOL B, V6, P8, DOI 10.1109/4233.992158
   Tang QL, 2007, PATTERN RECOGN, V40, P3100, DOI 10.1016/j.patcog.2007.02.009
   Tang QL, 2007, IMAGE VISION COMPUT, V25, P1282, DOI 10.1016/j.imavis.2006.08.007
   Teboul S, 1998, IEEE T IMAGE PROCESS, V7, P387, DOI 10.1109/83.661189
   Ter Haar Romeny B., 2002, FRONT END VISION MUL
   ter Haar Romeny B., 1994, GEOMETRY DRIVEN DIFF
   Thornber KK, 1996, BIOL CYBERN, V75, P141, DOI 10.1007/s004220050282
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tong WS, 2005, IEEE T PATTERN ANAL, V27, P434, DOI 10.1109/TPAMI.2005.62
   TorkamaniAzar F, 1996, IEEE T IMAGE PROCESS, V5, P1573, DOI 10.1109/83.541427
   Trahanias PE, 1996, IEEE T SYST MAN CY B, V26, P135, DOI 10.1109/3477.484445
   Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355
   Tuytelaars T, 2003, IEEE T PATTERN ANAL, V25, P418, DOI 10.1109/TPAMI.2003.1190569
   ULUPINAR F, 1990, COMPUT VISION GRAPH, V51, P275, DOI 10.1016/0734-189X(90)90004-F
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P834, DOI 10.1109/78.193221
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   Ursino M, 2004, NEURAL NETWORKS, V17, P719, DOI 10.1016/j.neunet.2004.03.007
   Van den Boomgaard R, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P283
   VANDENBOOMGAARD R, 1994, IEEE T PATTERN ANAL, V16, P1101, DOI 10.1109/34.334389
   VENKATESH S, 1990, PATTERN RECOGN LETT, V11, P339, DOI 10.1016/0167-8655(90)90043-2
   VENKATESH S, 1995, GRAPH MODEL IM PROC, V57, P146, DOI 10.1006/gmip.1995.1015
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   VIDAKOVIC B, 1998, J AM STAT ASS, V93
   VIEW TOC, 2003, IEEE T PAMI, V25, P755
   Vogel CR, 1998, IEEE T IMAGE PROCESS, V7, P813, DOI 10.1109/83.679423
   VRIENDT J, 1993, MULTIDIMENSIONAL SYS, V4, P227
   Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938
   Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P2313, DOI 10.1109/TIT.2005.850091
   Wang H, 2008, PATTERN RECOGN, V41, P3393, DOI 10.1016/j.patcog.2008.03.030
   Wang S, 2005, IEEE T PATTERN ANAL, V27, P546, DOI 10.1109/TPAMI.2005.84
   Wang S, 2003, IEEE T PATTERN ANAL, V25, P675, DOI 10.1109/TPAMI.2003.1201819
   Wang X, 2007, IEEE T PATTERN ANAL, V29, P886, DOI 10.1109/TPAMI.2007.1027
   Wang YP, 1998, IEEE T PATTERN ANAL, V20, P1040, DOI 10.1109/34.722612
   Wang YP, 1999, IEEE T IMAGE PROCESS, V8, P1757, DOI 10.1109/83.806621
   Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3
   Weickert J, 1999, J MATH IMAGING VIS, V10, P237, DOI 10.1023/A:1008344623873
   WEICKERT J, 1996, IVC, V11, P221
   Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036
   WHITAKER RT, 1993, CVGIP-IMAG UNDERSTAN, V57, P111, DOI 10.1006/ciun.1993.1007
   Wilkinson MHF, 1998, GRAPH MODEL IM PROC, V60, P385, DOI 10.1006/gmip.1998.0478
   Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu JJ, 2007, IEEE T IMAGE PROCESS, V16, P534, DOI 10.1109/TIP.2006.888335
   Yan H, 2001, IEEE T SYST MAN CY B, V31, P768, DOI 10.1109/3477.956038
   Yan H, 2004, IEEE T SYST MAN CY B, V34, P210, DOI 10.1109/TSMCB.2003.811763
   Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085
   Yen SC, 1998, VISION RES, V38, P719, DOI 10.1016/S0042-6989(97)00197-1
   Yitzhaky Y, 2003, IEEE T PATTERN ANAL, V25, P1027, DOI 10.1109/TPAMI.2003.1217608
   YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI 10.1109/TPAMI.1986.4767748
   Zhang W, 1997, INT J COMPUT VISION, V24, P219, DOI 10.1023/A:1007923307644
   ZHOU YT, 1989, IEEE T PATTERN ANAL, V11, P84, DOI 10.1109/34.23115
   Zhu QM, 1996, IMAGE VISION COMPUT, V14, P21, DOI 10.1016/0262-8856(95)01036-X
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
   Zhu SY, 1999, OPT ENG, V38, P612, DOI 10.1117/1.602105
NR 292
TC 257
Z9 300
U1 12
U2 196
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2011
VL 29
IS 2-3
BP 79
EP 103
DI 10.1016/j.imavis.2010.08.009
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 707NV
UT WOS:000286294200001
DA 2024-07-18
ER

PT J
AU Dehais, C
   Morin, G
   Charvillat, V
AF Dehais, Christophe
   Morin, Geraldine
   Charvillat, Vincent
TI From rendering to tracking point-based 3D models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Point-based model; Surface splatting; GPGPU
AB This paper adds to the abundant visual tracking literature with two main contributions. First, we illustrate the interest of using Graphic Processing Units (CPU) to support efficient implementations of computer vision algorithms, and secondly, we introduce the use of point-based 3D models as a shape prior for real-time 3D tracking with a monocular camera.
   The joint use of point-based 3D models together with CPU allows to adapt and simplify an existing tracking algorithm originally designed for triangular meshes. Point-based models are of particular interest in this context, because they are the direct output of most laser scanners.
   We show that state-of-the-art techniques developed for point-based rendering can be used to compute in real-time intermediate values required for visual tracking. In particular, apparent motion predictors at each pixel are computed in parallel, and novel views of the tracked object are generated online to help wide-baseline matching. Both computations derive from the same general surface splatting technique which we implement, along with other low-level vision tasks, on the CPU, leading to a real-time tracking algorithm. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Dehais, Christophe; Morin, Geraldine; Charvillat, Vincent] IRIT ENSEEIHT, F-31071 Toulouse, France.
C3 Universite de Toulouse; Universite Toulouse III - Paul Sabatier;
   Universite Federale Toulouse Midi-Pyrenees (ComUE); Institut National
   Polytechnique de Toulouse
RP Dehais, C (corresponding author), IRIT ENSEEIHT, 2 Rue Charles Camichel,BP 7122, F-31071 Toulouse, France.
EM christophe.dehais@enseeiht.fr
CR Botsch Mario, 2005, P EUROGRAPHICSIEEE V, P17, DOI [DOI 10.2312/SPBG/SPBG05/017-024, 10.1109/PBG.2005.194059.6]
   COMPORT AI, 2004, IEEE RSJ INT C INT R, V1, P692
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   Gross M., 2007, POINT BASED GRAPHICS
   Guennebaud G, 2004, COMPUT GRAPH FORUM, V23, P653, DOI 10.1111/j.1467-8659.2004.00797.x
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Huber P., 1981, Robust Statistics
   Klein G., 2006, P BRIT MACH VIS C BM
   Kollnig H, 1997, INT J COMPUT VISION, V23, P283, DOI 10.1023/A:1007927317325
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170
   Muñoz E, 2005, IEEE I CONF COMP VIS, P877
   Pressigout M, 2007, INT J ROBOT RES, V26, P689, DOI 10.1177/0278364907080477
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   Wiles CS, 2001, IEEE T PATTERN ANAL, V23, P1391, DOI 10.1109/34.977563
   Xiao J, 2004, PROC CVPR IEEE, P535
   Ziegler G., 2006, Workshop on Vision, Modeling, and Visualization (VMV 2006), P137
   Zwicker M, 2004, PROC GRAPH INTERF, P247
   Zwicker M, 2001, COMP GRAPH, P371, DOI 10.1145/383259.383300
   Zwicker M, 2002, IEEE T VIS COMPUT GR, V8, P223, DOI 10.1109/TVCG.2002.1021576
NR 22
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2010
VL 28
IS 9
BP 1386
EP 1395
DI 10.1016/j.imavis.2010.03.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 620NN
UT WOS:000279506700006
DA 2024-07-18
ER

PT J
AU Lin, DT
AF Lin, Daw-Tung
TI Autonomous sub-image matching for two-dimensional electrophoresis gels
   using MaxRST algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sub-image matching; Two-dimensional electrophoresis; Features
   extraction; Gabriel graph; Relative neighborhood graph; Maximum relation
   spanning tree; Gaussian similarity measure
ID SOFTWARE PACKAGES; COMPUTER-ANALYSIS; REGISTRATION; SYSTEM
AB Matching two-dimensional electrophoresis (2-DE) gel images typically generates a bottleneck in the automated protein analysis, and image distortion and experimental variation, which reduce the matching accuracy. However, conventional matching schemes only compare two complete images, and landmark selection and registration procedures are rather time-consuming. This work presents a novel and robust Maximum Relation Spanning Tree (MaxRST) algorithm, in which an autonomous sub-image matching method does not require registering or manual selection of landmarks. The 2D gel images are represented graphically. Image features are then quantitatively extracted regardless of image size. Similarity between a sub-image and large image is then determined based on Gaussian similarity measurement inspired by fuzzy method, thereby increasing the accuracy of fractional matching. The proposed autonomous matching algorithm achieves an accuracy of up to 97.29% when matching 627 2-DE gel test images. In addition to accommodating image rotation, reversals, shape deformation and intensity changes, the proposed algorithm effectively addresses the sub-image mapping problem and was analyzed thoroughly using a large dataset containing 4629 images. The contributions of this work are twofold. First, this work presents a novel MaxRST strategy and autonomous matching method that does not require manual landmark selection. Second, the proposed method, which extends 2-DE gel matching to query sub-image and a database containing large sets of images, can be adopted for mapping and locating, and to compare small gel images with large gel images with robustness and efficiency. (C) 2010 Elsevier B.V. All rights reserved.
C1 Natl Taipei Univ, Dept Comp Sci & Informat Engn, Sanshia 237, Taipei County, Taiwan.
C3 National Taipei University
RP Lin, DT (corresponding author), Natl Taipei Univ, Dept Comp Sci & Informat Engn, 151 Univ Rd, Sanshia 237, Taipei County, Taiwan.
EM dalton@mail.ntpu.edu.tw
RI Lin, Daw-Tung/B-7043-2009; cai, bo/G-1491-2010
FU National Science Council of the Republic of China, Taiwan
   [NSC93-2213-E216-016, NSC94-2213-E-305-004]
FX The authors would like to thank the National Science Council of the
   Republic of China, Taiwan, for partially supporting this research under
   Contract Nos. NSC93-2213-E216-016 and NSC94-2213-E-305-004. The Animal
   Technology Institute Taiwan (ATIT) is appreciated for supplying the 2-DE
   gel images. I am particularly grateful for the generous comments of
   Prof. En-Chung Lin at the Department of Animal Science and Technology of
   National Taiwan University, Taiwan, and Prof. San-Yuan Huang at the
   Department of Animal Science, National Chung Hsing University, Taiwan.
   Their initiation of this study is also appreciated. Mr. Juin-Lin Kuo is
   also commended for his work in the preliminary study. Ms. Chih-Hui Hsu
   is thanked for her assistance in the simulations in this study.
CR Akutsu T, 2003, DISCRETE APPL MATH, V127, P5, DOI 10.1016/S0166-218X(02)00282-2
   AKUTSU T, 1999, LNCS, V1645, P212
   ANDERSON NL, 1981, CLIN CHEM, V27, P1807
   [Anonymous], 1995, FUNDAMENTALS DATA ST
   Babnigg G, 2004, NUCLEIC ACIDS RES, V32, pD582, DOI 10.1093/nar/gkh089
   Berth M, 2007, APPL MICROBIOL BIOT, V76, P1223, DOI 10.1007/s00253-007-1128-0
   BOSE P, 2002, P LAT AM THEOR INF, P77
   Dowsey AW, 2003, PROTEOMICS, V3, P1567, DOI 10.1002/pmic.200300459
   Efrat A, 2002, J COMPUT BIOL, V9, P299, DOI 10.1089/10665270252935476
   GARRELS JI, 1979, J BIOL CHEM, V254, P7961
   GARRELS JI, 1981, BIOL CHEM, V264, P5269
   Gustafsson JS, 2002, ELECTROPHORESIS, V23, P1731, DOI 10.1002/1522-2683(200206)23:11<1731::AID-ELPS1731>3.0.CO;2-#
   Hoffmann F, 1999, DISCRETE APPL MATH, V93, P75, DOI 10.1016/S0166-218X(99)00007-4
   HOFFMANN F, 1998, S COMP GEOM, P231
   HOJTE P, 2003, P INT C MULT EXP 200, V3
   JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414
   Kaczmarek K, 2005, ACTA CHROMATOGR, V15, P82
   Kaczmarek K, 2004, PROTEOMICS, V4, P2377, DOI 10.1002/pmic.200300758
   Kaczmarek K, 2003, J CHEM INF COMP SCI, V43, P978, DOI 10.1021/ci0256337
   Kaczmarek K, 2002, J CHEM INF COMP SCI, V42, P1431, DOI 10.1021/ci020266K
   KARGER DR, 1995, J ASSOC COMPUT MACH, V42, P321, DOI 10.1145/201019.201022
   Klir G., 1995, Fuzzy sets and fuzzy logic, V4
   LEMKIN PF, 1981, COMPUT BIOMED RES, V14, P355, DOI 10.1016/0010-4809(81)90006-9
   Lin D-T, 2004, 6 IASTED INT C SIGN
   Lin DT, 2005, LECT NOTES ARTIF INT, V3683, P1366
   OFARRELL PH, 1975, J BIOL CHEM, V250, P4007
   Pánek J, 1999, ELECTROPHORESIS, V20, P3483, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3483::AID-ELPS3483>3.3.CO;2-I
   PLEIBNER KP, 2004, PROTEOMICS, V4, P1
   Pleissner KP, 1999, ELECTROPHORESIS, V20, P755, DOI 10.1002/(SICI)1522-2683(19990101)20:4/5<755::AID-ELPS755>3.0.CO;2-6
   Raman B, 2002, ELECTROPHORESIS, V23, P2194, DOI 10.1002/1522-2683(200207)23:14<2194::AID-ELPS2194>3.0.CO;2-#
   Rogers M, 2003, PROTEOMICS, V3, P887, DOI 10.1002/pmic.200300421
   Rogers M, 2007, IEEE T IMAGE PROCESS, V16, P624, DOI 10.1109/TIP.2007.891342
   Rosengren AT, 2003, PROTEOMICS, V3, P1936, DOI 10.1002/pmic.200300544
   Smilansky Z, 2001, ELECTROPHORESIS, V22, P1616, DOI 10.1002/1522-2683(200105)22:9<1616::AID-ELPS1616>3.0.CO;2-Z
   Sorzano COS, 2005, IEEE T BIO-MED ENG, V52, P652, DOI 10.1109/TBME.2005.844030
   Srinark T, 2006, IEEE IMAGE PROC, P1165, DOI 10.1109/ICIP.2006.312764
   TAKAHASHI K, 1998, GEN INF WORKSH, P161
   Veeser S, 2001, PROTEOMICS, V1, P856
   Veltkamp RC, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P188, DOI 10.1109/SMA.2001.923389
   WANG XY, 2003, 1 AS PAC BIOINF C RE, V19, P223
   Westermeier R., 1993, ELECTROPHORESIS PRAC
   MELANIE
   PDQUEST
NR 43
TC 11
Z9 16
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1267
EP 1279
DI 10.1016/j.imavis.2010.01.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400009
DA 2024-07-18
ER

PT J
AU Gonzalez-Mora, J
   De la Torre, F
   Guil, N
   Zapata, EL
AF Gonzalez-Mora, Jose
   De la Torre, Fernando
   Guil, Nicolas
   Zapata, Emilio L.
TI Learning a generic 3D face model from 2D image databases using
   incremental Structure-from-Motion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Structure-from-Motion; Incremental learning; Morphable Models; Active
   Appearance Models
ID ACTIVE APPEARANCE MODELS; SHAPE; CONSTRUCTION
AB Over the last decade 3D face models have been extensively used in many applications such as face recognition, facial animation and facial expression analysis. 3D Morphable Models (MMs) have become a popular tool to build and fit 3D face models to images. Critical to the success of MMs is the ability to build a generic 3D face model. Major limitations in the MMs building process are: (1) collecting 3D data usually involves the use of expensive laser scans and complex capture setups, (2) the number of available 3D databases is limited, and typically there is a lack of expression variability and (3) finding correspondences and registering the 3D model is a labor intensive and error prone process.
   This paper proposes an incremental Structure-from-Motion (SfM) approach to learn a generic 3D face model from large collections of existing 2D hand-labeled images containing many subjects under different expressions and poses. The two major contributions of the paper are: (1) learning a generic 3D deformable face model from 2D databases and (2) incorporating a prior subspace into the incremental SfM formulation to provide robustness to noise, missing data and degenerate shape configurations. Experimental results on the CMU-PIE database show improvements in the generalization of the 3D face model across expression and identity. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Gonzalez-Mora, Jose; Guil, Nicolas; Zapata, Emilio L.] Univ Malaga, Dept Comp Architecture, E-29071 Malaga, Spain.
   [De la Torre, Fernando; Guil, Nicolas] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
C3 Universidad de Malaga; Carnegie Mellon University
RP Gonzalez-Mora, J (corresponding author), Univ Malaga, Dept Comp Architecture, E-29071 Malaga, Spain.
EM jgmora@ac.uma.es; ftorre@cs.cmu.edu; nico@ac.uma.es; ezapata@ac.uma.es
RI Guil, Nicolas/AAM-6160-2020; Gonzalez-Mora, Jose Luis/L-6100-2014
OI Guil, Nicolas/0000-0003-3431-6516; Gonzalez-Mora, Jose
   Luis/0000-0001-8920-1375
FU Ministry of Education and Science (CICYT) of Spain [TIN2006-01078];
   Junta de Andalucia [PR07-TIC-02800]
FX This work was partially supported by the Ministry of Education and
   Science (CICYT) of Spain under Contract TIN2006-01078 and Junta de
   Andalucia under Contract PR07-TIC-02800. Thanks to the University of
   South Florida (USF) and the University of Freiburg for providing the
   Human ID 3D Database and the 3D Morphable Model. Thanks to Jeff Cohn for
   providing a partial labeling of the Multi-PIE database. Thanks to L.
   Torresani for providing a publicly available implementation of their SfM
   algorithm.
CR Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2005, NEURAL NETWORKS PATT
   [Anonymous], INT C COMP VIS PATT
   [Anonymous], INT J COMPUT SCI ENG
   Baker S, 2004, IEEE T PATTERN ANAL, V26, P1380, DOI 10.1109/TPAMI.2004.77
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Blanz V, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P293, DOI 10.1109/TDPVT.2004.1335212
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Brand M., 2002, EUR C COMP VIS
   BRAND M, 2001, INT C COMP VIS PATT
   BRAND M, 2005, INT C COMP VIS PATT
   BREGLER C, 2000, IEEE C COMP VIS PATT, V2
   BUCHANAN A, 2005, INT C COMP VIS PATT, V2, P312
   Buchanan Aeron., 2004, INVESTIGATION MATRIX
   BUE AD, 2004, IEEE WORKSH ART NONR
   BUE AD, 2008, INT C COMP VIS PATT
   Cootes T. F., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P52
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   De la Torre F, 2000, INT C PATT RECOG, P1106, DOI 10.1109/ICPR.2000.903739
   EDWARDS GJ, 1998, EUR C COMP VIS, V2, P581
   Foley JD, 1984, SYSTEMS PROGRAMMING
   Gross Ralph., 2002, GUIDE CMU MULTIPIE F
   Guerreiro RFC, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P897, DOI 10.1109/ICIP.2002.1039117
   JACOBS D, 1997, INT C COMP VIS PATT
   JULIA C, 2006, INT C COMP SCI
   Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432
   LU X, 2008, IEEE T PATTERN ANAL, V30, P5
   MARUYAMA M, 1999, IEEE INT C IM PROC, P120
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2
   Nister D., 2007, INT C COMPUTER VISIO, P1, DOI DOI 10.1109/ICCV.2007.4409095
   OLSEN S, 2007, BRIT MACH VIS C
   Kassim SRA, 2006, IEEE IMAGE PROC, P661
   Skocaj D, 2008, IMAGE VISION COMPUT, V26, P27, DOI 10.1016/j.imavis.2005.07.028
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torr PHS, 1999, INT J COMPUT VISION, V32, P27, DOI 10.1023/A:1008140928553
   TORRESANI L, 2001, INT C COMP VIS PATT
   Torresani L., 2003, Neural Information Processing Systems
   Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752
   Xiao J, 2004, PROC CVPR IEEE, P535
   XIAO J, 2006, IEEE C COMP VIS PATT, V2, P2429
   Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9
NR 47
TC 15
Z9 19
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2010
VL 28
IS 7
SI SI
BP 1117
EP 1129
DI 10.1016/j.imavis.2010.01.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 603UP
UT WOS:000278233900006
DA 2024-07-18
ER

PT J
AU Donner, R
   Langs, G
   Micusik, B
   Bischof, H
AF Donner, Rene
   Langs, Georg
   Micusik, Branislav
   Bischof, Horst
TI Generalized sparse MRF appearance models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Markov Random Fields; Appearance models; Object localization; Medical
   imaging
ID BELIEF PROPAGATION; SHAPE
AB Image segmentation or registration approaches that rely on a local search paradigm (e.g. Active Appearance Models, Active Contours) require an initialization that provides for considerable overlap or a coarse localization of the object to be segmented or localized. In this paper we propose an approach that does not need such an initialization, but localizes anatomical structures in a global manner by formulating the localization task as the solution of a Markov Random Field (MRF).
   During search Sparse MRF Appearance Models (SAMs) relate a priori information about the geometric configuration of landmarks and local appearance features to a set of candidate points in the target image. They encode the correspondence probabilities as an MRF, and the search in the target image is equivalent to solving the MRF. The resulting node labels define a mapping of the modeled object (e.g. a sequence of vertebrae) to the target image interest points. The local appearance information is captured by novel symmetry-based interest points and local descriptors derived from Gradient Vector Flow (GVF). Alternatively, arbitrary interest points can be used. Experimental results are reported for two data-sets showing the applicability to complex medical data. The approach does not require initialization and finds the most plausible match of the query structure in the entire image. It provides for precise, reliable and fast localization of the structure. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Donner, Rene; Langs, Georg] Med Univ Vienna, Computat Image Anal & Radiol Lab, Dept Radiol, A-1090 Vienna, Austria.
   [Micusik, Branislav] George Mason Univ, Fairfax, VA 22030 USA.
   [Bischof, Horst] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria.
C3 Medical University of Vienna; George Mason University; Graz University
   of Technology
RP Donner, R (corresponding author), Med Univ Vienna, Computat Image Anal & Radiol Lab, Dept Radiol, Wahringer Gurtel 18-22, A-1090 Vienna, Austria.
EM donner@icg.tu-graz.ac.at; georg.langs@meduni-wien.ac.at;
   bmicusik@gmu.edu; bischof@icg.tu-graz.ac.at
OI Langs, Georg/0000-0002-5536-6873; Bischof, Horst/0000-0002-9096-6671
CR [Anonymous], IEEE PAMI
   [Anonymous], 2001, Interactive graph cuts for optimal boundary & region segmentation of objects in nd images, DOI DOI 10.1109/ICCV.2001.937505
   [Anonymous], P ICPR
   [Anonymous], 2004, DISTINCTIVE IMAGE FE
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cootes T.F., 1992, P BMVC
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Donner R., 2007, P BMVC
   Donner R, 2006, IEEE T PATTERN ANAL, V28, P1690, DOI 10.1109/TPAMI.2006.206
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   FERGUS R, 2003, P CVPR 03
   HUANG R, 2004, P CVPR
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061
   Kovesi P., 1997, P 10 AUSTR JOINT C A, P185
   KUMAR MP, 2006, P CVPR, P1045
   Langs G, 2007, ACAD RADIOL, V14, P1179, DOI 10.1016/j.acra.2007.06.013
   Ling H., 2006, P CVPR
   Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601
   LOY G, 2006, P ECCV 06
   MATAS J, 1995, P ICCV
   Micusik B., 2007, P CVPR
   Mikolajczyk Krystian, 2005, IEEE PAMI
   Mitchell SC, 2002, IEEE T MED IMAGING, V21, P1167, DOI 10.1109/TMI.2002.804425
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   Roberts M, 2006, INVEST RADIOL, V41, P849, DOI 10.1097/01.rli.0000244343.27431.26
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Saxena A, 2007, IEEE I CONF COMP VIS, P1
   SCHLESINGER M, 1976, KIBERNETIKA, P113
   Shekhovtsov A., 2007, P CVPR
   Stegmann MB, 2005, MED IMAGE ANAL, V9, P394, DOI 10.1016/j.media.2004.10.002
   THODBERG H, 2001, BMVC, P43
   Vogiatzis G, 2005, PROC CVPR IEEE, P391
   WERNER T, 2007, IEEE T PATTERN RECOG, V29
   XIAO P, 2007, IEEE C COMP VIS PATT, P1
   XU C, 1998, IEEE T IMAGE PROC, V7
   Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085
NR 39
TC 16
Z9 18
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 1031
EP 1038
DI 10.1016/j.imavis.2009.07.010
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200016
DA 2024-07-18
ER

PT J
AU Ahmad, M
   Lee, SW
AF Ahmad, Mohiuddin
   Lee, Seong-Whan
TI Variable silhouette energy image representations for recognizing human
   actions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Silhouette energy image; Action recognition; Variability action models;
   Daily life actions; Global motion description
ID RECOGNITION
AB Recognizing human actions is an important topic in the computer vision community. One of the challenges of recognizing human actions is describing for the variability that arises when arbitrary view camera captures human performing actions. In this paper, we propose a spatio-temporal silhouette representation, called silhouette energy image (SEI), and multiple variability action models, to characterize motion and shape properties for automatic recognition of human actions in daily life. To address the variability in the recognition of human actions, several parameters, such as anthropometry of the person, speed of the action, phase (starting and ending state of an action), camera observations (distance from camera, slanting motion, and rotation of human body), and view variations are proposed. We construct the variability (or adaptable) models based on SEI and the proposed parameters. Global motion descriptors express the spatio-temporal properties of combined energy templates (SEI and variability action models). Our construction of the optimal model for each action and view is based on the support vectors of global motion descriptions of action models. We recognize different daily human actions of different styles successfully in the indoor and outdoor environment. Our experimental results show that the proposed method of human action recognition is robust, flexible and efficient. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Lee, Seong-Whan] Korea Univ, Dept Comp Sci & Engn, Seoul 136713, South Korea.
   [Ahmad, Mohiuddin] Khulna Univ Engn & Technol, Dept Elect & Elect Engn, Khulna 9203, Bangladesh.
C3 Korea University; Khulna University of Engineering & Technology (KUET)
RP Lee, SW (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul 136713, South Korea.
EM ahmad@eee.kuet.ac.bd; swlee@image.korea.ac.kr
RI Ahmad, Mohiuddin/AAV-1567-2021; Ahmad, Mohiuddin/JCE-4638-2023; Lee,
   Seong-Whan/C-7928-2012
OI Ahmad, Mohiuddin/0000-0001-9123-0618; Ahmad,
   Mohiuddin/0000-0001-9123-0618; 
FU Korea government (MEST) [2009-0060113]; Ministry of Knowledge Economy of
   Korea; KUET, Khulna, Bangladesh
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSEF) grant funded by the Korea government (MEST) (No. 2009-0060113).
   This research was also supported by the Intelligent Robotics Development
   Program, one of the 21st Century Frontier R&D Programs funded by the
   Ministry of Knowledge Economy of Korea. This work was also supported in
   part by CASR grants KUET, Khulna, Bangladesh.
CR Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   [Anonymous], 2005, 2 JOINT IEEE INT WOR
   [Anonymous], IEEE COMP SOC WORKSH
   [Anonymous], COMP VIS PATT REC IE
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ke Y, 2005, IEEE I CONF COMP VIS, P166
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Lam THW, 2006, LECT NOTES COMPUT SC, V3832, P612
   Lin C.-J., 2004, SIMPLE PROBABILISTIC
   Masoud O, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P157, DOI 10.1109/AVSS.2003.1217916
   Niebles JuanCarlos., 2006, British Machine Vision Conference, V3, P1249
   Parameswaran V., 2003, COMPUTER VISION PATT, V2, P613
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sheikh Y, 2005, IEEE I CONF COMP VIS, P144
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Weston J., 1999, PROC EUROPEAN S ARTI, P219
NR 19
TC 23
Z9 26
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 814
EP 824
DI 10.1016/j.imavis.2009.09.018
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900010
DA 2024-07-18
ER

PT J
AU Beveridge, JR
   Givens, GH
   Phillips, PJ
   Draper, BA
   Bolme, DS
   Lui, YM
AF Beveridge, J. Ross
   Givens, Geof H.
   Phillips, P. Jonathon
   Draper, Bruce A.
   Bolme, David S.
   Lui, Yui Man
TI FRVT 2006: Quo Vadis face quality
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Generalized linear mixed models; Image covariates;
   Biometric quality
ID RECOGNITION; PERFORMANCE; ALGORITHMS; FEATURES
AB A study is presented showing how three state-of-the-art algorithms from the Face Recognition Vendor Test 2006 (FRVT 2006) are effected by factors related to face images and people. The recognition scenario compares highly controlled images to images taken of people as they stand before a camera in settings such as hallways and outdoors in front of buildings. A Generalized Linear Mixed Model (GLMM) is used to estimate the probability an algorithm successfully verifies a person conditioned upon the factors included in the study. The factors associated with people are: Gender, Race, Age and whether they wear Glasses. The factors associated with images are: the size of the face, edge density and region density. The setting, indoors versus outdoors, is also a factor. Edge density can change the estimated probability of verification dramatically, for example from about 0.15 to 0.85. However, this effect is not consistent across algorithm or setting. This finding shows that simple measurable factors are capable of characterizing face quality; however, these factors typically interact with both algorithm and setting. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Beveridge, J. Ross; Draper, Bruce A.; Bolme, David S.; Lui, Yui Man] Colorado State Univ, Dept Comp Sci, Ft Collins, CO 80523 USA.
   [Givens, Geof H.] Colorado State Univ, Dept Stat, Ft Collins, CO 80523 USA.
   [Phillips, P. Jonathon] Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA.
C3 Colorado State University; Colorado State University; National Institute
   of Standards & Technology (NIST) - USA
RP Beveridge, JR (corresponding author), Colorado State Univ, Dept Comp Sci, Ft Collins, CO 80523 USA.
EM ross@CS.ColoState.EDU
OI Beveridge, Ross/0000-0001-6489-6676; Bolme, David/0000-0003-3807-7436
FU Technical Support Working Group (TSWG) [T-1840C]; Department of Homeland
   Security; Director of National Intelligence; Federal Bureau of
   Investigation; National Institute of Justice
FX The work was funded in part by the Technical Support Working Group
   (TSWG) under Task T-1840C. P.J.P. was supported by the Department of
   Homeland Security, Director of National Intelligence, Federal Bureau of
   Investigation and National Institute of Justice. The identification of
   any commercial product or trade name does not imply endorsement or
   recommendation by Colorado State University or the National Institute of
   Standards and Technology.
CR Alonso-Fernandez F, 2007, IEEE T INF FOREN SEC, V2, P734, DOI 10.1109/TIFS.2007.908228
   [Anonymous], 1998, P IC SLD 98 NIST 199
   Beveridge JR, 2009, COMPUT VIS IMAGE UND, V113, P750, DOI 10.1016/j.cviu.2008.12.007
   Beveridge JR, 2005, MACH VISION APPL, V16, P128, DOI 10.1007/s00138-004-0144-7
   BOULT T, 2006, BIOM QUAL WORKSH
   BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.1080/01621459.1993.10594284
   Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410
   Fierrez-Aguilar J, 2006, LECT NOTES COMPUT SC, V3832, P213
   Givens G, 2004, PROC CVPR IEEE, P381
   Grother P, 2007, IEEE T PATTERN ANAL, V29, P531, DOI 10.1109/TPAMI.2007.1019
   Krotkov E.P., 1989, Active Computer Vision by co-operative Focus and Stereo
   Littell R.C., 1996, SAS SYSTEMS MIXED MO
   Lui YM, 2008, IEEE INT CONF AUTOMA, P78
   MCCABE RM, 1997, BEST PRACTICE RECOMM
   O'Toole AJ, 2007, IEEE T SYST MAN CY B, V37, P1149, DOI 10.1109/TSMCB.2007.907034
   O'Toole AJ, 2007, IEEE T PATTERN ANAL, V29, P1642, DOI 10.1109/TPAMI.2007.1107
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P235, DOI 10.1109/AFGR.2002.1004160
   PHILLIPS PJ, 2003, 6965 NISTIR
   WANG P, 2006, IEEE C COMP VIS PATT, V2, P1566
   WEBER F, 2006, BIOM QUAL WORKSH
   WOLFINGER R, 1993, J STAT COMPUT SIM, V48, P233, DOI 10.1080/00949659308811554
   ZHANG A, 1998, P IM UND WORKSH, P1053
NR 25
TC 15
Z9 24
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 732
EP 743
DI 10.1016/j.imavis.2009.09.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900002
DA 2024-07-18
ER

PT J
AU Han, L
   Wu, XX
   Liang, W
   Hou, GM
   Jia, YD
AF Han, Lei
   Wu, Xinxiao
   Liang, Wei
   Hou, Guangming
   Jia, Yunde
TI Discriminative human action recognition in the learned hierarchical
   manifold space
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human action recognition; Discriminative model; Hierarchical manifold
   learning; Mutual invariant; Motion pattern
ID HUMAN MOTION ANALYSIS; HUMAN MOVEMENT
AB In this paper, we propose a hierarchical discriminative approach for human action recognition. It consists of feature extraction with mutual motion pattern analysis and discriminative action modeling in the hierarchical manifold space. Hierarchical Gaussian Process Latent Variable Model (HGPLVM) is employed to learn the hierarchical manifold space in which motion patterns are extracted. A cascade CRF is also presented to estimate the motion patterns in the corresponding manifold subspace, and the trained SVM classifier predicts the action label for the current observation. Using motion capture data, we test our method and evaluate how body parts make effect on human action recognition. The results on our test set of synthetic images are also presented to demonstrate the robustness. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Han, Lei; Wu, Xinxiao; Liang, Wei; Hou, Guangming; Jia, Yunde] Beijing Inst Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Han, L (corresponding author), Beijing Inst Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM hanlei@bit.edu.cn; wuxinxiao@bit.edu.cn; liangwei@bit.edu.cn;
   gmhou@bit.edu.cn; jiayunde@bit.edu.cn
RI Cataldi, Antonio/AAM-7411-2021
FU Natural Science Foundation of China [60675021]; Chinese High-Tech
   Program [2006AA01Z120]; Science and Technology Basic Work Program of
   China [2008IM030200]
FX This work was supported by the Natural Science Foundation of China
   (60675021), the Chinese High-Tech Program (2006AA01Z120) and the Science
   and Technology Basic Work Program of China (2008IM030200).
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Ali A, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P28, DOI 10.1109/EVENT.2001.938863
   [Anonymous], CMU GRAPH LAB MOT CA
   [Anonymous], P IEEE COMPUT SOC C
   [Anonymous], 2007, P CVPR 2 WORKSH EV A
   Bashir FI, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P623
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   CARLSSON S, 2001, P WORKSH MOD VERS EX, P1
   Chang C.C., LIBSVM: a library for support vector machines
   Cuntoor NP, 2008, IEEE T IMAGE PROCESS, V17, P594, DOI 10.1109/TIP.2008.916991
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Efros A., 2003, Proc. IEEE Internationa Conference on Computer Vision, V2, P726
   Elgammal A, 2004, PROC CVPR IEEE, P681
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Gritai A, 2004, INT C PATT RECOG, P923, DOI 10.1109/ICPR.2004.1334410
   Han L., Proceedings from IEEE International Conference on Automatic Face and Gesture Recognition, 2008, P1, DOI DOI 10.1109/AFGR.2008.4813416
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lawrence ND, 2004, ADV NEUR IN, V16, P329
   Lawrence ND, 2007, Proceedings of the 24th international conference on machine learning, P481, DOI DOI 10.1145/1273496.1273557
   Lu WL, 2009, IMAGE VISION COMPUT, V27, P189, DOI 10.1016/j.imavis.2008.02.008
   Lv F., 2007, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P1
   Lv FJ, 2005, LECT NOTES COMPUT SC, V3766, P120, DOI 10.1007/11573425_12
   Min JH, 2008, IMAGE VISION COMPUT, V26, P1621, DOI 10.1016/j.imavis.2008.03.006
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Morency L.P., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383299
   Mori T, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P779, DOI 10.1109/AFGR.2004.1301629
   Nguyen NT, 2005, PROC CVPR IEEE, P955
   Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4
   Parameswaran V, 2005, COMPUT VIS IMAGE UND, V98, P295, DOI 10.1016/j.cviu.2004.09.002
   POPPE R, 2008, P INT C AUT FAC GEST, P1
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Poppe R, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P541
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sheikh Y, 2005, IEEE I CONF COMP VIS, P144
   Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808
   Veeraraghavan A., 2006, CVPR 06, P959, DOI [DOI 10.1109/CVPR.2006.304, 10.1109/CVPR.2006.304]
   Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784
   Wang L, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN SECURITY AND DEFENSE APPLICATIONS, P1
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Wu Y, 1999, LECT NOTES ARTIF INT, V1739, P103
   Zhang Z, 2006, INT C PATT RECOG, P1135
NR 45
TC 60
Z9 67
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 836
EP 849
DI 10.1016/j.imavis.2009.08.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900012
DA 2024-07-18
ER

PT J
AU Oikonomopoulos, A
   Pantic, M
   Patras, I
AF Oikonomopoulos, Antonios
   Pantic, Maja
   Patras, Ioannis
TI Sparse B-spline polynomial descriptors for human activity recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optical flow; Median filter; Spatiotemporal salient points; B-splines;
   Gentleboost; Relevance Vector Machine
ID HUMAN MOTION ANALYSIS; IMAGE; SHAPE
AB The extraction and quantization of local image and video descriptors for the subsequent creation of visual codebooks is a technique that has proved very effective for image and video retrieval applications. In this paper we build on this concept and propose a new set of visual descriptors that provide a local space-time description of the visual activity. The proposed descriptors are extracted at spatiotemporal salient points detected on the estimated optical flow field for a given image sequence and are based on geometrical properties of three-dimensional piecewise polynomials, namely B-splines. The latter are fitted on the spatiotemporal locations of salient points that fall within a given spatiotemporal neighborhood. Our descriptors are invariant in translation and scaling in space-time. The latter is ensured by coupling the neighborhood dimensions to the scale at which the corresponding spatiotemporal salient points are detected. In addition, in order to provide robustness against camera motion (e.g. global translation due to camera panning) we subtract the motion component that is estimated by applying local median filters on the optical flow field. The descriptors that are extracted across the whole dataset are clustered in order to create a codebook of 'visual verbs', where each verb corresponds to a cluster center. We use the resulting codebook in a 'bag of verbs' approach in order to represent the motion of the subjects within small temporal windows. Finally, we use a boosting algorithm in order to select the most discriminative temporal windows of each class and Relevance Vector Machines (RVM) for classification. The presented results using three different databases of human actions verify the effectiveness of our method. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Oikonomopoulos, Antonios; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Computing, London SW7 2AZ, England.
   [Pantic, Maja] Univ Twente, Fac Elect Engn Math & Comp Sci, Enschede, Netherlands.
   [Patras, Ioannis] Queen Mary Univ London, Dept Elect Engn, London, England.
C3 Imperial College London; University of Twente; University of London;
   Queen Mary University London
RP Oikonomopoulos, A (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Computing, 180 Queensgate, London SW7 2AZ, England.
EM aoikonom@imperial.ac.uk; m.pantic@imperial.ac.uk;
   ioannis.patras@elec.qmul.ac.uk
OI Patras, Ioannis/0000-0003-3913-4738
FU European Research Council [ERC-2007-StG-203143]
FX This work has been supported in part by the European Research Council
   under the ERC Starting Grant agreement No. ERC-2007-StG-203143 (MAHNOB).
CR Abdelkader MF, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/347050
   Agarwal A, 2006, LECT NOTES COMPUT SC, V3951, P30
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   [Anonymous], 2006, P 20 ANN C NEUR INF
   [Anonymous], P IEEE C CVPR
   [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587735
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], 2004, ECCV WORKSH STAT LEA
   [Anonymous], 2005, VIS SURV PERF EV TRA
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P EUR C COMP VIS
   [Anonymous], INT C VIS INF ENG
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], ADDITIVE LOGISTIC RE
   [Anonymous], P IEEE C COMP VIS PA
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Black M.J., 1993, International Conference on Computer Vision (ICCV), P231
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x
   Guo F, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/326896
   Ikizler N, 2007, LECT NOTES COMPUT SC, V4814, P271
   JIANG H, 2008, EUR C COMP VIS
   Ke Y, 2005, IEEE I CONF COMP VIS, P166
   Ke Y, 2007, IEEE I CONF COMP VIS, P1424
   KLAESER A, 2008, BRIT MACH VIS C
   LAPTEV I, 2004, P IEEE C COMP VIS PA, V3, P32
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   LI IJ, 2007, ICCV, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Moon H, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/596989
   Natarajan P, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P87
   NIEBLES JC, 2006, BRIT MACH VIS C, V1
   OIKONOMOPOULOS A, 2007, ADV VIDEO SIGNAL BAS, P441
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600
   Serre T, 2005, PROC CVPR IEEE, P994
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Shechtman E, 2005, PROC CVPR IEEE, P405
   Sheikh Y, 2005, IEEE I CONF COMP VIS, P144
   Sigal L, 2004, PROC CVPR IEEE, P421
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Sivic J, 2006, LECT NOTES COMPUT SC, V4170, P127
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   THURAU C, 2007, ICCV WORKSH HUM BEH, P299
   Torralba A, 2004, PROC CVPR IEEE, P762
   Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66
   Yilmaz A, 2005, IEEE I CONF COMP VIS, P150
NR 58
TC 25
Z9 28
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2009
VL 27
IS 12
SI SI
BP 1814
EP 1825
DI 10.1016/j.imavis.2009.05.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 513PL
UT WOS:000271335000008
OA Green Published
DA 2024-07-18
ER

PT J
AU Liu, CC
   Chuang, KW
AF Liu, Chen-Chung
   Chuang, Kai-Wen
TI An outdoor time scenes simulation scheme based on support vector
   regression with radial basis function on DCT domain
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Discrete cosine transform; Support vector regression; Neural network;
   Radial basis function (RBF); Scene
ID FORECASTING INTERMITTENT DEMAND; COLOR-VISION; MACHINES; MODEL
AB In this paper, a novel strategy for forecasting outdoor scenes is introduced. This new approach combines the support vector regression in neural network computation and the discrete cosine transform (DCT). In 1995, Vapnik introduced a neural-network algorithm called support vector machine (SVM). During the recent years. due to SVM's high generalization performance and attractive modeling features, it has received increasing attention in the application of regression estimation - which is called support vector regression (M). In SVR, a set of color-block images were transformed by the discrete cosine transformation to be the training data. We also used the radial basis function (RBF) of the training data as SVR's kernel to establish the RBF neural network. Finally, the time scenes simulation algorithm (TSSA) is able to synthesize the corresponding scene of any assigned time of the original outdoor scene image.
   To explore the utility and demonstrate the efficiency of the proposed algorithm, simulations under various input images were conducted. The experiment results showed that our proposed algorithm can precisely simulate the desired scenes at an assigned time and has two advantages: (a) Using the color-block images instead of using the scene images of a place to create the reference database, the database can be used for any outdoor scene image taken at anywhere at anytime. (b) Taking the support vector regression on the DCT coefficients of scene images instead of taking the SVR on the spatial pixels of scene images, it simplifies the regression procedure and saves the processing time. Crown Copyright (C) 2009 Published by Elsevier B.V. All rights reserved.
C1 [Liu, Chen-Chung; Chuang, Kai-Wen] Natl Chin Yi Univ Technol, Dept Elect Engn, Taichung 411, Taiwan.
C3 National Chin-Yi University of Technology
RP Liu, CC (corresponding author), Natl Chin Yi Univ Technol, Dept Elect Engn, Taichung 411, Taiwan.
EM ccl@ncut.edu.tw
RI liu, chen/ISV-2093-2023
CR Andreadis I, 1997, REAL-TIME IMAGING, V3, P1, DOI 10.1006/rtim.1996.0041
   Bao YK, 2004, IEEE SYS MAN CYBERN, P461
   Batlle J, 2000, IMAGE VISION COMPUT, V18, P515, DOI 10.1016/S0262-8856(99)00040-2
   Bosch A, 2007, IMAGE VISION COMPUT, V25, P727, DOI 10.1016/j.imavis.2006.05.015
   Bose T., 2004, DIGITAL SIGNAL IMAGE
   Bozinovic N, 2005, SIGNAL PROCESS-IMAGE, V20, P510, DOI 10.1016/j.image.2005.03.007
   Buluswar SD, 2002, COMPUT VIS IMAGE UND, V85, P71, DOI 10.1006/cviu.2001.0950
   Cao LJ, 2003, IEEE T NEURAL NETWOR, V14, P1506, DOI 10.1109/TNN.2003.820556
   Chen GY, 2007, IMAGE VISION COMPUT, V25, P960, DOI 10.1016/j.imavis.2006.07.009
   Chen KY, 2007, RELIAB ENG SYST SAFE, V92, P423, DOI 10.1016/j.ress.2005.12.014
   CHEN WY, 2005, 10 C ART INT APPL IN
   Cheng JS, 2007, MECH SYST SIGNAL PR, V21, P1197, DOI 10.1016/j.ymssp.2005.09.005
   Clausen C, 2000, PATTERN RECOGN, V33, P1555, DOI 10.1016/S0031-3203(99)00126-0
   Deeb SS, 2006, CURR OPIN GENET DEV, V16, P301, DOI 10.1016/j.gde.2006.04.002
   DEELEN RV, 2005, J QUANTITATIVE SPECT, V95, P309
   Duh DJ, 2005, IMAGE VISION COMPUT, V23, P1115, DOI 10.1016/j.imavis.2005.05.013
   Gandhi AB, 2007, CHEM ENG SCI, V62, P7078, DOI 10.1016/j.ces.2007.07.071
   Hua ZS, 2006, APPL MATH COMPUT, V181, P1035, DOI 10.1016/j.amc.2006.01.064
   Jacobs N, 2007, IEEE I CONF COMP VIS, P1305
   Kawakami R, 2005, IEEE I CONF COMP VIS, P1200
   Kim KJ, 2003, NEUROCOMPUTING, V55, P307, DOI 10.1016/S0925-2312(03)00372-2
   LEA SM, 1997, PHYS NATURE THINGS, P597
   Lennie P, 2000, CURR BIOL, V10, pR589, DOI 10.1016/S0960-9822(00)00632-1
   Liu S, 2005, J VIS COMMUN IMAGE R, V16, P643, DOI 10.1016/j.jvcir.2005.04.001
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Pai PF, 2005, OMEGA-INT J MANAGE S, V33, P497, DOI 10.1016/j.omega.2004.07.024
   Sneep M, 2005, J QUANT SPECTROSC RA, V92, P293, DOI 10.1016/j.jqsrt.2004.07.025
   STU U, 2006, CHEMOMETRICS INTELLI, V81, P29
   Tang JS, 2004, DIGIT SIGNAL PROCESS, V14, P218, DOI 10.1016/j.dsp.2003.06.001
   Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3
   Toet A, 2005, DISPLAYS, V26, P15, DOI 10.1016/j.displa.2004.09.007
   Van de Hulst H.C., 1981, LIGHT SCATTERING SMA
   Vapnik V, 1997, ADV NEUR IN, V9, P281
   Vapnik V., 1999, NATURE STAT LEARNING
   WELSH T, 2002, P 29 ANN C COMP GRAP, P277, DOI DOI 10.1145/566570.566576
   Xi XC, 2007, CONTROL ENG PRACT, V15, P897, DOI 10.1016/j.conengprac.2006.10.010
   Zhong D, 2005, PATTERN RECOGN LETT, V26, P2272, DOI 10.1016/j.patrec.2005.04.012
   Zhou Q, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P121
   Zou TT, 2006, ANAL BIOCHEM, V355, P1, DOI 10.1016/j.ab.2006.04.025
NR 39
TC 8
Z9 10
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1626
EP 1636
DI 10.1016/j.imavis.2009.04.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800019
DA 2024-07-18
ER

PT J
AU Micheloni, C
   Snidaro, L
   Foresti, GL
AF Micheloni, Christian
   Snidaro, Lauro
   Foresti, Gian Luca
TI Exploiting temporal statistics for events analysis and understanding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Event analysis; Event understanding; Video surveillance; Security
ID RECOGNITION
AB In this paper, we propose a technique for detecting anomalous events in outdoor areas monitored by a video surveillance system. In particular, the focus is on the time spent by an object to carry out simple events. To have a statistical representation of the time commonly required to perform certain activities, mixtures of Gaussians are maintained for each event type. Such statistics are then exploited both for the analysis of simple activities and for discovering anomalous situations, eventually alerting the operator. To this end, a novel way of visualizing results is also discussed. Experiments have been performed on a multi-camera system for parking lot security. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Micheloni, Christian; Snidaro, Lauro; Foresti, Gian Luca] Univ Udine, Dept Math & Comp Sci, I-33100 Udine, Ud, Italy.
C3 University of Udine
RP Micheloni, C (corresponding author), Univ Udine, Dept Math & Comp Sci, Via Sci 206, I-33100 Udine, Ud, Italy.
EM christian.micheloni@dimi.uniud.it
RI Snidaro, Lauro/AAJ-8072-2021; Micheloni, Christian/E-5427-2012; Snidaro,
   Lauro/F-6897-2017
OI Micheloni, Christian/0000-0003-4503-7483; Snidaro,
   Lauro/0000-0003-3828-9017
FU Italian Ministry of University and Scientific Research; European FP6
   Project HAMLET
FX This work was partially supported by the Italian Ministry of University
   and Scientific Research within the framework of the project "Ambient
   Intelligence: event analysis, sensor recofiguration and multimodal
   interfaces" (2006-2008) and by the European FP6 Project HAMLET
   "Hazardous Material Localisation&Person Tracking".
CR Caelli T, 2004, IEEE T PATTERN ANAL, V26, P515, DOI 10.1109/TPAMI.2004.1265866
   Cesar RM, 2005, PATTERN RECOGN, V38, P2099, DOI 10.1016/j.patcog.2005.05.007
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Diamantopoulos G, 2005, REAL-TIME IMAGING, V11, P233, DOI 10.1016/j.rti.2005.02.002
   Dousson C, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P324
   Foresti GL, 2005, IEEE SIGNAL PROC MAG, V22, P25, DOI 10.1109/MSP.2005.1406473
   Foresti GL, 2004, IEEE T SYST MAN CY B, V34, P988, DOI 10.1109/TSMCB.2003.818538
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Hlaoui A, 2002, INT C PATT RECOG, P180, DOI 10.1109/ICPR.2002.1047427
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   MICHELONI C, 2006, P 6 IEEE INT WORKSH, P81
   Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004
   Porikli F., 2004, P 2004 C COMPUTER VI, V7, P114
   Rota N, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P59, DOI 10.1109/VS.2000.856858
   Shet VD, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P224
   Snidaro L, 2006, IEEE IMAGE PROC, P1753, DOI 10.1109/ICIP.2006.312721
   Vu V.T., 2003, Proc. of Int'l Joint Conf. o Artificial Intelligence, P9
   Zhong H, 2004, PROC CVPR IEEE, P819
NR 20
TC 15
Z9 17
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1459
EP 1469
DI 10.1016/j.imavis.2008.07.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800005
DA 2024-07-18
ER

PT J
AU Kawano, H
   Suetake, N
   Cha, B
   Aso, T
AF Kawano, Hideaki
   Suetake, Noriaki
   Cha, Byungki
   Aso, Takashi
TI Sharpness preserving image enlargement by using self-decomposed codebook
   and Mahalanobis distance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image enlargement; Self-decomposed codebook; Mahalanobis distance;
   Shape-invariant properties of edges across scales
ID HIGH-RESOLUTION IMAGE; NEURAL-NETWORKS; SUPERRESOLUTION; RECONSTRUCTION;
   INTERPOLATION; ALGORITHM; EXTRAPOLATION
AB We propose an image enlargement method preserving perceptual sharpness, which is achieved by augmenting a low resolution image with high-frequency components from a given image itself The estimation of high-frequency image components is performed by a codebook built by a decomposition of the given image, i.e. a self-decomposed codebook. The rational that is exploited in this approach is the shape-invariant properties of edges across scales. As a distance measure for matching from the codebook, we employ the Mahalanobis distance which is a local distance measure incorporating pixel correlation. The effectiveness of the proposed method is verified by some image enlargement experiments. Consequently, the experimental results show that the performance of the proposed method is superior to other conventional image enlargement methods objectively and subjectively. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Kawano, Hideaki] Kyushu Inst Technol, Fac Engn, Tobata Ku, Fukuoka 8048550, Japan.
   [Suetake, Noriaki] Yamaguchi Univ, Grad Sch Sci & Engn, Yamaguchi 7538512, Japan.
   [Cha, Byungki; Aso, Takashi] Kyushu Inst Informat Sci, Fac Management & Informat Sci, Dazaifu Shi, Fukuoka 8180117, Japan.
C3 Kyushu Institute of Technology; Yamaguchi University
RP Kawano, H (corresponding author), Kyushu Inst Technol, Fac Engn, Tobata Ku, 1-1 Sensui Cho, Fukuoka 8048550, Japan.
EM kawano@ecs.kyutech.ac.jp; suetake@sci.yamaguchi-u.ac.jp; cha@kiis.ac.jp;
   taso@kiis.ac.jp
FU Japan Society for the Promotion of Science [18500182]; Grants-in-Aid for
   Scientific Research [18500182] Funding Source: KAKEN
FX This work was supported by the Japan Society for the Promotion of
   Science under the Grant-in-Aid for Scientific Research (C) (No.
   18500182)
CR ANDERSON CH, 1987, Patent No. 71810431
   Aso T, 2006, INTELL AUTOM SOFT CO, V12, P345, DOI 10.1080/10798587.2006.10642937
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Candocia FM, 1999, IEEE T NEURAL NETWOR, V10, P372, DOI 10.1109/72.750566
   Chang S. G., 1995, P INT C AC SPEECH SI, V4, P2379
   Darwish AM, 1997, IEE P-VIS IMAGE SIGN, V144, P207, DOI 10.1049/ip-vis:19971342
   Duda R., 1973, Pattern Classification and Scene Analysis
   Greenspan H, 2000, IEEE T IMAGE PROCESS, V9, P1035, DOI 10.1109/83.846246
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Kaltenbacher E., 1996, Proceedings of the IEEE 1996 National Aerospace and Electronics Conference NAECON 1996 (Cat. No.96CH35934), P702, DOI 10.1109/NAECON.1996.517726
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   LIN JS, 1990, 2 DIMENSIONAL SIGNAL
   Martucci S. A., 1995, P IEEE INT C IM PROC, P2244
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   OSKOUIFARD P, 1988, IEEE T MED IMAGING, V7, P45, DOI 10.1109/42.3928
   Pan FZ, 2003, OPT ENG, V42, P3038, DOI 10.1117/1.1604397
   Patti AJ, 2001, IEEE T IMAGE PROCESS, V10, P179, DOI 10.1109/83.892456
   Plaziac N, 1999, IEEE T IMAGE PROCESS, V8, P1647, DOI 10.1109/83.799893
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   TSAI Y, 1984, ADV COMPUT VISION IM, V1, P317
   van Ouwerkerk JD, 2006, IMAGE VISION COMPUT, V24, P1039, DOI 10.1016/j.imavis.2006.02.026
NR 24
TC 7
Z9 10
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 684
EP 693
DI 10.1016/j.imavis.2008.07.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000009
DA 2024-07-18
ER

PT J
AU Humphreys, J
   Hunter, A
AF Humphreys, James
   Hunter, Andrew
TI Multiple object tracking using a neural cost function
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Surveillance; Tracking; Background differencing; Self-organizing maps;
   Neural networks
AB This paper presents a new approach to the tracking of multiple objects in CCTV surveillance using a combination of simple neural cost functions based on Self-Organizing Maps, and a greedy assignment algorithm. Using a reference standard data set and an exhaustive search algorithm for benchmarking, we show that the cost function plays the most significant role in realizing high levels of performance. The neural cost function's context-sensitive treatment of appearance, change of appearance and trajectory yield better tracking than a simple, explicitly designed cost function. The algorithm matches 98.8% of objects to within 15 pixels. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Hunter, Andrew] Lincoln Univ, Ctr Visual Surveillance & Machine Percept, Dept Comp & Informat, Lincoln LN2 7TS, England.
C3 University of Lincoln
RP Hunter, A (corresponding author), Flat 7,Pembroke House, Borehamwood WD6 1DB, England.
EM ahunter@lincoln.ac.uk
RI Hunter, Andrew/E-3880-2015
OI Hunter, Andrew/0000-0003-3786-4008
CR [Anonymous], 1999, P 7 INT C COMP VIS
   Baumberg A, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P87
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   FERRYMAN JM, 1997, ROBOTICS AUTONOMOUS, V19
   Harwood D., 1998, INT C FAC GEST REC N
   HUMPHREYS JA, 2004, THESIS U DURHAM DURH
   HUNTER A, 2003, IEE S INT DISTR SURV
   Javed O, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P22, DOI 10.1109/MOTION.2002.1182209
   JAVED O, 2002, 7 EUR C COMP VIS COP
   Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8
   Kaewtrakulpong P., 2001, 2 EUR WORKSH ADV VID
   KOLLER D, 1994, 3 EUR C COMP VIS, V1, P189
   Owens J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P767
   Owens J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P77, DOI 10.1109/VS.2000.856860
   OWENS J, 2002, P INT C ART NEUR NET, V2, P1249
   REMAGNINO P, 1997, BRIT MACH VIS C, V2
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 17
TC 1
Z9 2
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 417
EP 424
DI 10.1016/j.imavis.2008.06.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600012
DA 2024-07-18
ER

PT J
AU Fleck, S
   Busch, F
   Biber, P
   Strasser, W
AF Fleck, Sven
   Busch, Florian
   Biber, Peter
   Strasser, Wolfgang
TI Graph cut based panoramic 3D modeling and ground truth comparison with a
   mobile platform - The Wagele
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Graph cut; 3D model acquisition; 3DTV
AB Efficient and comfortable acquisition of large 3D scenes is an important topic for many current and future applications in the field of robotics, factory and office visualization, 3DTV and cultural heritage.
   In this paper we present both an omnidirectional stereo vision approach for 3D modeling based on graph cut techniques and also a new mobile 3D model acquisition platform where it is employed. The platform comprises a panoramic camera and a 2D laser range scanner for self localization by scan matching. 3D models are acquired just by moving the platform around and recording images in regular intervals. Additionally, we concurrently build 3D models using two supplementary laser range scanners. This enables the investigation of the stereo algorithm's quality by comparing it with the laser scanner based 3D model as ground truth. This offers a more objective point of view on the achieved 3D model quality. (C) 2008 Elsevier B.V. All rights reserved
C1 [Fleck, Sven; Busch, Florian; Biber, Peter; Strasser, Wolfgang] Univ Tubingen, WSI GRIS, Sand 14, Tubingen, Germany.
C3 Eberhard Karls University of Tubingen
RP Fleck, S (corresponding author), Univ Tubingen, WSI GRIS, Sand 14, Tubingen, Germany.
EM fleck@gris.uni-tuebingen.de; busch@gris.uni-tuebingen.de;
   biber@gris.uni-tuebingen.de; strasser@gris.uni-tuebingen.de
RI Fleck, Sven/ITV-3785-2023
CR [Anonymous], IEEE T PATTERN ANAL
   Arican Z, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P399, DOI 10.1109/AVSS.2007.4425344
   BENOSMAN R, 2001, PANORAMIC VISION
   Benosman R., 2001, PANORAMIC VISION SEN
   BIBER P, 2007, 3D IMAGING SAFETY SE
   Biber P., 2003, IEEE RJS INT C INT R
   Biber P., 2004, 26 PATT REC S DAGM 0
   BIBER P, 2006, IEEE INT C ROB AUT I
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   BOYKOV Y, 2001, IEEE T PATT AN MACH
   Bunschoten R, 2003, IEEE T ROBOTIC AUTOM, V19, P351, DOI 10.1109/TRA.2003.808850
   Daniilidis K., PAGE OMNIDIRECTIONAL
   FLECK S, 2006, IAPR CAN C COMP ROB
   FLECK S, 2005, IEEE INT C ROB AUT I, P18
   Fleck S, 2007, EURASIP J EMBED SYST, DOI 10.1155/2007/29858
   Frese U., 2003, P IJCAI WORKSH REAS
   GUTMANN JS, 1999, COMPUTATIONAL INTELL
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   He L, 2007, IEEE I CONF COMP VIS, P2895
   KOLMOGOROV V, 2001, INT C COMP VIS ICCV
   KONOLIGE K, 1997, 8 INT S ROB RES ISRR
   LHUILLIER M, 2007, IEEE COMPUTER VISION
   LU F, 1997, AUTON ROBOT, V4, P1
   NAYAR SK, 1998, BMVC
   PARIS S, 2004, AS C COMP VIS ACCV J
   Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880
   *POINT GREY, POINT GREY RES
   Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   SKRABA P, 2007, LECT NOTES COMPUTER, V4549
   SWAMINATHAN R, 2004, 5 WORKSH OMN VIS MAY
   SZELISKI R, 2000, P INT WORKSH VIS ALG, P1
   WEISS C, 2005, AUTONOME MOBILE SYST
NR 34
TC 6
Z9 6
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 141
EP 152
DI 10.1016/j.imavis.2008.05.009
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700015
DA 2024-07-18
ER

PT J
AU Akselrod-Ballin, A
   Ullman, S
AF Akselrod-Ballin, Ayelet
   Ullman, Shimon
TI Distinctive and compact features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE feature selection; object recognition; distinctive features; facial
   features
ID FACE RECOGNITION; IMAGES
AB We consider the problem of extracting features for multi-class recognition problems. The features are required to make fine distinctions between similar classes, combined with tolerance for distortions and missing information. We define and compare two general approaches, both based on maximizing the delivered information for recognition: one divides the problem into multiple binary classification tasks, while the other uses a single multi-class scheme. The two strategies result in markedly different sets of features, which we apply to face identification and detection. We show that the first produces a sparse set of distinctive features that are specific to an individual face, and are highly tolerant to distortions and missing input. The second produces compact features, each shared by about half of the faces, which perform better in general face detection. The results show the advantage of distinctive features for making fine distinctions in a robust manner. They also show that different features are optimal for recognition tasks at different levels of specificity. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Akselrod-Ballin, Ayelet; Ullman, Shimon] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.
C3 Weizmann Institute of Science
RP Akselrod-Ballin, A (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.
EM ayelet.akselrod-ballin@weizmann.ac.il
CR [Anonymous], 2005, CVPR
   [Anonymous], 2003, CVPR
   [Anonymous], 2005, CVPR
   BACHMANN T, 1991, European Journal of Cognitive Psychology, V3, P87, DOI 10.1080/09541449108406221
   BART E, 2004, P ECCV, V2, P152
   Bartlett MS, 1997, ADV NEUR IN, V9, P817
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BRUCE V, 1994, Q J EXP PSYCHOL-A, V47, P119, DOI 10.1080/14640749408401146
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Epshtein B., 2005, ICCV
   EPSTEIN B, 2006, P IEEE CVPR, P2079
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9
   HOLUB A, 2005, CVPR
   Kanade T., 1973, COMPUTER RECOGNITION
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Phillips PJ, 1999, ADV NEUR IN, V11, P803
   PIVEN H, 2002, PIVEN AM
   RHODES G, 1997, SUPERPORTRAIT CARICA
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sali E., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P203
   SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Torralba A, 2004, PROC CVPR IEEE, P762
   Turk MatthewA., 1991, P CVPR 91, P586
   Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870
   ULLMAN S, 2001, IWVF4
   VASCONCELOS N, 2004, CVPR
   VIDALNAQUET A, 2003, ICCV
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 39
TC 7
Z9 9
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1269
EP 1276
DI 10.1016/j.imavis.2008.03.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300009
DA 2024-07-18
ER

PT J
AU Malassiotis, S
   Strintzis, MG
AF Malassiotis, S.
   Strintzis, M. G.
TI Real-time hand posture recognition using range data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE range data; gesture; hand; real time
ID REPRESENTATION
AB A hand posture recognition system using 3D data is described. The system relies on a novel 3D sensor that generates a dense range image of the scene. The main advantage of the proposed system, compared to other gesture recognition techniques, is the capability for robust unconstrained recognition of complex hand postures such as those encountered in sign language alphabets. This is achieved by explicitly utilizing 3D hand geometry. Moreover, the proposed approach does not rely on color information, and guarantees robust segmentation of the hand under varying illumination conditions, and scene content. Several novel 3D image analysis algorithms are presented, covering the complete processing chain: 3D image acquisition, arm segmentation, hand-forearm segmentation, hand pose estimation, 3D feature extraction, and gesture classification. The proposed system is extensively evaluated. (c) 2008 Published by Elsevier B.V.
C1 [Malassiotis, S.; Strintzis, M. G.] Ctr Res & Technol Hellas, Informat & Telemat Inst, GR-57001 Thessaloniki, Greece.
C3 Centre for Research & Technology Hellas
RP Malassiotis, S (corresponding author), Ctr Res & Technol Hellas, Informat & Telemat Inst, 1st Km Thermi Panorama Rd,POB 361, GR-57001 Thessaloniki, Greece.
EM malasiot@iti.gr
CR ATHITSOS V, 2003, C COMP VIS PATT RECG, V1
   BRAY M, 2004, 1 EUR C VIS MED PROD, P59
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   Chua CS, 2002, IMAGE VISION COMPUT, V20, P191, DOI 10.1016/S0262-8856(01)00094-4
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   DEIMEL B, 1998, 6911998 U DORTM
   Delamarre Q, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P585, DOI 10.1109/AFGR.1998.671011
   DU H, 2007, IEEE WORKSH APPL COM, P31
   Duda R. O., 2000, PATTERN CLASSIFICATI
   EROL A, 2005, IEEE COMP SOC C COMP, V3, P75
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Foley J.D., 1990, Computer graphics: Principles and practice
   Grzeszczuk R, 2000, PROC CVPR IEEE, P826, DOI 10.1109/CVPR.2000.855906
   GUAN H, 2006, AUT FAC GEST REC C F, V10, P263
   *I GERM SIGN LANG, ALPH SIGN LANG
   Jennings C., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P152, DOI 10.1109/RATFG.1999.799238
   Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2
   Jojic N., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P468, DOI 10.1109/AFGR.2000.840676
   JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181
   LIU X, IEEE INT C AUT FAC G
   Malassiotis S, 1999, IEEE T MED IMAGING, V18, P282, DOI 10.1109/42.764905
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   REHG JM, 1995, INT C COMP VIS JUN
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   Roweis S, 1998, ADV NEUR IN, V10, P626
   SKOCAJ D, 2001, 3 INT C 3D DIG IM MO
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Stenger B, 2007, IMAGE VISION COMPUT, V25, P1885, DOI 10.1016/j.imavis.2005.12.018
   TORR PHS, 2004, INT WORKSH HUM COMP
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   TSALAKANIDOU F, 2005, REAL TIME IMAGING SP, V11
   Umeda K, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P1727, DOI 10.1109/IROS.1998.724847
   UTSUMI A, 1999, IEEE C COMP VIS PATT, V1, P473
   Yin XM, 2007, IMAGE VISION COMPUT, V25, P1291, DOI 10.1016/j.imavis.2006.08.003
   Zhou H., 2004, IEEE C COMPUTER VISI, P161, DOI DOI 10.1109/CVPR.2004.169
NR 37
TC 46
Z9 69
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 1027
EP 1037
DI 10.1016/j.imavis.2007.11.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800015
DA 2024-07-18
ER

PT J
AU Ghosh, K
   Sarkar, S
   Bhaumik, K
AF Ghosh, Kuntal
   Sarkar, Sandip
   Bhaumik, Kamales
TI Understanding image structure from a new multi-scale representation of
   higher order derivative filters
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multi-scale filters; derivative filters; zero-crossings; non-classical
   receptive field
ID CLASSICAL RECEPTIVE-FIELD; ZERO-CROSSINGS; CELLS; ENHANCEMENT;
   INFORMATION
AB We are proposing a biologically inspired multi-scale derivative filter in which the higher order derivatives are expressed as a linear combination of a smoothing function at various scales. One of the functions in the summation has been approximated to a Dirac-delta function to finally yield the new filter. This modification has some support from the point of view of authentic edge detection as well as from neurophysiological and psychophysical experiments at the retinal level. Besides, it improves the quality of the filter in a number of ways. The proposed filter can be optimized at any desired scale. Hence it is very effective in extracting the features from a noisy picture. The filter is rotationally symmetric. Zero-crossing map of any picture filtered with the proposed model gives a half-toning effect to the retrieved image and hence preserves the intensity information in the image even in the edge map. (c) 2006 Elsevier B.V. All rights reserved.
C1 Saha Inst Nucl Phys, Microelect Div, Kolkata 700064, W Bengal, India.
   W Bengal Univ Technol, Kolkata 700064, W Bengal, India.
C3 Saha Institute of Nuclear Physics; Maulana Abul Kalam Azad University of
   Technology
RP Ghosh, K (corresponding author), Saha Inst Nucl Phys, Microelect Div, 11AF Bidhannagar, Kolkata 700064, W Bengal, India.
EM kuntal.ghosh@saha.ac.in
OI , Kuntal/0000-0002-4431-1404
CR Bracewell R.N, 2003, FOURIER TRANSFORM IT, P151
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   DEVALOIS RL, 1982, VISION RES, V22, P545, DOI 10.1016/0042-6989(82)90113-4
   ENROTHCUGELL C, 1966, J PHYSIOL-LONDON, V187, P517, DOI 10.1113/jphysiol.1966.sp008107
   ENROTHCUGELL C, 1980, J PHYSIOL-LONDON, V302, P49
   Ghosh K, 2005, LECT NOTES COMPUT SC, V3776, P453
   Ghosh K, 2006, BIOL CYBERN, V94, P89, DOI 10.1007/s00422-005-0038-4
   Ghosh K, 2005, BIOL CYBERN, V93, P1, DOI 10.1007/s00422-005-0580-0
   GHOSH K, 2005, P 2 IND INT C ART PU, P3234
   IKEDA H, 1972, VISION RES, V12, P1857, DOI 10.1016/0042-6989(72)90076-4
   IVERSON LA, 1995, IEEE T PATTERN ANAL, V17, P982, DOI 10.1109/34.464562
   Kennedy LM, 1997, PATTERN RECOGN, V30, P2001, DOI 10.1016/S0031-3203(97)00014-9
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   KOENDERINK JJ, 1982, PERCEPTION, V11, P129, DOI 10.1068/p110129
   KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   KOPLOWITZ J, 1994, IEEE T PATTERN ANAL, V16, P1207, DOI 10.1109/34.387487
   KRUGER J, 1980, BRAIN RES, V201, P71, DOI 10.1016/0006-8993(80)90776-3
   Lindeberg T, 1994, SCALE SPACE THEORY C, P31
   LOGAN BF, 1977, AT&T TECH J, V56, P487, DOI 10.1002/j.1538-7305.1977.tb00522.x
   MA SD, 1998, IMAGE VISION COMPUT, V16, P43
   MARR D, 1980, J OPT SOC AM, V70, P868, DOI 10.1364/JOSA.70.000868
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   MARR D, 1979, J OPT SOC AM, V69, P914, DOI 10.1364/JOSA.69.000914
   Marr D., 1982, Vision
   MCILWAIN JT, 1966, EXP BRAIN RES, V1, P265
   Passaglia CL, 2001, J NEUROSCI, V21, P5794, DOI 10.1523/JNEUROSCI.21-15-05794.2001
   RATLIFF F, 1965, QUANTITATIVE STUDIES, P321
   RODIECK RW, 1965, J NEUROPHYSIOL, V28, P833, DOI 10.1152/jn.1965.28.5.833
   SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275
   Sarkar S, 2005, 2005 INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, PROCEEDINGS, P458, DOI 10.1109/ICISIP.2005.1529498
   Sceniak MP, 2002, J NEUROPHYSIOL, V88, P1363, DOI 10.1152/jn.2002.88.3.1363
   Sun C, 2004, NEUROSCIENCE, V125, P495, DOI 10.1016/j.neuroscience.2004.01.036
   WEISS I, 1994, IEEE T PATTERN ANAL, V16, P734, DOI 10.1109/34.297955
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   YOUNG R A, 1987, Spatial Vision, V2, P273, DOI 10.1163/156856887X00222
   YOUNG RA, 1985, GEN MOTORS RES PUBLI
   YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI 10.1109/TPAMI.1986.4767748
NR 38
TC 19
Z9 23
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1228
EP 1238
DI 10.1016/j.imavis.2006.07.022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000003
DA 2024-07-18
ER

PT J
AU Yin, XM
   Xie, M
AF Yin, Xiaoming
   Xie, Ming
TI Finger identification and hand posture recognition for human-robot
   interaction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE hand finger identification; hand posture recognition; hand image
   segmentation; human-robot interaction; robot programming
AB Natural and friendly interface is critical for the development of service robots. Gesture-based interface offers a way to enable untrained users to interact with robots more easily and efficiently. In this paper, we present a posture recognition system implemented on a real humanoid service robot. The system applies RCE neural network based color segmentation algorithm to separate hand images from complex backgrounds. The topological features of the hand are then extracted from the silhouette of the segmented hand region. Based on the analysis of these simple but distinctive features, hand postures are identified accurately. Experimental results on gesture-based robot programming demonstrated the effectiveness and robustness of the system. (c) 2006 Elsevier B.V. All rights reserved.
C1 Singapore Inst Mfg Technol, Singapore 638075, Singapore.
   Nanyang Technol Univ, Sch Mech & Prod Engn, Singapore 639798, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Singapore
   Institute of Manufacturing Technology (SIMTech); Nanyang Technological
   University
RP Yin, XM (corresponding author), Singapore Inst Mfg Technol, 71 Nanyang Dr, Singapore 638075, Singapore.
EM xmyin@simtech.a-star.edu.sg; mmxie@ntu.edu.sg
RI Xie, Ming/GOV-6892-2022; Xie, Ming/A-3821-2011
OI Xie, Ming/0000-0002-1696-9030; Xie, Ming/0000-0002-1696-9030
CR [Anonymous], 1995, P INT WORKSH AUT FAC
   Bekey GA, 1997, IEEE ROBOT AUTOM MAG, V4, P12
   Dario P, 1996, ROBOT AUTON SYST, V18, P225, DOI 10.1016/0921-8890(96)00006-1
   Ejiri M, 1996, ROBOT AUTON SYST, V18, P1, DOI 10.1016/0921-8890(95)00083-6
   Freeman W.T., 1995, International Workshop on Automatic Face- and Gesture- Recognition," in, P179
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kahn RE, 1996, PROC CVPR IEEE, P734, DOI 10.1109/CVPR.1996.517154
   Kang SB, 1997, IEEE T ROBOTIC AUTOM, V13, P81, DOI 10.1109/70.554349
   Kaplan G, 1998, IEEE SPECTRUM, V35, P73, DOI 10.1109/6.645984
   KASSON JM, 1992, ACM T GRAPHIC, V11, P373, DOI 10.1145/146443.146479
   Kawamura K, 1996, ROBOT AUTON SYST, V18, P109, DOI 10.1016/0921-8890(96)00005-X
   Kjeldsen R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P151, DOI 10.1109/AFGR.1996.557257
   Kjeldsen R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P312, DOI 10.1109/AFGR.1996.557283
   Krueger M.K., 1991, Artificial Reality, V2
   Maggioni C., 1995, P INT WORKSH AUT FAC
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211
   Segen J, 1998, INT C PATT RECOG, P86, DOI 10.1109/ICPR.1998.711086
   Triesch J, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P546, DOI 10.1109/AFGR.1998.671005
   Yang J, 1998, ACCV98, P687
   Yin XM, 2001, ROBOT AUTON SYST, V34, P235, DOI 10.1016/S0921-8890(00)00125-1
NR 21
TC 36
Z9 39
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1291
EP 1300
DI 10.1016/j.imavis.2006.08.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000010
DA 2024-07-18
ER

PT J
AU Karatzas, D
   Antonacopoulos, A
AF Karatzas, D.
   Antonacopoulos, A.
TI Colour text segmentation in web images based on human perception
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE web document image analysis; colour document analysis; character
   segmentation; text segmentation; colour images
ID LOCATION
AB There is a significant need to extract and analyse the text in images on Web documents, for effective indexing, semantic analysis and even presentation by non-visual means (e.g., audio). This paper argues that the challenging segmentation stage for such images benefits from a human perspective of colour perception in preference to RGB colour space analysis. The proposed approach enables the segmentation of text in complex situations such as in the presence of varying colour and texture (characters and background). More precisely, characters are segmented as distinct regions with separate chromaticity and/or lightness by performing a layer decomposition of the image. The method described here is a result of the authors' systematic approach to approximate the human colour perception characteristics for the identification of character regions. In this instance, the image is decomposed by performing histogram analysis of Hue and Lightness in the HLS colour space and merging using information on human discrimination of wavelength and luminance. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Salford, PRImA Res Lab, Sch Comp Sci & Engn, Salford M5 4WT, Lancs, England.
   Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
C3 University of Salford; University of Southampton
RP Antonacopoulos, A (corresponding author), Univ Salford, PRImA Res Lab, Sch Comp Sci & Engn, Salford M5 4WT, Lancs, England.
EM A.Antonacopoulos@primaresearch.org
RI Karatzas, Dimosthenis/C-7142-2008
OI Karatzas, Dimosthenis/0000-0001-8762-4454
CR [Anonymous], P ACM INT C DIG LIB
   Antonacopoulos A, 1998, COMPUT VIS IMAGE UND, V70, P350, DOI 10.1006/cviu.1998.0691
   Antonacopoulos A, 2001, P SOC PHOTO-OPT INS, V4311, P198
   ANTONACOPOULOS A, 2003, WEB DOCUMENT ANAL CH
   ANTONACOPOULOS A, 1999, VISUAL REPRESENTATIO
   ANTONACOPOULOS A, 2000, P 4 IAPR WORKSH DOC, P515
   BEDFORD RE, 1958, J OPT SOC AM, V48
   Brown M.K., 2001, P 1 INT WORKSH WEB D, P59
   Clark P., 2002, International Journal on Document Analysis and Recognition, V4, P243, DOI 10.1007/s10032-001-0072-2
   Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3
   KARATZAS D, 2002, THESIS U LIVERPOOL
   Kim HK, 1996, J VIS COMMUN IMAGE R, V7, P336, DOI 10.1006/jvci.1996.0029
   Ledley R.S., 1990, P INT C PATT REC, V1, P791, DOI DOI 10.1109/ICPR.1990.118218
   Lienhart R, 1996, P SOC PHOTO-OPT INS, V2666, P180, DOI 10.1117/12.234741
   Lopresti D., 2000, Information Retrieval, V2, P177, DOI 10.1023/A:1009954710479
   Messelodi S, 1999, PATTERN RECOGN, V32, P791, DOI 10.1016/S0031-3203(98)00108-3
   Moghaddamzadeh A, 1997, PATTERN RECOGN, V30, P867, DOI 10.1016/S0031-3203(96)00084-2
   Penn G., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P1074, DOI 10.1109/ICDAR.2001.953951
   Silverstein L., 1987, COLOR COMPUTER, P27
   Tominaga S., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P628
   Weeks AR, 1997, P SOC PHOTO-OPT INS, V3026, P143, DOI 10.1117/12.271117
   Wyszecki G., 1982, Color science: Concepts and methods, quantitative data and formulae
NR 22
TC 26
Z9 28
U1 1
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 564
EP 577
DI 10.1016/j.imavis.2006.05.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200005
DA 2024-07-18
ER

PT J
AU Sun, TK
   Chen, SC
AF Sun, Tingkai
   Chen, Songcan
TI Locality preserving CCA with applications to data visualization and pose
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE canonical correlation analysis (CCA); locality preservation; pose
   estimation; data visualization; dimensionality reduction
ID CANONICAL CORRELATION-ANALYSIS; DIMENSIONALITY REDUCTION; FACE
   RECOGNITION
AB Canonical correlation analysis (CCA) is a major linear subspace approach to dimensionality reduction and has been applied to image processing, pose estimation and other fields. However, it fails to discover or reveal the nonlinear correlation relationship between two sets of features. In contrast, its kernelized nonlinear version, KCCA, can overcome such a shortcoming, but the global kernelization of CCA restrains KCCA itself from effectively discovering the local structure of the data with complex and nonlinear characteristics. Recently, the locality methods, such as locally linear embedding (LLE) and locality preserving projections (LPP), are proposed to discover the low dimensional manifold embedded into the original high dimensional space. Compared to the subspace based methods, these locality methods take into account the local neighborhood structure of the data, and can discover the intrinsic structure of data to a better degree, which benefits subsequent computation. Inspired by the locality based methods, in this paper, we incorporate such an idea into CCA and propose locality preserving CCA (LPCCA) to discover the local manifold structure of the data and further apply it to data visualization and pose estimation. In addition, a fast algorithm of LPCCA is proposed for some special cases. The experiments show that LPCCA can both capture the intrinsic structure characteristic of the given data and achieve higher pose estimation accuracy than both CCA and KCCA. (c) 2006 Elsevier B.V. All rights reserved.
C1 Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Chen, SC (corresponding author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.
EM suntingkai@nuaa.edu.cn; s.chen@nuaa.edu.cn
CR Abraham B, 2005, COMPUT STAT DATA AN, V48, P5, DOI 10.1016/j.csda.2003.11.021
   [Anonymous], 2004, ADV NEURAL INFORM PR
   Ayat NE, 2005, PATTERN RECOGN, V38, P1733, DOI 10.1016/j.patcog.2005.03.011
   Belkin M., 2001, P C ADV NEUR INF PRO, V15
   *BLZA FORT, SIKDD 2004 MULT IS 2
   BORGA M, 1998, THESIS LINKOPING U L
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860
   FRIMAN O, 2001, P SSAB S IM AN NORRK
   Gou Z, 2004, NEURAL NETWORKS, V17, P285, DOI 10.1016/j.neunet.2003.07.002
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hoegaerts L, 2005, NEUROCOMPUTING, V63, P293, DOI 10.1016/j.neucom.2004.04.013
   Horikawa Y, 2004, LECT NOTES COMPUT SC, V3316, P1235
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493
   KIDRON E, 2005, IEEE P COMPUTER VISI, V1, P88
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   LAI PL, 2000, THESIS U PAISLEY SCO
   Loog M, 2005, PATTERN RECOGN, V38, P2409, DOI 10.1016/j.patcog.2005.04.011
   Mathworks Inc, 2005, MATL 7 0 REL 14 HELP
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Min WL, 2004, PATTERN RECOGN, V37, P781, DOI 10.1016/j.patcog.2003.09.005
   MURASE H, 1994, IEEE T PATTERN ANAL, V16, P1219, DOI 10.1109/34.387485
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Nayar SK, 1996, IEEE T ROBOTIC AUTOM, V12, P750, DOI 10.1109/70.538979
   Nene S. A., 1996, COLUMBIA OBJECT IMAG
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   PAN H, 1999, IEEE P C COMPUTER VI, V2, P407
   Parrado-Hernández E, 2003, NEUROCOMPUTING, V55, P135, DOI 10.1016/S0925-2312(03)00432-6
   RAYTCHEV B, 2004, IEEE P 17 INT C PATT
   Roweis SamT., 2003, J MACHINE LEARNING R, V4, P119
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Van Gestel T, 2001, LECT NOTES COMPUT SC, V2130, P384
   VERBEEK JJ, 2004, ADV NEURAL INFORM PR
   Vlassis N., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2979, DOI 10.1109/ROBOT.2000.846480
   YACOV HO, 2004, HPL2003164R1
   Yamanishi Y, 2003, BIOINFORMATICS, V19, pi323, DOI 10.1093/bioinformatics/btg1045
NR 44
TC 169
Z9 203
U1 0
U2 39
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 531
EP 543
DI 10.1016/j.imavis.2006.04.014
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200002
DA 2024-07-18
ER

PT J
AU Del Bue, A
   Smeraldi, F
   Agapito, L
AF Del Bue, A.
   Smeraldi, F.
   Agapito, L.
TI Non-rigid structure from motion using ranklet-based tracking and
   non-linear optimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE non-rigid structure for motion; rank features; ranklets; point tracking
ID MODELS; SHAPE
AB In this paper, we address the problem of estimating the 3D structure and motion of a deformable object given a set of image features tracked automatically throughout a video sequence. Our contributions are twofold: firstly, we propose a new approach to improve motion and structure estimates using a non-linear optimization scheme and secondly we propose a tracking algorithm based on ranklets, a recently developed family of orientation selective rank features.
   It has been shown that if the 3D deformations of an object can be modeled as a linear combination of shape bases then both its motion and shape may be recovered using an extension of Tomasi and Kanade's factorization algorithm for affine cameras. Crucially, these new factorization methods are model free and work purely from video in an unconstrained case: a single uncalibrated camera viewing an arbitrary 31) surface which is moving and articulating. The main drawback of existing methods is that they do not provide correct structure and motion estimates: the motion matrix has a repetitive structure which is not respected by the factorization algorithm. In this paper, we present a non-linear optimization method to refine the motion and shape estimates which minimizes the image reprojection error and imposes the correct structure onto the motion matrix by choosing an appropriate parameterization.
   Factorization algorithms require as input a set of feature tracks or correspondences found throughout the image sequence. The challenge here is to track the features while the object is deforming and the appearance of the image therefore changing. We propose a model free tracking algorithm based on ranklets, a multi-scale family of rank features that present an orientation selectivity pattern similar to Haar wavelets. A vector of ranklets is used to encode an appearance based description of a neighborhood of each tracked point. Robustness is enhanced by adapting, for each point, the shape of the filters to the structure of the particular neighborhood. A stack of models is maintained for each tracked point in order to manage large appearance variations with limited drift. Our experiments on sequences of a human subject performing different facial expressions show that this tracker provides a good set of feature correspondences for the non-rigid 3D reconstruction algorithm. (c) 2006 Elsevier B.V. All rights reserved.
C1 Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England.
C3 University of London; Queen Mary University London
RP Del Bue, A (corresponding author), Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England.
EM lourdes@dcs.qmul.ac.uk
OI Del Bue, Alessio/0000-0002-2262-4872; Agapito,
   Lourdes/0000-0002-6947-1092
CR Aans H., 2002, WORKSH VIS MOD DYN S
   [Anonymous], 2001, P IEEE C COMP VIS PA
   Bhat DN, 1996, PROC CVPR IEEE, P351, DOI 10.1109/CVPR.1996.517096
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Brand M, 2001, PROC CVPR IEEE, P456
   Brand M, 2001, PROC CVPR IEEE, P315
   Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DELBUE A, 2004, AS C COMP VIS 25 30
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Irani M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P626, DOI 10.1109/ICCV.1999.791283
   LEHMANN EL, 1975, NONPARMETRICS STAT M
   LEUNG AP, 2005, P BRIT MACH VIS C OX
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Manjunath BS, 1996, PATTERN RECOGN, V29, P627, DOI 10.1016/0031-3203(95)00115-8
   MATTHEWS I, 2003, P BRIT MACH VIS C, V2, P649
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   RAO RPN, 1995, ARTIF INTELL, V78, P461, DOI 10.1016/0004-3702(95)00026-7
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Smeraldi F, 2003, LECT NOTES COMPUT SC, V2688, P351
   Smeraldi F, 2002, INT C PATT RECOG, P379, DOI 10.1109/ICPR.2002.1047924
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Xiao J, 2004, PROC CVPR IEEE, P668
   Xiao J, 2004, LECT NOTES COMPUT SC, V2034, P573
   Zabih R., 1994, P ECCV, P151
NR 27
TC 31
Z9 35
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 297
EP 310
DI 10.1016/j.imavis.2005.10.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100006
DA 2024-07-18
ER

PT J
AU Vogler, C
   Goldenstein, S
   Stolfi, J
   Pavlovic, V
   Metaxas, D
AF Vogler, Christian
   Goldenstein, Siome
   Stolfi, Jorge
   Pavlovic, Vladimir
   Metaxas, Dimitris
TI Outlier rejection in high-dimensional deformable models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE outlier rejection; robust methods; deformable models; 3D face tracking
ID ROBUST; TRACKING; FLOW
AB Deformable model tracking is a powerful methodology that allows us to track the evolution of high-dimensional parameter vectors from uncalibrated monocular video sequences. The core of the approach consists of using low-level vision algorithms, such as edge trackers or optical flow, to collect a large number of 2D displacements, or motion measurements, at selected model points and mapping them into 3D space with the model Jacobians. However, the low-level algorithms are prone to errors and outliers, which can skew the entire tracking procedure if left unchecked.
   There are several known techniques in the literature, such as RANSAC, that can find and reject outliers. Unfortunately, these approaches are not easily mapped into the deformable model tracking framework, where there is no closed-form algebraic mapping from samples to the underlying parameter space. In this paper, we present three simple, yet effective ways to find the outliers. We validate and compare these approaches in an I I parameter deformable face tracking application against ground truth data. (c) 2006 Elsevier B.V. All rights reserved.
C1 Gallaudet Univ, Gallaudet Res Inst, Washington, DC 20002 USA.
   Univ Estadual Campinas, Inst Computacao, BR-13084971 Campinas, SP, Brazil.
   Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
C3 Universidade Estadual de Campinas; Rutgers University System; Rutgers
   University New Brunswick
RP Vogler, C (corresponding author), Gallaudet Univ, Gallaudet Res Inst, 800 Florida Ave NE,HMB S-433, Washington, DC 20002 USA.
EM christian.vogler@gallaudet.edu; siome@ic.unicamp.br;
   stolfi@ic.unicamp.br; vladimir@cs.rutgers.edu; dnm@cs.rutgers.edu
RI Stolfi, Jorge/B-3304-2012; Goldenstein, Siome K/A-4468-2013
OI Pavlovic, Vladimir/0000-0003-3979-1236
CR [Anonymous], IEEE T PATTERN ANAL
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Brand M, 2001, PROC CVPR IEEE, P315
   BROWN BM, 1983, J ROY STAT SOC B MET, V45, P25
   Brown LM, 2001, PROC CVPR IEEE, P998
   Chakraborty B, 1999, STAT PROBABIL LETT, V45, P269, DOI 10.1016/S0167-7152(99)00067-X
   Chen HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P878, DOI 10.1109/ICCV.2003.1238441
   Chen HF, 2002, LECT NOTES COMPUT SC, V2350, P236
   DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811
   DECARLO D, 1998, P SIGGRAPH 98, P67, DOI DOI 10.1145/280814.280823
   Dimitrijevic M, 2004, PROC CVPR IEEE, P1034
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goldenstein S., 2004, P IEEE COMP VIS PATT
   GOLDENSTEIN S, 2002, THESIS U PENNSYLVANI
   Goldenstein SK, 2003, IEEE T PATTERN ANAL, V25, P801, DOI 10.1109/TPAMI.2003.1206510
   HAMPEL FR, 1974, J AM STAT ASSOC, V69, P383, DOI 10.2307/2285666
   LIU RY, 1990, ANN STAT, V18, P405, DOI 10.1214/aos/1176347507
   MARONNA RA, 1976, ANN STAT, V4, P51, DOI 10.1214/aos/1176343347
   Meer P, 2000, COMPUT VIS IMAGE UND, V78, P1, DOI 10.1006/cviu.1999.0833
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Pighin F, 2002, INT J COMPUT VISION, V50, P143, DOI 10.1023/A:1020393915769
   Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210
   PIGHIN F, 1998, P SIGGRAPH 98, P75
   Romdhani S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P59
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566
   ROUSSEEUW PJ, 1999, COMPUTING SCI STAT, V31, P451
   Samaras D, 2000, PROC CVPR IEEE, P480, DOI 10.1109/CVPR.2000.855858
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tao H, 2002, INT J COMPUT VISION, V50, P111, DOI 10.1023/A:1020389714861
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Torr PHS, 2003, IEEE T PATTERN ANAL, V25, P354, DOI 10.1109/TPAMI.2003.1182098
   Wen Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1343, DOI 10.1109/ICCV.2003.1238646
   Wilcox RR., 2003, Applying Contemporary Statistical Techniques, DOI DOI 10.1016/B978-012751541-0/50029-8
NR 36
TC 6
Z9 7
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 274
EP 284
DI 10.1016/j.imavis.2005.10.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100004
DA 2024-07-18
ER

PT J
AU de Carvalho, MAG
   Lotufo, RDA
   Couprie, M
AF de Carvalho, Marco A. G.
   Lotufo, Roberto de A.
   Couprie, Michel
TI Morphological segmentation of yeast by image analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE yeast; watershed; scale-space; image analysis
ID MARXIANUS NRRLY2415
AB An image analysis method has been developed to segment yeast cells. Yeasts belong to the taxonomic group fungi and have been used on fuel and food industry, for example. The method is capable of segmenting yeast cells based on Watershed Transform and space-scale analysis of the Tree of Critical Lakes. We analise hierarchical, geometric and gray-scale properties of the Tree of Critical Lakes. We show experimental results for one group of yeast images obtained from the School ofFood Engineering at Unicamp, Brazil. Comparison shows that the proposed method provides cells with area 10% lower than traditional approach. Moreover, this approach preserves the cells contour, an important feature because of the performance of bioreactors and other chemical processes are greatly influenced by their morphological character. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Estadual Campinas, FEEC, DCA, BR-13083970 Campinas, SP, Brazil.
   A2 SI ESIEE Cite Descartes, F-93162 Noisy Le Grand, France.
C3 Universidade Estadual de Campinas
RP de Carvalho, MAG (corresponding author), Univ Estadual Campinas, FEEC, DCA, Caixa Postal 6101, BR-13083970 Campinas, SP, Brazil.
EM magic@dca.fee.unicamp.br; lotufo@dca.fee.unicamp.br; coupriem@esice.fr
RI Lotufo, Roberto/C-1496-2009; Carvalho, Marco/J-6634-2017
OI Lotufo, Roberto/0000-0002-5652-0852; Carvalho, Marco/0000-0002-1941-6036
CR Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   CARVALHO MAG, 2002, P 15 BRAZ S COMP GRA, P403
   CUTSEM BV, 1998, J CLASSIF, V15, P93
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Gondran M., 1995, Graphes Et Algorithmes, V3
   Kurtzman C.P., 1998, YEASTS TAXONOMIC STU, V4th
   LOTUFO RA, 2002, P INT S MATH MORPH S
   Metzler V.T, 2002, P ISMM2002 AUSTR APR, P265
   Meyer F, 1996, COMPUT IMAGING VIS, P329
   Meyer F, 1999, LECT NOTES COMPUT SC, V1682, P351
   O'Shea DG, 2000, APPL MICROBIOL BIOT, V53, P316, DOI 10.1007/s002530050027
   OShea DG, 1996, BIOTECHNOL BIOENG, V51, P679, DOI 10.1002/(SICI)1097-0290(19960920)51:6<679::AID-BIT6>3.0.CO;2-E
   PONS MN, 1993, BIOTECHNOL BIOENG, V42, P1352, DOI 10.1002/bit.260421112
   VACHIER C, 1995, THESIS ECOLE MINES P
   Zalewski K, 1996, J BIOTECHNOL, V48, P43, DOI 10.1016/0168-1656(96)01503-9
   ZANOGUERA F, 2001, THESIS ECOLE MINES P
NR 16
TC 15
Z9 17
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 34
EP 39
DI 10.1016/j.imavis.2006.01.006
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600005
DA 2024-07-18
ER

PT J
AU Penman, DW
   Alwesh, NS
AF Penman, David W.
   Alwesh, Nawar S.
TI 3D pose estimation of symmetrical objects of unknown shape
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE orientation; pose estimation; symmetry; range data
AB The estimation of the pose of an object is a frequent requirement in computer vision tasks. This paper outlines a method for estimating the pose of an object having a plane of bilateral symmetry but of otherwise unknown shape. The method can operate with a set of 3D range data suffering from self-occlusion, as is obtained from a single viewpoint. (C) 2006 Elsevier B.V. All rights reserved.
C1 Ind Res Ltd, Auckland, New Zealand.
C3 Callaghan Innovation
RP Penman, DW (corresponding author), Ind Res Ltd, POB 2225, Auckland, New Zealand.
EM d.penman@irl.cri.nz; n.alwesh@irl.cri.nz
CR BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Duda R. O., 2000, PATTERN CLASSIFICATI
   GIERES F, 1998, P 5 SEM RHOD PHYS DO
   Hattori K, 1998, INT C PATT RECOG, P1183, DOI 10.1109/ICPR.1998.711908
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Jenkinson M, 2002, IMAGE VISION COMPUT, V20, P85, DOI 10.1016/S0262-8856(01)00080-4
   Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2
   OLIVIER D, 2000, COW ZIP RAW FILE CON
   OMara D, 1996, TENCON IEEE REGION, P151, DOI 10.1109/TENCON.1996.608740
   Sun CM, 1997, IEEE T PATTERN ANAL, V19, P164, DOI 10.1109/34.574800
   ZABRODSKY H, 1995, J AM CHEM SOC, V117, P462, DOI 10.1021/ja00106a053
   Zabrodsky H, 1997, COMPUT VIS IMAGE UND, V67, P48, DOI 10.1006/cviu.1996.0506
   Zhou J, 2002, IMAGE VISION COMPUT, V20, P257, DOI 10.1016/S0262-8856(02)00018-5
NR 13
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 447
EP 454
DI 10.1016/j.imavis.2006.01.019
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600005
DA 2024-07-18
ER

PT J
AU Gladilin, E
   Pekar, V
   Rohr, K
   Stiehl, HS
AF Gladilin, E.
   Pekar, V.
   Rohr, K.
   Stiehl, H. S.
TI A comparison between BEM and FEM for elastic registration of medical
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE elastic image registration; deformable modeling; boundary element
   method; finite element method
AB The aim of medical image registration is to bring different images into the best possible spatial correspondence in order to obtain complementary information for clinical applications. When using physically-based techniques for image registration the transformation of images is typically obtained as the solution of partial differential equations of continuum mechanics. Because of the complexity of real boundary conditions, these equations can usually be solved with the help of numerical techniques only. One standard numerical method is the boundary element method (HEM) which allows to compute the solution exclusively through boundary integration. This paper investigates the applicability of BEM for registration of medical images and quantitatively assesses its advantages and disadvantages in comparison to the previously used finite element method (FEM). (c) 2006 Elsevier B.V. All rights reserved.
C1 German Canc Res Ctr, DKFZ, TBI, D-69120 Heidelberg, Germany.
   Heidelberg Univ, IPMB, D-69120 Heidelberg, Germany.
   Philips Res Labs, D-22335 Hamburg, Germany.
   Univ Hamburg, FB Informat, AB KOGS, D-22527 Hamburg, Germany.
C3 Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht
   Karls University Heidelberg; Philips; Philips Research; University of
   Hamburg
RP Gladilin, E (corresponding author), German Canc Res Ctr, DKFZ, TBI, Neuenheimer Feld 580, D-69120 Heidelberg, Germany.
EM e.gladilin@dkfz.de
CR BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3
   Ballard D.H., 1982, Computer Vision
   Beskos D.E., 1987, Boundary element methods in mechanics
   Christensen GE, 1996, COMPUTER, V29, P32, DOI 10.1109/2.481434
   CLERC M, 2002, P BIOMAG2002 JEN GER
   Davatzikos C, 1997, COMPUT VIS IMAGE UND, V66, P207, DOI 10.1006/cviu.1997.0605
   GEE JC, 1994, P SOC PHOTO-OPT INS, V2167, P327, DOI 10.1117/12.175067
   GLADILIN E, 1999, FBIHHM28799 U HAMB
   Hagemann A, 1999, IEEE T MED IMAGING, V18, P875, DOI 10.1109/42.811267
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   LANDAU LD, 1989, LEHRBUCH THEORETISCH, V7
   MICCOLI S, 2002, P IABEM 2002 AUST US
   Peckar W, 1999, J MATH IMAGING VIS, V10, P143, DOI 10.1023/A:1008375006703
   Schwarz H., 1991, METHODE FINITEN ELEM
NR 14
TC 2
Z9 3
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2006
VL 24
IS 4
BP 375
EP 379
DI 10.1016/j.imavis.2005.12.013
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 049US
UT WOS:000238043500006
DA 2024-07-18
ER

PT J
AU Liu, XH
   Chua, CS
AF Liu, XH
   Chua, CS
TI Multi-agent activity recognition using observation decomposed hidden
   Markov models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE hidden Markov models; activity recognition; visual surveillance;
   multi-agent activities
ID GESTURE RECOGNITION; BEHAVIOR
AB To automatically recognize multi-agent activities is a highly challenging task due to the complexity of the interactions between agents. The difficulties in this task stern from two aspects: firstly, the feature vectors derived from input data are of large dimensionality and variable length. Secondly, an efficient mapping of agents from input data to pre-defined activity models, known as agent assignment, is required. This paper presents a new method to model and classify multi-agent activities based on the proposed observation decomposed hidden Markov models (ODHMMs). To handle the feature vectors, we decomposed each original feature vector into a Set Of sub-feature vectors to keep the explored feature space consistent. Agent assignment is realized using a newly introduced parameter, which represents the 'role' of each agent. The experimental results show that the proposed method can successfully classify three-person activities with high accuracy and is less sensitive to incomplete data input. (c) 2005 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Elect & Elect Engn, Nanyang Ave, Singapore 639798, Singapore.
EM ecschua@ntu.edu.sg
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Campbell LW, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P157, DOI 10.1109/AFGR.1996.557258
   CHENYU D, 2002, P INT C DEV LEARN, P28
   Galata A, 2001, COMPUT VIS IMAGE UND, V81, P398, DOI 10.1006/cviu.2000.0894
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Hongeng S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P84, DOI 10.1109/ICCV.2001.937608
   Huang X. D., 1990, Hidden Markov Models for Speech Recognition
   Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896
   IVANOV Y, 1999, IEEE PAMI, V22, P852
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   OLIVER N, 2001, IEEE PAMI, V22, P831
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rota N, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P59, DOI 10.1109/VS.2000.856858
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Wada T, 2000, IEEE T PATTERN ANAL, V22, P873, DOI 10.1109/34.868687
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
NR 19
TC 30
Z9 36
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 166
EP 175
DI 10.1016/j.imavis.2005.09.024
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900006
DA 2024-07-18
ER

PT J
AU Chen, XJ
   Teoh, EK
AF Chen, XJ
   Teoh, EK
TI 3D object segmentation using B-Surface
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D object segmentation; deformable model
AB 3D object segmentation is important in computer vision such as target detection in biomedical image analysis. A new method, called B-Surface algorithm, is generated for 3D object segmentation. An improved 3D external force field combined with the normalized GVF is utilized. After the initialization of a surface model near the target, B-Surface starts to deform to locate the boundary of the object. First, it overcomes the difficulty that comes from analyzing 3D volume image slice by slice. And the speed of B-Surface deformation is enhanced since the internal forces are not needed to compute in every iteration deformation step. Next, the normal at every surface point can be calculated easily since B-Surface is a continuous deformable model. And it has the ability to achieve high compression ratio (ratio of data to parameters) by presenting the whole surface with only a relatively small number of control points. Experimental results and analysis are presented in this paper. We can see that the B-Surface algorithm can find the surface of the target efficiently. (C) 2005 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Elect & Elect Engn, Nanyang Ave, Singapore 639798, Singapore.
EM chenxujian@pmail.ntu.edu.sg
CR ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098
   CHAN TF, 2001, IEEE T IMAGE PROCESS, V10
   Davatzikos C, 1996, IEEE T MED IMAGING, V15, P785, DOI 10.1109/42.544496
   Huang JT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P732, DOI 10.1109/ICIP.1998.723600
   Iannizzotto G, 2000, IEEE T IMAGE PROCESS, V9, P1232, DOI 10.1109/83.847835
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lin N, 2003, MED IMAGE ANAL, V7, P529, DOI 10.1016/S1361-8415(03)00035-5
   Meegama RGN, 2003, IMAGE VISION COMPUT, V21, P551, DOI 10.1016/S0262-8856(03)00066-0
   RAJAPAKSE JC, ROB VIS ICARCV 02, P520
   Rey D, 2002, MED IMAGE ANAL, V6, P163, DOI 10.1016/S1361-8415(02)00056-7
   Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111
   STAIB LH, 1992, P 2 C VIS BIOM COMP, V1808
   Tao XD, 2002, IEEE T MED IMAGING, V21, P513, DOI 10.1109/TMI.2002.1009387
   Whitaker RT, 1998, INT J COMPUT VISION, V29, P203, DOI 10.1023/A:1008036829907
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yamaguchi F., 1988, CURVES SURFACES COMP
   [No title captured]
NR 17
TC 9
Z9 9
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 12
PY 2005
VL 23
IS 14
BP 1237
EP 1249
DI 10.1016/j.imavis.2005.09.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 997KJ
UT WOS:000234243800001
DA 2024-07-18
ER

PT J
AU Viéville, T
AF Viéville, T
TI An unbiased implementation of regularization mechanisms
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE regularization methods; diffusion operator; unbiased implementation
AB In computer or biological vision, computation of vectorial maps of parametric quantities (e.g. feature parameters, 3D or motion cues,..) are of common use in perceptual processes. Defining them using continuous partial differential equations yields highly parallelizable regularization processes allowing to obtain well-defined estimations of these quantities.
   However these equations have to be sampled on real data and this step is not obvious and may introduce some bias. In order to overcome this caveat, a method, introduced by Raviat and developed by Degond and Mas-Gallic, is based on an integral approximation of the diffusion operator used in regularization mechanisms: it leads to a so-called "particle" implementation of such diffusion process.
   Following this formulation, the present development defines an optimal implementation of such an integral operator with the interesting property that when used on sampled data such as image pixels or 3D data voxels, it provides an unbiased implementation of the corresponding continuous operator without any other approximation.
   Furthermore, the method is 'automatic' (using symbolic computations) in the sense that given a continuous regularization mechanism, the corresponding (non-linear) discrete filter is derived automatically, as made explicit here.
   A step ahead, the architecture of the implementation corresponds to what is observed in cortical visual maps, leading to a certain biological plausibility.
   The present development is illustrated by an experiment of visual motion estimation and another experiment in image denoising. (c) 2005 Elsevier B.V. All rights reserved.
CR Alvarez L., 1994, Acta Numerica, V3, P1
   [Anonymous], 2002, MATH PROBLEMS IMAGE
   Bugmann G, 1997, BIOSYSTEMS, V40, P11, DOI 10.1016/0303-2647(96)01625-5
   BULLIER J, 2004, 5451 INRIA
   Cottet GH, 1998, IEEE T IMAGE PROCESS, V7, P292, DOI 10.1109/83.661179
   Courant R., CALCULUS VARIATIONS
   DEGOND P, 1989, MATH COMPUT, V53, P485, DOI 10.2307/2008716
   DERICHE R, 1993, ARTIFICIAL BIOL VISI, P93
   DERICHE R, 1996, EDP TRAITEMENT IMAGE, V13
   Durbin R., 1989, COMPUTING NEURON
   Evans L., 1998, PARTIAL DIFFERENTIAL
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Gerstner W, 2002, BIOL CYBERN, V87, P404, DOI 10.1007/s00422-002-0353-y
   Hermosillo G, 2002, INT J COMPUT VISION, V50, P329, DOI 10.1023/A:1020830525823
   HERMOSILLO G, 2002, THESIS U NICE SOPHIA
   HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351
   HUBEL D, 1994, OEIL CERVEAU VISION
   KORNPROBST P, 2002, 4513 INRIA
   LEONARD A, 1980, J COMPUT PHYS, V37, P289, DOI 10.1016/0021-9991(80)90040-6
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833
   Otte M., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P51
   Rao RPN, 2001, NEURAL COMPUT, V13, P2221, DOI 10.1162/089976601750541787
   RAVIART PA, 1985, LECT NOTES MATH, V1127, P243
   SCHWARTZ L, 1957, THORIE DISTRIBUTIONS
   Tikhonov A.N., 1963, SOV MATH DOKL, V4, P1624
   TSCHUMPERL D, 2001, CONSTRAINED UNCONSTR, P153
   TSCHUMPERLE D, 1944, THESIS U NICE SOPHIA
   TSCHUMPERLE D, 2003, IEEE C COMP VIS PATT
   VIVILLE T, 2003, 4965 RR INRIA
   VIVILLE T, 2001, INT J COMPTUER VISIO, V44
   VIVILLE T, 1992, P 2 ECCV SANT MARGH, P203
   VIVILLE T, 2002, 4625 RR INRIA
   YU AJ, 2003, NEURAL COMPUTATION, V14
NR 33
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2005
VL 23
IS 11
BP 981
EP 998
DI 10.1016/j.imavis.2005.07.002
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 973KF
UT WOS:000232520600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Heidemann, G
AF Heidemann, G
TI Unsupervised image categorization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image categorization; image retrieval; image indexing; salient points;
   interest points; object recognition; unsupervised learning; vector
   quantization; color features
ID VECTOR QUANTIZATION; CORNER DETECTION; COLOR; RETRIEVAL; VISION; END
AB Large image collections require efficient organization and visualization. This paper describes an approach to establish image categories automatically by unsupervised learning. The method works free of context and previous knowledge: in a first stage, features are formed automatically, then images are clustered to form categories. The human database designer has to decide only whether a category is useful or too inhomogeneous from a high level point of view. To collect images that cannot be categorized automatically, an additional,miscellaneous' category exists. Categories are visualized by displaying the most typical image(s) of the categories as thumbnails. The main benefit of the approach is that it deals with color and shape in a unified way on a local scale, combined with the advantages of histogram techniques on the global scale. To judge results, an evaluation scheme which is adequate for the task of categorization is proposed. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Bielefeld, Neuroinformat Grp, D-33501 Bielefeld, Germany.
C3 University of Bielefeld
RP Univ Bielefeld, Neuroinformat Grp, POB 100131, D-33501 Bielefeld, Germany.
EM gheidema@techfak.uni-bielefeld.de
CR AHALT SC, 1990, NEURAL NETWORKS, V3, P277, DOI 10.1016/0893-6080(90)90071-R
   ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747
   Backer G, 2001, IEEE T PATTERN ANAL, V23, P1415, DOI 10.1109/34.977565
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   BEDERSON B, 2001, 14 ANN ACM S US INT, P71
   Brunnstrom K, 1996, INT J COMPUT VISION, V17, P137, DOI 10.1007/BF00058749
   BUHMANN J, 1993, IEEE T INFORM THEORY, V39, P1133, DOI 10.1109/18.243432
   COMBS TTA, 1999, P 4 ACM C DIG LIB, P130
   Cottier J.C., 1994, Extraction et appariements robustes des points d'interet de deux images non etalonnees
   CROWLEY JL, 1993, PATTERN RECOGNITION, V7
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Fairchild M.D., 1998, COLOR APPEARANCE MOD
   FORSTNER W, 1994, P EUR C COMP VIS, P383
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390
   Gevers T, 1999, IMAGE VISION COMPUT, V17, P475, DOI 10.1016/S0262-8856(98)00140-1
   GROSSBERG S, 1987, COGNITIVE SCI, V11, P23, DOI 10.1111/j.1551-6708.1987.tb00862.x
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Heidemann G, 2004, IEEE T PATTERN ANAL, V26, P817, DOI 10.1109/TPAMI.2004.29
   Heidemann G, 2004, COMPUT VIS IMAGE UND, V94, P234, DOI 10.1016/j.cviu.2003.10.009
   Heidemann G, 2001, NEURAL PROCESS LETT, V13, P17, DOI 10.1023/A:1009678928250
   HEIDEMANN G, 2005, IN PRESS IEEE T IMAG
   HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L
   Horaud R., 1990, P EUROPEAN C COMPUTE, P374
   Kohonen T, 1995, HDB BRAIN THEORY NEU, P175, DOI [DOI 10.1007/978-3-642-97610-0_6, 10.1007/978-3-642-97610-0]
   KOIKKALAINEN P, 1990, P 1990 INT JOINT C N, V2
   Laaksonen J, 2000, PATTERN RECOGN LETT, V21, P1199, DOI 10.1016/S0167-8655(00)00082-9
   Laganiere R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P280, DOI 10.1109/ICCV.1998.710731
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163
   LEE JS, 1995, IEEE T IMAGE PROCESS, V4, P100, DOI 10.1109/83.350810
   MacQueen J, 1965, P 5 BER S MATH STAT, P281
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311
   Medasani S, 2001, COMPUT VIS IMAGE UND, V83, P216, DOI 10.1006/cviu.2001.0926
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597
   Moravec Hans P., 1977, P INT JOINT C ART IN, P584
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Picard R., 1995, Vision texture database
   Qiu GP, 2004, PATTERN RECOGN, V37, P2177, DOI 10.1016/j.patcog.2004.03.006
   Qiu GP, 2002, LECT NOTES COMPUT SC, V2383, P100
   RAO RPN, 1995, ARTIF INTELL, V78, P461, DOI 10.1016/0004-3702(95)00026-7
   RODDEN K, 1999, IEEE S INF VIS 99
   RODDEN K, 2001, P SIGCHI C HUM FACT, P190, DOI DOI 10.1145/365024.365097
   RUBNER J, 1989, BIOL CYBERN, V61, P29, DOI 10.1007/BF00204757
   Salton G., 1989, Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Shilat E, 1997, PROC CVPR IEEE, P976, DOI 10.1109/CVPR.1997.609446
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   SIVIC J, 2004, P IEEE C COMP VIS PA
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith JR, 1996, P SOC PHOTO-OPT INS, V2670, P426, DOI 10.1117/12.234781
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tian Q, 2001, J ELECTRON IMAGING, V10, P835, DOI 10.1117/1.1406945
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Town C, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P75, DOI 10.1109/IVL.2001.990859
   TUYTELAARS T, 1999, 3 INT C VIS INF SYST, P493
   van de Weijer J, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P100
   VELTKAMP R, 2001, UUCS200034 DEP COMP
   VELTKAMP RC, 2001, STATE ART CONTENTBAS
   ZHOU SX, 1999, P IEEE INT C IM PROC
   Zitová B, 1999, PATTERN RECOGN LETT, V20, P199, DOI 10.1016/S0167-8655(98)00135-4
NR 70
TC 19
Z9 25
U1 2
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2005
VL 23
IS 10
BP 861
EP 876
DI 10.1016/j.imavis.2005.05.016
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 962PQ
UT WOS:000231745100002
DA 2024-07-18
ER

PT J
AU Smith, LN
   Smith, ML
AF Smith, LN
   Smith, ML
TI Automatic machine vision calibration using statistical and neural
   network methods
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE automatic calibration; radial lens distortion; linear regression;
   artificial neural network
ID COMPUTER VISION; CAMERA CALIBRATION; INSPECTION; RECOGNITION
AB A methodology is presented for camera calibration that is designed to improve the accuracy of machine vision based object measurement systems. The regression and artificial neural network techniques studied are considered to be complimentary rather than competitive. Neural networks have been identified as being particularly useful for the precise modelling of non-linear response, and offer the additional benefits of being non-prescriptive and generally applicable to factors such as radial lens distortion, manufacturing errors and minor camera misalignments. The combination of these modelling techniques within automated program control strategy is suggested as a new approach for straightforward and accessible machine vision calibration. The method has particularly good application to vision metrology and reverse engineering tasks. A demonstrator system has been constructed, employing a scanning laser line and vision system for object measurement in three-dimensions. Experimental results are presented along with a demonstration of the reduction in measurement error that can be attained through the application of regression analysis and artificial neural network modelling. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ W England, Fac Comp Engn & Math Sci, CEMS, Machine Vis Lab, Bristol BS16 1QY, Avon, England.
C3 University of West England
RP Univ W England, Fac Comp Engn & Math Sci, CEMS, Machine Vis Lab, Frenchay Campus,Coldharbour Lane, Bristol BS16 1QY, Avon, England.
EM lyndon.smith@uwe.ac.uk
OI Smith, Melvyn/0000-0002-5307-8288; Smith, Lyndon/0000-0001-5821-0586
CR Bishop C. M., 1995, NEURAL NETWORKS PATT
   Braines SA, 2001, COMPUT GRAPH-UK, V25, P643, DOI 10.1016/S0097-8493(01)00093-0
   Chan VH, 2001, COMPUT IND, V44, P105, DOI 10.1016/S0166-3615(00)00087-7
   CHANG CA, 1995, COMPUT IND ENG, V28, P593, DOI 10.1016/0360-8352(94)00211-5
   Cohen G, 1998, COMPUT INTEGR MANUF, V11, P243, DOI 10.1016/S0951-5240(98)00013-5
   Coit DW, 1998, INT J PROD RES, V36, P2953, DOI 10.1080/002075498192229
   Demuth H., 2003, NEURAL NETWORK TOOLB
   Dihoru LV, 2000, MATER MANUF PROCESS, V15, P419, DOI 10.1080/10426910008912997
   DIHORU LV, 2000, POWDER METALLURGY, V43
   Dowey SJ, 1998, SURF COAT TECH, V110, P86, DOI 10.1016/S0257-8972(98)00677-X
   Gallwey TJ, 1998, INT J IND ERGONOM, V22, P37, DOI 10.1016/S0169-8141(97)00066-8
   GUPTA MM, 1994, NEUROVISION SYSTEMS
   Hagan MT, 1997, NEURAL NETWORK DESIG
   HAMDI DH, 1994, J MATER PROCESS MANU, V2, P335
   JAIN C, 1999, IND APPL NEURAL NETW
   Ji Z., 1989, Optics and Laser Technology, V21, P335, DOI 10.1016/0030-3992(89)90068-6
   Keferstein C. P., 1998, Sensor Review, V18, P183, DOI 10.1108/02602289810226408
   KLETTE R, 1998, COMPUTER VISION 3D D
   Kulkarni ArunD., 2001, COMPUTER VISION FUZZ
   LEE S, 2000, BIOL MOTIVATED COMPU
   Lennox B, 2001, J PROCESS CONTR, V11, P497, DOI 10.1016/S0959-1524(00)00027-5
   Lynch MB, 1999, INT J PROD ECON, V60-1, P479, DOI 10.1016/S0925-5273(98)00199-6
   MARKOS S, 1993, IFIP TRANS B, V11, P239
   MUNDHENK TN, 2000, P SPIE C INT ROB COM, V19, P181
   Murino V, 2001, IMAGE VISION COMPUT, V19, P583, DOI 10.1016/S0262-8856(00)00112-8
   NOBLE JA, 1995, IMAGE VISION COMPUT, V13, P197, DOI 10.1016/0262-8856(95)90840-5
   Principe J. C., 1999, Neural and adaptive systems
   Rosandich R.G., 1996, Intelligent Visual Inspection: Using artificial neural networks
   SHIH SW, 1993, OPT ENG, V32, P138, DOI 10.1117/12.60087
   SHIH SW, 1995, PATTERN RECOGN, V28, P447, DOI 10.1016/0031-3203(94)00107-W
   Smith L.N., 2000, Metal Powder Report, V55, P30
   SMITH LN, 2000, METAL POWDER REPORT, V55
   Smith ML, 1999, IMAGE VISION COMPUT, V17, P321, DOI 10.1016/S0262-8856(98)00136-X
   Smith ML, 2000, COMPUT IND, V43, P73, DOI 10.1016/S0166-3615(00)00052-X
   Smith ML, 1997, IMAGE VISION COMPUT, V15, P949, DOI 10.1016/S0262-8856(97)00050-4
   Smith ML, 1999, IMAGE VISION COMPUT, V17, P1009, DOI 10.1016/S0262-8856(99)00003-7
   SMITH ML, 2000, SURFACE INSPECTION T
   SMITH ML, 1999, VISION SYSTEMS DESIG, V4, P16
   SU CT, 1995, COMPUT IND, V27, P225, DOI 10.1016/0166-3615(95)00024-8
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   UDO GJ, 1992, COMPUT IND ENG, V23, P97, DOI 10.1016/0360-8352(92)90072-R
   VANHEMMEN L, 2001, MODELS NEURAL NETWOR, V6
   Westkamper E, 1998, J INTELL MANUF, V9, P289, DOI 10.1023/A:1008966407212
   Wöhler C, 2001, IMAGE VISION COMPUT, V19, P593, DOI 10.1016/S0262-8856(01)00040-3
   Younis MA, 1998, COMPUT IND ENG, V35, P49, DOI 10.1016/S0360-8352(98)00017-5
   Yuan C, 2001, IMAGE VISION COMPUT, V19, P585, DOI 10.1016/S0262-8856(01)00037-3
   ZHANG HC, 1995, INT J PROD RES, V33, P705, DOI 10.1080/00207549508930175
   Zhang YF, 1998, COMPUT IND ENG, V34, P433, DOI 10.1016/S0360-8352(97)00141-1
   Zorriassatine F, 1998, J INTELL MANUF, V9, P209, DOI 10.1023/A:1008818817588
NR 49
TC 27
Z9 36
U1 0
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2005
VL 23
IS 10
BP 887
EP 899
DI 10.1016/j.imavis.2005.03.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 962PQ
UT WOS:000231745100004
DA 2024-07-18
ER

PT J
AU Kim, TK
   Kim, H
   Hwang, W
   Kittler, J
AF Kim, TK
   Kim, H
   Hwang, W
   Kittler, J
TI Component-based LDA face description for image retrieval and MPEG-7
   standardisation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE linear discriminant analysis (LDA); face recognition image retrieval;
   face descriptors; facial components; combining classifiers; MPEG-7
ID RECOGNITION
AB We propose a method of face description for facial image retrieval from a large data base and for MPEG-7 (Moving Picture Experts Group) standardisation. The novel descriptor is obtained by decomposing a face image into several components and then combining the component features. The decomposition combined with LDA (Linear Discriminant Analysis) provides discriminative facial descriptions that are less sensitive to light and pose changes. Each facial component is represented in its Fisher space and another LDA is then applied to compactly combine the features of the components. To enhance retrieval accuracy further, a simple pose classification and transformation technique is performed, followed by recursive matching. Our algorithm has been developed to deal with the problem of face image retrieval from huge databases such as those found in Internet environments. Such retrieval requires a compact face representation which has robust recognition performance under lighting and pose variations. The partitioning of a face image into components offers a number of benefits that facilitate the development of an efficient and robust face retrieval algorithm. Variation in image statistics due to pose and/or illumination changes within each component region can be simplified and more easily captured by a linear encoding than that of the whole image. So an LDA encoding at the component level facilitates better classification. Furthermore, a facial component can be weighted according to its importance. The component with a large variation is weighted less in the matching stage to yield a more reliable decision. The experimental results obtained on the MPEG-7 data set show an impressive accuracy of our algorithm as compared with other methods including conventional PCA (Principal Component Analysis)/ICA (Independent Component Analysis)/LDA methods and the previous MPEG-7 proposals. (c) 2005 Elsevier B.V. All rights reserved.
C1 Samsung Adv Inst Technol, Comp Lab, Yongin 449712, Kyungki, South Korea.
   Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 5XH, Surrey, England.
C3 Samsung; University of Surrey
RP Samsung Adv Inst Technol, Comp Lab, San 14-1,Nongseori, Yongin 449712, Kyungki, South Korea.
EM ktk22@hanmail.net
RI Kim, Tae-Kyun/HTL-2208-2023
OI Kim, Tae-Kyun/0000-0002-7587-6053
CR ABDELMOTTALEB M, 1999, M5207 ISO MPEG
   Bartlett M.S., 2001, FACE IMAGE ANAL UNSU
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   CIEPLINSKI L, 2003, 159383FPDAMI ISO IEC
   ECKES C, 2002, M8394 ISOIEC
   FRANC V, 2002, M8727 ISOIEC
   Heisele B., 2001, P IEEE INT C COMP VI
   KAMEI T, 2002, P IEEE INT C IM PROC
   KAMEI T, 2002, M8998 ISOIEC
   KIM HC, 2002, INT C IM PROC ROCH
   KIM MS, 2002, M8328 ISOIEC
   KIM TK, 2003, IEEE INT C IM PROC S
   KIM TK, 2002, M8243 ISO IEC
   KIM TK, 2002, BRIT MACH VIS C BMVC
   KIM TK, 2003, IEEE INT C COMP VIS
   MANJUNATH BS, 2002, INTRO MPEG7 MULTIMED
   MARTINEZ AM, 1997, IEEE T PATTERN RECOG, V23, P228
   MOGHADDAM B, 1994, SPIE AUTOMATIC SYSTE, P2277
   Nefian AV, 1999, INT CONF ACOUST SPEE, P3553, DOI 10.1109/ICASSP.1999.757610
   Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230
   WANG L, 2000, JTCISC21WG11M6001 IS
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
NR 22
TC 42
Z9 48
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2005
VL 23
IS 7
BP 631
EP 642
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 940LX
UT WOS:000230147100002
DA 2024-07-18
ER

PT J
AU Gorodnichy, DO
   Roth, G
AF Gorodnichy, DO
   Roth, G
TI Nouse 'use your nose as a mouse' perceptual vision technology for
   hands-free games and interfaces
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE computer-human; stereo-tracking; face-tracking
ID FACE DETECTION; IMAGES
AB Due to recent increase of computer power and decrease of camera cost, it became very common to see a camera on top of a computer monitor. This paper presents the vision-based technology which allows one in such a setup to significantly enhance the perceptual power of the computer. The described techniques for tracking a face using a convex-shape nose feature as well as for face-tracking with two off-the-shelf cameras allow one to track faces robustly and precisely in both 2D and 3D with low resolution cameras. Supplemented by the mechanism for detecting multiple eye blinks, this technology provides a complete solution for building intelligent hands-free input devices. The theory behind the technology is presented. The results from running several perceptual user interfaces built with this technology are shown. (C) 2004 Elsevier B.V. All rights reserved.
C1 Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada.
C3 National Research Council Canada
RP Gorodnichy, DO (corresponding author), Natl Res Council Canada, Inst Informat Technol, M-50 Montreal Rd, Ottawa, ON K1A 0R6, Canada.
EM dmitry.gorodnichy@nrc-cnrc.gc.ca; gerhard.roth@nrc-cnrc.gc.ca
CR [Anonymous], HDB NEURAL COMPUTATI
   [Anonymous], 1998, 4 IEEE WORKSH APPL C
   [Anonymous], P C VIS INT VI 2002
   COLMENAREZ A, 1999, ICIP P
   Darrell T, 1996, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.1996.517055
   DESLIVA LC, SPIE VISUAL COMMUNIC, V2501
   Durucan E, 2001, P IEEE, V89, P1368, DOI 10.1109/5.959336
   Féraud R, 2001, IEEE T PATTERN ANAL, V23, P42, DOI 10.1109/34.899945
   Gee A, 1996, IMAGE VISION COMPUT, V14, P105, DOI 10.1016/0262-8856(95)01044-0
   Gorodnichy D., 2003, P C VIS IM IM PROC V, P140
   Gorodnichy DO, 2003, LECT NOTES COMPUT SC, V2688, P505
   Gorodnichy DO, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P188, DOI 10.1109/AFGR.2002.1004153
   GORODNICHY DO, 1997, P INT C IM AN PROC I, V2, P332
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Heisele B., 2000, Face Detection in Still Gray Images
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   KLETTE R, 1996, COMPUTER VISION 3 DI
   LOY G, 2000, P AUSTR C ROB AUT AC
   Matsumoto Y., 2000, P IEEE INT C AUT FAC
   Newman R., 2000, P IEEE INT C AUT FAC
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   PICARDI M, 2003, IND PHYS, V9
   Press H., 1988, Numerical Recipes in C++. The Art of Computer Programming
   RODRIGUEZ JJ, 1990, IEEE T PATTERN ANAL, V12, P467, DOI 10.1109/34.55106
   ROTH G, 1993, CVGIP-IMAG UNDERSTAN, V58, P1, DOI 10.1006/ciun.1993.1028
   ROTH G, 2000, P 13 INT C VIS INT, P87
   ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   SHAKHNAROVICH G, 2002, INT C AUT FAC GEST R, P10
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   TERRILLON JC, 2000, P 4 INT C AUT FAC GE
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   TURK M, 2002, P INT C VIS INT VI 2
   XU M, 1998, P IEEE INT C AUT FAC
   Yang J., 1998, P AUDITORY VISUAL SP, P79
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
   2003, PLANETA DIGITAL 0806, P4
   2003, NACION LINE     0603
NR 43
TC 55
Z9 59
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 931
EP 942
DI 10.1016/j.imavis.2004.03.021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800002
DA 2024-07-18
ER

PT J
AU Horovitz, I
   Kiryati, N
AF Horovitz, I
   Kiryati, N
TI Depth from gradient fields and control points: bias correction in
   photometric stereo
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE photometric stereo; control points; depth from gradient field; weighted
   least squares; thin plate spline interpolation; full multigrid
ID SHAPE RECONSTRUCTION; VARIATIONAL APPROACH; SURFACE; RECOVERY;
   INTEGRABILITY; INTERPOLATION; INTEGRATION; COLOR
AB Photometric stereo is capable of high quality reconstruction of fine shape details, but is prone to systematic errors due to nonideal illumination or imperfect calibration. We present methods for correcting the bias, using sparse control points of known 3D location. An easy way to obtain control points is via the projection of a dot-matrix pattern using a laser pointer with a suitable adapter, and triangulation. Straight forward incorporation of control points as constraints in the computation of depth from the gradient field leads to singularities. We propose two well-behaved methods for bias correction using control points. One is based on constrained weighted least squares extension of depth from gradient-field computation. The other adds an interpolation surface to the reconstructed shape. Practical computation of depth from a gradient field requires an efficient numerical scheme. We employ full-multigrid computation with successive over-relaxation and show how to propagate the gradient field and the control points through the pyramid. Experimental results demonstrate significant bias reduction in photometric stereo, allowing high reconstruction quality even in the presence of severe setup errors. (C) 2004 Elsevier B.V. All rights reserved.
C1 Tel Aviv Univ, Fac Engn, Dept Elect Engn Syst, IL-69978 Tel Aviv, Israel.
C3 Tel Aviv University
RP Tel Aviv Univ, Fac Engn, Dept Elect Engn Syst, IL-69978 Tel Aviv, Israel.
EM nk@eng.tau.ac.il
OI Kiryati, Nahum/0000-0003-1436-2275
CR BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   CHEN Y, 2000, CITRTR68 U AUCKL COM
   CRYER JE, 1995, PATTERN RECOGN, V28, P1033, DOI 10.1016/0031-3203(94)00183-M
   Drbohlav O, 2002, LECT NOTES COMPUT SC, V2351, P46
   Drbohlav O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P581, DOI 10.1109/ICCV.2001.937570
   Drew MS, 1997, P SOC PHOTO-OPT INS, V3016, P369, DOI 10.1117/12.274534
   Drew MS, 2000, J OPT SOC AM A, V17, P1371, DOI 10.1364/JOSAA.17.001371
   DREW MS, 1992, J OPT SOC AM A, V9, P1255, DOI 10.1364/JOSAA.9.001255
   Fan J, 1997, COMPUT VIS IMAGE UND, V65, P347, DOI 10.1006/cviu.1996.0581
   FRANKE R, 1982, MATH COMPUT, V38, P181, DOI 10.2307/2007474
   FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909
   FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192
   Horn B.K.P, 1986, Robot Vision
   HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3
   HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771
   IKEUCHI K, 1986, INT J ROBOT RES, V5, P46, DOI 10.1177/027836498600500103
   IKEUCHI K, 1984, P INT C PATT REC, P736
   Klette R., 1998, COMPUTER VISION 3 DI, V1st
   Leclerc Y. G., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P552, DOI 10.1109/CVPR.1991.139752
   Lee KM, 1996, J VIS COMMUN IMAGE R, V7, P155, DOI 10.1006/jvci.1996.0015
   ONN R, 1990, INT J COMPUT VISION, V5, P105, DOI 10.1007/BF00056773
   OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684
   Press W. H, 1992, NUMERICAL RECIPES C
   Shah J, 1996, IEEE T IMAGE PROCESS, V5, P1243, DOI 10.1109/83.506759
   SHAO M, 1991, CVGIP-IMAG UNDERSTAN, V53, P219, DOI 10.1016/1049-9660(91)90029-O
   Shimshoni I, 2000, INT J COMPUT VISION, V39, P97, DOI 10.1023/A:1008118909580
   SPIEGELMAN M, MYTHS METHODS MODELI
   SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188
   TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8
   TERZOPOULOS D, 1984, THESIS MIT
   TERZOPOULOS D, 1983, P INT JOINT C ART IN, P1019
   VERWER BJH, 1991, PATTERN RECOGN LETT, V12, P671, DOI 10.1016/0167-8655(91)90004-6
   Wei GQ, 1997, IEEE T PATTERN ANAL, V19, P353, DOI 10.1109/34.588016
   WOLFF LB, 1994, J OPT SOC AM A, V11, P3069, DOI 10.1364/JOSAA.11.003069
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   WU ZQ, 1988, COMPUT VISION GRAPH, V43, P53, DOI 10.1016/0734-189X(88)90042-4
NR 36
TC 42
Z9 50
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 20
PY 2004
VL 22
IS 9
BP 681
EP 694
DI 10.1016/j.imavis.2004.01.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 834WE
UT WOS:000222440800001
DA 2024-07-18
ER

PT J
AU Yang, XY
   Krishnan, SM
AF Yang, XY
   Krishnan, SM
TI Image segmentation using finite mixtures and spatial information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE finite mixtures; image segmentation; Gaussian mixture; density
   estimation; EM algorithm
ID PARAMETER-ESTIMATION; MODEL-SELECTION; LIKELIHOOD; CRITERIA
AB The finite mixture is a flexible and powerful probabilistic modelling tool. It can be used to provide a model-based clustering in the field of pattern recognition. However, the application of finite mixtures to image segmentation faces some difficulties. First, the estimation of the number of components is still an open question. Second, mixture-based data clustering does not consider spatial information, which is important for smooth regions to be obtained in the segmentation results. In this paper, the spatial information is used as a prior knowledge of the number of components. The spatial information does not tell the value of the number of components; instead, it provides some indirect information about this value. An Expectation Maximization based algorithm is developed to estimate mixture density using the indirect information. The experimental results with simulated data of 2D Gaussian mixture show that the proposed algorithm is capable of estimating the number of components accurately without using any model selection criteria. The experimental results of image segmentation show that the proposed algorithm has better performance in generating smooth regions in the segmentation results compared to the common algorithms that use model selection criteria to estimate the number of components. (C) 2004 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 2263, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 2263, Singapore.
EM exyyang@ntu.edu.sg
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554
   Biernacki C., 1997, COMPUTING SCI STAT, V29, P451
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan KL, 2002, IEEE T BIO-MED ENG, V49, P963, DOI 10.1109/TBME.2002.802012
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Feng ZD, 1996, J ROY STAT SOC B MET, V58, P609
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   LIANG Z, 1992, IEEE T NUCL SCI, V39, P1126, DOI 10.1109/23.159772
   LIANG ZR, 1994, IEEE T MED IMAGING, V13, P441, DOI 10.1109/42.310875
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   SCLOVE SL, 1987, PSYCHOMETRIKA, V52, P333, DOI 10.1007/BF02294360
   Smyth P, 2000, STAT COMPUT, V10, P63, DOI 10.1023/A:1008940618127
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   Xiao GF, 2002, IEEE T MED IMAGING, V21, P48, DOI 10.1109/42.981233
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 17
TC 23
Z9 28
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 20
PY 2004
VL 22
IS 9
BP 735
EP 745
DI 10.1016/j.imavis.2004.04.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 834WE
UT WOS:000222440800005
DA 2024-07-18
ER

PT J
AU Pan, XB
   Brady, M
   Bowman, AK
   Crowther, B
   Tomlin, RSO
AF Pan, XB
   Brady, M
   Bowman, AK
   Crowther, B
   Tomlin, RSO
TI Enhancement and feature extraction for images of incised and ink texts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE document processing; incised and ink text; phase congruency
AB This paper describes the image enhancement techniques that we have used to help historians read three kinds of writing tablets: ink, wooden stilus and lead curse tablet. The techniques include: homomorphic filtering to correct uneven illumination, high-pass filtering to remove shading caused by surface undulations, and a newer technique to remove the often substantial complicating factor of wood grain. A phase-based feature detector has been developed to detect text stroke. A description of the detected strokes is generated for a text recognition system. (C) 2004 Elsevier B.V. All rights reserved.
C1 Mirada Solut Ltd, Oxford OX1 2ET, England.
   Univ Oxford, Dept Engn Sci, Oxford OX2 7BZ, England.
   Univ Oxford, Ctr Study Ancient Documents, Oxford OX1 3LU, England.
C3 University of Oxford; University of Oxford
RP Mirada Solut Ltd, Level 1,23-28 Hythe Bridge St, Oxford OX1 2ET, England.
EM bo.pan@mirada-solutions.com
OI Crowther, Charles/0000-0002-7813-7897
CR [Anonymous], 2008, A wavelet tour of signal processing: The sparse way
   BOUKKERAI D, UNPUB
   Bowman A.K., 1994, The Vindolanda Writing-Tablets (Tabulae Vindolandenses II)
   BOWMAN AK, 2003, IMAGES ARTEFACT ANCI
   BRADY M, 2003, IMAGES ARTEFACTS ANC
   FREEMAN WT, 1991, IEEE T PAMI, V15, P1253
   GONZALEZ N, 1992, DIGITAL IMAGE PROCES
   GRANLUND GH, 1994, IMAGE VISION COMPUT, V12, P131, DOI 10.1016/0262-8856(94)90065-5
   Molton N, 2003, PATTERN RECOGN, V36, P1031, DOI 10.1016/S0031-3203(02)00112-7
   MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4
   Tomlin R., 1988, FINDS SACRED SPRING, V2, P4
   WALLACE AM, 2003, IMAGES ARTEFACTS ANC
NR 12
TC 12
Z9 15
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2004
VL 22
IS 6
BP 443
EP 451
DI 10.1016/j.imavis.2003.11.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 817HB
UT WOS:000221167500001
DA 2024-07-18
ER

PT J
AU Fitzgibbon, AW
AF Fitzgibbon, AW
TI Robust registration of 2D and 3D point sets
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE iterated closest point; range image registration; Levenberg-Marquardt
AB This paper introduces a new method of registering point sets. The registration error is directly minimized using general-purpose non-linear optimization (the Levenberg-Marquardt algorithm). The surprising conclusion of the paper is that this technique is comparable in speed to the special-purpose Iterated Closest Point algorithm, which is most commonly used for this task. Because the routine directly minimizes an energy function, it is easy to extend it to incorporate robust estimation via a Huber kernel, yielding a basin of convergence that is many times wider than existing techniques. Finally, we introduce a data structure for the minimization based on the chamfer distance transform, which yields an algorithm that is both faster and more robust than previously described methods. (C) 2003 Published by Elsevier B.V.
C1 Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England.
C3 University of Oxford
RP Univ Oxford, Dept Engn Sci, 19 Parks Rd, Oxford OX1 3PJ, England.
EM awf@robots.ox.ac.uk
RI Fitzgibbon, Andrew/JFL-0330-2023
CR [Anonymous], 2002, ALGORITHMS MINIMIZAT
   [Anonymous], [No title captured]
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   CAHMPLEBOUX G, 1992, P IEEE C COMP VIS PA, P83
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733
   CUNNINGTON SJ, 1999, P 10 BRIT MACH VIS C, P234
   DENNIS JE, 1981, ACM T MATH SOFTWARE, V7, P369, DOI 10.1145/355958.355966
   Eggert DW, 1998, COMPUT VIS IMAGE UND, V69, P253, DOI 10.1006/cviu.1998.0667
   FELDMAR J, 1994, P EUR C COMP VIS, P397
   GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268
   GRIMSON WEL, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P430, DOI 10.1109/CVPR.1994.323862
   HARTLEY RI, 1994, LNCS SERIES, V825, P237
   Hilton A, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P381, DOI 10.1109/ICIP.1996.560840
   Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P234, DOI 10.1109/IM.1997.603871
   LUO B, 1999, P 10 BRIT MACH VIS C, P43
   Masters T., 1995, Advanced Algorithms for Neural Networks: a C++ Sourcebook
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Simon D A, 1995, J Image Guid Surg, V1, P17, DOI 10.3109/10929089509106822
   Stoddart A. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P40, DOI 10.1109/ICPR.1996.546720
   Studholme C, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P27
   TRIGGS W, 2000, LNCS
   Trucco E, 1999, PATTERN RECOGN LETT, V20, P889, DOI 10.1016/S0167-8655(99)00055-0
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   VIOLA P, 1995, 1548 MIT AITR AI LAB
   Wells WM, 1997, INT J COMPUT VISION, V21, P63, DOI 10.1023/A:1007923522710
   ZHANG Z, 1992, P BMVC, P347
NR 28
TC 517
Z9 606
U1 0
U2 63
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1145
EP 1153
DI 10.1016/j.imavis.2003.09.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100009
DA 2024-07-18
ER

PT J
AU Maskell, S
   Rollason, M
   Gordon, N
   Salmond, D
AF Maskell, S
   Rollason, M
   Gordon, N
   Salmond, D
TI Efficient particle filtering for multiple target tracking with
   application to tracking in structured images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Symposium on Probabilistic Models in Computer Vision
CY MAY, 2001
CL ENGLAND
SP British Mach Vis, Royal Stat Soc
DE tracking; particle filtering; Rao Blackwellisation; Monte Carlo
   integration; structured images
AB For many dynamic estimation problems involving nonlinear and/or non-Gaussian models, particle filtering offers improved performance at the expense of computational effort. This paper describes a scheme for efficiently tracking multiple targets using particle filters. The tracking of the individual targets is made efficient through the use of Rao-Blackwellisation. The tracking of multiple targets is made practicable using Quasi-Monte Carlo integration. The efficiency of the approach is illustrated on synthetic data. (C) 2003 Elsevier B.V. All rights reserved.
C1 QinetiQ Ltd, Malvern Technol Ctr, Malvern, Worcs, England.
   Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
   QinetiQ Ltd, Farnborough, Hants, England.
C3 Qinetiq Group Plc; University of Cambridge; Qinetiq Group Plc
RP Maskell, S (corresponding author), QinetiQ Ltd, Malvern Technol Ctr, St Andrews Rd, Malvern, Worcs, England.
EM srmaskell@qinetiq.com; mprollason@qinetiq.com; njgordon@qinetiq.com;
   djsalmond@qinetiq.com
OI Gordon, Neil/0000-0002-5927-2591
CR [Anonymous], LOCKHEED MARTIN TECH
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], 1982, Matrix algebra useful for statistics
   ARULAMPALAM, 2003, IEEE T SIGNAL PROCES
   Arulampalam S, 2000, P SOC PHOTO-OPT INS, V4048, P288, DOI 10.1117/12.391985
   BALLANTYNE DJ, 2001, P 4 INT C INF FUS
   BARSHALOM Y, 1989, IEEE T AEROSPACE ELE, V25
   BARSHALOM Y, 1989, OPTICAL ENG, V29
   Blackman S., 1999, Design and analysis of modern tracking systems
   DEHAAN DB, 1939, NOUVELLES TABLES INT
   FUDERER M, 1989, P SOC PHOTO-OPT INS, V1137, P84, DOI 10.1117/12.961720
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Harvey AC., 1989, FORECASTING STRUCTUR
   Kitagawa G., 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750
   Li X.R., 2000, SPIE SIGNAL DATA PRO, P4048
   MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275
   Maskell S, 2002, PROC SPIE, V4728, P251, DOI 10.1117/12.478509
   MASKELL S, 2001, MULTISENSOR MANAGEME
   Orton M, 2002, IEEE T SIGNAL PROCES, V50, P216, DOI 10.1109/78.978377
   ROLLASON M, 2001, P IEE SEM TARG TRACK
   SHERTUKDE H, 1991, IEEE T AEROSPACE ELE, V27
NR 21
TC 16
Z9 17
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2003
VL 21
IS 10
BP 931
EP 939
DI 10.1016/S0262-8856(03)00087-8
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 723KU
UT WOS:000185432200008
DA 2024-07-18
ER

PT J
AU Strens, MJA
   Gregory, IN
AF Strens, MJA
   Gregory, IN
TI Tracking in cluttered images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Symposium on Probabilistic Models in Computer Vision
CY MAY, 2001
CL ENGLAND
SP British Mach Vis, Royal Stat Soc
DE competitive attentional tracker; velocity estimating filter; image
   target tracking
AB A new algorithm, the competitive attentional tracker is proposed, which combines multiple velocity estimating filters to detect and track targets in cluttered images. Each filter tracks the motion of some scene content using a discrete grid representation for position and velocity beliefs. During operation, the filters can move between high confidence states (accurate tracking) and low confidence states (maximum detection sensitivity). Optimal detection performance is related to a hidden Markov model for target presence/absence, which can exploit statistical models of target and background appearance to detect targets in highly cluttered scenes. Experiments with synthetic data are used to characterise detection and tracking performance, and implementation in target tracking systems is described. (C) 2003 Elsevier B.V. All rights reserved.
C1 QinetiQ, Future Syst Technol Div, Guidance & Imaging Solut Business Grp, Farnborough GU14 0LX, Hants, England.
C3 Qinetiq Group Plc
RP QinetiQ, Future Syst Technol Div, Guidance & Imaging Solut Business Grp, Room 1032,X107 Bldg,Cody Technol Pk,Ively Rd, Farnborough GU14 0LX, Hants, England.
EM mjstrens@qinetiq.com
OI Strens, Malcolm John Alexander/0009-0005-8122-1976
CR [Anonymous], 2001, Sequential Monte Carlo methods in practice
   BAKER TW, 1998, P INT C PATT REC BRI
   Bar-Shalom Y., 1995, MULTITARGET MULTISEN
   BARNIV Y, 1995, IEEE T AERO ELEC SYS, V21, P144
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Fortmann T. E., 1980, Proceedings of the 19th IEEE Conference on Decision & Control Including the Symposium on Adaptive Processes, P807
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Isard M., 1996, Proceedings of the European Conference on Computer Vision (ECCV), P343
   Jazwinski A., 1970, STOCHASTIC PROCESSES
   MACCORMICK J, 1999, P 7 INT C COMP VIS I
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   ROZOVSKII BL, 2000, SPIE P SIGNAL DATA P, V4048
   Salmond D. J., 1990, Proceedings of the SPIE, V1305, P434, DOI 10.1117/12.2321784
   Stone L.D., 1999, ARTECH HOUSE RADAR
   STREIT RL, 1994, P SOC PHOTO-OPT INS, V2235, P394, DOI 10.1117/12.179066
   TARTAKOVSKY A, 1999, P SPIE SIGNAL DATA P, V3809
   WATSON GH, 1999, SPIE P SIGNAL DATA P, V3809, P11
   WOLF JK, 1989, IEEE T AERO ELEC SYS, V25, P287, DOI 10.1109/7.18692
NR 19
TC 6
Z9 7
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2003
VL 21
IS 10
BP 891
EP 911
DI 10.1016/S0262-8856(03)00075-1
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 723KU
UT WOS:000185432200006
DA 2024-07-18
ER

PT J
AU Golightly, I
   Jones, D
AF Golightly, I
   Jones, D
TI Corner detection and matching for visual tracking during power line
   inspection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE corner detection; corner matching; visual tracking
ID AERIAL INSPECTION; VIDEO
AB Power line inspection from a helicopter using video surveillance techniques demands that the camera be automatically pointed at the object of interest, in order to compensate for the helicopter's movement. The possibility of using corner detection and matching to maintain the fixation point in the image is investigated here. An attractive feature of corner-based methods is that they are invariant to camera focal length, which can vary widely during inspection. The paper considers the selection, parameter determination and testing of a customised method for detecting corners present in images of pole-tops. The method selected uses gradient computation and dissimilarity measures evaluated along the gradient to find clusters of corners, which are then aggregated to individual representative points. Results are presented for its detection and error rates. The stability of the corner detector in conjunction with a basic corner matcher is evaluated on image sequences produced on a laboratory test rig. Examples of its response to background clutter and change of illumination are given. Overall the results support the use of corners as robust, stable beacons suitable for use in this application. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales.
C3 Bangor University
RP Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales.
EM iang@informatics.bangor.ac.uk; dewi@informatics.bangor.ac.uk
CR Bae SC, 2002, PATTERN RECOGN LETT, V23, P1349, DOI 10.1016/S0167-8655(02)00083-1
   BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923
   Chien SI, 2000, PATTERN RECOGN, V33, P237, DOI 10.1016/S0031-3203(99)00056-4
   COOPER J, 1993, IEEE T PATTERN ANAL, V15, P823, DOI 10.1109/34.236246
   Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539
   Drummond T, 2002, IMAGE VISION COMPUT, V20, P427, DOI 10.1016/S0262-8856(02)00013-6
   Harris C., 1988, ALVEY VISION C, P147151
   HAYMAN E, 1996, P 7 BRIT MACH VIS C, P395
   HAYMAN E, 1999, P INT C COMP VISION
   Jones DI, 2000, IEE P-VIS IMAGE SIGN, V147, P157, DOI 10.1049/ip-vis:20000226
   Jones DI, 2001, ELECTR POW SYST RES, V57, P73, DOI 10.1016/S0378-7796(01)00100-6
   Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4
   Nickels K, 2002, IMAGE VISION COMPUT, V20, P47, DOI 10.1016/S0262-8856(01)00076-2
   Quddus A, 2002, PATTERN RECOGN LETT, V23, P215, DOI 10.1016/S0167-8655(01)00090-3
   Shapiro LS., 1995, AFFINE ANAL IMAGE SE
   Shen F, 2002, PATTERN RECOGN LETT, V23, P1039, DOI 10.1016/S0167-8655(02)00035-1
   Smith P., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P545
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Tissainayagam P, 2001, COMPUT VIS IMAGE UND, V84, P104, DOI 10.1006/cviu.2001.0939
   Tissainayagam P, 2001, PATTERN RECOGN, V34, P641, DOI 10.1016/S0031-3203(00)00019-4
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   Tzionas P, 2000, REAL-TIME IMAGING, V6, P461, DOI 10.1006/rtim.1999.0195
   WANG H, 1992, IMAGE VISION COMPUT, V16, P75
   Whitworth CC, 2001, POWER ENG J, V15, P25, DOI 10.1049/pe:20010103
   YAO YS, 1995, IEEE T IMAGE PROCESS, V4, P1382, DOI 10.1109/83.465103
NR 25
TC 62
Z9 75
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2003
VL 21
IS 9
BP 827
EP 840
DI 10.1016/S0262-8856(03)00097-0
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 711QX
UT WOS:000184753500006
DA 2024-07-18
ER

PT J
AU Rivera, M
   Marroquin, JL
AF Rivera, M
   Marroquin, JL
TI Efficient half-quadratic regularization with granularity control
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE half-quadratic regularization; edge-preserving regularization; image
   restoration; non-linear filtering; conjugate gradient algorithms
ID EDGE-PRESERVING REGULARIZATION; PARAMETER-ESTIMATION; RESTORATION;
   RECOVERY
AB In the last decade, several authors have proposed edge preserving regularization methods for solving ill posed problems in early vision. These techniques are based on potentials derived from robust M-Estimators. They are capable of detecting outliers in the data. finding the significant borders in noisy images and performing edge-preserving restorations. These methods, however. have some problems: they are computationally expensive. and often produce solutions which are either too smooth or too granular (with borders around small regions), In this paper, we present a new class of potentials that permits to separate robustness and granularity control, producing better results than the classical ones in both scalar- and vector-valued images. We also present a new fast, memory-limited minimization algorithm. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Ctr Invest & Math AC, Guanajuato 36020, Mexico.
RP Ctr Invest & Math AC, Apdo Postal 402, Guanajuato 36020, Mexico.
EM mrivera@cimat.mx
OI Rivera, Mariano/0000-0002-3211-2467
CR [Anonymous], 1981, Practical Optimization
   [Anonymous], 1985, Exploring Data Tables, Trends, and Shapes
   [Anonymous], 1987, Visual Reconstruction
   [Anonymous], 2001, COMP SCI W
   Ben-Ezra M, 2000, COMPUT VIS IMAGE UND, V78, P32, DOI 10.1006/cviu.1999.0826
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Black MJ, 2000, COMPUT VIS IMAGE UND, V78, P8, DOI 10.1006/cviu.1999.0825
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Dennis J.E., 1976, Proceedings of the American Statistical Association Statistical Computing Section, P83
   Ganan Stuart, 1985, P STAT COMP SECT AM, P12
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gilbert JC, 1992, SIAM J OPTIMIZ, V2, P21, DOI 10.1137/0802003
   Hampel FR, 1986, Robust statistics. The approach based on influence functions
   Hellier P, 2000, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.2000.854805
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huber P., 1981, Robust Statistics
   Kelley C.T., 1995, ITERATIVE METHODS LI
   Kubota T, 1997, LECT NOTES COMPUT SC, V1223, P179
   LAI SH, 2000, COMPUT VISION IMAGE, V78, P78
   MORE JJ, 1994, ACM T MATH SOFTWARE, V20, P286, DOI 10.1145/192115.192132
   RANGARAJAN A, 1993, MARKOV RANDOM FIELDS, P69
   Rey WJ, 1983, INTRO ROBUST QUASI R
   Rivera M, 2002, COMPUT VIS IMAGE UND, V88, P76, DOI 10.1006/cviu.2002.0975
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802
   Teboul S, 1998, IEEE T IMAGE PROCESS, V7, P387, DOI 10.1109/83.661189
NR 29
TC 26
Z9 29
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2003
VL 21
IS 4
BP 345
EP 357
DI 10.1016/S0262-8856(03)00005-2
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 669PH
UT WOS:000182359300003
DA 2024-07-18
ER

PT J
AU Buxton, H
AF Buxton, H
TI Learning and understanding dynamic scene activity: a review
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE cognitive computer vision; generative model; visual reasoning; visual
   control; visual learning
ID NONRIGID MOTION; MARKOV-MODELS; PERCEPTION; TRACKING; INDEXES; SHAPE
AB We are entering an era of more intelligent cognitive vision systems. Such systems can analyse activity in dynamic scenes to compute conceptual descriptions from motion trajectories of moving people and the objects they interact with. Here we review progress in the development of flexible, generative models that can explain visual input as a combination of hidden variables and can adapt to new types of input. Such models are particularly appropriate for the tasks posed by cognitive vision as they incorporate learning as well as having sufficient structure to represent a general class of problems. In addition, generative models explain all aspects of the input rather than attempting to ignore irrelevant sources of variation as in exemplar-based learning. Applications of these models in visual interaction for education, smart rooms and cars, as well as surveillance systems is also briefly reviewed. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Univ Sussex, Sch Cognit & Comp Sci, Brighton BN1 9QH, E Sussex, England.
C3 University of Sussex
RP Univ Sussex, Sch Cognit & Comp Sci, Brighton BN1 9QH, E Sussex, England.
EM hilaryb@cogs.susx.ac.uk
CR [Anonymous], BRIT MACH VIS C GUIL
   [Anonymous], 1987, Proceedings of the 6th National Conference on Artificial Intelligence, San Mateo, CA: Morgan Kaufmann
   [Anonymous], IEEE INT C COMP VIS
   BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4
   Baumberg A, 1996, IMAGE VISION COMPUT, V14, P525, DOI 10.1016/0262-8856(96)01092-X
   Baumberg A, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P87
   BAUMBERG A, 1996, BRIT MACH VIS C ED S, P313
   BAUMBERG A, 1994, EUR C COMP VIS, P299
   BEYMER D, 1997, IEEE C COMP VIS PATT
   Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933
   BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1
   Blake A., 1998, ACTIVE CONTOURS
   BOBICK AF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P382
   Bobick AF, 1999, PRESENCE-VIRTUAL AUG, V8, P369, DOI 10.1162/105474699566297
   Brand M., 1997, IEEE C COMP VIS PATT
   Buxton H, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P797, DOI 10.1109/ICIP.1996.561025
   BUXTON H, 1995, ARTIF INTELL, V78, P431, DOI 10.1016/0004-3702(95)00041-0
   BUXTON H, 1997, REPRESENTATION PROCE
   CHARNIAK E, 1991, AI MAG, V12, P50
   Cootes T. F., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P9
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dean T., 1988, AAAI 88. Seventh National Conference on Artificial Intelligence, P524
   EDWARDS GJ, 1997, BRIT MACH VIS C, P130
   Eklundh Janolof., 1996, BMVC, P1
   Forbes J., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1878
   FREY BJ, 2001, CVPR WORKSH MOD VERS
   Friedman N., 1997, ICML, P125
   Galata A, 2001, COMPUT VIS IMAGE UND, V81, P398, DOI 10.1006/cviu.2000.0894
   GONG S, 1992, INT C AD LEARN SYST, P175
   GONG S, 1992, INT C NEUR STOCH MET, P45
   HECKERMAN D, 1998, NATO ASI LEARNING GR, P301
   HILL A, 1993, BRIT MACH VIS C BMVC, P339
   Hogg D., 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3
   Hongeng S., 2000, INT C PATT REC BARC
   HOWARTH R, 1993, IJCAI-93, VOLS 1 AND 2, P1579
   HOWARTH R, 1997, ICCV WORHSH VIS SURV
   HOWARTH R, 1996, ECCV96 2, P321
   Howarth RJ, 2000, IMAGE VISION COMPUT, V18, P105, DOI 10.1016/S0262-8856(99)00025-6
   Howarth RJ, 1998, ARTIF INTELL, V100, P5, DOI 10.1016/S0004-3702(98)00004-6
   Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707
   Isard M., 1996, ECCV, P343
   JEBARA T, 1999, ICVS, P273
   JEBARA T, 2000, ADV NEURAL INFORMATI, V13
   Johnson N, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P583
   Johnson N, 1998, PROC CVPR IEEE, P866, DOI 10.1109/CVPR.1998.698706
   Jordan M. I., 1998, NATO SCI SERIES
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Land MF, 2000, NAT NEUROSCI, V3, P1340, DOI 10.1038/81887
   LEVITT TS, 1990, MACHINE INTELLIGENCE, V9
   LEVITT TS, 1990, MACHINE INTELLIGENCE, V10
   MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275
   MacCormick J., 2000, IEEE European Conference on Computer Vision, P3, DOI DOI 10.1007/3-540-45053-X1
   Malik J, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P367
   METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727
   Morris RJ, 2000, INT J COMPUT VISION, V37, P209, DOI 10.1023/A:1008159822101
   Murphy K., 2001, Learning Bayes net structure from sparse data sets
   NASTAR C, 1994, EUR C COMP VIS STOCK, P231
   NICHOLSON AE, 1992, ECAI 92 - 10TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE : PROCEEDINGS, P689
   OLIVER N, 1998, ADV NEURAL INFORMATI
   OLIVER N, 2000, INTELLIGENT VEHICLES
   Oliver N., 1999, INT C VIS SYST GRAN
   Pearl J., 1988, PROBABILISTIC REASON
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661
   Pentland A, 1999, NEURAL COMPUT, V11, P229, DOI 10.1162/089976699300016890
   Pentland AP, 1996, SCI AM, V274, P68, DOI 10.1038/scientificamerican0496-68
   Pinhanez CS, 1997, APPL ARTIF INTELL, V11, P285, DOI 10.1080/088395197118163
   PYLYSHYN Z, 1989, COGNITION, V32, P65, DOI 10.1016/0010-0277(89)90014-0
   Pylyshyn ZW, 2001, COGNITION, V80, P127, DOI 10.1016/S0010-0277(00)00156-6
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   REMAGNINO P, 1997, BRIT MACH VIS C, P380
   RIMEY RD, 1994, INT J COMPUT VISION, V12, P173, DOI 10.1007/BF01421202
   RIMEY RD, 1992, EUR C COMP VIS GEN I, P542
   Rittscher J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P634, DOI 10.1109/ICCV.1999.791284
   Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   SPIEGELHALTER DJ, 1992, BAYESIAN STAT, V4
   Starner T., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P265, DOI 10.1109/ISCV.1995.477012
   SULLIVAN GD, 1995, ICCV WORKSH CONT VIS, P75
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Terzopoulos D, 1999, COMPUT GRAPHICS-US, V33, P42, DOI 10.1145/345370.345400
   Terzopoulos D., 1997, Videre: Journal of Computer Vision Research, V1, P2
   TURK M, 1996, IEEE INT C AUT FAC G
   ULLMAN S, 1984, COGNITION, V18, P97, DOI 10.1016/0010-0277(84)90023-4
   *VIEWS CONS, 1992, ESPRIT WORKSH ECCV G
   WHITEHEAD SD, 1991, MACH LEARN, V7, P45, DOI 10.1023/A:1022619109594
   Wren C. R., 1998, IEEE INT C AUT FAC G
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726
NR 88
TC 93
Z9 100
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 125
EP 136
AR PII S0262-8856(02)00127-0
DI 10.1016/S0262-8856(02)00127-0
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800013
DA 2024-07-18
ER

PT J
AU Xu, T
   Han, B
   Li, J
   Du, YF
AF Xu, Tuo
   Han, Bing
   Li, Jie
   Du, Yuefan
TI A locally weighted, correlated subdomain adaptive network employed to
   facilitate transfer learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Domain adaptation; Correlation subdomain adaptation; Maximum mean
   difference; Correlation transfer learning; Deep learning
AB Domain adaptation has found extensive applications in diverse fields, including transfer learning, deep learning, and image processing, to effectively address the challenge of mismatched data distributions. Nevertheless, persistent challenges such as limited transfer data and the occurrence of negative transfer continue to exist. These issues not only increase the complexity of model learning but also affect the accuracy of the transfer results. To tackle these challenges, this paper introduces a novel approach called the Related Weighted Subdomain Adaptive Network (RWSAN). This network constructs related subdomain clusters in the source domain to encompass a wider spectrum of associated information. It aims to align target domain subdomains with the related subdomain clusters in the source domain as closely as possible, thus increasing the number of transferable samples from the source domain and solving insufficient transferable samples in some adaptations. To address the issue of negative transfer arising from irrelevant subdomains in the source domain during the transfer process, a related weighted maximum mean discrepancy method is introduced. This method optimizes transfer weights, minimizes the feature distribution disparity between the target domain and the source domain, and mitigates the negative impact of irrelevant subdomains on the target domain, thereby enhancing the accuracy of domain adaptation during transfer. To evaluate the proposed RWSAN method, comprehensive performance tests were conducted using widely used red-green-blue (RGB) and hyperspectral image (HIS) image datasets. The results demonstrate that the RWSAN method effectively resolves insufficient transfer data and negative transfer, proving its high reliability. Additionally, it exhibits excellent performance in error analysis, network convergence analysis, data visualization, and distribution difference.
C1 [Xu, Tuo; Han, Bing; Li, Jie] Xidian Univ, Sch Elect Engn, VIPSL Lab, Xian, Shannxi, Peoples R China.
   [Du, Yuefan] Xidian Univ, Sch Aerosp Sci & Technol, MCI Lab, Xian, Xian, Shannxi, Peoples R China.
C3 Xidian University; Xidian University
RP Xu, T (corresponding author), Xidian Univ, Sch Elect Engn, VIPSL Lab, Xian, Shannxi, Peoples R China.
EM xutuoxidian@163.com
RI Du, Yuefan/KBC-5686-2024
OI Du, Yuefan/0000-0002-1863-0225
FU National Natural Science Foundation of China [U21A20514]; Key chain
   innovation projects of Shaanxi
FX This work was supported by National Natural Science Foundation of China
   (No. U21A20514) , Key chain innovation projects of Shaanxi (Program
   No.2022ZDLGY01-14) .
CR Cao ZJ, 2018, LECT NOTES COMPUT SC, V11212, P139, DOI 10.1007/978-3-030-01237-3_9
   Chai S., 2024, Expert Syst. Appl., V237
   Elhadji-Ille-Gado N, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1006, DOI 10.1109/ICMLA.2017.00-20
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X, 2020, IEEE T GEOSCI REMOTE, V58, P3246, DOI 10.1109/TGRS.2019.2951445
   Kumar A, 2018, ADV NEUR IN, V31
   Li L, 2021, PROC CVPR IEEE, P224, DOI [10.1109/CVPR46437.2021.00029, 10.1109/ICPECA51329.2021.9362616]
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Long Mingsheng, 2018, Advances in Neural Information Processing Systems, V31
   Nam H, 2021, PROC CVPR IEEE, P8686, DOI 10.1109/CVPR46437.2021.00858
   Özcelik YB, 2023, FRACTAL FRACT, V7, DOI 10.3390/fractalfract7080598
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Sezer A, 2021, SOLDER SURF MT TECH, V33, P291, DOI 10.1108/SSMT-04-2021-0013
   Singh DK, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23198235
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Valente N.A., 2023, Mech. Syst. Signal Process., V204
   Venkateswara H, 2017, Arxiv, DOI arXiv:1706.07522
   Wang HY, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15040999
   Wang JD, 2018, INT CONF PERVAS COMP, P115
   Wang J, 2019, IEEE INT CON MULTI, P1210, DOI 10.1109/ICME.2019.00211
   Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang SS, 2023, NEUROCOMPUTING, V523, P213, DOI 10.1016/j.neucom.2022.12.048
   Wang Z., 2021, P IEEE CVF INT C COM, P834
   Xie SA, 2018, PR MACH LEARN RES, V80
   Yag I, 2022, BIOLOGY-BASEL, V11, DOI 10.3390/biology11121732
   Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107
   Yang JY, 2023, IEEE WINT CONF APPL, P520, DOI 10.1109/WACV56688.2023.00059
   Yu CH, 2019, IEEE DATA MINING, P778, DOI 10.1109/ICDM.2019.00088
   Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851
   Zhu YC, 2021, IEEE T NEUR NET LEAR, V32, P1713, DOI 10.1109/TNNLS.2020.2988928
   Zhuang FZ, 2020, Arxiv, DOI [arXiv:1911.02685, DOI 10.1109/JPROC.2020.3004555]
   Zhuang FZ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4119
NR 41
TC 1
Z9 1
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104887
DI 10.1016/j.imavis.2023.104887
EA DEC 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FZ3Y5
UT WOS:001149649900001
DA 2024-07-18
ER

PT J
AU Wang, MH
   Liao, L
   Huang, D
   Fan, Z
   Zhuang, JF
   Zhang, WS
AF Wang, Meihua
   Liao, Lei
   Huang, De
   Fan, Zhun
   Zhuang, Jiafan
   Zhang, Wensheng
TI Frequency and content dual stream network for image dehazing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image dehazing; Frequency features; Attention octave convolution; Dual
   self -attention
AB Image dehazing can improve image clarity and visual effect, which plays a pivotal role in many computer vision tasks. Existing dehazing methods are mostly based on a single feature stream and tend to ignore the lowfrequency characteristics of haze. In this paper, we propose a dual stream network for image dehazing. To enhance the edge information and texture detail of the image, we construct a frequency stream based on attention octave convolution. We decompose the features into high and low-frequency branches in the frequency stream to obtain different structural information. By adding a residual channel attention block, the attention octave convolution can extract frequency features more efficiently and effectively. Due to the lower resolution of low-frequency features in the frequency stream, the frequency stream features alone are insufficient for recovering the overall content of the image. Therefore, a content stream was added to compensate for the information lost in the frequency stream. By fusing the outputs of two feature streams, the network achieves an enhanced dehazing performance. The results show that our method is superior to other state-of-the-art algorithms in quantitative evaluation and visual impact.
C1 [Wang, Meihua; Liao, Lei; Huang, De] South China Agr Univ, Guangzhou 510642, Peoples R China.
   [Fan, Zhun; Zhuang, Jiafan] Shantou Univ, Shantou 515063, Peoples R China.
   [Zhang, Wensheng] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
C3 South China Agricultural University; Shantou University; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS
RP Fan, Z (corresponding author), Shantou Univ, Shantou 515063, Peoples R China.
EM zfan@stu.edu.cn
FU National Natural Science Foundation of China [61976052, 62176147]; Key
   Program of Wen's Joint Fund of Guangdong Basic and Applied Basic
   Research Fund [2019B1515210009]
FX This work was supported in part by the National Natural Science
   Foundation of China under grants 61976052 and 62176147, and in part by
   the Key Program of Wen's Joint Fund of Guangdong Basic and Applied Basic
   Research Fund under grant 2019B1515210009.
CR Ancuti CO, 2019, IEEE IMAGE PROC, P1014, DOI [10.1109/icip.2019.8803046, 10.1109/ICIP.2019.8803046]
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52
   Bai L, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3160492
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13910, DOI 10.1109/ICCV48922.2021.01367
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353
   Chen ZY, 2021, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR46437.2021.00710
   Cheng D., 2022, PROC 31 INT JOINT C, P848
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fan Z., 2019, arXiv
   Feng CM, 2021, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3090303
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo CL, 2022, PROC CVPR IEEE, P5802, DOI 10.1109/CVPR52688.2022.00572
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Ju MY, 2022, IEEE T CIRC SYST VID, V32, P4867, DOI 10.1109/TCSVT.2021.3101503
   Kan ZW, 2022, IEEE J-STARS, V15, P1089, DOI 10.1109/JSTARS.2021.3129622
   Li BY, 2018, AAAI CONF ARTIF INTE, P7016
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li PY, 2021, IEEE T IMAGE PROCESS, V30, P1100, DOI 10.1109/TIP.2020.3040075
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Liu F, 2015, APPL OPTICS, V54, P8116, DOI 10.1364/AO.54.008116
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Peng LT, 2023, IEEE T IMAGE PROCESS, V32, P3066, DOI 10.1109/TIP.2023.3276332
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Sharma P, 2023, ACM T SENSOR NETWORK, V19, DOI 10.1145/3577926
   Song XB, 2023, IEEE T IMAGE PROCESS, V32, P1231, DOI 10.1109/TIP.2023.3234701
   Tu Z., 2022, P IEEE CVF C COMP VI, P5769
   Wang JB, 2018, IEEE T CIRC SYST VID, V28, P2190, DOI 10.1109/TCSVT.2017.2728822
   Wang PY, 2022, IEEE T CIRC SYST VID, V32, P2760, DOI 10.1109/TCSVT.2021.3097713
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Xu Q, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010188
   Xu YJ, 2022, COMPUT GRAPH-UK, V107, P50, DOI 10.1016/j.cag.2022.07.001
   Yu H, 2022, LECT NOTES COMPUT SC, V13679, P181, DOI 10.1007/978-3-031-19800-7_11
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang XQ, 2022, IEEE T CIRC SYST VID, V32, P510, DOI 10.1109/TCSVT.2021.3067062
   Zhang XQ, 2021, IEEE T CIRC SYST VID, V31, P4162, DOI 10.1109/TCSVT.2020.3046625
   Zhao D, 2021, IEEE T CIRC SYST VID, V31, P3037, DOI 10.1109/TCSVT.2020.3036992
   Zhiwei Wang, 2021, 2021 IEEE 21st Annual Wireless and Microwave Technology Conference (WAMICON), P670, DOI 10.1109/ICSIP52628.2021.9688654
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 56
TC 0
Z9 0
U1 8
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104820
DI 10.1016/j.imavis.2023.104820
EA OCT 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA U8IR9
UT WOS:001087188600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, YA
   Liu, YF
   Zheng, DR
   Huang, YH
   Tang, YL
AF Li, Yanan
   Liu, Yifei
   Zheng, Dingrun
   Huang, Yuhan
   Tang, Yuling
TI Discriminable feature enhancement for unsupervised domain adaptation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised domain adaptation; Convolutional neural networks;
   Discriminable feature; Adversarial learning
AB Unsupervised domain adaptation addresses the problem of knowledge transformation from source domain to target domain, aiming to effectively alleviate data distribution mismatch and data labeling consumption. The issue of data distribution mismatches is widespread in actual agricultural visual tasks. Moreover, it is expensive and time-consuming to construct and label visual image data. For in-field cotton boll, its maturing status can greatly affect the yield and quality. Uneven distribution restrains the performance for maturing status recognition. Therefore, domain adaptation is essential for identifying cross-domain cotton boll maturity. Existing unsupervised domain adaptation methods obtain domain invariant feature for achieving domain alignment. However, the discriminability of features is less considered, which may result in unsatisfactory classification results. In this paper, an unsupervised domain adaptation method called discriminable feature enhancement (DFE-DA) is proposed to identify cross-domain cotton boll maturity. It enables to minimize intra-class distance by maximizing intra-domain density(MID) loss and realizes discriminable feature enhancement. The effectiveness of DFE-DA is verified on in-field cotton boll V2(IFCB-V2) dataset containing 2400 images. The experimental results demonstrate that DFE-DA has an average improvement of 12.8%, 10.3% and 7.6% compared with other methods in three different transfer tasks. Furthermore, the MID loss can cooperate well with other adversarial methods. To verity the robustness of DFE-DA, additional experiments conducted on the public benchmark Office31 and Office-Home indicates it is comparable to the state-of-the-arts.
C1 [Li, Yanan; Liu, Yifei; Zheng, Dingrun; Huang, Yuhan; Tang, Yuling] Wuhan Inst Technol, Sch Comp Sci & Engn, Sch Artificial Intelligence, Wuhan 430205, Hubei, Peoples R China.
   [Li, Yanan; Liu, Yifei; Zheng, Dingrun; Huang, Yuhan; Tang, Yuling] Wuhan Inst Technol, Hubei Key Lab Intelligent Robot, Wuhan 430073, Hubei, Peoples R China.
C3 Wuhan Institute of Technology; Wuhan Institute of Technology
RP Li, YA (corresponding author), Wuhan Inst Technol, Sch Comp Sci & Engn, Sch Artificial Intelligence, Wuhan 430205, Hubei, Peoples R China.
EM yananli@wit.edu.cn; 22107010108@stu.wit.edu.cn;
   22107010031@stu.wit.edu.cn; 22107010100@stu.wit.edu.cn;
   22107010047@stu.wit.edu.cn
RI Li, Yanan/ABL-1507-2022
OI Li, Yanan/0000-0002-6321-2567; Liu, Yifei/0000-0002-0198-0368
FU National Natural Science Foundation of China; Knowledge Innovation
   Program of Wuhan-Shuguang Project; Hubei Key Laboratory of Intelligent
   Robot (Wuhan Institute of Technology) of China
FX This work was supported in part by National Natural Science Foundation
   of China under Grant 61906139, in part by Knowledge Innovation Program
   of Wuhan-Shuguang Project under Grant 2022010801020359, and in part by
   the Hubei Key Laboratory of Intelligent Robot (Wuhan Institute of
   Technology) of China under Grant HBIRL 202108.
CR Arora S, 2017, PR MACH LEARN RES, V70
   Chen XY, 2019, PR MACH LEARN RES, V97
   Cui SH, 2020, PROC CVPR IEEE, P3940, DOI 10.1109/CVPR42600.2020.00400
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004
   Du ZK, 2021, PROC CVPR IEEE, P3936, DOI 10.1109/CVPR46437.2021.00393
   Ganin Y, 2016, J MACH LEARN RES, V17
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou XX, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103926
   Huang JX, 2022, PROC CVPR IEEE, P1193, DOI 10.1109/CVPR52688.2022.00127
   Iqbal J, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104504
   Jing LL, 2022, INT J OCCUP SAF ERGO, V28, P842, DOI [10.1080/10803548.2020.1835234, 10.1109/TPAMI.2020.2991050]
   Kurmi VK, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104180
   Li S, 2018, IEEE T IMAGE PROCESS, V27, P4260, DOI 10.1109/TIP.2018.2839528
   Li YA, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105745
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685
   Ma A, 2022, IEEE T NEUR NET LEAR, V33, P6263, DOI 10.1109/TNNLS.2021.3073119
   Ma YC, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106314
   Marino S, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105501
   Mengxue Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13933, DOI 10.1109/CVPR42600.2020.01395
   Na J, 2021, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR46437.2021.00115
   Paszke A, 2019, ADV NEUR IN, V32
   Ruder S, 2017, Arxiv, DOI arXiv:1609.04747
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Shamsolmoali P, 2021, IMAGE VISION COMPUT, V114, DOI 10.1016/j.imavis.2021.104268
   Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6
   Sharma A, 2021, PROC CVPR IEEE, P5357, DOI 10.1109/CVPR46437.2021.00532
   Shenaj D, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104426
   Shuhao Cui, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12452, DOI 10.1109/CVPR42600.2020.01247
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tzeng E, 2014, Arxiv, DOI [arXiv:1412.3474, 10.48550/arXiv.1412.3474, DOI 10.48550/ARXIV.1412.3474]
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Wei GQ, 2021, PROC CVPR IEEE, P16638, DOI 10.1109/CVPR46437.2021.01637
   Xiao N, 2021, PROC CVPR IEEE, P15237, DOI 10.1109/CVPR46437.2021.01499
   Zhou Q, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104137
   Zhu YC, 2021, IEEE T NEUR NET LEAR, V32, P1713, DOI 10.1109/TNNLS.2020.2988928
NR 41
TC 2
Z9 2
U1 7
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104755
DI 10.1016/j.imavis.2023.104755
EA JUL 2023
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA O1RK7
UT WOS:001041659600001
DA 2024-07-18
ER

PT J
AU Li, YQ
   Wu, Y
   Liu, C
   Wu, XY
AF Li, Yuqiang
   Wu, Ying
   Liu, Chun
   Wu, Xinyi
TI hr IAC-ReCAM: Two-dimensional attention modulation and category label
   guidance for weakly supervised semantic segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic segmentation; Weakly supervised learning; Attention modulation
AB Weakly supervised semantic segmentation (WSSS) approaches aim at pixel-level semantic category prediction using only image-level labels. The existing classifier-based method ReCAM has achieved good results, however, the classifiers tend to only focus on the most discriminative regions, resulting in an uneven distribution of fea-tures in the resulting class activation maps (CAMs). Besides, the classifiers are susceptible to image background interference and generate false activation mapping. To solve the above problems, we propose an improved method IAC-ReCAM, which introduces an activation network that integrated attention modulation and category label guidance based on the ReCAM method. We utilize the attention modulation module to reassign the feature distribution of the CAMs from the perspective of channels and spaces in turn. Meanwhile, we use the class label guidance module to suppress the generation of false activation mapping. Furthermore, we verified the effective-ness of the IAC-ReCAM method improvement work on both PASCAL VOC 2012 and MS COCO 2014 datasets, our method outperforms a large number of existing mainstream methods. Among them, compared with the ReCAM method, the mIoU of the pseudo-labels on the two datasets is improved by 2.9% and 1%, respectively.& COPY; 2023 Published by Elsevier B.V.
C1 [Li, Yuqiang; Wu, Ying; Liu, Chun; Wu, Xinyi] Wuhan Univ Technol, Wuhan 430070, Peoples R China.
C3 Wuhan University of Technology
RP Liu, C (corresponding author), Wuhan Univ Technol, Wuhan 430070, Peoples R China.
EM liuchun@whut.edu.cn
CR Ahn J, 2019, PROC CVPR IEEE, P2204, DOI 10.1109/CVPR.2019.00231
   Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   Bearman Amy, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Qi, 2022, P IEEECVF C COMPUTER, P4288
   Chen Z., 2022, IEEECVF C COMPUT VIS, P969
   Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Kim B, 2021, AAAI CONF ARTIF INTE, V35, P1754
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   Lee J., 2021, IEEE CVF C COMP VIS, P4071
   Lee J., 2022, P IEEECVF C COMPUTER, P16897
   Lee J, 2019, PROC CVPR IEEE, P5262, DOI 10.1109/CVPR.2019.00541
   Lee M, 2022, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR52688.2022.00429
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209
   Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780
   Qin J, 2022, AAAI CONF ARTIF INTE, P2117
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu J, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3336495
   Xie J., 2022, arXiv
   Yude Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12272, DOI 10.1109/CVPR42600.2020.01229
   Zhang BF, 2022, IEEE T PATTERN ANAL, V44, P8082, DOI 10.1109/TPAMI.2021.3083269
   ZHANG D, 2020, ADV NEURAL INFORM PR, V33, P655, DOI DOI 10.5555/3495724.3495780
   Zhang XR, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5463, DOI 10.1145/3474085.3475675
NR 32
TC 0
Z9 0
U1 2
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104738
DI 10.1016/j.imavis.2023.104738
EA JUN 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA M1EV7
UT WOS:001027660700001
DA 2024-07-18
ER

PT J
AU Yang, KQ
   Li, JD
   Dai, SM
   Li, XQ
AF Yang, Kequan
   Li, Jide
   Dai, Songmin
   Li, Xiaoqiang
TI Multiscale features integration based multiple-in-single-out network for
   object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Objects of different scales; Single-level feature map;
   Receptive fields
AB The single-level feature map-based object detection has been a challenging task due to the feature scale limitation. Therefore, enriching multiscale information of single-level features is considered a promising approach to deal with this challenge. Although most existing methods have attempted to augment the feature scale of single-level features, the detection performance is still unsatisfactory because these methods mine multiscale features only based on a one-level feature map. To address this problem, we propose a multiple-in-single-out network (MiSoNet) to integrate multiscale information from multilevel feature maps into a single-level feature map. To achieve this, MiSoNet's key component is equipped with two cascaded modules: a multilevel feature integration module (MFIM) and a depthwise convolutional residual encoder (DWEncoder). Specifically, MFIM adaptively fuses features of inconsistent semantics and scales from multilevel feature maps. DWEncoder stacks several residual blocks with depthwise convolutions to extract multiscale contexts in the single feature map, which can further extend the scale range of the receptive fields. Extensive experiments are conducted on the Common Objects in Context (COCO) dataset, where the MiSoNet achieves a 41.0AP, which surpasses the YOLOF by 1.4AP with negligible computational overhead. Moreover, the MiSoNet, with fewer parameters and FLOPs, outperforms some advanced detectors based on the feature pyramid network.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Yang, Kequan; Li, Jide; Dai, Songmin; Li, Xiaoqiang] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
C3 Shanghai University
RP Li, XQ (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
EM kqyang@shu.edu.cn; iavtvai@shu.edu.cn; laodar@shu.edu.cn;
   xqli@shu.edu.cn
RI Yang, Kequan/JZD-4316-2024
FU Science and Technology Innovation Plan Of Shanghai Science and
   Technology Commission [21511100600]
FX Acknowledgments This work is supported in part by Science and Technology
   Innovation Plan Of Shanghai Science and Technology Commission under
   Grant No. 21511100600. We appreciate the High Performance Computing
   Center of Shanghai University, and Shanghai Engineering Research Center
   of Intelligent Computing System for providing the computing resources
   and technical support.
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Aziz L, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104287
   Bolya Daniel, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P558, DOI 10.1007/978-3-030-58580-8_33
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen K, 2019, Arxiv, DOI arXiv:1906.07155
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dai XY, 2021, PROC CVPR IEEE, P7369, DOI 10.1109/CVPR46437.2021.00729
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Dosovitskiy Alexey, 2021, ICLR
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fan ZJ, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108437
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Gupta AK, 2021, PATTERN ANAL APPL, V24, P625, DOI 10.1007/s10044-020-00925-1
   Gupta AK, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22101174
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li BY, 2019, AAAI CONF ARTIF INTE, P8577
   Li F, 2022, PROC CVPR IEEE, P13609, DOI 10.1109/CVPR52688.2022.01325
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2022, 10 INT C LEARNING RE
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2019, Arxiv, DOI arXiv:1911.09516
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Luo WJ, 2016, ADV NEUR IN, V29
   Meng DP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3631, DOI 10.1109/ICCV48922.2021.00363
   Miao SY, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108258
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Peng JR, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108199
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Xi X, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104466
   Xie E., 2021, NeurIPS, P1
   Zhang XS, 2019, ADV NEUR IN, V32
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhu C., 2022, P IEEE CVF C COMP VI, P11112
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu Xizhou, 2021, 9 INT C LEARNING REP
NR 60
TC 2
Z9 2
U1 2
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104714
DI 10.1016/j.imavis.2023.104714
EA MAY 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA J8ZX5
UT WOS:001012463800001
DA 2024-07-18
ER

PT J
AU Batool, A
   Nisar, MW
   Khan, MA
   Shah, JH
   Tariq, U
   Damasevicius, R
AF Batool, Aisha
   Nisar, Muhammad Wasif
   Khan, Muhammad Attique
   Shah, Jamal Hussain
   Tariq, Usman
   Damasevicius, Robertas
TI Traffic sign recognition using proposed lightweight twig-net with linear
   discriminant classifier for biometric application
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Traffic sign; Classification; Machine learning; Autonomous vehicles;
   Computer vision
ID SELECTION
AB The development and rise in Artificial Intelligence (AI) applications including Intelligent Transport System (ITS) has significantly reshaped and transformed. A key research area that is, an intelligent visual aid for Traffic Sign Recognition (TSR) has been certainly persuaded and transformed to control automobiles and ensure safe driving. Similarly, TSR is an important feature of Advanced Driver Assistance Systems (ADAS) that contributes to the safety of drivers, pedestrians, and automobiles. This work is aimed to recognize traffic signs robustly and effi-ciently in challenging environmental conditions. Hence, keeping the diversity of the problem in mind, a novel 30-layered deep Convolutional Neural Network (CNN) model is proposed. In the proposed model each convolutional layer produced around a minimum number of salient and highly discriminative features incorpo-rating different datasets for classification purposes. This novel approach used the extracted features to train the model without the assistance of a Graphics Processing Unit (GPU). Once the model becomes trained, different competitive classifiers including Tree, SVM, KNN, and discriminant analysis are used to classify the data. The re-sult reflects that Linear Discriminant Analysis (LDA) achieves comparable results among all other competitive classifiers with 97.4% accuracy with a minimum training time of 5.12 s on the CURE-TSR dataset. To evaluate and monitor the efficacy of the novel approach, it is further tested on two more datasets including GTSRB and BTSRB. The proposed approach acquired 99.12% and 98.16% accuracy on both datasets respectively. Finally, the comparable results on all the benchmark datasets reflect the proposed approach's applicability and advantage.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Batool, Aisha; Nisar, Muhammad Wasif; Shah, Jamal Hussain] COMSATS Univ Islamabad, Dept Comp Sci, Wah campus, Islamabad, Pakistan.
   [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci, Taxila, Pakistan.
   [Tariq, Usman] Prince Sattam Bin Abdulaziz Univ, Dept Management Informat Syst, CoBA, Al Kharj, Saudi Arabia.
   [Damasevicius, Robertas] Kaunas Univ Technol, Fac Informat, LT-44249 Kaunas, Lithuania.
C3 COMSATS University Islamabad (CUI); NITEC University; Prince Sattam Bin
   Abdulaziz University; Kaunas University of Technology
RP Nisar, MW (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Wah campus, Islamabad, Pakistan.; Khan, MA (corresponding author), HITEC Univ, Dept Comp Sci, Taxila, Pakistan.; Damasevicius, R (corresponding author), Kaunas Univ Technol, Fac Informat, LT-44249 Kaunas, Lithuania.
EM wasifnisar@gmail.com; attique.khan@hitecuni.edu.pk
RI Tariq, Usman/GZL-9946-2022; Khan, Dr. Muhammad Attique/AAX-2644-2021;
   Damaševičius, Robertas/E-1387-2017; Shah, Jamal Hussain/AAA-7034-2021
OI Khan, Dr. Muhammad Attique/0000-0002-6347-4890; Damaševičius,
   Robertas/0000-0001-9990-1084; Shah, Jamal Hussain/0000-0002-7903-9391;
   Batool, Aisha/0000-0003-3981-1735
CR Al-Makhadmeh Z, 2020, COMPUTING, V102, P501, DOI 10.1007/s00607-019-00745-0
   Ansari GJ, 2021, IEEE ACCESS, V9, P54923, DOI 10.1109/ACCESS.2021.3071169
   Ardianto S, 2017, INT CONF SYST SIGNAL
   Bahlmann C, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P255
   Bi Z., 2020, IMPROVED VGG MODEL B, P1
   Boujemaa K.S., 2021, ATTICA DATASET ARABI
   Bouvrie J, 2006, MITCBCLTECH REPORT
   Chan C.-Y.J.I., 2017, ADV PROSPECTS IMPACT, V6, P208
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen SC, 2004, PATTERN RECOGN, V37, P1545, DOI 10.1016/j.patcog.2003.11.008
   Dagher I, 2008, J GLOBAL OPTIM, V41, P15, DOI 10.1007/s10898-007-9162-0
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   delaEscalera A, 1997, IEEE T IND ELECTRON, V44, P848, DOI 10.1109/41.649946
   Fang CY, 2003, IEEE T VEH TECHNOL, V52, P1329, DOI 10.1109/TVT.2003.810999
   Fatmehsan Younes Rakhshani, 2010, 2010 International Conference on Multimedia Computing and Information Technology (MCIT 2010), P25, DOI 10.1109/MCIT.2010.5444860
   Fleyeh H., 2008, 2008 IEEE INT VEH S
   Fujiyoshi H, 2019, IATSS RES, V43, P244, DOI 10.1016/j.iatssr.2019.11.008
   Gudigar A, 2016, MULTIMED TOOLS APPL, V75, P333, DOI 10.1007/s11042-014-2293-7
   Han Y., 2015, 2015 IEEE INT C EL I
   Haque W.A., 2021, DEEPTHIN NOVEL LIGHT, V168
   Huang ZY, 2017, IEEE T CYBERNETICS, V47, P920, DOI 10.1109/TCYB.2016.2533424
   Jain A, 2019, NEURAL PROCESS LETT, V50, P3019, DOI 10.1007/s11063-019-09991-x
   Janai J, 2020, FOUND TRENDS COMPUT, V12, P1, DOI 10.1561/0600000079
   Jayaprakash A, 2019, COGN SYST RES, V58, P123, DOI 10.1016/j.cogsys.2019.04.002
   Jiang L., 2005, INT C ADV DAT MIN AP
   Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281
   Jin YM, 2020, IEEE ACCESS, V8, P38931, DOI 10.1109/ACCESS.2020.2975828
   Jones C.I., 2017, ARTICIAL INTELLIGENC
   Kashinath SA, 2021, IEEE ACCESS, V9, P51258, DOI 10.1109/ACCESS.2021.3069770
   Kassani PH, 2017, APPL SOFT COMPUT, V52, P231, DOI 10.1016/j.asoc.2016.12.037
   Khan S., 2018, SYNTHESIS LECT COMPU, V8, P1, DOI DOI 10.2200/S00822ED1V01Y201712COV015
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   LACHENBRUCH PA, 1979, BIOMETRICS, V35, P69, DOI 10.2307/2529937
   Lakhan A, 2023, IEEE T INTELL TRANSP, V24, P8399, DOI 10.1109/TITS.2022.3147852
   Lamba A., 2016, ENG SURVEY KNN ITS V, V5, P430
   Le T.T., 2010, AS C INT INF DAT SYS
   Li HJ, 2015, NEUROCOMPUTING, V169, P77, DOI 10.1016/j.neucom.2014.12.111
   Liu CS, 2014, IEEE T INTELL TRANSP, V15, P2394, DOI 10.1109/TITS.2014.2314711
   Liu ZL, 2015, J INF SCI ENG, V31, P691
   Madani A., 2016, MALAYSIAN TRAFC SIGN, V8, P137
   Maletzky A., 2023, TRAFC SIGN DETECTION, V8, P16
   Mariut F., 2012, 2012 35 INT C TEL SI
   Mohammed M.A., 2022, FULLY HOMOMORPHIC EN, V71, P12140
   Mohd N.A., 2020, VEHICLES COUNTING VI, V8
   Natarajan S, 2018, IET INTELL TRANSP SY, V12, P1396, DOI 10.1049/iet-its.2018.5171
   Nayak A., 2017, 2017 INT C INTELLIGE, P1
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Nuakoh E.B., 2019, P 2019 3 INT C DEEP
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Pei DL, 2013, IEEE SIGNAL PROC LET, V20, P241, DOI 10.1109/LSP.2013.2241760
   Peterson L.E., 2009, SCHOLARPEDIA, V4, P1883, DOI 10.4249/scholarpedia.1883
   Prieto MS, 2009, IMAGE VISION COMPUT, V27, P673, DOI 10.1016/j.imavis.2008.07.006
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruping S., 2001, SVM Kernels for Time Series Analysis
   Saadna Y, 2019, NEURAL COMPUT APPL, V31, P5005, DOI 10.1007/s00521-018-03994-w
   Saha S, 2018, INT CONF COMPUT INFO
   Sebanja I., 2010, 2010 IEEE International Conference on Technologies for Homeland Security (HST 2010), P132, DOI 10.1109/THS.2010.5655078
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A.P, 2018, 2018 INT C ADV COMPU
   Song WZ, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020749
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Tabernik D, 2020, IEEE T INTELL TRANSP, V21, P1427, DOI 10.1109/TITS.2019.2913588
   Temel D., 2017, CURE TSR CHALLENGING
   Temel D., 2018, TRAFC SIGNS WILD HIG
   Tharwat A, 2016, INT J APPL PATTERN R, V3, P145, DOI 10.1504/IJAPR.2016.079050
   Tumer K., 1996, Connection Science, V8, P385, DOI 10.1080/095400996116839
   Vincent M.A., 2020, 2020 IEEE REC ADV IN
   Virdi P, 2016, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON POWER ELECTRONICS, INTELLIGENT CONTROL AND ENERGY SYSTEMS (ICPEICES 2016)
   Wali SB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092093
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu J., 2017, Nat. Key Lab Novel Softw. Technol. Nanjing Univ. China, V5, P495, DOI DOI 10.1007/978-3-642-28661-2-5
   Zhang J., 2020, LIGHTWEIGHT DEEP NET, V75, P369
NR 72
TC 1
Z9 1
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104711
DI 10.1016/j.imavis.2023.104711
EA MAY 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA K2NU9
UT WOS:001014866900001
DA 2024-07-18
ER

PT J
AU Hu, C
   Xie, XH
   Wu, L
AF Hu, Chen
   Xie, Xianghua
   Wu, Lin
TI Face reenactment via generative landmark guidance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face reenactment; GAN; Style transfer; Facial landmarks
AB The identity preserving problem is one of the major obstacles in face reenactment. The problem occurs when the model fails to preserve the detailed information of the source identity, and especially obvious when reenacting different identities. The underlying factors may include the leaking of driver identity, due to the identity mis-match, and unseen large head poses. In this paper, we propose a novel face reenactment approach via generative landmark coordinates. Specifically, a conditional generative adversarial network is developed to estimate reenacted landmark coordinates for the driving image, which successfully excludes its identity information. These generated coordinates are further injected into the subsequent inference style transferal module to in-crease the realism of face images. We evaluated our method on the VoxCeleb1 dataset for self-reenactment and the CelebV dataset for reenacting different identities. Extensive experiments demonstrate that our method can produce more realistic reenacted face images. (c) 2022 Published by Elsevier B.V.
C1 [Hu, Chen; Xie, Xianghua; Wu, Lin] Swansea Univ, Dept Comp Sci, Swansea, Wales.
C3 Swansea University
RP Xie, XH (corresponding author), Swansea Univ, Dept Comp Sci, Swansea, Wales.
EM x.xie@swansea.ac.uk
RI Wu, Lin/GOE-3613-2022; hu, chen/JHT-2836-2023
OI Wu, Lin/0000-0002-3188-0640; 
CR Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cheng Yi-Ting, 2009, SIGGRAPH
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dosovitskiy Alexey, 2021, ICLR
   Ekman P., 1978, Facial action coding system
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Ha S, 2020, AAAI CONF ARTIF INTE, V34, P10893
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaderberg M, 2015, ADV NEUR IN, V28
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Nagrani A, 2020, COMPUT SPEECH LANG, V60, DOI 10.1016/j.csl.2019.101027
   Nirkin Y., 2022, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Radford A., 2015, ARXIV151106434
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Reed S, 2016, PR MACH LEARN RES, V48
   Siarohin A., 2019, Advances in Neural Information Processing Systems (NeurIPS)
   Siarohin A, 2019, PROC CVPR IEEE, P2372, DOI 10.1109/CVPR.2019.00248
   Sun P., 2022, PATTERN RECOGN LETT
   Suwajanakorn S, 2015, IEEE I CONF COMP VIS, P3952, DOI 10.1109/ICCV.2015.450
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang TZ, 2018, ADV NEUR IN, V31
   Wiles O, 2018, LECT NOTES COMPUT SC, V11217, P690, DOI 10.1007/978-3-030-01261-8_41
   Wu WN, 2018, LECT NOTES COMPUT SC, V11205, P622, DOI 10.1007/978-3-030-01246-5_37
   Yao GM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1773, DOI 10.1145/3394171.3413865
   Yao GM, 2021, AAAI CONF ARTIF INTE, V35, P3172
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zeng XF, 2020, AAAI CONF ARTIF INTE, V34, P12757
NR 35
TC 5
Z9 5
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2023
VL 130
AR 104611
DI 10.1016/j.imavis.2022.104611
EA DEC 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 8B3QY
UT WOS:000916842100001
DA 2024-07-18
ER

PT J
AU Xia, HY
   Liu, G
   Xu, LH
   Gan, YL
AF Xia, Haiying
   Liu, Gan
   Xu, Luhui
   Gan, Yanling
TI Collaborative learning network for head pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Head pose estimation; Collaborative learning; Convolutional neural
   networks; Dual-branch transfer; Multi -loss strategy
ID MODEL
AB Head pose estimation is an important task in many real-world applications, such as human-computer interac-tion, driver monitoring, face localization and gaze estimation. In this paper, we present a novel collaborative learning framework based on Convolutional Neural Networks (CNNs) for head pose estimation. The proposed framework consists of a landmark-based branch and a landmark-free branch. The former first estimates facial landmarks and then follows the Landmark-MLP-Mixer module which models the complex nonlinear mapping relationship from facial landmarks to head pose angles. While the later adopts a label distribution learning strategy to estimate head pose. The two branches both dedicate themselves to head pose estimation task, and they collaborate with each other for mutual promotion and complementary semantic learning. Specifically, we introduce a dual-branch transfer module in the middle of the network to achieve explicit semantic interaction and introduce a multi-loss strategy that induces to implicit information interaction. We conduct extensive exper-iments on several popular benchmarks, including AFLW, AFLW2000 and BIWI, the results show that our method is competitive compared to other state-of-the-art methods. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Xia, Haiying; Liu, Gan; Xu, Luhui; Gan, Yanling] Guangxi Normal Univ, Guilin, Peoples R China.
C3 Guangxi Normal University
RP Xu, LH (corresponding author), Guangxi Normal Univ, Guilin, Peoples R China.
EM xhy22@mailbox.gxnu.edu.cn; 3037453964@qq.com; xlh@gxnu.edu.cn;
   gyl@gxnu.edu.cn
FU National Natural Science Founda-tion of China; Science and Technology
   Project of Guangxi; Major Special Projects of Guangxi Science and
   Technology;  [62167001];  [62106054];  [61762014];  [2018GXNSFAA281351];
    [AA20302003]
FX Acknowledgements This work was supported by the National Natural Science
   Founda-tion of China (Grant Nos. 62167001, 62106054, 61762014) , the
   Science and Technology Project of Guangxi (Grant No. 2018GXNSFAA281351)
   , and the Major Special Projects of Guangxi Science and Technology
   (Grant No. AA20302003) .
CR Albiero Vitor, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P7613, DOI 10.1109/CVPR46437.2021.00753
   Amador Elvira, 2018, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 22nd Iberoamerican Congress, CIARP 2017. Proceedings: LNCS 10657, P45, DOI 10.1007/978-3-319-75193-1_6
   Barra P, 2020, IEEE T IMAGE PROCESS, V29, P5457, DOI 10.1109/TIP.2020.2984373
   Bhagavatula C, 2017, IEEE I CONF COMP VIS, P4000, DOI 10.1109/ICCV.2017.429
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Bulat A, 2017, IEEE I CONF COMP VIS, P3726, DOI 10.1109/ICCV.2017.400
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao ZW, 2021, IEEE WINT CONF APPL, P1187, DOI 10.1109/WACV48630.2021.00123
   Chang FJ, 2017, IEEE INT CONF COMP V, P1599, DOI 10.1109/ICCVW.2017.188
   Chen ZZ, 2019, IEEE INT CONF COMP V, P2575, DOI 10.1109/ICCVW.2019.00315
   DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Deng JK, 2018, IEEE INT CONF AUTOMA, P399, DOI 10.1109/FG.2018.00064
   Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Fard AP, 2021, IEEE COMPUT SOC CONF, P1521, DOI 10.1109/CVPRW53098.2021.00168
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Gao BB, 2017, IEEE T IMAGE PROCESS, V26, P2825, DOI 10.1109/TIP.2017.2689998
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Gou C, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023028
   Gu JW, 2017, PROC CVPR IEEE, P1531, DOI 10.1109/CVPR.2017.167
   Gupta A, 2019, INT CONF ACOUST SPEE, P1977, DOI 10.1109/ICASSP.2019.8683503
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Hsu HW, 2019, IEEE T MULTIMEDIA, V21, P1035, DOI 10.1109/TMM.2018.2866770
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579
   Kumar A, 2017, IEEE INT CONF AUTOMA, P258, DOI 10.1109/FG.2017.149
   Lei Ba J., 2016, arXiv
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Liu LY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051841
   Liu ZX, 2019, IEEE INT CONF COMP V, P1232, DOI 10.1109/ICCVW.2019.00156
   Loshchilov I., 2019, arXiv
   Mukherjee SS, 2015, IEEE T MULTIMEDIA, V17, P2094, DOI 10.1109/TMM.2015.2482819
   Murphy-Chutorian E, 2007, 2007 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE, VOLS 1 AND 2, P1049
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Ruan ZY, 2021, IEEE T IMAGE PROCESS, V30, P5793, DOI 10.1109/TIP.2021.3087397
   Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281
   Seemann E, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P626, DOI 10.1109/AFGR.2004.1301603
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Vaezi Joze Hamid Reza, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13286, DOI 10.1109/CVPR42600.2020.01330
   Valle R, 2021, IEEE T PATTERN ANAL, V43, P2874, DOI 10.1109/TPAMI.2020.3046323
   Xin M, 2021, IEEE COMPUT SOC CONF, P1462, DOI 10.1109/CVPRW53098.2021.00162
   Yang H., 2015, P BRIT MACHINE VISIO, DOI [10.5244/C.29.130, DOI 10.5244/C.29.130]
   Yang TY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1078
   Yang TY, 2019, PROC CVPR IEEE, P1087, DOI 10.1109/CVPR.2019.00118
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12789
   Zhang W, 2018, LECT NOTES COMPUT SC, V10996, P148, DOI 10.1007/978-3-319-97909-0_16
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 53
TC 1
Z9 1
U1 8
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104555
DI 10.1016/j.imavis.2022.104555
EA SEP 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300002
DA 2024-07-18
ER

PT J
AU Qi, S
   Sang, XZ
   Yan, BB
   Wang, P
   Chen, D
   Wang, HC
   Ye, XQ
AF Qi, Shuai
   Sang, Xinzhu
   Yan, Binbin
   Wang, Peng
   Chen, Duo
   Wang, Huachun
   Ye, Xiaoqian
TI Unsupervised multi-view stereo network based on multi-stage depth
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D reconstruction; Depth estimation; Multi-view stereo
AB In current years, supervised learning multi-view stereo (MVS) methods have achieved impressive performance. However, these methods still suffer the limitation of hard to acquire large-scale depth supervision data, which hinders the generalization ability in never-seen-before scenarios. Recently, some unsupervised-learning methods have been proposed, which relieved the requirement of depth supervision data. However, the generated depth map with lower resolution since the memory consumption grows cubically. In this paper, we propose a novel unsupervised multi-view stereo network based on multi-stage depth estimation, which can increase depth map resolution and generate a dense 3D model with rich details without relying on depth supervision data. To reduce the 3D cost volume highly memory consumption, the progressive coarse-to-fine multiple stages are adopted. Besides, a multi-view group-wise correlation (MV-GwC) module is designed to introduce multiview correlation prior, which can enhance network performance and further reduce memory consumption. Qualitative and quantitative experiment results show the effectiveness of our method. We outperform some previous supervised and unsupervised MVS methods on DTU and Tanks & Temples benchmarks. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Qi, Shuai; Sang, Xinzhu; Yan, Binbin; Wang, Peng; Chen, Duo; Wang, Huachun; Ye, Xiaoqian] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Sang, XZ; Yan, BB (corresponding author), Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing 100876, Peoples R China.
EM xzsang@bupt.edu.cn; yanbinbin@bupt.edu.cn
RI qi, shuai/HDM-0369-2022; Wang, Huachun/AAO-3889-2021; Qi,
   Shuai/HDM-0320-2022
OI qi, shuai/0000-0002-4200-2472; Qi, Shuai/0000-0002-4200-2472
FU National Natural Science Foundation of China [61905020, 61905017,
   62175017]
FX This work was supported by National Natural Science Foundation of China
   (61905020, 61905017, 62175017).
CR Campbell NDF, 2008, LECT NOTES COMPUT SC, V5302, P766, DOI 10.1007/978-3-540-88682-2_58
   Cernea D., OpenMVS: Multi-view stereo reconstruction library
   Chen PH, 2020, IEEE T IMAGE PROCESS, V29, P7261, DOI 10.1109/TIP.2020.3000611
   Chen R., 2019 IEEECVF INT C C, P1538
   Chen R., P IEEECVF INT C COMP, P1538
   Chen R, 2021, IEEE T PATTERN ANAL, V43, P3695, DOI 10.1109/TPAMI.2020.2988729
   Collins R.T., P CVPR IEEE COMPUTER, P358
   Dai Y., 2019 INT C 3D VISION, P1
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Galliani S., 2015 IEEE INT C COMP, P873
   Gu X., 2020 IEEECVF C COMPU, P2492
   Guo X., 2019 IEEECVF C COMPU, P3268
   Hannah M. J., 1974, Computer Matching of Areas in Stereo Images
   Hongwei Yi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P766, DOI 10.1007/978-3-030-58545-7_44
   Huang B., 2020, ARXIV ABS200409722V2
   Jensen R., 2014 IEEE C COMPUTER, P406
   Ji M., 2017 IEEE INT C COMP, P2326
   Jianfeng Yan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P674, DOI 10.1007/978-3-030-58548-8_39
   Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Khot T., 2019, Learning unsupervised multi-view stereopsis via robust photometric consistency
   Kingma D. P., 2014, arXiv
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Kuhn A, 2019, LECT NOTES COMPUT SC, V11824, P18, DOI 10.1007/978-3-030-33676-9_2
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   Lin T-Y., 2017 IEEE C COMPUTER, P936
   Loshchilov I., 2017, P INT C LEARN REPR
   Luo K., 2019, P IEEECVF INT C COMP
   Luo K., 2020 IEEECVF C COMPU, P1587
   Luo KY, 2019, IEEE I CONF COMP VIS, P10451, DOI 10.1109/ICCV.2019.01055
   Mahjourian R., 2018 IEEE CVF C COMP, P5667
   Moulon P, 2017, LECT NOTES COMPUT SC, V10214, P60, DOI 10.1007/978-3-319-56414-2_5
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Pilzer A, 2020, IEEE T PATTERN ANAL, V42, P2380, DOI 10.1109/TPAMI.2019.2942928
   pix4d, Professional Photogrammetry and Drone Mapping Software
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Seitz S.M., P IEEE COMPUTER SOC, P1067
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun D., P IEEE C COMPUTER VI, P8934
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   Woodford O.J., ARXIV PREPRINT ARXIV
   Xu H., 2021, P IEEE CVF INT C COM, P6078
   Xu Q., 2019 IEEECVF C COMPU, P5478
   Xu QS, 2020, AAAI CONF ARTIF INTE, V34, P12516
   Xue Y., 2019 IEEECVF INT C C, P4311
   Yang J., P IEEECVF C COMPUTER, P4877
   Yang J., P IEEE CVF C COMP VI, P7526
   Yao Y., 2019 IEEE CVF C COMP, P5520
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yu Z., P IEEE CVF C COMP VI, P1949
   Zhan H., P IEEE C COMPUTER VI, P340
   Zhong YR, 2018, LECT NOTES COMPUT SC, V11206, P104, DOI 10.1007/978-3-030-01216-8_7
   Zhou HZ, 2018, LECT NOTES COMPUT SC, V11220, P851, DOI 10.1007/978-3-030-01270-0_50
   Zhou T., 2017 IEEE C COMPUTER, P6612
NR 55
TC 2
Z9 3
U1 5
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104449
DI 10.1016/j.imavis.2022.104449
EA APR 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1F1NU
UT WOS:000794942300007
DA 2024-07-18
ER

PT J
AU Luo, YM
   Ou, ZL
   Wan, TJ
   Guo, JM
AF Luo, Yanmin
   Ou, Zhilong
   Wan, Tianjun
   Guo, Jing-Ming
TI FastNet: Fast high-resolution network for human pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human pose estimation; FastNet; Asymmetric bottleneck module; Waterfall
   module
AB Aiming at the problem of developing efficient models for human pose estimation algorithms under computation-limited resources. In this paper, we proposed an efficient high-resolution network for human pose estimation, which named FastNet. First of all, The Lite-HRNet was constructed by using four parallel subnetworks. Each sub-network contained multiple bottleneck block for feature extraction. The Lite-HRNet can effectively learn the high-resolution representation features of key points because of maintaining high-resolution. Secondly, instead of standard convolution, the asymmetric convolution was introduced to build an asymmetric bottleneck module. The asymmetric bottleneck module has different aspect ratios, and can be used to exact image features of keypoints with multi-scale characteristics and reduce the number of parameters. Thirdly, the waterfall module composed of multiple parallel convolutions were proposed to aggregates features with the same spatial size which can efficiently obtain delicate local representations. It retains rich spatial information and results in precise keypoint localization. Finally, the bottleneck blocks were replaced with asymmetric bottleneck modules in the third subnetwork of LiteHRNet. By which, The waterfall module is embedded into the structure of FastNet. Com-prehensive experiments demonstrate that the proposed method achieves superior results on two benchmark datasets, MSCOCO and MPII. Moreover, FastNet demonstrates superior results on human pose estimation over popular lightweight networks.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Luo, Yanmin; Ou, Zhilong; Wan, Tianjun] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Luo, Yanmin; Ou, Zhilong; Wan, Tianjun] Huaqiao Univ, Xiamen Key Lab Comp Vis & Pattern Recognit, Xiamen 361021, Peoples R China.
   [Guo, Jing-Ming] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
C3 Huaqiao University; Huaqiao University; National Taiwan University of
   Science & Technology
RP Luo, YM (corresponding author), Huaqiao Univ, Xiamen Key Lab Comp Vis & Pattern Recognit, Xiamen 361021, Peoples R China.; Guo, JM (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
EM lym@hqu.edu.cn; 19013083010@stu.hqu.edu.cn; wantj@stu.hqu.edu.cn;
   jmguo@seed.net.tw
OI Ou, Zhilong/0000-0002-8587-1854
FU Natural Science Foundation of Fujian Province, China [2020J01082];
   Science and Technology Bureau of Quanzhou [2018C113R]
FX Acknowledgments This work was supported by Natural Science Foundation of
   Fujian Province, China under grant 2020J01082, and in part by the
   Science and Technology Bureau of Quanzhou under Grant 2018C113R.
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2016, ARXIV160207360
   Bhalgat Y, 2020, IEEE COMPUT SOC CONF, P2978, DOI 10.1109/CVPRW50498.2020.00356
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Cai Y., 2020, COMPUTER VISION ECCV, P455
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chen Y, 2017, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2017.137
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Chou CJ, 2018, ASIAPAC SIGN INFO PR, P17, DOI 10.23919/APSIPA.2018.8659538
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Gkioxari G, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.458
   Han S, 2015, ADV NEUR IN, V28
   Hinton G., 2015, COMPUT SCI, V2
   Howard A. G., 2017, PREPRINT
   Huang JJ, 2020, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR42600.2020.00574
   Ke LP, 2018, LECT NOTES COMPUT SC, V11206, P731, DOI 10.1007/978-3-030-01216-8_44
   Li H., 2017, PRUNING FILTERS EFFI, DOI DOI 10.48550/ARXIV.1608.08710
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Li Z., Proceedings of the IEEE/CVF International Conference on Computer Vision, P11740
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C, 2010, IMAGE VISION COMPUT, V28, P825, DOI 10.1016/j.imavis.2009.07.009
   Luo YM, 2019, IEEE T IMAGE PROCESS, V28, P142, DOI 10.1109/TIP.2018.2865666
   Luvizon DC, 2019, COMPUT GRAPH-UK, V85, P15, DOI 10.1016/j.cag.2019.09.002
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Newell A, 2017, ADV NEUR IN, V30
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Ning GH, 2018, IEEE T MULTIMEDIA, V20, P1246, DOI 10.1109/TMM.2017.2762010
   Ou ZL, 2022, J SUPERCOMPUT, V78, P691, DOI 10.1007/s11227-021-03889-z
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharifi A, 2017, IMAGE VISION COMPUT, V62, P28, DOI 10.1016/j.imavis.2017.03.003
   Shen X., 2021, P 30 INT JOINT C ART, P5012, DOI [10.24963/ijcai/715, DOI 10.24963/IJCAI/715]
   Srinivas S., 2015, P BRIT MACH VIS C 20, DOI DOI 10.5244/C.29.31
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang W, 2018, LECT NOTES COMPUT SC, V11207, P197, DOI 10.1007/978-3-030-01219-9_12
   Tang ZQ, 2018, LECT NOTES COMPUT SC, V11207, P348, DOI 10.1007/978-3-030-01219-9_21
   Wang K, 2019, PROC CVPR IEEE, P11899, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
   Zhang WQ, 2021, COMPUT VIS MEDIA, V7, P335, DOI 10.1007/s41095-021-0214-z
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang ZQ, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104198
NR 46
TC 18
Z9 19
U1 2
U2 39
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104390
DI 10.1016/j.imavis.2022.104390
EA FEB 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400012
DA 2024-07-18
ER

PT J
AU Qayyum, A
   Razzak, I
   Moustafa, N
   Mazher, M
AF Qayyum, Abdul
   Razzak, Imran
   Moustafa, Nour
   Mazher, Moona
TI Progressive ShallowNet for large scale dynamic and spontaneous facial
   behaviour analysis in children
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Psychological health; Human computer interaction; Emotion care;
   Depressed; Facial behavior recognition; Progressive ShallowNet; Patient
   monitoring
ID EXPRESSION RECOGNITION; LITERACY INTERVENTION; IMPACTS
AB COVID-19 has severely disrupted every aspect of society and left negative impact on our life. Resisting the temptation in engaging face-to-face social connection is not as easy as we imagine. Breaking ties within social circle makes us lonely and isolated, that in turns increase the likelihood of depression related disease and even can leads to death by increasing the chance of heart disease. Not only adults, children's are equally impacted where the contribution of emotional competence to social competence has long term implications. Early identification skill for facial behaviour emotions, deficits, and expression may help to prevent the low social functioning. Deficits in young children's ability to differentiate human emotions can leads to social functioning impairment. However, the existing work focus on adult emotions recognition mostly and ignores emotion recognition in children. By considering the working of pyramidal cells in the cerebral cortex, in this paper, we present progressive lightweight shallow learning for the classification by efficiently utilizing the skip-connection for spontaneous facial behaviour recognition in children. Unlike earlier deep neural networks, we limit the alternative path for the gradient at the earlier part of the network by increase gradually with the depth of the network. Progressive ShallowNet is not only able to explore more feature space but also resolve the over -fitting issue for smaller data, due to limiting the residual path locally, making the network vulnerable to perturbations. We have conducted extensive experiments on benchmark facial behaviour analysis in children that showed signifi-cant performance gain comparatively.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Qayyum, Abdul] Dijon Univ, Dept Elect & Comp Engn, Dijon, France.
   [Razzak, Imran] Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia.
   [Moustafa, Nour] Univ New South Wales, Sch Engn & Informat Technol, Canberra, ACT, Australia.
   [Mazher, Moona] Univ Rovira & Virgili, Dept Comp Engn & Math, Tarragona, Spain.
   [Qayyum, Abdul] CNRS, UMR 6285, LabSTICC, ENIB, Brest, France.
C3 Universite de Bourgogne; Deakin University; University of New South
   Wales Sydney; Universitat Rovira i Virgili; Universite de Bretagne
   Occidentale; Centre National de la Recherche Scientifique (CNRS); Ecole
   Nationale d'Ingenieurs de Brest (ENIB)
RP Razzak, I (corresponding author), Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia.
EM imran.razzak@deakin.edu.au
RI Razzak, Imran/AEW-5139-2022; Moustafa, Nour/Z-1160-2018
OI Razzak, Imran/0000-0002-3930-6600; Moustafa, Nour/0000-0001-6127-9349; ,
   Moona/0000-0003-4444-5776
CR Abbasnejad I, 2017, IEEE INT CONF COMP V, P1609, DOI 10.1109/ICCVW.2017.189
   Al Chanti D, 2021, IEEE T AFFECT COMPUT, V12, P363, DOI 10.1109/TAFFC.2018.2873600
   [Anonymous], 2020, BUSINESS INFORM SYST, V389, P434
   Barros P, 2016, ADAPT BEHAV, V24, P373, DOI 10.1177/1059712316664017
   DENHAM SA, 1990, CHILD DEV, V61, P1145, DOI 10.2307/1130882
   DENHAM SA, 1990, CHILD STUDY J, V20, P171
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Jones SM, 2011, CHILD DEV, V82, P533, DOI 10.1111/j.1467-8624.2010.01560.x
   Jones SM, 2010, J CONSULT CLIN PSYCH, V78, P829, DOI 10.1037/a0021383
   Khan RA, 2019, IMAGE VISION COMPUT, V83-84, P61, DOI 10.1016/j.imavis.2019.02.004
   Kim DH, 2019, IEEE T AFFECT COMPUT, V10, P223, DOI 10.1109/TAFFC.2017.2695999
   Lai YH, 2018, IEEE INT CONF AUTOMA, P263, DOI 10.1109/FG.2018.00046
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   McDowell DJ, 2000, MERRILL PALMER QUART, V46, P306
   Rifai S, 2012, LECT NOTES COMPUT SC, V7577, P808, DOI 10.1007/978-3-642-33783-3_58
   Sprung M, 2015, DEV REV, V37, P41, DOI 10.1016/j.dr.2015.05.001
   Vielzeuf V., 2017, P 19 ACM INT C MULT, P569
   Yadan Lv, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P303, DOI 10.1109/SMARTCOMP.2014.7043872
   Yang HY, 2018, IEEE INT CONF AUTOMA, P294, DOI 10.1109/FG.2018.00050
   Zhang FF, 2018, PROC CVPR IEEE, P3359, DOI 10.1109/CVPR.2018.00354
   Zhao JF, 2018, VISUAL COMPUT, V34, P1461, DOI 10.1007/s00371-018-1477-y
NR 23
TC 5
Z9 5
U1 4
U2 40
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104375
DI 10.1016/j.imavis.2022.104375
EA JAN 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400005
PM 35068648
OA Green Published
DA 2024-07-18
ER

PT J
AU Anjomshoae, S
   Omeiza, D
   Jiang, LL
AF Anjomshoae, Sule
   Omeiza, Daniel
   Jiang, Lili
TI Context-based image explanations for deep neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE DNNs; Explainable AI; Contextual importance; Visual explanations
AB With the increased use of machine learning in decision-making scenarios, there has been a growing interest in explaining and understanding the outcomes of machine learning models. Despite this growing interest, existing works on interpretability and explanations have been mostly intended for expert users. Explanations for general users have been neglected in many usable and practical applications (e.g., image tagging, caption generation). It is important for non-technical users to understand features and how they affect an instance-specific prediction to satisfy the need for justification. In this paper, we propose a model-agnostic method for generating context-based explanations aiming for general users. We implement partial masking on segmented components to identify the contextual importance of each segment in scene classification tasks. We then generate explanations based on feature importance. We present visual and text-based explanations: (i) saliency map presents the pertinent components with a descriptive textual justification, (ii) visual map with a color bar graph showing the relative importance of each feature for a prediction. Evaluating the explanations using a user study (N = 50), we observed that our proposed explanation method visually outperformed existing gradient and occlusion based methods. Hence, our proposed explanation method could be deployed to explain models' decisions to non-expert users in real-world applications. (c) 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Anjomshoae, Sule; Jiang, Lili] Umea Univ, Dept Comp Sci, Umea, Sweden.
   [Omeiza, Daniel] Univ Oxford, Dept Comp Sci, Oxford, England.
C3 Umea University; University of Oxford
RP Anjomshoae, S (corresponding author), Umea Univ, Dept Comp Sci, Umea, Sweden.
EM sulea@cs.umu.se; daniel.omeiza@cs.ox.ac.uk; lili.jiang@cs.umu.se
RI Tekkesinoglu, Sule/ABA-1592-2022
OI Tekkesinoglu, Sule/0000-0002-1232-346X
FU EPSRC [EP/S005099/1] Funding Source: UKRI
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Anjomshoae S., 2020, IJCAI PRICAI 2020 WO
   Anjomshoae S, 2021, LECT NOTES ARTIF INT, V12688, P83, DOI 10.1007/978-3-030-82017-6_6
   Anjomshoae S, 2019, LECT NOTES ARTIF INT, V11763, P95, DOI 10.1007/978-3-030-30391-4_6
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Biran O., 2014, P AUTOML WORKSHOP IC, V2014, P1
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Buhrmester, 2019, ARXIV191112116, P1
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.32
   Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786
   Framling K., 1996, THESIS
   Hendricks LA, 2016, LECT NOTES COMPUT SC, V9908, P3, DOI 10.1007/978-3-319-46493-0_1
   Hohman F., 2019, ARXIV190402323
   Lei T, 2019, IEEE T IMAGE PROCESS, V28, P5510, DOI 10.1109/TIP.2019.2920514
   Li O, 2018, AAAI CONF ARTIF INTE, P3530
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Mahendran A, 2016, INT J COMPUT VISION, V120, P233, DOI 10.1007/s11263-016-0911-8
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Nguyen A., 2016, Advances in Neural Information Processing Systems, P3387
   Omeiza D., 2019, ABS190801224 CORR
   Omeiza D, 2022, IEEE T INTELL TRANSP, V23, P10142, DOI 10.1109/TITS.2021.3122865
   Park DH, 2018, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2018.00915
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Simonyan Karen, 2014, WORKSH P INT C LEARN
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 34
TC 7
Z9 7
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104310
DI 10.1016/j.imavis.2021.104310
EA SEP 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WL9GT
UT WOS:000710706800003
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Yaghoubi, E
   Borza, D
   Degardin, B
   Proença, H
AF Yaghoubi, Ehsan
   Borza, Diana
   Degardin, Bruno
   Proenca, Hugo
TI You look so different! Haven't I seen you a long time ago?
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cloth-changing personre-identification; Long-term embedding; Biometric
   recognition; Visual surveillance; Identity feature extraction; Soft
   biometric analysis
AB Person re-identification (re-id) aims to match a query identity (ID) to an element in a gallery set, composed of elements collected from multiple cameras. Most of the existing re-id methods assume the short-term setting, where the query/gallery samples share the clothing style. In this setting, the optimal feature representations are based in the visual appearance of clothes, which considerably drops the identification performance for long-term settings. Having this problem in mind, we propose a model that learns long-term representations of persons by ignoring any features previously learned by a short-term re-id model, which naturally makes it invari-ant to clothing styles. We start by synthesizing a data set in which we distort the most relevant biometric infor-mation (based in face, body shape, height, and weight cues), keeping the short-term cues (color and texture of clothes) unchanged. This way, while the original data contains both ID-related and other varying features, the synthesized representations are composed mostly of short-term attributes. Then, the key to obtaining stable long-term representations is to learn embeddings of the original data that maximize the dissimilarity with the previously inferred short-term embeddings. In practice, we use the synthetic data to learn a model that embeds the ID-unrelated features and then learn a second model from the original data, where long-term embeddings are obtained, keeping their independence with respect to the previously obtained ID-unrelated features. Our exper-iments were performed on three challenging cloth-changing sets (LTCC, PRCC, and NKUP) and the results support the effectiveness of the proposed method, for both short and long-term re-id settings. The source code is available at https://github.com/Ehsan-Yaghoubi/You-Look-So-Different-Haven-t-I-Seen-You-a-Long-Time-Ago? (c) 2021 Elsevier B.V. All rights reserved.
C1 [Yaghoubi, Ehsan; Degardin, Bruno; Proenca, Hugo] Univ Beira Interior, Covilha, Portugal.
   [Borza, Diana] Babes Boylai Univ, Cluj Napoca, Romania.
   [Degardin, Bruno; Proenca, Hugo] IT Inst Telecomunicacoes, Covilha, Portugal.
C3 Universidade da Beira Interior; Babes Bolyai University from Cluj
RP Yaghoubi, E (corresponding author), Univ Beira Interior, Covilha, Portugal.
EM Ehsan.Yaghoubi@ubi.pt
RI Proença, Hugo/F-9499-2010; Borza, Diana Laura/W-7283-2019
OI Proença, Hugo/0000-0003-2551-8570; Degardin, Bruno/0000-0003-2462-7310
FU FCT/MEC [UIDB/50008/2020, POCI-01-0247-FEDER-033395]; FEDER-PT2020
   Partnership Agreement [UIDB/50008/2020, POCI-01-0247-FEDER-033395];
   Centro de Competencias em Cloud Computing
   [Centro-01-0145-FEDER-000019-C4]; European Regional Development Fund
   (ERDF) through the Programa Operacional Regional do Centro (Centro
   2020); FCT-Fundacao para a Ciencia e Tecnologia [UI/BD/150765/2020];
   Fundação para a Ciência e a Tecnologia [UI/BD/150765/2020] Funding
   Source: FCT
FX This work was supported in part by the FCT/MEC through National Funds
   and Co-Funded by the FEDER-PT2020 Partnership Agreement under Project
   UIDB/50008/2020, Project POCI-01-0247-FEDER-033395 and in part by
   operation Centro-01-0145-FEDER-000019-C4-Centro de Competencias em Cloud
   Computing, co-funded by the European Regional Development Fund (ERDF)
   through the Programa Operacional Regional do Centro (Centro 2020) , in
   the scope of the Sistema de Apoio a InvestigacAo Cientifica e
   Tecnologica-Programas Integrados de IC&DT. This research was also
   supported by 'FCT-Fundacao para a Ciencia e Tecnologia' through the
   research grant 'UI/BD/150765/2020'.
CR Almasawa MO, 2019, IEEE ACCESS, V7, P175228, DOI 10.1109/ACCESS.2019.2957336
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dietlmeier J, 2021, INT C PATT RECOG, P6912, DOI 10.1109/ICPR48806.2021.9412340
   Fangbin Wan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P3620, DOI 10.1109/CVPRW50498.2020.00423
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hong PX, 2021, PROC CVPR IEEE, P10508, DOI 10.1109/CVPR46437.2021.01037
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jin X., ARXIV PREPRINT ARXIV, V2021
   Ke Ma, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P4700, DOI 10.1109/CVPR.2018.00494
   Kingma D. P., 2014, arXiv
   Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453
   Lavi B, 2020, ARXIV PREPRINT ARXIV
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li Y, 2020, ARXIV PREPRINT ARXIV
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Qian X., 2020, P AS C COMP VIS
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Qian XL, 2020, IEEE T PATTERN ANAL, V42, P371, DOI 10.1109/TPAMI.2019.2928294
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shu XJ, 2021, IEEE SIGNAL PROC LET, V28, P1365, DOI 10.1109/LSP.2021.3091924
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang K, 2020, INT J INTELL SYST, V35, P1881, DOI 10.1002/int.22276
   Xiu Y., 2018, BMVC
   Xue J, 2018, IEEE COMPUT SOC CONF, P2193, DOI 10.1109/CVPRW.2018.00285
   Yaghoubi E, 2021, PATTERN RECOGN LETT, V143, P50, DOI 10.1016/j.patrec.2020.12.017
   Yang QZ, 2021, IEEE T PATTERN ANAL, V43, P2029, DOI 10.1109/TPAMI.2019.2960509
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yi Z., 2020, CVPR, P7508
   Yu ZT, 2020, IEEE SIGNAL PROC LET, V27, P1245, DOI 10.1109/LSP.2020.3007086
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang P, 2018, IEEE WINT CONF APPL, P494, DOI 10.1109/WACV.2018.00060
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 43
TC 6
Z9 8
U1 2
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104288
DI 10.1016/j.imavis.2021.104288
EA SEP 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WC6NH
UT WOS:000704372400004
DA 2024-07-18
ER

PT J
AU Pino, OV
   Nascimento, ER
   Campos, MFM
AF Pino, Omar Vidal
   Nascimento, Erickson R.
   Campos, Mario F. M.
TI Introducing the structural bases of typicality effects in deep learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Typicality effects; Category semantic representation; Image semantic
   representation; Semantic classification; Global features description;
   Prototype theory
ID PROTOTYPE; CLASSIFICATION; ACCOUNTS; SCALE
AB In this paper, we hypothesize that the effects of the degree of typicality in natural semantic categories can be gen-erated based on the structure of artificial categories learned with deep learning models. Motivated by the human approach to representing natural semantic categories and based on the Prototype Theory foundations, we pro -pose a novel Computational Prototype Model (CPM) to represent the internal structure of semantic categories. Unlike other prototype learning approaches, our mathematical framework proposes a first approach to provide deep neural networks with the ability to model abstract semantic concepts such as category central semantic meaning, typicality degree of an object's image, and family resemblance relationship. We proposed several meth-odologies based on the typicality's concept to evaluate our CPM-model in image semantic processing tasks such as image classification, a global semantic description, and transfer learning. Our experiments on different image datasets, such as ImageNet and Coco, showed that our approach might be an admissible proposition in the effort to endow machines with greater power of abstraction for the semantic representation of objects' categories. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Pino, Omar Vidal; Nascimento, Erickson R.; Campos, Mario F. M.] Univ Fed Minas Gerais, Comp Sci Dept, Comp Vis & Robot Lab, BR-31270010 Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Minas Gerais
RP Pino, OV (corresponding author), Univ Fed Minas Gerais, Comp Sci Dept, Comp Vis & Robot Lab, BR-31270010 Belo Horizonte, MG, Brazil.
EM ovidalp@dcc.ufmg.br; erickson@dcc.ufmg.br; mario@dcc.ufmg.br
RI Campos, Mario F. M./C-4647-2013
OI Vidal Pino, Omar/0000-0002-9917-3838
FU CAPES; CNPq; FAPEMIG
FX This research was supported by funding from the Brazilian agencies
   CAPES, CNPq, and FAPEMIG.
CR Allen K., P INT C MACH LEARN I, P232
   Angelov P, 2020, NEURAL NETWORKS, V130, P185, DOI 10.1016/j.neunet.2020.07.010
   [Anonymous], P 10 IEEE INT C WORK
   [Anonymous], 2015, P 37 ANN C COGN SCI
   Atkinson R. C., 1968, Psychology of learning and motivation, V2, P89, DOI [10.1016/S0079-7421(08)60422-3, DOI 10.1016/S0079-7421(08)60422-3, DOI 10.1017/CBO9781316422250.025]
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Cichy RM, 2017, NEUROIMAGE, V153, P346, DOI 10.1016/j.neuroimage.2016.03.063
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong N., 2018, BMVC, V4, P4
   Drumond T., 2017, ANN C NEUR INF PROC
   Fort S, 2018, GAUSSIAN PROTOTYPICA
   Garnot V.S.F., LEVERAGING CLASS HIE
   Geeraerts Dirk, 2010, THEORIES LEXICAL SEM
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HOMA D, 1976, J EXP PSYCHOL-HUM L, V2, P322, DOI 10.1037/0278-7393.2.3.322
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jetley Saumya, 2015, BMVC
   Khaligh-Razavi SM, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003915
   Kohonen T., 1997, Self-Organizing Maps, P203
   Krizhevsky A., Convolutional deep belief networks on cifar- 10. 2010
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li L, 2020, PROC CVPR IEEE, P1916, DOI 10.1109/CVPR42600.2020.00199
   Li MJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P508
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037/0033-295X.85.3.207
   Minda JP, 2002, J EXP PSYCHOL LEARN, V28, P275, DOI 10.1037//0278-7393.28.2.275
   Netto CGCM, 2015, NEW J CHEM, V39, P2162, DOI 10.1039/c4nj01716a
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojeda-Magaña B, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/716753
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oyedotun OK, 2018, IEEE T NEUR NET LEAR, V29, P3560, DOI 10.1109/TNNLS.2017.2730179
   Pino OV, 2019, IEEE WINT CONF APPL, P1233, DOI 10.1109/WACV.2019.00136
   ROSCH E, 1976, J EXP PSYCHOL HUMAN, V2, P491, DOI 10.1037/0096-1523.2.4.491
   ROSCH E, 1975, J EXP PSYCHOL GEN, V104, P192, DOI 10.1037/0096-3445.104.3.192
   ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9
   Rosch E., 1978, COGNITION CATEGORIZA, P27, DOI DOI 10.1016/B978-1-4832-1446-7.50028-5
   Rosch Eleanor, 1973, Cognitive Development and the Acquisition of Language, P111
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saleh B., 2016, INT JOINT C ART INT, P3446
   Saleh B, 2013, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2013.107
   Seo S, 2003, NEURAL COMPUT, V15, P1589, DOI 10.1162/089976603321891819
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snell J, 2017, ADV NEUR IN, V30
   Stellato B, 2017, AM STAT, V71, P123, DOI 10.1080/00031305.2016.1186559
   Tulving E., 2007, Coding and Representation: Searching for a Home in the Brain, P65
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wohlhart P, 2013, PROC CVPR IEEE, P460, DOI 10.1109/CVPR.2013.66
   Xiao M., 2020, ECCV 2020 WORKSH VIS
   Yang HM, 2018, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2018.00366
   Yang JW, 2016, PROC CVPR IEEE, P5147, DOI 10.1109/CVPR.2016.556
   Yee E., 2018, Stevens Handb. Exp. Psychol. Cogn. Neurosci, V3, P1
   Young-jun Song, 2004, Proceedings of 2004 International Symposium on Intelligent Signal Processing And Communication Systems ISPACS 2004 (IEEE Cat. No.04EX910), P609, DOI 10.1109/ISPACS.2004.1439129
   Zaki SR, 2003, J EXP PSYCHOL LEARN, V29, P1160, DOI 10.1037/0278-7393.29.6.1160
   Zhao HQ, 2015, LECT NOTES ARTIF INT, V9376, P236, DOI 10.1007/978-3-319-25135-6_23
NR 59
TC 0
Z9 0
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104249
DI 10.1016/j.imavis.2021.104249
EA JUL 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Schrom, S
   Hasler, S
   Adamy, J
AF Schrom, Sebastian
   Hasler, Stephan
   Adamy, Juergen
TI Improved multi-source domain adaptation by preservation of factors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Domain adaptation; Multi-source domain adaptation; Adversarial domain
   adaptation; Negative transfer; Visual factors; Domain factors
AB Domain Adaptation (DA) is a highly relevant research topic when it comes to image classification with deep neural networks. Combining multiple source domains in a sophisticated way to optimize a classification model can improve the generalization to a target domain. Here, the difference in data distributions of source and target image datasets plays a major role. In this paper, we describe based on a theory of visual factors how real-world scenes appear in images in general and how recent DA datasets are composed of such. We show that different domains can be described by a set of so called domain factors, whose values are consistent within a domain, but can change across domains. Many DA approaches try to remove all domain factors from the feature representation to be domain invariant. In this paper we show that this can lead to negative transfer since task-informative factors can get lost as well. To address this, we propose Factor-Preserving DA (FP-DA), a method to train a deep adversarial unsupervised DA model, which is able to preserve specific task relevant factors in a multi-domain scenario. We demonstrate on CORe50 how such factors can be identified by standard one-to-one transfer experiments between single domains combined with PCA. By applying FP-DA, we show that the highest average and minimum performance can be achieved. We also report improved performance for an adapted version of the OpenLORIS object dataset. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Schrom, Sebastian; Adamy, Juergen] Tech Univ Darmstadt, Control Methods & Robot Lab, D-64283 Darmstadt, Germany.
   [Hasler, Stephan] Honda Res Inst Europe, Carl Legien Str 30, D-63065 Offenbach, Germany.
C3 Technical University of Darmstadt; Honda Motor Company
RP Schrom, S (corresponding author), Tech Univ Darmstadt, Control Methods & Robot Lab, D-64283 Darmstadt, Germany.
EM sebastian.schrom@rmr.tu-darmstadt.de
CR Ajakan H., 2014, ARXIV14124446
   Bergamo Alessandro, 2010, ADV NEURAL INFORM PR, V23
   Bousmalis K, 2016, ADV NEUR IN, V29
   Cao ZJ, 2019, PROC CVPR IEEE, P2980, DOI 10.1109/CVPR.2019.00310
   Csurka G, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-58347-1_1
   de Vries T., 2019, P IEEECVF C COMPUTER, P52
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004
   Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819
   Ganin Y., 2015, ICML
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ge L, 2014, STAT ANAL DATA MIN, V7, P254, DOI 10.1002/sam.11217
   Gong B., 2013, NIPS, P1286
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Griffin G., 2007, CALTECH 256 OBJECT C
   Guo J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4694
   Hoffman J, 2012, LECT NOTES COMPUT SC, V7573, P702, DOI 10.1007/978-3-642-33709-3_50
   Hu LQ, 2020, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR42600.2020.00410
   Jiang X., P MACH LEARN RES PML, V119, P4816
   Karimpour M, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01093-2
   Koniusz P, 2018, LECT NOTES COMPUT SC, V11220, P815, DOI 10.1007/978-3-030-01270-0_48
   Kouw W. M., 2018, ARXIV181211806
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591
   Li Yitong, 2018, Adv Neural Inf Process Syst, V31, P6799
   Liang J, 2019, PROC CVPR IEEE, P2970, DOI 10.1109/CVPR.2019.00309
   Locatello F., P MACH LEARN RES 201, V97, P4114
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Maltoni D., P MACH LEARN RES PML, V78, P17
   Mancini M, 2018, PROC CVPR IEEE, P3771, DOI 10.1109/CVPR.2018.00397
   Mansour Yishay, 2008, Advances in neural information processing systems, V21, P1041
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan YW, 2019, PROC CVPR IEEE, P2234, DOI 10.1109/CVPR.2019.00234
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Peng X., ABS180609755 CORR
   Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149
   Peng XC, 2015, IEEE I CONF COMP VIS, P1278, DOI 10.1109/ICCV.2015.151
   Rakshit S, 2019, LECT NOTES COMPUT SC, V11824, P485, DOI 10.1007/978-3-030-33676-9_34
   Redko I, 2019, PR MACH LEARN RES, V89, P849
   Rosenstein M.T., 2005, NIPS 2005 workshop on transfer learning, P1
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Schrom Sebastian, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P22, DOI 10.1109/ICMLA.2019.00013
   Schrom S., 2017, MACHINE LEARNING REP
   Schutera M, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104079
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shankar S., 2017, ABS171108536 CORR
   She Q., INT C ROB AUT ICRA, P4767
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tommasi T., 2012, THESIS ECOLE POLYTEC
   TORRALBA A, 2011, PROC CVPR IEEE, P1521, DOI DOI 10.1109/CVPR.2011.5995347
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Wang HT, 2019, IEEE DATA MINING, P1372, DOI 10.1109/ICDM.2019.00176
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wen J., 2020, PMLR, V119, P10214
   Xie SA, 2018, PR MACH LEARN RES, V80
   Xiong CM, 2014, AAAI CONF ARTIF INTE, P2860
   Xu RJ, 2018, PROC CVPR IEEE, P3964, DOI 10.1109/CVPR.2018.00417
   Zhang Y, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103974
   Zhao SC, 2020, AAAI CONF ARTIF INTE, V34, P12975
   Zhou Q, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104137
NR 67
TC 1
Z9 1
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104209
DI 10.1016/j.imavis.2021.104209
EA JUN 2021
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, GQ
   Wu, JZ
AF Liu, Guiqing
   Wu, Jinzhao
TI Video-based person re-identification by intra-frame and inter-frame
   graph neural network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Graph neural network; Intra and inter frame;
   Body part; Video matching
AB In the past few years, video-based person re-identification (Re-ID) have attracted growing research attention. The crucial problem for this task is how to learn robust video feature representation, which can weaken the influence of factors such as occlusion, illumination, and background etc. A great deal of previous works utilize spatio-temporal information to represent pedestrian video, but the correlations between parts of human body are ignored. In order to take advantage of the relationship among different parts, we propose a novel Intraframe and Inter-frame Graph Neural Network (I2GNN) to solve the video-based person Re-ID task. Specifically, (1) the features from each part are treated as graph nodes from each frame; (2) the intra-frame edges are established by the correlation between different parts; (3) the inter-frame edges are constructed between the same parts across adjacent frames. I2GNN learns video representations by employing the adjacent matrix of the graph and input features to conduct graph convolution, and then adopts projection metric learning on Grassman manifold to measure the similarities between learned pedestrian features. Moreover, this paper proposes a novel occlusion-invariant term to make the part features close to their center, which can relive several uncontrolled complicated factors, such as occlusion and pose invariance. Besides, we have carried out extensive experiments on four widely used datasets: MARS, DukeMTMC-VideoReID, PRID2011, and iLIDS-VID. The experimental results demonstrate that our proposed I2GNN model is more competitive than other state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Liu, Guiqing; Wu, Jinzhao] Chinese Acad Sci, Chengdu Inst Comp Applicat, Chengdu 610041, Sichuan, Peoples R China.
   [Liu, Guiqing] Guangxi Univ Nationalities, Coll ASEAN Studies, Nanning 530006, Peoples R China.
   [Wu, Jinzhao] Guangxi Univ, Coll Math & Informat Sci, Nanning 530004, Peoples R China.
   [Liu, Guiqing; Wu, Jinzhao] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Chengdu Institute of Computer Application,
   CAS; Guangxi Minzu University; Guangxi University; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Wu, JZ (corresponding author), Chinese Acad Sci, Chengdu Inst Comp Applicat, Chengdu 610041, Sichuan, Peoples R China.
EM wuasean@163.com
FU National Natural Science Foundation of China [61772006]; Science and
   Technology Major Project of Guangxi Research and Application
   Demonstration of Key Technologies for Intelligent Ship Networking in
   Beibu Gulf [AA17204096]; Key Research and Development Project of Guangxi
   DPA-proof full asynchronous RSA security crypto chip: design methods,
   tools and prototypes [AB17129012]; Special Fund for Bagui Scholars of
   Guangxi Control system design and verification (2017); Promotion Project
   of BasicFaculties forYoung and Middle-aged College Teachers in Guangxi
   Common Sense Dynamic Logic Reasoning and Its Application [2018KY0164]
FX This research has been financed by the National Natural Science
   Foundation of China Error analysis and control of semi-algebraic model
   detection method (61772006), the Science and Technology Major Project of
   Guangxi Research and Application Demonstration of Key Technologies for
   Intelligent Ship Networking in Beibu Gulf (AA17204096), the Key Research
   and Development Project of Guangxi DPA-proof full asynchronous RSA
   security crypto chip: design methods, tools and prototypes (AB17129012),
   the Special Fund for Bagui Scholars of Guangxi Control system design and
   verification (2017), and the Promotion Project of BasicFaculties
   forYoung and Middle-aged College Teachers in Guangxi Common Sense
   Dynamic Logic Reasoning and Its Application (2018KY0164).
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], ABS200308177CORR
   Barman A, 2017, IEEE I CONF COMP VIS, P1124, DOI 10.1109/ICCV.2017.127
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902
   Chen Y.C., P IEEE CVF C COMP VI, P3289
   Chen Z., ABS200312224 CORR
   Cheng DC, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-26
   Cheng D, 2018, PATTERN RECOGN, V82, P94, DOI 10.1016/j.patcog.2018.05.007
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   Jiang XQ, 2018, AEROSP CONF PROC
   Kipf TN, 2017, INT C LEARN REPR
   Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu YH, 2019, AAAI CONF ARTIF INTE, P8786
   Luo B., ABS190708822 CORR
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Paisitkriangkrai S., ABS150301543 CORR
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tian Q., 2016, COMP VIS ECCV 2016 1
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550
   Zhang RM, 2019, IEEE T IMAGE PROCESS, V28, P4870, DOI 10.1109/TIP.2019.2911488
   Zhang S., ABS190810049 CORR
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
NR 49
TC 6
Z9 6
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104068
DI 10.1016/j.imavis.2020.104068
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700012
DA 2024-07-18
ER

PT J
AU Yang, F
   Chang, X
   Sakti, S
   Wu, Y
   Nakamura, S
AF Yang, Fan
   Chang, Xin
   Sakti, Sakriani
   Wu, Yang
   Nakamura, Satoshi
TI ReMOT: A model-agnostic refinement for multiple object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiple object tracking; refinement
ID ONLINE
AB Although refinement is commonly used in visual tasks to improve pre-obtained results, it has not been studied for Multiple Object Tracking (MOT) tasks. This could be attributed to two reasons: i) it has not been explored what kinds of errors should - and could - be reduced in MOT refinement; ii) the refinement target, namely, the tracklets, are intertwined and interactive in a 3D spatio-temporal space, and therefore changing one tracklet may affect the others. To tackle these issues, i) we define two types of errors in imperfect tracklets, as Mix-up Error and Cut-off Error, to clarify the refinement goal; ii) we propose a Refining MOT Framework (ReMOT), which first splits imperfect tracklets and then merges the split tracklets with appearance features improved by self-supervised learning. Experiments demonstrate that ReMOT can make significant improvements to state-of-the-art MOT results as powerful post-processing. As a new application, we demonstrate that ReMOT has the potential of being used to assist semi-automatic MOT data annotation and partially release humans from the tedious work. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Yang, Fan; Chang, Xin; Sakti, Sakriani; Nakamura, Satoshi] Nara Inst Sci & Technol, Ikoma, Nara, Japan.
   [Yang, Fan; Sakti, Sakriani; Nakamura, Satoshi] RIKEN, Ctr Adv Intelligence Project AIP, Tokyo, Japan.
   [Wu, Yang] Kyoto Univ, Kyoto, Japan.
C3 Nara Institute of Science & Technology; RIKEN; Kyoto University
RP Yang, F (corresponding author), Nara Inst Sci & Technol, Ikoma, Nara, Japan.; Yang, F (corresponding author), RIKEN, Ctr Adv Intelligence Project AIP, Tokyo, Japan.; Wu, Y (corresponding author), Kyoto Univ, Kyoto, Japan.
EM hongheyangfan@gmail.com; chang.xin.co0@is.naist.jp; ssakti@is.naist.jp;
   wu.yang.8c@kyoto-u.ac.jp; s-nakamura@is.naist.jp
OI Yang, Fan/0000-0001-7185-5688
FU JSPS KAKENHI [JP17H06101]; MSRA Collaborative Research 2019 Grant -
   Microsoft Research Asia
FX This work was supported by JSPS KAKENHI Grant Number JP17H06101, and a
   MSRA Collaborative Research 2019 Grant Awarded by Microsoft Research
   Asia.
CR Andriluka M, 2018, PROC CVPR IEEE, P5167, DOI 10.1109/CVPR.2018.00542
   [Anonymous], 2019, CVPR
   [Anonymous], 2014, ARXIV14097618
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Betke M, 2007, PROC CVPR IEEE, P192
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chen Z, 2018, LECT NOTES COMPUT SC, V11212, P74, DOI 10.1007/978-3-030-01237-3_5
   Dubuisson S, 2006, IEEE IMAGE PROC, P2805, DOI 10.1109/ICIP.2006.312991
   Fu KR, 2019, IEEE T MULTIMEDIA, V21, P457, DOI 10.1109/TMM.2018.2859746
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jinlong Peng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P145, DOI 10.1007/978-3-030-58548-8_9
   Kingma D. P., 2014, arXiv
   Klein M., 1967, Management Science, V14, P205
   Koller D., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P189
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kuma R., 2019, 2019 INT JOINT C NEU, P1
   Leal-Taixe L., 2015, MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li YS, 2019, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR.2019.00710
   Lu WL, 2013, IEEE T PATTERN ANAL, V35, P1704, DOI 10.1109/TPAMI.2012.242
   Luo H., 2019, ROC IEEE C COMP VIS
   Milan A., 2016, ARXIV160300831
   Moon G, 2019, PROC CVPR IEEE, P7765, DOI 10.1109/CVPR.2019.00796
   Pang B, 2020, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR42600.2020.00634
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Segen J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P63, DOI 10.1109/ICPR.1996.546795
   SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Tang S., 2016, ECCV WORKSH BENCHM M
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Weng XS, 2020, IEEE INT C INT ROBOT, P10359, DOI 10.1109/IROS45743.2020.9341164
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu GL, 2020, AAAI CONF ARTIF INTE, V34, P12362
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xin Li, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P1862, DOI 10.1109/ICINFA.2010.5512258
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Yang F, 2020, INT CONF ACOUST SPEE, P1863, DOI [10.1109/ICASSP40776.2020.9053497, 10.1109/icassp40776.2020.9053497]
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742
   Zhang S, 2015, PATTERN RECOGN, V48, P580, DOI 10.1016/j.patcog.2014.08.013
   Zhang YH, 2020, IEEE INT CONF AUTOMA, P356, DOI 10.1109/FG47880.2020.00134
NR 45
TC 43
Z9 45
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104091
DI 10.1016/j.imavis.2020.104091
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700004
DA 2024-07-18
ER

PT J
AU Sang, HW
   Zhou, QH
   Zhao, Y
AF Sang, Haiwei
   Zhou, Qiuhao
   Zhao, Yong
TI PCANet: Pyramid convolutional attention network for semantic
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Non-local module; Atrous convolution; Attention mechanism; Semantic
   segmentation
AB Pyramid Convolutional Attention Network is proposed to efficiently capture long-range dependency and fuse features from different levels for benefitting semantic segmentation problems. In this paper, we focus on how to extractmore representative features for segmentation object recognition and design a decoder to recover details in a more efficient way. Inspired by atrous sampling and attention mechanism, we propose Pyramid Atrous Attention module to capture long-range dependency for learning richer contextual features. We also find that features of different levels have diverse representation so we design Convolutional Attention Refinementmodule to provide global context for low-level features and local details for high-level features. By combining with these two efficient module, we construct our Pyramid Convolutional Attention Network (PCANet), which achieves state-of-the-art results on Pascal VOC 2012 and Cityscapes benchmark. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Sang, Haiwei] Guizhou Educ Univ, Sch Math & Big Data, Guiyang 550018, Peoples R China.
   [Sang, Haiwei] Guizhou Univ, Coll Comp Sci & Technol, Guiyang 550025, Peoples R China.
   [Zhou, Qiuhao; Zhao, Yong] Peking Univ, Sch Elect & Comp Engn, Shenzhen Grad Sch, Shenzhen 518055, Guangdong, Peoples R China.
C3 Guizhou Education University; Guizhou University; Peking University
RP Zhao, Y (corresponding author), Peking Univ, Sch Elect & Comp Engn, Shenzhen Grad Sch, Shenzhen 518055, Guangdong, Peoples R China.
EM zhouqiuhao@pku.edu.cn; yonwgzhao@pku.edu.cn
FU Key Disciplines of Guizhou Province Computer Science and Technology
   [ZDXK [2018]007]; Key Supported Disciplines of Guizhou Province Computer
   Application Technology [QianXueWeiHeZi ZDXK[2016]20]; Specialized Fund
   for Science and Technology Platform and Talent Team Project of Guizhou
   Province [QianKeHePingTaiRenCai [2016]5609]; Major Research Projects of
   Innovation Group of Guizhou Provincial Department of Education
   [QianJiaoHeKY [2016]040]
FX This work was supported by the Key Disciplines of Guizhou Province
   Computer Science and Technology (ZDXK [2018]007, the Key Supported
   Disciplines of Guizhou Province Computer Application Technology
   (No.QianXueWeiHeZi ZDXK[2016]20), Specialized Fund for Science and
   Technology Platform and Talent Team Project of Guizhou Province
   (No.QianKeHePingTaiRenCai [2016]5609) and the Major Research Projects of
   Innovation Group of Guizhou Provincial Department of Education
   (No.QianJiaoHeKY [2016]040).
CR [Anonymous], ARXIV150604579
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen Chen L. C. L. C., ARXIV170605587
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li H., ARXIV180510180
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo WJ, 2016, ADV NEUR IN, V29
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen FL, 2017, PROC CVPR IEEE, P5178, DOI 10.1109/CVPR.2017.550
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Toldo M, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103889
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Zhang C, 2019, IEEE I CONF COMP VIS, P9586, DOI 10.1109/ICCV.2019.00968
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang ZY, 2018, SUSTAIN CIV INFRASTR, P269, DOI 10.1007/978-3-319-61612-4_22
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 39
TC 23
Z9 28
U1 7
U2 54
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 103997
DI 10.1016/j.imavis.2020.103997
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000007
OA hybrid
DA 2024-07-18
ER

PT J
AU Mathew, A
   Mathew, J
AF Mathew, Alwyn
   Mathew, Jimson
TI Monocular depth estimation with SPN loss
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth estimation; Monocular depth estimation
AB Understanding the 3D space is crucial for autonomous vehicles for planning and navigation. Traditionally autonomous vehicles use LiDAR sensor to 3D map its environment. LiDAR sensor data are often noisy and sparse making it not fully reliable for real-time applications like autonomous driving, thus redundant such sensors are used for the purpose. The array of cameras in an autonomous vehide purposed for detection and tracking can be reused for depth estimation as well. In this paper, an unsupervised monocular depth estimation approach for autonomous vehicles which can be used as redundant depth estimators replacing multiple LiDAR sensors. Here, a deep learning based method is used with a multiscale encoder-decoder network to estimate depth. Target view among the stereo pairs is reconstructed by inverse warping the source view using geometric camera projection. The network is guided by the stereo positive-negative(SPN) loss which minimizes the loss between reconstructed view and corresponding stereo ground truth and, also maximizes the loss between reconstructed views and corresponding opposite stereo ground truth. The proposed approach shows state of the art accuracy in autonomous driving dataset KITTI. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Mathew, Alwyn; Mathew, Jimson] Indian Inst Technol Patna, Bihta, India.
C3 Indian Institute of Technology (IIT) - Patna
RP Mathew, A (corresponding author), Indian Inst Technol Patna, Bihta, India.
EM alwyn.pcs16@iitp.ac.in; jimson@iitp.ac.in
CR [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   Chen Weifeng, 2016, ADV NEURAL INFORM PR, V29, P730, DOI DOI 10.5555/3157096.3157178
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Eigen D., 2014, NIPS, DOI DOI 10.5555/2969033.2969091
   Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Gidaris S., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P5248
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Hamzah RA, 2016, J SENSORS, V2016, DOI 10.1155/2016/8742920
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Howard J, 2012, FEW HONEST WORDS: THE KENTUCKY ROOTS OF POPULAR MUSIC, P1
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56
   Kendall Alex., CoRR
   Kingma D. P., 2014, arXiv
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Liu MM, 2014, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2014.97
   LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   MENZE M, 2015, PROC CVPR IEEE, P3061, DOI DOI 10.1109/CVPR.2015.7298925
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saran R, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P300, DOI 10.1109/PDGC.2018.8745829
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Shaked A., CORR, Vabs/1701.00165.
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 39
TC 3
Z9 4
U1 2
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2020
VL 100
AR 103934
DI 10.1016/j.imavis.2020.103934
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA MY9GX
UT WOS:000558728800004
DA 2024-07-18
ER

PT J
AU Dahmani, D
   Cheref, M
   Larabi, S
AF Dahmani, Djamila
   Cheref, Mehdi
   Larabi, Slimane
TI Zero-sum game theory model for segmenting skin regions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Skin detection; Color; Texture; Zero-sum game; Nash Equilibrium
ID CLASSIFICATION; IMAGES
AB This paper presents a new method for skin region segmentation based on a zero-sum game theory model which exploits the opposite classifications of an image region by different skin detectors. In fact, these regions are considered conflict areas between two players (skin and non-skin) and skin detectors are considered strategies. An appropriate utility function is then defined. The computation of the saddle point (The Nash equilibrium) in the mixed extension of the proposed zero-sum game allows classifying effectively the conflict areas and so reducing the false positive skin detection. Experiments were conducted on three publicaily available databases using four selected skin detectors based on skin color information, skin-texture cues and employ rule-based or neural networks. The results show that the proposed method outperforms the existing skin segmentation approaches in reducing the false positive rates and obtains promising results in the skin segmentation performance. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Dahmani, Djamila; Cheref, Mehdi; Larabi, Slimane] Univ Sci & Technol Houari Boumediene USTHB, Comp Sci Dept, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Dahmani, D (corresponding author), Univ Sci & Technol Houari Boumediene USTHB, Comp Sci Dept, Algiers, Algeria.
EM ddahmani@usthb.dz; mehdi.cheref@etu.usthb.dz; slarabi@usthb.dz
RI Larabi, Slimane/AAD-7871-2020
OI larabi, slimane/0000-0001-8994-5980
CR [Anonymous], 1998, AR FACE DATABASE
   [Anonymous], 2007, ALGORITHMIC GAME THE
   Baldi A., 2014, SKIN CANC, P523
   Bilal S, 2015, J REAL-TIME IMAGE PR, V10, P371, DOI 10.1007/s11554-012-0305-2
   Brancati N, 2017, COMPUT VIS IMAGE UND, V155, P33, DOI 10.1016/j.cviu.2016.12.001
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Chen MJ, 2003, IEEE T CONSUM ELECTR, V49, P724, DOI 10.1109/TCE.2003.1233810
   Chen YH, 2012, ENG APPL ARTIF INTEL, V25, P1331, DOI 10.1016/j.engappai.2012.02.019
   Daxiang L., 2013, INT J COMPUT SCI, V10
   Dumitrescu CM, 2013, ADV INTELL SYST, V187, P59
   Feldmann-Wüstefeld T, 2014, VISION RES, V97, P108, DOI 10.1016/j.visres.2014.02.008
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Huang Shih-Miao, 2011, Proceedings of the 2011 International Conference on User Science and Engineering (i-USEr 2011), P1, DOI 10.1109/iUSEr.2011.6150526
   Intawong K., 2013, NEW PIXEL BASED QUAL, P188
   Jiang ZW, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P366, DOI 10.1109/FSKD.2007.518
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kallel M, 2014, APPL MATH MODEL, V38, P3038, DOI 10.1016/j.apm.2013.11.034
   Kawulok M., 2014, Advances in Low-Level Color Image Processing. Lecture Notes in Computational Vision and Biomechanics, V11, P329
   Kawulok M, 2008, LECT NOTES COMPUT SC, V5099, P112, DOI 10.1007/978-3-540-69905-7_13
   Kawulok M, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553733
   Kawulok M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-170
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Kawulok M, 2012, LECT NOTES COMPUT SC, V7626, P557, DOI 10.1007/978-3-642-34166-3_61
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Kukharev G., 2004, Machine Graphics & Vision, V13, P377
   Lee JS, 2007, PATTERN RECOGN, V40, P2261, DOI 10.1016/j.patcog.2006.11.016
   Ming-Ji Zhang, 2004, Proceedings. Third International Conference on Image and Graphics, P250
   Pan Ng, 2011, Proceedings of the 2011 3rd International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2011), P213, DOI 10.1109/CICSyN.2011.54
   Peer P., 1999, AUTOMATIC HUMAN FACE, P122
   Phillips P. J., 1996, FACIAL RECOGNITION T
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Pinna B, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01051
   Reenspan H., 2001, PATTERN RECOGN LETT, p[22, 1525]
   Seow MJ, 2004, 32ND APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P141
   Sobottka K, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P483, DOI 10.1109/ICIP.1996.560536
   Stöttinger J, 2009, LECT NOTES COMPUT SC, V5876, P303, DOI 10.1007/978-3-642-10520-3_28
   Tan TY, 2018, KNOWL-BASED SYST, V158, P118, DOI 10.1016/j.knosys.2018.05.042
   Taqa AY, 2010, SCI RES ESSAYS, V5, P2480
   von Neumann J, 1928, MATH ANN, V100, P295
   Wang T, 2016, PATTERN RECOGN, V55, P28, DOI 10.1016/j.patcog.2016.01.018
   Wang XQ, 2011, INT GEOSCI REMOTE SE, P1981
   Yas QM, 2018, MEASUREMENT, V114, P243, DOI 10.1016/j.measurement.2017.09.027
   Zakaria Z, 2018, APPL SOFT COMPUT, V68, P172, DOI 10.1016/j.asoc.2018.03.030
   Zhao J, 2018, ISPRS J PHOTOGRAMM, V135, P31, DOI 10.1016/j.isprsjprs.2017.10.006
   Zhu YX, 2002, COMPUT VIS IMAGE UND, V85, P189, DOI 10.1006/cviu.2002.0967
   2013, DATABASE HAND GESTUR
NR 50
TC 16
Z9 16
U1 1
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2020
VL 99
AR 103925
DI 10.1016/j.imavis.2020.103925
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LZ3LW
UT WOS:000541130800001
DA 2024-07-18
ER

PT J
AU Kim, SH
   Hwang, Y
   Kweon, IS
AF Kim, Seong-heum
   Hwang, Youngbae
   Kweon, In So
TI Category-specific upright orientation estimation for 3D model
   classification and retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Model-based 3D reconstruction; Multi-view object co-segmentation;
   Convolutional neural networks; Upright orientation estimation; 3D model
   classification; 3D model classification retrieval
ID NETWORKS
AB In this paper, we address a problem of correcting upright orientation of a reconstructed object to search. We first reconstruct an input object appearing in an image sequence, and generate a query shape using multi-view object co-segmentation. In the next phase, we utilize the Convolutional Neural Network (CNN) architecture to determine category-specific upright orientation of the queried shape for 3D model classification and retrieval. As a practical application of our system, a shape style and a pose from an inferred category and up-vector are obtained by comparing 3D shape similarity with candidate 3D models and aligning its projections with a set of 2D co-segmentation masks. We quantitatively and qualitatively evaluate the presented system with more than 720 upfront-aligned 3D models and five sets of multi-view image sequences. (C) 2020 Published by Elsevier B.V.
C1 [Kim, Seong-heum] Korea Elect Technol Inst, Intelligent Image Proc Res Ctr, Seongnam Si 13509, Gyeonggi Do, South Korea.
   [Hwang, Youngbae] Chungbuk Natl Univ, Dept Elect Engn, 1 Chungdae Ro, Cheongju 28644, Chungbuk, South Korea.
   [Kweon, In So] Korea Adv Inst Sci & Technol, Elect Engn Dept, 335 Gwahak Ro, Daejeon 305701, South Korea.
C3 Korea Electronics Technology Institute (KETI); Chungbuk National
   University; Korea Advanced Institute of Science & Technology (KAIST)
RP Hwang, Y (corresponding author), Chungbuk Natl Univ, Dept Elect Engn, 1 Chungdae Ro, Cheongju 28644, Chungbuk, South Korea.
EM ybhwang@cbnu.ac.kr
FU 'The Cross-Ministry Giga KOREA Project' - Korea government (MSIT)
   [GK20P0300]; Korean Health Technology R&D project by the Korea goverment
   (MOHW) [HI19C0665]
FX This work was partially supported by 'The Cross-Ministry Giga KOREA
   Project' funded by the Korea government (MSIT) (No. GK20P0300) and by
   the Korean Health Technology R&D project by the Korea goverment (MOHW)
   (No. HI19C0665).
CR [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2016, C COMP VIS PATT REC
   Arandjelovic R, 2011, IEEE I CONF COMP VIS, P375, DOI 10.1109/ICCV.2011.6126265
   Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487
   Baatz G, 2012, LECT NOTES COMPUT SC, V7573, P517, DOI 10.1007/978-3-642-33709-3_37
   Bansal A, 2016, PROC CVPR IEEE, P5965, DOI 10.1109/CVPR.2016.642
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Djelouah A, 2015, IEEE T PATTERN ANAL, V37, P1890, DOI 10.1109/TPAMI.2014.2385704
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Fu HB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360641
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Han P., COMPUT GRAPH
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kanezaki A, 2018, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR.2018.00526
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kholgade N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601209
   Kim SH, 2017, COMPUT GRAPH FORUM, V36, P313, DOI 10.1111/cgf.13082
   Kim SH, 2016, IEEE T IMAGE PROCESS, V25, P3639, DOI 10.1109/TIP.2016.2555698
   Kowdle A, 2012, LECT NOTES COMPUT SC, V7576, P789, DOI 10.1007/978-3-642-33715-4_57
   Lee W, 2011, IEEE T PATTERN ANAL, V33, P1429, DOI 10.1109/TPAMI.2010.196
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li JG, 2010, PROC CVPR IEEE, P2769, DOI 10.1109/CVPR.2010.5540004
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372
   Liu ZS, 2016, GRAPH MODELS, V85, P22, DOI 10.1016/j.gmod.2016.03.001
   Mundy JL, 2006, LECT NOTES COMPUT SC, V4170, P3
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Petit A., IEEE INT C ROB AUT I
   Prisacariu VA, 2012, INT J COMPUT VISION, V98, P335, DOI 10.1007/s11263-011-0514-3
   Qi C.R., P IEEE C COMP VIS PA, P652
   Roberts L., 1963, MACHINE PERCEPTION 3
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shen SH, 2013, IEEE T IMAGE PROCESS, V22, P1901, DOI 10.1109/TIP.2013.2237921
   Su H., P IEEE INT C COMP VI, VVolume 18, P945
   Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Taco Cohen, 2018, P 6 INT C LEARN REPR
   Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409
   van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x
   Waechter M, 2014, LECT NOTES COMPUT SC, V8693, P836, DOI 10.1007/978-3-319-10602-1_54
   Wu Changchang., VisualSFM: A Visual Structure from Motion System
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
NR 44
TC 2
Z9 2
U1 0
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2020
VL 96
AR 103900
DI 10.1016/j.imavis.2020.103900
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YN
UT WOS:000527905200003
DA 2024-07-18
ER

PT J
AU Peixoto, SA
   Vasconcelos, FFX
   Guimaraes, MT
   Medeiros, AG
   Rego, PAL
   Neto, AVL
   de Albuquerque, VHC
   Rebouças, PP
AF Peixoto, Solon A.
   Vasconcelos, Francisco F. X.
   Guimaraes, Matheus T.
   Medeiros, Aldisio G.
   Rego, Paulo A. L.
   Lira Neto, Aloisio, V
   de Albuquerque, Victor Hugo C.
   Reboucas Filho, Pedro P.
TI A high-efficiency energy and storage approach for IoT applications of
   facial recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Data compression; Face recognition; IoT; Deep learning
ID FACE RECOGNITION; EXPRESSION RECOGNITION; COMPRESSION; IMAGES
AB This work introduces a high-efficiency approach for face recognition applications based on features using a recent algorithm called Floor of Log (FoL). The advantage of this method is the reduction of storage and energy, maintaining accuracy. K-Nearest Neighbors and Support Vector Machine algorithm was applied to learn the better parameter of the FoL algorithm using cross-validation. Accuracy and the size after the compression process were adopted to evaluate the proposed algorithm. The FoL was tested in CelebA, Extended YaleB, AR, and LFW face datasets obtaining the same or better results when compared with the approach using the same classifiers with uncompressed features, but with a reduction of 86 to 91% compared to the original data size. The proposed method of this work presents a robust and straightforward algorithm of compression of features for face recognition applications. The FoL is a new supervised compression algorithm that can be adapted to achieve great results and integrated with edge computing systems. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Peixoto, Solon A.; Reboucas Filho, Pedro P.] Univ Fed Ceara, Programa Posgrad Engn Teleinformat PPGETI, Fortaleza, Ceara, Brazil.
   [Vasconcelos, Francisco F. X.; Reboucas Filho, Pedro P.] Inst Fed Educ Ciencia & Tecnol Ceara, Dept Ind, Fortaleza, Ceara, Brazil.
   [Lira Neto, Aloisio, V; de Albuquerque, Victor Hugo C.] Univ Fortaleza, Programa Posgrad Informat Aplicada, Fortaleza, Ceara, Brazil.
   [Guimaraes, Matheus T.; Medeiros, Aldisio G.; Rego, Paulo A. L.] Univ Fed Ceara, Dept Comp, Fortaleza, Ceara, Brazil.
   [Lira Neto, Aloisio, V] Secretaria Seguranca Publ & Def Social Estado Cea, Superintendancia Pesquisa & Estratagia Seguranca, Fortaleza, Ceara, Brazil.
C3 Universidade Federal do Ceara; Instituto Federal do Ceara (IFCE);
   Universidade Fortaleza; Universidade Federal do Ceara
RP de Albuquerque, VHC (corresponding author), Univ Fortaleza, Programa Posgrad Informat Aplicada, Fortaleza, Ceara, Brazil.
EM solon.alves@lapisco.ifce.edu.br; fabio.ximenes@lapisco.ifce.edu.br;
   matheus.guimaraes@lapisco.ifce.edu.br;
   aldisio.medeiros@lapisco.ifce.edu.br; pauloalr@ufc.br;
   aloisio.lira@prf.gov.br; victor.albuquerque@unifor.br;
   pedrosarf@ifce.edu.br
RI Ximenes, Fabio/AAW-7225-2020; de Albuquerque, Victor Hugo
   C./C-3677-2016; Peixoto, Solon/G-6094-2018
OI de Albuquerque, Victor Hugo C./0000-0003-3886-4309; Peixoto,
   Solon/0000-0002-3864-2506; Medeiros, Aldisio/0000-0001-8408-4042
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]; Brazilian National Council for Research and Development
   (CNPq) [431709/2018-1, 311973/2018-3]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001. Also
   Pedro Pedrosa Reboucas Filho acknowledges the sponsorship from the
   Brazilian National Council for Research and Development (CNPq) via
   Grants Nos. 431709/2018-1 and 311973/2018-3.
CR Al-Maitah M, 2019, COMPUT NETW, V152, P98, DOI 10.1016/j.comnet.2019.01.025
   [Anonymous], MEASUREMENT
   [Anonymous], SIGNAL PROCESS
   [Anonymous], 24 CVC
   [Anonymous], IEEE INTERNET THINGS
   Azar J, 2019, FUTURE GENER COMP SY, V96, P168, DOI 10.1016/j.future.2019.02.005
   da Cruz MAA, 2018, IEEE INTERNET THINGS, V5, P871, DOI 10.1109/JIOT.2018.2796561
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Elmahmudi A, 2019, FUTURE GENER COMP SY, V99, P213, DOI 10.1016/j.future.2019.04.025
   Fang J, 2019, NEUROCOMPUTING, V334, P114, DOI 10.1016/j.neucom.2018.12.073
   Farahzadi A, 2018, DIGIT COMMUN NETW, V4, P176, DOI 10.1016/j.dcan.2017.04.005
   Gabryel M, 2017, LECT NOTES ARTIF INT, V10245, P497, DOI 10.1007/978-3-319-59063-9_44
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Guimaraes RR, 2019, IEEE NETWORK, V33, P126, DOI 10.1109/MNET.2018.1800151
   Heinsohn D, 2019, IMAGE VISION COMPUT, V85, P46, DOI 10.1016/j.imavis.2019.02.012
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang XH, 2012, PATTERN RECOGN LETT, V33, P2181, DOI 10.1016/j.patrec.2012.07.015
   Hussain T, 2020, IEEE T IND INFORM, V16, P2592, DOI 10.1109/TII.2019.2937905
   Hussain T, 2020, IEEE T IND INFORM, V16, P77, DOI 10.1109/TII.2019.2929228
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Li Y., NEUROCOMPUTING
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Luo XL, 2019, PATTERN RECOGN, V93, P283, DOI 10.1016/j.patcog.2019.04.027
   Moon A, 2018, COMPUT ELECTRON AGR, V154, P304, DOI 10.1016/j.compag.2018.08.045
   Mukherjee Dhritiman, 2019, Procedia Computer Science, V152, P274, DOI 10.1016/j.procs.2019.05.016
   Ngu AH, 2017, IEEE INTERNET THINGS, V4, P1, DOI 10.1109/JIOT.2016.2615180
   Randhawa RH, 2019, AD HOC NETW, V92, DOI 10.1016/j.adhoc.2018.09.006
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Sodhro AH, 2019, IEEE T IND INFORM, V15, P4235, DOI 10.1109/TII.2019.2902878
   Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Ullah A, 2019, IEEE T IND ELECTRON, V66, P9692, DOI 10.1109/TIE.2018.2881943
   Wozniak M, 2018, NEUROCOMPUTING, V320, P76, DOI 10.1016/j.neucom.2018.09.003
   Xu Z, 2019, NEUROCOMPUTING, V355, P1, DOI 10.1016/j.neucom.2018.09.056
   Zangeneh E, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112854
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang L, 2018, IET IMAGE PROCESS, V12, P314, DOI 10.1049/iet-ipr.2017.0482
   Zhang LG, 2014, NEUROCOMPUTING, V145, P451, DOI 10.1016/j.neucom.2014.05.008
   Zhou B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224792
NR 40
TC 12
Z9 12
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2020
VL 96
AR 103899
DI 10.1016/j.imavis.2020.103899
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YN
UT WOS:000527905200005
DA 2024-07-18
ER

PT J
AU Shi, H
   Liu, CJ
AF Shi, Hang
   Liu, Chengjun
TI A new cast shadow detection method for traffic surveillance video
   analysis using color and statistical modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Traffic video analysis; Shadow detection; Global Foreground Modeling
   (GFM); New chromatic criteria; Shadow region detection method;
   Statistical shadow modeling
ID MOVING VEHICLE DETECTION; OBJECT DETECTION; ALGORITHMS
AB In traffic surveillance video analysis systems, the cast shadows of vehicles often have a negative effect or video analysis results. A novel cast shadow detection framework, which consists of a new foreground detec. tion method and a cast shadow detection method, is presented in this paper to detect and remove the cal shadows from the foreground. The new foreground detection method applies an innovative Global Fore" ground Modeling (GFM) method, a Gaussian mixture model or GMM, and the Bayes classifier for foregrounc and background classification. While the GFM method is for global foreground modeling, the GMM is foi local background modeling, and the Bayes classifier applies both the foreground and the background model! for foreground detection. The rationale of the GFM method stems from the observation that the foregrounc objects often appear in recent frames and their trajectories often lead them to different locations in these frames. As a result, the statistical models used to characterize the foreground objects should not be pixe based or locally defined. The cast shadow detection method contains four hierarchical steps. First, a set of new chromatic criteria is presented to detect the candidate shadow pixels in the HSV color space. Second a new shadow region detection method is proposed to cluster the candidate shadow pixels into shadow regions. Third, a statistical shadow model, which uses a single Gaussian distribution to model the shadow, class, is presented for classifying shadow pixels. Fourth, an aggregated shadow detection method is presented for final shadow detection. Experiments using the public video data 'Highway-1' and 'Highway-3' and the New Jersey Department of Transportation (NJDOT) real traffic video sequences show the feasibility of the proposed method. In particular, the proposed method achieves better shadow detection performance than the popular shadow detection methods, and is able to improve the traffic video analysis results. (C) 2019 Elsevier B.V. All rights reserved
C1 [Shi, Hang; Liu, Chengjun] New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
C3 New Jersey Institute of Technology
RP Shi, H (corresponding author), New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
EM hs328@njit.edu; cliu@njit.edu
RI Shi, Hang/AAI-1621-2021
OI Shi, Hang/0000-0002-6326-9942
FU NSF [1647170]; Direct For Computer & Info Scie & Enginr; Division Of
   Computer and Network Systems [1647170] Funding Source: National Science
   Foundation
FX This paper is partially supported by the NSF grant1647170.
CR Amato A, 2011, IEEE T IMAGE PROCESS, V20, P2954, DOI 10.1109/TIP.2011.2132728
   [Anonymous], 2003, STAT PATTERN RECOGNI
   [Anonymous], 2010, Chinese Conference on Pattern Recognition, DOI DOI 10.1109/CCPR.2010.5659321
   [Anonymous], 2004, COMPUT VIS IMAGE UND, DOI DOI 10.1016/j.cviu.2004.03.008
   [Anonymous], 2016, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2015.2462355
   Boulmerka A, 2018, IEEE T CIRC SYST VID, V28, P1330, DOI 10.1109/TCSVT.2017.2665970
   Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001
   Bouwmans T, 2018, COMPUT SCI REV, V28, P26, DOI 10.1016/j.cosrev.2018.01.004
   Bullkich E., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P146
   Chia-Chih Chen, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2407, DOI 10.1109/ICPR.2010.589
   Chun-Ting Chen, 2010, 2010 International Conference on Green Circuits and Systems (ICGCS 2010), P679, DOI 10.1109/ICGCS.2010.5542975
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Fang LZ, 2008, PATTERN RECOGN LETT, V29, P2182, DOI 10.1016/j.patrec.2008.08.009
   Gomes V, 2017, PATTERN RECOGN, V63, P30, DOI 10.1016/j.patcog.2016.09.008
   Guo Ruiqi, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P2956, DOI 10.1109/TPAMI.2012.214
   Hayman E, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P67
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778
   Huang JB, 2009, PROC CVPR IEEE, P2310, DOI 10.1109/CVPRW.2009.5206629
   Huerta I, 2015, IMAGE VISION COMPUT, V41, P42, DOI 10.1016/j.imavis.2015.06.003
   Ji W, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P439, DOI 10.1109/CompComm.2016.7924739
   Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24
   Le Hieu, 2018, ECCV, P662
   Lee H, 2016, IEEE T MULTIMEDIA, V18, P2093, DOI 10.1109/TMM.2016.2595262
   Leone A, 2007, PATTERN RECOGN, V40, P1222, DOI 10.1016/j.patcog.2006.09.017
   Mahajan R, 2015, PROCEEDINGS OF 2015 IEEE 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO), DOI 10.1109/ISCO.2015.7282374
   Mittal A, 2000, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2000.854767
   Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51
   Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383
   Perner P, 2018, INT C MACHINE LEARNI, V10934, P49
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Qu LQ, 2017, PROC CVPR IEEE, P2308, DOI 10.1109/CVPR.2017.248
   Sanin Andres, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P141, DOI 10.1109/ICPR.2010.43
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Shen L, 2015, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2015.7298818
   Shi H, 2018, INT C PATT RECOG, P2899, DOI 10.1109/ICPR.2018.8545500
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Song HS, 2014, IEEE T VEH TECHNOL, V63, P3580, DOI 10.1109/TVT.2014.2307958
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Vicente TFY, 2018, IEEE T PATTERN ANAL, V40, P682, DOI 10.1109/TPAMI.2017.2691703
   Vicente TFY, 2015, IEEE I CONF COMP VIS, P3388, DOI 10.1109/ICCV.2015.387
   Wang Y, 2009, IEEE T CIRC SYST VID, V19, P437, DOI 10.1109/TCSVT.2009.2013500
   Wang YP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1007
   Xu D, 2005, IEEE T CIRC SYST VID, V15, P1058, DOI 10.1109/TCSVT.2005.852402
   Xu Y, 2016, CAAI T INTELL TECHNO, V1, P43, DOI 10.1016/j.trit.2020.03.005
   Zhou J, 2007, IEEE T VEH TECHNOL, V56, P51, DOI 10.1109/TVT.2006.883735
   Zhu L., 2018, EUR C COMP VIS ECCV
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 48
TC 9
Z9 10
U1 1
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103863
DI 10.1016/j.imavis.2019.103863
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900006
OA Bronze
DA 2024-07-18
ER

PT J
AU Ly, TS
   Do, NT
   Kim, SH
   Yang, HJ
   Lee, GS
AF Ly, Thai Son
   Do, Nhu-Tai
   Kim, Soo-Hyung
   Yang, Hyung-Jeong
   Lee, Guee-Sang
TI A novel 2D and 3D multimodal approach for in-the-wild facial expression
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; In-the-wild FER; 2D+3D FER
ID FACE; DATABASE; DEEP; MODEL
AB This study proposes a novel deep learning approach for the fusion of 2D and 3D modalities in in-the-wild facial expression recognition (FER). Different from other studies, we exploit the 3D facial information in in-the-wild FER. In particular, in-the-wild 3D FER dataset is not widely available; therefore, 3D facial data are constructed from available 2D datasets thanks to recent advances in 3D face reconstruction. The 3D facial geometry features are then extracted by deep learning technique to exploit the mid-level details, which provides meaningful expression for the recognition. In addition, to demonstrate the potential of 3D data on FER, the 2D projected images of 3D faces are taken as additional input to FER. These features are then jointly fused with 2D features obtained from the original input. The fused features are then classified by support vector machines (SVMs). The results show that the proposed approach achieves state-of-the-art recognition performances on Real-World Affective Faces (RAF) and Static Facial Expressions in the Wild (SFEW 2.0), and AffectNet dataset. This approach is also applied to a 3D FER dataset, i.e. BU-3DFE, to compare the effectiveness of reconstructed and available 3D face data for FER. This is the first time such a deep learning combination of 3D and 2D facial modalities is presented in the context of in-the-wild FER. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Ly, Thai Son; Do, Nhu-Tai; Kim, Soo-Hyung; Yang, Hyung-Jeong; Lee, Guee-Sang] Chonnam Natl Univ, 77 Yongbong Ro, Gwangju 61186, South Korea.
C3 Chonnam National University
RP Lee, GS (corresponding author), Chonnam Natl Univ, 77 Yongbong Ro, Gwangju 61186, South Korea.
EM gslee@jnu.ac.kr
RI ARSLAN, Okan/AAA-3232-2020; Do, Tai Nhu/AAZ-2526-2021; Yang,
   Hyung-Jeong/GXV-4819-2022
OI Do, Tai Nhu/0000-0002-7034-0364; 
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2018R1D1A3B05049058,
   NRF-2017R1A4A1015559]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2018R1D1A3B05049058 & NRF-2017R1A4A1015559).
   The corresponding author is Guee-Sang Lee.
CR Acharya Dinesh, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P480, DOI 10.1109/CVPRW.2018.00077
   Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Tran AT, 2018, PROC CVPR IEEE, P3935, DOI 10.1109/CVPR.2018.00414
   [Anonymous], 2010, IEEE CVPR 10 WORKSHO
   [Anonymous], 2018, CORR
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2008 23 INT S COMP I
   [Anonymous], 2016, P BRIT MACH VIS C BM
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], ACM T GRAPH TOG
   [Anonymous], PROCESS IMAGES FACES
   [Anonymous], 2018, TOMCCAP
   [Anonymous], 2013, 2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Berretti S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   BRUCE V, 1986, BRIT J PSYCHOL, V77, P305, DOI 10.1111/j.2044-8295.1986.tb02199.x
   BRUCE V, 1992, PHILOS T ROY SOC B, V335, P121, DOI 10.1098/rstb.1992.0015
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chang FJ, 2018, IEEE INT CONF AUTOMA, P122, DOI 10.1109/FG.2018.00027
   Cheng SY, 2018, PROC CVPR IEEE, P5117, DOI 10.1109/CVPR.2018.00537
   Chu B, 2014, PROC CVPR IEEE, P1907, DOI 10.1109/CVPR.2014.245
   Dahmane Mohamed, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P884, DOI 10.1109/FG.2011.5771368
   Deng W., 2018, China's Regional Expansion Input-Output Table 2012: Preparation and Application
   Derkach D, 2018, IMAGE VISION COMPUT, V79, P86, DOI 10.1016/j.imavis.2018.09.007
   Dhall A., 2017, P 19 ACM INT C MULT, P524, DOI [10.1145/3136755.3143004, DOI 10.1145/3136755.3143004]
   Dhall A., 2014, PROC ICMI, P461, DOI DOI 10.1145/2663204.2666275
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fan YR, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P584, DOI 10.1145/3242969.3264978
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Hua WT, 2019, IEEE ACCESS, V7, P24321, DOI 10.1109/ACCESS.2019.2900231
   Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117
   Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691
   Kingma D. P., 2015, P INT C LEARN REPR, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   Li HB, 2017, IEEE T MULTIMEDIA, V19, P2816, DOI 10.1109/TMM.2017.2713408
   Li HB, 2015, COMPUT VIS IMAGE UND, V140, P83, DOI 10.1016/j.cviu.2015.07.005
   Li HB, 2012, INT C PATT RECOG, P2577
   Li HB, 2011, LECT NOTES COMPUT SC, V6915, P483, DOI 10.1007/978-3-642-23687-7_44
   Li ST, 2017, IEEE IND ELEC, P2852
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Li YZ, 2018, ADV NEUR IN, V31
   Liu CH, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P630, DOI 10.1145/3242969.3264989
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Ocegueda O., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1270, DOI 10.1109/ICCVW.2011.6130397
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Rifai S, 2012, LECT NOTES COMPUT SC, V7577, P808, DOI 10.1007/978-3-642-33783-3_58
   Romdhani S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P59
   Savran A, 2017, COMPUT VIS IMAGE UND, V162, P146, DOI 10.1016/j.cviu.2017.07.005
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang H., 2008, IEEE INT C AUTOM FAC, P1
   Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401
   Trân AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   Valstar MF, 2017, IEEE INT CONF AUTOMA, P839, DOI 10.1109/FG.2017.107
   Vielzeuf V., 2017, P 19 ACM INT C MULT, P569
   Vielzeuf V, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P589, DOI 10.1145/3242969.3264980
   Wang F, 2017, IEEE IMAGE PROC, P1087, DOI 10.1109/ICIP.2017.8296449
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wei J, 2013, IEEE ICCE, P1, DOI 10.1109/ICCE.2013.6486769
   Wu Y, 2016, PROC CVPR IEEE, P5101, DOI 10.1109/CVPR.2016.551
   Xudong Yang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163090
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Yang J, 2011, COMPUT RISK MANAG, P3, DOI 10.1007/978-3-642-19339-2_1
   Yin L, 2008, IEEE INT C AUTOM FAC, P1
   Yin L, 2010, INT J COMPUT MATH, V87, P690, DOI 10.1080/00207160802169360
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zeng J., 2018, P ECCV, P222
   Zhang FF, 2018, PROC CVPR IEEE, P3359, DOI 10.1109/CVPR.2018.00354
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao X, 2010, INT GEOSCI REMOTE SE, P4272, DOI 10.1109/IGARSS.2010.5649250
   Zhen QK, 2016, IEEE T MULTIMEDIA, V18, P1438, DOI 10.1109/TMM.2016.2557063
   Zheng QJ, 2014, IEEE INFOCOM SER, P522, DOI 10.1109/INFOCOM.2014.6847976
NR 84
TC 13
Z9 13
U1 0
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2019
VL 92
AR 103817
DI 10.1016/j.imavis.2019.10.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JW2JO
UT WOS:000502884200006
DA 2024-07-18
ER

PT J
AU Ahmad, A
   Migniot, C
   Dipanda, A
AF Ahmad, Ammar
   Migniot, Cyrille
   Dipanda, Albert
TI Hand pose estimation and tracking in real and virtual interaction: A
   review
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Hand tracking; Real interaction; Virtual interaction; Hand-object
   interdependencies
AB Vision-based 3D hand tracking is a key and popular component for interaction studies in a broad range of domains such as virtual reality (VR), augmented reality (AR) and natural human-computer interaction (HCI). While this research field has been well studied in the last decades, most approaches have considered the human hand in isolation and not in action or in interaction with the surrounding environment. Even the common collaborative and strong interactions with the other hand have been ignored. However, many of today's computer applications require more and more hand-object interactions. Furthermore, employing contextual information about the object in the hand (e.g. the shape, the texture, and the pose) can remarkably constrain the tracking problem. The most studied contextual constraints involve interaction with real objects and not with virtual objects which is still a very big challenge. The goal of this survey is to develop an up-to-date taxonomy of the state-of-the-art vision-based hand pose estimation and tracking methods with a new classification scheme: hand-object interaction constraints. This taxonomy allows us to examine the strengths and weaknesses of the current state of the art and to highlight future trends in the domain. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Ahmad, Ammar; Migniot, Cyrille; Dipanda, Albert] Univ Bourgogne Franche Comte, ImViA EA 7535, Dijon, France.
C3 Universite de Bourgogne
RP Migniot, C (corresponding author), Univ Bourgogne Franche Comte, ImViA EA 7535, Dijon, France.
EM cyrille.migniot@u-bourgogne.fr
CR [Anonymous], EN CONV C EXH ECCE 2
   [Anonymous], 2004, COMP VIS PATT REC WO
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 2013, P GRAPHICS INTERFACE
   [Anonymous], 2015, P COMP VIS PATT REC
   Athitsos V., 2003, COMP VIS PATT REC 20, V2, P11
   Ballan L, 2012, LECT NOTES COMPUT SC, V7577, P640, DOI 10.1007/978-3-642-33783-3_46
   Blake a., 2011, IEEE C COMP VIS PATT, V411, P119
   Borst CW, 2006, PRESENCE-VIRTUAL AUG, V15, P47, DOI 10.1162/pres.2006.15.1.47
   Brubaker MA, 2009, IEEE I CONF COMP VIS, P2389, DOI 10.1109/ICCV.2009.5459407
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Cariani Peter A., 1989, THESIS STATE U NEW Y
   Choi I, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P986, DOI 10.1109/IROS.2016.7759169
   de Campos T.E., 2006, IEEE C COMPUTER VISI, V1, P782
   Dipietro L, 2008, IEEE T SYST MAN CY C, V38, P461, DOI 10.1109/TSMCC.2008.923862
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Feix T, 2016, IEEE T HUM-MACH SYST, V46, P66, DOI 10.1109/THMS.2015.2470657
   Fuchs P., 2006, TRAITE REALITE VIRTU, V1, P380
   Guan H., 2006, INT C AUT FAC GEST R
   Gustus A, 2012, BIOL CYBERN, V106, P741, DOI 10.1007/s00422-012-0532-4
   Hamer H., 2009, INT C COMP VIS
   Hamer H, 2010, PROC CVPR IEEE, P671, DOI 10.1109/CVPR.2010.5540150
   Hongwang Du, 2011, 2011 International Conference on Fluid Power and Mechatronics, P292, DOI 10.1109/FPM.2011.6045775
   Huang Y., 2005, COMPUTER VISION PATT
   Keskin C, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130391
   Kim JS, 2015, IEEE INT CONF ROBOT, P3814, DOI 10.1109/ICRA.2015.7139730
   Kyriazis N, 2016, ADV INTELL SYST, V391, P19, DOI 10.1007/978-3-319-23437-3_2
   Kyriazis N, 2014, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2014.438
   Liang H, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P87, DOI 10.1145/2856400.2856411
   Lin J, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P121, DOI 10.1109/HUMO.2000.897381
   Mueller F., 2017, CORR
   Oikonomidis A., 2012, INT C COMP VIS PATT, V95
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483
   Oikonomidis I, 2011, LECT NOTES COMPUT SC, V6494, P744, DOI 10.1007/978-3-642-19318-7_58
   Panteleris P., 2017, CoRR
   Panteleris Paschalis, 2015, P BRIT MACH VIS C 20
   Prachyabrued M., 2011, IEEE S 3D US INT 3DU
   Rehg J. M., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P35, DOI 10.1007/BFb0028333
   REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882
   Roditakis K, 2015, LECT NOTES COMPUT SC, V9163, P404, DOI 10.1007/978-3-319-20904-3_36
   Romero Javier, 2009, 2009 9th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2009), P87, DOI 10.1109/ICHR.2009.5379596
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Romero J, 2013, IMAGE VISION COMPUT, V31, P555, DOI 10.1016/j.imavis.2013.04.002
   Schmidt T., 2014, ROBOTICS SCI SYSTEMS, V2
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Sridhar S., 2016, REAL TIME HAND TRACK
   Taylor J, 2014, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2014.88
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Tsoli A., 2018, P EUR C COMP VIS ECC
   Tzionas D, 2016, INT J COMPUT VISION, V118, P172, DOI 10.1007/s11263-016-0895-4
   Wang D., 2018, IEEE T HAPTICS
   Wang R., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology. UIST '11, P549
   Xu C, 2013, IEEE I CONF COMP VIS, P3456, DOI 10.1109/ICCV.2013.429
   Ying Wu, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P6, DOI 10.1109/ICIP.1999.817058
NR 55
TC 21
Z9 23
U1 12
U2 111
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 35
EP 49
DI 10.1016/j.imavis.2019.06.003
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900004
DA 2024-07-18
ER

PT J
AU Park, JH
   Park, S
   Shim, H
AF Park, Joo Hyun
   Park, Song
   Shim, Hyunjung
TI Semantic-aware neural style transfer
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic mismatch; Neural style transfer; Segmentation; Domain
   adaptation; Word embedding
AB This study proposes a semantic-aware style transfer method for resolving semantic mismatch problems in existing algorithms. As the primary focus of this study, the consideration of semantic matching is expected to improve the quality of artistic style transfer. Here, each image is partitioned into several semantic regions for both a target photograph and a source painting. All partitioned regions of the target are then associated with one of the partitioned regions in the source according to their semantic interpretation. Given a pair of target and source regions, style is learned from the source region whereas content is learned from the target region. By integrating both the style and content components, we can successfully generate a stylized output. Unlike previous approaches, we obtain the best semantic match between regions using word embeddings. Thus, we guarantee that semantic matching is always established between the target and source. Moreover, it is unreliable to partition a painting using existing algorithms because of statistical gaps between the real photographs and paintings. To bridge such gaps, we apply a domain adaptation technique on the source painting to extract its semantic regions. We evaluated the effectiveness of the proposed algorithm based on a thorough experimental analysis and comparison. Through a user study, it is confirmed that semantic information considerably influences the quality assessment of style transfer. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Park, Joo Hyun; Park, Song; Shim, Hyunjung] Yonsei Univ, Sch Integrated Technol, Songdogwahak Ro 85, Incheon, South Korea.
C3 Yonsei University
RP Shim, H (corresponding author), Yonsei Univ, Sch Integrated Technol, Songdogwahak Ro 85, Incheon, South Korea.
EM kateshim@yonsei.ac.kr
RI Shim, Hyunjung/AAS-3610-2021
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - MS1P [NRF-2019R1A2C2006123]; MSIT (Ministry of Science
   and ICT), Korea, under the "ICT Consilience Creative Program"
   [IITP-2018-2017-0-01015]; MSIT (Ministry of Science and ICT), Korea,
   under the ITRC (Information Technology Research Center) support program
   [IITP-2019-2016-0-00288]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   MS1P (NRF-2019R1A2C2006123), the MSIT (Ministry of Science and ICT),
   Korea, under the "ICT Consilience Creative Program"
   (IITP-2018-2017-0-01015) supervised by the IITP (Institute of
   Information & Communications Technology Planning & Evaluation), and the
   MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program (IITP-2019-2016-0-00288)
   supervised by the IITP (Institute for Information & Communications
   Technology Planning & Evaluation).
CR [Anonymous], 2017, Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses
   [Anonymous], 2016, ARXIV160104568
   [Anonymous], ARXIV161107865
   Arbelot B., 2016, 5 JOINT S COMPUTATIO, P21
   Badrinarayanan V., 2017, TPAMI, DOI DOI 10.1109/TPAMI.2016.2644615
   Bénard P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461929
   Champandard AJ, ARXIV160301768
   Chang YH, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P176, DOI 10.1109/CGI.2003.1214463
   Chen DD, 2017, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2017.296
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen Y.-L, 2016, P BRIT MACH VIS C
   Cheng L, 2008, PROC CVPR IEEE, P179
   Dumoulin V.., 2017, P INT C LEARN REPR I
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Elad M., 2017, IEEE T IMAGE PROCESS, P1
   Frigo O, 2016, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2016.66
   Gatys L., 2015, NIPS
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Johnson MK, 2011, IEEE T VIS COMPUT GR, V17, P1273, DOI 10.1109/TVCG.2010.233
   Kim T., 2017, P 34 INT C MACH LEAR, P1857, DOI DOI 10.1109/WPT.2017.7953894
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Lai Yu-Kun, 2005, P ACM S SOL PHYS MOD, P15
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li YH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2230
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liang X., 2016, ARXIV160504731V1
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Shan Y, 2001, PROC CVPR IEEE, P794
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Ulyanov D., 2016, FAST NEURAL DOODLE
   Ulyanov D., 2016, P 33 INT C INT C MAC, V48, P1349
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Xiao Xuezhong, 2006, PACM INT C VIRT REAL, P305, DOI DOI 10.1145/1128923.1128974
   Zhang H., 2017, MULTISTYLE GENERATIV
   Zhang W, 2013, IEEE T MULTIMEDIA, V15, P1594, DOI 10.1109/TMM.2013.2265675
   Zhang Y., 2013, Innovative Smart Grid Technologies (ISG T), 2013 IEEE PES, P1
   Zhao H., 2017, ARXIV170809641
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 53
TC 11
Z9 13
U1 2
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2019
VL 87
BP 13
EP 23
DI 10.1016/j.imavis.2019.04.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IF3NV
UT WOS:000472988400002
DA 2024-07-18
ER

PT J
AU Gultekin, GK
   Saranli, A
AF Gultekin, Gokhan Koray
   Saranli, Afsar
TI Feature Detection Performance Based Benchmarking of Motion Deblurring
   Methods: Applications to Vision for Legged Robots
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature detection; Computer vision; Motion blur; Motion deblurring; Blur
   metric; Legged locomotion; Robotics; Computer vision dataset
ID CODED EXPOSURE; IMAGE
AB Dexterous legged robots can move on variable terrain at high speeds. The locomotion of these legged platforms on such terrain causes severe oscillations of the robot body depending on the surface and locomotion speed. Camera sensors mounted on such platforms experience the same disturbances, hence resulting in motion blur. This is a particular corruption of the image and results in information loss further resulting in degradation or loss of important image features. Although motion blur is a significant problem for legged mobile robots, it is of more general interest since it is present in many other handheld/mobile camera applications. Deblurring methods exist in the literature to compensate for blur, however most proposed performance metrics focus on the visual quality of compensated images. From the perspective of computer vision algorithms, feature detection performance is an essential factor that determines vision performance. In this study, we claim that existing image quality based metrics are not suitable to assess the performance of deblurring algorithms when the output is used for computer vision in general and legged robotics in particular. For comparatively evaluating deblurring algorithms, we define a novel performance metric based on the feature detection accuracy on sharp and deblurred images. We rank these algorithms according to the new metric as well as image quality based metrics from the literature and experimentally demonstrate that existing metrics may not be good indicators of algorithm performance, hence good selection criteria for computer vision application. Additionally, noting that a suitable data set to evaluate the effects of motion blur and its compensation for legged platforms is lacking in the literature, we develop a comprehensive multi-sensor data set for that purpose. The data set consists of monocular image sequences collected in synchronization with a low cost MEMS gyroscope, an accurate fiber optic gyroscope and an externally measured ground truth motion data. We make use of this data set for an extensive benchmarking of prominent motion deblurring methods from the literature in terms of existing and the proposed feature based metric. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Gultekin, Gokhan Koray; Saranli, Afsar] METU, Dept Elect & Elect Engn, Ankara, Turkey.
C3 Middle East Technical University
RP Gultekin, GK (corresponding author), METU, Dept Elect & Elect Engn, Ankara, Turkey.
EM gokhang@metu.edu.tr
RI Saranli, Afsar/ABA-4458-2020
OI Saranli, Afsar/0000-0001-9680-2558
FU Tubitak (The Scientific and Technological Research Council of Turkey)
   [110E120]
FX This study is partially funded by Tubitak (The Scientific and
   Technological Research Council of Turkey) under grant no 110E120.
CR Agrawal A, 2009, PROC CVPR IEEE, P2066, DOI 10.1109/CVPRW.2009.5206685
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], STAT METHODS RATES P
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], ASTRON J
   [Anonymous], MULTIMED EXPO ICME 2
   [Anonymous], ACM T GRAPH SIGGRAPH
   [Anonymous], 2010, ACM T GRAPHICS TOG
   Bando Y, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451239
   Bando Y, 2011, COMPUT GRAPH FORUM, V30, P1869, DOI 10.1111/j.1467-8659.2011.02057.x
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Goldstein A, 2012, LECT NOTES COMPUT SC, V7576, P622, DOI 10.1007/978-3-642-33715-4_45
   Harris C., 1988, P ALV VIS C, P5210
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Kim MD, 2015, INT J ROBOT RES, V34, P653, DOI 10.1177/0278364914557968
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Levin A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360670
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mutlu M, 2014, IEEE INT CONF ROBOT, P671, DOI 10.1109/ICRA.2014.6906926
   Park K, 2014, INT CONF UBIQ ROBOT, P665, DOI 10.1109/URAI.2014.7057492
   Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957
   REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107
   RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055
   Rohani B, 2014, J COMPUT APPL MATH, V259, P955, DOI 10.1016/j.cam.2013.10.018
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Schuon S, 2009, ACTA ASTRONAUT, V64, P1050, DOI 10.1016/j.actaastro.2009.01.012
   Tai YW, 2010, IEEE T PATTERN ANAL, V32, P1012, DOI 10.1109/TPAMI.2009.97
   Villgrattner T, 2011, IEEE-ASME T MECH, V16, P221, DOI 10.1109/TMECH.2009.2039223
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiener N., 1964, Extrapolation, interpolation, and smoothing of stationary time series: with engineering applications
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 37
TC 4
Z9 5
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2019
VL 82
BP 26
EP 38
DI 10.1016/j.imavis.2019.01.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HU1RT
UT WOS:000465050200003
DA 2024-07-18
ER

PT J
AU Trigueros, DS
   Meng, L
   Hartnett, M
AF Trigueros, Daniel Saez
   Meng, Li
   Hartnett, Margaret
TI Enhancing convolutional neural networks for face recognition with
   occlusion maps and batch triplet loss
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Convolutional neural networks; Facial occlusions;
   Distance metric learning
AB Despite the recent success of convolutional neural networks for computer vision applications, unconstrained face recognition remains a challenge. In this work, we make two contributions to the field. Firstly, we consider the problem of face recognition with partial occlusions and show how current approaches might suffer significant performance degradation when dealing with this kind of face images. We propose a simple method to find out which parts of the human face are more important to achieve a high recognition rate, and use that information during training to force a convolutional neural network to learn discriminative features from all the face regions more equally, including those that typical approaches tend to pay less attention to. We test the accuracy of the proposed method when dealing with real-life occlusions using the AR face database. Secondly, we propose a novel loss function called batch triplet loss that improves the performance of the triplet loss by adding an extra term to the loss function to cause minimisation of the standard deviation of both positive and negative scores. We show consistent improvement in the Labeled Faces in the Wild (LFW) benchmark by applying both proposed adjustments to the convolutional neural network training. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Trigueros, Daniel Saez; Meng, Li] Univ Hertfordshire, Sch Engn & Technol, Hatfield AL10 9AB, Herts, England.
   [Trigueros, Daniel Saez; Hartnett, Margaret] GBG Plc, London E14 9QD, England.
C3 University of Hertfordshire
RP Meng, L (corresponding author), Univ Hertfordshire, Sch Engn & Technol, Hatfield AL10 9AB, Herts, England.
EM l.1.meng@herts.ac.uk
OI Meng, Li/0000-0002-7567-5331
FU Innovate UK [009547]
FX This work resulted from a collaborative research project between the
   University of Hertfordshire and IDscan Biometrics Ltd (now part of GBG
   plc) as part of a Knowledge Transfer Partnership (KTP) programme
   supported by Innovate UK (partnership number: 009547).
CR [Anonymous], 2016, ARXIV161208534
   Benavente R, 1998, 24 COMP VIS CTR
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   Cheng LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1099, DOI 10.1145/2733373.2806291
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Daugman John., 2000, BIOMETRIC DECISION L
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Fan H., 2014, ARXIV14032802
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Huang G. B., 2014, LABELED FACES WILD U
   Jia H., 2008, Proc. FG, P1
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu J., 2015, ARXIV150607310CS
   Min R., 2011, IEEE INT C AUT FAC G, P442, DOI DOI 10.1109/FG.2011.5771439
   Park S, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/217568
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Sankaranarayanan S., 2016, 2016 IEEE 8th international conference on biometrics theory, applications and systems (BTAS), P1
   Sankaranarayanan S., 2016, ARXIV160203418CS
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharma M, 2013, NEUROCOMPUTING, V116, P231, DOI 10.1016/j.neucom.2011.12.063
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Yang M, 2013, PATTERN RECOGN, V46, P1865, DOI 10.1016/j.patcog.2012.06.022
   Yi Dong, 2014, ARXIV14117923
   Ying Zhang, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P352, DOI 10.1007/978-3-642-42051-1_44
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhou E., 2015, arXiv preprint arXiv:1501.04690
   Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383
NR 41
TC 46
Z9 49
U1 1
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 99
EP 108
DI 10.1016/j.imavis.2018.09.011
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kuehlkamp, A
   Bowyer, K
AF Kuehlkamp, Andrey
   Bowyer, Kevin
TI Found a good match: Should I keep searching? - Accuracy and performance
   in iris matching using 1-to-First search
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Iris recognition; Error rates; Identification; Accuracy;
   Search; 1:First; 1:N; Open-set
AB Iris recognition is used in many applications around the world, with enrollment sizes as large as over one billion persons in India's Aadhaar program. Large enrollment sizes can require special optimizations in order to achieve fast database searches. One such optimization that has been used in some operational scenarios is 1:First search. In this approach, instead of scanning the entire database, the search is terminated when the first sufficiently good match is found. This saves time, but ignores potentially better matches that may exist in the unexamined portion of the enrollments. At least one prominent and successful border-crossing program used this approach for nearly a decade, in order to allow users a fast "token-free" search. Our work investigates the search accuracy of 1:First and compares it to the traditional 1:N search. Several different scenarios are considered trying to emulate real environments as best as possible: a range of enrollment sizes, closed- and open-set configurations, two iris matchers, and different permutations of the galleries. Results confirm the expected accuracy degradation using 1:First search, and also allow us to identify acceptable working parameters where significant search time reduction is achieved, while maintaining accuracy similar to 1:N search. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Kuehlkamp, Andrey; Bowyer, Kevin] Univ Notre Dame, Notre Dame, IN 46556 USA.
C3 University of Notre Dame
RP Kuehlkamp, A (corresponding author), Univ Notre Dame, Notre Dame, IN 46556 USA.
EM akuehlka@nd.edu; kwb@nd.edu
OI Bowyer, Kevin/0000-0002-7562-4390
FU Brazilian Ministry of Education - CAPES [BEX 12976/13-0]
FX The authors thank the valuable contributions given by Dr. Adam Czajka.
   This research was partially supported by the Brazilian Ministry of
   Education - CAPES through process BEX 12976/13-0.
CR [Anonymous], 2006, 1979512006 ISO
   Bengali Shashank., 2017, Los Angeles Times
   Bowyer K.W., 2013, Handbook of Iris Recognition, P15, DOI [10.1007/978-1-4471-4402-1_2, DOI 10.1007/978-1-4471-4402-1_2, DOI 10.1007/978-1-4471-4402-12]
   Bowyer KW, 2015, IEEE INT CONF AUTOMA
   Canada Border Services Agency, 2017, TRAV OFT APPL NEXUS
   Chumakov M., 2015, COMMUNICATION
   Czajka A, 2017, IEEE T INF FOREN SEC, V12, P2184, DOI 10.1109/TIFS.2017.2701332
   Daugman J, 2006, P IEEE, V94, P1927, DOI 10.1109/JPROC.2006.884092
   Daugman John., 2015, Encyclopedia of Biometrics, P998
   Daugman John., 2008, Handbook of Biometrics
   Hao F, 2008, IEEE T INF FOREN SEC, V3, P203, DOI 10.1109/TIFS.2008.920726
   Interpeace, 2016, SOM SUCC LAUNCH VOT
   Jain A K, 2011, Introduction to Biometrics
   Kuehlkamp A, 2016, IEEE WINT CONF APPL
   Mukherjee R, 2008, INT C PATT RECOG, P2901
   National Science and Technology Council Subcommittee on Biometrics, 2006, BIOM GLOSS
   Ortiz Estefan, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301317
   Proença H, 2013, IEEE T INF FOREN SEC, V8, P1975, DOI 10.1109/TIFS.2013.2283458
   Rakvic RN, 2009, IEEE T INF FOREN SEC, V4, P812, DOI 10.1109/TIFS.2009.2032012
   Rathgeb C., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2848, DOI 10.1109/ICPR.2010.698
   Sandhana L., 2014, NEW SCI
NR 21
TC 2
Z9 3
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2018
VL 73
BP 17
EP 27
DI 10.1016/j.imavis.2018.03.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GH7SF
UT WOS:000433653000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Desrosiers, PA
   Bennis, Y
   Daoudi, M
   Ben Amor, B
   Guerreschi, P
AF Desrosiers, Paul Audain
   Bennis, Yasmine
   Daoudi, Mohamed
   Ben Amor, Boulbaba
   Guerreschi, Pierre
TI Analyzing of facial paralysis by shape analysis of 3D face sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 4D faces; Facial asymmetry; Facial paralysis; Dense Scalar Fields
ID EXPRESSION RECOGNITION; BOTULINUM TOXIN; DYNAMICS; 4D
AB In this paper, we address the problem of quantifying the facial asymmetry from 3D face sequence (4D). We investigate the role of 4D data to reveal the amount of both static and dynamic asymmetry in the clinical case of facial paralysis. The goal is to provide tools to clinicians to evaluate quantitatively facial paralysis treatment based on Botulinum Toxin (BT), which can provide qualitative and quantitative evaluations. To this end, Dense Scalar Fields (DSFs), based on Riemannian analysis of 3D facial shape, is proposed to quantify facial deformations. To assess this approach, a new 3D facial sequences of 16 patients data set is collected, before and after injecting the BT. For each patient, we have collected 8 facial expressions before and after injecting BT. Experimental results obtained on this data set show that the proposed approach allows clinicians to evaluate more accurately the facial asymmetry before and after the treatment. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Desrosiers, Paul Audain; Daoudi, Mohamed; Ben Amor, Boulbaba] Univ Lille, Ctr Rech Informat Signal & Automat Lille, IMT Lille Douai, CNRS,UMR 9189,CRIStAL, F-59000 Lille, France.
   [Bennis, Yasmine; Guerreschi, Pierre] Univ Lille 2 Droit & Sante, Serv Chirurg Plast Reconstructrice & Esthet, Lille, France.
C3 Universite de Lille; Centrale Lille; IMT - Institut Mines-Telecom; IMT
   Nord Europe; Centre National de la Recherche Scientifique (CNRS);
   Universite de Lille
RP Daoudi, M (corresponding author), Univ Lille, Ctr Rech Informat Signal & Automat Lille, IMT Lille Douai, CNRS,UMR 9189,CRIStAL, F-59000 Lille, France.
EM mohamed.daoudi@imt-lille-douai.fr
RI Ben Amor, Boulbaba/K-7066-2018; guerreschi, pierre/H-4757-2015; Daoudi,
   Mohammed/H-5935-2013
OI Ben Amor, Boulbaba/0000-0002-4176-9305; guerreschi,
   pierre/0000-0002-2955-5291; Daoudi, Mohammed/0000-0003-4219-7860
FU Etude realisee avec le soutien de la fondation de l'Avenir, Paris,
   France [AP-RM-2016-019]
FX Etude realisee avec le soutien de la fondation de l'Avenir, Paris,
   France, Etude no AP-RM-2016-019.
CR Al-Anezi T, 2013, INT J ORAL MAX SURG, V42, P9, DOI 10.1016/j.ijom.2012.10.035
   [Anonymous], P CVPR
   [Anonymous], 2012, EURASIP J ADV SIG PR, DOI DOI 10.1186/1687-6180-2012-1
   Ben Amor B, 2014, IEEE T CYBERNETICS, V44, P2443, DOI 10.1109/TCYB.2014.2308091
   Benichou L, 2015, FACIAL PALSY SEQUEL, V60, P377
   CLARK RP, 1989, PLAST RECONSTR SURG, V84, P353, DOI 10.1097/00006534-198908000-00027
   Desrosiers P. A., INT C COMP VIS THEOR
   Fang TH, 2012, IMAGE VISION COMPUT, V30, P738, DOI 10.1016/j.imavis.2012.02.004
   Filipo R, 2012, LARYNGOSCOPE, V122, P266, DOI 10.1002/lary.22404
   Gaber A, 2015, IEEE ENG MED BIO, P2497, DOI 10.1109/EMBC.2015.7318899
   Li HB, 2012, INT C PATT RECOG, P2577
   Quan W, 2012, IEEE SYS MAN CYBERN, P2676, DOI 10.1109/ICSMC.2012.6378151
   Risoud M., 2015, BOTULINUM TOXIN TYPE
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P762, DOI 10.1016/j.imavis.2012.01.006
   Shiyang Cheng, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163161
   Shujaat S, 2014, INT J ORAL MAX SURG, V43, P907, DOI 10.1016/j.ijom.2014.01.010
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Xudong Yang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163090
   Zhao X, 2016, IEEE T CYBERNETICS, V46, P2042, DOI 10.1109/TCYB.2015.2461131
   Zhao X, 2011, IEEE T SYST MAN CY B, V41, P1417, DOI 10.1109/TSMCB.2011.2148711
   Zhen QK, 2016, IEEE T MULTIMEDIA, V18, P1438, DOI 10.1109/TMM.2016.2557063
NR 21
TC 9
Z9 9
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2017
VL 67
BP 67
EP 88
DI 10.1016/j.imavis.2017.08.006
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FM3DF
UT WOS:000414883800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Goldman, Y
   Rivlin, E
   Shimshoni, I
AF Goldman, Yehonatan
   Rivlin, Ehud
   Shimshoni, Ilan
TI Robust epipolar geometry estimation using noisy pose priors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Robust estimation; Epipolar geometry; Pose priors
AB Epipolar geometry estimation is fundamental to many computer vision algorithms. It has therefore attracted a lot of interest in recent years, yielding high quality estimation algorithms for wide baseline image pairs. Currently many types of cameras such as smartphones produce geo-tagged images containing pose and internal calibration data. These include a GPS receiver, which estimates the position, a compass, accelerometers, and gyros, which estimate the orientation, and the focal length. Exploiting this information as part of an epipolar geometry estimation algorithm may be useful but not trivial, since the pose measurement may be quite noisy. We introduce SOREPP (Soft Optimization method for Robust Estimation based on Pose Priors), a novel estimation algorithm designed to exploit pose priors naturally. It sparsely samples the pose space around the measured pose and for a few promising candidates applies a robust optimization procedure. It uses all the putative correspondences simultaneously, even though many of them are outliers, yielding a very efficient algorithm whose runtime is independent of the inlier fraction. SOREPP was extensively tested on synthetic data and on hundreds of real image pairs taken by smartphones. Its ability to handle challenging scenarios with extremely low inlier fractions of less than 10% was demonstrated. It outperforms current state-of-the-art algorithms that do not use pose priors as well as others that do. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Goldman, Yehonatan; Rivlin, Ehud] Technion Israel Inst Technol, Technion City, IL-3200003 Haifa, Israel.
   [Shimshoni, Ilan] Univ Haifa, 199 Aba Khoushy Ave, Haifa, Israel.
C3 Technion Israel Institute of Technology; University of Haifa
RP Shimshoni, I (corresponding author), Univ Haifa, 199 Aba Khoushy Ave, Haifa, Israel.
EM ishimshoni@is.haifa.ac.il
OI Shimshoni, Ilan/0000-0002-5276-0242
CR [Anonymous], BMVC
   [Anonymous], THESIS
   [Anonymous], MAC RANSAC ROBUST AL
   [Anonymous], 2007, 070012 UCLA CSD
   [Anonymous], INT C IM VIS COMP NE
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Armangué X, 2003, IMAGE VISION COMPUT, V21, P205, DOI 10.1016/S0262-8856(02)00154-3
   Brahmachari AS, 2009, IEEE I CONF COMP VIS, P1685, DOI 10.1109/ICCV.2009.5459379
   Carceroni Rodrigo., 2006, Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 1, V1, P477, DOI DOI 10.1109/CVPR.2006.296
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Di Corato F, 2011, IEEE INT CONF ROBOT, P1640
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fraundorfer F, 2010, LECT NOTES COMPUT SC, V6314, P269, DOI 10.1007/978-3-642-15561-1_20
   Goshen L, 2008, IEEE T PATTERN ANAL, V30, P1230, DOI 10.1109/TPAMI.2007.70768
   Hartley RichardI., 2007, ICCV
   Irschara A., 2011, Proc. of IEEE Conference on Computer Vision and Pattern Recognition Workshops, P21
   Kneip L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.16
   Konolige K, 2010, SPRINGER TRAC ADV RO, V66, P201
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164, DOI [10.1090/QAM/10666, DOI 10.1090/QAM/10666]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moisan L, 2004, INT J COMPUT VISION, V57, P201, DOI 10.1023/B:VISI.0000013094.38752.54
   Naroditsky O, 2012, IEEE T PATTERN ANAL, V34, P818, DOI 10.1109/TPAMI.2011.226
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Tamaazousti M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3073, DOI 10.1109/CVPR.2011.5995358
   Tardif JP, 2010, IEEE INT C INT ROBOT, P4161, DOI 10.1109/IROS.2010.5651059
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
NR 31
TC 6
Z9 7
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2017
VL 67
BP 16
EP 28
DI 10.1016/j.imavis.2017.09.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FM3DF
UT WOS:000414883800002
DA 2024-07-18
ER

PT J
AU Herath, S
   Harandi, M
   Porikli, F
AF Herath, Samitha
   Harandi, Mehrtash
   Porikli, Fatih
TI Going deeper into action recognition: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human action recognition; Motion recognition; Survey; Deep networks
ID MOTION; CLASSIFICATION; REPRESENTATION; MOVEMENTS; MODEL; SCALE
AB Understanding human actions in visual data is tied to advances in complementary research areas including object recognition, human dynamics, domain adaptation and semantic segmentation. Over the last decade, human action analysis evolved from earlier schemes that are often limited to controlled environments to nowadays advanced solutions that can learn from millions of videos and apply to almost all daily activities. Given the broad range of applications from video surveillance to human-computer interaction, scientific milestones in action recognition are achieved more rapidly, eventually leading to the demise of what used to be good in a short time. This motivated us to provide a comprehensive review of the notable steps taken towards recognizing human actions. To this end, we start our discussion with the pioneering methods that use handcrafted representations, and then, navigate into the realm of deep learning based approaches. We aim to remain objective throughout this survey, touching upon encouraging improvements as well as inevitable fallbacks, in the hope of raising fresh questions and motivating new research directions for the reader. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Herath, Samitha] Australian Natl Univ, Canberra, ACT, Australia.
   Australia Data61 CSIRO, Canberra, ACT, Australia.
C3 Australian National University; Commonwealth Scientific & Industrial
   Research Organisation (CSIRO)
RP Herath, S (corresponding author), Australian Natl Univ, Canberra, ACT, Australia.
EM samitha.herath@data61.csiro.au
RI Harandi, Mehrtash/D-6586-2018
OI Harandi, Mehrtash/0000-0002-6937-6300
FU ARC [DP150104645]
FX This work was supported in part by the ARC under Grant DP150104645.
CR Aggarwal JK, 2011, DISTRIBUTED VIDEO SENSOR NETWORKS, P27, DOI 10.1007/978-0-85729-127-1_2
   Chaaraoui AA, 2012, EXPERT SYST APPL, V39, P10873, DOI 10.1016/j.eswa.2012.03.005
   [Anonymous], 2012, ABS12120402 CORR
   [Anonymous], FDN TRENDS SIGNAL PR
   [Anonymous], 2014, ABS14054506 CORR
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 1988, Annual Conference on Neural Information Processing Systems (NIPS)
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2015, CORR
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2010, P NIPS
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], P 2009 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2009.5206557
   [Anonymous], 2016, PR MACH LEARN RES
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2016, 2016 IEEE MTT S INT
   [Anonymous], BMVC 2008 19 BRIT MA
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2015, CoRR
   [Anonymous], MACH VIS APPL
   [Anonymous], 2016, P 4 INT C LEARNING R
   [Anonymous], 2014, INT C MACH LEARN ICM
   [Anonymous], 2008, BMVC
   [Anonymous], 2014, CORR
   [Anonymous], 2015, ABS150702159 CORR
   [Anonymous], 2001, PROC 18 INT C MACH L
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Borzeshi EZ, 2013, IEEE SIGNAL PROC LET, V20, P1207, DOI 10.1109/LSP.2013.2284196
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Carreira J, 2015, IEEE T PATTERN ANAL, V37, P1177, DOI 10.1109/TPAMI.2014.2361137
   Carvajal J, 2016, LECT NOTES ARTIF INT, V9794, P115, DOI 10.1007/978-3-319-42996-0_10
   Carvajal Johanna, 2014, MLSDA, P19
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646
   Gaidon A, 2014, INT J COMPUT VISION, V107, P219, DOI 10.1007/s11263-013-0677-1
   Goodale MA, 2003, BRADFORD BOOKS, P175
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goroshin R, 2015, IEEE I CONF COMP VIS, P4086, DOI 10.1109/ICCV.2015.465
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Harandi M, 2014, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2014.132
   Harris C., 1988, ALVEY VISION C, P147151
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hoai M, 2015, LECT NOTES COMPUT SC, V9007, P3, DOI 10.1007/978-3-319-16814-2_1
   Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3
   Hogg D., 1983, Image Vision Computing, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3
   Hongeng S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1455, DOI 10.1109/ICCV.2003.1238661
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang YG, 2015, IEEE T IMAGE PROCESS, V24, P3781, DOI 10.1109/TIP.2015.2456412
   Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kliper-Gross O, 2012, LECT NOTES COMPUT SC, V7577, P256, DOI 10.1007/978-3-642-33783-3_19
   Koniusz P, 2016, LECT NOTES COMPUT SC, V9908, P37, DOI 10.1007/978-3-319-46493-0_3
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Kuehne H, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P571, DOI 10.1007/978-3-642-33374-3_41
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lea C, 2016, LECT NOTES COMPUT SC, V9907, P36, DOI 10.1007/978-3-319-46487-9_3
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   MARR D, 1982, PROC R SOC SER B-BIO, V214, P501, DOI 10.1098/rspb.1982.0024
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   McCallum Andrew, 2003, Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, P188, DOI DOI 10.3115/1119176.1119206
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Metaxas D, 2013, IMAGE VISION COMPUT, V31, P421, DOI 10.1016/j.imavis.2013.03.005
   Mikolajczyk K., 2008, PROC IEEE C COMPUTER, P1
   Misra Ishan., 2016, Unsupervised learning using sequential veri cation for action recognition
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Norouznezhad E, 2012, LECT NOTES COMPUT SC, V7574, P736, DOI 10.1007/978-3-642-33712-3_53
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Perronnin F., 2007, P IEEE CVPR, P1
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167
   Rahmani H, 2015, PROC CVPR IEEE, P2458, DOI 10.1109/CVPR.2015.7298860
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   de Souza CR, 2016, LECT NOTES COMPUT SC, V9911, P697, DOI 10.1007/978-3-319-46478-7_43
   ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shah M., 2008, PROC IEEE C COMPUTER, P1
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Somasundaram G, 2014, COMPUT VIS IMAGE UND, V123, P1, DOI 10.1016/j.cviu.2014.01.002
   Song Y, 2013, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2013.457
   Srivastava RK., 2015, P 28 INT C NEURAL IN, P2377, DOI DOI 10.48550/ARXIV.1507.06228
   Su B, 2016, LECT NOTES COMPUT SC, V9908, P202, DOI 10.1007/978-3-319-46493-0_13
   Sun C, 2013, IEEE I CONF COMP VIS, P913, DOI 10.1109/ICCV.2013.453
   Sun C, 2013, IEEE WORK APP COMP, P15, DOI 10.1109/WACV.2013.6474994
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Tsai Yao-Hung Hubert, 2016, P IEEE C COMP VIS PA
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varol G., 2016, CoRR
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang XL, 2016, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2016.291
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330
   Xing D, 2015, LECT NOTES COMPUT SC, V9008, P99, DOI 10.1007/978-3-319-16628-5_8
   Yan X, 2014, LECT NOTES COMPUT SC, V8692, P215, DOI 10.1007/978-3-319-10593-2_15
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhu Y, 2011, LECT NOTES COMPUT SC, V6493, P660
NR 161
TC 394
Z9 451
U1 4
U2 176
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 4
EP 21
DI 10.1016/j.imavis.2017.01.010
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800002
OA Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU López-Fernández, D
   Madrid-Cuevas, FJ
   Carmona-Poyato, A
   Marín-Jiménez, MJ
   Muñoz-Salinas, R
   Medina-Carnicer, R
AF Lopez-Fernandez, D.
   Madrid-Cuevas, F. J.
   Carmona-Poyato, A.
   Marin-Jimenez, M. J.
   Munoz-Salinas, R.
   Medina-Carnicer, R.
TI Viewpoint-independent gait recognition through morphological
   descriptions of 3D human reconstructions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gait recognition; Morphology; View-independent; Appearance-based; 3D
   reconstruction; Histogram
ID IDENTIFICATION; IMAGE
AB Many studies have confirmed gait as a robust biometric feature for identification of individuals. However, direction changes cause difficulties for most of the gait recognition systems, due to appearance changes. This study presents an efficient multi-view gait recognition method that allows curved trajectories on unconstrained paths in indoor environments. The recognition is based on volumetric analysis of the human gait, to exploit most of the 3D information enclosed in it. Appearance-based gait descriptors are extracted from 3D gait volumes and temporal patterns of them are classified using a Support Vector Machine with a sliding temporal window for majority voting. The proposed approach is experimentally validated on the "AVA Multi-View Dataset (AVAMVG)" and on the "Kyushu University 4D Gait Database (KY4D)". The results show that this new approach is able to identify people walking on curved paths. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Lopez-Fernandez, D.; Madrid-Cuevas, F. J.; Carmona-Poyato, A.; Marin-Jimenez, M. J.; Munoz-Salinas, R.; Medina-Carnicer, R.] Univ Cordoba, Maimnides Inst Biomed Res IMIBIC, Dept Comp & Numer Anal, Cordoba, Spain.
   [Lopez-Fernandez, D.; Madrid-Cuevas, F. J.; Carmona-Poyato, A.; Marin-Jimenez, M. J.; Munoz-Salinas, R.; Medina-Carnicer, R.] Univ Cordoba, Comp & Numer Anal Dept, Edificio Einstein,Campus Rabanales, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba; Universidad de Cordoba
RP López-Fernández, D (corresponding author), Univ Cordoba, Maimnides Inst Biomed Res IMIBIC, Dept Comp & Numer Anal, Cordoba, Spain.; López-Fernández, D (corresponding author), Univ Cordoba, Comp & Numer Anal Dept, Edificio Einstein,Campus Rabanales, E-14071 Cordoba, Spain.
EM i52lofed@uco.es; fjmadrid@uco.es; ma1capoa@uco.es; mjmarin@uco.es;
   rmsalinas@uco.es; rmedina@uco.es
RI Cuevas, Francisco José Madrid/H-1396-2015; Marin-Jimenez, Manuel
   J./AAS-9152-2020; Carmona-Poyato, Angel/G-1593-2015; Munoz-Salinas,
   Rafael/K-5999-2014; Medina-Carnicer, Rafael/G-3401-2015
OI Marin-Jimenez, Manuel J./0000-0001-9294-6714; Carmona-Poyato,
   Angel/0000-0002-8820-8396; Lopez-Fernandez, David/0000-0003-2582-4260;
   Munoz-Salinas, Rafael/0000-0002-8773-8571; Medina-Carnicer,
   Rafael/0000-0003-4481-0614
FU Science and Technology Ministry of Spain [TIN2012-32952]; BROCA -
   Science and Technology Ministry of Spain; FEDER
FX This work has been developed with the support of the Research Projects
   called TIN2012-32952 and BROCA both financed by Science and Technology
   Ministry of Spain and FEDER.
CR [Anonymous], AUT FAC GEST REC 200
   [Anonymous], 2012, 2012 INT C DIGITAL I
   [Anonymous], IM PROC 2005 ICIP 20
   [Anonymous], 2008, 2008 IEEE 2 INT C BI
   [Anonymous], 2001, CMU MOTION BODY MOBO
   Ariyanto G., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117582
   Barnich O, 2009, PATTERN RECOGN LETT, V30, P893, DOI 10.1016/j.patrec.2009.03.014
   Bodor R, 2009, IMAGE VISION COMPUT, V27, P1194, DOI 10.1016/j.imavis.2008.11.008
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chattopadhyay P, 2015, PATTERN RECOGN LETT, V63, P9, DOI 10.1016/j.patrec.2015.06.004
   Cheng MH, 2008, PATTERN RECOGN, V41, P2541, DOI 10.1016/j.patcog.2007.11.021
   Das Choudhury S, 2012, PATTERN RECOGN, V45, P3414, DOI 10.1016/j.patcog.2012.02.032
   Diaz-Más L, 2010, PATTERN RECOGN, V43, P2119, DOI 10.1016/j.patcog.2010.01.001
   Drinkwater D, 1980, KINANTHROPOMETRY 2, P178
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hofmann M., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P399, DOI 10.1109/BTAS.2012.6374606
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Iwashita Y, 2014, PATTERN RECOGN LETT, V48, P60, DOI 10.1016/j.patrec.2014.04.004
   Jean F, 2009, PATTERN RECOGN, V42, P2936, DOI 10.1016/j.patcog.2009.05.006
   Jegoon Ryu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3209, DOI 10.1109/ICIP.2011.6116351
   Jeong S, 2013, J SUPERCOMPUT, V65, P122, DOI 10.1007/s11227-013-0897-8
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Kale A, 2003, LECT NOTES COMPUT SC, V2688, P706
   Kastaniotis D, 2015, PATTERN RECOGN LETT, V68, P327, DOI 10.1016/j.patrec.2015.06.020
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Lee CP, 2013, PATTERN RECOGN LETT, V34, P663, DOI 10.1016/j.patrec.2013.01.013
   Liu NN, 2010, INT CONF ACOUST SPEE, P1410, DOI 10.1109/ICASSP.2010.5495466
   López-Fernández D, 2014, LECT NOTES COMPUT SC, V8703, P26, DOI 10.1007/978-3-319-13323-2_3
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Mowbray SD, 2003, LECT NOTES COMPUT SC, V2688, P566
   Rougier C, 2011, IEEE ENG MED BIO, P5136, DOI 10.1109/IEMBS.2011.6091272
   Shakhnarovich G, 2001, PROC CVPR IEEE, P439
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Sungjun Hong, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P647, DOI 10.1109/ICIEA.2009.5138285
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Yamauchi Koichiro, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P45, DOI 10.1109/CVPR.2009.5204296
   Yu SQ, 2006, LECT NOTES COMPUT SC, V3851, P807
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 44
TC 12
Z9 12
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR-MAY
PY 2016
VL 48-49
BP 1
EP 13
DI 10.1016/j.imavis.2016.01.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO4GS
UT WOS:000377740400001
DA 2024-07-18
ER

PT J
AU Alvarez-Meza, AM
   Molina-Giraldo, S
   Castellanos-Dominguez, G
AF Alvarez-Meza, A. M.
   Molina-Giraldo, S.
   Castellanos-Dominguez, G.
TI Background modeling using Object-based Selective Updating and
   Correntropy adaptation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Background modeling; Learning rate; Correntropy-based adaptation; Moving
   object detection
ID SUBTRACTION; PEOPLE
AB Background modeling is widely used in visual surveillance systems aiming to facilitate analysis of real-world video scenes. The goal is to discriminate between pixels from foreground objects and those ones from the background. However, real-world scenarios tend to have time and spatial non-stationary variations, being difficult to reveal the foreground and background entities from video data. Here, we propose a novel adaptive background modeling, termed Object-based Selective Updating with Correntropy (OSUC), to support video-based surveillance systems. Our approach that is developed within an adaptive learning framework unveils existing spatio-temporal pixel relationships, making use of a single Gaussian for the model representation stage. Moreover, we introduce a background updating scheme composed of an updating rule that is based on the stochastic gradient algorithm and Correntropy cost function. As a result, this scheme can extract the temporal statistical pixel distribution, at the same time, dealing with non-stationary pixel value fluctuations that affect the background model. Here, an automatic tuning strategy of the cost function bandwidth parameter is carried out that can handle both Gaussian and non-Gaussian noise environments. Besides, to include pixel spatial relationships in the background modeling processing, we introduce an object-based selective learning rate strategy for enhancing the background modeling accuracy. Particularly, an object motion analysis stage is presented to detect and track foreground entities based on pixel intensities and motion direction attained via optical flow computation. Testing is provided on well-known datasets for discriminating between foreground and background that include stationary and non-stationary behaviors. Achieved results show that the OSUC outperforms, in most of the considered cases, the-state-of-the-art approaches with an affordable computational cost. Therefore, the proposed approach is suitable for supporting real-world video-based surveillance systems. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Alvarez-Meza, A. M.; Molina-Giraldo, S.; Castellanos-Dominguez, G.] Univ Nacl Colombia, Signal Proc & Recognit Grp, Manizales, Colombia.
C3 Universidad Nacional de Colombia
RP Alvarez-Meza, AM (corresponding author), Signal Proc & Recognit Grp, Km 7 Via Magdalena,Campus Nubia,Bloque 5, Bogota, Colombia.
EM amalavarezme@unal.edu.co; smolinag@unal.edu.co;
   cgcastellanosd@unal.edu.co
OI Alvarez-Meza, Andres/0000-0003-0308-9576
FU PhD. scholarship - Colciencias; projects "Plataforma tecnologica para
   los servicios de teleasistencia, emergencias medicas, seguimiento y
   monitoreo permanente de pacientes y apoyo a los programas de prevencion"
   - ARTICA; Universidad Nacional de Colombia [16882]; Universidad de
   Caldas
FX Research supported by a PhD. scholarship funded by Colciencias and the
   projects "Plataforma tecnologica para los servicios de teleasistencia,
   emergencias medicas, seguimiento y monitoreo permanente de pacientes y
   apoyo a los programas de prevencion" - ARTICA and project 16882 funded
   by Universidad Nacional de Colombia and Universidad de Caldas.
CR [Anonymous], 2012, P ACM SIGKDD WORKSH, DOI DOI 10.1109/KNN.2012.6252495
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bloisi DD, 2014, MACH VISION APPL, V25, P1257, DOI 10.1007/s00138-013-0554-5
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Brendel W, 2009, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2009.5459242
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Chen ZZ, 2014, COMPUT VIS IMAGE UND, V122, P35, DOI 10.1016/j.cviu.2014.01.004
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   García J, 2013, IEEE T IND ELECTRON, V60, P3991, DOI 10.1109/TIE.2012.2206330
   Gong BQ, 2014, INT J COMPUT VISION, V109, P3, DOI 10.1007/s11263-014-0718-4
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guo JM, 2013, IEEE T CIRC SYST VID, V23, P1809, DOI 10.1109/TCSVT.2013.2269011
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Jabri S, 2000, INT C PATT RECOG, P627, DOI 10.1109/ICPR.2000.902997
   Jie Shao, 2011, Journal of Multimedia, V6, P33, DOI 10.4304/jmm.6.1.33-38
   Kim H, 2008, ELECTRON LETT, V44, P189, DOI 10.1049/el:20083126
   Kim W, 2012, IEEE SIGNAL PROC LET, V19, P127, DOI 10.1109/LSP.2011.2182648
   Kivinen J., 2010, IEEE Transactions on Signal Processing, V100, P1
   Lin HH, 2011, IEEE T IMAGE PROCESS, V20, P822, DOI 10.1109/TIP.2010.2075938
   Ling Q, 2014, NEUROCOMPUTING, V133, P32, DOI 10.1016/j.neucom.2013.11.034
   Liu WF, 2008, IEEE T SIGNAL PROCES, V56, P543, DOI 10.1109/TSP.2007.907881
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Maddalena L, 2014, COMPUT VIS IMAGE UND, V122, P65, DOI 10.1016/j.cviu.2013.11.006
   Molina-Giraldo S, 2015, ADV INTELL SYST, V318, P273, DOI 10.1007/978-3-319-12610-4_17
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Räty TD, 2010, IEEE T SYST MAN CY C, V40, P493, DOI 10.1109/TSMCC.2010.2042446
   Sánchez A, 2012, INTEGR COMPUT-AID E, V19, P239, DOI 10.3233/ICA-2012-0402
   Santamaría I, 2006, IEEE T SIGNAL PROCES, V54, P2187, DOI 10.1109/TSP.2006.872524
   Scholkopf B., 2002, Encyclopedia of Biostatistics
   Shah M, 2014, MACH VISION APPL, V25, P1105, DOI 10.1007/s00138-013-0552-7
   Singh Abhishek, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P2950, DOI 10.1109/IJCNN.2009.5178823
   Sobral A., 2013, P 9 WORKSH VIS COMP P 9 WORKSH VIS COMP, P38
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   Wong S, 2002, EUROMICRO CONF PROC, P183, DOI 10.1109/EURMIC.2002.1046155
   Zhang R, 2013, IEEE SIGNAL PROC LET, V20, P1266, DOI 10.1109/LSP.2013.2288579
   Zhou DX, 2005, IEEE SYS MAN CYBERN, P2224
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 41
TC 6
Z9 6
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2016
VL 45
BP 22
EP 36
DI 10.1016/j.imavis.2015.11.006
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DE8PY
UT WOS:000370900000003
DA 2024-07-18
ER

PT J
AU Hamza, A
   Hafiz, R
   Khan, MM
   Cho, Y
   Cha, J
AF Hamza, Ameer
   Hafiz, Rehan
   Khan, Muhammad M.
   Cho, Yongju
   Cha, Jihun
TI Stabilization of panoramic videos from mobile multi-camera platforms
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Panoramic Videos; Video Stabilization; Video Stitching; Mobile
   multi-camera platforms
ID DIGITAL IMAGE STABILIZATION
AB Wide field of view panoramic videos have recently become popular due to the availability of high resolution displays. These panoramic videos are generated by stitching video frames captured from a panoramic video acquisition system, typically comprising of multiple video cameras arranged on a static or mobile platform. A mobile panoramic video acquisition system may suffer from global mechanical vibrations as well as independent inter-camera vibrations resulting in a jittery panoramic video. While existing stabilization schemes generally tackle single-camera vibrations, they do not account for these inter-camera vibrations. In this paper, we propose a video stabilization technique for multi-camera panoramic videos under the consideration that independent jitter may be exhibited by content of each camera. The proposed method comprises of three steps; the first step removes the global jitter in the video by estimating collective motion and subsequently removing the high frequency component from it. The second step removes the independent i.e. local jitter of each camera by estimating motion of each camera content separately. Pixels that are located in the overlapping regions of panoramic video are contributed by neighboring cameras, therefore, the estimated camera motion for these pixels is weighted using the blend masks generated by the stitching process. The final step applies local geometric warping to the stitched frames and removes any residual jitter induced due to parallax. Experimental results prove that proposed scheme performs better than existing panoramic stabilization schemes. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Hamza, Ameer; Hafiz, Rehan; Khan, Muhammad M.] NUST, SEECS, VISpro Lab, Islamabad, Pakistan.
   [Cho, Yongju; Cha, Jihun] Elect & Telecommun Res Inst, Taejon, South Korea.
C3 National University of Sciences & Technology - Pakistan; Electronics &
   Telecommunications Research Institute - Korea (ETRI)
RP Hafiz, R (corresponding author), NUST, SEECS, VISpro Lab, Islamabad, Pakistan.
EM rehanhafiz@gmail.com
RI Khan, Muhammad Murtaza/K-9719-2015; Hamza, Ameer/IYI-9183-2023
OI Hafiz, Rehan/0000-0002-5062-3068; Khan, Muhammad
   Murtaza/0000-0002-3255-4812
FU MKE/ETRI [14ZR1110]
FX We would like to thank IT R&D program of MKE/ETRI (14ZR1110, HCI based
   UHD Panorama Technology Development) for their generous funding.
CR [Anonymous], 1999, SUBJ VID QUAL ASS ME
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Anwar-ul-Haq, INT C DIG IM COMP TE, P411
   Battiato S, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P373, DOI 10.1109/ICME.2008.4607449
   Battiato S, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P825, DOI 10.1109/ICIAP.2007.4362878
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Buehler C, 2001, PROC CVPR IEEE, P609
   Chang HC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P29, DOI 10.1109/ICME.2004.1394117
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ertürk S, 2003, IEEE T CONSUM ELECTR, V49, P1320, DOI 10.1109/TCE.2003.1261235
   Ertürk S, 2002, REAL-TIME IMAGING, V8, P317, DOI 10.1006/rtim.2001.0278
   Fehn C, 2007, INT J SEMANT COMPUT, V1, P171, DOI 10.1142/S1793351X07000135
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gledhill D, 2003, COMPUT GRAPH-UK, V27, P435, DOI 10.1016/S0097-8493(03)00038-4
   Hu R, 2007, IEEE INT CONF INF VI, P871
   Kamali M., C MACH VIS APPL 2011, P177
   Kimber D., 2001, P 9 ACM INT C MULT 2, P339
   Lee J, 2009, IEEE T CONSUM ELECTR, V55, P1748, DOI 10.1109/TCE.2009.5373727
   Lee KY, 2009, IEEE I CONF COMP VIS, P1397
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lucas B.D., DARPA IMAGE UNDERSTA
   Majumder A, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P169, DOI 10.1145/319463.319485
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Matsushita Y, 2005, PROC CVPR IEEE, P50
   Puglisi G, 2011, IEEE T CIRC SYST VID, V21, P1390, DOI 10.1109/TCSVT.2011.2162689
   Pulli K, 2012, COMMUN ACM, V55, P61, DOI 10.1145/2184319.2184337
   Ryu YG, 2012, IEEE SIGNAL PROC LET, V19, P223, DOI 10.1109/LSP.2012.2188286
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Vogler C, 2007, IMAGE VISION COMPUT, V25, P274, DOI 10.1016/j.imavis.2005.10.010
   Wu S., 2003, COMP VIS PATT REC WO, V5, P57
   Xu LD, 2006, IEEE T CONSUM ELECTR, V52, P566, DOI 10.1109/TCE.2006.1649681
   Yang JL, 2006, IEEE IMAGE PROC, P1545, DOI 10.1109/ICIP.2006.312645
   Zhu W, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-5, P702, DOI 10.1109/ROBIO.2007.4522248
NR 36
TC 15
Z9 19
U1 2
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2015
VL 37
BP 20
EP 30
DI 10.1016/j.imavis.2015.02.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CI8NK
UT WOS:000355028800003
DA 2024-07-18
ER

PT J
AU López-Rubio, FJ
   López-Rubio, E
AF Javier Lopez-Rubio, Francisco
   Lopez-Rubio, Ezequiel
TI Local color transformation analysis for sudden illumination change
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Background modeling; Foreground detection; Illumination invariance;
   Color transformation
ID BACKGROUND SUBTRACTION
AB Sudden illumination changes are a fundamental problem in background modeling applications. Most strategies to solve it are based on determining the particular form of the color transformation which the pixels undergo when an illumination change occurs. Here we present an approach which does not assume any specific form of the color transformation. It is based on a quantitative assessment of the smoothness of the local color transformation from one frame to the background model. In addition to this, an assessment of the obtained illumination states of the pixels is carried out with the help of fuzzy logic. Experimental results are presented, which demonstrate the performance of our approach in a range of situations. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Javier Lopez-Rubio, Francisco; Lopez-Rubio, Ezequiel] Univ Malaga, Dept Comp Languages & Comp Sci, E-29071 Malaga, Spain.
C3 Universidad de Malaga
RP López-Rubio, E (corresponding author), Univ Malaga, Dept Comp Languages & Comp Sci, Bulevar Louis Pasteur 35, E-29071 Malaga, Spain.
EM xavierprof@hotmail.com; ezeqlr@lcc.uma.es
RI López-Rubio, Ezequiel/N-7753-2019
OI López-Rubio, Ezequiel/0000-0001-8231-5687; Lopez Rubio, Francisco
   Javier/0000-0002-9891-266X
FU Ministry of Economy and Competitiveness of Spain [TIN2011-24141];
   Autonomous Government of Andalusia (Spain) [TIC-6213, TIC-657]; European
   Regional Development Fund (ERDF)
FX This work is partially supported by the Ministry of Economy and
   Competitiveness of Spain under grant TIN2011-24141, project name
   Detection of anomalous activities in video sequences by self-organizing
   neural systems. It is also partially supported by the Autonomous
   Government of Andalusia (Spain) under projects TIC-6213, project name
   Development of Self-Organizing Neural Networks for Information
   Technologies; and TIC-657, project name Self-organizing systems and
   robust estimators for video surveillance. All of them include funds from
   the European Regional Development Fund (ERDF). The authors thankfully
   acknowledge the computer resources, technical expertise and assistance
   provided by the SCBI (Supercomputing and Bioinformatics) center of the
   University of Malaga.
CR Anderson K, 2004, COMPUT VIS IMAGE UND, V95, P184, DOI 10.1016/j.cviu.2004.01.001
   [Anonymous], 2006, 2006 IEEE COMP VIS P, DOI DOI 10.1109/CVPR.2006.106
   [Anonymous], 2007, EURASIP J APPL SIG P
   [Anonymous], IEEJ T FUNDAM MAT
   [Anonymous], INT J ADV COMPUTING
   [Anonymous], 1999, P IEEE C COMPUTER VI
   Bales M., 2011, EURASIP J IMAGE VIDE, V2011
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Ding Y, 2010, COMPUT SCI INF SYST, V7, P201, DOI [10.2298/CSIS1001201, 10.2298/CSIS1001201D]
   Dong Y, 2011, COMPUT VIS IMAGE UND, V115, P31, DOI 10.1016/j.cviu.2010.08.003
   Farcas D, 2012, MACH VISION APPL, V23, P1083, DOI 10.1007/s00138-012-0421-9
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Huerta I, 2013, NEUROCOMPUTING, V100, P183, DOI 10.1016/j.neucom.2011.10.036
   Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263
   KaewTraKulPong P., 2001, Proc. European Workshop Advanced Video Based Surveillance Systems, V1, P1
   Li J, 2012, IET IMAGE PROCESS, V6, P606, DOI 10.1049/iet-ipr.2012.0025
   Li LY, 2004, OPT ENG, V43, P2381, DOI 10.1117/1.1788694
   Liu LY, 2010, ELECTRON LETT, V46, P41, DOI 10.1049/el.2010.2833
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Mao Yan-fen, 2005, Journal of System Simulation, V17, P1182
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Reddy Vikas, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P172, DOI 10.1109/AVSS.2010.84
   Reddy V., 2012, CIRCUITS SYSTEMS VID, V232013, P83
   Shimada A., 2010, IEEJ T ELECT INFORM, P1524
   Sivabalakrishnan M, 2012, IMAGING SCI J, V60, P39, DOI 10.1179/1743131X11Y.0000000008
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toth D., 2000, 4th IEEE Southwest Symposium on Image Analysis and Interpretation, P3, DOI 10.1109/IAI.2000.839561
   Van Es JJ, 2007, SPATIAL VISION, V20, P139, DOI 10.1163/156856807779369733
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xie BL, 2004, IMAGE VISION COMPUT, V22, P117, DOI 10.1016/j.imavis.2003.07.003
   [喻夏琼 Yu Xiaqiong], 2012, [光电工程, Opto-Electronic Engineering], V39, P94
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 33
TC 9
Z9 9
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2015
VL 37
BP 31
EP 47
DI 10.1016/j.imavis.2015.03.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CI8NK
UT WOS:000355028800004
DA 2024-07-18
ER

PT J
AU Charalampous, K
   Gasteratos, A
AF Charalampous, Konstantinos
   Gasteratos, Antonios
TI A tensor-based deep learning framework
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Hierarchical Temporal Memory (HTM); Tensor algebra;
   L-1-norm; Support Vector Clustering; Spatio-temporal features
ID SUPPORT; RECOGNITION; PROJECTIONS; ALGORITHM; CORTEX; ROBUST
AB This paper presents an unsupervised deep leaming framework that derives spatio-temporal features for human-robot interaction. The respective models extract high-level features from low-level ones through a hierarchical network, viz. the Hierarchical Temporal Memory (HTM), providing at the same time a solution to the curse of dimensionality in shallow techniques. The presented work incorporates the tensor-based framework within the operation of the nodes and, thus, enhances the feature derivation procedure. This is due to the fact that tensors allow the preservation of the initial data format and their respective correlation and, moreover, attain more compact representations. The computational nodes form spatial and temporal groups by exploiting the multilinear algebra and subsequently express the samples according to those groups in terms of proximity. This generic framework may be applied in a diverse of visual data, while it has been examined on sequences of color and depth images, exhibiting remarkable performance. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Charalampous, Konstantinos; Gasteratos, Antonios] Democritus Univ Thrace, Dept Prod & Management Engn, GR-67100 Xanthi, Greece.
C3 Democritus University of Thrace
RP Charalampous, K (corresponding author), Democritus Univ Thrace, Dept Prod & Management Engn, Vas Sofias 12,Bldg 1,Off 205, GR-67100 Xanthi, Greece.
EM kchara@pme.duth.gr; agaster@pme.duth.gr
RI Gasteratos, Antonios/B-7796-2012; Gasteratos, Antonios/AAI-4740-2021
OI Gasteratos, Antonios/0000-0002-5421-0332
CR [Anonymous], PROC CVPR IEEE
   [Anonymous], 2008, THESIS STANFORD U
   [Anonymous], T PATTERN ANAL MACH
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   [Anonymous], 2012, IMPROVING NEURAL NET
   [Anonymous], 2004, Advances in Neural Information Processing Systems
   [Anonymous], ORG PRINCIPLE CEREBR
   [Anonymous], 2009, BMVC 2009 BRIT MACH
   [Anonymous], 2005, ADV NEURAL INFORM PR
   [Anonymous], 2012, NIPS
   Bazzani L., 2011, P 28 INT C MACH LEAR, P937, DOI [DOI 10.5555/3104482.3104600, 10.5555/3104482.3104600]
   Ben-Hur A, 2002, J MACH LEARN RES, V2, P125, DOI 10.1162/15324430260185565
   Ben-Hur A, 2001, ADV NEUR IN, V13, P367
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125
   Charalampous K, 2012, ELECTRON LETT, V48, P1259, DOI 10.1049/el.2012.1033
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Chiang JH, 2003, IEEE T FUZZY SYST, V11, P518, DOI 10.1109/TFUZZ.2003.814839
   Tao DC, 2007, KNOWL INF SYST, V13, P1, DOI 10.1007/s10115-006-0050-6
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   FLETCHER R., 1987, PRACTICAL METHODS OP
   George D, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000532
   Guo WW, 2012, IEEE T IMAGE PROCESS, V21, P816, DOI 10.1109/TIP.2011.2165291
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang F. J., 2006, 2006 IEEE COMP SOC C, V1, P284, DOI DOI 10.1109/CVPR.2006.164
   Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Ko B, 2013, IMAGE VISION COMPUT, V31, P786, DOI 10.1016/j.imavis.2013.08.001
   Kostavelis I, 2012, PATTERN RECOGN LETT, V33, P670, DOI 10.1016/j.patrec.2011.11.017
   Kotsia I, 2012, PATTERN RECOGN, V45, P4192, DOI 10.1016/j.patcog.2012.04.033
   Kotsia I, 2011, PROC CVPR IEEE, P633, DOI 10.1109/CVPR.2011.5995663
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Lee J, 2005, IEEE T PATTERN ANAL, V27, P461, DOI 10.1109/TPAMI.2005.47
   Lee J, 2006, IEEE T PATTERN ANAL, V28, P1869, DOI 10.1109/TPAMI.2006.225
   Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Norouzi Mohammad, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2735, DOI 10.1109/CVPRW.2009.5206577
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Ranzato MA., 2007, CVPR, DOI [10.1109/cvpr.2007.383157, 10.1109/CVPR.2007.383157]
   Ranzato M, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995710
   Rodriguez M. D., 2008, C COMPUTER VISION PA, P1, DOI [10.1109/CVPR.2008A587727, DOI 10.1109/CVPR.2008A587727]
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Tang Y., 2010, ICML 2010, P1055
   Tao D., 2006, Computer_Vision_and_Pattern Recognition, P1670
   Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881
   von Melchner L, 2000, NATURE, V404, P871, DOI 10.1038/35009102
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Xiaofei He, 2005, 13th Annual ACM International Conference on Multimedia, P132
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Yang JH, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P898
   Zafeiriou S, 2009, IEEE T NEURAL NETWOR, V20, P217, DOI 10.1109/TNN.2008.2005293
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
NR 63
TC 8
Z9 8
U1 0
U2 44
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 916
EP 929
DI 10.1016/j.imavis.2014.08.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900009
DA 2024-07-18
ER

PT J
AU Girard, JM
   Cohn, JF
   Mahoor, MH
   Mavadati, SM
   Hammal, Z
   Rosenwald, DP
AF Girard, Jeffrey M.
   Cohn, Jeffrey F.
   Mahoor, Mohammad H.
   Mavadati, S. Mohammad
   Hammal, Zakia
   Rosenwald, Dean P.
TI Nonverbal social withdrawal in depression: Evidence from manual and
   automatic analyses
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depression; Multimodal; FACS; Facial expression; Head motion
ID FACIAL EXPRESSION; MAJOR DEPRESSION; EMOTION; SCHIZOPHRENIA; BEHAVIOR;
   METAANALYSIS; HYPOTHESIS; REACTIVITY; EXPERIENCE; DOMINANCE
AB The relationship between nonverbal behavior and severity of depression was investigated by following depressed participants over the course of treatment and video recording a series of clinical interviews. Facial expressions and head pose were analyzed from video using manual and automatic systems. Both systems were highly consistent for FACS action units (AUs) and showed similar effects for change over time in depression severity. When symptom severity was high, participants made fewer affiliative facial expressions (AUs 12 and 15) and more non-affiliative facial expressions (AU 14). Participants also exhibited diminished head motion (i.e., amplitude and velocity) when symptom severity was high. These results are consistent with the Social Withdrawal hypothesis: that depressed individuals use nonverbal behavior to maintain or increase interpersonal distance. As individuals recover, they send more signals indicating a willingness to affiliate. The finding that automatic facial expression analysis was both consistent with manual coding and revealed the same pattern of findings suggests that automatic facial expression analysis may be ready to relieve the burden of manual coding in behavioral and clinical science. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Girard, Jeffrey M.; Cohn, Jeffrey F.; Rosenwald, Dean P.] Univ Pittsburgh, Dept Psychol, Pittsburgh, PA 15260 USA.
   [Cohn, Jeffrey F.; Hammal, Zakia] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   [Mahoor, Mohammad H.; Mavadati, S. Mohammad] Univ Denver, Dept Elect & Comp Engn, Denver, CO 80208 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh; Carnegie Mellon University; University of Denver
RP Girard, JM (corresponding author), Univ Pittsburgh, Dept Psychol, 4322 Sennott Sq, Pittsburgh, PA 15260 USA.
EM jmg174@pitt.edu; jeffcohn@cs.cmu.edu; mohammad.mahoor@du.edu;
   seyedmohammad.mavadati@du.edu; zakia_hammal@yahoo.fr; dpr10@pitt.edu
RI Girard, Jeffrey M/H-4088-2019
OI Girard, Jeffrey M/0000-0002-7359-3746; Mahoor,
   Mohammad/0000-0001-8923-4660
FU US National Institutes of Health [MH61435, MH65376, MH096951]
FX The authors wish to thank Nicole Siverling and Shawn Zuratovic for their
   generous assistance. This work was supported in part by the US National
   Institutes of Health grants MH61435, MH65376, and MH096951 to the
   University of Pittsburgh. Any opinions, conclusions, or recommendations
   expressed in this material are those of the authors and do not
   necessarily reflect the views of the National Institutes of Health.
CR Allen NB, 2003, PSYCHOL BULL, V129, P887, DOI 10.1037/0033-2909.129.6.887
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   [Anonymous], INT C AUT FAC GEST R
   [Anonymous], 2002, SURVEY DIMENSION RED
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2003, PRACTICAL GUIDE SUPP
   [Anonymous], CS20080923
   [Anonymous], 1972, STUDIES DYADIC COMMU
   [Anonymous], INTEGRATIVE VIEWS MO
   [Anonymous], FACIAL EXPRESSION AN
   [Anonymous], EMOTION
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Baron-Cohen S., 2003, Mind Reading: The interactive guide to emotion
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Beck A.T., 1967, DEPRESSION
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   BERENBAUM H, 1992, J ABNORM PSYCHOL, V101, P37, DOI 10.1037/0021-843X.101.1.37
   BOWER GH, 1981, AM PSYCHOL, V36, P129, DOI 10.1037/0003-066X.36.2.129
   Brozgold A Z, 1998, Appl Neuropsychol, V5, P15, DOI 10.1207/s15324826an0501_2
   Bylsma LM, 2008, CLIN PSYCHOL REV, V28, P676, DOI 10.1016/j.cpr.2007.10.001
   Chentsova-Dutton YE, 2010, CULT DIVERS ETHN MIN, V16, P284, DOI 10.1037/a0017562
   Chew SW, 2012, IEEE T SYST MAN CY B, V42, P1006, DOI 10.1109/TSMCB.2012.2194485
   CLARK LA, 1991, J ABNORM PSYCHOL, V100, P316, DOI 10.1037/0021-843X.100.3.316
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Cohn JF, 2010, BEHAV RES METHODS, V42, P1079, DOI 10.3758/BRM.42.4.1079
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cox M., 2013, Csiro face analysis sdk
   COYNE JC, 1976, PSYCHIATRY, V39, P28, DOI 10.1080/00332747.1976.11023874
   De La Torre F, 2009, P 2009 3 INT C AFF C, P1, DOI 10.1109/ACII.2009.5349358
   DEPUE RA, 1989, ANNU REV PSYCHOL, V40, P457, DOI 10.1146/annurev.ps.40.020189.002325
   DIXON AK, 1989, PHARMACOPSYCHIATRY, V22, P44, DOI 10.1055/s-2007-1014624
   Ekman P., 2002, FACIAL ACTION CODING
   Ellgring H., 1989, Nonverbal communication in depression
   First M.B., 1995, USERS GUIDE STRUCTUR
   FISCH HU, 1983, J ABNORM PSYCHOL, V92, P307, DOI 10.1037/0021-843X.92.3.307
   Fleiss Joseph L., 1981, STAT METHODS RATES P
   FOSSI L, 1984, J NERV MENT DIS, V172, P332, DOI 10.1097/00005053-198406000-00004
   Fridlund A. J., 1994, Human Facial Expression: An Evolutionary View
   FRIJDA NH, 1995, COGNITION EMOTION, V9, P617, DOI 10.1080/02699939508408986
   Gaebel W, 2004, EUR ARCH PSY CLIN N, V254, P335, DOI 10.1007/s00406-004-0510-5
   Gehricke JG, 2000, PSYCHIAT RES, V95, P157, DOI 10.1016/S0165-1781(00)00168-2
   HAMILTON M, 1967, BRIT J SOC CLIN PSYC, V6, P278, DOI [10.1111/j.2044-8260.1967.tb00530.x, DOI 10.1111/J.2044-8260.1967.TB00530.X]
   Henriques JB, 2000, COGNITION EMOTION, V14, P711, DOI 10.1080/02699930050117684
   Hess U, 2000, J NONVERBAL BEHAV, V24, P265, DOI 10.1023/A:1006623213355
   Hess U, 2005, COGNITION EMOTION, V19, P515, DOI 10.1080/02699930441000364
   Hollon SD, 2002, PSYCHOL SCI, P39, DOI 10.1111/1529-1006.00008
   JONES IH, 1979, J NERV MENT DIS, V167, P402, DOI 10.1097/00005053-197907000-00002
   Joshi J, 2013, IEEE INT CONF AUTOMA
   KATSIKITIS M, 1991, J NERV MENT DIS, V179, P683, DOI 10.1097/00005053-199111000-00006
   Keltner D, 1997, PSYCHOL BULL, V122, P250, DOI 10.1037/0033-2909.122.3.250
   Klerman GL., 1984, INTERPERSONAL PSYCHO
   KLINGER E, 1975, PSYCHOL REV, V82, P1, DOI 10.1037/h0076171
   Knutson B, 1996, J NONVERBAL BEHAV, V20, P165, DOI 10.1007/BF02281954
   Kotov R, 2010, PSYCHOL BULL, V136, P768, DOI 10.1037/a0020327
   Mahoor Mohammad H., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P74, DOI 10.1109/CVPR.2009.5204259
   Mathers CD, 2006, PLOS MED, V3, DOI 10.1371/journal.pmed.0030442
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Mauss IB, 2005, EMOTION, V5, P175, DOI 10.1037/1528-3542.5.2.175
   Mergl R, 2005, J NEUROL NEUROSUR PS, V76, P138, DOI 10.1136/jnnp.2004.037127
   Nesse RM, 2000, ARCH GEN PSYCHIAT, V57, P14, DOI 10.1001/archpsyc.57.1.14
   Reed LI, 2007, J ABNORM PSYCHOL, V116, P804, DOI 10.1037/0021-843X.116.4.804
   Renneberg B, 2005, J BEHAV THER EXP PSY, V36, P183, DOI 10.1016/j.jbtep.2005.05.002
   Rottenberg J, 2005, J ABNORM PSYCHOL, V114, P627, DOI 10.1037/0021-843X.114.4.627
   Rottenberg J, 2002, EMOTION, V2, P135, DOI 10.1037//1528-3542.2.2.135
   Rush A.J., 2008, HDB PSYCHIAT MEASURE, V2nd
   Sakamoto S, 1997, PERCEPT MOTOR SKILL, V85, P1291, DOI 10.2466/pms.1997.85.3f.1291
   Schelde JTM, 1998, J NERV MENT DIS, V186, P133, DOI 10.1097/00005053-199803000-00001
   Scherer S, 2013, IEEE INT CONF AUTOMA
   SCHNEIDER F, 1990, EUR ARCH PSY CLIN N, V240, P67, DOI 10.1007/BF02189974
   Segrin C, 2000, CLIN PSYCHOL REV, V20, P379, DOI 10.1016/S0272-7358(98)00104-4
   SEGRIN C, 1992, J SOC CLIN PSYCHOL, V11, P43, DOI 10.1521/jscp.1992.11.1.43
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Sloan DM, 2001, J ABNORM PSYCHOL, V110, P488, DOI 10.1037//0021-843X.110.3.488
   Sloan DM, 1997, J AFFECT DISORDERS, V46, P135, DOI 10.1016/S0165-0327(97)00097-9
   Sloman L, 2003, J AFFECT DISORDERS, V74, P107, DOI 10.1016/S0165-0327(02)00116-7
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Trémeau F, 2005, AM J PSYCHIAT, V162, P92, DOI 10.1176/appi.ajp.162.1.92
   Troisi A, 1999, J PSYCHIAT RES, V33, P243, DOI 10.1016/S0022-3956(98)00064-8
   Tsai Jeanne L, 2003, Cultur Divers Ethnic Minor Psychol, V9, P49, DOI 10.1037/1099-9809.9.1.49
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   YOUNGREN MA, 1980, J ABNORM PSYCHOL, V89, P333, DOI 10.1037/0021-843X.89.3.333
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhu Y., 2007, INFORM FUSION 2007 1, P1
NR 85
TC 150
Z9 162
U1 2
U2 48
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 641
EP 647
DI 10.1016/j.imavis.2013.12.007
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700003
PM 25378765
OA Green Accepted
DA 2024-07-18
ER

PT J
AU As'ari, MA
   Sheikh, UU
   Supriyanto, E
AF As'ari, M. A.
   Sheikh, U. U.
   Supriyanto, E.
TI 3D shape descriptor for object recognition based on Kinect-like depth
   image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Inter-class; Intra-class; Instance; Kinect-like depth image; 3D object
   retrieval; 3D shape descriptors
ID RETRIEVAL; SIMILARITY; SEARCH
AB 3D shape descriptor has been used widely in the field of 3D object retrieval. However, the performance of object retrieval greatly depends on the shape descriptor used. The aims of this study is to review and compare the common 3D shape descriptors proposed in 3D object retrieval literature for object recognition and classification based on Kinect-like depth image obtained from RGB-D object dataset In this paper, we introduce (I) inter-class; and (2) intra-class evaluation in order to study the feasibility of such descriptors in object recognition. Based on these evaluations, local spin image outperforms the rest in discriminating different classes when several depth images from an instance per class are used in inter-class evaluation. This might be due to the slightly consistent local shape property of such images and due to the proposed local similarity measurement that manages to extract the local based descriptor. However, shape distribution performs excellent for intra-class evaluation (that involves several instances per class) may be due to the global shape from different instances per class is slightly unchanged. These results indicate a remarkable feasibility analysis of the 3D shape descriptor in object recognition that can be potentially used for Kinect-like sensor. (C) 2014 Elsevier B.V. All rights reserved.
C1 [As'ari, M. A.; Supriyanto, E.] Univ Teknol Malaysia, Fac Biosci & Med Engn, Johor Baharu, Malaysia.
   [Sheikh, U. U.] Univ Teknol Malaysia, Fac Elect Engn, Comp Vis Video & Image Proc Res Grp CvviP, Johor Baharu, Malaysia.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia
RP As'ari, MA (corresponding author), Univ Teknol Malaysia, Fac Biosci & Med Engn, Johor Baharu, Malaysia.
EM amir-asari@biomedical.utm.my
RI Sheikh, Usman Ullah/GRO-0863-2022; Sheikh, Usman U/C-3596-2013;
   Supriyanto, Eko/AAZ-1135-2021
OI Ullah Sheikh, Usman/0000-0001-9054-093X; SUPRIYANTO,
   EKO/0000-0002-2142-8351
FU Minister of Higher Education (MOHE), Malaysia [Q.J130000.2623.08189]
FX The authors would like to express their gratitude to Universiti
   Teknologi Malaysia (UTM) and the Minister of Higher Education (MOHE),
   Malaysia for supporting this research work under Research Grant No.
   Q.J130000.2623.08189.
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], EURASIP J ADV SIGNAL
   [Anonymous], 2012, Kinect
   [Anonymous], 2003, 7 CENTR EUR SEM COMP
   [Anonymous], CONT BASED MULTIMEDI
   [Anonymous], P 28 ANN C COMP GRAP
   [Anonymous], P INT C ROB AUT ICRA
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Asari M. A., 2012, 2012 4th International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2012), P313, DOI 10.1109/CICSyN.2012.65
   Bustos B, 2007, IEEE COMPUT GRAPH, V27, P22, DOI 10.1109/MCG.2007.80
   Chang MC, 2011, COMPUT VIS IMAGE UND, V115, P707, DOI 10.1016/j.cviu.2010.10.013
   Chen D.-Y., 2003, COMP GRAPH FOR EUROG
   Corney J, 2002, IEEE COMPUT GRAPH, V22, P65, DOI 10.1109/MCG.2002.999789
   Del Bimbo A, 2006, ACM T MULTIM COMPUT, V2, P20
   El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P95, DOI 10.1016/S0010-4485(01)00178-6
   Ferreira A, 2010, INT J COMPUT VISION, V89, P327, DOI 10.1007/s11263-009-0257-6
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   KAZHDAN M, 2003, P 2003 EUR ACM SIGGR
   Lafarge F, 2010, IEEE T IMAGE PROCESS, V19, P1683, DOI 10.1109/TIP.2010.2045695
   Lai K, 2011, 25 C ART INT AAAI
   Mahmoudi S, 2002, INT C PATT RECOG, P457, DOI 10.1109/ICPR.2002.1048337
   Novotni M., 2003, P 8 ACM S SOL MOD AP
   Ohbuchi R, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P97, DOI 10.1109/TPCG.2003.1206936
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Shan Y, 2006, IEEE T PATTERN ANAL, V28, P568, DOI 10.1109/TPAMI.2006.83
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Shum HY, 1996, PROC CVPR IEEE, P526, DOI 10.1109/CVPR.1996.517122
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Suzuki M.T., 2005, 9 IASTED INT C SOFTW, P389
   Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502
   Zaharia T, 2001, PROC SPIE, V4304, P133, DOI 10.1117/12.424969
   Zhang C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P935, DOI 10.1109/ICIP.2001.958278
NR 36
TC 21
Z9 23
U1 0
U2 48
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2014
VL 32
IS 4
BP 260
EP 269
DI 10.1016/j.imavis.2014.02.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AG0MN
UT WOS:000335109700004
DA 2024-07-18
ER

PT J
AU Shi, CJ
   Ruan, QQ
   An, GY
AF Shi, Caijuan
   Ruan, Qiuqi
   An, Gaoyun
TI Sparse feature selection based on graph Laplacian for web image
   annotation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Web image annotation; Sparse feature selection; l(2,1/2)-matrix norm;
   Semi-supervised learning; Graph Laplacian
ID FRAMEWORK; RECONSTRUCTION; REGULARIZATION
AB Confronted with the explosive growth of web images, the web image annotation has become a critical research issue for image search and index. Sparse feature selection plays an important role in improving the efficiency and performance of web image annotation. Meanwhile, it is beneficial to developing an effective mechanism to leverage the unlabeled training data for large-scale web image annotation. In this paper we propose a novel sparse feature selection framework for web image annotation, namely sparse Feature Selection based on Graph Laplacian (FSLG)(2). FSLG applies the l(2,1/2)-matrix norm into the sparse feature selection algorithm to select the most sparse and discriminative features. Additional, graph Laplacian based semi-supervised learning is used to exploit both labeled and unlabeled data for enhancing the annotation performance. An efficient iterative algorithm is designed to optimize the objective function. Extensive experiments on two web image datasets are performed and the results illustrate that our method is promising for large-scale web image annotation. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Shi, Caijuan; Ruan, Qiuqi; An, Gaoyun] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Shi, Caijuan] Hebei United Univ, Coll Informat Engn, Tangshan 063009, Peoples R China.
   [Shi, Caijuan; Ruan, Qiuqi; An, Gaoyun] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; North China University of Science &
   Technology; Beijing Jiaotong University
RP Shi, CJ (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM shicaijuan2011@gmail.com; qqruan@center.njtu.edu.cn; gyan@bjtu.edu.cn
FU National Natural Science Foundation of China [61172128, 61003114];
   National Key Basic Research Program of China [2012CB316304]; Fundamental
   Research Funds for the Central Universities [2013JBM020, 2013JBZ003];
   Program for Innovative Research Team in University of Ministry of
   Education of China [IRT201206]; Doctoral Foundation of China Ministry of
   Education [20120009120009]
FX This work was supported partly by the National Natural Science
   Foundation of China (61172128, 61003114), the National Key Basic
   Research Program of China (2012CB316304), the Fundamental Research Funds
   for the Central Universities (2013JBM020, 2013JBZ003), the Program for
   Innovative Research Team in University of Ministry of Education of China
   (IRT201206) and the Doctoral Foundation of China Ministry of Education
   (20120009120009).
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], EURASIP J APPL SIGNA
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], P CIVR
   [Anonymous], I2 P MATRIX NORM ITS
   [Anonymous], FAST IMAGE DECONVOLU
   [Anonymous], 2007, Proceedings of the 24th interna- tional conference on Machine learning
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Cai D., 2010, KDD, P333
   Cawley G.C., 2006, Advances in Neural Information Processing Systems, P209
   Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300
   Chartrand R, 2009, I S BIOMED IMAGING, P262, DOI 10.1109/ISBI.2009.5193034
   Chen D, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE OF MANAGEMENT SCIENCE AND INFORMATION SYSTEM, VOLS 1-4, P1375
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Foucart S, 2009, APPL COMPUT HARMON A, V26, P395, DOI 10.1016/j.acha.2008.09.001
   Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831
   Jebara T., 2009, P 26 ANN INT C MACH, P441
   Ji SW, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1754428.1754431
   Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings, P171
   Lee WY, 2013, J VIS COMMUN IMAGE R, V24, P295, DOI 10.1016/j.jvcir.2012.12.002
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   Li H, 2009, INT CONF DAT MIN WOR, P164, DOI 10.1109/ICDMW.2009.46
   Ma Z., 2012, MM 2012 - Proceedings of the 20th ACM International Conference on Multimedia, P469, DOI DOI 10.1145/2393347.2393414
   Ma Z., 2011, Proc. 19th ACM Int'l Conf. Multimedia, P283, DOI DOI 10.1145/2072298.2072336
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Shen HF, 2010, IEEE INT CON MULTI, P980, DOI 10.1109/ICME.2010.5583900
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
   Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127
   Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412
   Xu ZB, 2010, SCI CHINA INFORM SCI, V53, P1159, DOI 10.1007/s11432-010-0090-0
   Yang Y, 2013, PATTERN RECOGN, V46, P1358, DOI 10.1016/j.patcog.2012.10.026
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009
   Zhou D., 2003, P ADV NEUR INF PROC, V16, P1
   Zhu X, 2003, ICML
   Zhu Xiaojin, 2007, 1530 U WISC
NR 42
TC 37
Z9 41
U1 1
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2014
VL 32
IS 3
BP 189
EP 201
DI 10.1016/j.imavis.2013.12.013
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AE3CG
UT WOS:000333854000003
DA 2024-07-18
ER

PT J
AU Andreu, Y
   García-Sevilla, P
   Mollineda, RA
AF Andreu, Yasmina
   Garcia-Sevilla, Pedro
   Mollineda, Ramon A.
TI Face gender classification: A statistical study when neutral and
   distorted faces are combined for training and testing purposes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face analysis; Gender classification; Global/local representation;
   Cross-database experiment
ID INVARIANT TEXTURE CLASSIFICATION; GRAY-SCALE; RECOGNITION; METHODOLOGY
AB This paper presents a thorough study of gender classification methodologies performing on neutral, expressive and partially occluded faces, when they are used in all possible arrangements of training and testing roles. A comprehensive comparison of two representation approaches (global and local), three types of features (grey levels, PCA and LBP), three classifiers (1-NN, PCA + LDA and SVM) and two performance measures (CCR and d') is provided over single- and cross-database experiments. Experiments revealed some interesting findings, which were supported by three non-parametric statistical tests: when training and test sets contain different types of faces, local models using the 1-NN rule outperform global approaches, even those using SVM classifiers; however, with the same type of faces, even if the acquisition conditions are diverse, the statistical tests could not reject the null hypothesis of equal performance of global SVMs and local 1-NN5. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Andreu, Yasmina; Garcia-Sevilla, Pedro; Mollineda, Ramon A.] Univ Jaume 1, Dept Lenguajes & Sistemas Informat, Castellon De La Plana 12071, Spain.
C3 Universitat Jaume I
RP Andreu, Y (corresponding author), Univ Jaume 1, Dept Lenguajes & Sistemas Informat, Castellon De La Plana 12071, Spain.
EM yandreu@uji.es; pgarcia@uji.es; mollined@uji.es
RI Mollineda, Ramón A/G-1260-2016
OI Garcia-Sevilla, Pedro/0000-0002-7211-7457
FU Universitat Jaume I [FPI PREDOC/2009/20, P1-1B2012-22]; Spanish
   Ministerio de Economia y Competitividad [TIN2009-14205-C04-04]
FX This work has been partially funded by Universitat Jaume I through grant
   FPI PREDOC/2009/20 and project P1-1B2012-22, and project
   TIN2009-14205-C04-04 from the Spanish Ministerio de Economia y
   Competitividad.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alcalá-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255
   [Anonymous], ICPR
   [Anonymous], 2008, LEARNING OPENCV COMP
   [Anonymous], PATTERN RECOGNIT LET
   [Anonymous], J STAT ED
   [Anonymous], P INT C COMM COMP SE
   [Anonymous], FACIAL EXPRESSION AN
   [Anonymous], INT J MULTIMED UBIQU
   [Anonymous], INT J COMPUT INTELL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Baudouin JY, 2002, J EXP PSYCHOL LEARN, V28, P362, DOI 10.1037/0278-7393.28.2.362
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Buchala S, 2005, INT J NEURAL SYST, V15, P121, DOI 10.1142/S0129065705000074
   Chen L, 2005, PATTERN RECOGN, V38, P799, DOI 10.1016/j.patcog.2004.11.003
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Hole G., 2010, FACE PROCESSING PSYC
   HOLM S, 1979, SCAND J STAT, V6, P65
   IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Martinez A., 1998, AR FACE DATABASE
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   O'Toole AJ, 1998, MEM COGNITION, V26, P146, DOI 10.3758/BF03211378
   Oh HJ, 2008, IMAGE VISION COMPUT, V26, P1515, DOI 10.1016/j.imavis.2008.04.016
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rajagopalan AN, 2007, PATTERN RECOGN LETT, V28, P335, DOI 10.1016/j.patrec.2006.04.003
   Toews M, 2009, IEEE T PATTERN ANAL, V31, P1567, DOI 10.1109/TPAMI.2008.233
   Turkowski K, 1990, GRAPHICS GEMS, P147, DOI DOI 10.1016/B978-0-08-050753-8.50042-5
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang WK, 2011, LECT NOTES COMPUT SC, V7098, P214, DOI 10.1007/978-3-642-25449-9_27
   Zhao W., 2006, FACE PROCESSING ADV
NR 43
TC 21
Z9 21
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2014
VL 32
IS 1
BP 27
EP 36
DI 10.1016/j.imavis.2013.11.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AB0RV
UT WOS:000331500700003
OA Green Published
DA 2024-07-18
ER

PT J
AU Ning, JF
   Shi, WZ
   Yang, SQ
   Yanne, P
AF Ning, Jifeng
   Shi, Wuzhen
   Yang, Shuqin
   Yanne, Paul
TI Visual tracking based on Distribution Fields and online weighted
   multiple instance learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Distribution Fields; Weighted-geometric-mean multiple instance learning;
   Discriminative classifier; Object tracking
AB This paper presents an improved multiple instance learning (MIL) tracker representing target with Distribution Fields (DFs) and building a weighted-geometric-mean MIL classifier. Firstly, we adopt OF layer as feature instead of traditional Haar-like one to model the target thanks to the DF specificity and the landscape smoothness. Secondly, we integrate sample importance into the weighted-geometric-mean MIL model and derive an online approach to maximize the bag likelihood by AnyBoost gradient framework to select the most discriminative layers. Due to the target model consisting of selected discriminative layers, our tracker is more robust while needing fewer features than the traditional Haar-like one and the original DFs one. The experimental results show higher performances of our tracker than those of five state-of-the-art ones on several challenging video sequences. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Ning, Jifeng; Shi, Wuzhen; Yanne, Paul] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Peoples R China.
   [Yang, Shuqin] Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Peoples R China.
C3 Northwest A&F University - China; Northwest A&F University - China
RP Shi, WZ (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Peoples R China.
EM jf_ning@sina.com; cvwzhshi@gmail.com; yangshuqin1978@163.com;
   pyanne@nwsuaf.edu.cn
FU National Natural Science Foundation of China [61003151]; Fundamental
   Research Funds for the Central Universities [QN2013055, QN2013062]
FX This work is supported by the National Natural Science Foundation of
   China under Grants 61003151 and the Fundamental Research Funds for the
   Central Universities under Grant QN2013055 and QN2013062.
CR [Anonymous], 2005, Proc._Neural_Information_Processing_System
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bibby C, 2008, LECT NOTES COMPUT SC, V5303, P831, DOI 10.1007/978-3-540-88688-4_61
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Czyz J, 2007, IMAGE VISION COMPUT, V25, P1271, DOI 10.1016/j.imavis.2006.07.027
   Dollr P., 2007, IEEE C COMP VIS PATT, V33, P1619
   Freedman D, 2004, IEEE T IMAGE PROCESS, V13, P518, DOI 10.1109/TIP.2003.821445
   Fröba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Huang C, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P401
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Li SX, 2010, IMAGE VISION COMPUT, V28, P424, DOI 10.1016/j.imavis.2009.06.012
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Mason L, 2000, ADV NEUR IN, P221
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Xu X, 2004, LECT NOTES ARTIF INT, V3056, P272
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
NR 28
TC 13
Z9 20
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2013
VL 31
IS 11
BP 853
EP 863
DI 10.1016/j.imavis.2013.09.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 268PX
UT WOS:000328184100003
DA 2024-07-18
ER

PT J
AU Merino-Gracia, C
   Mirmehdi, M
   Sigut, J
   González-Mora, JL
AF Merino-Gracia, Carlos
   Mirmehdi, Majid
   Sigut, Jose
   Gonzalez-Mora, Jose L.
TI Fast perspective recovery of text in natural scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Scene text extraction; Perspective recovery; Homography rectification
AB Cheap, ubiquitous, high-resolution digital cameras have led to opportunities that demand camera-based text understanding, such as wearable computing or assistive technology. Perspective distortion is one of the main challenges for text recognition in camera captured images since the camera may often not have a fronto-parallel view of the text. We present a method for perspective recovery of text in natural scenes, where text can appear as isolated words, short sentences or small paragraphs (as found on posters, billboards, shop and street signs etc.). It relies on the geometry of the characters themselves to estimate a rectifying homography for every line of text, irrespective of the view of the text over a large range of orientations. The horizontal perspective foreshortening is corrected by fitting two lines to the top and bottom of the text, while the vertical perspective foreshortening and shearing are estimated by performing a linear regression on the shear variation of the individual characters within the text line. The proposed method is efficient and fast. We present comparative results with improved recognition accuracy against the current state-of-the-art. (C) 2013 Elsevier BM. All rights reserved.
C1 [Merino-Gracia, Carlos; Gonzalez-Mora, Jose L.] Univ La Laguna, Neurochem & Neuroimaging Lab, E-38207 San Cristobal la Laguna, Spain.
   [Merino-Gracia, Carlos; Mirmehdi, Majid] Univ Bristol, Visual Informat Lab, Bristol BS8 1TH, Avon, England.
   [Sigut, Jose] Univ La Laguna, Dept Syst Engn & Control & Comp Architecture, E-38207 San Cristobal la Laguna, Spain.
C3 Universidad de la Laguna; University of Bristol; Universidad de la
   Laguna
RP Merino-Gracia, C (corresponding author), Univ La Laguna, Neurochem & Neuroimaging Lab, E-38207 San Cristobal la Laguna, Spain.
EM cmerino@ull.es; majid@cs.bris.ac.uk; sigut@isaatc.ull.es;
   jlgonzal@ull.es
RI Gonzalez-Mora, Jose Luis/L-6100-2014
OI Gonzalez-Mora, Jose Luis/0000-0001-8920-1375; Sigut,
   Jose/0000-0002-3309-5953
FU Spanish Ministerio de Industria y Comercio [TSI-020100-2010-346]
FX This work was carried out at Bristol University by Carlos Merino-Gracia,
   who is funded by the Spanish Ministerio de Industria y Comercio (project
   TSI-020100-2010-346).
CR [Anonymous], 1983, P IEEE MEL
   [Anonymous], 2007, P CBDAR
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2000, Computational Geometry Algorithms and Applications
   Cambra A. B., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P64, DOI 10.1109/ICCVW.2011.6130223
   Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223
   Clark P, 2003, PATTERN RECOGN, V36, P2673, DOI 10.1016/S0031-3203(03)00132-8
   Clark P., 2002, International Journal on Document Analysis and Recognition, V4, P243, DOI 10.1007/s10032-001-0072-2
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Gao J, 2001, PROC CVPR IEEE, P84
   Karatzas D, 2011, PROC INT CONF DOC, P1485, DOI 10.1109/ICDAR.2011.295
   Li LL, 2010, IEEE T PATTERN ANAL, V32, P755, DOI 10.1109/TPAMI.2009.196
   Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Mancas-Thillou C, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/64295
   Merino-Gracia Carlos, 2012, Camera-Based Document Analysis and Recognition. 4th International Workshop, CBDAR 2011. Revised Selected Papers, P29, DOI 10.1007/978-3-642-29364-1_3
   Myers G. K., 2005, International Journal on Document Analysis and Recognition, V7, P147, DOI 10.1007/s10032-004-0133-4
   Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820
   Pilu M, 2001, PROC CVPR IEEE, P363
   Posner I, 2010, IEEE INT C INT ROBOT, P3181, DOI 10.1109/IROS.2010.5653151
   Saba T, 2011, ARTIF INTELL REV, V35, P101, DOI 10.1007/s10462-010-9186-6
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Stamatopoulos N, 2011, IEEE T IMAGE PROCESS, V20, P910, DOI 10.1109/TIP.2010.2080280
   Tang YY, 1996, PATTERN RECOGN, V29, P1931, DOI 10.1016/S0031-3203(96)00044-1
   Targhi AT, 2006, LECT NOTES COMPUT SC, V3851, P70
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Yamaguchi T., 2005, International Journal on Document Analysis and Recognition, V7, P168, DOI 10.1007/s10032-004-0136-1
   Yi-Feng Pan, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P6, DOI 10.1109/ICDAR.2009.97
NR 28
TC 16
Z9 21
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 714
EP 724
DI 10.1016/j.imavis.2013.07.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900003
DA 2024-07-18
ER

PT J
AU Khokhar, S
   Saleemi, I
   Shah, M
AF Khokhar, S.
   Saleemi, I.
   Shah, M.
TI Multi-agent event recognition by preservation of spatiotemporal
   relationships between probabilistic models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Football play recognition; Multi-agent activity modeling and
   recognition; Graph matching; Lie algebra
ID ASSIGNMENT
AB We present a new method for multi-agent activity analysis and recognition that uses low level motion features and exploits the inherent structure and recurrence of motion present in multi-agent activity scenarios. Our representation is inspired by the need to circumvent the difficult problem of tracking in multi-agent scenarios and the observation that for many visual multi-agent recognition tasks, the spatiotemporal description of events irrespective of agent identity is sufficient for activity classification.
   We begin by learning generative models describing motion induced by individual actors or groups, which are considered to be agents. These models are Gaussian mixture distributions learned by linking clusters of optical flow to obtain contiguous regions of locally coherent motion. These possibly overlapping regions or segments, known as motion patterns are then used to analyze a scene by estimating their spatial and temporal relationships. The geometric transformations between two patterns are obtained by iteratively warping one pattern onto another, whereas the temporal relationships are obtained from their relative times of occurrence within videos. These motion segments and their spatio-temporal relationships are represented as a graph, where the nodes are the statistical distributions, and the edges have geometric transformations between motion patterns transformed to Lie space, as their attributes. Two activity instances are then compared by estimating the cost of attributed inexact graph matching. We demonstrate the application of our framework in the analysis of American football plays, a typical multi-agent activity. The performance analysis of our method shows that it is feasible and easily generalizable. Published by Elsevier B.V.
C1 [Khokhar, S.; Saleemi, I.; Shah, M.] Univ Cent Florida, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Khokhar, S (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.
EM skhokhar@eecs.ucf.edu; saleemi@eecs.ucf.edu; shah@eecs.ucf.edu
RI Sahoo, Sarat Kumar/J-8765-2014
OI Sahoo, Sarat Kumar/0000-0001-5734-6844; Shah,
   Mubarak/0000-0001-6172-5572
CR Allen J. E., 1994, Journal of Logic and Computation, V4, P531, DOI 10.1093/logcom/4.5.531
   [Anonymous], PAMI
   [Anonymous], ICME
   [Anonymous], PAMI
   [Anonymous], ICCV
   [Anonymous], JOINT RECOGNITION CO
   [Anonymous], IMPROVED VIDEO REGIS
   [Anonymous], CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], SNOWB LEARN WORKSH
   [Anonymous], ICIP
   [Anonymous], CVPR
   [Anonymous], CVPR
   [Anonymous], PAMI
   [Anonymous], PAMI
   [Anonymous], MULTIPLE AGENT EVENT
   [Anonymous], WORKSH APPL COMP VIS
   [Anonymous], 2016, MULTIAGENT SYSTEMS
   Drummond T, 2000, INT J COMPUT VISION, V37, P21, DOI 10.1023/A:1008125412549
   Hall B.C, 2003, Lie Groups, Lie Algebras, and Representations; An Elementary Introduction
   Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005
   Hongeng Somboon., 2001, ICCV
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896
   Kuettel Daniel., 2010, CVPR
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lee J.M., 2002, Graduate Texts in Math
   Li Ruonan., 2009, CVPR
   Lin D., 2010, CVPR
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Moeslund T.B., 2006, CVIU
   Morariu Vlad., 2011, CVPR
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
NR 33
TC 6
Z9 6
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2013
VL 31
IS 9
BP 603
EP 615
DI 10.1016/j.imavis.2013.06.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220EG
UT WOS:000324564300002
DA 2024-07-18
ER

PT J
AU Zhang, X
   Fan, GL
   Chou, LS
AF Zhang, Xin
   Fan, Guoliang
   Chou, Li-shan
TI Two-layer dual gait generative models for human motion estimation from a
   single camera
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human motion estimation; Manifold learning; Manifold topology;
   Generative models; Part-whole human representation
ID RECOGNITION
AB This paper presents a two-layer gait representation framework for video-based human motion estimation that extends our recent dual gait generative models, visual gait generative model (VGGM) and kinematic gait generative model (KGGM), with a new capability of part-whole gait modeling. Specifically, the idea of gait manifold learning is revisited to capture the gait variability among different individuals at both whole and part levels. A key issue is the selection of an appropriate distance metric to evaluate the dissimilarity between two gaits (either at whole or part levels) that determines an optimal manifold topology. Several metrics are studied and compared in terms of their effectiveness for gait manifold learning at both whole and part levels. This work involves one whole-based and two part-level gait manifolds by which three pairs of KGGM and VGGM can be learned and integrated for part-whole gait modeling. Moreover, a two-stage Monte Carlo Markov Chain (MCMC) inference algorithm is developed for video-based part-whole motion estimation. The proposed algorithm is tested on the HumanEva data and reaches state-of-art results. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Zhang, Xin] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Fan, Guoliang] Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74078 USA.
   [Chou, Li-shan] Univ Oregon, Dept Human Physiol, Eugene, OR 97403 USA.
C3 South China University of Technology; Oklahoma State University System;
   Oklahoma State University - Stillwater; University of Oregon
RP Fan, GL (corresponding author), Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74078 USA.
EM eexinzhang@scut.edu.cn; guoliang.fan@okstate.edu; chou@uoregon.edu
FU National Science Foundation (NSF) [IIS-0347613]; Oklahoma Center for the
   Advancement of Science and Technology (OCAST) [HR09-030, HR12-30];
   National Science Foundation of China (NSFC) [61202292]; Fundamental
   Research Funds for Central Universities of China [2012M0022]
FX This work is supported by the National Science Foundation (NSF) under
   Grant IIS-0347613, two OHRS awards (HR09-030 and HR12-30) from the
   Oklahoma Center for the Advancement of Science and Technology (OCAST),
   the National Science Foundation of China (NSFC) (No. 61202292) and the
   Fundamental Research Funds for Central Universities of China (No.
   2012M0022).
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   [Anonymous], P EUR C COMP VIS
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], CVPR 2 WORKSH EV ART
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2003, ADV NEURAL INFORM PR
   Athitsos V., 2000, P IEEE INT C COMP VI
   BRUBAKER M, 2006, P NIPS WORKSH EV ART
   Brubaker MA, 2010, INT J COMPUT VISION, V87, P140, DOI 10.1007/s11263-009-0274-5
   Canton-Ferrer C., 2008, P C ART MOT DEF OBJ
   CHENG SY, 2007, P CVPR 2 WORKSH EV A
   Corazza S, 2010, INT J COMPUT VISION, V87, P156, DOI 10.1007/s11263-009-0284-3
   Elgammal A, 2009, IEEE T PATTERN ANAL, V31, P520, DOI 10.1109/TPAMI.2008.101
   Fan GL, 2011, IEEE INT WORKS MACH
   Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1
   Grochow K., 2004, P SIGGRAPH
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Husz Z.L., 2007, P IEEE CVPR 2 WORKSH
   Huttenlocher D., 2004, P COMP VIS PATT REC
   LAWRENCE ND, 2007, P INT C MACH LEARN
   Lee CS, 2010, INT J COMPUT VISION, V87, P118, DOI 10.1007/s11263-009-0266-5
   Memisevic R, 2012, IEEE T PATTERN ANAL, V34, P778, DOI 10.1109/TPAMI.2011.154
   Peursum P, 2010, INT J COMPUT VISION, V87, P53, DOI 10.1007/s11263-009-0205-5
   POPPE RW, 2009, THESIS U TWENTE
   Raskin L., 2009, P INT C COMP VIS WOR
   Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667
   Sigal L, 2012, INT J COMPUT VISION, V98, P15, DOI 10.1007/s11263-011-0493-4
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Taylor G.W., 2010, P IEEE INT C COMP VI
   Urtasun R., 2005, P IEEE INT C COMP VI
   Urtasun R., 2006, P IEEE INT C CVPR
   Urtasun R., 2008, P INT C MACH LEARN
   vanBeck P.J.L., 1995, THESIS U TECHNOLOGY
   Vondrak M., 2008, P IEEE INT C COMP VI
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Xu X., 2007, P IEEE INT C COMP VI
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yan SC, 2009, IEEE T IMAGE PROCESS, V18, P202, DOI 10.1109/TIP.2008.2006400
   Zhang X., 2009, P IEEE ICCV WORKSH M
   Zhang X., 2010, P ACM INT C IM VID R
   Zhang X, 2010, IEEE T SYST MAN CY B, V40, P1034, DOI 10.1109/TSMCB.2010.2044240
NR 43
TC 1
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2013
VL 31
IS 6-7
BP 473
EP 486
DI 10.1016/j.imavis.2012.12.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 172UH
UT WOS:000321029900006
DA 2024-07-18
ER

PT J
AU Huang, YH
   Zhang, X
   Fan, YY
   Yin, LJ
   Seversky, L
   Allen, J
   Lei, T
   Dong, WJ
AF Huang, Yanhui
   Zhang, Xing
   Fan, Yangyu
   Yin, Lijun
   Seversky, Lee
   Allen, James
   Lei, Tao
   Dong, Weijun
TI Reshaping 3D facial scans for facial appearance modeling and 3D facial
   expression analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D facial expression recognition; 3D face modeling; 3D face scans; 3D
   model mapping
ID RECOGNITION; FACE
AB 3D face scans have been widely used for face modeling and analysis. Due to the fact that face scans provide variable point clouds across frames, they may not capture complete facial data or miss point-to-point correspondences across various facial scans, thus causing difficulties to use such data for analysis. This paper presents an efficient approach to representing facial shapes from face scans through the reconstruction of face models based on regional information and a generic model. A new approach for 3D feature detection and a hybrid approach using two vertex mapping algorithms, displacement mapping and point-to-surface mapping, and a regional blending algorithm are proposed to reconstruct the facial surface detail. The resulting models can represent individual facial shapes consistently and adaptively, establishing facial point correspondences across individual models. The accuracy of the generated models is evaluated quantitatively. The applicability of the models is validated through the application of 3D facial expression recognition using the static 3DFE and dynamic 4DFE databases. A comparison with the state of the art has also been reported. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Zhang, Xing; Yin, Lijun; Seversky, Lee; Allen, James] SUNY Binghamton, Binghamton, NY 13901 USA.
   [Huang, Yanhui; Fan, Yangyu; Lei, Tao] Northwestern Polytech Univ, Xian, Peoples R China.
   [Seversky, Lee] USAF, Res Lab, Rome, NY USA.
   [Dong, Weijun] Northwest Univ, Xian, Peoples R China.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Binghamton; Northwestern Polytechnical University; United States
   Department of Defense; United States Air Force; Northwest University
   Xi'an
RP Yin, LJ (corresponding author), SUNY Binghamton, Binghamton, NY 13901 USA.
EM lijun@cs.binghamton.edu
RI Huang, Yanhui/H-8829-2018
FU NSF [IIS-0414029, IIS-0541044, IIS-1051103]; FRL/AFOSR; NYSTAR; 863
   Program of China [2007AA01Z324]; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [1051103] Funding
   Source: National Science Foundation
FX This work was supported in part by the NSF (IIS-0414029, IIS-0541044,
   and IIS-1051103), AFRL/AFOSR, and NYSTAR; it was also supported in part
   by the 863 Program of China (No. 2007AA01Z324). This paper has been
   recommended for acceptance by Stefanos Zafeiriou.
CR [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 1963, MORSE THEORY AM 51, DOI [10.1515/9781400881802, DOI 10.1515/9781400881802]
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Berretti S., 2006, P 8 ACM INT WORKSH M
   Besl P.J., 1990, Machine Vision for Three-Dimensional Scenes, P25, DOI [10.1016/B978-0-12-266722-0.50006-3, DOI 10.1016/B978-0-12-266722-0.50006-3]
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2007, IEEE I CONF COMP VIS, P1562
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   CHANG Y, 2005, IEEE ICCV05 WORKSH A
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Dorai C., 1997, IEEE Transactions on Pattern Analysis and Machine Intelligence, V19
   Kakadiaris I., 2007, IEEE T PATTERN ANAL, V29
   Kemelmacher-Shlizerman I., 2010, IEEE T PATTERN ANAL, V32, P1
   Kittler J., 2005, CVPR05 WORKSH ADV 3D
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Lee WS, 2006, COMPUT ANIMAT VIRT W, V17, P501, DOI 10.1002/cav.152
   Lu X., 2006, Proc. IEEE Conf. Computer Vision and Pattern Recognition, V2, P1377
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mpiperis I, 2008, IEEE T INF FOREN SEC, V3, P498, DOI 10.1109/TIFS.2008.924598
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pighin F, 2002, INT J COMPUT VISION, V50, P143, DOI 10.1023/A:1020393915769
   Reale MJ, 2011, IEEE T MULTIMEDIA, V13, P474, DOI 10.1109/TMM.2011.2120600
   Savran A., 2010, CVPR10 WORKSH HUM CO
   Sidorov K., 2011, CVPR
   Sun Y., 2008, IEEE IAPR INT C PATT
   Sun Y, 2010, IEEE T SYST MAN CY A, V40, P461, DOI 10.1109/TSMCA.2010.2041659
   Wang J, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1314303.1314306
   Wang S., 2006, IEEE INT C COMP VIS
   Wang Y., 2004, COMPUTER GRAPHICS FO, V23
   Wang Y, 2008, INT J COMPUT VISION, V76, P283, DOI 10.1007/s11263-007-0063-y
   YIN L, 2008, IEEE INT C FAC GEST
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zeng Y., 2010, IEEE INT C COMP VIS
   Zeng Y., 2011, CVPR
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang Y, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P518, DOI 10.1109/CGI.2004.1309257
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 40
TC 14
Z9 15
U1 1
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2012
VL 30
IS 10
BP 750
EP 761
DI 10.1016/j.imavis.2011.12.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 027YD
UT WOS:000310389100007
DA 2024-07-18
ER

PT J
AU Luo, SQ
   Zhang, JP
   Zhang, Q
   Yuan, XR
AF Luo, Siqiang
   Zhang, Junping
   Zhang, Qian
   Yuan, Xiaoru
TI Multi-operator image retargeting with automatic integration of direct
   and indirect seam carving
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image resizing; Multi-operator; Seam carving; Cropping method; Image
   similarity
ID VISUAL-ATTENTION; MODEL
AB Multi-operator image resizing can preserve important objects and structure in an image by combining multiple image resizing operators. However, traditional multi-operator methods do not take both horizontal and vertical content-aware resizing potential into consideration, which essentially leads to squeeze/stretch effect in the resultant images. In this paper, we propose a new multi-operator scheme that addresses aforementioned issue by integrating direct and indirect seam carving. Compared with previous methods, the proposed scheme remarkably reduces the cost of deciding when to change operators, by employing a newly defined image artifact measure. Furthermore, we propose a novel seam carving enhancement, named ACcumulated Energy Seam Carving (ACESC), as a basic operator to improve global structure preservation. By combining horizontal and vertical seam carving, our scheme preserves the shapes of important objects well. We present typical results to demonstrate the effectiveness of our method. User study shows that our method has high user preference. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Luo, Siqiang; Zhang, Junping; Zhang, Qian] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China.
C3 Fudan University; Peking University
RP Zhang, JP (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China.
EM sqluo@fudan.edu.cn; jpzhang@fudan.edu.cn; 10210240044@fudan.edu.cn;
   xiaoru.yuan@pku.edu.cn
RI Luo, Siqiang/ABC-8964-2022; Luo, Siqiang/AFM-6934-2022; Yuan,
   Xiaoru/E-1798-2013
OI Luo, Siqiang/0000-0001-8197-0903; Yuan, Xiaoru/0000-0002-7233-980X
FU National Natural Science Foundation of China (NNSFC) [60975044];
   National Fundamental Research Program of China [2010CB327900]
FX We would like to thank Dr. Michael Rubinstein for valuable suggestions
   on the multi-operator retargeting algorithm. We would also like to thank
   the reviewers for their various comments, which helped improve this
   paper. This work was partially supported by the National Natural Science
   Foundation of China (NNSFC no. 60975044) and the National Fundamental
   Research Program of China (no. 2010CB327900).
CR [Anonymous], ICCV
   [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], ACM T GRAPHICS
   [Anonymous], 2008, CVPR
   [Anonymous], 2007, CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   [Anonymous], 2009, CVPR
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Bosse T, 2006, 2006 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, Proceedings, P255, DOI 10.1109/IAT.2006.2
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Ciocca G, 2007, IEEE T CONSUM ELECTR, V53, P1622, DOI 10.1109/TCE.2007.4429261
   Daniel V., 2010, P SPIE
   Deselaers T., 2008, CVPR
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Gal R., 2006, P 17 EUROGRAPHICS C, P297, DOI DOI 10.2312/EGWR/EGSR06/297-303
   Grundmann M, 2010, PROC CVPR IEEE, P569, DOI 10.1109/CVPR.2010.5540165
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Hu Y., 2005, P ACM MULT
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Karni Z, 2009, COMPUT GRAPH FORUM, V28, P1257, DOI 10.1111/j.1467-8659.2009.01503.x
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
   Zhang YF, 2008, COMPUT GRAPH FORUM, V27, P1797, DOI 10.1111/j.1467-8659.2008.01325.x
NR 34
TC 17
Z9 21
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2012
VL 30
IS 9
BP 655
EP 667
DI 10.1016/j.imavis.2012.06.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 024EV
UT WOS:000310092600006
DA 2024-07-18
ER

PT J
AU Duan, GQ
   Ai, HZ
   Xing, JL
   Cao, S
   Lao, SH
AF Duan, Genquan
   Ai, Haizhou
   Xing, Junliang
   Cao, Song
   Lao, Shihong
TI Scene Aware Detection and Block Assignment Tracking in crowded scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual surveillance; Object detection; Object tracking; Particle filter
ID MULTIPLE; OBJECTS; HUMANS
AB How far can human detection and tracking go in real world crowded scenes? Many algorithms often fail in such scenes due to frequent and severe occlusions as well as viewpoint changes. In order to handle these difficulties, we propose Scene Aware Detection (SAD) and Block Assignment Tracking (BAT) that incorporate with some available scene models (e.g. background, layout, ground plane and camera models). The SAD is proposed for accurate detection through utilizing 1) camera model to deal with viewpoint changes by rectifying sub-images, 2) a structural filter approach to handle occlusions based on a feature sharing mechanism in which a three-level hierarchical structure is built for humans, and 3) foregrounds for pruning negative and false positive samples and merging intermediate detection results. Many detection or appearance based tracking systems are prone to errors in occluded scenes because of failures of detectors and interactions of multiple objects. Differently, the BAT formulates tracking as a block assignment process, where blocks with the same label form the appearance of one object. In the BAT, we model objects on two levels, one is the ensemble level to measure how it is like an object by discriminative models, and the other one is the block level to measure how it is like a target object by appearance and motion models. The main advantage of BAT is that it can track an object even when all the part detectors fail as long as the object has assigned blocks. Extensive experiments in many challenging real world scenes demonstrate the efficiency and effectiveness of our approach, (C) 2012 Elsevier B.V. All rights reserved.
C1 [Duan, Genquan; Ai, Haizhou; Xing, Junliang] Tsinghua Univ, Comp Sci & Technol Dept, Beijing 100084, Peoples R China.
   [Cao, Song] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   [Lao, Shihong] OMRON Social Solut Co LTD, Dev Ctr, Kyoto, Japan.
C3 Tsinghua University; Tsinghua University
RP Duan, GQ (corresponding author), Tsinghua Univ, Comp Sci & Technol Dept, Beijing 100084, Peoples R China.
EM dgq08@mails.tsinghua.edu.cn; ahz@mail.tsinghua.edu.cn;
   xjl07@mails.tsinghua.edu.cn; cao-s08@mails.tsinghua.edu.cn;
   lao@ari.ncl.omron.co.jp
RI Xing, Junliang/HGE-9630-2022
OI Xing, Junliang/0000-0001-6801-0510
FU National Science Foundation of China [61075026]; National Basic Research
   Program of China [2011CB302203]; MEXT, the Japanese Government
FX This work is supported in part by National Science Foundation of China
   under grant No.61075026, National Basic Research Program of China under
   Grant No.2011CB302203. Mr. Shihong LAO is partially supported by "R&D
   Program for Implementation of Anti-Crime and Anti-Terrorism Technologies
   for a Safe and Secure Society", Special Coordination Fund for Promoting
   Science and Technology of MEXT, the Japanese Government.
CR Andriluka M., 2008, PROC IEEE INT C COMP, P1
   [Anonymous], BRIT MACH VIS C ED B
   [Anonymous], 2008, P 2008 IEEE C COMP V
   [Anonymous], P IEEE INT C IM PROC
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Beleznai C, 2009, PROC CVPR IEEE, P2246, DOI 10.1109/CVPRW.2009.5206564
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Clarke JC, 1996, IMAGE VISION COMPUT, V14, P565, DOI 10.1016/0262-8856(96)01096-7
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Duan GQ, 2010, LECT NOTES COMPUT SC, V6316, P238, DOI 10.1007/978-3-642-15567-3_18
   Fieguth P, 1997, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.1997.609292
   Gao W, 2009, PROC CVPR IEEE, P1786, DOI 10.1109/CVPRW.2009.5206762
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Genquan Duan, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P683, DOI 10.1007/978-3-642-19309-5_53
   Genquan Duan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1097, DOI 10.1109/ICCVW.2009.5457580
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58
   Huang C, 2010, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2010.5540230
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549
   Jian-Yu Hsieh, 2007, Proceedings of the Fifth IASTED International Conference on Circuits, Signals, and Systems, P1, DOI 10.1145/1329125.1329139
   Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968
   Kelly P, 2009, IMAGE VISION COMPUT, V27, P1445, DOI 10.1016/j.imavis.2008.04.006
   Li Yanjun, 2008, PLoS One, V3, pe2166, DOI 10.1371/journal.pone.0002166
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Rodriguez M., 2007, Proceedings of the 15th international conference on Multimedia, MULTIMEDIA '07, P353
   Senior A., 2002, PROC PERFORMANCE EVA, P48
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu Bo., 2008, PROC IEEE C COMPUTER, P1, DOI DOI 10.1109/GLOCOM.2008.ECP.519
   Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhang L, 2008, PROC IEEE INT C COMP, P1
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
NR 38
TC 2
Z9 3
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2012
VL 30
IS 4-5
BP 292
EP 305
DI 10.1016/j.imavis.2012.02.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 964WF
UT WOS:000305726700003
DA 2024-07-18
ER

PT J
AU Suryanto
   Kim, DH
   Kim, HK
   Ko, SJ
AF Suryanto
   Kim, Dae-Hwan
   Kim, Hyo-Kak
   Ko, Sung-Jea
TI Spatial color histogram based center voting method for subsequent object
   tracking and segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object tracking; Spatial color; Histogram; Center voting; Back
   projection; Generalized Hough transform
AB In this paper, we introduce an algorithm for object tracking in video sequences. In order to represent the object to be tracked, we propose a new spatial color histogram model which encodes both the color distribution and spatial information. Using this spatial color histogram model, a voting method based on the generalized Hough transform is employed to estimate the object location from frame to frame. The proposed voting based method, called the center voting method, requests every pixel near the previous object center to cast a vote for locating the new object center in the new frame. Once the location of the object is obtained, the back projection method is used to segment the object from the background. Experiment results show successful tracking of the object even when the object being tracked changes in size and shares similar color with the background. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Suryanto; Kim, Dae-Hwan; Kim, Hyo-Kak; Ko, Sung-Jea] Korea Univ, Sch Elect Engn, Seoul 136713, South Korea.
C3 Korea University
RP Ko, SJ (corresponding author), Korea Univ, Sch Elect Engn, Seoul 136713, South Korea.
EM suryanto@dali.korea.ac.kr; dhkim@dali.korea.ac.kr;
   hkkim@dali.korea.ac.kr; sjko@korea.ac.kr
FU NRF; MEST [2011-0000200]
FX This work was supported by the Mid-career Researcher Program through NRF
   grant funded by the MEST (No. 2011-0000200).
CR [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   Buccolieri F, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P213
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hoshino R, 2002, LECT NOTES COMPUT SC, V2492, P92
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Leibe Bastian, 2004, WORKSH STAT LEARN CO
   Leichter I, 2009, IEEE T PATTERN ANAL, V31, P164, DOI 10.1109/TPAMI.2008.194
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B. D., 1981, P IJCAI, P674
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shi YG, 2005, PROC CVPR IEEE, P34
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Suryanto H.-K. Kim, 2009, WORLD ACAD SCI ENG T, V59, P450
   Tabb K, 2000, LECT NOTES COMPUT SC, V1899, P48
   Tomasi C, 1991, DETECTION TRACKING P
   Wang JQ, 2008, IEEE T IMAGE PROCESS, V17, P235, DOI 10.1109/TIP.2007.914150
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 24
TC 15
Z9 16
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2011
VL 29
IS 12
BP 850
EP 860
DI 10.1016/j.imavis.2011.09.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 873TJ
UT WOS:000298905600005
DA 2024-07-18
ER

PT J
AU Lebrun, J
   Gosselin, PH
   Philipp-Foliguet, S
AF Lebrun, Justine
   Gosselin, Philippe-Henri
   Philipp-Foliguet, Sylvie
TI Inexact graph matching based on kernels for object retrieval in image
   databases
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Online; Interactive; Database; Content-based; Object retrieval; Image
   retrieval; Machine learning; Kernel methods; Graph matching; Inexact
   match
AB In the framework of online object retrieval with learning, we address the problem of graph matching using kernel functions. An image is represented by a graph of regions where the edges represent the spatial relationships. Kernels on graphs are built from kernel on walks in the graph. This paper firstly proposes new kernels on graphs and on walks, which are very efficient for graphs of regions. Secondly we propose fast solutions for exact or approximate computation of these kernels. Thirdly we show results for the retrieval of images containing a specific object with the help of very few examples and counter-examples in the framework of an active retrieval scheme. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Lebrun, Justine; Gosselin, Philippe-Henri; Philipp-Foliguet, Sylvie] Univ Cergy Pontoise, ENSEA, CNRS, ETIS, F-95000 Cergy Pontoise, France.
C3 Centre National de la Recherche Scientifique (CNRS); CY Cergy Paris
   Universite
RP Gosselin, PH (corresponding author), Univ Cergy Pontoise, ENSEA, CNRS, ETIS, F-95000 Cergy Pontoise, France.
EM gosselin@ensea.fr
RI cai, bo/G-1491-2010
CR Aguilar W, 2009, IMAGE VISION COMPUT, V27, P897, DOI 10.1016/j.imavis.2008.05.004
   Ambauen R., 2003, IAPR TC1K WKSP GRAPH, P95
   Bengoetxea E, 2002, PATTERN RECOGN, V35, P2867, DOI 10.1016/S0031-3203(01)00232-1
   Berretti S, 2001, IEEE T PATTERN ANAL, V23, P1089, DOI 10.1109/34.954600
   Borgwardt KM, 2005, BIOINFORMATICS, V21, pI47, DOI 10.1093/bioinformatics/bti1007
   Bunke H., 2000, INT SER INTELL TECHN, P281
   Bunke H, 2007, LECT NOTES COMPUT SC, V4756, P20
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Cordella LP, 1998, COMP SUPPL, V12, P43
   Duchenne O, 2009, PROC CVPR IEEE, P1980, DOI 10.1109/CVPRW.2009.5206619
   EICHHORN J, 2004, OBJECT CATEGORIZATIO
   GANRTNER T, 2003, COLT, P129
   Gartner T., 2003, SIGKDD Explor., V5, P49, DOI DOI 10.1145/959242.959248
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   GONDRA I, 2004, IEEE INT C COMP VIS, V27, P149
   Gosselin PH, 2007, IEEE IMAGE PROC, P177
   Gosselin PH, 2006, IEEE IMAGE PROC, P3197, DOI 10.1109/ICIP.2006.313067
   Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78
   Haasdonk B., 2008, ICPR, P1, DOI DOI 10.1109/ICPR.2008.4761718
   Haussler D., 1999, CONVOLUTION KERNELS
   KASHIMA H, 2004, INT C MACH LEARN ICM, P58
   Kondor R. I., 2002, P 19 INT C MACH LEAR, P315
   Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   LYU S, 2005, IEEE C COMP VIS PATT, V2, P223
   Mahé P, 2009, MACH LEARN, V75, P3, DOI 10.1007/s10994-008-5086-2
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   McKay B., 1981, CONGR NUMERANTIUM, V30, P45
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Neuhaus M, 2006, LECT NOTES COMPUT SC, V4109, P163
   PHILIPPFOLIGUET S, 2006, FREBIR FUZZY REGIONS, P693
   Ralaivola L, 2005, NEURAL NETWORKS, V18, P1093, DOI 10.1016/j.neunet.2005.07.009
   Riesen K, 2007, LECT NOTES COMPUT SC, V4538, P1
   SAMMOUD O, 2006, 6 EUR C EV COMP COMB, P287
   Scholkopf B., 2002, Encyclopedia of Biostatistics
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   SHERVASHIDZE N, 2009, NIPS IN PRESS
   SHERVASHIDZE N, 2009, AISTATS IN PRESS
   Smalter Aaron, 2008, Proc IEEE Int Symp Bioinformatics Bioeng, V2008, P1
   SORLIN S, 2006, EXTRACTION CONNAISSA, P21
   Sorlin S., 2005, IAPR WORKSH GRAPH BA, P172
   Suard F, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P267
   *TREC, TREC VID RETR EV CAM
   Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Wilson RC, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P480, DOI 10.1109/ICIAP.2003.1234096
NR 47
TC 8
Z9 9
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2011
VL 29
IS 11
BP 716
EP 729
DI 10.1016/j.imavis.2011.07.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 864EE
UT WOS:000298219000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sladoje, N
   Lindblad, J
   Nyström, I
AF Sladoje, Natasa
   Lindblad, Joakim
   Nystrom, Ingela
TI Defuzzification of spatial fuzzy sets by feature distance minimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Defuzzification; Shape matching; Segmentation; Feature representation;
   Fuzzy set distance
ID FLOATING SEARCH METHODS; HAUSDORFF-LIKE METRICS; DIGITIZED OBJECTS;
   FEATURE-SELECTION
AB We present a novel defuzzification method, i.e., a mapping from the set of fuzzy sets to the set of crisp sets, and we suggest its application to image processing. Spatial fuzzy sets are, e.g., useful as information preserving representations of objects in images. Defuzzification of such a spatial fuzzy set can be seen as a crisp segmentation procedure. With the aim to provide preservation of selected quantitative features of the fuzzy set, we define the defuzzification of a fuzzy set to be a crisp set which is as close as possible to the fuzzy set, where the distance measure on the set of fuzzy sets, that we propose for defuzzification, incorporates selected local and global features of the fuzzy sets. The distance measure is based on the Minkowski distance between feature representations of the sets. The distance minimization, performed in the suggested defuzzification method, provides preservation of the selected quantitative features of the fuzzy set. The method utilizes the information contained in the fuzzy representation for defining a mapping from the set of fuzzy sets to the set of crisp sets. If the fuzzy set is a representation of an unknown crisp original set, such that the selected features of the original set are preserved in the fuzzy representation, then the defuzzified set may be seen as an approximate reconstruction of the crisp original. We present four optimization algorithms, exhibiting different properties, for finding the crisp set closest to a given discrete fuzzy set. A number of examples, using both synthetic and real images, illustrate the main properties of the proposed method. An evaluation of both theoretical aspects of the method, and its results, is given. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Lindblad, Joakim] Swedish Univ Agr Sci, Ctr Image Anal, Uppsala, Sweden.
   [Sladoje, Natasa] Univ Novi Sad, Fac Tech Sci, Novi Sad 21000, Serbia.
   [Nystrom, Ingela] Uppsala Univ, Ctr Image Anal, Uppsala, Sweden.
C3 Swedish University of Agricultural Sciences; University of Novi Sad;
   Uppsala University
RP Lindblad, J (corresponding author), Swedish Univ Agr Sci, Ctr Image Anal, Uppsala, Sweden.
EM sladoje@uns.ns.ac.yu; joakim@cb.uu.se; ingela@cb.uu.se
RI Lindblad, Joakim/F-1960-2016
OI Lindblad, Joakim/0000-0001-7312-8222
FU Ministry of Science of the Republic of Serbia [ON144018, ON144029];
   Goran Gustafsson Foundation [0374 B]
FX Prof. Gunilla Borgefors, and Dr. Xavier Tizon, both from Centre for
   Image Analysis, Uppsala, Sweden, are gratefully acknowledged for their
   scientific support. The first two authors acknowledge the Ministry of
   Science of the Republic of Serbia for financial support through the
   Projects ON144018 and ON144029. The Goran Gustafsson Foundation is
   acknowledged for financial support under contract no. 0374 B. The
   authors are grateful to the reviewers for fruitful and constructive
   discussions.
CR BLOCH I, 1995, PATTERN RECOGN, V28, P1341, DOI 10.1016/0031-3203(94)00312-A
   Bloch I, 1999, PATTERN RECOGN, V32, P1873, DOI 10.1016/S0031-3203(99)00011-4
   BLOCH I, 1997, LNCS, V1310, P30
   Boxer L, 1997, PATTERN RECOGN LETT, V18, P115, DOI 10.1016/S0167-8655(97)00006-8
   Boxer L, 1997, PATTERN RECOGN LETT, V18, P505, DOI 10.1016/S0167-8655(97)81191-9
   Brass P, 2002, PATTERN RECOGN LETT, V23, P39, DOI 10.1016/S0167-8655(01)00117-9
   Chaudhuri BB, 1996, PATTERN RECOGN LETT, V17, P1157, DOI 10.1016/0167-8655(96)00077-3
   HILDITCH CJ, 1969, MACH INTELL, V4, P403
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jawahar CV, 2000, PATTERN RECOGN, V33, P1339, DOI 10.1016/S0031-3203(99)00122-3
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   LACHAUD JO, 2001, LNCS, V2059, P542
   Leekwijck W.V., 1999, FUZZY SETS SYSTEMS, V108, P159, DOI DOI 10.1016/S0165-0114(97)00337-0
   Lindblad J, 2006, LECT NOTES COMPUT SC, V4245, P379
   Lindblad J, 2006, LECT NOTES COMPUT SC, V4040, P131
   Lowen R, 1998, FUZZY SET SYST, V99, P135, DOI 10.1016/S0165-0114(96)00399-5
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   MURTHY CA, 1990, PATTERN RECOGN LETT, V11, P197, DOI 10.1016/0167-8655(90)90006-N
   Ogura Y, 2001, INT J UNCERTAIN FUZZ, V9, P1, DOI 10.1142/S0218488501000570
   PAL SK, 1988, PATTERN RECOGN LETT, V7, P77, DOI 10.1016/0167-8655(88)90122-5
   PAL SK, 1990, PATTERN RECOGN LETT, V11, P831, DOI 10.1016/0167-8655(90)90036-2
   Prados-Suárez B, 2007, IEEE INT CONF FUZZY, P1914
   PUDIL P, 1994, INT C PATT RECOG, P279, DOI 10.1109/ICPR.1994.576920
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   RALESCU AL, 1984, INFORM SCIENCES, V34, P85, DOI 10.1016/0020-0255(84)90018-5
   Rondeau L, 1997, FUZZY SET SYST, V86, P311, DOI 10.1016/S0165-0114(95)00399-1
   ROSENFELD A, 1984, PATTERN RECOGN LETT, V2, P311, DOI 10.1016/0167-8655(84)90018-7
   ROSENFELD A, 1979, INFORM CONTROL, V40, P76, DOI 10.1016/S0019-9958(79)90353-X
   Roventa E, 2003, FUZZY SET SYST, V136, P375, DOI 10.1016/S0165-0114(02)00218-X
   Sladoje N, 2005, LECT NOTES COMPUT SC, V3617, P188, DOI 10.1007/11553595_23
   Sladoje N, 2005, IMAGE VISION COMPUT, V23, P123, DOI 10.1016/j.imavis.2004.06.011
   Sladoje N, 2004, INT C PATT RECOG, P526, DOI 10.1109/ICPR.2004.1334582
   Sladoje N, 2009, IEEE T PATTERN ANAL, V31, P357, DOI 10.1109/TPAMI.2008.184
   Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021
   WENSTOP F, 1980, FUZZY SET SYST, V4, P99, DOI 10.1016/0165-0114(80)90031-7
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zwick R., 1987, International Journal of Approximate Reasoning, V1, P221, DOI 10.1016/0888-613X(87)90015-6
NR 37
TC 8
Z9 9
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2011
VL 29
IS 2-3
BP 127
EP 141
DI 10.1016/j.imavis.2010.08.007
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 707NV
UT WOS:000286294200004
DA 2024-07-18
ER

PT J
AU Xu, F
   Lam, KM
   Dai, QH
AF Xu, Feng
   Lam, Kin-Man
   Dai, Qionghai
TI Video-object segmentation and 3D-trajectory estimation for monocular
   video sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 2D-to-3D video conversion; 3D trajectory estimation; Video-object
   segmentation
ID MULTIPLE MOTION; TRACKING; RECONSTRUCTION; EXTRACTION; FRAMEWORK; SHAPE
AB In this paper, we describe a video-object segmentation and 3D-trajectory estimation method for the analysis of dynamic scenes from a monocular uncalibrated view. Based on the color and motion information among video frames, our proposed method segments the scene, calibrates the camera, and calculates the 3D trajectories of moving objects. It can be employed for video-object segmentation, 2D-to-3D video conversion, video-object retrieval, etc. In our method, reliable 2D feature motions are established by comparing SIFT descriptors among successive frames, and image over-segmentation is achieved using a graph-based method. Then, the 2D motions and the segmentation result iteratively refine each other in a hierarchically structured framework to achieve video-object segmentation. Finally, the 3D trajectories of the segmented moving objects are estimated based on a local constant-velocity constraint, and are refined by a Hidden Markov Model (HMM)-based algorithm. Experiments show that the proposed framework can achieve a good performance in terms of both object segmentation and 3D-trajectory estimation. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Xu, Feng; Lam, Kin-Man] Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
   [Xu, Feng; Dai, Qionghai] Tsinghua Univ, TNList & Dept Automat, Beijing 100086, Peoples R China.
C3 Hong Kong Polytechnic University; Tsinghua University
RP Lam, KM (corresponding author), Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
EM xufeng2003@gmail.com; enkmlam@polyu.edu.hk; qhdai@mail.tsinghua.edu.cn
RI Dai, Qionghai/ABD-5298-2021; Kan, Kin-Man/A-9352-2014
OI Dai, Qionghai/0000-0001-7043-3061; Kan, Kin-Man/0000-0002-0422-8454
FU Centre for Signal Processing; Hong Kong Polytechnic University, Hong
   Kong, China [1-BB9C]; National Basic Research Project [2010CB731800];
   NSFC [61035002]
FX The work described in this paper was supported by an internal grant from
   the Centre for Signal Processing, The Hong Kong Polytechnic University,
   Hong Kong, China (Project No. 1-BB9C), and the grants from the National
   Basic Research Project (No. 2010CB731800) and the Key Project of NSFC
   (No. 61035002).
CR [Anonymous], P 6 INT C COMP VIS I
   [Anonymous], 3DTV C
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], INT C FAST PROC PHOT
   Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377
   Babu RV, 2004, IEEE T CIRC SYST VID, V14, P462, DOI 10.1109/TCSVT.2004.825536
   Borshukov GD, 1997, IEEE T IMAGE PROCESS, V6, P1591, DOI 10.1109/83.641420
   Briassouli A, 2008, IEEE T CIRC SYST VID, V18, P657, DOI 10.1109/TCSVT.2008.918799
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Georghiades A. S., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P230
   Gevers T, 2004, IEEE T CIRC SYST VID, V14, P776, DOI 10.1109/TCSVT.2004.828347
   Han M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P163, DOI 10.1109/ICCV.2001.937513
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   He Z, 2005, IEE P-VIS IMAGE SIGN, V152, P597, DOI 10.1049/ip-vis:20041200
   Jebara T, 1999, IEEE SIGNAL PROC MAG, V16, P66, DOI 10.1109/79.768574
   Joshi N., 2007, PROC IEEE INT C COMP, P1
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   Li HL, 2006, IEEE INT SYMP CIRC S, P2681
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P782, DOI 10.1109/TCSVT.2004.828341
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Min JH, 2008, IMAGE VISION COMPUT, V26, P1621, DOI 10.1016/j.imavis.2008.03.006
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Ozden KE, 2004, PROC CVPR IEEE, P819
   Piroddi R, 2006, IEEE SIGNAL PROC LET, V13, P421, DOI 10.1109/LSP.2006.873143
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Tsai YP, 2005, IEEE T CIRC SYST VID, V15, P175, DOI 10.1109/TCSVT.2004.839973
   Verma RC, 2003, IEEE T PATTERN ANAL, V25, P1215, DOI 10.1109/TPAMI.2003.1233896
   Wang DM, 1998, IEEE T CIRC SYST VID, V8, P539, DOI 10.1109/76.718501
   Wang WQ, 2008, IEEE T CIRC SYST VID, V18, P670, DOI 10.1109/TCSVT.2008.918800
   Wang Y, 2005, IEEE T IMAGE PROCESS, V14, P937, DOI 10.1109/TIP.2005.849330
   Wills J, 2006, INT J COMPUT VISION, V68, P125, DOI 10.1007/s11263-006-6660-3
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Wu CL, 2008, 3DTV CONF, P45, DOI 10.1109/3DTV.2008.4547809
   Xiao JJ, 2005, IEEE T PATTERN ANAL, V27, P1644, DOI 10.1109/TPAMI.2005.202
   Zhong D, 1999, IEEE T CIRC SYST VID, V9, P1259, DOI 10.1109/76.809160
NR 39
TC 7
Z9 10
U1 4
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2011
VL 29
IS 2-3
BP 190
EP 205
DI 10.1016/j.imavis.2010.09.001
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 707NV
UT WOS:000286294200009
DA 2024-07-18
ER

PT J
AU Poppe, R
AF Poppe, Ronald
TI A survey on vision-based human action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human action recognition; Motion analysis; Action detection
ID HUMAN MOTION ANALYSIS; HUMAN MOVEMENT; VIEW; SHAPE; REPRESENTATION;
   MODELS; VIDEO; PERCEPTION; MANIFOLDS; FEATURES
AB Vision-based human action recognition is the process of labeling image sequences with action labels. Robust solutions to this problem have applications in domains such as visual surveillance, video retrieval and human-computer interaction. The task is challenging due to variations in motion performance, recording settings and inter-personal differences. In this survey, we explicitly address these challenges. We provide a detailed overview of current advances in the field. Image representations and the subsequent classification process are discussed separately to focus on the novelties of recent research. Moreover, we discuss limitations of the state of the art and outline promising directions of research. (C) 2009 Elsevier B.V. All rights reserved.
C1 Univ Twente, Human Media Interact Grp, Fac Elect Engn Math & Comp Sci, NL-7500 AE Enschede, Netherlands.
C3 University of Twente
RP Poppe, R (corresponding author), Univ Twente, Human Media Interact Grp, Fac Elect Engn Math & Comp Sci, POB 217, NL-7500 AE Enschede, Netherlands.
EM poppe@ewi.utwente.nl
OI Poppe, Ronald/0000-0002-0843-7878
FU European IST Programme [FP6-033812]; ICIS; Dutch government [BSIK03024]
FX This work was supported by the European IST Programme Project FP6-033812
   (Augmented Multi-party Interaction with Distant Access), and is part of
   the ICIS program. ICIS is sponsored by the Dutch government under
   contract BSIK03024. The author wishes to thank the reviewers for their
   valuable comments and the authors that contributed figures to this
   survey.
CR Achard C, 2008, MACH VISION APPL, V19, P27, DOI 10.1007/s00138-007-0074-2
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Ahad A R., 2008, Automatic Face Gesture Recognition, P1
   Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   ALI S, IEEE T PATT IN PRESS
   [Anonymous], P INT C COMP VIS
   [Anonymous], P BMVA BRIT MACH VIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2008, IEEE Conf. on Computer Vision and Pattern Recognition, DOI [10.1109/CVPR.2008.4587527, DOI 10.1109/CVPR.2008.4587527]
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], PROC BRIT MACH VIS C
   [Anonymous], 2006, ACM International Workshop on Video Surveillance and Sensor Networks, DOI DOI 10.1145/1178782.1178808
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273619
   [Anonymous], 2008, BMVC
   Batra D, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P161
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Blackburn J, 2007, LECT NOTES COMPUT SC, V4814, P285
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bobick AF, 1997, PHILOS T ROY SOC B, V352, P1257, DOI 10.1098/rstb.1997.0108
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Caillette F, 2008, COMPUT VIS IMAGE UND, V109, P112, DOI 10.1016/j.cviu.2007.05.005
   Chakrabarti BB, 2008, 2008 JOINT INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY (POWERCON) AND IEEE POWER INDIA CONFERENCE, VOLS 1 AND 2, P124
   Cherla S, 2008, PROC CVPR IEEE, P1650
   CHIN TJ, 2007, P INT C IM PROC ICIP, V1, P381
   Chomat O, 2000, LECT NOTES COMPUT SC, V1842, P487
   Cour T, 2008, LECT NOTES COMPUT SC, V5305, P158, DOI 10.1007/978-3-540-88693-8_12
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Danafar S, 2007, LECT NOTES COMPUT SC, V4844, P457
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Duchenne O., 2009, Proceedings of the International Conference On Computer Vision (ICCV09), P1
   DUTRAN, 2008, LECT NOTES COMPUTER, V5302, P548
   Efros A., 2003, Proc. IEEE Internationa Conference on Computer Vision, V2, P726
   Elgammal A, 2004, PROC CVPR IEEE, P478
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Escobar MJ, 2009, INT J COMPUT VISION, V82, P284, DOI 10.1007/s11263-008-0201-1
   FANTI C, 2005, P 10 IEEE INT C COMP, V1, P1166
   Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13
   Farhadi Ali, 2009, CVPR
   Fathi A, 2008, PROC CVPR IEEE, P3064
   Feng XL, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P717, DOI 10.1109/TDPVT.2002.1024148
   Filipovych R, 2008, PROC CVPR IEEE, P2994
   Forsyth DA, 2005, FOUND TRENDS COMPUT, V1, P77, DOI 10.1561/0600000005
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   GAIDON A, P BRIT MACH IN PRESS
   Gandhi T, 2007, IEEE T INTELL TRANSP, V8, P413, DOI 10.1109/TITS.2007.903444
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   GERONIMO D, IEEE T PATT IN PRESS
   Gilbert A, 2008, LECT NOTES COMPUT SC, V5302, P222, DOI 10.1007/978-3-540-88682-2_18
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Grün R, 2008, QUAT GEOCHRONOL, V3, P1, DOI 10.1016/j.quageo.2007.09.001
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Gupta S, 2009, INT PARALL DISTRIB P, P267
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hatun K., P 19 INT C PATT REC, P1, DOI 10.1109/ICPR.2008.4761702
   Hu Yegang., 2009, Pattern Recognition 2009 CCPR 2009 Chinese Conference on, P1
   Huang FY, 2007, LECT NOTES COMPUT SC, V4844, P477
   Ikizler N., 2008, ICPR, P1, DOI DOI 10.1109/ICPR.2008.4761663
   Ikizler N, 2008, INT J COMPUT VISION, V80, P337, DOI 10.1007/s11263-008-0142-8
   Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002
   IKIZLERCINBIS N, 2009, P INT C COMP VIS ICC, P1
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Jia K., 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587732
   Jiang H, 2008, LECT NOTES COMPUT SC, V5303, P278, DOI 10.1007/978-3-540-88688-4_21
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22
   Kadir T., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P25, DOI 10.1049/cp:20030478
   Ke Y, 2005, IEEE I CONF COMP VIS, P166
   Ke Y, 2007, PROC CVPR IEEE, P3835
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Krüger V, 2007, ADV ROBOTICS, V21, P1473
   Lafferty John, 2001, INT C MACH LEARN ICM
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023
   Lin Z., 2009, Proc. Wireless Commun. Netw. Mobile Comput. Conf, P1
   Liu Jun., 2009, POWER ELECT SYSTEMS, P1, DOI DOI 10.1109/CISP.2009.5304603
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu W.-L., 2006, The 3rd Canadian Conference on Computer and Robot Vision (CRV'06), P6
   Lv F., 2007, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P1
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Mars M.M., 2009, Advances in the study of entrepreneurship, innovation and economic growth: Measuring the social value of innovation, P1
   Masoud O, 2003, IMAGE VISION COMPUT, V21, P729, DOI 10.1016/S0262-8856(03)00068-4
   Mendoza MA, 2008, LECT NOTES COMPUT SC, V5098, P53, DOI 10.1007/978-3-540-70517-8_6
   Messeguer R, 2009, LECT NOTES COMPUT SC, V5784, P1, DOI 10.1007/978-3-642-04216-4_1
   Mikolajczyk K, 2008, PROC CVPR IEEE, P2229
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Moore D. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P80, DOI 10.1109/ICCV.1999.791201
   Natarajan P, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P87
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Niebles JC, 2007, PROC CVPR IEEE, P1235
   Ning HZ, 2008, LECT NOTES COMPUT SC, V5303, P419, DOI 10.1007/978-3-540-88688-4_31
   Ning HZ, 2007, IEEE IMAGE PROC, P3133
   Nowozin S., 2007, Computer Vision and Pattern Recognition 2007. CVPR '07, P1, DOI DOI 10.1109/CVPR.2007.383171
   Ogale AS, 2007, LECT NOTES COMPUT SC, V4358, P115
   Ogata T, 2006, INT C PATT RECOG, P295
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Oikonomopoulos A, 2009, IMAGE VISION COMPUT, V27, P1814, DOI 10.1016/j.imavis.2009.05.010
   OSHIN O, 2008, P INT WORKSH MACH LE, P1
   Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4
   Park S, 2008, COMPUT VIS IMAGE UND, V111, P2, DOI 10.1016/j.cviu.2007.10.005
   PATRICK A, 2007, P SAE DIG HUM MOD C, P1
   Peursum P., 2007, P IEEE C COMP VIS PA, P1
   Ping Y., 2008, IV International Conference on Wireless Comunications, Networking and Mobile Computing, Dalian-China, 12-17 October, P1, DOI DOI 10.1109/ISABEL.2008.4712613
   Polana R, 1997, INT J COMPUT VISION, V23, P261, DOI 10.1023/A:1007975200487
   POPPE R, 2008, P INT C AUT FAC GEST, P1
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124
   Ragheb H, 2008, IEEE IMAGE PROC, P753, DOI 10.1109/ICIP.2008.4711864
   Ramadan FH, 2003, J GERIATR PSYCH NEUR, V16, P8, DOI 10.1177/0891988703252177
   Ramanan D., 2006, NIPS
   Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Rapantzikos K., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P294, DOI DOI 10.1145/1282280.1282326
   RAPANTZIKOS K, 2009, P C COMP VIS PATT RE, P1
   Robertson N, 2006, COMPUT VIS IMAGE UND, V104, P232, DOI 10.1016/j.cviu.2006.07.006
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   ROSALES RE, 1998, BU1998020
   Ryoo MS, 2009, INT J COMPUT VISION, V82, P1, DOI 10.1007/s11263-008-0181-1
   Savarese S, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P119
   Schindler K, 2008, PROC CVPR IEEE, P3025
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Seitz SM, 1997, INT J COMPUT VISION, V25, P231, DOI 10.1023/A:1007928103394
   Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Sheikh Y, 2005, IEEE I CONF COMP VIS, P144
   Shen YP, 2009, IEEE T PATTERN ANAL, V31, P1898, DOI 10.1109/TPAMI.2009.41
   Shi Qinfeng., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587557
   Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014
   SMITH P, 2005, P ICCV 2005, V1, P733
   Song Y, 2003, IEEE T PATTERN ANAL, V25, P814, DOI 10.1109/TPAMI.2003.1206511
   Souvenir R, 2008, PROC CVPR IEEE, P1634
   Sullivan J, 2002, LECT NOTES COMPUT SC, V2350, P629
   Suma EA, 2008, LECT NOTES COMPUT SC, V5358, P418, DOI 10.1007/978-3-540-89639-5_40
   Sun J., 2009, IEEE C COMP VIS PATT
   Thurau C., 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587721
   Turaga P., 2008, 2008 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2008.4587733, DOI 10.1109/CVPR.2008.4587733]
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Turaga P, 2009, COMPUT VIS IMAGE UND, V113, P353, DOI 10.1016/j.cviu.2008.08.009
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Veeraraghavan A., 2006, CVPR 06, P959, DOI [DOI 10.1109/CVPR.2006.304, 10.1109/CVPR.2006.304]
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vitaladevuni S N., 2008, Computer Vision and Pattern Recognition, P1
   Wang C, 2006, PROG SAFETY SCI TECH, V6, P1269
   WANG H, P BRIT MACH IN PRESS
   Wang L., 2007, Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383298
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang L, 2008, COMPUT VIS IMAGE UND, V110, P153, DOI 10.1016/j.cviu.2007.06.001
   Wang L, 2007, IEEE T IMAGE PROCESS, V16, P1646, DOI 10.1109/TIP.2007.896661
   WANG Y, 2006, P IEEE C COMP VIS PA, V2, P1654
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   Ying-Hong Wang, 2009, 2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in conjunction with the UIC 2009 and ATC 2009 Conferences, P1, DOI [10.1109/ICBBE.2009.5163482, 10.1109/UIC-ATC.2009.19]
   Wang YS, 2007, ASIA PACIF MICROWAVE, P1, DOI 10.1109/IITA.2007.19
   WEINLAND D, 2006, P 2006 IEEE COMP SOC, V2, P1639
   Weinland D., 2008, CVPR, P1
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yang C, 2007, LECT NOTES COMPUT SC, V4814, P313
   YAO B, 2009, P INT C COMP VIS ICC, P1
   Yilmaz A, 2008, COMPUT VIS IMAGE UND, V109, P335, DOI 10.1016/j.cviu.2007.09.006
   Yimaz A, 2006, COMPUT VIS IMAGE UND, V104, P221, DOI 10.1016/j.cviu.2006.07.012
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zelnik-Manor L, 2006, IEEE T PATTERN ANAL, V28, P1530, DOI 10.1109/TPAMI.2006.194
   Zhang JG, 2010, PATTERN RECOGN, V43, P197, DOI 10.1016/j.patcog.2009.05.015
   Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60
   Zhao ZP, 2008, INT C PATT RECOG, P737
NR 175
TC 1417
Z9 1617
U1 5
U2 366
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 976
EP 990
DI 10.1016/j.imavis.2009.11.014
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200012
OA Green Published
DA 2024-07-18
ER

PT J
AU Liang, C
   Wong, KYK
AF Liang, Chen
   Wong, Kwan-Yee K.
TI 3D reconstruction using silhouettes from unordered viewpoints
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D reconstruction; Dual space; Delaunay triangulation
ID OBJECTS
AB In this paper, we present a novel approach for reconstructing an object surface from its silhouettes. The proposed approach directly estimates the differential structure of the Surface, and results in a higher accuracy than existing volumetric approaches for object reconstruction. Compared with other existing differential approaches, our approach produces relatively complete 3D models similar to volumetric approaches, with the topology conforming to what is observed from the silhouettes. In addition, the method neither assumes nor depends on the spatial order of viewpoints. Experimental results on both synthetic and real world data are presented, and comparison is made with other existing approaches to demonstrate the Superiority of the proposed approach. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Liang, Chen; Wong, Kwan-Yee K.] Univ Hong Kong, Dept Comp Sci, Pokfulam, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Liang, C (corresponding author), Univ Hong Kong, Dept Comp Sci, Pokfulam, Hong Kong, Peoples R China.
EM liangchen@live.com; kykwong@cs.hku.hk
RI Liang, Chen/HNP-5916-2023; Wong, Kenneth Kwan Yee/C-1577-2009
OI Wong, Kenneth Kwan Yee/0000-0001-8560-9007
FU Research Grants Council of the Hong Kong Special Administration Region,
   China [HKU 7180/06E]
FX This project is supported by a grant from the Research Grants Council of
   the Hong Kong Special Administration Region, China, under Project HKU
   7180/06E.
CR BOISSONNAT JD, 1988, COMPUT VISION GRAPH, V44, P1, DOI 10.1016/S0734-189X(88)80028-8
   Boyer E., 1995, Computer Analysis of Images and Patterns. 6th International Conference, CAIP'95. Proceedings, P198
   Boyer E, 2003, PROC CVPR IEEE, P695
   BRAND M, 2004, COMPUTER VISION PATT, V1, P30
   CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P100, DOI 10.1016/S0734-189X(86)80031-7
   CIPOLLA R, 1990, INT C COMP VIS OS JA, P616
   Cross Geoffrey., 2000, CONFLUENCE COMPUTER, P25
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Franco J.S., 2003, P 14 BRIT MACHINE VI, P329, DOI [10.5244/C.17.32, DOI 10.5244/C.17.32]
   Garcia B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1067, DOI 10.1109/ICCV.1998.710849
   Giblin P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P136
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   LAZEBNIK S, 2002, THESIS U ILLINOIS UR
   Liang C, 2007, IEEE T PATTERN ANAL, V29, P2205, DOI 10.1109/TPAMI.2007.1127
   MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367
   Montani C., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P281, DOI 10.1109/VISUAL.1994.346308
   POTMESIL M, 1987, COMPUT VISION GRAPH, V40, P1, DOI 10.1016/0734-189X(87)90053-3
   SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029
   VAILLANT R, 1990, EUR C COMP VIS, P454
   Wong KYK, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P217, DOI 10.1109/ICCV.2001.937627
NR 20
TC 24
Z9 26
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 579
EP 589
DI 10.1016/j.imavis.2009.09.012
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600004
DA 2024-07-18
ER

PT J
AU Papakostas, GA
   Karakasis, EG
   Koulouriotis, DE
AF Papakostas, G. A.
   Karakasis, E. G.
   Koulouriotis, D. E.
TI Accurate and speedy computation of image Legendre moments for computer
   vision applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Legendre moments; Image Block Representation; Feature extraction;
   Computer vision; Pattern recognition
ID EFFICIENT
AB A novel algorithm that permits the fast and accurate computation of the Legendre image moments is introduced in this paper. The proposed algorithm is based on the block representation of an image and on a new image representation scheme, the Image Slice Representation (ISR) method. The ISR method decomposes a gray-scale image as an expansion of several two-level images of different intensities (slices) and thus enables the partial application of the well-known Image Block Representation (IBR) algorithm to each image component. Moreover, using the resulted set of image blocks, the Legendre moments' computation can be accelerated through appropriate computation schemes. Extensive experiments prove that the proposed methodology exhibits high efficiency in calculating Legendre moments on gray-scale, but furthermore on binary images. The newly introduced algorithm is suitable for the computation of the Legendre moments for pattern recognition and computer vision applications, where the images consist of objects presented in a scene. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Papakostas, G. A.] Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
   [Karakasis, E. G.; Koulouriotis, D. E.] Democritus Univ Thrace, Dept Prod Engn & Management, GR-67100 Xanthi, Greece.
C3 Democritus University of Thrace; Democritus University of Thrace
RP Papakostas, GA (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
EM gpapakos@ee.duth.gr; ekarakas@pme.duth.gr; jimk@pme.duth.gr
RI cai, bo/G-1491-2010; Papakostas, George A./F-1038-2017; Koulouriotis,
   Dimitrios/AAI-9437-2021
OI Papakostas, George A./0000-0001-5545-1499; Koulouriotis,
   Dimitrios/0000-0003-0194-0654
CR [Anonymous], CUCS00696
   [Anonymous], Yale Face database
   [Anonymous], 2005, ICGST International Journal on Graphics, Vision and Image Processing
   *ETH ZUR COMP VIS, 53 OBJ DAT
   Fu B, 2007, PATTERN RECOGN, V40, P691, DOI 10.1016/j.patcog.2006.05.020
   Hosny KM, 2007, PATTERN RECOGN, V40, P3597, DOI 10.1016/j.patcog.2007.04.014
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   MUKUNDAN R, 1995, PATTERN RECOGN, V28, P1433, DOI 10.1016/0031-3203(95)00011-N
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Papakostas GA, 2008, PATTERN RECOGN, V41, P1895, DOI 10.1016/j.patcog.2007.11.015
   Papakostas GA, 2008, ICSES 2008 INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS, CONFERENCE PROCEEDINGS, P7, DOI 10.1109/ICSES.2008.4673343
   PAPAKOSTAS GA, 2007, 8 INT WORKSH IM AN M, P48
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shu HZ, 2000, PATTERN RECOGN, V33, P341, DOI 10.1016/S0031-3203(99)00044-8
   Spiliotis IM, 1998, IEEE T IMAGE PROCESS, V7, P1609, DOI 10.1109/83.725368
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Vatkin M, 2001, DESDES '1: PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON DISCRETE-EVENT SYSTEM DESIGN, P259
   Yang GY, 2006, PATTERN RECOGN, V39, P74, DOI 10.1016/j.patcog.2005.08.008
   Yap PT, 2005, IEEE T PATTERN ANAL, V27, P1996, DOI 10.1109/TPAMI.2005.232
   Zhou JD, 2002, PATTERN RECOGN, V35, P1143, DOI 10.1016/S0031-3203(01)00104-2
NR 21
TC 42
Z9 43
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 414
EP 423
DI 10.1016/j.imavis.2009.06.011
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300012
DA 2024-07-18
ER

PT J
AU Tan, TN
   He, ZF
   Sun, ZZ
AF Tan, Tieniu
   He, Zhaofeng
   Sun, Zhenan
TI Efficient and robust segmentation of noisy iris images for
   non-cooperative iris recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Coarse iris localization; Eyelid and eyelash detection; Iris
   segmentation; Non-cooperative iris recognition
AB This paper describes the winning algorithm we submitted to the recent NICE.I iris recognition contest. Efficient and robust segmentation of noisy iris images is one of the bottlenecks for non-cooperative iris recognition. To address this problem, a novel iris segmentation algorithm is proposed in this paper. After reflection removal, a clustering based coarse iris localization scheme is first performed to extract a rough position of the iris, as well as to identify non-iris regions such as eyelashes and eyebrows. A novel integrodifferential constellation is then constructed for the localization of pupillary and limbic boundaries, which not only accelerates the traditional integrodifferential operator but also enhances its global convergence. After that, a curvature model and a prediction model are learned to deal with eyelids and eyelashes, respectively. Extensive experiments on the challenging UBIRIS iris image databases demonstrate that encouraging accuracy is achieved by the proposed algorithm which is ranked the best performing algorithm in the recent open contest on iris recognition (the Noisy Iris Challenge Evaluation, NICE.I). (C) 2009 Elsevier B.V. All rights reserved.
C1 [Tan, Tieniu; He, Zhaofeng; Sun, Zhenan] Chinese Acad Sci, Ctr Biometr & Secur Res, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Tan, TN (corresponding author), Chinese Acad Sci, Ctr Biometr & Secur Res, Natl Lab Pattern Recognit, Inst Automat, POB 2728, Beijing 100190, Peoples R China.
EM tnt@nlpr.ia.ac.cn; zfhe@nlpr.ia.ac.cn; znsun@nl-pr.ia.ac.cn
RI Huang, Yan/HCH-6526-2022
OI Huang, Yan/0000-0002-8239-7229; Wang, Yunlong/0000-0002-3535-308X
FU National Basic Research Program [2004CB318110]; Natural Science
   Foundation of China [60736018]; National Hi Tech Research and
   Development Program of China [2006AA01ZI93, 2007AAO1Z162]
FX This work is supported by research grants from the National Basic
   Research Program (Grant No. 2004CB318110), the Natural Science
   Foundation of China (Grant No. 60736018), the National Hi Tech Research
   and Development Program of China (2006AA01ZI93 and 2007AAO1Z162).
CR [Anonymous], P INT C PATT REC ICP
   [Anonymous], P SPIE BIOM TECHN HU
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   HE Z, 2008, P ICIP, P265
   HE Z, 2008, P IEEE C COMP VIS PA
   HE ZF, 2009, IEEE T PATTERN ANAL
   He ZF, 2009, LECT NOTES COMPUT SC, V5558, P1080
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Proença H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   PROENCA H, 2007, P 1 INT C BIOM THEOR, P1
   QIU XC, 2007, P 2 INT C BIOM SEOUL, P770
   Sun Z., 2009, IEEE T PATTERN ANAL
   Wei ZS, 2006, LECT NOTES COMPUT SC, V3832, P464
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
NR 18
TC 174
Z9 200
U1 1
U2 42
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2010
VL 28
IS 2
SI SI
BP 223
EP 230
DI 10.1016/j.imavis.2009.05.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 538GR
UT WOS:000273173100003
DA 2024-07-18
ER

PT J
AU Larsson, F
   Jonsson, E
   Felsberg, M
AF Larsson, Fredrik
   Jonsson, Erik
   Felsberg, Michael
TI Simultaneously learning to recognize and control a low-cost robotic arm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual servoing; LWPR; Gripper recognition; Jacobian estimation
AB In this paper, we present a visual servoing method based on a learned mapping between feature space and control space. Using a suitable recognition algorithm, we present and evaluate a complete method that simultaneously learns the appearance and control of a low-cost robotic arm. The recognition part is trained using an action precedes perception approach. The novelty of this paper, apart from the visual servoing method per se, is the combination of visual servoing with gripper recognition. We show that we can achieve high precision positioning without knowing in advance what the robotic arm looks like or how it is controlled. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Larsson, Fredrik; Jonsson, Erik; Felsberg, Michael] Linkoping Univ, Dept Elect Engn, Comp Vis Lab, S-58183 Linkoping, Sweden.
C3 Linkoping University
RP Larsson, F (corresponding author), Linkoping Univ, Dept Elect Engn, Comp Vis Lab, S-58183 Linkoping, Sweden.
EM larsson@isy.liu.se
OI Landolsi, Erik/0000-0002-6639-1257; Felsberg,
   Michael/0000-0002-6096-3648
CR Ballard D.H., 1982, Computer Vision
   Buessler JL, 1998, NEURAL NETWORKS, V11, P1395, DOI 10.1016/S0893-6080(98)00050-1
   Butz MV, 2007, PSYCHOL REV, V114, P1015, DOI 10.1037/0033-295X.114.4.1015
   Corke PetrI., 1997, VISUAL CONTROL ROBOT
   FARAHMAND A, 2007, P IEEE RSJ INT C INT, P1969
   Felsberg M, 2006, IEEE T PATTERN ANAL, V28, P209, DOI 10.1109/TPAMI.2006.29
   FORSSEN PE, 2004, SE58183 LINK U
   GRANLUND GH, 2000, P ALG FRAM PERC ACT
   Granlund GH, 2006, LECT NOTES COMPUT SC, V3948, P37, DOI 10.1007/11414353_4
   Jagersand M, 1996, IMAGE UNDERSTANDING WORKSHOP, 1996 PROCEEDINGS, VOLS I AND II, P677
   JAGERSAND M, 1994, 579 U ROCH COMP SCI
   JONSSON E, 2005, LITHISYR2691 LINK U
   Jonsson E, 2007, LECT NOTES COMPUT SC, V4522, P1
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kragic D., 2002, Survey on visual servoing for manipulation
   LARSSON F, 2007, P INT WORKSH ROB MAT
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   *LYNXM, LYNXM ROB KITS
   OGNIBENE D, 2006, SAB, P381
   Ridder C., 1995, P ICAM
   Schaal S, 2002, APPL INTELL, V17, P49, DOI 10.1023/A:1015727715131
   Schott JM, 2003, J NEUROL NEUROSUR PS, V74, P558, DOI 10.1136/jnnp.74.5.558
   Siebel N. T., 2006, HIS 06, P6
   Stauffer C., 1999, P IEEE INT C COMP VI
   TOUSSAINT M, 2007, INT C INT ROB SYST I, P3068
   Vernon D., 1991, Machine vision-Automated visual inspection and robot vision
   Vijayakumar S, 2002, AUTON ROBOT, V12, P55, DOI 10.1023/A:1013258808932
   Vijayakumar S., 2000, Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000), V1, P288
NR 28
TC 5
Z9 5
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 2
PY 2009
VL 27
IS 11
SI SI
BP 1729
EP 1739
DI 10.1016/j.imavis.2009.04.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 498HJ
UT WOS:000270127800009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Arcelli, C
   di Baja, GS
   Serino, L
AF Arcelli, Carlo
   di Baja, Gabriella Sanniti
   Serino, Luca
TI A parallel algorithm to skeletonize the distance transform of 3D objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D Object; Surface skeleton; Distance transform; Topology preservation;
   Reversibility
ID THINNING ALGORITHM; SIMPLE POINTS; TOPOLOGY; IMAGES
AB A 2-subiteration parallel algorithm is suggested to compute the surface skeleton of a 3D digital object represented by its D-6 distance transform, without resorting to directional processes. The algorithm is based on the use of two operators, with 3 x 3 x 3 and 2 x 2 x 2 support, that are, respectively, applied during the two subiterations to mark the voxels of the D-6 distance transform to be ascribed to the skeleton. The resulting surface skeleton is centered within the object, is homotopic to the object and is fully reversible since it includes all centers of the maximal balls of the object. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Arcelli, Carlo; di Baja, Gabriella Sanniti; Serino, Luca] CNR, Inst Cybernet E Caianiello, Image Anal Dept, I-80078 Naples, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Cibernetica
   "Eduardo Caianiello" (ICIB-CNR)
RP Arcelli, C (corresponding author), CNR, Inst Cybernet E Caianiello, Image Anal Dept, Via Campi Fiegrei 34, I-80078 Naples, Italy.
EM c.arcetli@cib.na.cnr.it; g.sannitidibaja@cib.na.cnr.it;
   l.serino@cib.na.cnr.it
RI ; SERINO, LUCA/D-2167-2016
OI Sanniti di Baja, Gabriella/0000-0003-2218-0412; SERINO,
   LUCA/0000-0003-0077-1799
CR Arcelli C., 1996, Topological Algorithms for Digital Image Processing, volume 19 of Machine Intelligence and Pattern Recognition, V19, P99
   ARCELLI C, 2006, P 18 ICPR, V3, P1055
   ARCELLI C, 2008, 16708 ICIB CNR
   Arcelli C, 2006, LECT NOTES COMPUT SC, V4245, P555
   BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P169, DOI 10.1016/0167-8655(94)90046-9
   Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154
   Borgefors G, 2000, P SOC PHOTO-OPT INS, V4117, P300, DOI 10.1117/12.404833
   BORGEFORS G, 1997, P 10 SCAND C IM AN S, P567
   BORGEFORS G, 2005, HDB PATTERN RECOGNIT, P157
   Bouix S, 2005, MED IMAGE ANAL, V9, P209, DOI 10.1016/j.media.2004.06.026
   DIBAJA GS, 2005, HDB PATTERN RECOGNIT, P137
   Hilditch C.J., 1969, MACHINE INTELLIGENCE, V4, P403
   Kong T. Y., 1996, TOPOLOGICAL ALGORITH, P263
   KONG TY, 1989, COMPUT GRAPH, V13, P159, DOI 10.1016/0097-8493(89)90058-7
   KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3
   Ma CM, 1996, COMPUT VIS IMAGE UND, V64, P420, DOI 10.1006/cviu.1996.0069
   Ma CM, 2003, PATTERN RECOGN, V36, P1775, DOI [10.1016/S0031-3203(03)00007-4, 10.1016/S0031-3203(03)000074]
   Ma CM, 2000, COMPUT VIS IMAGE UND, V80, P364, DOI 10.1006/cviu.2000.0879
   Palágyi K, 1999, GRAPH MODEL IM PROC, V61, P199, DOI 10.1006/gmip.1999.0498
   Pudney C, 1998, COMPUT VIS IMAGE UND, V72, P404, DOI 10.1006/cviu.1998.0680
   Richard W., 1996, Machine Intelligence and Pattern Recognition, V19, P145, DOI [10.1016/S0923-0459(96)80014-0, DOI 10.1016/S0923-0459(96)80014-0]
   SAHA PK, 1994, IEEE T PATTERN ANAL, V16, P1028, DOI 10.1109/34.329007
   Svensson S, 2003, COMPUT VIS IMAGE UND, V90, P242, DOI 10.1016/S1077-3142(03)00061-4
   Svensson S, 2002, PATTERN RECOGN LETT, V23, P1419, DOI 10.1016/S0167-8655(02)00102-2
   TSAO YF, 1981, COMPUT VISION GRAPH, V17, P315, DOI 10.1016/0146-664X(81)90011-3
   Wang T, 2007, PATTERN RECOGN LETT, V28, P501, DOI 10.1016/j.patrec.2006.09.004
   Xie WJ, 2003, PATTERN RECOGN, V36, P1529, DOI 10.1016/S0031-3203(02)00348-5
   Yokoi S., 1975, COMPUTER GRAPHICS IM, V4, P63, DOI DOI 10.1016/0146-664X(75)90022-2
NR 28
TC 8
Z9 8
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 666
EP 672
DI 10.1016/j.imavis.2008.07.014
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000007
DA 2024-07-18
ER

PT J
AU Snoek, J
   Hoey, J
   Stewart, L
   Zemel, RS
   Mihailidis, A
AF Snoek, Jasper
   Hoey, Jesse
   Stewart, Liam
   Zemel, Richard S.
   Mihailidis, Alex
TI Automated detection of unusual events on stairs
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Human motion analysis; Hidden Markov model; Gait analysis; Anomaly
   detection; Event recognition; Bayesian tracking; Particle filter;
   Automated video analysis; Machine learning; Biomedical analysis; Stairs
ID HUMAN MOVEMENT; MODELS
AB This paper presents a method for automatically detecting unusual human events on stairs from video data. The motivation is to provide a tool for biomedical researchers to rapidly find the events of interest within large quantities of video data. Our system identifies potential sequences containing anomalies, and reduces the amount of data that needs to be searched by a human. We compute two sets of features from a video of a person descending a stairwell. The first set of features are the foot positions and velocities. We track both feet using a mixed state particle filter with an appearance model based on histograms of oriented gradients. We compute expected (most likely) foot positions given the state of the filter at each frame. The second set of features are the parameters of the mean optical flow over a foreground region. Our final classification system inputs these two sets of features into a hidden Markov model (HMM) to analyse the spatio-temporal progression of the stair descent. A single HMM is trained on sequences of normal stair use, and a threshold on sequence likelihoods is used to detect unusual events in new data. We demonstrate our system on a data set with five people descending a set of stairs in a laboratory environment. We show how our system can successfully detect nearly all anomalous events, with a low false positive rate. We discuss limitations and suggest improvements to the system. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Snoek, Jasper; Stewart, Liam; Zemel, Richard S.; Mihailidis, Alex] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3H5, Canada.
   [Hoey, Jesse] Univ Dundee, Sch Comp, Dundee, Scotland.
   [Mihailidis, Alex] Univ Toronto, Dept Occupat Sci & Occupat Therapy, Toronto, ON M5S 3H5, Canada.
C3 University of Toronto; University of Dundee; University of Toronto
RP Snoek, J (corresponding author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd, Toronto, ON M5S 3H5, Canada.
EM jasper@cs.toronto.edu
OI Mihailidis, Alex/0000-0003-2233-0919
CR [Anonymous], 1995, Technical report
   [Anonymous], CVPR
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2003, Injury Facts, V2003
   ARCHEA J, 1979, NATL BUREAU STANDARD, P120
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   BAUCKHAGE C, 2005, CRV
   Baum L. E., 1972, Inequalities, V3, P1
   Bengio Y., 1996, MARKOVIAN MODELS SEQ
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Brand M, 2000, IEEE T PATTERN ANAL, V22, P844, DOI 10.1109/34.868685
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Campbell LW, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P157, DOI 10.1109/AFGR.1996.557258
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   *CPS COMM, 2005, NAT INJ SURV SYST ON
   Cutting J.E., 1977, B PSYCHONOMIC SOC, V9, P353
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fernyhough J, 2000, IMAGE VISION COMPUT, V18, P81, DOI 10.1016/S0262-8856(99)00023-2
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Hyman J., 2003, THESIS MIT
   Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263
   KAPOOR A, 2001, P WORKSH PERSP US IN
   KHAN Z, 2004, CVPR
   Lee T, 2005, J TELEMED TELECARE, V11, P194, DOI 10.1258/1357633054068946
   LIAO L, 2004, P AAAI 04
   Little J.J., 1996, Recognizing People by Their Gait: The Shape of Motion
   Masud T, 2001, AGE AGEING, V30, P3, DOI 10.1093/ageing/30.suppl_4.3
   MCKENNA J, 2004, SUMMARISING CONTEXTU
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Murphy K. P., COMPUTING SCI STAT, V33
   Murray M P, 1967, Am J Phys Med, V46, P290
   National Safety Council, 1998, ACC FACTS
   NIYOGI A, 1993, IEEE C COMP VIS PATT, P469
   North B, 2000, IEEE T PATTERN ANAL, V22, P1016, DOI 10.1109/34.877523
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   PEREZ P, 2002, EUR C COMP VIS, P661
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   SNOEK J, 2006, CRV
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   TEMPLER JA, 1994, STAIRCASE STUDIES HA
   Toyama K., 1999, The Proceedings of the Seventh IEEE International Conference on Computer Vision, V1, P255
   Vasilescu M. A. O., 2002, HUMAN MOTION SIGNATU, V3, P456
   Vogler C, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P33, DOI 10.1109/HUMO.2000.897368
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 51
TC 26
Z9 32
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 153
EP 166
DI 10.1016/j.imavis.2008.04.021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700016
DA 2024-07-18
ER

PT J
AU Ren, Y
   Chua, CS
AF Ren, Ying
   Chua, Chin Seng
TI Bilateral learning for color-based tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE color-based tracking; color model adaptation; Bilateral Learning (BL)
ID REAL-TIME TRACKING
AB This paper addresses the issue of color model adaptation and color-based object tracking in a dynamic scene. Under different environmental conditions such as illumination changes, a static color model is inadequate for the purpose of color-based object detection and tracking. Color model adaptation is required and this has to be integrated into the tracking procedure within the spatial domain. To track a target in both the color and spatial domains, a Bilateral Learning (BL) approach is proposed in this paper. Formulated as an unsupervised learning problem, the adaptations of the color and spatial models are fitted into an EM framework by updating in the color and image spaces alternately. This results in the adaptation of the color model and the localization of the target along the image sequence. Experimental results show the effectiveness and efficacy of the proposed approach for color model adaptation and object tracking under illumination changes and environmental noise in real time. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Ren, Ying; Chua, Chin Seng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chua, CS (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Block S1,Nanyang Ave, Singapore 639798, Singapore.
EM ecschua@ntu.edu.sg
CR [Anonymous], P AS C COMP VIS
   [Anonymous], 1992, ACTIVE VISION
   BULUSWAR SD, 1997, BRIT MACH VIS C
   Collins R., 2000, CMURITR0012
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   DARELL T, 1998, P IEEE C COMP VIS PA, P601
   Grove TD, 1998, INT C PATT RECOG, P1442, DOI 10.1109/ICPR.1998.711975
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Odobez J., 1997, Video Data Compression for Multimedia Computing, P283, DOI DOI 10.1007/978-1-4615-6239-9_8
   RAJA Y, 1998, P EUR C COMP VIS
   Ren Hong-shan, 2002, APPL MATH E NOTES, V2, P1
   Ren Y, 2003, PATTERN RECOGN LETT, V24, P183, DOI 10.1016/S0167-8655(02)00210-6
   REN Y, 2000, P IEEE INT C VIS INT, P280
   Ricquebourg Y, 2000, IEEE T PATTERN ANAL, V22, P797, DOI 10.1109/34.868682
   SMITH SM, 1995, IEEE T PATTERN ANAL, V17, P814, DOI 10.1109/34.400573
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan TN, 1998, INT J COMPUT VISION, V27, P5, DOI 10.1023/A:1007924428535
   Triesch J, 2001, NEURAL COMPUT, V13, P2049, DOI 10.1162/089976601750399308
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937590
   Wu Y, 2000, PROC CVPR IEEE, P133, DOI 10.1109/CVPR.2000.855810
   Yang J, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P142, DOI 10.1109/ACV.1996.572043
   ZHANG ZY, 1992, INT J COMPUT VISION, V7, P211, DOI 10.1007/BF00126394
NR 28
TC 6
Z9 7
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1530
EP 1539
DI 10.1016/j.imavis.2008.04.023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000009
DA 2024-07-18
ER

PT J
AU Srinivasan, M
   Annadurai, S
AF Srinivasan, Meena
   Annadurai, S.
TI Improved spatially adaptive MDL denoising of images using normalized
   maximum likelihood density
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE minimum description length; wavelet denoising; normalized maximum
   likelihood
ID DESCRIPTION LENGTH PRINCIPLE; WAVELET SHRINKAGE
AB This paper presents a new method for wavelet denoising using minimum description length (MDL) principle with normalized maximum likelihood density. Denoising is done by hard thresholding and a new spatially adaptive threshold which varies according to the estimated signal variance of each wavelet coefficient is derived using the MDL principle with normalized maximum likelihood density. As the normalized maximum likelihood code encodes the data with the shortest description length, smaller proportion of significant coefficients could be achieved after thresholding compared with simple MDL denoising. Thus better compression is obtained without detoriating the denoising performance measure (PSNR) compared to the MDL thresholding. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Srinivasan, Meena] Govt Coll Technol, Dept Elect & Commun, Coimbatore 641013, TN, India.
RP Srinivasan, M (corresponding author), Govt Coll Technol, Dept Elect & Commun, Coimbatore 641013, TN, India.
EM ravimeena63@yahoo.co.in
CR Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   FAN J, 1993, ADAPTATION HIGH SPAT, P18
   Hansen M, 2000, IEEE T INFORM THEORY, V46, P1778, DOI 10.1109/18.857790
   HANSEN MH, 1998, J AM STAT ASS
   KONTKANEN P, EURASIP J BIOINFORMA, DOI UNSP 90947
   Krim H, 1999, IEEE T INFORM THEORY, V45, P898, DOI 10.1109/18.761331
   Michak M. K., 1999, IEEE SIGNAL PROCESSI, V6, P300
   MYUNG JI, 2005, J MATH PSYCHOL   JUN
   Rissanen J, 2000, IEEE T INFORM THEORY, V46, P2537, DOI 10.1109/18.887861
   RISSANEN J, 1997, HYPOTHESIS SELECTION
   ROOS T, 2005, P 10 INT WORKSH ART
   SHTRAKOV YM, 1987, PROBL INFORM TRANSMI, V23, P175
   XIE J, 2002, P 4 WORLD C INT CONT
   Xie JC, 2004, IEEE T IMAGE PROCESS, V13, P179, DOI 10.1109/tip.2004.823828
NR 16
TC 5
Z9 5
U1 1
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1524
EP 1529
DI 10.1016/j.imavis.2008.04.011
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000008
DA 2024-07-18
ER

PT J
AU Stelldinger, P
   Terzic, K
AF Stelldinger, Peer
   Terzic, Kasim
TI Digitization of non-regular shapes in arbitrary dimensions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE shape; digitization; repairing; topology; reconstruction; irregular grid
ID PRESERVATION
AB The preservation of topological properties during digitization is a hard problem in 3 and higher dimensions. Only for the very restricted class of r-regular shapes it is known that the connectivity and inclusion properties of shape components do not change. In a previous paper it was shown for the 2D case, how a much wider class of shapes, for which the morphological open-close and the close-open-operator with an r-disc lead to the same result, can be digitized correctly in this sense by using an additional repairing step. This paper extends this to the arbitrary dimensions and analyses the difficulties which occur in 3 or higher dimensional spaces. The repairing step is easy to compute, parallelizable and does not change as much hyper-voxels as a preprocessing regularization step. The results are applicable for arbitrary, even irregular, sampling grids in arbitrary dimensions. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Stelldinger, Peer; Terzic, Kasim] Univ Hamburg, Cognit Syst Grp, D-22527 Hamburg, Germany.
C3 University of Hamburg
RP Stelldinger, P (corresponding author), Univ Hamburg, Cognit Syst Grp, Vogt Kolln Str 30, D-22527 Hamburg, Germany.
EM stelldinger@informatik.uni-hamburg.de
RI ; Terzic, Kasim/N-6522-2013
OI Stelldinger, Peer/0000-0001-8079-2797; Terzic, Kasim/0000-0001-6692-209X
CR BING RH, 1957, ANN MATH, V65, P456, DOI 10.2307/1970057
   Giraldo A, 1999, PATTERN RECOGN, V32, P365, DOI 10.1016/S0031-3203(98)00101-0
   Keller P.E., 1982, Algorithms for Graphics and Image Processing, V42, P709, DOI 10.1109/23.467888
   Köthe U, 2003, LECT NOTES COMPUT SC, V2886, P82
   Latecki L., 1998, Discrete Representation of Spatial Objects in Computer Vision
   Latecki LJ, 1998, J MATH IMAGING VIS, V8, P131, DOI 10.1023/A:1008273227913
   Serra J., 1983, IMAGE ANAL MATH MORP
   Stelldinger P, 2005, COMP IMAG VIS, V30, P269
   Stelldinger P, 2005, IMAGE VISION COMPUT, V23, P237, DOI 10.1016/j.imavis.2004.06.003
   Stelldinger P, 2003, LECT NOTES COMPUT SC, V2781, P108
   WALTHER T, 2006, DEV XRAY TOMOGRAPHY, V6318
   Windreich G, 2003, PATTERN RECOGN, V36, P2531, DOI 10.1016/S0031-3203(03)00173-0
NR 12
TC 5
Z9 5
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1338
EP 1346
DI 10.1016/j.imavis.2007.07.013
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Verdú-Monedero, R
   Morales-Sánchez, J
   Weruaga, L
AF Verdu-Monedero, Rafael
   Morales-Sanchez, Juan
   Weruaga, Luis
TI Convergence analysis of active contours
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE active contours; snakes; convergence analysis; image segmentation
ID FIELD
AB Active contours are very useful tools in image segmentation and object tracking in video sequences. The practical implementations are built with an iterative algorithm based on a second order system defined in the spatial domain, where the elasticity and rigidity are the static parameters for its characterization and mass and damping are the dynamic parameters. In the process, the contour is influenced by external and internal forces varying its shape adaptively. The number of iterations required by the contour to delineate the objects is determined by these forces, by its initialization and by the coefficients of the second order system. This paper analyzes the convergence of active contours using the frequency based formulation and shows that the convergence depends on the dynamic parameters of the second order system and the distance between nodes of the contour attracted by the external forces. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Verdu-Monedero, Rafael; Morales-Sanchez, Juan] Tech Univ Cartagena, Dept Informat Technol & Commun, Cartagena 30202, Spain.
   [Weruaga, Luis] Austrian Acad Sci, A-1220 Vienna, Austria.
C3 Universidad Politecnica de Cartagena; Austrian Academy of Sciences
RP Verdú-Monedero, R (corresponding author), Tech Univ Cartagena, Dept Informat Technol & Commun, Cartagena 30202, Spain.
EM rafael.verdu@upct.es; juan.morales@upct.es; weruaga@ieee.org
RI Verdú-Monedero, Rafael/A-2473-2012; Morales-Sánchez, Juan/KHW-1192-2024
OI Verdú-Monedero, Rafael/0000-0001-9227-7397; Morales-Sánchez,
   Juan/0000-0002-2894-3292
CR [Anonymous], BERKELEY SEGMENTATIO
   [Anonymous], 2003, Geometric Level Set Methods in Imaging, Vision, and Graphics
   BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1
   Chaudhury KN, 2007, PATTERN RECOGN LETT, V28, P884, DOI 10.1016/j.patrec.2006.12.003
   Cheng JR, 2006, IEEE T IMAGE PROCESS, V15, P1563, DOI 10.1109/TIP.2006.871140
   Davatzikos C, 1999, IMAGE VISION COMPUT, V17, P27, DOI 10.1016/S0262-8856(98)00087-0
   FERREIRA PJSG, 1994, IEEE T SIGNAL PROCES, V42, P2596, DOI 10.1109/78.324726
   Ferreira PJSG., 2001, Nonuniform Sampling. Theory and Practice, P235
   GIRALDI GA, 2005, CONVEXITY ANAL SNAKE
   Giusto DD, 2004, SIGNAL PROCESS-IMAGE, V19, P517, DOI 10.1016/j.image.2004.04.003
   Hou ZQ, 2005, PATTERN RECOGN LETT, V26, P513, DOI 10.1016/j.patrec.2004.09.001
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   LARSEN OV, 1995, P 8 INT C IM AN PROC, P37
   Liang JM, 2006, MED IMAGE ANAL, V10, P215, DOI 10.1016/j.media.2005.09.002
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Metaxas D.N., 1996, PHYS BASED DEFORMABL
   Metaxas DN, 2002, IEEE T PATTERN ANAL, V24, P1310, DOI 10.1109/TPAMI.2002.1039203
   Ozertem U, 2007, IEEE T IMAGE PROCESS, V16, P2361, DOI 10.1109/TIP.2007.902335
   Papandreou G, 2007, IEEE T IMAGE PROCESS, V16, P229, DOI 10.1109/TIP.2006.884952
   Pujol O, 2005, IMAGE VISION COMPUT, V23, P681, DOI 10.1016/j.imavis.2005.03.007
   SADAMANI R, 1991, P SPIE GEOMETRIC MET, V1570, P202
   Sum KW, 2007, PATTERN RECOGN, V40, P1635, DOI 10.1016/j.patcog.2006.11.006
   TEYTAUD O, 2001, P INT JOINT C NEURAL, V4, P2850
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   Verdú R, 2005, LECT NOTES COMPUT SC, V3708, P483
   Verdú R, 2004, IEEE IMAGE PROC, P2749
   Weruaga L, 2004, IEEE T PATTERN ANAL, V26, P1568, DOI 10.1109/TPAMI.2004.124
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
NR 29
TC 6
Z9 7
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1118
EP 1128
DI 10.1016/j.imavis.2007.12.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300005
DA 2024-07-18
ER

PT J
AU Lin, QH
   Yin, FL
   Mei, TM
   Liang, HL
AF Lin, Qiu-Hua
   Yin, Fu-Liang
   Mei, Tie-Min
   Liang, Hualou
TI A blind source separation-based method for multiple images encryption
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE blind source separation; independent component analysis; image
   encryption
ID INDEPENDENT COMPONENT ANALYSIS; ALGORITHM
AB Blind source separation (BSS) has been successfully applied to many fields such as communications and biomedical engineering. Its application for image encryption, however, remains largely unexplored. In this contribution, a novel BSS-based scheme is proposed for encrypting multiple images, in which the underdetermined BSS problem is fully exploited to achieve the image security. The necessary conditions for generating the key images required for this underdetermined system are presented. The sufficient conditions for constructing the underdetermined mixing matrix for encryption are then described. Extensive computer simulations, coupled with the performance analyses, demonstrate the high level of security of the proposed method. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Lin, Qiu-Hua; Yin, Fu-Liang; Mei, Tie-Min] Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116023, Peoples R China.
   [Liang, Hualou] Univ Texas Houston, Sch Hlth Informat Sci, Houston, TX 77030 USA.
C3 Dalian University of Technology; University of Texas System; University
   of Texas Health Science Center Houston
RP Lin, QH (corresponding author), Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116023, Peoples R China.
EM qhlin@dlut.edu.cn; hualou.liang@uth.tmc.edu
OI Mei, Tiemin/0000-0002-6523-2457
CR Abrard F, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P81, DOI 10.1109/ISSPA.2003.1224820
   Amari SI, 1998, P IEEE, V86, P2026, DOI 10.1109/5.720251
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   BOURBAKIS N, 1992, PATTERN RECOGN, V25, P567, DOI 10.1016/0031-3203(92)90074-S
   Calhoun V.D., 2003, INT S INDEPENDENT CO, P281
   Cao XR, 1996, IEEE T SIGNAL PROCES, V44, P562, DOI 10.1109/78.489029
   Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250
   CARDOSO JF, 2003, 4 INT S IND COMP AN, P1111
   Chang CC, 2001, J SYST SOFTWARE, V58, P83, DOI 10.1016/S0164-1212(01)00029-2
   Chang HKC, 1997, SIGNAL PROCESS-IMAGE, V10, P279, DOI 10.1016/S0923-5965(96)00025-2
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Cichocki A, 1999, NEUROCOMPUTING, V24, P55, DOI 10.1016/S0925-2312(98)00091-5
   Cichocki A, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P455, DOI 10.1109/NNSP.2000.889438
   Cichocki A., 2003, Adaptive Blind Signal and Image Processing
   CICHOCKI A, 2004, ICALAB IMAGE PROCESS
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Dang PP, 2000, IEEE T CONSUM ELECTR, V46, P395, DOI 10.1109/30.883383
   Denning D.E.R., 1982, CRYPTOGRAPHY DATA SE, V112, DOI [10.5555/539308, DOI 10.5555/539308]
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Hyvärinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   KASPRZAK W, 1996, P 13 INT C PATT REC, V2, P398
   Kawakatsu M, 2003, 4 INT S IND COMP AN, V1, P535
   Kuo C. J., 1991, Proceedings. 25th Annual 1991 IEEE International Carnahan Conference on Security Technology (Cat. No.91CH3031-2), P149, DOI 10.1109/CCST.1991.202208
   Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719
   LIN QH, 2003, P IEEE INT C NEUR NE, V2, P1366
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   MOLER C, 1995, RANDOM THOUGHTS MATL, P12
   Norcen R, 2003, COMPUT BIOL MED, V33, P277, DOI 10.1016/S0010-4825(02)00094-X
   Peyravian M, 1999, COMPUT SECUR, V18, P619, DOI 10.1016/S0167-4048(99)82040-9
   RISTANIEMI T, 2003, 4 INT S IND COMP AN, P739
   Salleh M, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P508
   Yen JC, 2000, IEE P-VIS IMAGE SIGN, V147, P167, DOI 10.1049/ip-vis:20000208
NR 33
TC 25
Z9 28
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 788
EP 798
DI 10.1016/j.imavis.2007.08.017
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900006
DA 2024-07-18
ER

PT J
AU Wu, CH
   Horng, SJ
   Wen, CF
   Wang, YR
AF Wu, Chin-Hsiung
   Horng, Shi-Jinn
   Wen, Ching-Feng
   Wang, Yuh-Rau
TI Fast and scalable computations of 2D image moments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image moments; moment invariants; suffix sums; scalable algorithm;
   pattern recognition; reconfigurable optical buses
ID PIPELINED BUS SYSTEM; EFFICIENT COMPUTATION; GEOMETRIC MOMENTS;
   LINEAR-ARRAY; ALGORITHMS; INVARIANTS; TRANSFORM
AB Image moments are used in image analysis for object modelling and matching. The moment computation of a two-dimensional (213) image involves a significant amount of multiplication and addition in a direct method. In this paper, we use the suffix sum functions to compute the gray-level image moments instead of using a direct method. This new method can reduce drastically the number of multiplications required. We first derive the mathematical relationships between moment computations and suffix sums. Based on the derived mathematical relationships, four new parallel algorithms for computing image moments are derived on various computational models. By integrating the advantages of both optical transmission and electronic computation, the 2D image moments can be computed in constant time on a 2D array with reconfigurable optical buses. The performance comparison shows that the proposed method is fast and efficient. In addition, three scalable and cost optimal algorithms are derived on the AROB, the hypercube computer and the EREW PRAM model. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Wu, Chin-Hsiung] Shih Chien Univ, Dept Informat Technol & Commun, Kaohsiung, Taiwan.
   [Horng, Shi-Jinn] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Wen, Ching-Feng] Kaohsiung Med Univ, Gen Educ Ctr, Kaohsiung, Taiwan.
   [Wang, Yuh-Rau] St Johns Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 Shih Chien University; National Taiwan University of Science &
   Technology; Kaohsiung Medical University
RP Wu, CH (corresponding author), Shih Chien Univ, Dept Informat Technol & Commun, Kaohsiung Campus,200 Univ Rd, Kaohsiung, Taiwan.
EM chwu@mail.kh.usc.edu.tw
RI Horng, Shi-Jinn/GVU-0488-2022; Wen, Ching-Feng/AAD-6334-2020; Wen,
   Ching-Feng/C-1215-2010
OI Wen, Ching-Feng/0000-0001-8900-761X; 
CR BENASHER Y, 1991, J PARALLEL DISTR COM, V13, P139, DOI 10.1016/0743-7315(91)90084-M
   Chen K., 1990, Pattern Recognition, V23, P109, DOI 10.1016/0031-3203(90)90053-N
   Cheng HD, 1998, PATTERN RECOGN, V31, P1391, DOI 10.1016/S0031-3203(97)00154-4
   Fich F.E., 1983, Proceedings of the fifteenth annual ACM symposium on Theory of computing, P100
   FU CW, 1993, PATTERN RECOGN, V26, P287, DOI 10.1016/0031-3203(93)90037-W
   GUO ZC, 1991, J PARALLEL DISTR COM, V12, P269, DOI 10.1016/0743-7315(91)90130-2
   HATAMIAN M, 1986, IEEE T ACOUST SPEECH, V34, P546, DOI 10.1109/TASSP.1986.1164853
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Kotoulas L, 2004, REAL-TIME IMAGING, V10, P371, DOI 10.1016/j.rti.2004.09.002
   LADNER RE, 1980, J ACM, V27, P831, DOI 10.1145/322217.322232
   LEIGHTON FT, 1992, HYPERCUBES RELATED N, pCH3
   LI BC, 1995, IEEE T IMAGE PROCESS, V4, P502, DOI 10.1109/83.370680
   Li KQ, 1998, IEEE T PARALL DISTR, V9, P705, DOI 10.1109/71.706044
   Martínez J, 2002, IEEE T IMAGE PROCESS, V11, P1102, DOI 10.1109/TIP.2002.802532
   Miller R., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P925, DOI 10.1109/CVPR.1988.196343
   Pan Y, 1998, INFORM SCIENCES, V106, P237, DOI 10.1016/S0020-0255(97)10013-5
   Pavel S.D., 1996, Journal of Parallel Algorithms and Applications, Volume, V8, P223
   PHILIPS W, 1993, PATTERN RECOGN, V26, P1619, DOI 10.1016/0031-3203(93)90017-Q
   RANKA S, 1990, FUNDAMENTAL OPERATIO, pCH2
   Reeves A. P., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P465
   Shen TW, 1998, PATTERN RECOGN, V31, P115, DOI 10.1016/S0031-3203(97)00035-6
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Wong WH, 1999, IEE P-VIS IMAGE SIGN, V146, P73, DOI 10.1049/ip-vis:19990158
   Wu CH, 2004, IEEE T SYST MAN CY B, V34, P845, DOI 10.1109/TSMCB.2003.817102
   Wu CH, 2003, IEEE T PARALL DISTR, V14, P983, DOI 10.1109/TPDS.2003.1239867
   Wu CH, 2002, J PARALLEL DISTR COM, V62, P1021, DOI 10.1006/jpdc.2001.1821
   Wu CH, 2001, PATTERN RECOGN, V34, P1319, DOI 10.1016/S0031-3203(00)00100-X
   Yang LR, 1996, PATTERN RECOGN, V29, P1061, DOI 10.1016/0031-3203(95)00147-6
   Zhou F, 2000, J VLSI SIG PROCESS S, V25, P5, DOI 10.1023/A:1008163918289
NR 29
TC 1
Z9 3
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 799
EP 811
DI 10.1016/j.imavis.2007.08.016
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900007
DA 2024-07-18
ER

PT J
AU Courteille, F
   Crouzil, A
   Durou, JD
   Gurdjos, P
AF Courteille, F.
   Crouzil, A.
   Durou, J. -D.
   Gurdjos, P.
TI 3D-spline reconstruction using shape from shading: Spline from shading
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE shape from shading; 3D-spline
ID INCORPORATING ILLUMINATION CONSTRAINTS; IMAGE; PROJECTION
AB In this work, we describe an original method of solving the shape from shading (SFS) problem, which relies on the marriage of two simple ideas. On the one hand, we propose to modelize the scene by a parametric surface, namely a 3D-spline. The key advantage is that boundary conditions are no longer required to render the problem well-posed. On the other hand, we introduce the concept of "useful domain": this is a sufficient set of pixels, whose greylevels are in accordance with the SFS hypotheses, which allows to solve the SFS problem on the whole reconstruction domain. The proposed method is described for both formulations of SFS, corresponding to orthographic and perspective projections. We can thus validate our method on synthetic as well as on real images. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Courteille, F.; Crouzil, A.; Durou, J. -D.; Gurdjos, P.] Univ Toulouse 3, IRIT, F-31062 Toulouse 9, France.
C3 Universite de Toulouse; Universite Toulouse III - Paul Sabatier
RP Courteille, F (corresponding author), Univ Toulouse 3, IRIT, 118 Route De Narbonne, F-31062 Toulouse 9, France.
EM courteille@irit.fr
CR [Anonymous], 1975, The psychology of computer vision.
   Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321
   BAKHADYROV I, 2002, P IEEE INT C SYST MA, P218
   Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611
   Bichsel M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P459, DOI 10.1109/CVPR.1992.223150
   BORA PK, 1990, P 14 ANN CONV EXH IE, P260
   Breton P, 1996, PROC CVPR IEEE, P782, DOI 10.1109/CVPR.1996.517161
   Courteille F, 2004, INT C PATT RECOG, P277, DOI 10.1109/ICPR.2004.1334160
   Crouzil A, 2003, IEEE T PATTERN ANAL, V25, P1416, DOI 10.1109/TPAMI.2003.1240116
   Durou JD, 2000, J MATH IMAGING VIS, V12, P99, DOI 10.1023/A:1008361021281
   FALCONE M, 1997, LNCS, V1310, P596
   Farin G., 2001, MORGAN KAUFMANN SERI, V5th
   Hasegawa JK, 1996, COMPUT GRAPH, V20, P351, DOI 10.1016/0097-8493(96)00004-0
   HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3
   HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771
   Kim BH, 1997, COMPUT VIS IMAGE UND, V66, P255, DOI 10.1006/cviu.1997.0515
   KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040
   LEE KM, 1994, CVGIP-IMAG UNDERSTAN, V59, P202, DOI 10.1006/ciun.1994.1013
   LEE KM, 1993, IEEE T PATTERN ANAL, V15, P815, DOI 10.1109/34.236247
   LIONS PL, 1993, NUMER MATH, V64, P323, DOI 10.1007/BF01388692
   MARCH R, 1992, IMAGE VISION COMPUT, V10, P30, DOI 10.1016/0262-8856(92)90081-D
   NAYAR SK, 1991, INT J COMPUT VISION, V6, P173, DOI 10.1007/BF00115695
   Okatani T, 1997, COMPUT VIS IMAGE UND, V66, P119, DOI 10.1006/cviu.1997.0613
   Oliensis J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P692, DOI 10.1109/ICCV.1993.378145
   OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684
   PENNA MA, 1989, IEEE T PATTERN ANAL, V11, P545, DOI 10.1109/34.24790
   PONG TC, 1989, PATTERN RECOGN, V22, P683, DOI 10.1016/0031-3203(89)90005-8
   Prados E, 2005, PROC CVPR IEEE, P870
   Prados E, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P826
   RAGHEB H, 2001, P BRIT MACH VIS C, P541
   Rindfleisch T., 1966, Photometric Eng, V32, P262
   Robles-Kelly A, 2004, IEEE T IMAGE PROCESS, V13, P912, DOI 10.1109/TIP.2004.828414
   Sagona M., 2001, SER ADV MATH APPL SC, V59, P197
   SAITO H, 1994, P 12 INT C PATT REC, V1, P668
   Samaras D, 2003, IEEE T PATTERN ANAL, V25, P247, DOI 10.1109/TPAMI.2003.1177155
   Samaras D, 1998, PROC CVPR IEEE, P322, DOI 10.1109/CVPR.1998.698626
   SAMARAS D, 1999, P INT C COMP VIS, V2, P868
   SZELISKI R, 1991, CVGIP-IMAG UNDERSTAN, V53, P129, DOI 10.1016/1049-9660(91)90023-I
   Tankus A, 2004, PROC CVPR IEEE, P43
   Tankus A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P862
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767
   TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7
   Tsai PS, 1998, OPT ENG, V37, P1212, DOI 10.1117/1.601957
   Worthington PL, 1999, IMAGE VISION COMPUT, V17, P545, DOI 10.1016/S0262-8856(98)00173-5
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
NR 45
TC 10
Z9 10
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 466
EP 479
DI 10.1016/j.imavis.2007.02.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100002
DA 2024-07-18
ER

PT J
AU Kenmochi, Y
   Nomura, Y
AF Kenmochi, Yukiko
   Nomura, Yusuke
TI Local configurations in discrete combinatorial surfaces
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE discrete surface; local configurations; polyhedral complex
ID TOPOLOGY; SET
AB Representing discrete objects by polyhedral complexes, we can define all conceivable topological characteristics of points in discrete objects, namely those of vertices of polyhedral complexes. Such a topological characteristic is determined for each point by observing a configuration of object points in the 3 x 3 x 3 local point set of its neighbors. We study a topological characteristic such that the point is in the boundary of a 3D polyhedral complex and the boundary forms a 2D combinatorial surface. By using the topological characteristic, we present an algorithm which examines whether the central point of a local point set is in a combinatorial surface, and show how many local point configurations exist in combinatorial surfaces in a 3D discrete space. (c) 2006 Elsevier B.V. All rights reserved.
C1 Grp ESIEE, Lab A2SI, Unite Mixte Rech, CNRS UMLV ESIEE,Inst Gaspard Monge, F-93162 Noisy Le Grand, France.
   Okayama Univ, Dept Informat Technol, Okayama 7008530, Japan.
C3 Universite Gustave-Eiffel; Okayama University
RP Kenmochi, Y (corresponding author), Grp ESIEE, Lab A2SI, Unite Mixte Rech, CNRS UMLV ESIEE,Inst Gaspard Monge, BP 99, F-93162 Noisy Le Grand, France.
EM y.kenmochi@esiee.fr
RI Arita, Ryotaro/D-5965-2012
OI Arita, Ryotaro/0000-0001-5725-072X
CR ALEXANDROV PS, 1956, COMBINATION TOPOLOGY, V1
   [Anonymous], IMAGE UNDERSTANDING
   Bertrand G, 1999, LECT NOTES COMPUT SC, V1568, P218
   Bertrand G, 1999, LECT NOTES COMPUT SC, V1568, P229
   Ciria JC, 2005, LECT NOTES COMPUT SC, V3429, P161
   Couprie M, 1998, P SOC PHOTO-OPT INS, V3454, P40, DOI 10.1117/12.323265
   ESNARD A, 2002, 127002 LABRI U BORD
   Francon J, 1996, THEOR COMPUT SCI, V156, P159, DOI 10.1016/0304-3975(95)00059-3
   FRANCON J, 1995, GRAPH MODEL IM PROC, V57, P20, DOI 10.1006/gmip.1995.1003
   Imiya A, 1999, COMPUT VIS IMAGE UND, V75, P307, DOI 10.1006/cviu.1999.0791
   Jonker PP, 2003, LECT NOTES COMPUT SC, V2886, P420
   Kenmochi Y, 2003, LECT NOTES COMPUT SC, V2886, P144
   Kenmochi Y, 1997, PATTERN RECOGN, V30, P1719, DOI 10.1016/S0031-3203(97)00001-0
   KENMOCHI Y, 2005, LNCS, V3429, P336
   Kenmochi Y, 2006, J VIS COMMUN IMAGE R, V17, P738, DOI 10.1016/j.jvcir.2005.11.001
   KHALIMSKY E, 1990, TOPOL APPL, V36, P1, DOI 10.1016/0166-8641(90)90031-V
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   MORGENTHALER DG, 1981, INFORM CONTROL, V51, P227, DOI 10.1016/S0019-9958(81)90290-4
   Stillwell J., 1993, Classical Topology and Combinatorial Group Theory
   Ziegler G. M., 1998, LECT POLYTOPES
NR 20
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1657
EP 1670
DI 10.1016/j.imavis.2006.06.018
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lachaud, JO
   Vialard, A
   de Vieilleville, F
AF Lachaud, Jacques-Olivier
   Vialard, Anne
   de Vieilleville, Francois
TI Fast, accurate and convergent tangent estimation on digital contours
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE multigrid convergence; digital straight segment; tangent estimator;
   maximal segments
ID CURVES; CURVATURE; LENGTH
AB This paper presents a new tangent estimator to digitized curves based on digital line recognition. It outperforms existing ones on important criteria while keeping the same computation time: accuracy on smooth or polygonal shapes, isotropy, preservation of inflexion points and convexity, asymptotic behaviour. Its asymptotic convergence (sometimes called multigrid convergence) is proved in the case of convex shapes with C-3 boundary. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Bordeaux 1, LaBRI, F-33405 Talence, France.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS)
RP Lachaud, JO (corresponding author), Univ Bordeaux 1, LaBRI, 351 Cours Liderat, F-33405 Talence, France.
EM lachaud@labri.fr
RI Lachaud, Jacques-Olivier/JCU-8247-2023; Lachaud,
   Jacques-Olivier/AAL-1080-2020
OI Lachaud, Jacques-Olivier/0000-0003-4236-2133; 
CR ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472
   Braquelaire JP, 1999, GRAPH MODEL IM PROC, V61, P16, DOI 10.1006/prmp.1999.0488
   Coeurjolly D, 2004, IEEE T PATTERN ANAL, V26, P252, DOI 10.1109/TPAMI.2004.1262194
   COEURJOLLY D, 2001, MULTIGRID CONVERGENC
   COEURJOLLY D, 2002, THESIS U LUMIERE LYO
   de Vieilleville F, 2005, LECT NOTES COMPUT SC, V3540, P988
   Debled-Rennesson I, 2003, DISCRETE APPL MATH, V125, P115, DOI 10.1016/S0166-218X(02)00227-5
   DEBLEDRENNESSON I, 1995, INT J PATTERN RECOGN, V9, P635, DOI 10.1142/S0218001495000249
   DEVIEILLEVILLE F, 2005, 136405 LABRI U BORD
   DORST L, 1986, IEEE T PATTERN ANAL, V8, P276, DOI 10.1109/TPAMI.1986.4767781
   FESCHET F, 1999, P DGCI 99 SPRING, P31
   FESCHET F, 2004, IN PRESS DISCRETE AP
   KIM CE, 1982, IEEE T PATTERN ANAL, V6, P618
   Klette R, 2000, J MATH IMAGING VIS, V13, P173, DOI 10.1023/A:1011289414377
   KOVALEVSKY V, 1992, P ROB COMP VIS, P218
   Lachaud JO, 2003, LECT NOTES COMPUT SC, V2886, P434
   LACHAUD JO, 2001, P 4 INT WORKSH VIS F, V2059, P542
   LACHAUD JO, 2005, LNCS, V3429, P140
   LACHAUD JO, 2005, 134705 LABRI U BORD
   LENOIR A, 1996, LECT NOTES COMPUTER, V1176, P101
   MATAS J, 1995, P 8 INT C IM AN PROC, P83
   REITERDOERKSEN H, 2004, GEOMETRIC PROPERTIES
   Reveilles J.-P., 1991, THESIS U LOUIS PASTE
   Tajine M, 2003, LECT NOTES COMPUT SC, V2886, P114
   VIALARD A, 1996, LECT NOTES COMPUTER, V1176, P24
   WORRING M, 1993, CVGIP-IMAG UNDERSTAN, V58, P366, DOI 10.1006/ciun.1993.1048
NR 26
TC 49
Z9 50
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1572
EP 1587
DI 10.1016/j.imavis.2006.06.019
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200006
DA 2024-07-18
ER

PT J
AU Li, ZW
   Duan, GL
   Sun, JH
   Lv, X
AF Li, Zhanwei
   Duan, Guolin
   Sun, Jizhou
   Lv, Xinran
TI Obtaining virtual lighting condition based on images using NNs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image-based rendering (IBR); neural networks (NNs); virtual images;
   lighting conditions; dynamic reconstruction; virtual reality
AB Using Neural Networks, this paper present a method of generating virtual images under virtual lighting conditions. The relationship between the lighting conditions and the color of image is non-linear, several neural networks technologies are introduced to make curve fitting. As a result, virtual images of same scene under different lighting conditions can be deduced from known real scene image, and the inherent relations of image color and outside lighting conditions are discovered. Combining techniques of IBMR or panoramic image, the model of scene is recovered. Further, combining the dynamic virtual images obtained by our method, time-sequence dynamic virtual scene can be reconstructed and revisited in virtual reality. (c) 2006 Elsevier B.V. All rights reserved.
C1 Hebei Univ Technol, Tianjin 300130, Peoples R China.
   Tianjin Univ, Tianjin 300072, Peoples R China.
C3 Hebei University of Technology; Tianjin University
RP Li, ZW (corresponding author), Hebei Univ Technol, Tianjin 300130, Peoples R China.
EM lzw@hebut.edu.cn; glduan@hebut.edu.cn; jzsun@tju.edu.cn
CR DEBEVEC PE, 1996, THESIS U CALIF, P109
   LAGARIAS JC, 1977, J OPTIMIZATION
   LI Z, 2003, TIME SEQUENCE DYNAMI
   LI Z, COMPUTING MODELS BAS
   NISHINO K, 2001, P ICCV
   Shum HY, 2000, PROC SPIE, V4067, P2, DOI 10.1117/12.386541
   SHUM HY, SIGGRAPH 99
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Szeliski R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P251, DOI 10.1145/258734.258861
   YU Y, SIGGRAPH99
NR 10
TC 0
Z9 0
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1249
EP 1254
DI 10.1016/j.imavis.2006.07.029
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000005
DA 2024-07-18
ER

PT J
AU Caleb-Solly, P
   Smith, JE
AF Caleb-Solly, P.
   Smith, J. E.
TI Adaptive surface inspection via interactive evolution
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE machine vision; configuration; interative; evolution
AB An increasingly frequent application of Machine Vision technologies is in automated surface inspection for the detection of defects in manufactured products. Such systems offer significant benefits in terms of cost, detection rates, and user-satisfaction over conventional human inspection systems. However, they usually require significant investment of expert time to set up, are "brittle" in the sense of being highly specialised to the task for which they are tuned, and are consequently sensitive to changes in operating conditions or product specifications. This raises problems within an industrial setting, where operating conditions or requirements may change, and the end-users are experts in their manufacturing field, but not in image processing.
   In this paper, we describe the development of a rapidly reconfigurable system in which the users' tacit knowledge and requirements are elicited via a process of Interactive Evolution, finding the image processing parameters to achieve the required goals without any need for specialised knowledge of the machine vision system. We show that the resulting segmentation can be quickly and easily evolved from scratch, and achieves detection rates comparable to those of a hand-tuned system on a hot-rolled steel defect recognition problem. (C) 2007 Published by Elsevier B.V.
C1 Univ W England, Fac Comp Engn & Math Sci, Bristol BS16 1QY, Avon, England.
C3 University of West England
RP Smith, JE (corresponding author), Univ W England, Fac Comp Engn & Math Sci, Bristol BS16 1QY, Avon, England.
EM praminda.caleb-solly@uwe.ac.uk; james.smith@uwe.ac.uk
RI Smith, Jim/M-7533-2015
OI Smith, Jim/0000-0001-7908-1859; Caleb-Solly,
   Praminda/0000-0001-8821-0464
CR ALOCK R, 2004, ARTIFICIAL INTELLIGE
   Back Thomas, 1991, P 4 INT C GEN ALG, V2
   BILES JA, 1994, ICMC P
   BRODATZ P, 1966, PHOTOGRAPHIC ALBUM A
   CALEB P, P IEEE 4 INT C KNOWL, V1, P103, DOI UNSP 0-7803-6400-7
   CALEBSOLLY P, 2004, P 6 INT C AD COMP DE
   Dawkins Richard., 1987, BLIND WATCHMAKER
   EIBEN AE, 2003, INTRO EVOLUTIONARY
   Eichhorn A, 2005, APPL SOFT COMPUT, V5, P301, DOI 10.1016/j.asoc.2004.08.002
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Rosenfeld A, 2000, COMPUT VIS IMAGE UND, V78, P222, DOI 10.1006/cviu.2000.0835
   SMITH J, 1995, EVOLUTIONARY COMPUTI, V2, P48
   Smith ML, 2005, COMPUT IND, V56, P773, DOI 10.1016/j.compind.2005.05.024
   TAKAGI H, 1998, IEEE INT C INT ENG S
   TAKAGI H, 1999, P INT C SYST MAN CYB, V3, P657
NR 15
TC 35
Z9 42
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1058
EP 1072
DI 10.1016/j.imavis.2006.04.023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300004
DA 2024-07-18
ER

PT J
AU Bayro-Corrochano, E
   Ortegón-Aguilar, J
AF Bayro-Corrochano, Eduardo
   Ortegon-Aguilar, Jaime
TI Lie algebra approach for tracking and 3D motion estimation using
   monocular vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Lie algebra; template tracking; monocular 3D motion estimation; least
   squares estimation; system identification
AB The main purpose of this paper is to estimate 2D and 3D transformation parameters. All the group transformations are represented in terms of their Lie algebra elements. The Lie algebra approach assures to follow the shortest path or geodesic in the involved Lie group. For the estimation of the Lie algebra parameters, we take advantage of the theory of system identification. Two experiments are presented to show the potential of the method. First, we carry out the estimation of the affine or projective parameters related to the transformation involved in monocular region tracking. Second, we develop a monocular method to estimate 3D motion of an object in the visual space. In the latter, the six parameters of the rigid motion are estimated based on measurements of the six parameters of the affine transformation in the image. (C) 2006 Elsevier B.V. All rights reserved.
C1 CINVESTAV, Unidad Guadalajara, Dept Elect Engn & Comp Sci, Zapopan, Jalisco, Mexico.
C3 CINVESTAV - Centro de Investigacion y de Estudios Avanzados del
   Instituto Politecnico Nacional
RP Bayro-Corrochano, E (corresponding author), CINVESTAV, Unidad Guadalajara, Dept Elect Engn & Comp Sci, Av Cient 1145,Col Bajio, Zapopan, Jalisco, Mexico.
EM edb@gdl.cinvestav.mx; jortegon@gdl.cinvestav.mx
RI Aguilar, Jaime Ortegon/K-1460-2019
OI Aguilar, Jaime Ortegon/0000-0001-8595-1355
CR [Anonymous], P IEEE C INT ROB SYS
   [Anonymous], 1981, P 7 INT JOINT C ART
   AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557
   Buenaposada M, 2002, INT C PATT RECOG, P697, DOI 10.1109/ICPR.2002.1048397
   Chiuso A, 2002, IEEE T PATTERN ANAL, V24, P523, DOI 10.1109/34.993559
   Colombo C, 1999, IEEE T SYST MAN CY A, V29, P92, DOI 10.1109/3468.736363
   Daniilidis K, 1997, COMPUT VIS IMAGE UND, V68, P158, DOI 10.1006/cviu.1997.0535
   Drummond T, 2000, INT J COMPUT VISION, V37, P21, DOI 10.1023/A:1008125412549
   Frankel T., 1997, GEOMETRY PHYS INTRO
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Hall B.C, 2003, Lie Groups, Lie Algebras, and Representations; An Elementary Introduction
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Mann S, 1997, IEEE T IMAGE PROCESS, V6, P1281, DOI 10.1109/83.623191
   PARK FC, 1995, INT J ROBOT RES, V14, P609, DOI 10.1177/027836499501400606
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   SHUM H.-Y., 2000, INT J COMPUT VISION, V16, P63
   THOMAS HJR, 1990, IEEE T NEURAL NETWOR, V1, P131
   Tommasini T, 1998, PROC CVPR IEEE, P178, DOI 10.1109/CVPR.1998.698606
NR 22
TC 16
Z9 20
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 907
EP 921
DI 10.1016/j.imavis.2006.07.005
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600013
DA 2024-07-18
ER

PT J
AU Bosch, A
   Muñoz, X
   Martí, R
AF Bosch, Anna
   Munoz, Xavier
   Marti, Robert
TI Which is the best way to organize/classify images by content?
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE scene classification; object recognition; semantic concepts; image
   segmentation
ID SCENE CLASSIFICATION; RETRIEVAL; FEATURES
AB Thousands of images are generated every day, which implies the necessity to classify, organise and access them using an easy, faster and efficient way. Scene classification, the classification of images into semantic categories (e.g. coast, mountains and streets), is a challenging and important problem nowadays. Many different approaches concerning scene classification have been proposed in the last few years. This article presents a detailed review of some of the most commonly used scene classification approaches. Furthermore, the surveyed techniques have been tested and their accuracy evaluated. Comparative results are shown and discussed giving the advantages and disadvantages of each methodology. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Girona, Dept Elect Informat & Automat, Girona 17071, Spain.
C3 Universitat de Girona
RP Bosch, A (corresponding author), Univ Girona, Dept Elect Informat & Automat, Campus Montilivi,Edifici P 4,Av Lluis Santalo, Girona 17071, Spain.
EM aboschr@eia.udg.es
RI Martí, Robert/H-7917-2015; Munoz, Xavier/R-9446-2018
OI Martí, Robert/0000-0002-8080-2710; Munoz, Xavier/0000-0002-2560-3540
CR Aksoy S, 2005, IEEE T GEOSCI REMOTE, V43, P581, DOI 10.1109/TGRS.2004.839547
   [Anonymous], EURASIP J ADV SIGNAL
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   BOSCH A, 2005, IEEE INT C IM PROC G, V2, P1218
   BOSCH A, 2006, IN PRESS IAPR INT C
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   BOUTELL M, 2001, REV STAT ART SEM SCE
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Fan JP, 2005, PATTERN RECOGN, V38, P865, DOI 10.1016/j.patcog.2004.07.011
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Fredembach C, 2004, IEEE T PATTERN ANAL, V26, P1645, DOI 10.1109/TPAMI.2004.123
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Jing F, 2003, LECT NOTES COMPUT SC, V2728, P206
   Lazebnik S, 2003, PROC CVPR IEEE, P319
   LAZEBNIK S, 2006, IN PRESS IEEE COMP S
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li FF, 2002, P NATL ACAD SCI USA, V99, P9596, DOI 10.1073/pnas.092277599
   Luo J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P745, DOI 10.1109/ICIP.2001.958601
   Luo JB, 2005, PATTERN RECOGN, V38, P919, DOI 10.1016/j.patcog.2004.11.001
   Luo JB, 2004, IMAGE VISION COMPUT, V22, P227, DOI 10.1016/j.imavis.2003.09.012
   Mojsilovic A, 2002, PROC SPIE, V4662, P266, DOI 10.1117/12.469523
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   OLIVA A, 2002, INT WORKSH BIOL MOT, V2525, P263
   Paek SY, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1133, DOI 10.1109/ICME.2000.871560
   Perronnin F, 2006, LECT NOTES COMPUT SC, V3954, P464
   Porter LC, 2001, BRIGHAM YOUNG U STUD, V40, P49
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   RUSSELL BC, 2006, IN PRESS IEEE COMP S
   Serrano N, 2004, PATTERN RECOGN, V37, P1773, DOI 10.1016/j.patcog.2004.03.003
   Shen JL, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P340, DOI 10.1109/MMMC.2005.66
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Squire DM, 2000, PATTERN RECOGN LETT, V21, P1193, DOI 10.1016/S0167-8655(00)00081-7
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   TEH Y, 2005, NEURAL INFORM PROCES, V17, P1385
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951
   TORRALBA A, 1999, INT C COMP VIS, P1253
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vailaya A, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P518, DOI 10.1109/MMCS.1999.779255
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   Varma M, 2003, PROC CVPR IEEE, P691
   Vogel J, 2004, LECT NOTES COMPUT SC, V3115, P207
   VOGEL J, 2004, SELECTED READINGS VI, V33
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
NR 48
TC 151
Z9 182
U1 0
U2 41
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 778
EP 791
DI 10.1016/j.imavis.2006.07.015
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600002
DA 2024-07-18
ER

PT J
AU Comport, AI
   Marchand, E
   Chaumette, F
AF Comport, Andrew I.
   Marchand, Eric
   Chaumette, Francois
TI Kinematic sets for real-time robust articulated object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE non-rigid articulated motion; model based; 3D tracking; real-time;
   kinematic sets
ID NONRIGID MOTION; FRAMEWORK; MODELS; POSE
AB In this article, a new approach is given for real-time visual tracking of a class of articulated non-rigid objects in 31). The main contribution of this paper consists in symmetrically modeling the motion and velocity of an articulated object via a novel kinematic set approach. This is likened to a Lagrange-d'Alembert formulation in classical physics. The advantages of this new model over pre-existing methods include improved precision, robustness and efficiency, leading to real-time performance. Furthermore, a general class of mechanical joints can be considered and the method can track objects where previous approaches have failed due to a lack of visual information. In summary, a joint configuration is modeled by using Pfaffian velocity constraints. The configuration and location of a joint is then used to build a general Jacobian Matrix, which relates individual rigid body velocities (twists) to an underlying minimal subspace. A closed loop control law is then derived in order to minimize a set of distance errors in the image and estimate the system parameters. The tracking is locally based upon efficient distance criterion. Experimental results show prismatic, rotational and helical type links and eight general parameters. A statistical M-estimation technique is applied to improve robustness. A monocular camera system was used as a real-time sensor to verify the theory. (c) 2006 Elsevier B.V. All rights reserved.
C1 INRIA Rennes, Lagadic, IRISA, F-35042 Rennes, France.
C3 Universite de Rennes
RP Comport, AI (corresponding author), INRIA Rennes, Lagadic, IRISA, Campus Beaulieu, F-35042 Rennes, France.
EM andrew.comport@sophia.inria.fr
RI Francois, Chaumette/AAH-1481-2021; Comport, Andrew I/A-4672-2012;
   Marchand, Eric/AAF-2809-2019
OI Francois, Chaumette/0000-0002-1238-4385; Marchand,
   Eric/0000-0001-7096-5236
CR Aggarwal JK, 1998, COMPUT VIS IMAGE UND, V70, P142, DOI 10.1006/cviu.1997.0620
   BOUTHEMY P, 1989, IEEE T PATTERN ANAL, V11, P499, DOI 10.1109/34.24782
   Comport AI, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P36, DOI 10.1109/ISMAR.2003.1240686
   COMPORT AI, 2004, IEEE WORKSH ART NONR
   DELAMARRE Q, 1999, INT C COMP VIS
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   Denavit J., 1955, J. Appl. Mech., V22, P215, DOI DOI 10.1115/1.4011045
   Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c
   DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   ESPIAU B, 1992, IEEE T ROBOTIC AUTOM, V8, P313, DOI 10.1109/70.143350
   Fua P, 1997, COMPUT VIS IMAGE UND, V65, P148, DOI 10.1006/cviu.1996.0568
   Huber P., 1981, Robust Statistics
   Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   Marchand T, 2002, COMPUT GRAPH FORUM, V21, P289, DOI 10.1111/1467-8659.t01-1-00588
   Metaxas DN, 2002, IEEE T PATTERN ANAL, V24, P1310, DOI 10.1109/TPAMI.2002.1039203
   Murray RM, 1994, MATH INTRO ROBOTIC M
   NUNOMAKI T, 2000, 1 INT WORKSH ART MOT, P78
   Plänkers R, 2003, IEEE T PATTERN ANAL, V25, P1182, DOI 10.1109/TPAMI.2003.1227995
   ROCKETT RW, 1984, MATH THEORY NETWORKS, P120
   Rosenberg R.M., 1977, ANAL DYNAMICS DISCRE
   RUF A, 1999, IEEE INT C COMP VIS, V2, P789
   Samson C., 1991, Robot Control: the Task Function Approach
   WU Y, 2003, COMPUTER VISION 2003, V2, P1094
   Zhou L, 2001, IEEE T PATTERN ANAL, V23, P1330, DOI 10.1109/34.969121
NR 29
TC 13
Z9 15
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 374
EP 391
DI 10.1016/j.imavis.2005.10.005
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Carvalho, BA
   Herman, GT
AF Carvalho, Bruno A.
   Herman, Gabor T.
TI Low-dose, large-angled cone-beam helical CT data reconstruction using
   algebraic reconstruction techniques
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, State Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE cone-beam helical CT; ART; block-ART; PI-original; PI-geometry; blobs;
   Bcc grid
ID SYMMETRICAL VOLUME ELEMENTS; IMAGE-RECONSTRUCTION; TOMOGRAPHY;
   ALGORITHMS; EFFICIENT; ANGIOGRAPHY
AB We report on results on the use of two variants of the algebraic reconstruction techniques (ART) for reconstructing from helical cone-beam computerized tomography (CT) data: a standard one that considers a single ray in an iterative step and a block version which treats simultaneously several cone-beam projections when calculating an iterative step. Both algorithms were implemented using the modified Kaiser-Bessel window functions, also known as blobs, placed on the body-centered cubic (bcc) grid. The algorithms were used to reconstruct phantoms from data collected for the PI-geometry for four different maximum cone-beam angles (2.39, 7.13, 9.46 and 18.43 degrees). Both scattering and quantum noise (for three different noise levels) were introduced to create noisy projections that simulate low-dose examinations. The results presented here (for both noiseless and noisy data sets) point to the facts that, as opposed to a filtered back-projection algorithm, the quality of the reconstructions produced by the ART methods does not suffer from the increase in the cone-beam angle and it is more robust in the presence of noise. (c) 2006 Elsevier B.V. All rights reserved.
C1 UFRN, Dept Informat & Matemat Aplicada, Natal, RN, Brazil.
   CUNY, Grad Ctr, Doctoral Program Comp Sci, New York, NY USA.
C3 Universidade Federal do Rio Grande do Norte; City University of New York
   (CUNY) System
RP Carvalho, BA (corresponding author), UFRN, Dept Informat & Matemat Aplicada, Natal, RN, Brazil.
EM bruno_m_carvalho@yahoo.com
OI Motta de Carvalho, Bruno/0000-0002-9122-0257
CR CARVALHO BM, 2003, THESIS U PENNSYLVANI
   CARVALHO BM, 2003, BRAZ S COMP GRAPH IM
   CARVALHO BM, 2001, D 2001 6 INT M FULL, P249
   Defrise M, 2000, PHYS MED BIOL, V45, P623, DOI 10.1088/0031-9155/45/3/305
   EGGERMONT PPB, 1981, LINEAR ALGEBRA APPL, V40, P37, DOI 10.1016/0024-3795(81)90139-7
   FELDKAMP LA, 1984, J OPT SOC AM A, V1, P612, DOI 10.1364/JOSAA.1.000612
   GRANGEAT P, 1990, MATH METHODS TOMOGRA, P66
   Herman G. T, 1980, IMAGE RECONSTRUCTION
   HERMAN GT, 1993, IEEE T MED IMAGING, V12, P600, DOI 10.1109/42.241889
   HERMAN GT, 2001, INHERENTLY PARALLEL, P307
   Kinahan PE, 1995, IEEE T NUCL SCI, V42, P2281, DOI 10.1109/23.489428
   LEWITT RM, 1990, J OPT SOC AM A, V7, P1834, DOI 10.1364/JOSAA.7.001834
   LEWITT RM, 1992, PHYS MED BIOL, V37, P705, DOI 10.1088/0031-9155/37/3/015
   Marabini R, 1998, ULTRAMICROSCOPY, V72, P53, DOI 10.1016/S0304-3991(97)00127-7
   MATEJ S, 1995, IEEE T NUCL SCI, V42, P1361, DOI 10.1109/23.467854
   Matej S, 1996, IEEE T MED IMAGING, V15, P68, DOI 10.1109/42.481442
   MATEJ S, 1994, PHYS MED BIOL, V39, P355, DOI 10.1088/0031-9155/39/3/004
   MULLERMERBACH J, 1996, LITHISYR1866
   Ogata I, 1999, COMPUT MED IMAG GRAP, V23, P143, DOI 10.1016/S0895-6111(99)00002-6
   Proksa R, 2000, IEEE T MED IMAGING, V19, P848, DOI 10.1109/42.887834
   Schaller S, 1998, IEEE T MED IMAGING, V17, P244, DOI 10.1109/42.700736
   Schweiger M, 2003, J ELECTRON IMAGING, V12, P583, DOI 10.1117/1.1586919
   Sun ZH, 2004, COMPUT MED IMAG GRAP, V28, P3, DOI 10.1016/j.compmedimag.2003.09.001
   Tam KC, 2004, PHYS MED BIOL, V49, P2453, DOI 10.1088/0031-9155/49/11/023
   Turbell H, 2000, INT J IMAG SYST TECH, V11, P91, DOI 10.1002/(SICI)1098-1098(2000)11:1<91::AID-IMA10>3.0.CO;2-F
   Turbell H, 2001, THESIS LINKOPING U S
   Watson G. N., 1944, THEORY BESSEL FUNCTI
   [No title captured]
NR 28
TC 11
Z9 12
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 78
EP 94
DI 10.1016/j.imavis.2006.03.003
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600010
DA 2024-07-18
ER

PT J
AU Sifre-Maunier, L
   Taylor, RG
   Berge, P
   Culioli, J
   Bonny, JM
AF Sifre-Maunier, Laurence
   Taylor, Richard G.
   Berge, Philippe
   Culioli, Joseph
   Bonny, Jean-Marie
TI A global unimodal thresholding based on probabilistic reference maps for
   the segmentation of muscle images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE unimodal thresholding; segmentation; muscle
ID BEEF; CLASSIFICATION; PERIMYSIUM; COLLAGEN
AB A global probabilistic maps thresholding (PMT) method was applied to characterise intramuscular connective tissue (IMCT) distribution on images of muscle histological sections exhibiting unimodal histograms. Probabilistic reference maps were defined and then used to set-up thresholding rules, derived from linear combinations of parameters calculated from the intensity histogram of the images. This PMT method was objectively compared to Rosin's unimodal thresholding algorithm (RT) and validated by a histochemical quantification of IMCT collagen. Morphometrical parameters of the IMCT (area, length and thickness of the extracted network) were determined for different muscles and used to quantify INICT distribution differences. (c) 2006 Elsevier BN. All rights reserved.
C1 INRA, Meat Res Unit, Ctr Theix, F-63122 St Genes Champanelle, France.
C3 INRAE
RP Sifre-Maunier, L (corresponding author), INRA, Meat Res Unit, Ctr Theix, F-63122 St Genes Champanelle, France.
EM lmaunier@clermont.inra.fr
CR [Anonymous], 1985, INTRO DIGITAL IMAGE
   Baradez MO, 2004, PATTERN RECOGN, V37, P1131, DOI 10.1016/j.patcog.2003.12.008
   Basset O, 2000, FOOD CHEM, V69, P437, DOI 10.1016/S0308-8146(00)00057-1
   Boleman SJ, 1997, J ANIM SCI, V75, P1521
   Bonny JM, 2001, J SCI FOOD AGR, V81, P337, DOI 10.1002/1097-0010(200102)81:3<337::AID-JSFA827>3.0.CO;2-W
   Culioli J., 1995, EXPRESSION TISSUE PR, P239
   GEESINK GH, 1995, MEAT SCI, V41, P7, DOI 10.1016/0309-1740(94)00066-G
   Li J, 2001, MEAT SCI, V57, P341, DOI 10.1016/S0309-1740(00)00105-4
   Li J, 1999, MEAT SCI, V53, P17, DOI 10.1016/S0309-1740(99)00031-5
   Likar B, 2000, J MICROSC-OXFORD, V197, P285, DOI 10.1046/j.1365-2818.2000.00669.x
   LIU A, 1994, MEAT SCI, V38, P315, DOI 10.1016/0309-1740(94)90120-1
   LOPEZDELEON A, 1985, J HISTOCHEM CYTOCHEM, V33, P737, DOI 10.1177/33.8.2410480
   MCCORMICK RJ, 1994, MEAT SCI, V36, P79, DOI 10.1016/0309-1740(94)90035-3
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PURSLOW PP, 2004, INT C MEAT SCI TECHN, P305
   Rosin PL, 2001, PATTERN RECOGN, V34, P2083, DOI 10.1016/S0031-3203(00)00136-9
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2761, DOI 10.1016/S0167-8655(03)00119-3
   Sifre L, 2005, J AGR FOOD CHEM, V53, P8390, DOI 10.1021/jf0508910
   SIMMONS A, 1994, MAGNET RESON MED, V32, P121, DOI 10.1002/mrm.1910320117
   Tan JL, 2004, J FOOD ENG, V61, P27, DOI 10.1016/S0260-8774(03)00185-7
   Torrescano G., 2001, 47 INT C MEAT SCI TE, P236
   TSAI DM, 1995, PATTERN RECOGN LETT, V16, P653, DOI 10.1016/0167-8655(95)80011-H
   Van der Weken D, 2004, IMAGE VISION COMPUT, V22, P695, DOI 10.1016/j.imavis.2004.03.002
   Zhang YJ, 1997, PATTERN RECOGN LETT, V18, P963, DOI 10.1016/S0167-8655(97)00083-4
NR 24
TC 12
Z9 14
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1080
EP 1089
DI 10.1016/j.imavis.2006.03.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300004
DA 2024-07-18
ER

PT J
AU Cheng, J
   Yang, H
   Zhou, Y
   Cui, YY
AF Cheng, Jian
   Yang, Jie
   Zhou, Yue
   Cui, Yingying
TI Flexible background mixture models for foreground segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE foreground segmentation; background subtraction; mixture models; EM
   algorithm; maximum a posteriori (MAP)
ID TRACKING
AB Robust and real-time foreground segmentation is a crucial topic in many computer vision applications. Background subtraction is a typical approach to segment foreground by comparing each new frame with a learned model of the scene background in image sequences taken from a static camera. In this paper, we propose a flexible method to estimate the background model with the finite Gaussian mixture model. A stochastic approximation procedure is used to recursively estimate the parameters of the Gaussian mixture model, and to simultaneously obtain the asymptotically optimal number of the mixture components. Our method is highly memory and time efficient. Moreover, it can effectively deal with the many scenes, such as the indoor scene, the outdoor scene, and the clutter scene. The experimental results show our method is efficient and effective. (C) 2006 Elsevier B.V. All rights reserved.
C1 Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University
RP Cheng, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.
EM ch_jian@sjtu.edu.cn
RI , chengjian/KGL-5551-2024
OI , chengjian/0000-0003-1289-2758
CR [Anonymous], P IEEE INT C COMP VI
   Brand M, 1999, NEURAL COMPUT, V11, P1155, DOI 10.1162/089976699300016395
   Cucchiara R, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P360, DOI 10.1109/ICIAP.2001.957036
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Friedman N., 1997, PROC UNCERTAINTY ART, P175
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Joga S., 2000, Proc. European Conf. on Computer Vision, P336
   Kato J, 2002, IEEE T PATTERN ANAL, V24, P1291, DOI 10.1109/TPAMI.2002.1033221
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Power P., 2002, Proceedings Image and Vision Computing New Zealand, P267
   Rasmussen CE, 2000, ADV NEUR IN, V12, P554
   Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095
   Ridder C., 1995, PROC INT C RECENT AD, P193
   RISSANEN J, 1987, J ROY STAT SOC B MET, V49, P223
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Stenger B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P294, DOI 10.1109/ICCV.2001.937532
   Wallace CS, 1999, COMPUT J, V42, P270, DOI 10.1093/comjnl/42.4.270
   Webb A.R., 2003, Statistical Pattern Recognition
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Ziou D, 2004, INT C PATT RECOG, P68, DOI 10.1109/ICPR.2004.1334042
   Zivkovic Z, 2004, IEEE T PATTERN ANAL, V26, P651, DOI 10.1109/TPAMI.2004.1273970
NR 23
TC 53
Z9 66
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 473
EP 482
DI 10.1016/j.imavis.2006.01.018
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600007
DA 2024-07-18
ER

PT J
AU Dosil, R
   Pardo, XM
   Fdez-Vidal, XR
AF Dosil, R
   Pardo, XM
   Fdez-Vidal, XR
TI Data-driven synthesis of composite-feature detectors for 3D image
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D image representation; composite features; multiresolution analysis;
   mutual information; hierarchical clustering
ID EDGE-DETECTION; CONTOURS; VISION; ENERGY; MODEL
AB Most image analysis techniques are based upon low level descriptions of the data. It is important that the chosen representation is able to discriminate as much as possible among independent image features. In particular, this is of great importance in segmentation with deformable models, which must be guided to the target object boundary avoiding other image features. In this paper, we present a multiresolution method for the decomposition of a volumetric image into its most relevant visual patterns. which we define as features associated to local energy maxima of the image. The method involves the clustering of a set of predefined band-pass energy filters according to their ability to segregate the different features in the image. In this way, the method generates a set of composite-feature detectors tuned to the specific visual patterns present in the data. Clustering is accomplished by defining a distance metric between the frequency features that reflects the degree of alignment of their energy maxima. This distance is related to the mutual information of their responses' energy maps. As will be shown. the method is able to isolate the frequency components of independent visual patterns in 3D images. We have applied this composite-feature detection method to the initialization of active models. Among the visual patterns detected, those associated to the segmentation target are selected by user interaction to define the initial state of a geodesic active model. We will demonstrate that this initialization technique facilitates the evolution of the model to the proper boundary. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Santiago Compostela, Santiago De Compostela 15782, Galicia, Spain.
C3 Universidade de Santiago de Compostela
RP Univ Santiago Compostela, Campus Univ Sur S-N, Santiago De Compostela 15782, Galicia, Spain.
EM rdosil@usc.es
RI Dosil, Raquel/JSK-7672-2023; Pardo, Xose M./L-8567-2014; Fdez-Vidal,
   Xose R./L-5740-2014
OI Dosil, Raquel/0000-0001-8171-9268; Pardo, Xose M./0000-0002-3997-5150;
   Fdez-Vidal, Xose R./0000-0001-9388-7461
CR [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], 1548 MIT ART INT LAB
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CHAMORROMARTINE.J, 2003, IEEE INT C AC SPEECH, V3, P165
   Faas FGA, 2003, LECT NOTES COMPUT SC, V2749, P36
   Field D. J, 1993, WAVELETS FRACTALS FO, P151
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KOVESI PD, 1996, THESIS U W AUSTR MAY
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   MANJUNATH BS, 1993, IEEE T NEURAL NETWOR, V4, P96, DOI 10.1109/72.182699
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073
   MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4
   OWENS R, 1989, PATTERN RECOGN LETT, V9, P233, DOI 10.1016/0167-8655(89)90002-0
   Pal NR, 1997, PATTERN RECOGN, V30, P847, DOI 10.1016/S0031-3203(96)00127-6
   Rodriguez-Sánchez R, 1999, IEEE T PATTERN ANAL, V21, P1044, DOI 10.1109/34.799910
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   VENKATESH S, 1990, PATTERN RECOGN LETT, V11, P339, DOI 10.1016/0167-8655(90)90043-2
   Weickert J, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P43, DOI 10.1007/0-387-21810-6_3
   Yu WC, 2003, IMAGE VISION COMPUT, V21, P447, DOI 10.1016/S0262-8856(03)00012-X
NR 25
TC 8
Z9 8
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2006
VL 24
IS 3
BP 225
EP 238
DI 10.1016/j.imavis.2005.11.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 031PI
UT WOS:000236716100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shivakumara, P
   Kumar, GH
   Guru, DS
   Nagabhushan, P
AF Shivakumara, P
   Kumar, GH
   Guru, DS
   Nagabhushan, P
TI Sliding window based approach for document image mosaicing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE window matching; overlapping region; document image mosaicing
AB There are situations where it is not possible to capture a large document with a given imaging media such as Scanner and Xerox machine in a single stretch because of their inherent limitations. This result in capturing a large document in terms of split components of an image. Hence, the need is to mosaic the split components into a large document image.
   In this paper, we present a new and simple approach to mosaic the two split images of a large document based on matching sum of values of pixels of window in the split images. The method compares the sum of values of pixels of window in split images to identify Overlapping Region (OLR) in the split images. The OLR, a region in common, helps in mosaicing of two split images of large document. However, a small OLR is assumed to be available at the end of split images of a large document. In addition to this, the OLR in the split images depends on the size of the window. Experimental results show that the performance of the proposed method is satisfactorily. (C) 2005 Elsevier B.V. All rights reserved.
C1 Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 117543, Singapore.
   Univ Mysore, Dept Studies Comp Sci Manasagangotri, Mysore 570006, Karnataka, India.
C3 National University of Singapore; University of Mysore
RP Natl Univ Singapore, Sch Comp, Dept Comp Sci, 3 Sci Dr 2, Singapore 117543, Singapore.
EM hudempsk@yahoo.com
RI Palaiahnakote, Shivakumara/ITU-6488-2023; Palaiahnakote,
   Shivakumara/B-6261-2013
CR GURU DSS, 2001, P NAT C NCCIT KIL TA, P69
   GURU DSS, 2001, P NAT C DOC AN REC N
   GURU DSS, 2002, P 3 NAT C REC TRENDS
   PELEG S, 1997, VIRTUAL CAMERAS USIN
   SCHUTTE K, P 1 ANN C ADV SCH CO, P353
   SHIVAKUMARA P, 2003, P NAT WORKSH MACH IN, P16
   SHIVAKUMARA P, 2001, P NAT C REC TRENDS A
   WHICHELLO AP, 1997, DOCUMENT IMAGE MOSAI
   ZAPPALA AR, 1997, P BRIT MACH VIS C CO, V2, P600
NR 9
TC 7
Z9 8
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 94
EP 100
DI 10.1016/j.imavis.2005.09.015
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200009
DA 2024-07-18
ER

PT J
AU Bae, H
   Kim, S
AF Bae, H
   Kim, S
TI Real-time face detection and recognition using hybrid-information
   extracted from face space and facial features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face detection; face recognition; eigenface space; geometric feature;
   facial feature; neural network
AB This paper describes both face detection using the eigenface space and face recognition using neural networks. Real-time face detection from face images was performed in two steps. In the first step, a normalized skin color map based on the Gaussian function was applied to extract a face candidate region. The facial feature information in the candidate region was employed to detect the face region. In this step, face detection was sequentially accomplished using three methods. DFFS, a combination of DFFS and DIFS, and template matching were used. Facial features were extracted according to the Euclidian distance between the determined face region and the predefined eigenfaces from the face region. In the second step, neural network models were trained using 120 images for face recognition. In the experiments, three neural network models corresponding to input variables that included features from face spaces, facial features (geometrical features), and both, were constructed. The image of each person was obtained based on the various directions, poses, and facial expressions. The number of hidden layers was changed from 1 to 3 for several tests of the neural network models. The goal of this study was to reduce lighting effects in order to achieve high-performance of face recognition, because face recognition cannot cope with changes due to lighting. (C) 2005 Elsevier Ltd All rights reserved.
C1 Pusan Natl Univ, Sch Elect & Comp Engn, Pusan 609735, South Korea.
C3 Pusan National University
RP Kim, S (corresponding author), Pusan Natl Univ, Sch Elect & Comp Engn, Pusan 609735, South Korea.
EM baehyeon@pusan.ac.kr; sskim@pusan.ac.kr
CR [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   Bassiou N, 2001, IEEE IMAGE PROC, P1026, DOI 10.1109/ICIP.2001.959223
   Choi JM, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P1686, DOI 10.1109/ISIE.2001.931962
   Eickeler S, 2001, INT CONF ACOUST SPEE, P1505, DOI 10.1109/ICASSP.2001.941217
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   Menser B, 1999, IEE CONF PUBL, P620, DOI 10.1049/cp:19990397
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   NASSIF S, 1997, CAN C EL COMP ENG CC, V3, P391
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   TIQIONG X, 2003, P 2003 INT C NEUR NE, V1, P228
   Verma RC, 2003, IEEE T PATTERN ANAL, V25, P1215, DOI 10.1109/TPAMI.2003.1233896
   Zhang J, 1997, P IEEE, V85, P1423, DOI 10.1109/5.628712
   ZHANG L, 2000, 4 INT C KNOWL BAS IN, P117
NR 15
TC 19
Z9 19
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1181
EP 1191
DI 10.1016/j.imavis.2005.07.017
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500007
DA 2024-07-18
ER

PT J
AU Murtagh, F
   Raftery, AE
   Starck, JL
AF Murtagh, F
   Raftery, AE
   Starck, JL
TI Bayesian inference for multiband image segmentation via model-based
   cluster trees
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Bayesian model; Markov model; Potts; Ising; Information Criterion;
   quantization; clustering; segmentation; multiband; multispectral;
   hyperspectral; multichannel; information fusion
ID QUANTIZATION
AB We consider the problem of multiband image clustering and segmentation. We propose a new methodology for doing this, called model-based cluster trees. This is grounded in model-based clustering, which bases inference on finite mixture models estimated by maximum likelihood using the EM algorithm, and automatically chooses the number of Clusters by Bayesian model selection, approximated using BIC, the Bayesian Information Criterion. For segmentation, model-based clustering is based on a Mark-v spatial dependence model. In the Markov model case, the Bayesian model selection criterion takes account of spatial neighborhood information, and is termed PLIC, the Pseudolikelihood Information Criterion. We build a cluster tree by first segmenting an image band, then using the second band to cluster each of the level 1 Clusters, and continuing if required for further bands. The tree is pruned automatically as a part of the algorithm by using Bayesian model selection to choose the number of clusters at each stage. An efficient algorithm for implementing the methodology is proposed. An example is used to evaluate this new approach, and the advantages and disadvantages of alternative approaches to multiband segmentation and clustering are discussed. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ London Royal Holloway & Bedford New Coll, Dept Comp Sci, Egham TW20 0EX, Surrey, England.
   Univ Washington, Dept Stat, Seattle, WA 98915 USA.
   CEA Saclay, SEI SAP DAPNIA, F-91191 Gif Sur Yvette, France.
C3 University of London; Royal Holloway University London; University of
   Washington; University of Washington Seattle; CEA; Universite Paris
   Saclay
RP Univ London Royal Holloway & Bedford New Coll, Dept Comp Sci, Egham TW20 0EX, Surrey, England.
EM fmurtagh@acm.org; raftery@stat.washington.edu; jstarck@cea.fr
RI Raftery, Adrian M/P-2042-2015; Starck, Jean-Luc/D-9467-2011
OI Starck, Jean-Luc/0000-0003-2177-7794
CR [Anonymous], THESIS U WASHINGTON
   Barreto D, 2003, P SOC PHOTO-OPT INS, V4877, P144, DOI 10.1117/12.463768
   BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Campbell JG, 1997, PATTERN RECOGN LETT, V18, P1539, DOI 10.1016/S0167-8655(97)00148-7
   Campbell JG, 1999, INT J IMAG SYST TECH, V10, P339, DOI 10.1002/(SICI)1098-1098(1999)10:4<339::AID-IMA5>3.0.CO;2-3
   CELEUX G, 1995, PATTERN RECOGN, V28, P781, DOI 10.1016/0031-3203(94)00125-6
   Collet C, 2004, PATTERN RECOGN, V37, P2337, DOI 10.1016/j.patcog.2004.03.017
   Dasgupta A, 1998, J AM STAT ASSOC, V93, P294, DOI 10.2307/2669625
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DJORGOVSKI S, 2001, SPIE P, V4472, P43
   Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578
   Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131
   Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   McLachlan G., 1988, MIXTURE MODELS
   McLachlan G. J., 1997, The EM Algorithm and Extensions, V473, P486
   Mukherjee S, 1998, ASTROPHYS J, V508, P314, DOI 10.1086/306386
   Murtagh F, 2003, IEEE T GEOSCI REMOTE, V41, P2952, DOI 10.1109/TGRS.2003.819874
   Murtagh F, 2003, OPT ENG, V42, P1375, DOI 10.1117/1.1564104
   Murtagh F, 2003, PATTERN RECOGN LETT, V24, P2001, DOI 10.1016/S0167-8655(03)00038-2
   MURTAGH F, 1985, COMPUT J, V28, P82, DOI 10.1093/comjnl/28.1.82
   Pei SC, 2000, IEEE T CIRC SYST VID, V10, P913, DOI 10.1109/76.867929
   Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063
   Roeder K, 1997, J AM STAT ASSOC, V92, P894, DOI 10.2307/2965553
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Stanford DC, 2002, IEEE T PATTERN ANAL, V24, P1517, DOI 10.1109/TPAMI.2002.1046170
   Starck J. L., 2002, ASTR AST LI
   Tate SR, 1997, IEEE T COMPUT, V46, P477, DOI 10.1109/12.588062
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   2001, MR MULTIRESOLUTION A, V3
NR 31
TC 23
Z9 25
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2005
VL 23
IS 6
BP 587
EP 596
DI 10.1016/j.imavis.2005.02.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 924CA
UT WOS:000228955100004
DA 2024-07-18
ER

PT J
AU Ye, J
   Fu, GK
   Poudel, UP
AF Ye, J
   Fu, GK
   Poudel, UP
TI High-accuracy edge detection with Blurred Edge Model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE edge detection; sub-pixel accuracy; least-squared-error solution;
   blurred edge model
ID SUBPIXEL ACCURACY; LOCATION
AB A high-accuracy edge detection algorithm at sub-pixel level is proposed in this work. A bluffed edge model is adopted here, and a least-squared-error based solution is derived. Its applications to both synthetic and real images are presented for evaluation. It is compared with two other sub-pixel edge detectors. One uses a moment-based approach, and the other an interpolation-based approach. The comparison shows higher accuracy of the proposed algorithm, even for image data with significant noise. An application of the proposed algorithm in engineering is also introduced herein. (c) 2004 Elsevier B.V. All rights reserved.
C1 Wayne State Univ, Dept Civil & Environm Engn, Ctr Adv Bridge Engn, Detroit, MI 48202 USA.
C3 Wayne State University
RP Wayne State Univ, Dept Civil & Environm Engn, Ctr Adv Bridge Engn, Detroit, MI 48202 USA.
EM jye@wayne.edu
CR Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838
   KISWORO M, 1994, IEEE T PATTERN ANAL, V16, P405, DOI 10.1109/34.277593
   LYVERS EP, 1989, IEEE T PATTERN ANAL, V11, P1293, DOI 10.1109/34.41367
   MOSSA AG, 1999, THESIS WAYNE STATE U
   NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852
   OVERINGTON I, 1987, IMAGE VISION COMPUT, V5, P217, DOI 10.1016/0262-8856(87)90052-7
   Shan Y, 2000, IMAGE VISION COMPUT, V18, P1015, DOI 10.1016/S0262-8856(00)00040-8
   Steger C., 2000, International Archives of Photogrammetry and Remote Sensing, VXXXIII, P141
   STEGER C, 1998, THESIS TU MUNCHEN GE
   TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502
   TABBONE S, 1992, 11 INT C PATT REC, V3, P655
   YE J, 2004, 8 PAN AM C APPL MECH, V8
NR 13
TC 78
Z9 95
U1 1
U2 49
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2005
VL 23
IS 5
BP 453
EP 467
DI 10.1016/j.imavis.2004.07.007
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 917XA
UT WOS:000228501300001
DA 2024-07-18
ER

PT J
AU Burgi, PY
AF Burgi, PY
TI Motion estimation based on the direction of intensity gradient
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE motion field; optical flow constraint; histogramming; intensity gradient
   direction; parametric estimation
ID OPTICAL-FLOW; COMPUTATION; VELOCITY; COLOR
AB The optical flow constraint (OFC) equation has been extensively studied in computer vision to estimate motion from image sequences. Traditionally the OFC relies on spatio-temporal brightness variations caused by motion. However, many other features are in principle appropriate, including gradient directions of the image intensity. Given gradient directions are more tolerant to changes in lighting, they seem to be an adequate choice for computing optical flows. Their applicability in the OFC is, however, not straightforward as the gradient direction is independent of the gradient magnitude, and is not defined in homogeneous areas. To palliate to these difficulties, a form of OFC equation based on probability distributions of gradient directions is proposed. The performance of the approach is assessed by experiments realized on synthetic and real world images. (C) 2004 Elsevier B.V. All rights reserved.
C1 Ctr Suisse Elect & Microtech SA, CH-2007 Neuchatel, Switzerland.
C3 Swiss Center for Electronics & Microtechnology (CSEM)
RP Burgi, PY (corresponding author), Univ Geneva, IT Div, Rue Gen Dufour 24, CH-1211 Geneva 4, Switzerland.
EM pierre-yves.burgi@adm.unige.ch
OI Burgi, Pierre-Yves/0000-0002-4956-9279
CR [Anonymous], 1981, P 7 INT JOINT C ART
   Balboa RM, 2000, NEURAL COMPUT, V12, P1485, DOI 10.1162/089976600300015231
   Barbaro M, 2002, IEEE J SOLID-ST CIRC, V37, P160, DOI 10.1109/4.982422
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Black MJ, 1996, IEEE T PATTERN ANAL, V18, P972, DOI 10.1109/34.541407
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Brandt JW, 1997, INT J COMPUT VISION, V25, P5, DOI 10.1023/A:1007987001439
   Burgi PY, 2000, NEURAL COMPUT, V12, P1839, DOI 10.1162/089976600300015169
   Chang MM, 1997, IEEE T IMAGE PROCESS, V6, P1326, DOI 10.1109/83.623196
   Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827
   DelBimbo A, 1996, IEEE T IMAGE PROCESS, V5, P720, DOI 10.1109/83.495956
   FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2
   FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772
   Galvin B., 1998, PROC 9 BRIT MACHINE, V1, P195
   HAUSSECKER H, 1999, HDB COMPUTER VISION, P310
   HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jazwinski A., 1970, STOCHASTIC PROCESSES
   Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090
   Konishi S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P573, DOI 10.1109/CVPR.1999.786996
   KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350
   LI S, 1995, RANDOMI FIELD MODELI
   Liu HC, 1997, INT J COMPUT VISION, V22, P141, DOI 10.1023/A:1007988028861
   LUETTGEN MR, 1994, IEEE T IMAGE PROCESS, V3, P41, DOI 10.1109/83.265979
   MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001
   Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777
   Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147
   MITICHE A, 1987, PATTERN RECOGN, V20, P173, DOI 10.1016/0031-3203(87)90051-3
   NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5
   NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9
   Rüedi PF, 2003, IEEE J SOLID-ST CIRC, V38, P2325, DOI 10.1109/JSSC.2003.819169
   SCHIELE B, 1997, 453 MIT MED LAB
   Simoncelli E.P., 1999, HDB COMPUTER VISION, P397
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895
   VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781
   Weng Juyang., 1993, MOTION STRUCTURE IMA
   WOHN KY, 1983, PATTERN RECOGN, V16, P563, DOI 10.1016/0031-3203(83)90072-9
NR 38
TC 14
Z9 15
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2004
VL 22
IS 8
BP 637
EP 653
DI 10.1016/j.imavis.2004.01.003
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RV
UT WOS:000221481200005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Horiuchi, T
AF Horiuchi, T
TI Colorization algorithm using probabilistic relaxation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE colorization; probabilistic relaxation; markov property; grayscale image
AB This paper presents a method of colorizing a black and white imagery based on the probabilistic relaxation algorithm. Since the colorization is an ill-posed problem, a user specifies a suitable color on each isolated pixel of an image as prior information in this paper. Then other pixels in the image are colorized automatically. The colorizing process is done by assuming local Markov property on the images. By minimizing a total of RGB pixel-wise differences, the problem can be considered as a combinatorial optimization problem and it is solved by using the probabilistic relaxation. The proposed algorithm works very well when a few percent color pixels are known with confidence. (C) 2003 Elsevier B.V. All rights reserved.
C1 Chiba Univ, Fac Engn, Dept Informat & Image Sci, Inage Ku, Chiba 2638522, Japan.
C3 Chiba University
RP Chiba Univ, Fac Engn, Dept Informat & Image Sci, Inage Ku, 1-33 Yayoi Cho, Chiba 2638522, Japan.
EM horiuchi@faculty.chiba-u.jp
RI Horiuchi, Takahiko/M-7864-2017
OI Horiuchi, Takahiko/0000-0002-8197-6499
CR DROR RO, 2001, P INT WORKSH STAT CO
   Gonzales Rafael C., 1987, DIGITAL IMAGE PROCES
   KAMADA M, 1988, PATTERN RECOGN, V21, P175, DOI 10.1016/0031-3203(88)90025-8
   KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5
   Markle W., 1991, Canadian Patent, Patent No. 1291260
   MORI K, 1995, IEEE PACIF, P74, DOI 10.1109/PACRIM.1995.519413
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519
   ROY PV, 1998, Patent No. 5831633
   WELSH T, 2002, P ACM SIGGRAPH 2002, V20, P277
NR 10
TC 38
Z9 42
U1 2
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2004
VL 22
IS 3
BP 197
EP 202
DI 10.1016/j.imavis.2003.08.004
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 776RH
UT WOS:000189130100003
DA 2024-07-18
ER

PT J
AU Nunes, JC
   Bouaoune, Y
   Delechelle, E
   Niang, O
   Bunel, P
AF Nunes, JC
   Bouaoune, Y
   Delechelle, E
   Niang, O
   Bunel, P
TI Image analysis by bidimensional empirical mode decomposition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE bidimensional empirical mode decomposition texture analysis;
   unsupervised texture decomposition; radial basis function; surface
   interpolation
ID TEXTURE CLASSIFICATION; SEGMENTATION
AB Recent developments in analysis methods on the non-linear and non-stationary data have received large attention by the image analysts. In 1998, Huang introduced the empirical mode decomposition (EMD) in signal processing. The EMD approach, fully unsupervised, proved reliable monodimensional (seismic and biomedical) signals. The main contribution of our approach is to apply the EMD to texture extraction and image filtering, which are widely recognized as a difficult and challenging computer vision problem. We developed an algorithm based on bidimensional empirical mode decomposition (BEMD) to extract features at multiple scales or spatial frequencies. These features, called intrinsic mode functions, are extracted by a sifting process. The bidimensional sifting process is realized using morphological operators to detect regional maxima and thanks to radial basis function for surface interpolation. The performance of the texture extraction algorithms, using BEMD method, is demonstrated in the experiment with both synthetic and natural images. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Paris 12, LERISS, F-94010 Creteil, France.
C3 Universite Paris-Est-Creteil-Val-de-Marne (UPEC)
RP Univ Paris 12, LERISS, Bat P2 Piece 230 61 Ave Gen de Gaulle, F-94010 Creteil, France.
EM nunes@univ-paris12.fr
RI Nunes, Jean-Claude/O-7431-2017
OI Nunes, Jean-Claude/0000-0001-6560-1518
CR [Anonymous], 1993, Wavelets: Algorithms and Applications
   Beucher S., 2001, Image Anal. Stereol, V20, P137, DOI [10.5566/ias.v20.p137-141, DOI 10.5566/IAS.V20.P137-141]
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   CESMELI E, 1997, P IEEE INT C NEUR NE, V3, P1529
   CHEN CC, 1989, IEEE T MED IMAGING, V8, P133, DOI 10.1109/42.24861
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   DUNN D, 1994, IEEE T PATTERN ANAL, V16, P130, DOI 10.1109/34.273736
   Eom KB, 1999, IMAGE VISION COMPUT, V17, P233, DOI 10.1016/S0262-8856(98)00105-X
   FLANDRIN P, 2003, IN PRESS IEEE SIGNAL
   Gimel'farb G., 1999, IMAGE TEXTURES GIBBS
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Havlicek JP, 2000, IEEE T IMAGE PROCESS, V9, P227, DOI 10.1109/83.821736
   Hormigo J, 1998, IEEE T SIGNAL PROCES, V46, P1757, DOI 10.1109/78.678519
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   JULESZ B, 1983, BELL SYST TECH J, V62, P1619, DOI 10.1002/j.1538-7305.1983.tb03502.x
   LAINE A, 1993, TR93025 U FLOR CTR C
   LIU X, 25 EL
   LIVENS S, 1997, P 6 INT C IM PROC IT, P581
   Mallat S, 1996, P IEEE, V84, P604, DOI 10.1109/5.488702
   MATERKA A, 1998, B11 COST
   NUNES JC, 2003, IN PRESS MACH VISION
   OONINCX PJ, 2002, PNAR0203
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   Peters RA, 1996, J ELECTRON IMAGING, V5, P198, DOI 10.1117/12.231976
   Pichler O, 1996, PATTERN RECOGN, V29, P733, DOI 10.1016/0031-3203(95)00127-1
   PICKETT RM, 1970, VISUAL ANAL TEXTURE
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   REED TR, 1990, IEEE T PATTERN ANAL, V12, P1, DOI 10.1109/34.41379
   SARKAR N, 1992, PATTERN RECOGN, V25, P1035, DOI 10.1016/0031-3203(92)90066-R
   Tuceryan M., 1998, HDB PATTERN RECOGNIT, V2nd
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Wickerhauser M.V., 1994, Adapted wavelet analysis from theory to software, V1st
NR 36
TC 528
Z9 650
U1 1
U2 105
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2003
VL 21
IS 12
BP 1019
EP 1026
DI 10.1016/S0262-8856(03)00094-5
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 737UW
UT WOS:000186251000001
DA 2024-07-18
ER

PT J
AU Chen, LH
   Lin, JJ
AF Chen, LH
   Lin, JJ
TI Mean quantization based image watermarking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE copyright protection; image watermarking; wavelet transform
ID VISIBILITY
AB In this paper, a mean quantization based watermarking technique for the copyright protection of still digital images is proposed. Watermark embedding is performed in the wavelet transform domain by encoding each watermark bit into a set of wavelet coefficients. Watermark extraction does not require the existence of the original image. The proposed technique also integrates the human visual system characteristics and complementary hiding strategy to achieve the highest possible robustness without degrading image quality. Experimental results show that the proposed watermarking scheme is robust to a wide range of image distortions and is superior to the conventional quantization based technique. (C) 2003 Elsevier Science B.V. All fights reserved.
C1 Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, Taipei 242, Taiwan.
C3 Fu Jen Catholic University
RP Chen, LH (corresponding author), Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, Hsinchuang, Taipei 242, Taiwan.
EM lchen@csie.fju.edu.tw
CR Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   CARLSON CR, 1980, P SID, V21, P229
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cornsweet T.N., 1970, Visual Perception
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Delaigle JF, 1998, SIGNAL PROCESS, V66, P319, DOI 10.1016/S0165-1684(98)00013-9
   Eggers J. J., 2002, INFORMED WATERMARKIN
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Ohnishi J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P514, DOI 10.1109/MMCS.1996.535017
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Pérez-González F, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P889
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Swanson MD, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P211, DOI 10.1109/ICIP.1996.560421
   Tao B, 1997, INT CONF ACOUST SPEE, P2985, DOI 10.1109/ICASSP.1997.595419
   VANSCHYNDEL RG, 1994, P INT C IM PROCESSIN, V2, P286
   VEHEL JL, 2000, P INT C PATT REC BAR, V3, P417
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   WOLFGANG RB, 1996, P INT C IM PROC
   Xia XG, 1998, OPT EXPRESS, V3, P497, DOI 10.1364/OE.3.000497
NR 22
TC 39
Z9 50
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2003
VL 21
IS 8
BP 717
EP 727
DI 10.1016/S0262-8856(03)00067-2
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 706VM
UT WOS:000184475800004
DA 2024-07-18
ER

PT J
AU Alfano, PD
   Pastore, VP
   Rosasco, L
   Odone, F
AF Alfano, Paolo Didier
   Pastore, Vito Paolo
   Rosasco, Lorenzo
   Odone, Francesca
TI Top-tuning: A study on transfer learning for an efficient alternative to
   fine tuning for image classification with fast kernel methods
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fast kernel methods; Training on a budget; Fast training; Transfer
   learning; Image classification
ID CONVOLUTIONAL NEURAL-NETWORKS
AB The impressive performance of deep learning architectures is associated with a massive increase in model complexity. Millions of parameters need to be tuned, with training and inference time scaling accordingly, together with energy consumption. But is massive fine-tuning always necessary? In this paper, focusing on image classification, we consider a simple transfer learning approach exploiting pre-trained convolutional features as input for a fast-to-train kernel method. We refer to this approach as top-tuning since only the kernel classifier is trained on the target dataset. In our study, we perform more than 3000 training processes focusing on 32 small to medium-sized target datasets, a typical situation where transfer learning is necessary. We show that the toptuning approach provides comparable accuracy with respect to fine-tuning, with a training time between one and two orders of magnitude smaller. These results suggest that top-tuning is an effective alternative to finetuning in small/medium datasets, being especially useful when training time efficiency and computational resources saving are crucial.
C1 [Alfano, Paolo Didier; Rosasco, Lorenzo] Italian Insitute Technol, Via Morego 30, I-16163 Genoa, Italy.
   [Alfano, Paolo Didier; Pastore, Vito Paolo; Rosasco, Lorenzo; Odone, Francesca] Univ Genoa, DIBRIS, Via Dodecaneso 35, I-16143 Genoa, Italy.
   [Rosasco, Lorenzo] Massachusetts Inst Technol MIT, Inst Technol, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
C3 University of Genoa
RP Pastore, VP (corresponding author), Univ Genoa, DIBRIS, Via Dodecaneso 35, I-16143 Genoa, Italy.
EM paolo.alfano@iit.it; vito.paolo.pastore@unige.it;
   Lorenzo.Rosasco@unige.it; Francesca.Odone@unige.it
OI PASTORE, VITO PAOLO/0000-0002-5827-5571
FU European Research Council [SLING 819789]; FSE REACT-EU-PON 2014-2020 [DM
   1062/2021]
FX P.D.A. and L.R. acknowledge the financial support of the European
   Research Council (grant SLING 819789). V.P.P. acknowledges fundings from
   FSE REACT-EU-PON 2014-2020, DM 1062/2021.
CR A. challenge team, 2019, Best Artworks of All Time
   Allard UC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2464, DOI 10.1109/IROS.2016.7759384
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Belkin M., 2018, PR MACH LEARN RES, P541
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Canziani A., 2017, arXiv
   Ceola F, 2022, IEEE T ROBOT, DOI 10.1109/TRO.2022.3164331
   Chemkaeva D., 2020, Football vs Rugby
   Cheng Yu, 2017, ARXIV
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Clorichel P.-A., 2018, Boat Types Recognition
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doersch C, 2017, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2017.226
   Dosovitskiy Alexey, 2021, ICLR
   Elson J, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P366
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Garcia-Gasulla D, 2018, J ARTIF INTELL RES, V61, P563, DOI 10.1613/jair.5756
   Gautam T., 2021, Football vs rugby
   Gholami Amir, 2021, ARXIV210313630, DOI DOI 10.1201/9781003162810-13
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Han D, 2017, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR.2017.668
   He FX, 2019, ADV NEUR IN, V32
   He J., 2021, INT C LEARNING REPRE
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huh M, 2016, Arxiv, DOI arXiv:1608.08614
   Jia ML, 2022, LECT NOTES COMPUT SC, V13693, P709, DOI 10.1007/978-3-031-19827-4_41
   Jin J., 2015, INT C LEARNING REPRE
   Jogin Manjunath, 2018, 2018 3rd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT), P2319, DOI 10.1109/RTEICT42901.2018.9012507
   Kather Jakob Nikolas, 2016, Zenodo
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khosla A., 2012, Novel Dataset for Fine-Grained Image Categorization
   Kolesnikov Alexander, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P491, DOI 10.1007/978-3-030-58558-7_29
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumra S, 2017, IEEE INT C INT ROBOT, P769, DOI 10.1109/IROS.2017.8202237
   Hutchinson ML, 2017, Arxiv, DOI [arXiv:1711.05099, DOI 10.48550/ARXIV.1711.05099]
   Li D, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P477, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.76
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Li ZP, 2017, LECT NOTES COMPUT SC, V10638, P858, DOI 10.1007/978-3-319-70139-4_87
   Lian D., 2022, Advances in Neural Information Processing Systems, V35, P109
   M.A. Lab, 2020, Bean Disease Dataset
   Maiettini E, 2018, IEEE INT C INT ROBOT, P5770
   Maji S, 2013, Arxiv, DOI arXiv:1306.5151
   Mamalet Franck, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. 22nd International Conference on Artificial Neural Networks, P58, DOI 10.1007/978-3-642-33266-1_8
   Masters D, 2018, Arxiv, DOI arXiv:1804.07612
   Meanti G., 2020, Advances in Neural Information Processing Systems, V33, P14410
   Meanti G, 2022, PR MACH LEARN RES, V151
   Moro M, 2022, COMPUT METH PROG BIO, V226, DOI 10.1016/j.cmpb.2022.107119
   Moroney L., 2019, Horses or Humans Dataset
   Musco C, 2017, ADV NEUR IN, V30
   Mwebaze E, 2019, Arxiv, DOI arXiv:1908.02900
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Nystrom EJ, 1930, ACTA MATH-DJURSHOLM, V54, P185, DOI 10.1007/BF02547521
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Olsen A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-38343-3
   Oztel I, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P290, DOI [10.1109/UBMK.2019.8907203, 10.1109/ubmk.2019.8907203]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Pasquale G, 2019, ROBOT AUTON SYST, V112, P260, DOI 10.1016/j.robot.2018.11.001
   Pastore VP, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68662-3
   Prabhavalkar N., 2020, Indian food
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Rauf HT, 2019, DATA BRIEF, V26, DOI 10.1016/j.dib.2019.104340
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452
   Ridnik T., 2021, 35 C NEURAL INFORM P
   Rudi A, 2017, ADV NEUR IN, V30
   Schölkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416, DOI 10.1007/3-540-44581-1_27
   Snell J, 2017, ADV NEUR IN, V30
   Soares Eduardo, 2020, HarvardDataverse, V1
   Srivastava P., 2020, Multi-Class Weather
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
   Sunga P., 2018, Make Up vs No Make Up
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   T. T. Team, 2019, Flowers
   Tan MX, 2019, PR MACH LEARN RES, V97
   Ulucan O, 2019, 2019 INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS CONFERENCE (ASYU), P62, DOI 10.1109/asyu48272.2019.8946388
   Vaswani A, 2017, ADV NEUR IN, V30
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Williams F, 2021, PROC CVPR IEEE, P9944, DOI 10.1109/CVPR46437.2021.00982
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhai XH, 2019, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2019.00156
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zheng ZB, 2018, IEEE T IND INFORM, V14, P1606, DOI 10.1109/TII.2017.2785963
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 98
TC 1
Z9 1
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2024
VL 142
AR 104894
DI 10.1016/j.imavis.2023.104894
EA DEC 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GJ9D5
UT WOS:001152410500001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Zhao, HG
   Jin, GZ
   Jiang, XL
   Li, MY
AF Zhao, Honggang
   Jin, Guozhu
   Jiang, Xiaolong
   Li, Mingyong
TI SDE-RAE:CLIP-based realistic image reconstruction and editing network
   using stochastic differential diffusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stochastic differential equations; GANs; Image reconstruction; Image
   editing; CLIP; Diffusion model
AB Generative Adversarial Networks (GANs) has long dominated the field of image reconstruction and editing. It is capable to train a generator in an adversarial way, which can fool the discriminator and enable the generated image to be of high quality. However, this approach is often difficult to train, and the final result is hard to converge. Each different style of image requires construction of different datasets and complex optimization functions, and the training process is uncertain. To solve this problem, we propose a realistic image reconstruction and editing method based on Stochastic Differential Equation (SDE-RAE), where the diffusion model converts Gaussian noise to real photos by iterative denoising. What we only need to do is to construct simple loss functions in the reconstruction process to achieve high-quality image reconstruction, and we propose a novel semantic enhancement CLIP (Contrastive Language-Image Pre-Training) to interfere with the SDE parameter optimization direction in the editing process. Simple text is needed to achieve unique image editing. Our method generates high-quality images that retain the texture and contour features of the original image. Specifically, we manipulate the initial image, perturb the image by adding random noise, and then iteratively denoise the image by reverse SDE, manipulating the image's RGB pixels to achieve image reconstruction and editing. Code and dataset https://github.com/haizhu12/SDE-RAE.
C1 [Zhao, Honggang; Jin, Guozhu; Jiang, Xiaolong; Li, Mingyong] Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing, Peoples R China.
   [Li, Mingyong] Chongqing Natl Ctr Appl Math, Chongqing, Peoples R China.
C3 Chongqing Normal University
RP Li, MY (corresponding author), Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing, Peoples R China.
EM 2021210516098@stu.cqnu.edu.cn; 2021110516041@stu.cqnu.edu.cn;
   2022110516060@stu.cqnu.edu.cn; limingyong@cqnu.edu.cn
RI jiang, xiaolong/KJM-3457-2024
FU Chongqing Natural Science Foundation of China [CSTB2022NSCQ-MSX1417];
   Science and Technology Research Program of Chongqing Municipal Education
   Commission [KJZD-K202200513]; Chongqing Normal Uni- versity Graduate
   Student Research and Innovation Program [YZH23015, YZH22021]
FX This work was supported by Chongqing Natural Science Foundation of China
   (Grant no. CSTB2022NSCQ-MSX1417) and the Science and Technology Research
   Program of Chongqing Municipal Education Commission (Grant no.
   KJZD-K202200513) . Chongqing Normal Uni- versity Graduate Student
   Research and Innovation Program (Grant no. YZH23015, YZH22021) .
CR Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Anderson B.D., 1982, Stochastic Processes and their Applications, V12, P313, DOI [10.1016/0304-4149(82)90051-5, DOI 10.1016/0304-4149(82)90051-5]
   Anirudh R, 2020, INT J COMPUT VISION, V128, P2459, DOI 10.1007/s11263-020-01310-5
   Brock A, 2017, Arxiv, DOI arXiv:1609.07093
   Cheng SI, 2023, IEEE WINT CONF APPL, P4043, DOI 10.1109/WACV56688.2023.00404
   Choi J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14347, DOI 10.1109/ICCV48922.2021.01410
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Couairon G, 2022, PROC CVPR IEEE, P18249, DOI 10.1109/CVPR52688.2022.01773
   Crowson K, 2022, LECT NOTES COMPUT SC, V13697, P88, DOI 10.1007/978-3-031-19836-6_6
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dhariwal P, 2021, ADV NEUR IN, V34
   Gal R, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530164
   Goetschalckx L, 2019, IEEE I CONF COMP VIS, P5743, DOI 10.1109/ICCV.2019.00584
   Gu SY, 2022, PROC CVPR IEEE, P10686, DOI 10.1109/CVPR52688.2022.01043
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Hyvärinen A, 2005, J MACH LEARN RES, V6, P695
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jahanian A., 2019, arXiv
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim G., 2021, Diffusionclip: Text-Guided Image Manipulation Using Diffu-sion Models
   Kim G, 2022, PROC CVPR IEEE, P2416, DOI 10.1109/CVPR52688.2022.00246
   Kim J, 2020, Arxiv, DOI [arXiv:1907.10830, DOI 10.48550/ARXIV.1907.10830]
   Kwon G, 2023, IEEE T PATTERN ANAL, V45, P12179, DOI 10.1109/TPAMI.2023.3283551
   Kwon G, 2022, PROC CVPR IEEE, P18041, DOI 10.1109/CVPR52688.2022.01753
   Meng Chenlin, 2021, INT C LEARN REPR
   Minyoung Huh, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P17, DOI 10.1007/978-3-030-58536-5_2
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   Radford A, 2021, PR MACH LEARN RES, V139
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Shen Yujun, 2020, P IEEE CVF C COMP VI, P9243, DOI DOI 10.1109/CVPR42600.2020.00926
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song JM, 2022, Arxiv, DOI [arXiv:2010.02502, DOI 10.48550/ARXIV.2010.02502]
   Song Y, 2019, ADV NEUR IN, V32
   Song Y, 2021, Arxiv, DOI [arXiv:2011.13456, DOI 10.48550/ARXIV.2011.13456]
   Su Xuan, 2022, INT C LEARN REPR
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Vincent P, 2011, NEURAL COMPUT, V23, P1661, DOI 10.1162/NECO_a_00142
   Wang SY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14030, DOI 10.1109/ICCV48922.2021.01379
   Wang TF, 2022, PROC CVPR IEEE, P11369, DOI 10.1109/CVPR52688.2022.01109
   Wang ZZ, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P1095, DOI 10.1145/3503161.3547939
   Wu ZZ, 2021, PROC CVPR IEEE, P12858, DOI 10.1109/CVPR46437.2021.01267
   Xia WH, 2021, PROC CVPR IEEE, P2256, DOI 10.1109/CVPR46437.2021.00229
   Yu FS, 2016, Arxiv, DOI arXiv:1506.03365
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   [张乐 Zhang Yue], 2023, [人类学学报, Acta Anthropologica Sinica], V42, P1
   Zhang Z., 2022, ADV NEURAL INFORM PR, P13718
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
NR 51
TC 0
Z9 0
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104836
DI 10.1016/j.imavis.2023.104836
EA OCT 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA W3WW1
UT WOS:001090974000001
DA 2024-07-18
ER

PT J
AU Sekeroglu, B
AF Sekeroglu, Boran
TI Time-shift image enhancement method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Space-time; Time-shift; Image enhancement; Contrast adjustment
ID QUALITY ASSESSMENT
AB This paper proposes a time-shift image enhancement method for representing constant images in spacetime, deriving the associated events in a specified time, and using them to enhance the degraded images. We assumed constant images as moving objects on a z-plane with different velocities and adopted the spacetime using the Lorentz factor to represent the movement of objects at the constant moment. The changes between the events and a reference frame are used to create adjacent z-plane events. The events provide statistical and pixel-based relationships in order to reconstruct a single frame for the common perspective of the reference image in time. Then, the gamma correction is applied in the reconstructed image based on the obtained statistics to provide enhancement of images by preserving the brightness and improving the contrast and details. In order to demonstrate the proposed methods' general applicability, several challenging referenced and non-referenced datasets from different problem domains are considered. A comparative study has been performed, and the proposed method has been compared to state-of-the-art and recent image enhancement techniques. Both qualitative and quantitative results are analyzed for color correction, detail enhancement, and additional noise for each dataset. The results show that the Time-Shift Method could be effectively used for image enhancement for different problem domains without producing over- or under-enhancement.
C1 [Sekeroglu, Boran] Near East Univ, Fac Engn, Comp Engn Dept, Near East Blvd,Mersin 10, TR-99138 Nicosia, N Cyprus, Turkiye.
C3 Near East University
RP Sekeroglu, B (corresponding author), Near East Univ, Fac Engn, Comp Engn Dept, Near East Blvd,Mersin 10, TR-99138 Nicosia, N Cyprus, Turkiye.
EM boran.sekeroglu@neu.edu.tr
RI Sekeroglu, Boran/X-6510-2019
OI Sekeroglu, Boran/0000-0001-7284-1173
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chen SD, 2012, DIGIT SIGNAL PROCESS, V22, P640, DOI 10.1016/j.dsp.2012.04.002
   Cline D., 2021, Variational Principles in Classical Mechanics, V3rd
   Culina B., 2022, Sci. Philos., V10, P41
   Curtis W.D., 1985, Differential Manifolds and Theoretical Physics
   Dong J, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3556544
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Gao JC, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22207749
   Geng ZC, 2022, PROC CVPR IEEE, P17420, DOI 10.1109/CVPR52688.2022.01692
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Huang LH, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P189, DOI 10.1109/CISP-BMEI.2016.7852706
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li YM, 2022, OPT EXPRESS, V30, P33826, DOI 10.1364/OE.463682
   Li ZC, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3240195
   Lu L., 2022, P IEEECVF C COMPUTER, P3532
   Madhusudana PC, 2021, IEEE T IMAGE PROCESS, V30, P7446, DOI 10.1109/TIP.2021.3106801
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Saleem A, 2012, EURASIP J IMAGE VIDE, P1, DOI 10.1186/1687-5281-2012-10
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tang H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P610, DOI 10.1145/3394171.3413884
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang D., 2022, P 31 INT JOINT C ART, P3508, DOI DOI 10.24963/IJCAI.2022/487
   Wang D, 2023, INFORM FUSION, V98, DOI 10.1016/j.inffus.2023.101828
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wexler Y., 2004, P 2004 IEEE COMP SOC, P1063
   Wu Y., 2022, CVPR, P17814
   Wu YD, 2014, J APPL MATH, DOI 10.1155/2014/294870
   Xu J., 2018, arXiv
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Zha ZC, 2023, IEEE T CIRC SYST VID, V33, P3947, DOI 10.1109/TCSVT.2023.3236636
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang WD, 2022, IEEE T IMAGE PROCESS, V31, P3997, DOI 10.1109/TIP.2022.3177129
   Zhou JC, 2022, APPL INTELL, V52, P16435, DOI 10.1007/s10489-022-03275-z
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 44
TC 2
Z9 2
U1 5
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104810
DI 10.1016/j.imavis.2023.104810
EA SEP 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA T1IQ0
UT WOS:001075596000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, LM
   Peng, JJ
   Liu, WF
   Yuan, HC
   Tan, SH
   Wang, L
   Yi, F
AF Zhang, Luming
   Peng, Junjie
   Liu, Wenfu
   Yuan, Haochen
   Tan, Shuhua
   Wang, Lu
   Yi, Fen
TI A semantic fusion based approach for express bill detection in complex
   scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Oriented objects; Object detection; Semantic fusion; Complex scenes
AB With the explosive growth of the express logistics industry, hundreds of millions of images of express bills need to be recognized in the process of express transportation. However, it is challenging to detect express bills in an automated manner as the images of express bills acquired on the assembly line are of inferior quality and in complex scenes. Existing methods have difficulty in extracting semantic texture features at the pixel level for express bills in complex scenes. To solve the problem mentioned above, we propose an oriented frame target detection method Semantic Fusion Rotated Object Detector (SFRDet). In order to enhance the feature extraction capability in complex scenarios by fusing pixel-level texture features, SFRDet employs a semantic fusion mecha-nism to extract low-level semantic information from images to guide training. On this basis, the Semantic Reinforcement Feature Pyramid Network (SRFPN) is used to enhance the model's attention to semantic informa-tion during the feature extraction process. This enables the model to obtain better feature extraction capability and faster inference at the same time. Extensive experiments are conducted on multiple datasets in practical application scenes. The result indicates the proposed method outperforms other state-of-the-art methods in precision and efficiency. It has a wild application prospect in the industry.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Zhang, Luming; Peng, Junjie; Liu, Wenfu; Yuan, Haochen; Wang, Lu] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Peng, Junjie] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
   [Tan, Shuhua; Yi, Fen] YTO Express Co Ltd, Natl Engn Lab Logist Informat Technol, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University
RP Peng, JJ (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
EM zhanglm@shu.edu.cn; jjie.peng@shu.edu.cn; wenfuliu@shu.edu.cn;
   yuanhc@shu.edu.cn; 00000226@yto.net.cn; luwang@shu.edu.cn;
   00001225@yto.net.cn
RI Chen, Zheng/KCY-2338-2024; yu, xiao/KFT-1725-2024
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Dharampal V., 2015, Journal of Electrical & Electronic Systems, V4, DOI DOI 10.4172/2332-0796.1000150
   Ding J, 2019, PROC CVPR IEEE, P2844, DOI 10.1109/CVPR.2019.00296
   Garcia-Garcia A, 2017, Arxiv, DOI [arXiv:1704.06857, DOI 10.48550/ARXIV.1704.06857]
   Han JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3062048
   Han JM, 2021, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR46437.2021.00281
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hou LP, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15030757
   Hou LP, 2022, AAAI CONF ARTIF INTE, P923
   Hou LP, 2022, IEEE T IMAGE PROCESS, V31, P1545, DOI 10.1109/TIP.2022.3143690
   Jiang YY, 2017, Arxiv, DOI [arXiv:1706.09579, DOI 10.48550/ARXIV.1706.09579]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li WT, 2022, PROC CVPR IEEE, P1819, DOI 10.1109/CVPR52688.2022.00187
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tian FK, 2020, Arxiv, DOI arXiv:2010.15356
   Tian J., 2011, INT J COMPUT APPL, V22, P33
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu YC, 2021, IEEE T PATTERN ANAL, V43, P1452, DOI [10.1109/TGRS.2020.3026387, 10.1109/TPAMI.2020.2974745]
   Yang X, 2023, IEEE T PATTERN ANAL, V45, P2384, DOI 10.1109/TPAMI.2022.3166956
   Yang X, 2022, Arxiv, DOI arXiv:2201.12558
   Yang X, 2022, INT J COMPUT VISION, V130, P1340, DOI 10.1007/s11263-022-01593-w
   Yang X, 2021, AAAI CONF ARTIF INTE, V35, P3163
   Yao YQ, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2022.3231340
   Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191
   Zhang Junyou, 2010, Proceedings of the Third International Conference on Information and Computing Science (ICIC 2010), P185, DOI 10.1109/ICIC.2010.317
   Zhou Y, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P7331, DOI 10.1145/3503161.3548541
   Zou Z., 2019, arXiv
NR 38
TC 1
Z9 1
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104708
DI 10.1016/j.imavis.2023.104708
EA MAY 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA K0SW0
UT WOS:001013642100001
DA 2024-07-18
ER

PT J
AU Chen, K
   Zhu, HH
   Tang, DB
   Zheng, K
AF Chen, Kai
   Zhu, Haihua
   Tang, Dunbing
   Zheng, Kun
TI Future pedestrian location prediction in first-person videos for
   autonomous vehicles and social robots
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Social intention; Human-vehicle interactions; First-person videos; Image
   depth; Social spatial dependencies; Transformer
AB Future pedestrian trajectory prediction in first-person videos offers great prospects to help autonomous vehicles and social robots to enable better human-vehicle interactions. Given an egocentric video stream, we aim to predict the location and depth (distance between the observed person and the camera) of his/her neighbors in future frames. To locate their future trajectories, we mainly consider three main factors: a) It is necessary to restore the spatial distribution of pedestrians in 2D image to 3D space, i.e., to extract the distance between the pedestrian and the camera which is often neglected. b) It is critical to utilize neighbors' poses to recognize their intentions. c) It is important to learn human-vehicle interactions from the pedestrian's historical trajecto-ries. We propose to incorporate these three factors into a multi-channel tensor to represent the main features in real-life 3D space. We then put this tensor into an innovative end-to-end fully convolutional network based on transformer architecture. Experimental results reveal our method outperforms other state-of-the-art methods on public benchmarks MOT15, MOT16 and MOT17. The proposed method will be useful to understand human -vehicle interaction and helpful for pedestrian collision avoidance.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Chen, Kai; Zhu, Haihua; Tang, Dunbing] Nanjing Univ Aeronaut & Astronaut NUAA, Coll Mech & Elect Engn, Nanjing, Peoples R China.
   [Zheng, Kun] Nanjing Inst Technol Nanjing, Sch Automot & Rail Transit, Nanjing, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing Institute of
   Technology
RP Chen, K (corresponding author), Nanjing Univ Aeronaut & Astronaut NUAA, Coll Mech & Elect Engn, Nanjing, Peoples R China.
EM chen_kai@nuaa.edu.cn
FU National Natural Science Foundation of China [52202417]; China
   Postdoctoral Science Foundation [2022M721605, 2022TQ0155]
FX This work was supported by the National Natural Science Foundation of
   China (No.52202417) , China Postdoctoral Science Foundation
   (No.2022M721605, No.2022TQ0155) . Authors thank reviews for their
   valuable comments.
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Bashir FI, 2007, IEEE T MULTIMEDIA, V9, P58, DOI 10.1109/TMM.2006.886346
   Choi C, 2019, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2019.00101
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Garcia-Salguero M, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104142
   Gehring J, 2017, PR MACH LEARN RES, V70
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Jaipuria N, 2018, Arxiv, DOI [arXiv:1806.09444, 10.48550/arXiv.1806.09444]
   Junwei Liang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10505, DOI 10.1109/CVPR42600.2020.01052
   Kingma D. P., 2014, arXiv
   Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15
   Kooij JFP, 2014, LECT NOTES COMPUT SC, V8694, P618, DOI 10.1007/978-3-319-10599-4_40
   Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Li YK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P235, DOI 10.1145/3123266.3123287
   Li ZQ, 2019, PROC CVPR IEEE, P4516, DOI 10.1109/CVPR.2019.00465
   Liang JW, 2019, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR.2019.00587
   Manh H, 2019, Arxiv, DOI [arXiv:1808.04018, DOI 10.48550/ARXIV.1808.04018]
   Milan A, 2016, Arxiv, DOI arXiv:1603.00831
   Nikhil N., 2018, PROC EUR C COMPUT VI
   Ohashi T, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104028
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Piotto N, 2009, IEEE T MULTIMEDIA, V11, P1266, DOI 10.1109/TMM.2009.2030746
   Saito Y, 2016, IEEE T INTELL VEHICL, V1, P314, DOI 10.1109/TIV.2017.2700210
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song X, 2021, IEEE T INTELL TRANSP, V22, P3285, DOI 10.1109/TITS.2020.2981118
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Vaswani A, 2017, ADV NEUR IN, V30
   Vemula A, 2018, IEEE INT CONF ROBOT, P4601
   Yagi T, 2018, PROC CVPR IEEE, P7593, DOI 10.1109/CVPR.2018.00792
NR 33
TC 3
Z9 3
U1 5
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2023
VL 134
AR 104671
DI 10.1016/j.imavis.2023.104671
EA APR 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA G5TQ6
UT WOS:000989783800001
DA 2024-07-18
ER

PT J
AU Ye, X
   Bilodeau, GA
AF Ye, Xi
   Bilodeau, Guillaume-Alexandre
TI Video prediction by efficient transformers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video prediction; Transformers; Video representation learning;
   Autoregressive generative models; Non-autoregressive generative models
AB Video prediction is a challenging computer vision task that has a wide range of applications. In this work, we present a new family of Transformer-based models for video prediction. Firstly, an efficient local spatial- temporal separation attention mechanism is proposed to reduce the complexity of standard Transformers. Then, a full autoregressive model, a partial autoregressive model and a non-autoregressive model are developed based on the new efficient Transformer. The partial autoregressive model has a similar performance with the full autoregressive model but a faster inference speed. The non-autoregressive model not only achieves a faster infer-ence speed but also mitigates the quality degradation problem of the autoregressive counterparts, but it requires additional parameters and loss function for learning. Given the same attention mechanism, we conducted a com-prehensive study to compare the proposed three video prediction variants. Experiments show that the proposed video prediction models are competitive with more complex state-of-the-art convolutional-LSTM based models. The source code is available at https://github.com/XiYe20/VPTR.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Ye, Xi; Bilodeau, Guillaume-Alexandre] Polytech Montreal, LITIV Lab, POB 6079, Montreal, PQ H3C 3A7, Canada.
C3 Universite de Montreal; Polytechnique Montreal
RP Ye, X (corresponding author), Polytech Montreal, LITIV Lab, POB 6079, Montreal, PQ H3C 3A7, Canada.
EM xi.ye@polymtl.ca; gabilodeau@polymtl.ca
RI ye, xi/KTH-8756-2024
FU Natural Sciences and Engineer- ing Research Council of Canada (NSERC)
   [DGDND-2020-04633]
FX We acknowledge the support of the Natural Sciences and Engineer- ing
   Research Council of Canada (NSERC) , DGDND-2020-04633.
CR Andonian A, 2021, IEEE INT CONF COMP V, P1934, DOI 10.1109/ICCVW54120.2021.00220
   [Anonymous], 2017, NIPS
   Arnab Anurag, 2021, VIVIT VIDEO VISION T
   Babaeizadeh Mohammad, 2018, Stochastic variational video prediction, P2
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bolte JA, 2019, IEEE INT VEH SYM, P438, DOI 10.1109/IVS.2019.8813817
   Cai HY, 2018, LECT NOTES COMPUT SC, V11206, P374, DOI [10.1007/978-3-030-01216-8_, 10.1007/978-3-030-01216-8_23]
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Castrejon L, 2019, IEEE I CONF COMP VIS, P7607, DOI 10.1109/ICCV.2019.00770
   Chen BY, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P358, DOI 10.1145/3126686.3126737
   Chen XY, 2020, IEEE T IMAGE PROCESS, V29, P7090, DOI 10.1109/TIP.2020.2998297
   Chen XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1503, DOI 10.1145/3123266.3123349
   Denton Emily, 2018, Stochastic video generation with a learned prior, V2, P4
   Dosovitskiy Alexey, 2021, ICLR
   Ebert F., 2017, P MACHINE LEARNING R, P344
   Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Fragkiadaki K, 2017, Arxiv, DOI arXiv:1705.02082
   Franceschi Jean-Yves, 2020, ICLR
   Fushishita Naoya, COMPUTER VISION ECCV, P596
   Hsieh JT, 2018, ADV NEUR IN, V31
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jang Yunseok, 2018, VIDEO PREDICTION APP
   Jayaraman Dinesh, 2019, TIME AGNOSTIC PREDIC
   Jiahao Su, 2020, NEURIPS
   Jin BB, 2020, PROC CVPR IEEE, P4553, DOI 10.1109/CVPR42600.2020.00461
   Jin BB, 2018, IEEE INT C INT ROBOT, P5801, DOI 10.1109/IROS.2018.8594264
   Kosiorek AR, 2018, ADV NEUR IN, V31
   Kwon YH, 2019, PROC CVPR IEEE, P1811, DOI 10.1109/CVPR.2019.00191
   Lee S, 2021, PROC CVPR IEEE, P3053, DOI 10.1109/CVPR46437.2021.00307
   Leibfried F., 2016, ICML WORKSH PRINC AP
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu Z., 2020, arXiv
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mathieu Michael, 2016, ICLR, DOI DOI 10.48550/ARXIV.1511.05440
   Meinhardt T, 2022, Arxiv, DOI arXiv:2101.02702
   Radford A, Improving language understanding by generative pre-training
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shaw P., 2018, P 2018 NAACL, V2, P464, DOI [DOI 10.18653/V1/N18-2074, 10.18653/v1/N18-2074]
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   van den Oord A, 2017, ADV NEUR IN, V30
   Vaswani A, 2017, ADV NEUR IN, V30
   Villegas Ruben, 2017, ICLR
   Voleti Vikram, 2022, ADV NEURAL INFORM PR
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Wang YR, 2019, AAAI CONF ARTIF INTE, P5377
   Wang YZ, 2018, PR MACH LEARN RES, V80
   Wang Yunbo, 2018, ICLR
   Wang Yuqing, 2020, CVPR
   Wu C, 2021, arXiv
   Wu Y, 2020, PROC CVPR IEEE, P5538, DOI 10.1109/CVPR42600.2020.00558
   Xu Jingwei, 2020, ICML
   Yan W., 2021, arXiv, DOI DOI 10.48550/ARXIV.2104.10157
   Ye Xi, 2022, 26 INT C PATT REC IC
   Yuan Y., 2021, NEURIPS
   Zhang PC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2978, DOI 10.1109/ICCV48922.2021.00299
   Zheng Chang, 2021, NEURIPS
NR 64
TC 11
Z9 11
U1 5
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2023
VL 130
AR 104612
DI 10.1016/j.imavis.2022.104612
EA DEC 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA C5TM7
UT WOS:000962537700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, RQ
   Zhang, JH
   Li, B
AF Yang, Ruiqi
   Zhang, Junhua
   Li, Bo
TI An end-to-end convolutional network for estimating the essential matrix
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE E-matrix; Estimation layer; Guarantee layer; Self-defined loss function
AB Essential matrix (E-matrix) estimation is a crucial aspect of pose estimation. In this study, we developed an end-to-end method (E-net) to estimate the E-matrix without correspondences. A pair of the corresponding images was placed in the twin transformer architecture to simultaneously extract the features. We devel-oped a feature matching module for matching the extracted features based on their commonalities. To avoid excessive network parameters, matched features with their weights obtained by multilayer perceptron were transmitted to the flatten layer, where the Max-Pooling was used to eliminate their useless portions. We further constructed three self-defined layers to ensure that E-matrix is rank-2 with 5 degrees of freedom using reserved helpful features. Besides, we presented two self-defined loss functions (Loss1 and Loss2) to train the E-net and improve the estimated E-matrix's accuracy. E-net's performance was evaluated on the KITTI and TUM SLAM datasets using two self-defined metrics, M1 (mean value of matching error) and M2 (mean squared value of matching error). The E-net achieved M1 0.107 and M2 0.091 on the KITTI dataset and M1 0.253 and M2 0.144 on the TUM SLAM dataset. The results demonstrated that the E-net trained with self-defined loss functions outperforms other algorithms when compared to the 5-point algorithm of M1 10.411 and M2 8.332.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yang, Ruiqi; Zhang, Junhua; Li, Bo] Yunnan Univ, Dept Elect Engn, Kunming, Peoples R China.
C3 Yunnan University
RP Zhang, JH (corresponding author), Yunnan Univ, Dept Elect Engn, Kunming, Peoples R China.
EM jhzhang@ynu.edu.cn
FU National Natural Science Foundation of China [62063034]
FX Acknowledgements This work is supported by the National Natural Science
   Foundation of China (62063034) .
CR [Anonymous], 2008, BMVC
   Bai Xuebing, 2016, Journal of Computer Applications, V36, P1923, DOI 10.11772/j.issn.1001-9081.2016.07.1923
   Botterill T., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P561, DOI 10.1109/DICTA.2011.100
   Chin TJ, 2020, INT J COMPUT VISION, V128, P575, DOI 10.1007/s11263-019-01207-y
   Chojnacki W, 2003, IEEE T PATTERN ANAL, V25, P1172, DOI 10.1109/TPAMI.2003.1227992
   Efe U, 2021, IEEE COMPUT SOC CONF, P4279, DOI 10.1109/CVPRW53098.2021.00484
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Helmke U., 2004, P 16 INT S MATH THEO
   Helmke U, 2007, INT J COMPUT VISION, V74, P117, DOI 10.1007/s11263-006-0005-0
   Hold-Geoffroy Y, 2018, PROC CVPR IEEE, P2354, DOI 10.1109/CVPR.2018.00250
   Izquierdo E, 2003, IEEE T CIRC SYST VID, V13, P925, DOI 10.1109/TCSVT.2003.816503
   Kahl F, 2007, INT J COMPUT VISION, V74, P3, DOI 10.1007/s11263-006-0015-y
   Kanaes H., 2016 IEEECVF INT J C
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Kneip L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.16
   Li HD, 2006, INT C PATT RECOG, P630
   Lim J, 2010, COMPUT VIS IMAGE UND, V114, P245, DOI 10.1016/j.cviu.2009.04.005
   Lindeberg T., 2012, SCHOLARPEDIA, V7, P10491, DOI [10.4249/scholarpedia.10491, DOI 10.4249/SCHOLARPEDIA.10491]
   López-Antequera M, 2019, PROC CVPR IEEE, P11809, DOI 10.1109/CVPR.2019.01209
   Luo ZX, 2019, PROC CVPR IEEE, P2522, DOI 10.1109/CVPR.2019.00263
   Lv XD, 2021, IEEE COMPUT SOC CONF, P2888, DOI 10.1109/CVPRW53098.2021.00324
   Michaelsen E., 2006, PHOTOGRAMMETRIC COMP, P1
   Naroditsky O, 2012, IEEE T PATTERN ANAL, V34, P818, DOI 10.1109/TPAMI.2011.226
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Philip J., 1996, Photogrammetric Record, V15, P589, DOI 10.1111/0031-868X.00066
   Poursaeed O., 2018, 2018 EUROPEAN C COMP, P1
   Ranftl R, 2018, LECT NOTES COMPUT SC, V11205, P292, DOI 10.1007/978-3-030-01246-5_18
   Sa-Couto L, 2022, NEUROCOMPUTING, V495, P97, DOI 10.1016/j.neucom.2022.04.130
   Shahbazi M, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104533
   Stewénius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005
   Sturm J., 2012, PROC WORKSHOP COLOR
   Varma A, 2022, Arxiv, DOI arXiv:2202.03131
   Wang FJ, 2021, PROC CVPR IEEE, P14189, DOI 10.1109/CVPR46437.2021.01397
   Wang LB, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.103984
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282
   Zhang BF, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P553, DOI 10.1109/ICMA.2014.6885757
   Zhang J., 2022, IMAGE VISION COMPUT, V124, P1
   Zhang JH, 2019, IEEE I CONF COMP VIS, P5844, DOI 10.1109/ICCV.2019.00594
   Zhang YS, 2020, Arxiv, DOI arXiv:2010.15528
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   Zhao J, 2022, IEEE T PATTERN ANAL, V44, P1777, DOI 10.1109/TPAMI.2020.3030161
NR 44
TC 0
Z9 0
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2023
VL 130
AR 104616
DI 10.1016/j.imavis.2022.104616
EA DEC 2022
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7W8NH
UT WOS:000913763700001
DA 2024-07-18
ER

PT J
AU Khan, MA
   Menouar, H
   Hamila, R
AF Khan, Muhammad Asif
   Menouar, Hamid
   Hamila, Ridha
TI Revisiting crowd counting: State-of-the-art, trends, and future
   perspectives
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Crowd counting; CNN; Density estimation; Evaluation metrics; Loss
   functions; Transformers
ID NEURAL-NETWORKS; PEOPLE; NUMBER; SCENES
AB Crowd counting is an effective tool for situational awareness in public places. Automated crowd counting using images and videos is an interesting yet challenging problem that has gained significant attention in computer vision. Over the past few years, various deep learning methods have been developed to achieve state-of-the-art performance. The methods evolved over time vary in many aspects such as model architecture, input pipeline, learning paradigm, computational complexity, and accuracy gains etc. In this paper, we present a systematic and comprehensive review of the most significant contributions in the area of crowd counting. Although few surveys exist on the topic, our survey is most up-to date and different in several aspects. First, it provides a more meaningful categorization of the most significant contributions by model architectures, learning methods (i.e., loss functions), and evaluation methods (i.e., evaluation metrics). We chose prominent and distinct works and excluded similar works. We also sort the well-known crowd counting models by their performance over benchmark datasets. We believe that this survey can be a good resource for novice researchers to understand the progressive developments and contributions over time and the current state-of-the-art. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Khan, Muhammad Asif; Menouar, Hamid] Qatar Univ, Qatar Mobil Innovat Ctr, Doha, Qatar.
   [Hamila, Ridha] Qatar Univ, Elect Engn, Doha, Qatar.
C3 Qatar University; Qatar Mobility Innovations Center (QMIC); Qatar
   University
RP Khan, MA (corresponding author), Qatar Univ, Qatar Mobil Innovat Ctr, Doha, Qatar.
EM asifk@ieee.org
RI Khan, Muhammad Asif/G-2629-2013; Hamila, Ridha/ABI-2129-2020
OI Khan, Muhammad Asif/0000-0003-2925-8841; Hamila,
   Ridha/0000-0002-6920-7371
FU Qatar National Research Fund (a member of The Qatar Foundation) [PDRA7-
   0606-21012]
FX This publication was made possible by the PDRA award PDRA7-0606-21012
   from the Qatar National Research Fund (a member of TheQatar Foundation).
   The statements made herein are solely the responsibility of the authors.
CR Abdou Mohamed, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P48, DOI 10.1109/ICIoT48696.2020.9089594
   Aich S, 2019, Arxiv, DOI arXiv:1805.11123
   Al-Sa'd M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020418
   Badrinarayanan V, 2015, Arxiv, DOI arXiv:1505.07293
   Bai H., 2020, SURVEY DEEP LEARNING
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Carion N, 2020, Arxiv, DOI [arXiv:2005.12872, DOI 10.48550/ARXIV.2005.12872]
   Cenggoro T.W., 2019, ENG MATH COMPUT SCI
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen Z., 2020, ECAI
   Chenyu Gao, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11858), P582, DOI 10.1007/978-3-030-31723-2_50
   Chu X., 2021, NEURIPS
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Deng J., 2009, IEEE C COMP VIS PATT
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan ZZ, 2022, NEUROCOMPUTING, V472, P224, DOI 10.1016/j.neucom.2021.02.103
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gao GS, 2020, Arxiv, DOI [arXiv:2003.12783, DOI 10.48550/ARXIV.2003.12783]
   Gao JY, 2021, Arxiv, DOI [arXiv:2108.00584, DOI 10.1016/J.NEUCOM.2022.09.113]
   Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gouiaa R, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5040050
   Gu SQ, 2022, Arxiv, DOI arXiv:2202.03843
   Guerrero-Gómez-Olmedo R, 2015, LECT NOTES COMPUT SC, V9117, P423, DOI 10.1007/978-3-319-19390-8_48
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsieh MR, 2017, IEEE I CONF COMP VIS, P4165, DOI 10.1109/ICCV.2017.446
   Idrees H, 2018, Arxiv, DOI arXiv:1808.01050
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Ilyas N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010043
   Jarraya SK, 2021, CMC-COMPUT MATER CON, V66, P1315, DOI 10.32604/cmc.2020.013522
   Jeevitha, 2018, REV CROWD COUNTING T
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Jingying W, 2020, SURVEY CROWD COUNTIN
   Lei YJ, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107616
   Leibe B, 2005, PROC CVPR IEEE, P878
   Li M, 2008, INT C PATT RECOG, P1998
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liang DK, 2022, Arxiv, DOI arXiv:2202.13065
   Liang DK, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3445-y
   Lin H., 2022, arXiv
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Lin Z, 2010, IEEE T PATTERN ANAL, V32, P604, DOI 10.1109/TPAMI.2009.204
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu L, 2020, Arxiv, DOI arXiv:2007.08260
   Liu LB, 2021, PROC CVPR IEEE, P4821, DOI 10.1109/CVPR46437.2021.00479
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Liu XL, 2019, IEEE T PATTERN ANAL, V41, P1862, DOI 10.1109/TPAMI.2019.2899857
   Liu YT, 2019, PROC CVPR IEEE, P6462, DOI 10.1109/CVPR.2019.00663
   Luo Y, 2020, CHIN CONTR CONF, P6602, DOI 10.23919/CCC50068.2020.9189599
   Ma YM, 2022, Arxiv, DOI arXiv:2202.13660
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Nekrasov V, 2018, Arxiv, DOI arXiv:1810.03272
   Nithya S., 2018, CROWD DENSITY ESTIMA
   Paragios N, 2001, PROC CVPR IEEE, P1034
   Peng T., 2020, P AS C COMP VIS ACCV, DOI DOI 10.1007/978-3-030-69544-6_30
   Peng Tao, 2020, COMPUTER VISION ACCV
   Phuc Thinh Do, 2021, 2021 8th NAFOSTED Conference on Information and Computer Science (NICS), P65, DOI 10.1109/NICS54270.2021.9701500
   Ranjan V, 2019, Arxiv, DOI arXiv:1904.02774
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ronneberger O, 2015, Arxiv, DOI [arXiv:1505.04597, DOI 10.48550/ARXIV.1505.04597]
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shi MJ, 2019, PROC CVPR IEEE, P7271, DOI 10.1109/CVPR.2019.00745
   Shi XW, 2020, INT CONF ACOUST SPEE, P2328, DOI [10.1109/icassp40776.2020.9053780, 10.1109/ICASSP40776.2020.9053780]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sindagi V. A., 2017, 2017 14 IEEE INT C A, P1
   Sindagi VA, 2022, IEEE T PATTERN ANAL, V44, P2594, DOI 10.1109/TPAMI.2020.3035969
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Song QY, 2021, AAAI CONF ARTIF INTE, V35, P2576
   Sun GL, 2023, Arxiv, DOI [arXiv:2105.10926, DOI 10.48550/ARXIV.2105.10926]
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang H., 2022, ARXIV
   Thanasutives P, 2021, INT C PATT RECOG, P2382, DOI 10.1109/ICPR48806.2021.9413286
   Tian Y, 2011, LECT NOTES COMPUT SC, V6494, P679, DOI 10.1007/978-3-642-19318-7_53
   Tian Y, 2021, Arxiv, DOI [arXiv:2109.14483, DOI 10.48550/ARXIV.2109.14483]
   Topkaya IS, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P313, DOI 10.1109/AVSS.2014.6918687
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Vaswani A, 2017, ADV NEUR IN, V30
   Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747
   Wan J., 2020, NEURIPS
   Wang BY, 2020, Arxiv, DOI arXiv:2009.13077
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang Q, 2022, IEEE T INTELL TRANSP, V23, P15233, DOI 10.1109/TITS.2021.3138896
   Wei X., 2021, arXiv
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xu JF, 2021, MULTIMED TOOLS APPL, V80, P6121, DOI 10.1007/s11042-020-09888-1
   Yan ZY, 2019, IEEE I CONF COMP VIS, P952, DOI 10.1109/ICCV.2019.00104
   Ye LW, 2019, PROC CVPR IEEE, P10494, DOI 10.1109/CVPR.2019.01075
   Yifan Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P1, DOI 10.1007/978-3-030-58598-3_1
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhang A, 2019, IEEE I CONF COMP VIS, P5713, DOI 10.1109/ICCV.2019.00581
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhu PF, 2022, IEEE T PATTERN ANAL, V44, P7380, DOI 10.1109/TPAMI.2021.3119563
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 105
TC 14
Z9 14
U1 6
U2 45
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104597
DI 10.1016/j.imavis.2022.104597
EA DEC 2022
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7S6FQ
UT WOS:000910848000004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fuentes-Jimenez, D
   Pizarro, D
   Casillas-Pérez, D
   Collins, T
   Bartoli, A
AF Fuentes-Jimenez, David
   Pizarro, Daniel
   Casillas-Perez, David
   Collins, Toby
   Bartoli, Adrien
TI Deep Shape-from-Template: Single-image quasi-isometric deformable
   registration and reconstruction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Monocular; 3D Model; Registration; Reconstruction; Wide-baseline; Dense;
   Deformable; Shape-from-Template
ID SURFACE DETECTION; 3D SHAPE; MOTION
AB Shape-from-Template (SfT) solves 3D vision from a single image and a deformable 3D object model, called a tem-plate. Concretely, SfT computes registration (the correspondence between the template and the image) and re-construction (the depth in camera frame). It constrains the object deformation to quasi-isometry. Real-time and automatic SfT represents an open problem for complex objects and imaging conditions. We present four contri-butions to address core unmet challenges to realise SfT with a Deep Neural Network (DNN). First, we propose a novel DNN called DeepSfT, which encodes the template in its weights and hence copes with highly complex tem-plates. Second, we propose a semi-supervised training procedure to exploit real data. This is a practical solution to overcome the render gap that occurs when training only with simulated data. Third, we propose a geometry ad-aptation module to deal with different cameras at training and inference. Fourth, we combine statistical learning with physics-based reasoning. DeepSfT runs automatically and in real-time and we show with numerous exper-iments and an ablation study that it consistently achieves a lower 3D error than previous work. It outperforms in generalisation and achieves great performance in terms of reconstruction and registration error with wide -baseline, occlusions, illumination changes, weak texture and blur.(c) 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Fuentes-Jimenez, David; Pizarro, Daniel] Univ Alcala, Dept Elect, Alcala De Henares 28943, Spain.
   [Collins, Toby] IRCAD, Pl Hop, F-67000 Strasbourg, France.
   [Casillas-Perez, David] Univ Rey Juan Carlos, Dept Signal Theory & Commun, Fuenlabrada 28942, Spain.
   [Pizarro, Daniel; Bartoli, Adrien] Univ Clermont Auvergne, CNRS, EnCoV Inst Pascal, F-63000 Clermont Ferrand, France.
   [Collins, Toby] IRCAD Africa, Kigali, Rwanda.
C3 Universidad de Alcala; Universidad Rey Juan Carlos; Centre National de
   la Recherche Scientifique (CNRS); Universite Clermont Auvergne (UCA)
RP Casillas-Pérez, D (corresponding author), Univ Rey Juan Carlos, Dept Signal Theory & Commun, Fuenlabrada 28942, Spain.
RI 辛, 雨菲/JBS-6390-2023
OI Casillas-Perez, David/0000-0002-5721-1242; Fuentes Jimenez,
   David/0000-0001-6424-4782
FU Spanish Ministry of Science and Innovation MCIN/AEI [CAS21/00182];
   Spanish Ministry of Education trough the Jose Castillejo fellowship; 
   [PID2020-115995RB-I00]
FX This research has been supported by the Spanish Ministry of Science and
   Innovation MCIN/AEI/10.13039/501100011033 through the Project ATHENA
   under Grant PID2020-115995RB-I00. This work has been also supported by
   the Spanish Ministry of Education trough the Jose Castillejo fellowship
   under Grant CAS21/00182
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agudo A, 2016, IEEE T PATTERN ANAL, V38, P979, DOI 10.1109/TPAMI.2015.2469293
   Agudo A, 2015, PROC CVPR IEEE, P2179, DOI 10.1109/CVPR.2015.7298830
   Alhashim I, 2019, Arxiv, DOI arXiv:1812.11941
   [Anonymous], Agisoft photoscan
   [Anonymous], 2010, PROC 13 INT C ARTIF
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bartoli A, 2015, IEEE T PATTERN ANAL, V37, P2099, DOI 10.1109/TPAMI.2015.2392759
   Bartoli A, 2013, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2013.199
   Bednarík J, 2018, INT CONF 3D VISION, P606, DOI 10.1109/3DV.2018.00075
   Blender Online Community, Blender-a 3D modelling and rendering package
   Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941
   Brickwedde F., 2019, ARXIV
   Brunet F, 2014, COMPUT VIS IMAGE UND, V125, P138, DOI 10.1016/j.cviu.2014.04.003
   Casillas-Perez D, 2021, INT J COMPUT VISION, V129, P2194, DOI 10.1007/s11263-021-01472-w
   Casillas-Perez D, 2019, J MATH IMAGING VIS, V61, P607, DOI 10.1007/s10851-018-0862-5
   Chhabra A., 2017, IEEE T PATTERN ANAL, P1
   Chhatkuli A, 2017, IEEE T PATTERN ANAL, V39, P833, DOI 10.1109/TPAMI.2016.2562622
   Collins Toby, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P404, DOI 10.1007/978-3-319-46720-7_47
   Collins T, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P116, DOI 10.1109/ISMAR.2015.35
   Collins T, 2014, LECT NOTES COMPUT SC, V8695, P138, DOI 10.1007/978-3-319-10584-0_10
   Computer Vision Laboratory, DEF SURF REC
   Dai YC, 2012, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2012.6247905
   Ngo DT, 2015, IEEE I CONF COMP VIS, P2273, DOI 10.1109/ICCV.2015.262
   Ngo DT, 2016, IEEE T PATTERN ANAL, V38, P172, DOI 10.1109/TPAMI.2015.2435739
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Foley J.D., 2020, COMPUTER GRAPHICS PR, V2nd
   Fuentes-Jimenez D., 2021, DEEP SHAPE TEMPLATE, DOI [10.34740/KAGGLE/DSV/1955934, DOI 10.34740/KAGGLE/DSV/1955934]
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Gay-Bellile V, 2010, IEEE T PATTERN ANAL, V32, P87, DOI 10.1109/TPAMI.2008.265
   Golyanik V, 2019, Arxiv, DOI [arXiv:1803.10193, 10.1007/978-3-030-01790-3_4, DOI 10.1007/978-3-030-01790-3_4]
   GoPro, GOPR HER SILV V3 RGB
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Hafez Nawal, 2020, Advances in Service and Industrial Robotics. Results of RAAD. Mechanisms and Machine Science (MMS 84), P505, DOI 10.1007/978-3-030-48989-2_54
   Haouchine N, 2017, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2017.381
   Haouchine N, 2014, INT SYM MIX AUGMENT, P229, DOI 10.1109/ISMAR.2014.6948432
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hornácek M, 2014, PROC CVPR IEEE, P3526, DOI 10.1109/CVPR.2014.451
   Huang G, 2018, Arxiv, DOI [arXiv:1608.06993, DOI 10.48550/ARXIV.1608.06993]
   Hur Junhwa, 2020, P IEEE CVF C COMP VI, P7396
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Intel, INT REALS D435 STER
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kingma D. P., 2014, arXiv
   Lee J, 2019, PR MACH LEARN RES, V97
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu-Yin Q., 2016, BRIT MACH VIS C BMVC
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv ZY, 2018, LECT NOTES COMPUT SC, V11209, P484, DOI 10.1007/978-3-030-01228-1_29
   Malti A, 2015, PROC CVPR IEEE, P1629, DOI 10.1109/CVPR.2015.7298771
   Malti A, 2013, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2013.200
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Özgür E, 2017, INT J COMPUT VISION, V123, P184, DOI 10.1007/s11263-016-0968-4
   Parashar S., 2015, IEEE INT C COMPUTER
   Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8
   Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9
   Pizarro D, 2012, INT J COMPUT VISION, V97, P54, DOI 10.1007/s11263-011-0452-0
   Pumarola A, 2018, PROC CVPR IEEE, P4681, DOI 10.1109/CVPR.2018.00492
   Ren Z, 2017, AAAI CONF ARTIF INTE, P1495
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Salzmann M, 2008, LECT NOTES COMPUT SC, V5305, P581, DOI 10.1007/978-3-540-88693-8_43
   Salzmann M, 2009, PROC CVPR IEEE, P1054, DOI 10.1109/CVPRW.2009.5206759
   Schuster R, 2018, IEEE WINT CONF APPL, P1056, DOI 10.1109/WACV.2018.00121
   Shimada S, 2019, IEEE COMPUT SOC CONF, P2876, DOI 10.1109/CVPRW.2019.00347
   Keskar NS, 2017, Arxiv, DOI [arXiv:1712.07628, 10.48550/arXiv.1712.07628, DOI 10.48550/ARXIV.1712.07628]
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32
   Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752
   Tsoli A, 2019, IEEE INT CONF COMP V, P4034, DOI 10.1109/ICCVW.2019.00498
   Wang K., 2019, INT JOINT C NEURAL N, P1
   Wedel A, 2011, INT J COMPUT VISION, V95, P29, DOI 10.1007/s11263-010-0404-0
   Zhang Z, 2017, ARXIV
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 78
TC 3
Z9 3
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104531
DI 10.1016/j.imavis.2022.104531
EA SEP 2022
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300008
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Abdelpakey, MH
   Shehata, MS
AF Abdelpakey, Mohamed H.
   Shehata, Mohamed S.
TI NullSpaceRDAR: Regularized discriminative adaptive nullspace for object
   tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual object tracking; Joint-nullspace; Convolutional neural network
AB Recently, discriminative-based and Siamese-based trackers have achieved outstanding performance on most tracking benchmarks. However, these trackers use the pre-trained backbone networks that have been mainly de-signed for classification to extract target-specific features without taking into consideration the visual object tracking task. In this paper, we propose NullSpaceRDAR, a novel tracker that learns a robust target-specific feature representation specifically designed for object tracking. This feature representation is learned by projecting the traditional backbone feature space onto a novel discriminative nullspace that is used to regularize the backbone loss function. We refer to the discriminative nullspace herein as joint-nullspace. The same target features (i.e., target-specific) in the proposed joint-nullspace are collapsed into a single point, and different target -specific features are collapsed into different points. Consequently, the joint-nullspace forces the network to be sensitive to the object's variations from the same class (i.e., intra-class variations). Moreover, a modified adaptive loss function is developed for bounding box estimation to select the most suitable loss function from a super set family of loss functions based on the training data. This makes NullSpaceRDAR more robust to different chal-lenges such as occlusions and background clutter. Extensive experiments have been conducted on six bench-marks to evaluate NullSpaceRDAR: OTB100, VOT variations (VOT2018, VOT2019, and VOT2020), LaSOT, TrackingNet, UAV123, and GOT10k. The results show that NullSpaceRDAR outperforms the state-of-the-art trackers.(c) 2022 Published by Elsevier B.V.
C1 [Abdelpakey, Mohamed H.; Shehata, Mohamed S.] Univ British Columbia, Dept Comp Sci Math Phys & Stat, Kelowna, BC, Canada.
C3 University of British Columbia
RP Abdelpakey, MH (corresponding author), Univ British Columbia, Dept Comp Sci Math Phys & Stat, Kelowna, BC, Canada.
EM mohamed.abdelpakey@ubc.ca
RI Shehata, Mohamed S./AER-6269-2022
OI Shehata, Mohamed S./0000-0002-8464-8650
CR Abdelpakey Mohamed H., 2019, Advances in Visual Computing. 14th International Symposium on Visual Computing, ISVC 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11844), P45, DOI 10.1007/978-3-030-33720-9_4
   Abdelpakey MH, 2020, IEEE T IMAGE PROCESS, V29, P1479, DOI 10.1109/TIP.2019.2942506
   Abdelpakey MH, 2018, LECT NOTES COMPUT SC, V11241, P463, DOI 10.1007/978-3-030-03801-4_41
   [Anonymous], 2017, IN P IEEE C COMPUTER
   Barron JT, 2019, PROC CVPR IEEE, P4326, DOI 10.1109/CVPR.2019.00446
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P777, DOI 10.1007/978-3-030-58536-5_46
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   CHARBONNIER P, 1994, IEEE IMAGE PROC, P168
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Choi J, 2019, IEEE I CONF COMP VIS, P911, DOI 10.1109/ICCV.2019.00100
   Dai KN, 2020, PROC CVPR IEEE, P6297, DOI 10.1109/CVPR42600.2020.00633
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Dong XP, 2018, PROC CVPR IEEE, P518, DOI 10.1109/CVPR.2018.00061
   Dorfer M., 2015, arXiv, P1, DOI [10.48550/arXiv.1511.04707, DOI 10.48550/ARXIV.1511.04707]
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Finn C, 2017, Arxiv, DOI arXiv:1703.03400
   FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Huang C, 2017, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2017.21
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jensen V.G., 1977, MATH METHODCHEM EN
   Kristan M., 2020, COMPUTER VISION ECCV, P547
   Kristan M., 2018, P EUR C COMP VIS ECC, P0
   Kristanl M, 2019, IEEE INT CONF COMP V, P2206, DOI 10.1109/ICCVW.2019.00276
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Lukezic A., 2017, CVPR, V6, P8
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Nvidia, 2020, NVID AP
   Park E., 2018, EUR C COMPUT VIS, P569
   Paszke A., PYTORCH TENSORS DYNA, P6
   Ravi S., Optimization as a model for few-shot learning
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tripathi AS, 2019, BMVC, P6
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang GT, 2020, PROC CVPR IEEE, P6287, DOI 10.1109/CVPR42600.2020.00632
   Wang Q, 2019, Arxiv, DOI [arXiv:1812.05050, 10.48550/arXiv.1812.05050]
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang T., 2018, P ECCV, P152
   Yiwei Chen, 2020, Proceedings of the 16th European Conference on Computer Vision (ECCV 2020) Workshops. Lecture Notes in Computer Science (LNCS 12539), P666, DOI 10.1007/978-3-030-68238-5_44
   Zhang ZP, 2020, Arxiv, DOI arXiv:2006.10721
   Zheng LY, 2020, Arxiv, DOI arXiv:1906.10414
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 59
TC 3
Z9 3
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104550
DI 10.1016/j.imavis.2022.104550
EA SEP 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300003
DA 2024-07-18
ER

PT J
AU Demirel, B
   Cinbis, RG
AF Demirel, Berkan
   Cinbis, Ramazan Gokberk
TI Caption generation on scenes with seen and unseen object categories
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Zero -shot learning; Zero -shot image captioning
AB Image caption generation is one of the most challenging problems at the intersection of vision and language do-mains. In this work, we propose a realistic captioning task where the input scenes may incorporate visual objects with no corresponding visual or textual training examples. For this problem, we propose a detection-driven ap-proach that consists of a single-stage generalized zero-shot detection model to recognize and localize instances of both seen and unseen classes, and a template-based captioning model that transforms detections into sentences. To improve the generalized zero-shot detection model, which provides essential information for captioning, we define effective class representations in terms of class-to-class semantic similarities, and leverage their special structure to construct an effective unseen/seen class confidence score calibration mechanism. We also propose a novel evaluation metric that provides additional insights for the captioning outputs by separately measuring the visual and non-visual contents of generated sentences. Our experiments highlight the importance of studying captioning in the proposed zero-shot setting, and verify the effectiveness of the proposed detection-driven zero -shot captioning approach.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Demirel, Berkan; Cinbis, Ramazan Gokberk] Middle East Tech Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
   [Demirel, Berkan] HAVELSAN Inc, Image & Video Proc Grp, TR-06800 Ankara, Turkey.
C3 Middle East Technical University; Havelsan AS
RP Cinbis, RG (corresponding author), Middle East Tech Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM berkan.demirel@metu.edu.tr; gcinbis@ceng.metu.edu.tr
RI Cinbis, Ramazan Gokberk/AAQ-6929-2020
OI Cinbis, Ramazan Gokberk/0000-0003-0962-7101; Demirel,
   Berkan/0000-0002-5759-6410
FU TUBITAK [116E445, 119E597]
FX Acknowledgements This work was supported in part by the TUBITAK Grants
   116E445 and 119E597. The numerical calculations reported in this paper
   were partially performed at TUBITAK ULAKBIM, High Performance and Grid
   Computing Center (TRUBA resources) .
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   Anderson P, PROC EMPIRICIAL METH, P936
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2015, ICLR 2015
   [Anonymous], 2017, P 2017 C EMPIRICAL M
   [Anonymous], 2015, Advances in neural information processing systems
   Arun A, 2019, PROC CVPR IEEE, P9424, DOI 10.1109/CVPR.2019.00966
   Bahdanau D., 2014, ARXIV
   Bansal A, 2018, LECT NOTES COMPUT SC, V11205, P397, DOI 10.1007/978-3-030-01246-5_24
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bucher M, 2017, IEEE INT CONF COMP V, P2666, DOI 10.1109/ICCVW.2017.308
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4
   Chen S, P IEEECVF C COMPUTER, P9962
   Chen Shixing, 2021, CVPR
   Chen Z., 2021, ICCV, P8712
   Cheng L, 2020, IEEE ACCESS, V8, P154953, DOI 10.1109/ACCESS.2020.3018752
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   Demirel B, 2019, BRIT MACH VIS C
   Demirel B, 2017, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2017.139
   Demirel Berkan, 2018, BRIT MACH VIS C BMVC, P56
   Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gupta D, 2020, IEEE WINT CONF APPL, P1198, DOI 10.1109/WACV45572.2020.9093384
   Hendricks LA, 2016, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2016.8
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hoffman J., 2014, NIPS (News Physiol. Sci.), P3536
   Hoffman J, 2015, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2015.7298906
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Jiang HJ, 2019, IEEE I CONF COMP VIS, P9764, DOI 10.1109/ICCV.2019.00986
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khan R, 2022, Arxiv, DOI arXiv:2203.01594
   Kilickaya M, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P199
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li B., 2021, P IEEE CVPR, P7363
   Li JJ, 2019, PROC CVPR IEEE, P7394, DOI 10.1109/CVPR.2019.00758
   Li YA, 2021, AAAI CONF ARTIF INTE, V35, P1993
   Li ZH, 2019, AAAI CONF ARTIF INTE, P8690
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S., 2018, P ADV NEUR INF PROC
   Liu SC, 2018, ADV NEUR IN, V31
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long Y, 2018, IEEE T PATTERN ANAL, V40, P2498, DOI 10.1109/TPAMI.2017.2762295
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Luo CZ, 2018, IEEE T IMAGE PROCESS, V27, P637, DOI 10.1109/TIP.2017.2745109
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T., 2013, ICLR WORKSH
   Mishra A, 2018, IEEE COMPUT SOC CONF, P2269, DOI 10.1109/CVPRW.2018.00294
   Nie H, P IEEECVF WINTER C A, P1109
   Norouzi M., 2014, P INT C LEARN REPR
   Ordonez V., 2011, ADV NEURAL INFORM PR
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rahman S, 2020, Arxiv, DOI arXiv:1811.08982
   Rahman S, 2020, AAAI CONF ARTIF INTE, V34, P11932
   Rahman S, 2019, IEEE I CONF COMP VIS, P6081, DOI 10.1109/ICCV.2019.00618
   Rahman S, 2019, LECT NOTES COMPUT SC, V11361, P547, DOI 10.1007/978-3-030-20887-5_34
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sariyildiz MB, 2019, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2019.00227
   Sermanet P., 2 INT C LEARN REPR
   Shao Y, IEEE INT C IMAGE PRO, P3666
   Sun C, 2015, IEEE I CONF COMP VIS, P2596, DOI 10.1109/ICCV.2015.298
   Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130
   Wu Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1029, DOI 10.1145/3240508.3240640
   Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan CX, 2024, IEEE T PATTERN ANAL, V46, P1530, DOI 10.1109/TPAMI.2021.3140070
   Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320
   Yang LJ, 2017, PROC CVPR IEEE, P1978, DOI 10.1109/CVPR.2017.214
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu Y., 2018, IEEE T CYBERNETICS, V49, P1
   Yuan AH, 2019, NEUROCOMPUTING, V330, P17, DOI 10.1016/j.neucom.2018.10.059
   Zeyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P629, DOI 10.1007/978-3-030-58571-6_37
   Zheng Y., 2020, P ASIAN C COMPUTER V, P107
   Zheng Y, P 29 ACM INT C MULTI, P5410
   Zhongzheng Ren, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10595, DOI 10.1109/CVPR42600.2020.01061
   Zhu YZ, 2018, PROC CVPR IEEE, P1004, DOI 10.1109/CVPR.2018.00111
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 93
TC 0
Z9 0
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104515
DI 10.1016/j.imavis.2022.104515
EA JUL 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3F6VI
UT WOS:000830804100004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ke, X
   Lin, BH
   Guo, WZ
AF Ke, Xiao
   Lin, BingHui
   Guo, WenZhong
TI LocalFace: Learning significant local features for deep face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; ArcFace; Channel attention; Deep learning
AB As a widely mentioned topic in face recognition, the margin-based loss function enhances the discriminability of face recognition models by applying margin between class decision boundaries. However, there is still room to improve the representation of face features. Local face feature extraction has been employed in traditional face recognition methods, but with the increase of network depth in deep learning, the traditional approach requires a large number of computational resources. In this paper, we propose a novel face recognition architecture called LocalFace to extract local face features. First, by analyzing the distribution of significant features in face images, we propose an efficient face fixed-point local feature extraction approach and improve this method to propose a more effective face dynamic local feature extraction scheme. Subsequently, we propose a block-based random occlusion method for the limitations of the random face occlusion method to better simulate the occlusion situation in real scenes. In the end, we present a detailed discussion on the channel attention method that is more appropriate for face recognition and classification tasks. Our method enhances the representation of face features by ensembling local features into global features without extra parameters, which is efficient and easy to implement. Extensive experiments on various benchmarks demonstrate the superiority of our LocalFace, and part of the experimental results achieve SOTA results. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Ke, Xiao; Lin, BingHui; Guo, WenZhong] Fuzhou Univ, Coll Comp & Data Sci, Fujian Prov Key Lab Networking Comp & Intelligent, Fuzhou 350116, Peoples R China.
   [Ke, Xiao; Guo, WenZhong] Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou 350003, Peoples R China.
C3 Fuzhou University
RP Guo, WZ (corresponding author), Fuzhou Univ, Coll Comp & Data Sci, Fujian Prov Key Lab Networking Comp & Intelligent, Fuzhou 350116, Peoples R China.; Guo, WZ (corresponding author), Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou 350003, Peoples R China.
EM guowenzhong@fzu.edu.cn
FU National Natural Science Foundation of China [61972097, U21A20472];
   National Key Research and Development Plan of China [2021YFB3600503];
   Natural Science Foundation of Fujian Province [2021J01612, 2020J01494];
   Major Science and Technology Project of Fujian Province [2021HZ022007];
   Industry-Academy Cooperation Project of Fujian Province [2018H6010];
   Fujian Collaborative Innovation Center for Big Data Application in
   Governments; Fujian Engineering Research Center of Big Data Analysis and
   Processing
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61972097 and U21A20472, in part by the
   National Key Research and Development Plan of China under Grant
   2021YFB3600503, in part by the Natural Science Foundation of Fujian
   Province under Grant 2021J01612 and 2020J01494, in part by the Major
   Science and Technology Project of Fujian Province under Grant
   2021HZ022007, in part by the Industry-Academy Cooperation Project of
   Fujian Province under Grant 2018H6010, in part by the Fujian
   Collaborative Innovation Center for Big Data Application in Governments,
   and in part by the Fujian Engineering Research Center of Big Data
   Analysis and Processing. The authors also gratefully acknowledge the
   helpful comments and suggestions of the reviewers.
CR Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dong Y., 2014, ARXIV 14117923 CSCV
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu W., 2019, 2019 IEEECVF C COMPU
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Jiankang Deng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P741, DOI 10.1007/978-3-030-58621-8_43
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Kim Y., 2020, P IEEECVF C COMPUTER
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Sengupta S, 2016, IEEE WINT CONF APPL
   Shi YC, 2020, PROC CVPR IEEE, P6816, DOI 10.1109/CVPR42600.2020.00685
   Shi YC, 2019, IEEE I CONF COMP VIS, P6901, DOI 10.1109/ICCV.2019.00700
   Su Yu, 2010, Journal of Software, V21, P1849, DOI 10.3724/SP.J.1001.2010.03627
   Trigueros DS, 2018, IMAGE VISION COMPUT, V79, P99, DOI 10.1016/j.imavis.2018.09.011
   Wang F., 2018, P EUROPEAN C COMPUTE
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081
   Wang Q, 2020, 2020 IEEECVF C COMPU
   Wang X., 2020, P AAAI C ARTIFICIAL
   Wang XB, 2019, IEEE I CONF COMP VIS, P9357, DOI 10.1109/ICCV.2019.00945
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87
   Xie WD, 2018, LECT NOTES COMPUT SC, V11215, P811, DOI 10.1007/978-3-030-01252-6_48
   Xu J, 2021, NEUROCOMPUTING, V448, P40, DOI 10.1016/j.neucom.2021.03.043
   Zhang F, 2020, INT C MULTIMEDIA MOD
   Zhang X, 2019, PROC CVPR IEEE, P10815, DOI 10.1109/CVPR.2019.01108
   Zhang X, 2019, PROC CVPR IEEE, P9898, DOI 10.1109/CVPR.2019.01014
   Zheng T., 2018, 1801 BEIJ U POSTS TE
   Zheng Tianyue, 2017, CROSS AGE LFW DATABA
   Zongxin Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11791, DOI 10.1109/CVPR42600.2020.01181
NR 36
TC 3
Z9 3
U1 5
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104484
DI 10.1016/j.imavis.2022.104484
EA MAY 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1W0YE
UT WOS:000806506500005
DA 2024-07-18
ER

PT J
AU Chen, K
   Yi, TH
   Lv, Q
AF Chen, Kai
   Yi, Taihe
   Lv, Qi
TI Fast and reliable probabilistic face embeddings based on constrained
   data uncertainty estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Probabilistic face embeddings; Deep learning; Face recognition; Data
   uncertainty estimation
ID QUALITY ASSESSMENT; IMAGE QUALITY
AB Probabilistic Face Embeddings (PFE) can improve face recognition performance in unconstrained scenarios by in-tegrating data uncertainty into the feature representation. However, the matching speed of PFE is too slow to be applied to large-scale face recognition or retrieval applications. Moreover, since deep learning-based data uncer-tainty estimation tends to be over-confident, the recognition performance of PFE is unstable. This paper proposes a probabilistic face embedding method to improve the robustness and speed of PFE. Specifically, the mutual like-lihood score (MLS) metric used in PFE is simplified by using a one-dimensional variance to approximate the data uncertainty of face feature, to speed up the matching of probabilistic embedding pairs. Then, a unilateral con-straint loss is proposed to limit the variation range of the lower part of the estimated data uncertainties, which can solve the problem of accuracy degradation in high-quality images. In addition, a feature fusion method based on temperature scaling is proposed, which can adjust the fusion weights of different quality images to im-prove the performance of video face recognition. Comprehensive experiments show that the proposed method can achieve comparable or better results in 6 benchmarks than the state-of-the-art methods with a less compu-tational cost at the matching process.
   (c) 2022 Elsevier B.V. All rights reserved.
C1 [Chen, Kai; Yi, Taihe] Natl Univ Def Technol, Coll Syst Engn, Changsha, Peoples R China.
   [Lv, Qi] Natl Univ Def Technol, Coll Meteorol & Oceanog, Changsha, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China
RP Lv, Q (corresponding author), Natl Univ Def Technol, Coll Meteorol & Oceanog, Changsha, Peoples R China.
EM lvqi@nudt.edu.cn
RI ; Chen, Kai/G-8575-2016
OI Lv, Qi/0000-0003-4115-720X; Chen, Kai/0000-0003-4160-1024
FU National Natural Science Foun-dation of China [61906207, 61803376]
FX Acknowledgement This work was mainly supported by National Natural
   Science Foun-dation of China (61906207, 61803376) .
CR Abdar M., 2021, UncertaintyFuseNet: robust uncertainty-aware hierarchical feature fusion with ensemble Monte Carlo dropout for COVID-19 detection
   An Xiang, 2020, ARXIV201005222
   [Anonymous], Handbook of Face Recognition, DOI [DOI 10.1007/978-0-85729-932-1_21, 10.1007/978-0-85729-932-1_21]
   Ashukha A., 2020, 8 INT C LEARN REPR I
   Bertoni L., P IEEE INT C COMPUTE, P6861
   Best-Rowden L, 2018, IEEE T INF FOREN SEC, V13, P3064, DOI 10.1109/TIFS.2018.2799585
   Bharadwaj S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-34
   Bojchevski Aleksandar, 2018, ICLR
   Cao K., P IEEE C COMPUTER VI, P5187
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chang Jie., P IEEECVF C COMPUTER, P5710
   Chen D., P IEEE C COMPUTER VI, P3025
   Chen K, 2021, IEEE SIGNAL PROC LET, V28, P1878, DOI 10.1109/LSP.2021.3109781
   Deng J., 2019, P IEEE C COMPUTER VI, P4690
   Deng JJ, 2019, IEEE I CONF COMP VIS, P7022, DOI 10.1109/ICCV.2019.00712
   Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5
   Feng D, 2018, IEEE INT C INTELL TR, P3266, DOI 10.1109/ITSC.2018.8569814
   Gal Y., INT C MACHINE LEARNI, P1050
   Gal Y., 2015, ARXIV PREPRINT
   Gallagher A., 2018, ARXIV181000319
   Gong S., ARXIV PREPRINT ARXIV
   Grother P, 2020, ONGOING FACE RECOG 5
   Gundavarapu NB, 2019, IEEE C COMP VIS PATT
   Guo CA, 2017, PR MACH LEARN RES, V70
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hernandez-Ortega J, 2019, INT CONF BIOMETR
   Hu J., P IEEE C COMPUTER VI, P7132
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang Y., P IEEECVF C COMPUTER, P5901
   Kendall A, 2017, 31 ANN C NEURAL INFO, V30
   Khan S., P IEEE C COMPUTER VI, P103
   Kim Y., P IEEECVF C COMPUTER, P5621
   Kraus F, 2019, IEEE INT C INTELL TR, P53, DOI 10.1109/ITSC.2019.8917494
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lakshminarayanan Balaji, 2017, ADV NEURAL INFORM PR, P6402, DOI DOI 10.5555/3295222.3295387
   Le H., 2019 IEEE WINTER C A, P2146
   Li C., P IEEE C COMPUTER VI, P5666
   Liu R., 2021, P IEEE CVF C COMP VI, P1482
   Liu W, P IEEE C COMP VIS PA, P212
   Liu WY, 2016, PR MACH LEARN RES, V48
   Loquercio A, 2020, IEEE ROBOT AUTOM LET, V5, P3153, DOI 10.1109/LRA.2020.2974682
   Masi I., P IEEE C COMPUTER VI, P4838
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Moschoglou S., 2017, P IEEE C COMPUTER VI, P51
   Nair T, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101557
   Olsen MA, 2016, IET BIOMETRICS, V5, P47, DOI 10.1049/iet-bmt.2014.0055
   Pereyra G., 2017, ICLR WORKSH, P313
   Posch K., 2019, ARXIV PREPRINT ARXIV
   Qian Y., P IEEE C COMP VIS PA, P9851
   Schlett T, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3507901
   Schroff F., P IEEE C COMPUTER VI P IEEE C COMPUTER VI, P815
   Scott T.R., 2019, ARXIV
   Sengupta S., 2016, 2016 IEEE WINT C APP, P1, DOI [DOI 10.1109/WACV.2016.7477558, 10.1109/WACV.2016.7477558]
   Shi Y., P IEEECVF C COMPUTER, P6817
   Shi YC, 2019, IEEE I CONF COMP VIS, P6901, DOI 10.1109/ICCV.2019.00700
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sünderhauf N, 2018, INT J ROBOT RES, V37, P405, DOI 10.1177/0278364918770733
   Sun Jennifer J., 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P53, DOI 10.1007/978-3-030-58558-7_4
   Sun Y., 2015, ARXIV150200873
   Taigman Y., P IEEE C COMPUTER VI, P1701
   Terhörst P, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185975
   Terhorst P., P IEEECVF C COMPUTER, P5651
   Terhrst P., 2021, ARXIV PREPRINT ARXIV
   Tran L., Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1415
   Tu XG, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3402446
   Vilnis L., 2015, C TRACK P
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H., Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P5265
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Whitelam C., P IEEE C COMPUTER VI, P90
   Wirges S., 2019 IEEE INTELLIGEN, P1520
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Xianyi Zhang., OpenBLAS
   Xie W., 2020, ARXIV PREPRINT ARXIV
   Xie Weidi, 2018, Proc. British Machine Vision Conference
   Xu Y, 2017, IEEE T NEUR NET LEAR, V28, P2233, DOI 10.1109/TNNLS.2016.2580572
   Yi D., 2014, ARXIV PREPRINT
   Yin X, P IEEE INT C COMP VI, P3990
   Yu T., P IEEE INT C COMPUTE, P552
   Zhao K., P IEEECVF C COMPUTER, P1136
   Zheng T., 2018, DATA STUDYING CROSS, V5
   Zheng T, 2017, ARXIV COMPUTER VISIO
   Zhu Z., Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P10492
NR 85
TC 2
Z9 2
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104429
DI 10.1016/j.imavis.2022.104429
EA MAR 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0Z8MP
UT WOS:000791325900004
DA 2024-07-18
ER

PT J
AU Liu, YR
   Ju, YK
   Jian, MW
   Gao, F
   Rao, Y
   Hu, YQ
   Dong, JY
AF Liu, Yanru
   Ju, Yakun
   Jian, Muwei
   Gao, Feng
   Rao, Yuan
   Hu, Yeqi
   Dong, Junyu
TI A deep-shallow and global-local multi-feature fusion network for
   photometric stereo
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Photometric stereo; 3D reconstruction; Deep neural networks;
   Convolutional neural network; Multi-feature fusion
ID RECONSTRUCTION; IMAGES; SHAPE
AB Recovering 3D surfaces based on the photometric stereo is a challenging task, due to the non-Lambertian surface of real-world objects. Although much effort has been made to address this issue, existing photometric stereo methods based on deep learning did not fully consider the influence of global-local features and deep-shallow features on the training process. How to combine multi-feature into a framework effectively to overcome their drawbacks has not been explored. Therefore, we propose a novel multi-feature fusion photometric stereo network (MF-PSN), focusing on both local-global and deep-shallow features fusion. Global-local feature fusion maintains the features under different illuminations and the most salient features of all illuminations, thereby effectively uses the information of each input image. Deep-shallow feature fusion keeps the features from deep and shallow layers with different receptive fields, which effectively improves the accuracy and robustness of the model. Experiments show that multi-feature fusion can make full use of the information of the input image to achieve a better reconstruction of surface normals of the object. Extensive ablation studies and experiments on the widely used DiLiGenT benchmark dataset have well verified the effectiveness of our proposed method. In addition, testing on the Gourd & Apple dataset and Light Stage Data Gallery verifies the generalization of our method. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Yanru; Ju, Yakun; Gao, Feng; Rao, Yuan; Hu, Yeqi; Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, Qingdao 266100, Peoples R China.
   [Jian, Muwei] Linyi Univ, Sch Informat Sci & Engn, Linyi 276000, Peoples R China.
   [Jian, Muwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
C3 Ocean University of China; Linyi University; Shandong University of
   Finance & Economics
RP Ju, YK; Dong, JY (corresponding author), Ocean Univ China, Dept Comp Sci & Technol, Qingdao 266100, Peoples R China.
EM juyakun@stu.ouc.edu.cn; dongjunyu@ouc.edu.cn
RI Ju, Yakun/JEP-0636-2023; 刘, 彦汝/HTO-0487-2023; Jian, Muwei/Q-8319-2018
OI Ju, Yakun/0000-0003-4065-4108; Jian, Muwei/0000-0002-4249-2264
FU National Key Scientific Instrument and Equipment Development Projects of
   China [41927805]; National Natural Science Foundation of China
   [61501417, 61976123]; Royal Society-K. C. Wong International Fellowship
   [NIF\R1\180909]; Taishan Young Scholars Program of Shandong Province
FX This work was supported by the National Key Scientific Instrument and
   Equipment Development Projects of China (Grant No.41927805) , and the
   National Natural Science Foundation of China (Grants No.61501417 and
   No.61976123) , the Royal Society-K. C. Wong Inter-national Fellowship
   (NIF\R1\180909) and the Taishan Young Scholars Program of Shandong
   Province.
CR Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898
   Chandraker M, 2013, IEEE T PATTERN ANAL, V35, P2941, DOI 10.1109/TPAMI.2012.217
   Chen G., LECT NOTES COMPUT, P318
   Chen GY, 2022, IEEE T PATTERN ANAL, V44, P129, DOI 10.1109/TPAMI.2020.3005397
   Chen L, 2017, IEEE I CONF COMP VIS, P3181, DOI 10.1109/ICCV.2017.343
   Cheng KHM, 2019, IEEE T IMAGE PROCESS, V28, P1544, DOI 10.1109/TIP.2018.2875531
   Chung H.-S., 2008, P IEEE C COMP VIS PA
   Cong Wang, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P1643, DOI 10.1145/3394171.3413820
   Einarsson P., 2006, P EUROGRAPHICS S R, P76
   Enomoto K., P IEEECVF C COMPUTER, P2311
   Fan Q., 2019, PROC CVPR IEEE
   Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816
   Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P1060, DOI 10.1109/TPAMI.2009.102
   Higo T, 2010, PROC CVPR IEEE, P1157, DOI 10.1109/CVPR.2010.5540084
   Ikehata S, 2018, LECT NOTES COMPUT SC, V11219, P3, DOI 10.1007/978-3-030-01267-0_1
   Ikehata S, 2014, PROC CVPR IEEE, P2187, DOI 10.1109/CVPR.2014.280
   Jakob Wenzel, 2010, Mitsuba renderer
   Jian MW, 2020, IEEE T MULTIMEDIA, V22, P970, DOI 10.1109/TMM.2019.2937187
   Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510
   Ju YK, 2022, COMPUT VIS MEDIA, V8, P105, DOI 10.1007/s41095-021-0223-y
   Ju YK, 2020, IEEE I C VI COM I PR, P411, DOI 10.1109/vcip49819.2020.9301860
   Ju YK, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3096282
   Ju YK, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P694
   Ju YK, 2021, IEEE T IMAGE PROCESS, V30, P3676, DOI 10.1109/TIP.2021.3064230
   Ju YK, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107162
   Ju YK, 2020, NEUROCOMPUTING, V375, P62, DOI 10.1016/j.neucom.2019.09.084
   Ju YK, 2018, IEEE ACCESS, V6, P30804, DOI 10.1109/ACCESS.2018.2840138
   Li J., P IEEECVF C COMPUTER
   Li S, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.8.083104
   Nie W., 2021, IEEE T GEOSCI REMOTE
   Nie WZ, 2021, IEEE T MULTIMEDIA, V23, P1021, DOI 10.1109/TMM.2020.2991532
   Nie WZ, 2021, IEEE T MULTIMEDIA, V23, P1962, DOI 10.1109/TMM.2020.3006371
   Nie Wei-Zhi, 2020, IEEE T CYBERN, V52, P1862
   Nie WZ, 2021, IEEE T IMAGE PROCESS, V30, P4371, DOI 10.1109/TIP.2021.3071687
   Ruiters R, 2009, COMPUT GRAPH FORUM, V28, P513, DOI 10.1111/j.1467-8659.2009.01390.x
   Santo H, 2017, IEEE INT CONF COMP V, P501, DOI 10.1109/ICCVW.2017.66
   Shi BX, 2019, IEEE T PATTERN ANAL, V41, P271, DOI 10.1109/TPAMI.2018.2799222
   Shi BX, 2014, IEEE T PATTERN ANAL, V36, P1078, DOI 10.1109/TPAMI.2013.196
   SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103
   Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627
   Sun ZL, 2011, IEEE T INF FOREN SEC, V6, P360, DOI 10.1109/TIFS.2011.2118207
   Tan P, 2011, IEEE T PATTERN ANAL, V33, P2506, DOI 10.1109/TPAMI.2011.35
   Taniai T., 2018, P INT C MACHINE LEAR
   Verbiest F., 2008, P IEEE C COMP VIS PA, P1
   Wang C, 2022, NEUROCOMPUTING, V467, P242, DOI 10.1016/j.neucom.2021.10.029
   Wang C, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2517, DOI 10.1145/3394171.3413559
   Wang C, 2019, SIGNAL PROCESS-IMAGE, V78, P206, DOI 10.1016/j.image.2019.07.003
   Wiles O., P BRIT MACHINE VIS
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55
   Xiao J., P 29 ACM IN TERNAT
   Xiao J, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1620, DOI 10.1109/ICASSP39728.2021.9413846
   Xiao J, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116299
   Xiao J, 2019, IEEE IMAGE PROC, P2856, DOI [10.1109/icip.2019.8803251, 10.1109/ICIP.2019.8803251]
   Yao Z., 2020, P ADV NEUR INF PROC, V33, P10306
   Zheng Q., P INT C COMPUTER VIS, P8549
   Zhu H., 2020, 2020 IEEE INT C MULT, P1
NR 57
TC 14
Z9 14
U1 6
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2022
VL 118
AR 104368
DI 10.1016/j.imavis.2021.104368
EA JAN 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0F3OZ
UT WOS:000777273700007
DA 2024-07-18
ER

PT J
AU Jian, YR
   Gao, CY
AF Jian, Yiren
   Gao, Chongyang
TI MetaPix: Domain transfer for semantic segmentation by meta pixel
   weighting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Meta learning; Domain transfer learning; Semantic segmentation; Street
   view semantic segmentation
AB Training a deep neural model for semantic segmentation requires collecting a large amount of pixel-level labeled data. To alleviate the data scarcity problem presented in the real world, one could utilize synthetic data whose label is easy to obtain. Previous work has shown that the performance of a semantic segmentation model can be improved by training jointly with real and synthetic examples with a proper weighting on the synthetic data. Such weighting was learned by a heuristic to maximize the similarity between synthetic and real examples. In our work, we instead learn a pixel-level weighting of the synthetic data by meta-learning, i.e., the learning of weighting should only be minimizing the loss on the target task. We achieve this by gradient-on-gradient tech-nique to propagate the target loss back into the parameters of the weighting model. The experiments show that our method with only one single meta module can outperform a complicated combination of an adversarial fea-ture alignment, a reconstruction loss, plus a hierarchical heuristic weighting at pixel, region and image levels. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Jian, Yiren] Dartmouth Coll, Hanover, NH 03755 USA.
   [Gao, Chongyang] Northwestern Univ, Evanston, IL 60208 USA.
C3 Dartmouth College; Northwestern University
RP Jian, YR (corresponding author), Dartmouth Coll, Hanover, NH 03755 USA.
EM yiren.jian.gr@dartmouth.edu; chongyanggao2026@u.northwestern.edu
CR Andrychowicz M., ADV NEURAL INFORM PR, P3981
   [Anonymous], 2019, CVPR, DOI DOI 10.1109/CVPR.2019.00262
   Balaji Y, 2019, IEEE I CONF COMP VIS, P6509, DOI 10.1109/ICCV.2019.00660
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Chang WL, 2019, PROC CVPR IEEE, P1900, DOI 10.1109/CVPR.2019.00200
   Chen L.-J., 2015, INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION INT J HYPERTENSION, V2015, P2015
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, RETHINKING ATROUS CO
   Chen MH, 2019, IEEE I CONF COMP VIS, P2090, DOI 10.1109/ICCV.2019.00218
   Chen X., INT C MACH LEARN 201, P1081
   Chen YH, 2018, PROC CVPR IEEE, P7892, DOI 10.1109/CVPR.2018.00823
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cui S., 2020, ADV NEURAL INFORM PR, V33, P7571
   Devlin J., 2018, BERT PRE TRAINING DE
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Finn C, 2017, PR MACH LEARN RES, V70
   Flennerhag S., 2020, INT C LEARN REPR
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Haoran Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P642, DOI 10.1007/978-3-030-58568-6_38
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Li L, 2019, IEEE IMAGE PROC, P3167, DOI [10.1109/icip.2019.8803233, 10.1109/ICIP.2019.8803233]
   Li S, 2020, AAAI CONF ARTIF INTE, V34, P11386
   Li Y., 2021, ARXIV190410620
   Li YZ, 2018, OPTICA, V5, P1181, DOI 10.1364/OPTICA.5.001181
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin X, 2019, ADV NEUR IN, V32
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo YW, 2019, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2019.00261
   Pan Fei, 2020, IEEE C COMP VIS PATT
   Pandey P., 2021, ARXIV200608696
   Pham H., 2021, P C COMP VIS PATT RE, P11557
   Qibin Hou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P4002, DOI 10.1109/CVPR42600.2020.00406
   Ravi S., 2016, INT C LEARNING REPRE
   Ravi S, 2017, LIT CULT ENVIRON, P25, DOI 10.1007/978-3-319-41516-1_2
   Ren MY, 2018, PR MACH LEARN RES, V80
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Rozantsev A, 2018, PROC CVPR IEEE, P4339, DOI 10.1109/CVPR.2018.00456
   Rusu A. A., 2019, INT C LEARN REPR
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P3752, DOI 10.1109/CVPR.2018.00395
   Sun B, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P161, DOI 10.1109/ROBIO.2016.7866315
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sun RQ, 2019, PROC CVPR IEEE, P4355, DOI 10.1109/CVPR.2019.00449
   Takalani R, 2020, 2020 INTERNATIONAL SAUPEC/ROBMECH/PRASA CONFERENCE, P250, DOI 10.1109/saupec/robmech/prasa48453.2020.9041001
   Tang W, 2020, CHIN CONT DECIS CONF, P1440, DOI [10.1109/CCDC49329.2020.9164755, 10.1109/ccdc49329.2020.9164755]
   Tao A., 2021, HIERARCHICAL MULTISC
   Tian PZ, 2020, AAAI CONF ARTIF INTE, V34, P12087
   Tsai YH, 2019, IEEE I CONF COMP VIS, P1456, DOI 10.1109/ICCV.2019.00154
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Vaswani A, 2017, ADV NEUR IN, V30
   Vu TH, 2019, IEEE I CONF COMP VIS, P7363, DOI 10.1109/ICCV.2019.00746
   Yabin Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P781, DOI 10.1007/978-3-030-58548-8_45
   Yang YC, 2020, PROC CVPR IEEE, P4084, DOI 10.1109/CVPR42600.2020.00414
   Yang YC, 2020, PROC CVPR IEEE, P6557, DOI 10.1109/CVPR42600.2020.00659
   Yu S, 2019, ACTA METALL SIN-ENGL, V32, P433, DOI 10.1007/s40195-018-0792-7
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhang H., 2021, RESNEST SPLIT ATTENT
   Zhang P., 2021, P CVPR
   Zhang YB, 2019, PROC CVPR IEEE, P5026, DOI 10.1109/CVPR.2019.00517
   Zhang Y, 2020, IEEE T PATTERN ANAL, V42, P1823, DOI 10.1109/TPAMI.2019.2903401
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhu JY, 2017, I COMP CONF WAVELET, P179, DOI 10.1109/ICCWAMTIP.2017.8301474
   Zhu L., P IEEE CVF C COMP VI, P12537
   Zhu XG, 2018, LECT NOTES COMPUT SC, V11211, P587, DOI 10.1007/978-3-030-01234-2_35
   Zou Y., 2018, P EUR C COMP VIS ECC, P289
NR 71
TC 3
Z9 3
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104334
DI 10.1016/j.imavis.2021.104334
EA NOV 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA XF7WP
UT WOS:000724279100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zang, XH
   Li, G
   Gao, W
   Shu, XJ
AF Zang, Xianghao
   Li, Ge
   Gao, Wei
   Shu, Xiujun
TI Learning to disentangle scenes for person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Divide-and-conquer; Multi-branch network
AB There are many challenging problems in the person re-identification (ReID) task, such as the occlusion and scale variation. Existing works usually tried to solve them by employing a one-branch network. This one-branch net -work needs to be robust to various challenging problems, which makes this network overburdened. This paper proposes to divide-and-conquer the ReID task. For this purpose, we employ several self-supervision operations to simulate different challenging problems and handle each challenging problem using different networks. Con-cretely, we use the random erasing operation and propose a novel random scaling operation to generate new im-ages with controllable characteristics. A general multi-branch network, including one master branch and two servant branches, is introduced to handle different scenes. These branches learn collaboratively and achieve dif-ferent perceptive abilities. In this way, the complex scenes in the ReID task are effectively disentangled, and the burden of each branch is relieved. The results from extensive experiments demonstrate that the proposed method achieves state-of-the-art performances on three ReID benchmarks and two occluded ReID benchmarks. Ablation study also shows that the proposed scheme and operations significantly improve the performance in various scenes. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zang, Xianghao; Li, Ge; Gao, Wei] Peking Univ, Sch Elect & Comp Engn, Shenzhen 518055, Peoples R China.
   [Shu, Xiujun] Peng Cheng Lab, Shenzhen 518034, Peoples R China.
C3 Peking University; Peng Cheng Laboratory
RP Gao, W (corresponding author), Peking Univ, Sch Elect & Comp Engn, Shenzhen 518055, Peoples R China.
EM zangxh@pku.edu.cn; geli@ece.pku.edu.cn; gaowei262@pku.edu.cn;
   shuxj@pcl.ac.cn
RI Xianghao, Zang/AGJ-2975-2022
FU Key-Area Research and Development Program of Guangdong Province
   [2019B121204008]; National Natural Science Foundation of China
   [61801303, 62031013]; Guangdong Basic and Applied Basic Research
   Foundation [2019A1515012031]; Shenzhen Science and Technology Plan Basic
   Research Project [JCYJ20190808161805519]; Shenzhen Fundamental Research
   Program [GXWD20201231165807007-20200806163656003]
FX This work was supported by the Key-Area Research and Development Program
   of Guangdong Province (2019B121204008), the National Natural Science
   Foundation of China (61801303 and 62031013), the Guangdong Basic and
   Applied Basic Research Foundation (2019A1515012031), the Shenzhen
   Science and Technology Plan Basic Research Project
   (JCYJ20190808161805519), and the Shenzhen Fundamental Research Program
   (GXWD20201231165807007-20200806163656003).
CR Ahn S, 2019, PROC CVPR IEEE, P9155, DOI 10.1109/CVPR.2019.00938
   Alemu LT, 2019, IEEE I CONF COMP VIS, P9854, DOI 10.1109/ICCV.2019.00995
   [Anonymous], 2017, P 31 INT C NEUR INF
   [Anonymous], 2019, ABS190703253 CORR
   [Anonymous], 2017, ARXIV171000870
   Boyan Zhou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9716, DOI 10.1109/CVPR42600.2020.00974
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dai ZZ, 2019, IEEE I CONF COMP VIS, P3690, DOI 10.1109/ICCV.2019.00379
   Dean J., 2015, NIPS DEEP LEARNING R
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fang PF, 2019, IEEE I CONF COMP VIS, P8029, DOI 10.1109/ICCV.2019.00812
   Gao Lishuai, 2020, P 28 ACM INT C MULT, P3771
   Gao Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1879, DOI 10.1145/3343031.3350861
   Ge Yixiao, 2020, ARXIV200101526
   Gray Douglas, 2007, P IEEE INT WORKSH PE, V3, P1
   Guan'an Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P275, DOI 10.1007/978-3-030-58598-3_17
   Guo JY, 2019, IEEE I CONF COMP VIS, P3641, DOI 10.1109/ICCV.2019.00374
   Hao Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P57, DOI 10.1145/3343031.3351006
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   He Lingxiao, 2020, VOLABS200602631 CORR, V6, P8
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Huang H, 2018, ARXIV181211369
   Jiaxin Chen, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P3034, DOI 10.1145/3394171.3413979
   Jin X, 2019, ARXIV PREPRINT ARXIV
   Jin X, 2020, AAAI CONF ARTIF INTE, V34, P11165
   King DB, 2015, ACS SYM SER, V1214, P1
   Leibe B., 2017, ARXIV170307737CS
   Liu FY, 2019, IEEE I CONF COMP VIS, P6638, DOI 10.1109/ICCV.2019.00674
   Loshchilov I, 2016, ARXIV
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   Lv JY, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103875
   Lv Y., 2020, ADV NEURAL INF PROCE, V33
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Munjal B., 2019, BMVC
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Park H., 2019, ARXIV PREPRINT ARXIV
   Peng P., P274
   Porrello Angelo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P93, DOI 10.1007/978-3-030-58607-2_6
   Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Sun H, 2019, IEEE I CONF COMP VIS, P6736, DOI 10.1109/ICCV.2019.00684
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Taojiannan Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P299, DOI 10.1007/978-3-030-58452-8_18
   Tian Yonglong, 2019, INT C LEARN REPR
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang Jiaxing, 2020, ADV NEUR IN, V33
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xu BQ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P673, DOI 10.1145/3394171.3414056
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Yang FX, 2020, AAAI CONF ARTIF INTE, V34, P12597
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Yu Zhengxu, 2019, IJCAI
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, ARXIV
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhipu Liu, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P4289, DOI 10.1145/3394171.3413689
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou JH, 2020, PROC CVPR IEEE, P2906, DOI 10.1109/CVPR42600.2020.00298
   Zhou JM, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103931
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhou SP, 2019, IEEE I CONF COMP VIS, P8039, DOI 10.1109/ICCV.2019.00813
   Zhu K., 2020, ECCV, P346, DOI [10.1007/978-3-030-58580-8_21, DOI 10.1007/978-3-030-58580-8_21]
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 80
TC 16
Z9 18
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104330
DI 10.1016/j.imavis.2021.104330
EA NOV 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WU6KE
UT WOS:000716651500003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Manmadhan, S
   Kovoor, BC
AF Manmadhan, Sruthy
   Kovoor, Binsu C.
TI Multi-Tier Attention Network using Term-weighted Question Features for
   Visual Question Answering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Attention mechanism; Deep learning; Semantic similarity; Supervised term
   weighting; Visual Question Answering
AB Visual Question Answering (VQA) is a multi-modal challenging task that accepts an image and a natural language question about that image as inputs and desires to find the correct answer. This AI-complete task necessitates the fine-grained joint understanding of the two input modalities. Inspired by the success of attention mechanism in the task of efficient comprehension of visual-language features for VQA, this paper proposes a Multi-Tier Attention Network (MTAN) with the major component being term-weighted question-guided visual attention. Additionally, we introduce a novel Supervised Term Weighting (STW) scheme named 'qf.obj.cos' to semantically weight words utilizing the notion of visual object detection. This can be generalized to other vision-language comprehension tasks like image captioning, text-to-image-retrieval, multi-modal summarization etc. In effect, the proposed system allows the generation of more discriminative visual features from the progressive steps of question guided visual attention where question embedding is indeed guided by semantic term weighting. MTAN is quantitatively and qualitatively evaluated on the benchmark DAQUAR dataset and an extensive set of ablations are studied to demonstrate the individual significance of each of the components of the system. Experimental results certify that MTAN performs better than the previous works using the same dataset. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Manmadhan, Sruthy; Kovoor, Binsu C.] Cochin Univ Sci & Technol, Div Informat Technol, Kochi 682022, Kerala, India.
C3 Cochin University Science & Technology
RP Manmadhan, S (corresponding author), Cochin Univ Sci & Technol, Div Informat Technol, Kochi 682022, Kerala, India.
EM sruthym.88@gmail.com
CR [Anonymous], 2017, ARXIV170206700
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chen K., 2015, Abc-cnn: An attention based convolutional neural network for visual question answering
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Debole F, 2004, STUD FUZZ SOFT COMP, V138, P81
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Gao LL, 2020, NEUROCOMPUTING, V391, P227, DOI 10.1016/j.neucom.2018.11.102
   Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112
   Guo WY, 2021, IEEE T IMAGE PROCESS, V30, P6730, DOI 10.1109/TIP.2021.3097180
   Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380
   Hasan Sadid A, 2018, CLEF WORKING NOTES
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kafle K, 2016, PROC CVPR IEEE, P4976, DOI 10.1109/CVPR.2016.538
   Kazemi V., 2017, ARXIV170403162
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan M, 2009, IEEE T PATTERN ANAL, V31, P721, DOI 10.1109/TPAMI.2008.110
   Li W, 2019, LECT NOTES COMPUT SC, V11132, P145, DOI 10.1007/978-3-030-11018-5_13
   Liang JW, 2018, PROC CVPR IEEE, P6135, DOI 10.1109/CVPR.2018.00642
   Lobry S, 2020, IEEE T GEOSCI REMOTE, V58, P8555, DOI 10.1109/TGRS.2020.2988782
   Lu JS, 2016, ADV NEUR IN, V29
   Luo QM, 2011, EXPERT SYST APPL, V38, P12708, DOI 10.1016/j.eswa.2011.04.058
   Ma L, 2016, AAAI CONF ARTIF INTE, P3567
   Malinowski M, 2014, ADV NEUR IN, V27
   Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1
   Malinowski M, 2017, INT J COMPUT VISION, V125, P110, DOI 10.1007/s11263-017-1038-2
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Manmadhan S, 2020, ARTIF INTELL REV, V53, P5705, DOI 10.1007/s10462-020-09832-7
   Moreo A, 2020, IEEE T KNOWL DATA EN, V32, P302, DOI 10.1109/TKDE.2018.2883446
   Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11
   Peng L, 2019, MULTIMED TOOLS APPL, V78, P3843, DOI 10.1007/s11042-018-6389-3
   Quan XJ, 2011, IEEE T PATTERN ANAL, V33, P1009, DOI 10.1109/TPAMI.2010.154
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Q, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P207, DOI 10.1145/3323873.3325044
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wei B, 2011, LECT NOTES ELECT ENG, P87, DOI DOI 10.1007/978-94-007-2105-0_11
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Yu LC, 2015, IEEE I CONF COMP VIS, P2461, DOI 10.1109/ICCV.2015.283
   Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542
   Zhang S, 2021, INFORM FUSION, V73, P1, DOI 10.1016/j.inffus.2021.02.022
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 49
TC 4
Z9 4
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104291
DI 10.1016/j.imavis.2021.104291
EA SEP 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WB1NI
UT WOS:000703345700003
DA 2024-07-18
ER

PT J
AU Shao, BT
   Chen, Y
AF Shao, Baitan
   Chen, Ying
TI Multi-granularity for knowledge distillation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Knowledge distillation; Model compression; Multi-granularity
   distillation mechanism; Multi-granularity self-analyzing module; Stable
   excitation scheme
ID NETWORK
AB Considering the fact that students have different abilities to understand the knowledge imparted by teachers, a multi-granularity distillation mechanism is proposed for transferring more understandable knowledge for stu-dent networks. A multi-granularity self-analyzing module of the teacher network is designed, which enables the student network to learn knowledge from different teaching patterns. Furthermore, a stable excitation scheme is proposed to train the student under robust supervision. The proposed distillation mechanism can be embedded into different distillation frameworks, which are taken as baselines. Experiments show the mecha-nism improves the accuracy by 0.58% on average and by 1.08% in the best over the baselines, which makes its per-formance superior to the state-of-the-arts. It is also exploited that the student's ability of fine-tuning and robustness to noisy inputs can be improved via the proposed mechanism. The code is available at https:// github.com/shaoeric/multi-granularity-distillation. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Shao, Baitan; Chen, Ying] Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Chen, Y (corresponding author), Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
EM shaoeric@foxmail.com; chenying@jiangnan.edu.cn
RI Ying, Chen/GRX-5695-2022; Chen, Ying/AAA-2911-2022
OI Chen, Ying/0000-0002-1674-0869; Shao, Baitan/0000-0002-3502-4884
FU National Natural Science Foundation of China [62173160]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62173160.
CR Ahn S, 2019, PROC CVPR IEEE, P9155, DOI 10.1109/CVPR.2019.00938
   [Anonymous], 2020, PROC CVPR IEEE, DOI DOI 10.1109/CVPR42600.2020.00643
   [Anonymous], 2015, COMPUT SCI, DOI DOI 10.4140/TCP.N.2015.249
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P37, DOI 10.1007/978-3-642-00296-0_5
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen DF, 2021, AAAI CONF ARTIF INTE, V35, P7028
   Coates A., 2011, P 14 INT C ART INT S, V15, P215
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Gu HY, 2021, NEUROCOMPUTING, V435, P53, DOI 10.1016/j.neucom.2020.12.105
   Guan'an Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P275, DOI 10.1007/978-3-030-58598-3_17
   Guo Q., 2020, P IEEE CVF C COMP VI
   Han  S., 2015, ARXIV151000149
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helong Z., 2021, INT C LEARN REPR ICL
   Heo B, 2019, IEEE I CONF COMP VIS, P1921, DOI 10.1109/ICCV.2019.00201
   Heo B, 2019, AAAI CONF ARTIF INTE, P3779
   Howard A. G., 2017, arXiv
   Huang Z., 2017, ARXIV170701219
   Hubara I., 2016, ADV NEURAL INFORM PR, P4114
   Izenman AJ, 2008, SPRINGER TEXTS STAT, P237, DOI 10.1007/978-0-387-78189-1_8
   Ji M, 2021, AAAI CONF ARTIF INTE, V35, P7945
   Jia FW, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104143
   Kim J, 2018, ADV NEUR IN, V31
   Komodakis N, 2017, ICLR
   Kornblith S, 2019, PR MACH LEARN RES, V97
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Kumar D, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104111
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li YY, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.10.005
   Musgrave K., 2020, ABS200809164 ARXIV
   Nguyen-Meidine L, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104096
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Passalis N, 2018, LECT NOTES COMPUT SC, V11215, P283, DOI 10.1007/978-3-030-01252-6_17
   Peng BY, 2019, IEEE I CONF COMP VIS, P5006, DOI 10.1109/ICCV.2019.00511
   Romero A., 2015, ABS14126550
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tian Yonglong, 2020, INT C LEARN REPR ICL
   Tung F, 2019, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2019.00145
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei YX, 2021, CIRC SYST SIGNAL PR, V40, P4127, DOI 10.1007/s00034-021-01668-y
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Yosinski J, 2014, ADV NEUR IN, V27
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang HR, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107659
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou K., 2019, ARXIV191010093
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
NR 54
TC 2
Z9 2
U1 3
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104286
DI 10.1016/j.imavis.2021.104286
EA SEP 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WC6NH
UT WOS:000704372400008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nayak, R
   Pati, UC
   Das, SK
AF Nayak, Rashmiranjan
   Pati, Umesh Chandra
   Das, Santos Kumar
TI A comprehensive review on deep learning-based methods for video anomaly
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Deep learning; Deep regenerative models; Deep one-class models; Hybrid
   models; Spatiotemporal models; Video anomaly detection
ID SLOW FEATURE ANALYSIS; BEHAVIOR DETECTION; NEURAL-NETWORKS;
   LOCALIZATION; SURVEILLANCE; REPRESENTATIONS; EVENTS; ONLINE
AB Video surveillance systems are popular and used in public places such as market places, shopping malls, hospitals, banks, streets, education institutions, city administrative offices, and smart cities to enhance the safety of public lives and assets. Most of the time, the timely and accurate detection of video anomalies is the main objective of security applications. The video anomalies such as anomalous activities and anomalous entities are defined as the abnormal or irregular patterns present in the video that do not conform to the normal trained patterns. Anomalous activities such as fighting, riots, traffic rule violations, and stampede as well as anomalous entities such as weapons at the sensitive place and abandoned luggage should be detected automatically in time. However, the detection of video anomalies is challenging due to the ambiguous nature of the anomaly, various environmental conditions, the complex nature of human behaviors, and the lack of proper datasets. There are only a few dedicated surveys related to deep learning-based video anomaly detection as the research domain is in its early stages. However, state of the art lacks a review that provides a comprehensive study covering all the aspects such as definitions, classifications, modelings, performance evaluation methodologies, open and trending research challenges of video anomaly detection. Hence, in this survey, we present a comprehensive study of the deep learning-based methods reported in state of the art to detect the video anomalies. Further, we discuss the comparative analysis of the state of the art methods in terms of datasets, computational infrastructure, and performance metrics for both quantitative and qualitative analyses. Finally, we outline the challenges and promising directions for further research. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Nayak, Rashmiranjan; Pati, Umesh Chandra; Das, Santos Kumar] Natl Inst Technol, Dept Elect & Commun Engn, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Nayak, R (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Rourkela 769008, Odisha, India.
EM rashmiranjan.et@gmail.com; ucpati@nitrkl.ac.in; dassk@nitrkl.ac.in
RI Das, Santos Kumar/M-5844-2019
OI Das, Santos Kumar/0000-0002-8788-6152
FU IMPACTING RESEARCH INNOVATION AND TECHNOLOGY (IMPRINT) INDIA, an
   initiative of Ministry of Human Resource Development, Government of
   India [7794/2016]; Ministry of Housing and Urban Affairs, Government of
   India
FX This work is supported by the IMPACTING RESEARCH INNOVATION AND
   TECHNOLOGY (IMPRINT) INDIA (Grant No.-7794/2016), an initiative of
   Ministry of Human Resource Development, Government of India and Ministry
   of Housing and Urban Affairs, Government of India.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Aggarwal, 2010, IEEE International Conference on Pattern Recognition Workshops, P4
   Aggarwal C.C., 2015, Data Mining, P237, DOI [DOI 10.1007/978-3-319-14142-8_8, 10.1007/978-3-319-14142-8_8]
   Ahmed SA, 2019, IEEE T CIRC SYST VID, V29, P1985, DOI 10.1109/TCSVT.2018.2857489
   Ali Rabia, 2020, ARXIV PREPRINT ARXIV
   Ali S., 2020, CROWD FLOW SEGMENTAT
   Ali S, 2007, PROC CVPR IEEE, P65
   Amarasinghe K, 2018, C HUM SYST INTERACT, P311, DOI 10.1109/HSI.2018.8430788
   An J., 2015, Technical Report, V2, P1
   [Anonymous], 2015, P 2015 10 AS CONTR C
   Ballas N., 2020, ARXIV PREPRINT ARXIV
   Bao TL, 2017, MULTIMED TOOLS APPL, V76, P23213, DOI 10.1007/s11042-016-4100-0
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Benezeth Y, 2009, PROC CVPR IEEE, P2450
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bertini M, 2012, COMPUT VIS IMAGE UND, V116, P320, DOI 10.1016/j.cviu.2011.09.009
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhakat S, 2019, PROCEEDINGS OF THE 6TH ACM IKDD CODS AND 24TH COMAD, P252, DOI 10.1145/3297001.3297034
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Bird N, 2006, IEEE INT CONF ROBOT, P3775, DOI 10.1109/ROBOT.2006.1642279
   Bokhari M.U., 2018, BIG DATA ANAL, P149, DOI [10.1007/978-981-10-6620-7_16, DOI 10.1007/978-981-10-6620-7_16]
   Brun L, 2014, IEEE T CIRC SYST VID, V24, P1669, DOI 10.1109/TCSVT.2014.2302521
   Buch N, 2011, IEEE T INTELL TRANSP, V12, P920, DOI 10.1109/TITS.2011.2119372
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Chalapathy R, 2017, LECT NOTES ARTIF INT, V10534, P36, DOI 10.1007/978-3-319-71249-9_3
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chawla S., 2019, ARXIV PREPRINT ARXIV
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909
   Cheng KW, 2015, IEEE T IMAGE PROCESS, V24, P5288, DOI 10.1109/TIP.2015.2479561
   Chong Y.S., 2015, ARXIV PREPRINT ARXIV
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Christiansen P, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111904
   Chu WQ, 2019, IEEE T MULTIMEDIA, V21, P246, DOI 10.1109/TMM.2018.2846411
   Cong Y, 2013, IEEE T INF FOREN SEC, V8, P1590, DOI 10.1109/TIFS.2013.2272243
   Cosar S, 2017, IEEE T CIRC SYST VID, V27, P683, DOI 10.1109/TCSVT.2016.2589859
   Cui XG, 2014, PROC SPIE, V9069, DOI 10.1117/12.2050229
   CVPR, 2020, PETS 2009 BENCHM DAT
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dally B., EFFICIENTMETHODS HAR
   Das S.K., 2019, P IEEE INT S SMART E, P215
   Das S.K., P IEEE INT C ADV NER, P1
   Deepak K, 2021, SIGNAL IMAGE VIDEO P, V15, P215, DOI 10.1007/s11760-020-01740-1
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Dimokranitou Asimenia., 2017, Adversarial autoencoders for anomalous event detection in images
   Dong F, 2020, IEEE ACCESS, V8, P88170, DOI 10.1109/ACCESS.2020.2993373
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Elhamod M, 2013, IEEE T INTELL TRANSP, V14, P688, DOI 10.1109/TITS.2012.2228640
   Farhadi A., ARXIV PREPRINT ARXIV
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Fisher R.B., 2004, IEEE International Workshop on Performance Evaluation of Tracking and Surveillance (PETS), P1
   George M, 2020, MULTIMED TOOLS APPL, V79, P27511, DOI 10.1007/s11042-020-09277-8
   Germain M, 2015, PR MACH LEARN RES, V37, P881
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Gowsikhaa D, 2014, ARTIF INTELL REV, V42, P747, DOI 10.1007/s10462-012-9341-3
   Han Shaoning, 2020, ARXIV PREPRINT ARXIV
   Han S, 2013, IEEE IMAGE PROC, P151, DOI 10.1109/ICIP.2013.6738032
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Hettich S. D., UCI KDD ARCH
   Hiley L., 2020, ARXIV PREPRINT ARXIV
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hu X, 2016, IET COMPUT VIS, V10, P258, DOI 10.1049/iet-cvi.2015.0271
   I. I. C. on Advanced Video, 2020, S BASED SURVEILLANCE
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jacobs H., 1967, COLUMBIA JOURNAL REV, V5, P37
   Jia J., P IEEE C COMP VIS PA, P2211
   Jiang F, 2011, COMPUT VIS IMAGE UND, V115, P323, DOI 10.1016/j.cviu.2010.10.008
   Joshi P.M., GENERATIVE VS DISCRI
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kiran BR, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020036
   Ko KE, 2018, ENG APPL ARTIF INTEL, V67, P226, DOI 10.1016/j.engappai.2017.10.001
   Ko Teddy, 2011, Video Surveillance, P279
   Kompella VR, 2012, NEURAL COMPUT, V24, P2994, DOI 10.1162/NECO_a_00344
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Krausz B, 2012, COMPUT VIS IMAGE UND, V116, P307, DOI 10.1016/j.cviu.2011.08.006
   Kumaran, 2019, ARXIV PREPRINT ARXIV
   Larochelle H., 2011, P 14 INT C ARTIFICIA, P29
   Leach MJV, 2014, PATTERN RECOGN LETT, V44, P71, DOI 10.1016/j.patrec.2013.11.018
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lee DG, 2015, IEEE T CIRC SYST VID, V25, P1612, DOI 10.1109/TCSVT.2015.2395752
   Leyva R., 2016, 2016 INT C DIG IM CO, P1, DOI [DOI 10.1109/DICTA.2016.7797041, 10.1109/DICTA.2016.7797041.]
   Leyva R, 2017, I W BIOMETRIC FORENS
   Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105
   Leyva R, 2016, IEEE IMAGE PROC, P4185, DOI 10.1109/ICIP.2016.7533148
   Li H, 2012, IET SIGNAL PROCESS, V6, P521, DOI 10.1049/iet-spr.2011.0074
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Li YY, 2019, IEEE ACCESS, V7, P172425, DOI 10.1109/ACCESS.2019.2954540
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu YZ, 2020, IEEE T KNOWL DATA EN, V32, P1517, DOI 10.1109/TKDE.2019.2905606
   Loy C., 2010, AS C COMP VIS, P161
   Loy CC., 2012, International symposium on communications control and signal processing p, P1
   Loy CC, 2012, PROC CVPR IEEE, P1560, DOI 10.1109/CVPR.2012.6247847
   Loy CC, 2011, PATTERN RECOGN, V44, P117, DOI 10.1016/j.patcog.2010.07.023
   Loy ChenChange., 2009, BMVC, P1
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lu CW, 2014, IEEE T IMAGE PROCESS, V23, P837, DOI 10.1109/TIP.2013.2287602
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Majhi S, 2019, INT C COMP VIS IM PR, P343
   Torres DM, 2019, IMAGE VISION COMPUT, V89, P197, DOI 10.1016/j.imavis.2019.07.006
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Maxion R.A., 2004, Proper use of roc curves in intrusion/anomaly detection
   Medel J.R., 2016, ARXIV PREPRINT ARXIV
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Meng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3401, DOI 10.1109/CVPR.2011.5995698
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Mousavi H, 2015, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2015.27
   Mukherjee M, 2018, IEEE COMMUN SURV TUT, V20, P1826, DOI 10.1109/COMST.2018.2814571
   Munawar A, 2017, IEEE WINT CONF APPL, P1017, DOI 10.1109/WACV.2017.118
   Narasimhan MG, 2018, MULTIMED TOOLS APPL, V77, P13173, DOI 10.1007/s11042-017-4940-2
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Parameswaran S, 2016, PROC SPIE, V9844, DOI 10.1117/12.2224667
   Patil N, 2016, 2016 SIXTH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2016), P43, DOI 10.1109/ISED.2016.7977052
   Patraucean V., 2015, WORKSH TRACK INT C L, P01
   Pawar K, 2019, WORLD WIDE WEB, V22, P571, DOI 10.1007/s11280-018-0582-1
   Peng X, 2018, IEEE T IMAGE PROCESS, V27, P5076, DOI 10.1109/TIP.2018.2848470
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026
   Pimentel Tiago, 2020, IEEE IJCNN, P1, DOI DOI 10.1109/IJCNN48605.2020.9206769
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ramachandra B, 2020, IEEE WINT CONF APPL, P2558, DOI [10.1109/WACV45572.2020.9093457, 10.1109/wacv45572.2020.9093457]
   Ravanbakhsh M., 2020, ARXIV PREPRINT ARXIV
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Revathi AR, 2017, SIGNAL IMAGE VIDEO P, V11, P291, DOI 10.1007/s11760-016-0935-0
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Ribnick E, 2006, P IEEE INT C VID SIG, P10
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P1235, DOI 10.1109/ICCV.2011.6126374
   Roman R, 2018, FUTURE GENER COMP SY, V78, P680, DOI 10.1016/j.future.2016.11.009
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Roy P, 2003, TRANSPORT RES REC, P96
   Rui Huang, 2019, Security, Privacy, and Anonymity in Computation, Communication, and Storage. SpaCCS 2019 International Workshops. Proceedings: Lecture Notes in Computer Science (LNCS 11637), P160, DOI 10.1007/978-3-030-24900-7_13
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shi XJ, 2015, ADV NEUR IN, V28
   Singh Prashant, 2018, 2018 IEEE International Symposium on Circuits and Systems (ISCAS), DOI 10.1109/ISCAS.2018.8351054
   Singh S.B.ShawandA.K., 2014, P 2014 INT C GREEN C, P1
   Snoek J, 2009, IMAGE VISION COMPUT, V27, P153, DOI 10.1016/j.imavis.2008.04.021
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Song X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2438653.2438670
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun L, 2016, COMPUT VIS IMAGE UND, V144, P144, DOI 10.1016/j.cviu.2015.10.009
   Sun L, 2014, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2014.336
   Tripathi RK, 2018, ARTIF INTELL REV, V50, P283, DOI 10.1007/s10462-017-9545-7
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varadarajan Jagannadan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1338, DOI 10.1109/ICCVW.2009.5457456
   Varadarajan J, 2017, IEEE WINT CONF APPL, P615, DOI 10.1109/WACV.2017.74
   Venkatesh S., 2020, ARXIV PREPRINT ARXIV
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang L, 2018, IEEE IMAGE PROC, P2276, DOI 10.1109/ICIP.2018.8451070
   Wang T, 2019, IEEE T INF FOREN SEC, V14, P1390, DOI 10.1109/TIFS.2018.2878538
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wierstra D., 2020, ARXIV PREPRINT ARXIV
   Wikipedia, 2020, CONF MATR
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu P, 2020, IEEE T NEUR NET LEAR, V31, P2609, DOI 10.1109/TNNLS.2019.2933554
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xiang T, 2008, COMPUT VIS IMAGE UND, V111, P59, DOI 10.1016/j.cviu.2007.06.004
   Xie N., 2020, ARXIV PREPRINT ARXIV
   Xiong GG, 2012, NEUROCOMPUTING, V83, P121, DOI 10.1016/j.neucom.2011.12.007
   Xu Da, 2020, ICLR
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu K, 2020, IEEE T MULTIMEDIA, V22, P394, DOI 10.1109/TMM.2019.2929931
   Xu K, 2018, IEEE T MULTIMEDIA, V20, P1062, DOI 10.1109/TMM.2018.2818942
   Yang B, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/2087574
   Yu K, 2011, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2011.5995732
   Yu W, 2018, IEEE ACCESS, V6, P6900, DOI 10.1109/ACCESS.2017.2778504
   Yuan Y, 2017, IEEE T CYBERNETICS, V47, P3597, DOI 10.1109/TCYB.2016.2572609
   Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41
   Zendel O, 2017, INT J COMPUT VISION, V125, P95, DOI 10.1007/s11263-017-1020-z
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zhang YH, 2015, IEEE T CIRC SYST VID, V25, P1231, DOI 10.1109/TCSVT.2014.2355711
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhong H, 2004, PROC CVPR IEEE, P819
   Zhou C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P665, DOI 10.1145/3097983.3098052
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
   Zhu YY, 2013, IEEE J-STSP, V7, P91, DOI 10.1109/JSTSP.2012.2234722
NR 194
TC 97
Z9 100
U1 15
U2 130
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104078
DI 10.1016/j.imavis.2020.104078
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700005
DA 2024-07-18
ER

PT J
AU Dai, Y
   Li, Y
   Li, ST
AF Dai, Yong
   Li, Yi
   Li, Shu-Tao
TI Multi-label learning for concept-oriented labels of product image data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-label learning; Concept-oriented labels; Product image data;
   Feature correlation learning; Gram matrices
ID CONVOLUTIONAL NEURAL-NETWORKS; FEATURE-SELECTION
AB In the designing field, designers usually retrieve the images for reference according to product attributes when designing new proposals. To obtain the attributes of the product, the designers take lots of time and effort to collect product images and annotate them with multiple labels. However, the labels of product images represent the concept of subjective perception, which makes the multi-label learning more challenging to imitate the human aesthetic rather than discriminate the appearance. In this paper, a Feature Correlation Learning (FCL) network is proposed to solve this problem by exploiting the potential feature correlations of product images. Given a product image, the FCL network calculates the features of different levels and their correlations via gram matrices. The FCL is aggregated with the DenseNet to predict the labels of the input product image. The proposed method is compared with several outstanding multi-label learning methods, as well as DenseNet. Experimental results demonstrate that the proposed method outperforms the state-of-the-arts for multi-label learning problem of product image data. (C) 2019 Published by Elsevier B.V. reserved.
C1 [Dai, Yong; Li, Shu-Tao] Hunan Univ, Sch Elect & Informat Engn, Changsha, Hunan, Peoples R China.
   [Li, Yi] Hunan Univ, Sch Design, Changsha, Hunan, Peoples R China.
   [Dai, Yong; Li, Shu-Tao] Key Lab Visual Percept & Artificial Intelligence, Changsha, Hunan, Peoples R China.
C3 Hunan University; Hunan University
RP Li, Y (corresponding author), Hunan Univ, Sch Design, Changsha, Hunan, Peoples R China.
EM 2012171@hnu.edu.cn
RI Li, Shutao/Y-3102-2019
OI Li, Shutao/0000-0002-0585-9848; Dai, Yong/0000-0003-2137-4821
FU National Natural Science Foundation of China [61772186]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61772186).
CR Alessandro A., 2013, International Joint Conference on Artificial Intelligence, P1220
   [Anonymous], ABS151206963 ARXIV
   [Anonymous], 2002, Computer Science, DOI DOI 10.1007/978-3-642-27733-7299-3
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Breiman L., 2001, Mach. Learn., V45, P5
   Cheng WW, 2009, MACH LEARN, V76, P211, DOI 10.1007/s10994-009-5127-5
   Dai Y, 2019, SENS IMAGING, V20, DOI 10.1007/s11220-019-0249-8
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gibaja E, 2014, WIRES DATA MIN KNOWL, V4, P411, DOI 10.1002/widm.1139
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Bui HM, 2016, IEEE ACCESS, V4, P10059, DOI 10.1109/ACCESS.2016.2639543
   Hu HX, 2016, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2016.323
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang XY, 2018, IEEE ACCESS, V6, P13716, DOI 10.1109/ACCESS.2018.2812794
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95
   Lee SJ, 2018, IEEE ACCESS, V6, P12755, DOI 10.1109/ACCESS.2018.2796722
   Li JJ, 2017, IEEE ACCESS, V5, P2955, DOI 10.1109/ACCESS.2017.2676761
   Li YN, 2016, LECT NOTES COMPUT SC, V9910, P684, DOI 10.1007/978-3-319-46466-4_41
   Li YC, 2017, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2017.199
   Liang GB, 2018, IEEE ACCESS, V6, P36188, DOI 10.1109/ACCESS.2018.2846685
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu N, 2018, IEEE ACCESS, V6, P11215, DOI 10.1109/ACCESS.2018.2798799
   Liu WW, 2015, AAAI CONF ARTIF INTE, P2800
   Luaces O, 2012, PROG ARTIF INTELL, V1, P303, DOI 10.1007/s13748-012-0030-x
   Madjarov G, 2012, PATTERN RECOGN, V45, P3084, DOI 10.1016/j.patcog.2012.03.004
   Nowak S., 2010, P INT C MULTIMEDIA I, P35
   Rokach L, 2014, EXPERT SYST APPL, V41, P7507, DOI 10.1016/j.eswa.2014.06.015
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santos KP, 2010, ZOOTAXA, P61, DOI 10.11646/zootaxa.2336.1.5
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Shu X, 2015, NEUROCOMPUTING, V168, P356, DOI 10.1016/j.neucom.2015.05.090
   Simonyan K., 2014, 14091556 ARXIV
   Spolaôr N, 2015, INT J COMPUT INT SYS, V8, P3, DOI 10.1080/18756891.2015.1129587
   Szymanski P, 2017, ABS170201460 ARXIV
   Tomar D, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT), P37, DOI 10.1109/CICT.2016.17
   Tsoumakas G, 2007, LECT NOTES ARTIF INT, V4701, P406
   Tsoumakas G, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P667, DOI 10.1007/978-0-387-09823-4_34
   Tsoumakas G, 2011, IEEE T KNOWL DATA EN, V23, P1079, DOI 10.1109/TKDE.2010.164
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang X, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P464
   Wang XD, 2017, IMAGE VISION COMPUT, V63, P10, DOI 10.1016/j.imavis.2017.05.004
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Yeh CK, 2017, AAAI CONF ARTIF INTE, P2838
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
   Zhu JQ, 2017, IMAGE VISION COMPUT, V58, P224, DOI 10.1016/j.imavis.2016.07.004
   杨云峰, 1999, [西安公路交通大学学报, Journal of Xian Highway University], P67
NR 50
TC 80
Z9 82
U1 2
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103821
DI 10.1016/j.imavis.2019.10.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000008
DA 2024-07-18
ER

PT J
AU Li, YY
   Zhang, D
   Lee, DJ
AF Li, Yuyuan
   Zhang, Dong
   Lee, Dah-Jye
TI IIRNet: A lightweight deep neural network using intensely inverted
   residuals for image recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional neural network (CNN); Lightweight CNN; Image recognition;
   Low-redundancy; Model size; Computation complexity
ID OBJECT
AB Deep neural networks have achieved great success in many tasks of pattern recognition. However, large model size and high cost in computation limit their applications in resource-limited systems. In this paper, our focus is to design a lightweight and efficient convolutional neural network architecture by directly training the compact network for image recognition. To achieve a good balance among classification accuracy, model size, and computation complexity, we propose a lightweight convolutional neural network architecture named IIRNet for resource-limited systems. The new architecture is built based on Intensely Inverted Residual block (IIR block) to decrease the redundancy of the convolutional blocks. By utilizing two new operations, intensely inverted residual and multi-scale low-redundancy convolutions, IIR block greatly reduces its model size and computational costs while matches the classification accuracy of the state-of-the-art networks. Experiments on CIFAR-10, CIFAR-100, and ImageNet datasets demonstrate the superior performance of IIRNet on the trade-offs among classification accuracy, computation complexity, and model size, compared to the mainstream compact network architectures. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Li, Yuyuan; Zhang, Dong] Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou, Guangdong, Peoples R China.
   [Li, Yuyuan; Zhang, Dong; Lee, Dah-Jye] Sun Yat Sen Univ, Shunde Res Inst, Shunde, Foshan, Peoples R China.
   [Lee, Dah-Jye] Brigham Young Univ, Dept Elect & Comp Engn, Provo, UT 84602 USA.
C3 Sun Yat Sen University; Sun Yat Sen University; Brigham Young University
RP Zhang, D (corresponding author), Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou, Guangdong, Peoples R China.
EM zhangd@mail.sysu.edu.cn
FU Guangzhou Municipal Science and Technology Project of China
   [201903010040]; Science and Technology Planning Project of Guangdong
   Province of China [20198070702004]
FX This work was supported by Guangzhou Municipal Science and Technology
   Project of China (201903010040), and the Science and Technology Planning
   Project of Guangdong Province of China (20198070702004).
CR Alistarh D, 2017, ADV NEUR IN, V30
   [Anonymous], P NEUR INF PROC SYST
   [Anonymous], 2014, Deeply-supervised nets
   [Anonymous], 2018, ARXIV180310615
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2018, P IEEE C COMP VIS PA
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2009, TECH REP
   [Anonymous], P 29 BRIT MACH VIS C
   [Anonymous], 2017, INT C LEARN REPR
   [Anonymous], 2017, INT C LEARN REPR
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2018, P IEEE C COMP VIS PA
   [Anonymous], 2018, P IEEE C COMP VIS PA
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   Bai Y, 2014, PROC INT CONF RECON
   Brahimi S, 2019, NEUROCOMPUTING, V330, P337, DOI 10.1016/j.neucom.2018.11.031
   Chen Guobin, 2017, NEURIPS
   Chollet F., 2017, P 2017 IEEE C COMP V, P1800
   Dou C, 2019, AGING MENT HEALTH, V23, P411, DOI 10.1080/13607863.2017.1423030
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Iandola F.N., 2016, PROC INT C LEARN
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim Yong-Deok, 2016, INT C LEARNING REPRE
   Lebedev V., 2015, T ICLR POST
   Li YY, 2019, NEUROCOMPUTING, V329, P329, DOI 10.1016/j.neucom.2018.10.070
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Ou J, 2019, NEUROCOMPUTING, V330, P253, DOI 10.1016/j.neucom.2018.11.028
   Ren MY, 2018, PROC CVPR IEEE, P8711, DOI 10.1109/CVPR.2018.00908
   Romero Adriana, 2015, ICLR 2015
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Singh S, 2016, P ADV NEUR INF PROC, V29
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava RK, 2015, ARXIV150500387
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taheri S, 2019, NEUROCOMPUTING, V329, P300, DOI 10.1016/j.neucom.2018.10.071
   Targ S., 2016, Resnet in Resnet: Generalizing Residual Architectures
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wang J., 2016, ARXIV 160507716
   Yang ML, 2019, NEUROCOMPUTING, V330, P48, DOI 10.1016/j.neucom.2018.10.075
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yoon J., 2017, P INT C MACHINE LEAR, P3958
   Yuan CH, 2019, NEUROCOMPUTING, V330, P127, DOI 10.1016/j.neucom.2018.11.010
   Zagoruyko S., 2016, BMVC, P1
   Zhang HY, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277958
   Zhang T., 2017, P IEEE INT C COMP VI
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhao Liming, 2016, ARXIV161107718
NR 51
TC 14
Z9 16
U1 4
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2019
VL 92
AR 103819
DI 10.1016/j.imavis.2019.10.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JW2JO
UT WOS:000502884200001
DA 2024-07-18
ER

PT J
AU Jaafra, Y
   Laurent, JL
   Deruyver, A
   Naceur, MS
AF Jaafra, Yesmina
   Laurent, Jean Luc
   Deruyver, Aline
   Naceur, Mohamed Saber
TI Reinforcement learning for neural architecture search: A review
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Reinforcement learning; Convolutional neural networks; Neural
   Architecture Search; AutoML
ID NETWORKS
AB Deep neural networks are efficient and flexible models that perform well for a variety of tasks such as image, speech recognition and natural language understanding. In particular, convolutional neural networks (CNN) generate a keen interest among researchers in computer vision and more specifically in classification tasks. CNN architecture and related hyperparameters are generally correlated to the nature of the processed task as the network extracts complex and relevant characteristics allowing the optimal convergence. Designing such architectures requires significant human expertise, substantial computation time and does not always lead to the optimal network. Reinforcement learning (RL) has been extensively used in automating CNN models design generating notable advances and interesting results in the field. This work aims at reviewing and discussing the recent progress of RL methods in Neural Architecture Search task and the current challenges that still require further consideration. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Jaafra, Yesmina; Deruyver, Aline] Univ Strasbourg, lCube Lab, 300 Bd Sebastien Brant, F-67412 Illkirch Graffenstaden, France.
   [Jaafra, Yesmina; Laurent, Jean Luc] Segula Technol, Parc Activite Pissaloup,8 Ave Jean dAlembert, F-78190 Trappes, France.
   [Jaafra, Yesmina; Naceur, Mohamed Saber] ENIT, LTSIRS Lab, Tunis 1002, Tunisia.
C3 Universites de Strasbourg Etablissements Associes; Universite de
   Strasbourg; Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs
   de Tunis (ENIT)
RP Jaafra, Y (corresponding author), Univ Strasbourg, lCube Lab, 300 Bd Sebastien Brant, F-67412 Illkirch Graffenstaden, France.; Jaafra, Y (corresponding author), Segula Technol, Parc Activite Pissaloup,8 Ave Jean dAlembert, F-78190 Trappes, France.; Jaafra, Y (corresponding author), ENIT, LTSIRS Lab, Tunis 1002, Tunisia.
EM yasminajaafra@etu.unistra.fr
OI Jaafra, Yesmina/0000-0002-2831-877X
CR [Anonymous], INT C LEARN REPR WOR
   [Anonymous], INT C LEARN REPR WOR
   [Anonymous], 1989, LEARNING DELAYED REW
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2015, ICLR
   [Anonymous], 2017, P INT C LEARN REPR I
   [Anonymous], P GEN EV COMP C
   [Anonymous], 2018, REINFORCEMENT LEARNI
   [Anonymous], 2015, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-26532-2_6
   [Anonymous], 2019, ICLR
   [Anonymous], 2018, INT C LEARN REPR ICL
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2010, P 2010 ACM SIGGRAPH
   [Anonymous], 2015, 3 INT C LEARN REPR I
   [Anonymous], 2007, A Brief Introduction on Neural Networks
   [Anonymous], ICML 2018 REPR MACH
   [Anonymous], 2013, P INT C LEARN REPR I
   [Anonymous], INTERNATIONAL CONFER
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Bender G, 2018, PR MACH LEARN RES, V80
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bergstra J., 2011, P 24 ADV NEUR INF PR
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cai H, 2018, P INT C MACH LEARN, P677
   Cai H, 2018, AAAI CONF ARTIF INTE, P2787
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Corrado G., 2012, P 25 INT C NEUR INF, P1223
   Domhan T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3460
   Eiben A., 2015, INTRO EVOLUTIONARY C, V2nd, DOI DOI 10.1007/978-3-662-44874-8
   Elsken T, 2019, J MACH LEARN RES, V20
   Floreano Dario., 2008, Neuroevolution: from architectures to learning
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinz T, 2018, INT J COMPUT INTELL, V17, DOI 10.1142/S1469026818500086
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Hutter F., 2018, INT C LEARNING REPRE
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Khan SG, 2012, ANNU REV CONTROL, V36, P42, DOI 10.1016/j.arcontrol.2012.03.004
   Klein A, 2017, PR MACH LEARN RES, V54, P528
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, NeurIPS, P396
   Levine S, 2016, J MACH LEARN RES, V17
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Minsky M., 1969, PERCEPTRONS INTRO CO
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nielsen MA., 2018, Neural Networks and Deep Learning
   Perez-Rua J, 2018, ARXIV180800391, P150
   Pham Hieu., 2018, ICML, V80, P4095, DOI [https://doi.org/10.48550/arXiv.1802.03268, DOI 10.48550/ARXIV.1802.03268]
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stanley KO, 2009, ARTIF LIFE, V15, P185, DOI 10.1162/artl.2009.15.2.15202
   Sutton R., 1998, Reinforcement Learning: An Introduction
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tan FX, 2017, LECT NOTES COMPUT SC, V10637, P475, DOI 10.1007/978-3-319-70093-9_50
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zoph Barret, 2017, INT C LEARNING REPRE
NR 64
TC 80
Z9 84
U1 7
U2 133
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 57
EP 66
DI 10.1016/j.imavis.2019.06.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900006
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Beksi, WJ
   Papanikolopoulos, N
AF Beksi, William J.
   Papanikolopoulos, Nikolaos
TI A topology-based descriptor for 3D point cloud modeling: Theory and
   experiments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Topological data analysis; Persistent homology; Shape analysis; Object
   classification
ID PERSISTENCE; RECOGNITION; FEATURES
AB This paper presents a topology-based global descriptor that allows for efficient 3D point cloud processing tasks associated with the analysis of shapes. The descriptor is called the Signature of Topologically Persistent Points (STPP). By using persistent homology, STPP is formed by the computation of topological invariants involving the zeroth and first homology groups. Persistent homology is a methodology that finds the features of a topological space at different spatial resolutions. STPP requires no preprocessing and uses a single tuning parameter. It is an effective 3D point cloud descriptor with robustness to noisy sensor data. The paper highlights this aspect with experimental comparisons to the state of the art. Our research has been validated on a publicly available RGB-D dataset. The results show that STPP can be used as a distinctive signature by employing a small number of features with object detection and classification benefiting from its usage. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Beksi, William J.] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA.
   [Papanikolopoulos, Nikolaos] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
C3 University of Texas System; University of Texas Arlington; University of
   Minnesota System; University of Minnesota Twin Cities
RP Papanikolopoulos, N (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
EM npapas@cs.umn.edu
RI Papanikolopoulos, Nikos/ITW-0029-2023
OI Papanikolopoulos, Nikos/0000-0002-2177-1870; Beksi,
   William/0000-0001-5377-2627
FU National Science Foundation [CNS-1338042, IIS-1427014, CNS-1439728,
   CNS-1531330, CNS-1544887]; University of Minnesota Informatics Institute
   (UMII)
FX This material is based upon work supported by the National Science
   Foundation through grants #CNS-1338042, #IIS-1427014, #CNS-1439728,
   #CNS-1531330 and #CNS-1544887. The authors acknowledge the Minnesota
   Supercomputing Institute at the University of Minnesota for providing
   software, computational, and storage resources that contributed to these
   research results. The University of Minnesota Informatics Institute
   (UMII) has partially supported the work of William Beksi.
CR Adcock A, 2014, COMPUT VIS IMAGE UND, V121, P36, DOI 10.1016/j.cviu.2013.10.014
   Aldoma Aitor, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P113, DOI 10.1007/978-3-642-32717-9_12
   Aldoma A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P585, DOI 10.1109/ICCVW.2011.6130296
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], IROS WORKSH ACT SEM
   Asaad A, 2017, LECT NOTES COMPUT SC, V10431, P136, DOI 10.1007/978-3-319-64185-0_11
   Beksi WJ, 2016, IEEE INT CONF ROBOT, P5046, DOI 10.1109/ICRA.2016.7487710
   Beksi WJ., 2016, IEEE RSJ INT C INT R
   Carlsson G., 2004, P 2004 EUR ACM SIGGR, P124
   Carlsson G, 2009, B AM MATH SOC, V46, P255, DOI 10.1090/S0273-0979-09-01249-X
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   DELFINADO CJA, 1995, COMPUT AIDED GEOM D, V12, P771, DOI 10.1016/0167-8396(95)00016-Y
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   Edelsbrunner H., 2010, American Mathematical Soc., DOI DOI 10.1090/MBK/069
   Fehr D, 2016, COMPUT VIS IMAGE UND, V142, P80, DOI 10.1016/j.cviu.2015.06.008
   Gamble J, 2010, J MULTIVARIATE ANAL, V101, P2184, DOI 10.1016/j.jmva.2010.04.016
   Gu C, 2014, LECT N BIOINFORMAT, V8701, P326, DOI 10.1007/978-3-662-44753-6_24
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Hatcher A., 2003, ALGEBRAIC TOPOLOGY
   Jimenez MJ, 2016, LECT NOTES COMPUT SC, V9667, P193, DOI 10.1007/978-3-319-39441-1_18
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Leon JL, 2014, LECT NOTES COMPUT SC, V8703, P40, DOI 10.1007/978-3-319-13323-2_4
   Lamar-Leon Javier, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P244, DOI 10.1007/978-3-642-33275-3_30
   Leon JavierLamar., 2013, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications, P366, DOI DOI 10.1007/978-3-642-41827-346
   Li CY, 2014, PROC CVPR IEEE, P2003, DOI 10.1109/CVPR.2014.257
   Marton Z.-C., 2010, IEEE RAS INT C HUM R, P365
   Marton ZC, 2010, IEEE INT C INT ROBOT, P3700, DOI 10.1109/IROS.2010.5650434
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Reininghaus J, 2015, PROC CVPR IEEE, P4741, DOI 10.1109/CVPR.2015.7299106
   Rusu Radu Bogdan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P47, DOI 10.1109/ICCVW.2009.5457718
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280
   Sedgewick R., 2011, Algorithm
   Singh N, 2014, LECT NOTES COMPUT SC, V8679, P231, DOI 10.1007/978-3-319-10581-9_29
   Skraba P., 2010, 2010 IEEE COMP SOC C, P45, DOI 10.1109/CVPRW.2010.5543285
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wohlkinger W., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2987, DOI 10.1109/ROBIO.2011.6181760
   Zaheer Manzil, 2017, P ADV NEURAL INFORM, P3391
   Zhou Z, 2017, PATTERN RECOGN LETT, V87, P177, DOI 10.1016/j.patrec.2016.04.002
NR 43
TC 12
Z9 13
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 84
EP 95
DI 10.1016/j.imavis.2019.05.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400009
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, LZ
   Yu, X
   Bourlai, T
   Metaxas, DN
AF Wang, Lezi
   Yu, Xiang
   Bourlai, Thirimachos
   Metaxas, Dimitris N.
TI A coupled encoder-decoder network for joint face detection and landmark
   localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Face detection; Landmark localization; Convolutional neural network;
   Deep learning
AB Face detection and landmark localization have been extensively investigated and are the prerequisite for many face related applications, such as face recognition and 3D face reconstruction. Most existing methods address only one of the two problems. In this paper, we propose a coupled encoder-decoder network to jointly detect faces and localize facial key points. The encoder and decoder generate response maps for facial landmark localization. Moreover, we observe that the intermediate feature maps from the encoder and decoder represent facial regions, which motivates us to build a unified framework for multi-scale cascaded face detection by coupling the feature maps. Experiments on face detection using two public benchmarks show improved results compared to the existing methods. They also demonstrate that face detection as a pre-processing step leads to increased robustness in face recognition. Finally, our experiments show that the landmark localization accuracy is consistently better than the state-of-the-art on three face-in-the-wild databases. (C) 2018 Published by Elsevier B.V.
C1 [Wang, Lezi; Metaxas, Dimitris N.] Rutgers State Univ, Piscataway, NJ 08854 USA.
   [Yu, Xiang] Media Analyt, NEC Labs Amer, Menlo Pk, CA USA.
   [Bourlai, Thirimachos] West Virginia Univ, MILab, LCSEE, Morgantown, WV 26506 USA.
C3 Rutgers University System; Rutgers University New Brunswick; NEC
   Corporation; West Virginia University
RP Wang, LZ (corresponding author), Rutgers State Univ, Piscataway, NJ 08854 USA.
EM lw462@cs.rutgers.edu
OI Bourlai, Thirimachos/0000-0001-8751-0836
FU U.S. Department of Homeland Security (OHS) [2015-ST-061-BSH001, AFOSR
   FA9550-15-1-0054, NSF-11733843, NSF-1703883, ARO-MURI-68985NSMUR]
FX This work is supported partially by the following grants: AFOSR
   FA9550-15-1-0054, NSF-11733843, NSF-1703883. and ARO-MURI-68985NSMUR to
   D. Metaxas, and a project to T. Bourlai and D. Metaxas from the U.S.
   Department of Homeland Security (OHS) under Grant Award
   #2015-ST-061-BSH001.
CR [Anonymous], 2010, UMCS2010009
   [Anonymous], 2015, ARXIV150608347
   [Anonymous], 2014, ECCV
   [Anonymous], IEEE INT C BIOM THEO
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], P 5 ACM INT C MULT
   [Anonymous], 2013, ICCVW
   [Anonymous], EUR C COMP VIS
   [Anonymous], INPROCEEDINGS EUR C
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], 2017, INT C COMP VIS
   [Anonymous], 2015, INTERSPEECH
   [Anonymous], 14 EUR C COMP VIS NE
   [Anonymous], P 24 IEEE C COMP VIS
   [Anonymous], 2014, CORR
   [Anonymous], 2014, CVPR
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], ARXIV14074023
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2015, P IEEE INT C COMP VI
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], 2015, P IEEE INT C COMP VI
   [Anonymous], 2010, INT C MACH LEARN ICM
   [Anonymous], 2016, CORR
   [Anonymous], 2016, ARXIV160402878
   [Anonymous], 2015, NEURAL INFORM PROCES
   [Anonymous], IEEE TRANSAC
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2014 IEEE C COMP VIS
   [Anonymous], 2 CROAT COMP VIS WOR
   [Anonymous], 2012, ECCV
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P145, DOI 10.1109/TSMCC.2009.2035631
   Ioffe S., 2015, INT C MACHINE LEARN, P448, DOI DOI 10.5555/3045118.3045167
   King DE, 2009, J MACH LEARN RES, V10, P1755
   LI HX, 2015, PROC CVPR IEEE, P5325, DOI DOI 10.1109/CVPR.2015.7299170
   Li Y, 2016, SIGNAL AND INFORMATION PROCESSING, NETWORKING AND COMPUTERS, P3
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Narang N, 2017, IEEE INT CONF AUTOMA, P186, DOI 10.1109/FG.2017.139
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Shen XH, 2013, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2013.444
   Shukla A, 2016, 2016 IEEE CONFERENCE ON ELECTROMAGNETIC FIELD COMPUTATION (CEFC)
   Simonyan K., 2014, CORR
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Trigeorgis G., 2016, CVPR
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang B, 2017, 2017 26TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN 2017)
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang B, 2015, IEEE IC COMP COM NET
   Yu X., 2014, ECCV
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 59
TC 12
Z9 12
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2019
VL 87
BP 37
EP 46
DI 10.1016/j.imavis.2018.09.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA IF3NV
UT WOS:000472988400004
DA 2024-07-18
ER

PT J
AU Li, DD
   Wen, GJ
   Kuai, YL
   Hui, BW
AF Li, Dongdong
   Wen, Gongjian
   Kuai, Yangliu
   Hui, Bingwei
TI LCO: Lightweight Convolution Operators for fast tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Correlation filter; Feature compression; Spatial constraints
ID OBJECT TRACKING
AB In recent years, Discriminative Correlation Filters (DCFs) based trackers have achieved continuous performance improvement due to sophisticated learning models (e.g. HCF [1]) or multiple feature integration (e.g. CCOT [2]). However, the increasingly complex model introduces a massive number of trainable parameters in the correlation filter. This significantly slows down the tracking speed and increases the risk of over fitting. In this work, we tackle the problems of model complexity and over-fitting by introducing Lightweight Convolution Operators (LCO). Our LCO tracker performs dimensionality reduction and spatial constraints on the correlation filters to reduce the model complexity and accelerate the tracking speed. Compared with the baseline method, LCO reduces over 90% of the redundant trainable parameters in the tracking model. We perform experiments on three benchmarks: OTB2013, OTB100 and VOT2016. On OTB100, LCO runs at 24 fps with hand-crafted features on CPU and at 30 fps with shallow convolutional features on CPU. With shallow convolutional features, LCO obtains 65.8% in AUC of the success plots on OTB100. On VOT2016, our tracker ranks second in Expected Average Overlap (EAO) and first in Equivalent Filter Operations (EFO) compared with the top 5 trackers. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Li, Dongdong; Wen, Gongjian; Kuai, Yangliu; Hui, Bingwei] Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Li, DD (corresponding author), Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
EM moqimubai@sina.cn
FU National Natural Science Foundation of China (NSFC) [41601487]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) (no. 41601487).
CR [Anonymous], 2016, IEEE T PATTERN ANAL
   [Anonymous], 2017, P IEEE C COMP VIS PA
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bibi A, 2016, LECT NOTES COMPUT SC, V9910, P419, DOI 10.1007/978-3-319-46466-4_25
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fuentes LM, 2006, IMAGE VISION COMPUT, V24, P1165, DOI 10.1016/j.imavis.2005.06.006
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Gundogdu E, 2016, IEEE IMAGE PROC, P1684, DOI 10.1109/ICIP.2016.7532645
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Kristan M, 2016, The Visual Object Tracking VOT2016 challenge results, P777
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Prisacariu VA, 2012, IMAGE VISION COMPUT, V30, P236, DOI 10.1016/j.imavis.2012.01.003
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu K, 2008, IMAGE VISION COMPUT, V26, P673, DOI 10.1016/j.imavis.2007.08.015
NR 30
TC 0
Z9 0
U1 0
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2018
VL 80
BP 92
EP 101
DI 10.1016/j.imavis.2018.10.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HF6VQ
UT WOS:000454376800006
DA 2024-07-18
ER

PT J
AU Wu, Y
   Liu, HF
   Li, J
   Fu, Y
AF Wu, Yue
   Liu, Hongfu
   Li, Jun
   Fu, Yun
TI Improving face representation learning with center invariant loss
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Convolutional Neural Network; Center invariant loss
ID RECOGNITION; NETWORK
AB In this paper, we address on the deep face representation learning with imbalanced data. With a large number of available face images of different people for training, Convolutional Neural Networks could learn deep face representation through classifying these people. However, uniformed distributed data for all people are hard to get. Some people come with more images but some come with less. In learning the deep face representation, the imbalanced images between people introduce the bias towards these people that have more images. Existing methods focus on the intra-class and inter-class variations but not well address the imbalanced data problem. To generate a robust and discriminative face representation for all people, we propose a center invariant loss which adds penalty to the differences between each center of classes. The center invariant loss could align the center of each person to the mean of all centers, which could force the deeply learned face features to have a good representation for all people with better generalization ability. Extensive experiments well demonstrate the effectiveness of the proposed approach. Many existing methods in learning deep face representation are further improved after adding the proposed center invariant loss. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Wu, Yue; Li, Jun; Fu, Yun] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
   [Liu, Hongfu] Brandeis Univ, Michtom Sch Comp Sci, Waltham, MA 02254 USA.
   [Fu, Yun] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.
C3 Northeastern University; Brandeis University; Northeastern University
RP Wu, Y (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
EM yuewu@ece.neu.edu
CR [Anonymous], ARXIV160602819
   [Anonymous], ARXIV170408063
   [Anonymous], 0749 U MASS AMB
   [Anonymous], ECCV
   [Anonymous], ARXIV151102683
   [Anonymous], ARXIV161108976
   [Anonymous], 2016, Proceedings of the 2016 ACM on Multimedia Conference
   [Anonymous], ARXIV14117923
   [Anonymous], INT C LEARN REPR
   [Anonymous], P IEEE C CVPR
   [Anonymous], IEEE T NEUR NET LEAR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], ARXIVI70705574
   [Anonymous], CONSENSUS STYLE CENT
   [Anonymous], ACM MM THEM WORKSH
   [Anonymous], ARXIV150707242
   [Anonymous], 2016, Proceedings of the 2016 ACM on Multimedia Conference
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Dong Y, 2015, COMPUT STAND INTER, V42, P105, DOI 10.1016/j.csi.2015.06.004
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Hu JL, 2017, IMAGE VISION COMPUT, V60, P48, DOI 10.1016/j.imavis.2016.08.007
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Huang WL, 2012, IMAGE VISION COMPUT, V30, P355, DOI 10.1016/j.imavis.2012.03.004
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang SH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P52, DOI 10.1145/2964284.2967182
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P1425, DOI 10.1109/TNNLS.2016.2541681
   Li J, 2015, AAAI CONF ARTIF INTE, P3804
   Li Ying., 2016, Proceedings of the 2016 ACM on Multimedia Conference, P132
   Liu WY, 2016, PR MACH LEARN RES, V48
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Sarvadevabhatla Ravi Kiran., 2016, Proceedings of the 2016 ACM on Multimedia Conference, P187
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2015, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2015.7298891
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Titsias Michalis, 2016, Advances in Neural Information Processing Systems, P4161
   Vonikakis V, 2016, IEEE IMAGE PROC, P3753, DOI 10.1109/ICIP.2016.7533061
   Wang YH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P307, DOI 10.1145/2964284.2967232
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Yamamoto Shohei., 2016, Proceedings of the 2016 ACM on Multimedia Conference, P576
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 47
TC 5
Z9 6
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 123
EP 132
DI 10.1016/j.imavis.2018.09.010
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800011
DA 2024-07-18
ER

PT J
AU Ng, CC
   Yap, MH
   Cheng, YT
   Hsu, GS
AF Ng, Choon-Ching
   Yap, Moi Hoon
   Cheng, Yi-Tseng
   Hsu, Gee-Sern
TI Hybrid Ageing Patterns for face age estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Age estimation; Wrinkle detection; Facial appearance model; Line
   tracking; Support vector regression
ID RECOGNITION; CLASSIFICATION; REGRESSION; KERNEL
AB Wrinkles can be embedded in several image-based applications as a descriptor for human skin. However, wrinkle-based age estimation research has not been widely addressed. In this paper, we introduce a Multi scale Wrinkle Patterns (MWP) representation, investigate the effect of wrinkles on face age estimation and propose Hybrid Ageing Patterns (HAP) for face age estimation. To define the wrinkle regions more precisely, a template consisting of 10 regions constructed relatively to a set of automatically located facial landmarks is used. We extract the multi-scale wrinkles in each region and encode them into MWP. We use Support Vector Regression to estimate age from the combination of such patterns. The performance of the algorithms is assessed by using Mean Absolute Error (MAE) on three state-of-the-art datasets-FG-NET, FERET and MORPH. We observe that MWP produces a comparable MAE of 4.16 on FERET to the state of the art. Finally we propose HAP, which combines the features from MWP and the facial appearance model (FAM), and demonstrate improved performance on FERET and MORPH with MAE of 3.02 (2.92) and 3.68 (2.98), respectively. Therefore, we conclude that MWP is an important complementary feature for face age estimation. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Ng, Choon-Ching; Yap, Moi Hoon] Manchester Metropolitan Univ, Chester St, Manchester M1 5GD, Lancs, England.
   [Cheng, Yi-Tseng; Hsu, Gee-Sern] Natl Taiwan Univ Sci & Technol, Taipei, Taiwan.
C3 Manchester Metropolitan University; National Taiwan University of
   Science & Technology
RP Yap, MH (corresponding author), Manchester Metropolitan Univ, Chester St, Manchester M1 5GD, Lancs, England.
EM moihoon@gmail.com
OI Hsu, Gee-Sern/0000-0003-2631-0448; Yap, Moi Hoon/0000-0001-7681-4287
FU Royal Society [IE141338]; Taiwan Ministry of Science and Technology
   [IE141338]
FX This work was supported by the joint fund of Royal Society (IE141338)
   and Taiwan Ministry of Science and Technology (awarded to Moi Hoon Yap
   and Gee-Sern Hsu). The authors would like to thanks Philips et al. [23],
   Ricanek and Tesafaye [24], and FGNET working group [21] for the FERET,
   MORPH and FGNET datasets. The authors gratefully thank Ylioinas et al.
   [27] and Batool et al. [49] for the implementation of KLBP and BLT. Last
   but not least, the authors would like to thank Prof. Timothy Cootes for
   his help in correcting FAM description; Dr. N. Costen and Dr. B. Li for
   proof read an early draft of the manuscript.
CR Albert Midori, 2011, Biometrics - Unique and Diverse Applications in Nature, Science, and Technology, P89
   [Anonymous], P 27 INT S COMP INF
   [Anonymous], 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on
   [Anonymous], 2010, Proc. MPVA
   [Anonymous], 2006, P 14 ANN ACM INT C M
   [Anonymous], 2013, ICB, DOI DOI 10.1109/ICB.2013.6613022
   [Anonymous], 2001, J Appl Sci Eng, DOI DOI 10.6180/JASE.2001.4.3.05
   Aznar-Casanova J, 2010, AGING NEUROPSYCHOL C, V17, P406, DOI 10.1080/13825580903420153
   Batool N., 2016, ADV FACE DETECTION F, P299
   Batool N, 2015, PATTERN RECOGN, V48, P642, DOI 10.1016/j.patcog.2014.08.003
   Batool N, 2014, IEEE T IMAGE PROCESS, V23, P3773, DOI 10.1109/TIP.2014.2332401
   Ben-Hur A, 2010, METHODS MOL BIOL, V609, P223, DOI 10.1007/978-1-60327-241-4_13
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Chao WL, 2013, PATTERN RECOGN, V46, P628, DOI 10.1016/j.patcog.2012.09.011
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cuixian Chen, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P200, DOI 10.1109/FG.2011.5771398
   Cula GO, 2013, SKIN RES TECHNOL, V19, pE243, DOI 10.1111/j.1600-0846.2012.00635.x
   Dibeklioglu H, 2015, IEEE T MULTIMEDIA, V17, P279, DOI 10.1109/TMM.2015.2394777
   Frangi A. F., 2001, THESIS U MED CTR UTR
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Fukai Hironobu, 2007, SICE '07. 46th SICE Annual Conference, P2808
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P145, DOI 10.1109/TSMCC.2009.2035631
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Huang YZ, 2010, IEEE T MULTIMEDIA, V12, P536, DOI 10.1109/TMM.2010.2052792
   Iga R, 2003, SICE 2003 ANNUAL CONFERENCE, VOLS 1-3, P756
   Jaccard P., 1901, B SOCIETE VAUDOISEDE, V37, P241
   Jana R, 2015, PROCEDIA COMPUT SCI, V46, P1754, DOI 10.1016/j.procs.2015.02.126
   Khavkin J, 2011, FACIAL PLAST SURG CL, V19, P229, DOI 10.1016/j.fsc.2011.04.003
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787
   Ling HB, 2010, IEEE T INF FOREN SEC, V5, P82, DOI 10.1109/TIFS.2009.2038751
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Ng C.-C., 2014, 12 AS C COMP VIS, P609
   Ng CC, 2015, IEEE SYS MAN CYBERN, P2418, DOI 10.1109/SMC.2015.423
   Ng CC, 2015, IEEE ACCESS, V3, P1079, DOI 10.1109/ACCESS.2015.2455871
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ramanathan N, 2009, J VISUAL LANG COMPUT, V20, P131, DOI 10.1016/j.jvlc.2009.01.011
   Real R., 1999, Miscellania Zoologica (Barcelona), V22, P29
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050
   Takimoto Hironori, 2006, 2006 SICE-ICASE International Joint Conference, P3883, DOI 10.1109/SICE.2006.314846
   Tsukahara K, 2000, J COSMET SCI, V51, P127
   Üstün B, 2006, CHEMOMETR INTELL LAB, V81, P29, DOI 10.1016/j.chemolab.2005.09.003
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   Ylioinas J, 2013, LECT NOTES COMPUT SC, V8156, P141
   Zhang GY, 2013, COMPUT BIOL CHEM, V46, P16, DOI 10.1016/j.compbiolchem.2013.05.001
   Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58
NR 56
TC 18
Z9 21
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 92
EP 102
DI 10.1016/j.imavis.2017.08.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100008
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Gehrig, S
   Schneider, N
   Stalder, R
   Franke, U
AF Gehrig, Stefan
   Schneider, Nicolai
   Stalder, Reto
   Franke, Uwe
TI Stereo vision during adverse weather - Using priors to increase
   robustness in real-time stereo vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo vision; Embedded computer vision; Autonomous driving; Mobile
   robotics
AB Stereo vision can deliver a dense 3D reconstruction of the environment in real-time for driver assistance as well as autonomous driving. Semi-Global Matching (SGM) is a popular method of choice for solving this task which is already in use for production vehicles. Despite the enormous progress in the field and the high level of performance of modern stereo methods, one key challenge remains: robust stereo vision in automotive scenarios during rain, snow and darkness. Under these circumstances, current methods generate strong temporal noise, many disparity outliers and false positives on object level. These problems are addressed in this work by regularizing stereo vision via prior information. We formulate a temporal prior and a scene prior, which we apply to SGM in order to overcome the deficiencies. The temporal prior integrates knowledge from the previous disparity map to exploit the high temporal correlation, the scene prior exploits knowledge of a representative traffic scene. Using these priors, the object detection rate improves significantly on a driver assistance dataset of 3000 frames including bad weather while reducing the rate of erroneous object detections. We also outperform the ECCV Robust Vision Challenge 2012 winner, iSGM, on this dataset. In addition, results are presented for the KITTI dataset, even showing improvements under good weather conditions when exploiting the temporal prior.
   We also show that the temporal and scene priors are easy and efficient to implement on a hybrid CPU/reconfigurable hardware platform. The use of these priors can be extended to other application areas such as mobile robotics. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Gehrig, Stefan; Schneider, Nicolai; Franke, Uwe] Daimler AG, HPC 050 G 024, D-71059 Sindelfingen, Germany.
   [Stalder, Reto] Supercomp Syst, Techno Pk Str 1, CH-8005 Zurich, Switzerland.
C3 Daimler AG
RP Gehrig, S (corresponding author), Daimler AG, HPC 050 G 024, D-71059 Sindelfingen, Germany.
EM stefan.gehrig@daimler.com
CR [Anonymous], 1990, Entropy and Information Theory
   [Anonymous], 2012, Are we ready for autonomous driving? the kitti vision benchmark suite
   Black M., 1991, IEEE COMPUTER SOC C, P292
   Boykov Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P377, DOI 10.1109/ICCV.1999.791245
   Davis J, 2005, IEEE T PATTERN ANAL, V27, P296, DOI 10.1109/TPAMI.2005.37
   Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z
   Drory A., 2014, SEMI GLOBAL MATCHING
   Franke U, 2005, LECT NOTES COMPUT SC, V3663, P216
   GALLUP D, 2007, INT C COMP VIS PATT
   Gehrig S., 2013, PRIORS STEREO VISION
   Gehrig S., 2014, EXPLOITING TRAFFIC S
   Gehrig SK, 2007, IEEE T INTELL TRANSP, V8, P233, DOI 10.1109/TITS.2006.888594
   Gehrig SK, 2015, LECT NOTES COMPUT SC, V9163, P69, DOI 10.1007/978-3-319-20904-3_7
   Gehrig SK, 2012, COMPUT VIS IMAGE UND, V116, P16, DOI 10.1016/j.cviu.2011.07.008
   Haller I., 2010, GPU OPTIMIZATION SGM
   Hegerath A., 2006, BMVC, P4
   Hermann S., 2012, ACCV
   Hirschmueller H., 2009, STEREO MATCHING PRES
   Hirschmüller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Huguet F., 2007, P INT C COMP VIS 07
   Koch M., 1998, EUR C COMP VIS
   Kofuji Kentaro, 2011, 2011 IEEE International Conference on Robotics and Automation, P5198
   Meister S., J OPT ENG, V51
   Mueller T., 2011, C COMP VIS PATT REC, P2011
   Mühlmann K, 2002, INT J COMPUT VISION, V47, P79, DOI 10.1023/A:1014581421794
   Nagel H.H., 1990, ECCV, P139
   Pfeiffer D., 2011, GLOBAL OPTIMAL MULTI
   Pfeiffer D., 2013, EXPLOITING POWER STE
   Pollefeys M., 2007, P INT C COMP VIS 07
   Rabe C, 2010, LECT NOTES COMPUT SC, V6314, P582, DOI 10.1007/978-3-642-15561-1_42
   Reichardt C., 2010, EUR C COMP VIS
   Scharstein D., 2013, MIDDLEBURY ONLINE ST
   Schumacher F., 2014, ITSC
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Soquet N., 2007, ROAD SEGMENTATION SU, VIV
   Stein F., 2004, EFFICIENT COMPUTATIO
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   Vogel C, 2015, INT J COMPUT VISION, V115, P1, DOI 10.1007/s11263-015-0806-0
   Wedel A., 2008, DAGST VIS MOT AN WOR
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
NR 41
TC 9
Z9 10
U1 0
U2 16
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2017
VL 68
SI SI
BP 28
EP 39
DI 10.1016/j.imavis.2017.07.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FR9UP
UT WOS:000419418900004
DA 2024-07-18
ER

PT J
AU Wong, D
   Deguchi, D
   Kawanishi, Y
   Ide, I
   Murase, H
AF Wong, David
   Deguchi, Daisuke
   Kawanishi, Yasutomo
   Ide, Ichiro
   Murase, Hiroshi
TI Regression of feature scale tracklets for decimeter visual localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ego-localization; Monocular vision; Feature scale
ID CAMERA; SLAM
AB Localization along a route is an everyday necessity for in-vehicle navigation systems, and a vital task for automated driving technologies. Visual ego-localization promises reliable accuracy even in challenging urban environments where Global Positioning Systems (GPSs) can fail. Using cameras for localization against a pre-constructed database requires either the creation of a dense three-dimensional feature point map and pose estimation of a query camera relative to this map, or image matching along a database route to determine the capture position of the query camera based on the most similar database image. While the latter method is potentially less computationally intensive and can provide a more compact database, localization accuracy is limited by the discrete positioning information at database frame capture locations. In this paper we propose an image matching method that makes use of image features which are pre matched during database construction, allowing linear regression coefficients for the relationship between capture position and feature scale to be calculated. The capture position of matched query features can then be estimated to sub-database spacing resolution. By incorporating the visual localization system into a Bayes estimator, we demonstrate an average monocular vision localization accuracy of 0.33 m in tests on actual vehicle image streams. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Wong, David; Kawanishi, Yasutomo; Ide, Ichiro; Murase, Hiroshi] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Deguchi, Daisuke] Nagoya Univ, Informat Strategy Off, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
C3 Nagoya University; Nagoya University
RP Wong, D (corresponding author), Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM davidw@murase.is.i.nagoya-u.ac.jp; ddeguchi@nagoya-u.jp;
   kawanishi@i.nagoya-u.ac.jp; ide@i.nagoya-u.ac.jp;
   murase@i.nagoya-u.ac.jp
RI Wong, David Sai Hung/C-4440-2009; Kawanishi, Yasutomo/AAF-9529-2019;
   Ide, Ichiro/M-4863-2014
OI Kawanishi, Yasutomo/0000-0002-3799-4550; Ide,
   Ichiro/0000-0003-3942-9296; Deguchi, Daisuke/0000-0003-0603-8790
FU MEXT [17H00745]; Grants-in-Aid for Scientific Research [17H00745]
   Funding Source: KAKEN
FX Parts of this research were supported by MEXT (17H00745), Grant-in-Aid
   for Scientific Research.
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2012, PROC 2012 ROBOTICS S
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Botterill T, 2011, J FIELD ROBOT, V28, P204, DOI 10.1002/rob.20368
   Bradski G, 2000, DR DOBBS J, V25, P120
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925
   Kyutoku H, 2011, MVA, P357
   Lategahn H, 2014, IEEE T INTELL TRANSP, V15, P1246, DOI 10.1109/TITS.2014.2298492
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lopez-Nicolas G., 2009, P IEEE INT C ROB AUT, P1098
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marchetti L., 2006, LECT NOTES COMPUTER, V4434, P442
   Mouragnon E, 2006, INT C PATT RECOG, P1027
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Muller M., 2007, INFORM RETRIEVAL MUS, P69, DOI DOI 10.1007/978-3-540-74048-34
   Qu XZ, 2015, IEEE INT VEH SYM, P605, DOI 10.1109/IVS.2015.7225751
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sibley G., 2010, INT J ROBOT RES, V34, P1688
   Uchiyama H, 2009, IEEE INT VEH SYM, P185, DOI 10.1109/IVS.2009.5164275
   Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463
   Wong D., 2015, Proceedings of the IEEE International Conference on Computer Vision Workshops, P1
   Wong D, 2017, IEICE T FUND ELECTR, VE100A, P702, DOI 10.1587/transfun.E100.A.702
   Wong D, 2015, LECT NOTES COMPUT SC, V8925, P167, DOI 10.1007/978-3-319-16178-5_11
   Xu DF, 2014, IEEE INT C INT ROBOT, P3448, DOI 10.1109/IROS.2014.6943043
NR 30
TC 2
Z9 2
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2017
VL 68
SI SI
BP 53
EP 63
DI 10.1016/j.imavis.2017.07.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FR9UP
UT WOS:000419418900006
DA 2024-07-18
ER

PT J
AU Brejcha, J
   Cadík, M
AF Brejcha, Jan
   Cadik, Martin
TI GeoPose3K: Mountain landscape dataset for camera pose estimation in
   outdoor environments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camera pose estimation; Visual geo-localization; Camera orientation
   estimation; Image-to-model registration; Digital terrain models;
   Semantic segmentation
ID MOBILE ROBOT
AB We introduce a new dataset called GeoPose3K(1) which contains over three thousand precise camera poses of mountain landscape images. In addition to camera location and orientation, we provide data for the training and evaluation of computer vision methods and applications in the context of outdoor scenes; synthetic depth maps, normal maps, illumination simulation and semantic labels. In order to illustrate properties of the dataset, we compare results achieved by state-of-the-art visual geo-localization method on GeoPose3K with results achieved on an existing dataset for visual geo-localization. So as to foster research of computer vision algorithms for outdoor environments, several novel future use-cases of our new GeoPose3K dataset are proposed. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Brejcha, Jan; Cadik, Martin] Brno Univ Technol, Fac Informat Technol, Ctr Excellence IT4Innovat, Brno, Czech Republic.
C3 Brno University of Technology
RP Brejcha, J (corresponding author), Brno Univ Technol, Fac Informat Technol, Ctr Excellence IT4Innovat, Brno, Czech Republic.
EM ibrejcha@fit.vutbr.cz
RI Cadik, Martin/O-4824-2014; Brejcha, Jan/AAQ-1024-2020
OI Cadik, Martin/0000-0001-7058-9912; Brejcha, Jan/0000-0002-2091-6185
FU Ministry of Education, Youth and Sports from the "National Programme of
   Sustainability (NPU II) project IT4Innovations excellence in science"
   [LQ1602]; IT4Innovations infrastructure from the Large Infrastructures
   for Research, Experimental Development and Innovations project
   "IT4Innovations National Supercomputing Center" [LM2015070]; SoMoPro II
   grant (EU 7 FP People Programme Marie Curie Actions) [REA 291782];
   SoMoPro II grant (South Moravian Region); TACR Competence Centres
   project V3C - Visual Computing Competence Center [TE01020415]
FX This work was supported by The Ministry of Education, Youth and Sports
   from the "National Programme of Sustainability (NPU II) project
   IT4Innovations excellence in science - LQ1602" and by the IT4Innovations
   infrastructure which is supported from the Large Infrastructures for
   Research, Experimental Development and Innovations project
   "IT4Innovations National Supercomputing Center - LM2015070".; This work
   was supported by SoMoPro II grant (financial contribution from the EU 7
   FP People Programme Marie Curie Actions, REA 291782, and from the South
   Moravian Region).; This work was supported by the TACR Competence
   Centres project V3C - Visual Computing Competence Center (no.
   TE01020415).
CR [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], ACM T GRAPH
   [Anonymous], P 17 ACM INT C MULT
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], 2015, PROC CVPR WORKSHOP V
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2004, P BRIT MACH C
   [Anonymous], P 2013 IEEE INT C CO
   [Anonymous], P INT C DISTR SMART
   [Anonymous], 2010, P IEEE INT C COMP VI
   [Anonymous], 14 IEEE INT C MACH L
   Arandjelovic R., 2016, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2711011
   Baatz G, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P487, DOI 10.1109/3DIMPVT.2012.33
   Baatz G, 2012, LECT NOTES COMPUT SC, V7573, P517, DOI 10.1007/978-3-642-33709-3_37
   Baboud L, 2011, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2011.5995727
   Bae S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805968
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Chen Y, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1587
   Epshtein Boris., 2007, Proceedings of the ACM International Symposium on Advances in Geographic Information Systems (ACM GIS), P1
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Hammoud RI, 2013, IEEE COMPUT SOC CONF, P320, DOI 10.1109/CVPRW.2013.55
   Hays J, 2008, PROC CVPR IEEE, P3436
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hsieh C.-C., 2008, ACM International Conference on Multimedia (MM), P419
   Ji RR, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2597181
   Johns E, 2011, IEEE I CONF COMP VIS, P874, DOI 10.1109/ICCV.2011.6126328
   Jr P.C. N., 1997, 38th_Research_Meeting_of_the_Pattern _Sensing_Group,_Society_of_Instrument_and_Control_Engineers, P9
   Kendall A, 2016, IEEE INT CONF ROBOT, P4762, DOI 10.1109/ICRA.2016.7487679
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Lalonde JF, 2010, INT J COMPUT VISION, V88, P24, DOI 10.1007/s11263-009-0291-4
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Naval P. C.  Jr., 1998, SIRS '98. Proceedings of the 6th International Symposium on Intelligent Robotic Systems, P157
   Ruzon M. A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P160, DOI 10.1109/CVPR.1999.784624
   Saxena A., 2006, NIPS, P1161, DOI DOI 10.1109/TPAMI.2015.2505283A
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Schindler G., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   STEIN F, 1995, IEEE T ROBOTIC AUTOM, V11, P892, DOI 10.1109/70.478436
   TALLURI R, 1992, IEEE T ROBOTIC AUTOM, V8, P573, DOI 10.1109/70.163782
   TALLURI R, 1993, IEEE T PATTERN ANAL, V15, P597, DOI 10.1109/34.216729
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Tzeng E, 2013, IEEE COMPUT SOC CONF, P237, DOI 10.1109/CVPRW.2013.42
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3
   Zamir AR, 2014, PROC CVPR IEEE, P4280, DOI 10.1109/CVPR.2014.545
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799
   Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80
NR 54
TC 12
Z9 14
U1 3
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2017
VL 66
BP 1
EP 14
DI 10.1016/j.imavis.2017.05.009
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FJ9AO
UT WOS:000413060000001
DA 2024-07-18
ER

PT J
AU Soleymani, M
   Garcia, D
   Jou, B
   Schuller, B
   Chang, SF
   Pantic, M
AF Soleymani, Mohammad
   Garcia, David
   Jou, Brendan
   Schuller, Bjoern
   Chang, Shih-Fu
   Pantic, Maja
TI A survey of multimodal sentiment analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sentiment; Affect; Sentiment analysis; Human behavior analysis; Computer
   vision; Affective computing
ID EMOTIONS; AUDIO; NORMS
AB Sentiment analysis aims to automatically uncover the underlying attitude that we hold towards an entity. The aggregation of these sentiments over a population represents opinion polling and has numerous applications. Current text-based sentiment analysis relies on the construction of dictionaries and machine learning models that learn sentiment from large text corpora. Sentiment analysis from text is currently widely used for customer satisfaction assessment and brand perception analysis, among others. With the proliferation of social media, multimodal sentiment analysis is set to bring new opportunities with the arrival of complementary data streams for improving and going beyond text-based sentiment analysis. Since sentiment can be detected through affective traces it leaves, such as facial and vocal displays, multimodal sentiment analysis offers promising avenues for analyzing facial and vocal expressions in addition to the transcript or textual content. These approaches leverage emotion recognition and context inference to determine the underlying polarity and scope of an individual's sentiment. In this survey, we define sentiment and the problem of multimodal sentiment analysis and review recent developments in multimodal sentiment analysis in different domains, including spoken reviews, images, video blogs, human machine and human human interactions. Challenges and opportunities of this emerging field are also discussed, leading to our thesis that multimodal sentiment analysis holds a significant untapped potential. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Soleymani, Mohammad; Schuller, Bjoern] Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
   [Garcia, David] Swiss Fed Inst Technol, Chair Syst Design, Zurich, Switzerland.
   [Jou, Brendan; Chang, Shih-Fu] Columbia Univ, Elect Engn Dept, New York, NY USA.
   [Chang, Shih-Fu] Columbia Univ, Comp Sci Dept, New York, NY USA.
   [Chang, Shih-Fu] Univ Passau, Chair Complex & Intelligent Syst, Passau, Germany.
   [Schuller, Bjoern; Pantic, Maja] Imperial Coll London, Dept Comp, London, England.
   [Pantic, Maja] Univ Twente, EEMCS, Human Media Interact, Enschede, Netherlands.
   [Jou, Brendan] Google Inc, Mountain View, CA USA.
C3 University of Geneva; Swiss Federal Institutes of Technology Domain; ETH
   Zurich; Columbia University; Columbia University; University of Passau;
   Imperial College London; University of Twente; Google Incorporated
RP Soleymani, M (corresponding author), Univ Geneva, Swiss Ctr Affect Sci, Geneva, Switzerland.
EM mohammad.soleymani@unige.ch; dgarcia@ethz.ch; bjou@caa.columbia.edu;
   bjoern.schuller@imperial.ac.uk; shih.fu.chang@columbia.edu;
   m.pantic@imperial.ac.uk
RI Soleymani, Mohammad/AAS-2161-2020; Schuller, Björn Wolfgang/D-3241-2011;
   Garcia, David/A-2113-2014
OI Soleymani, Mohammad/0000-0003-2770-7236; Schuller, Björn
   Wolfgang/0000-0002-6478-8699; Garcia, David/0000-0002-2820-9151
FU Swiss National Science Foundation; European Community Horizon [645094]
FX The work of Soleymani is supported by his Ambizione grant from the Swiss
   National Science Foundation. The work of Pantic and Schuller is
   partially supported by the European Community Horizon 2020
   [H2020/2014-2020] under grant agreement no. 645094 (SEWA). We would like
   to thank Julien Deonna and Cristina Soriano for invaluable discussions
   on the definition of sentiment.
CR Abbasi A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P823
   [Anonymous], ACM INT WORKSH ISS S
   [Anonymous], IEEE INT C SYST MAN
   [Anonymous], INT WORKSH SEM EV SE
   [Anonymous], ARXIV160403489
   [Anonymous], 2015, ADV MECH ENG
   [Anonymous], 2014, P 16 INT C MULT INT
   [Anonymous], EMOTION SYCHOEVOLUTI
   [Anonymous], C ASS ADV ART INT AA
   [Anonymous], ARXIV151106838
   [Anonymous], 2012, The Emotions, DOI DOI 10.4324/9780203721742
   [Anonymous], 2014, P 8 INT WORKSH SEM E
   [Anonymous], 1997, TECH REP
   [Anonymous], 1998, P IEEE
   [Anonymous], 2016, P 10 INT WORKSH SEM
   [Anonymous], 2015, Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)
   [Anonymous], ACM INT C MULT
   [Anonymous], ACM INT C MULT MM
   [Anonymous], 1999, TECH REP
   [Anonymous], ACM INT C INT US INT
   [Anonymous], 2014, P 8 INT WORKSH SEM E
   [Anonymous], C ASS ADV ART INT AA
   [Anonymous], TEXT ANAL SOCIAL SCI
   [Anonymous], KNOWL BASED IN PRESS
   [Anonymous], 2014, Eighth Int. AAAI Conf. Weblogs Soc. Media
   [Anonymous], 2012, DATA CENTRIC SYST AP, DOI DOI 10.1007/978-3-031-02145-9
   [Anonymous], 2012, P 8 INT C LANG RES E
   [Anonymous], DATA SCI POPUP AUSTI
   [Anonymous], 2015, P 1 INT WORKSH AFF S, DOI 10.1145/2813524.2813530
   [Anonymous], ANN C NEUR INF PROC
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], 2011, P 13 INT C MULT INT
   [Anonymous], 2011, J COMPUT SCI-NETH, DOI DOI 10.1016/j.jocs.2010.12.007
   [Anonymous], DIRECTION BASED TEXT
   [Anonymous], ACM INT C MULT MM
   [Anonymous], THESIS
   [Anonymous], ARXIV151201818
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], TECH REP
   [Anonymous], ACM INT C MULT MM
   [Anonymous], C HUM LANG TECHN HLT
   [Anonymous], 2014, 15 ANN C INT SPEECH
   [Anonymous], ASS COMPUTATIONAL LI
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], C COMP LING
   [Anonymous], C ASS ADV ART INT AA
   [Anonymous], 2015, IEEE T AFFECTIVE COM
   [Anonymous], 2003, P 12 INT C WORLD WID, DOI DOI 10.1145/775152.775226
   [Anonymous], 2004, 20 INT C COMP LING G
   [Anonymous], ACM INT C MULT MM
   [Anonymous], ARXIV160503757
   [Anonymous], ACM WEB SCI C
   [Anonymous], 2013, P 7 INT WORKSH SEM E
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], 2015, ACM COMPUT SURV, DOI DOI 10.1145/2682899
   [Anonymous], 2012, ACM SIGHIT Record
   [Anonymous], 2010, LREC 10
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/d15-1303, 10.18653/v1/D15-1303]
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], 2013, P 2013 C EMP METH NA
   Asur S., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P492, DOI 10.1109/WI-IAT.2010.63
   Belagiannis V., 2016, CoRR
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Bousmalis K, 2015, IEEE T PATTERN ANAL, V37, P1917, DOI 10.1109/TPAMI.2014.2388228
   Bousmalis K, 2013, IMAGE VISION COMPUT, V31, P203, DOI 10.1016/j.imavis.2012.07.003
   Bousmalis K, 2013, IEEE T NEUR NET LEAR, V24, P170, DOI 10.1109/TNNLS.2012.2224882
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Cambria E, 2010, LECT NOTES COMPUT SC, V5967, P148
   Chen T., 2014, DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks
   Chen YY, 2015, IEEE T AFFECT COMPUT, V6, P298, DOI 10.1109/TAFFC.2014.2388370
   Costa Pereira Jose, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4583, DOI 10.1109/ICASSP.2014.6854470
   Das S.R., 2001, Yahoo! for Amazon: Sentiment parsing from small talk on the web
   Dellaert F, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1970, DOI 10.1109/ICSLP.1996.608022
   Deriu J, 2016, P 10 INT WORKSH SEM, P1124, DOI DOI 10.18653/V1/S16-1173
   Deriu J, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1045, DOI 10.1145/3038912.3052611
   Dodds PS, 2015, P NATL ACAD SCI USA, V112, P2389, DOI 10.1073/pnas.1411678112
   Dodds PS, 2010, J HAPPINESS STUD, V11, P441, DOI 10.1007/s10902-009-9150-9
   Eyben F., 2009, 3 INT C AFF COMP INT, P1, DOI DOI 10.1109/ACII.2009.5349350
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4647, DOI 10.1145/2858036.2858535
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Hassan A, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P357, DOI 10.1109/SocialCom.2013.56
   Hatzivassiloglou V, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P174, DOI 10.3115/976909.979640
   Irsoy O., 2014, P 2014 C EMP METH NA, P720, DOI 10.3115/v1/D14-1080
   Jansen BJ, 2009, J AM SOC INF SCI TEC, V60, P2169, DOI 10.1002/asi.21149
   Jou B, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P159, DOI 10.1145/2733373.2806246
   Jou B, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P389, DOI 10.1145/2911996.2912022
   Jou B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P213, DOI 10.1145/2647868.2656408
   Kaltwang S, 2016, IEEE T PATTERN ANAL, V38, P1748, DOI 10.1109/TPAMI.2015.2501824
   Kaushik L, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P239, DOI 10.1109/ASRU.2013.6707736
   Kaushik L, 2013, INT CONF ACOUST SPEE, P8485, DOI 10.1109/ICASSP.2013.6639321
   Khosla A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P867, DOI 10.1145/2566486.2567996
   Krizhevsky A., 2012, ANN C NEURAL INFORM
   Langlet C, 2015, INT CONF AFFECT, P14, DOI 10.1109/ACII.2015.7344545
   Larson M, 2012, IEEE MULTIMEDIA, V19, P15, DOI 10.1109/MMUL.2012.27
   Liu HY, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P417, DOI 10.1145/2911996.2912030
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Mairesse F, 2012, INT CONF ACOUST SPEE, P5093, DOI 10.1109/ICASSP.2012.6289066
   Mandera P, 2015, Q J EXP PSYCHOL, V68, P1623, DOI 10.1080/17470218.2014.988735
   McDuff Daniel, 2015, IEEE Transactions on Affective Computing, V6, P223, DOI 10.1109/TAFFC.2014.2384198
   Mcduff D, 2013, INT CONF AFFECT, P369, DOI 10.1109/ACII.2013.67
   Melville P, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1275
   Metze F, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P478
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Morrison D, 2014, LECT NOTES ARTIF INT, V8643, P572, DOI 10.1007/978-3-319-13186-3_51
   Mozetic I, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155036
   Munezero M, 2014, IEEE T AFFECT COMPUT, V5, P101, DOI 10.1109/TAFFC.2014.2317187
   Nicolaou MA, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853852
   Panagakis Y, 2016, IEEE T PATTERN ANAL, V38, P1665, DOI 10.1109/TPAMI.2015.2497700
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pappas N, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P151, DOI 10.1145/2911996.2912016
   Pennebaker J.W., 2015, LIWC 2015 operators manual, DOI DOI 10.15781/T29G6Z
   Pérez-Rosas V, 2013, INTERSPEECH, P862
   Polanyi L, 2006, INFORM RETRIEVAL SER, V20, P1
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redondo J, 2007, BEHAV RES METHODS, V39, P600, DOI 10.3758/BF03193031
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Roseman I.J., 2001, Appraisal processes in emotion: Theory, method, research, P3
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SACK W, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1488
   Sander D, 2005, NEURAL NETWORKS, V18, P317, DOI 10.1016/j.neunet.2005.03.001
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Schuller B, 2011, SPEECH COMMUN, V53, P1062, DOI 10.1016/j.specom.2011.01.011
   Siddiquie B, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P203, DOI 10.1145/2818346.2820732
   Stone P. J., 1966, GEN INQUIRER COMPUTE
   Subasic P, 2001, IEEE T FUZZY SYST, V9, P483, DOI 10.1109/91.940962
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Tumasjan A, 2010, 4 INT AAAI C WEBL SO, V10, P178, DOI 10.1074/jbc.M501708200
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Vo MLH, 2009, BEHAV RES METHODS, V41, P534, DOI 10.3758/BRM.41.2.534
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   Wiebe J. M., 1999, Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, P246, DOI [DOI 10.3115/1034678.1034721, 10.3115/1034678.1034721]
   Wöllmer M, 2013, IEEE INTELL SYST, V28, P46, DOI 10.1109/MIS.2013.34
   Wöllmer M, 2013, IMAGE VISION COMPUT, V31, P153, DOI 10.1016/j.imavis.2012.03.001
   Yatani K., 2011, IJCAI, V22, P2771
   Yu X, 2014, ABSTR APPL ANAL, DOI 10.1155/2014/643640
   Zadeh A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P587, DOI 10.1145/2818346.2823317
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 149
TC 266
Z9 284
U1 35
U2 285
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2017
VL 65
SI SI
BP 3
EP 14
DI 10.1016/j.imavis.2017.08.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA FJ3GM
UT WOS:000412618500002
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Biris, O
   Ulusoy, AO
   Mundy, JL
AF Biris, Octavian
   Ulusoy, Ali O.
   Mundy, Joseph L.
TI Compression of Probabilistic Volumetric Models using multi-resolution
   scene flow
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optical flow; PVM; Compression; 3-d; Segmentation; Coarse-to-fine; Scene
   flow; Korn and Schunck; GPU
ID VISIBILITY; TRACKING; STEREO
AB This paper presents a novel method to estimate dense scene flow using volumetric and probabilistic 3-d models. The method first reconstructs 3-d models at each time step using images synchronously captured from multiple views. Then, the 3-d motion between two consecutive 3-d models is estimated using a formulation that is the analog of Horn and Schunck's optical flow method. This particular choice of 3-d model representation allows estimating highly dense scene flow results, tracking of surfaces undergoing topological change and reliably recovering large motion displacements. The benefits of the method and the accuracy of 3-d flow results are demonstrated on recent multi-view datasets. The second goal of this work is to compress and reconstruct 3-d scenes at various time points using the estimated flow. A new method of scene warping is proposed that involves partitioning the optical flow field in regions of coherent motion which are subsequently parametrized by affine transformations. The compression objective of this work is achieved by the low storage requirements of the affine parameters that describe the optical flow field and the efficient reconstruction method through warping. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Biris, Octavian; Mundy, Joseph L.] Brown Univ, Sch Engn, Providence, RI 02912 USA.
   [Ulusoy, Ali O.] Max Planck Inst Intelligent Syst, Perceiving Syst, Tubingen, Germany.
C3 Brown University; Max Planck Society
RP Biris, O (corresponding author), Brown Univ, Sch Engn, Providence, RI 02912 USA.
EM octavian_biris@brown.edu; osman.ulusoy@tuebingeh.mpg.de;
   mundy@lems.brown.edu
CR [Anonymous], 1950ZLIB RFC
   [Anonymous], IEEE T GEOSCIENCE RE
   [Anonymous], LECT NOTES COMPUTE 4
   [Anonymous], 3D IMAGING MODELING
   [Anonymous], CHANGE DETECTION 3D
   [Anonymous], BMVC
   [Anonymous], THESIS
   [Anonymous], 2013, ICCV WORKSH DYN SHAP
   [Anonymous], DENSE SEMI RIGID SCE
   [Anonymous], APPL MECH REV
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Basha T, 2012, PROC CVPR IEEE, P1426, DOI 10.1109/CVPR.2012.6247830
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bojsen-Hansen M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185549
   Cagniart C, 2010, LECT NOTES COMPUT SC, V6314, P326, DOI 10.1007/978-3-642-15561-1_24
   Carceroni RL, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P60
   Cremers D, 2011, IEEE T PATTERN ANAL, V33, P1161, DOI 10.1109/TPAMI.2010.174
   De Aguiar E., 2007, Computer Vision and Pattern Recognition, 2007, P1, DOI DOI 10.1109/CVPR.2007.383296
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Furukawa Y., 2008, CVPR
   Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755
   Glocker B, 2011, ANNU REV BIOMED ENG, V13, P219, DOI 10.1146/annurev-bioeng-071910-124649
   Guan L, 2010, PROC CVPR IEEE, P1379, DOI 10.1109/CVPR.2010.5539807
   Hadfield S, 2014, IEEE T PATTERN ANAL, V36, P564, DOI 10.1109/TPAMI.2013.162
   Hadfield S, 2011, IEEE I CONF COMP VIS, P2290, DOI 10.1109/ICCV.2011.6126509
   Herbst E, 2013, IEEE INT CONF ROBOT, P2276, DOI 10.1109/ICRA.2013.6630885
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hornácek M, 2014, PROC CVPR IEEE, P3526, DOI 10.1109/CVPR.2014.451
   Huguet F, 2007, IEEE I CONF COMP VIS, P1342, DOI 10.1109/iccv.2007.4409000
   Joo H, 2014, PROC CVPR IEEE, P1122, DOI 10.1109/CVPR.2014.147
   Miller A., 2011, REAL TIME RENDERING, DOI [10.1145/1964179.1964190, DOI 10.1145/1964179.1964190]
   Restrepo MI, 2012, IEEE J-STSP, V6, P522, DOI 10.1109/JSTSP.2012.2201693
   Sizintsev M, 2014, IEEE T PATTERN ANAL, V36, P2241, DOI 10.1109/TPAMI.2014.2321373
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Ulusoy AliOsman., 2013, ICCV
   Varanasi K, 2008, LECT NOTES COMPUT SC, V5303, P30, DOI 10.1007/978-3-540-88688-4_3
   Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293
   Vogel C, 2013, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2013.174
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zollhöfer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601165
NR 41
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2017
VL 64
BP 79
EP 89
DI 10.1016/j.imavis.2017.06.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FH0ZW
UT WOS:000410870200007
DA 2024-07-18
ER

PT J
AU Zhang, WC
   Liu, ZG
   Zhou, LY
   Leung, H
   Chan, AB
AF Zhang, Weichen
   Liu, Zhiguang
   Zhou, Liuyang
   Leung, Howard
   Chan, Antoni B.
TI Martial Arts, Dancing and Sports dataset: A challenging stereo and
   multi-view dataset for 3D human pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human pose estimation; Robust tracking; Evaluation; Martial arts;
   Dancing and sports
ID HUMAN MOTION; TRACKING; RECOGNITION; ACCURATE; MODEL
AB Human pose estimation is one of the most popular research topics in the past two decades, especially with the introduction of human pose datasets for benchmark evaluation. These datasets usually capture simple daily life actions. Here, we introduce a new dataset, the Martial Arts, Dancing and Sports (MADS), which consists of challenging martial arts actions (Tai-chi and Karate), dancing actions (hip-hop and jazz), and sports actions (basketball, volleyball, football, rugby, tennis and badminton). Two martial art masters, two dancers and an athlete performed these actions while being recorded with either multiple cameras or a stereo depth camera. In the multi-view or single-view setting, we provide three color views for 2D image-based human pose estimation algorithms. For depth-based human pose estimation, we provide stereo-based depth images from a single view. All videos have corresponding synchronized and calibrated ground-truth poses, which were captured using a Motion Capture system. We provide initial baseline results on our dataset using a variety of tracking frameworks, including a generative tracker based on the annealing particle filter and robust likelihood function, a discriminative tracker using twin Gaussian processes [1], and hybrid trackers, such as Personalized Depth Tracker [2]. The results of our evaluation suggest that discriminative approaches perform better than generative approaches when there are enough representative training samples, and that the generative methods are more robust to diversity of poses, but can fail to track when the motion is too quick for the effective search range of the particle filter. The data and the accompanying code will be made available to the research community. (C) 2017 Elsevier B.V. All rights reserved.
EM wczhang4-c@my.cityu.edu.hk
RI CHAN, Antoni B./D-7858-2013
OI CHAN, Antoni B./0000-0002-2886-2513
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [CityU 123212]
FX We thank L Sigal, AO Balan and MI Black for providing the HumanEva
   baseline protocol. We thank L Bo and C Sminchisescu for their TGP code.
   We also thank Mao Ye from University of Kentucky for running his
   GMM-based algorithm on our Tai-chi depth data, Thomas Helten from MPI
   (now in Pixargus) for running his PDT tracker on our Tai-chi depth data,
   and Vasileios Belagiannis from TUM for running his 3DPS tracker on our
   multi-view data. We also thank Sensei Alan Lai and Ueshiro Karate Hong
   Kong for helping with the data collection. This work was supported by
   the Research Grants Council of the Hong Kong Special Administrative
   Region, China (CityU 123212).
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 10 INT C COMP GRAPH
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2012, PROC CVPR IEEE
   [Anonymous], 3 D VIS TOOLB
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2010, INT J COMPUT VISION, DOI DOI 10.1007/s11263-008-0204-y
   [Anonymous], 2014, P INT C CYB TECHN CC
   Baak A., 2013, Consumer Depth Camerasfor Computer Vision: Research Topics and Applications, P71, DOI DOI 10.1007/978-1-4471-4640-7_5
   Bandouch J, 2012, INT J COMPUT VISION, V99, P166, DOI 10.1007/s11263-012-0522-y
   Belagiannis V., 2016, CoRR
   Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Bouguet J.-Y., 2013, CAMERA CALIBRATION T
   Bregler C, 2004, INT J COMPUT VISION, V56, P179, DOI 10.1023/B:VISI.0000011203.00237.9b
   Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464
   Corazza S, 2010, INT J COMPUT VISION, V87, P156, DOI 10.1007/s11263-009-0284-3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Droeschel D, 2011, LECT NOTES ARTIF INT, V7102, P157, DOI 10.1007/978-3-642-25489-5_16
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Gall J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1969, DOI 10.1109/CVPR.2011.5995582
   Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1
   Ganapathi V, 2012, LECT NOTES COMPUT SC, V7577, P738, DOI 10.1007/978-3-642-33783-3_53
   Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141
   Gkalelis N, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P159, DOI 10.1109/CVMP.2009.19
   Helten T, 2013, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2013.141
   Helten T, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P279, DOI 10.1109/3DV.2013.44
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   HORPRASERT T, 2000, P ACCV, P983
   Huang CH, 2014, PROC CVPR IEEE, P3446, DOI 10.1109/CVPR.2014.440
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Ionescu C, 2011, IEEE I CONF COMP VIS, P2220, DOI 10.1109/ICCV.2011.6126500
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   John V, 2010, IMAGE VISION COMPUT, V28, P1530, DOI 10.1016/j.imavis.2010.03.008
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Knoop S, 2009, ROBOT AUTON SYST, V57, P321, DOI 10.1016/j.robot.2008.10.017
   Lallemand J, 2014, LECT NOTES COMPUT SC, V8563, P10, DOI 10.1007/978-3-319-08849-5_2
   Lawrence N, 2005, J MACH LEARN RES, V6, P1783
   Li SF, 2015, APPL LINGUIST, V36, P385, DOI 10.1093/applin/amu054
   Li SJ, 2015, INT J COMPUT VISION, V113, P19, DOI 10.1007/s11263-014-0767-8
   Menier C, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P389
   Moeslund ThomasB., 2011, Visual analysis of humans
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Pellegrini S., 2008, BRIT MACHINE VISION, P4
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Qian C., 2014, PROC CVPR IEEE, P1106, DOI DOI 10.1109/CVPR.2014.145
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Sigal L, 2012, INT J COMPUT VISION, V98, P15, DOI 10.1007/s11263-011-0493-4
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003
   Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157
   Toshev A., 2014, IEEE C COMPUTER VISI, P1
   Tung T, 2012, IEEE T PATTERN ANAL, V34, P1645, DOI 10.1109/TPAMI.2011.258
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wang P., 2006, CVPR06, P790
   Wei XL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366207
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
   Zhang WC, 2014, IEEE T IMAGE PROCESS, V23, P5374, DOI 10.1109/TIP.2014.2364113
   Zhu YD, 2010, COMPUT VIS IMAGE UND, V114, P1362, DOI 10.1016/j.cviu.2009.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 66
TC 46
Z9 50
U1 7
U2 60
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2017
VL 61
BP 22
EP 39
DI 10.1016/j.imavis.2017.02.002
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EU7HK
UT WOS:000401205700003
DA 2024-07-18
ER

PT J
AU Jammalamadaka, N
   Zisserman, A
   Jawahar, CV
AF Jammalamadaka, Nataraj
   Zisserman, Andrew
   Jawahar, C. V.
TI Human pose search using deep networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pose retrieval; Pose estimation; Video and image retrieval; Deep
   networks
AB Human pose as a query modality is an alternative and rich experience for image and video retrieval. It has interesting retrieval applications in domains such as sports and dance databases. In this work we propose two novel ways for representing the image of a person striking a pose, one looking for parts and other looking at the whole image. These representations are then used for retrieval. Both the representations are obtained using deep learning methods.
   In the first method, we make the following contributions: (a) We introduce 'deep poselets' for pose sensitive detection of various body parts, built on convolutional neural network (CNN) features. These deep poselets significantly outperform previous instantiations of Berkeley poselets [6], and (b) Using these detector responses, we construct a pose representation that is suitable for pose search, and show that pose retrieval performance is on par with the previous methods. In the second method, we make the following contributions: (a) We design an optimized neural network which maps the input image to a very low dimensional space where similar poses are close by and dissimilar poses are farther away, and (b) We show that pose retrieval system using these low dimensional representation is on par with the deep poselet representation and is on par with the previous methods.
   The previous works with which the above two methods are compared include bag of visual words [44], Berkeley poselets [6] and human pose estimation algorithms [52]. All the methods are quantitatively evaluated on a large dataset of images built from a number of standard benchmarks together with frames from Hollywood movies. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Jammalamadaka, Nataraj; Jawahar, C. V.] IIIT, CVIT, Hyderabad, Andhra Pradesh, India.
   [Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Oxford, England.
C3 International Institute of Information Technology Hyderabad; University
   of Oxford
RP Jammalamadaka, N (corresponding author), IIIT, CVIT, Hyderabad, Andhra Pradesh, India.
EM nataraj.j@research.iiit.ac.in
RI Jawahar, C.V./ACR-3102-2022
OI Jawahar, C.V./0000-0001-6767-7057; Jammalamadaka,
   Nataraj/0000-0002-7207-9315
FU UKIERI; EPSRC [EP/M013774/1]; EPSRC [EP/M013774/1] Funding Source: UKRI
FX We would like to thank Aniket Singh for helping with the implementation
   of the triplet network in the Theano framework and for other helpful
   discussions during the implementation. We also would like to thank James
   Charles for sharing the trained models of a HPE algorithm. We are
   grateful for financial support from the UKIERI and EPSRC (EP/M013774/1)
   program grant Seebibyte.
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Andrews S., 2002, Advances in neural information processing systems, V2, P7
   [Anonymous], 2013, DECAF DEEP CONVOLUTI
   [Anonymous], 2003, P IEEE INT C COMP VI
   [Anonymous], 2010, P PYTHON SCI COMPUTI
   [Anonymous], 2012, DEEP LEARNING UNSUPE
   [Anonymous], 1998, P IEEE
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2014, CORR
   [Anonymous], 2014, CVPR
   [Anonymous], 2010, IEEE INT C MACH LEAR
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2009, Construction and Analysis of a Large Scale Image Ontology
   [Anonymous], 2013, IEEE C COMP VIS PATT
   Bourdev L.D., 2014, CORR
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen X., 2015, COMPUTER VISION PATT
   Cherian A., 2014, IEEE C COMP VIS PATT
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Drucker H., 1996, ADV NEUR INF PROC SY
   Eichner M., 2009, BRIT MACH VIS C BMVC
   Eichner M, 2012, IEEE T PATTERN ANAL, V34, P2282, DOI 10.1109/TPAMI.2012.85
   Eichner M, 2010, LECT NOTES COMPUT SC, V6311, P228, DOI 10.1007/978-3-642-15549-9_17
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Ferrari V., 2009, IEEE CONFERENCE ON C
   Ferrari V., 2001, IEEE C COMP VIS PATT
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Girshick R., 2014, P IEEE C COMP VIS PA, P580
   Gkioxari G., 2013, IEEE C COMP VIS PATT
   Gkioxari G., 2014, IEEE C COMP VIS PATT
   Hinton G.E., 2012, ABS12070580 CORR
   Jammalamadaka N., 2012, INT C MULT RETR ICMR
   Jammalamadaka N., 2012, IEEE EUR C COMP VIS
   Jammalamadaka N., 2015, INT C AUT FAC GEST R
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kiefel M., 2014, EUR C COMP VIS ECCV
   Krizhevsky A., CUDA CONVNET FAST C
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222
   Pishchulin L., 2013, IEEE C COMP VIS PATT
   Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433
   Platt JC, 2000, ADV NEUR IN, P61
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Taylor GW, 2011, PROC CVPR IEEE
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang L, 2011, PROC CVPR IEEE
   Yang Y., 2011, IEEE C COMP VIS PATT
NR 52
TC 10
Z9 11
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2017
VL 59
BP 31
EP 43
DI 10.1016/j.imavis.2016.12.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EP9IS
UT WOS:000397687900003
DA 2024-07-18
ER

PT J
AU Ouyang, SX
   Hospedales, T
   Song, YZ
   Li, XM
   Loy, CC
   Wang, XG
AF Ouyang, Shuxin
   Hospedales, Timothy
   Song, Yi-Zhe
   Li, Xueming
   Loy, Chen Change
   Wang, Xiaogang
TI A survey on heterogeneous face recognition: Sketch, infra-red, 3D and
   low-resolution
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Cross-modality face recognition; Heterogeneous face recognition;
   Sketch-based face recognition; Visual-infrared matching; 2D-3D matching;
   High-low resolution matching
ID DISCRIMINANT-ANALYSIS; FEATURES; SUPERRESOLUTION
AB Heterogeneous face recognition (HFR) refers to matching face imagery across different domains. It has received much interest from the research community as a result of its profound implications in law enforcement. A wide variety of new invariant features, cross-modality matching models and heterogeneous datasets are being established in recent years. This survey provides a comprehensive review of established techniques and recent developments in HFR. Moreover, we offer a detailed account of datasets and benchmarks commonly used for evaluation. We finish by assessing the state of the field and discussing promising directions for future research. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Ouyang, Shuxin; Li, Xueming] Beijing Univ Posts & Telecommun, 10 Xituchen St, Beijing, Peoples R China.
   [Ouyang, Shuxin; Hospedales, Timothy; Song, Yi-Zhe] Queen Mary Univ London, London E1 4NS, England.
   [Loy, Chen Change; Wang, Xiaogang] Chinese Univ Hong Kong, Shatin, Hong Kong, Peoples R China.
C3 Beijing University of Posts & Telecommunications; University of London;
   Queen Mary University London; Chinese University of Hong Kong
RP Ouyang, SX (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, 10 Xituchen Rd, Beijing 100876, Peoples R China.
EM ouyangshuxin@gmail.com
RI Li, Xueming/W-8707-2019; zhang, weijie/JQX-1450-2023; Wang,
   Xiaogang/L-4369-2014; Wang, Xiaogang/B-2439-2013; yang,
   qing/JBR-8440-2023
OI Wang, Xiaogang/0000-0002-7929-5889; Song, Yi-Zhe/0000-0001-5908-3275;
   Loy, Chen Change/0000-0001-5345-1591
CR An L, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P244, DOI 10.1109/AVSS.2013.6636647
   [Anonymous], 2010, BIOPASS 2 AUT BIOM B
   [Anonymous], 2011, 2011 2 INT C WIRELES
   [Anonymous], 2014, NIPS
   [Anonymous], 2010, CHIN C PATT REC CCPR
   [Anonymous], 2012, 2012 INT C EM TECHN
   [Anonymous], 2015, IEEE C WORKSH AUT FA
   [Anonymous], 2013, P IEEE 6 INT C BIOM
   [Anonymous], 2015, ARXIV150402351
   [Anonymous], 2007, 0749 U MASS
   [Anonymous], 2008, 2008 IEEE C COMP VIS
   [Anonymous], 2009, UHDB12 FAC DAT
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bhatt H., 2012, TIFS, P1522
   Bhatt H., 2010, BTAS, P1
   Bhatt HS, 2014, IEEE T IMAGE PROCESS, V23, P5654, DOI 10.1109/TIP.2014.2362658
   Biometrix I., 2011, FACE 4 0
   Biswas S, 2012, IEEE T PATTERN ANAL, V34, P2019, DOI 10.1109/TPAMI.2011.278
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Cai D, 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/CVPR.2007.383054
   Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Cho S, 2007, IEEE I CONF COMP VIS, P596
   Choi Jonghyun., 2012, Proceedings of the American Education Research Association, Vancouver, BC, Canada, P1
   Chugh T., 2013, P IEEE INT C BIOM TH, P1, DOI DOI 10.1109/BTAS.2013.6712719
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhamecha TI, 2014, INT C PATT RECOG, P1788, DOI 10.1109/ICPR.2014.314
   Di Huang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P125, DOI 10.1109/ICB.2012.6199769
   Di Huang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1225, DOI 10.1109/ICPR.2010.305
   Dong C., 2014, P EUR C COMP VIS, P1
   Dou P., 2015, Proc. Biometrics Theory, P1
   Frowd C. D., 2004, ACM Transactions on Applied Perception, V1939, P19, DOI DOI 10.1145/1008722.1008725
   Frowd C, 2007, BRIT J PSYCHOL, V98, P61, DOI 10.1348/000712606X104481
   Frowd CD, 2015, J FORENSIC PRACT, V17, P319, DOI 10.1108/JFP-08-2014-0025
   Galoogahi H. K., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P224, DOI 10.1109/ICME.2012.128
   Galoogahi HK, 2012, IEEE IMAGE PROC, P1837, DOI 10.1109/ICIP.2012.6467240
   Gao XB, 2008, NEUROCOMPUTING, V71, P1921, DOI 10.1016/j.neucom.2007.10.025
   Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770
   Gibson L., 2008, Forensic art essentials: a manual for law enforcement artists
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Gong DH, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P135, DOI 10.1109/ACPR.2013.12
   Goswami D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2160, DOI 10.1109/ICCVW.2011.6130515
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513
   Han H, 2013, IEEE T INF FOREN SEC, V8, P191, DOI 10.1109/TIFS.2012.2228856
   Hennings-Yeomans PH, 2009, IEEE IMAGE PROC, P33, DOI 10.1109/ICIP.2009.5413920
   Ho H. T., 2014, IJCV
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu G., ABS160306470 CORR
   Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310
   Huang D, 2009, IEEE IMAGE PROC, P3325, DOI 10.1109/ICIP.2009.5413901
   Huang H, 2011, IEEE T NEURAL NETWOR, V22, P121, DOI 10.1109/TNN.2010.2089470
   Huang LK, 2012, INT C PATT RECOG, P1683
   Huang XS, 2013, IEEE T IMAGE PROCESS, V22, P353, DOI 10.1109/TIP.2012.2215617
   Jia K, 2005, IEEE I CONF COMP VIS, P1683
   Jiang JJ, 2012, IEEE IMAGE PROC, P1465, DOI 10.1109/ICIP.2012.6467147
   Juefei-Xu Felix, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P141, DOI 10.1109/CVPRW.2015.7301308
   Kiani Galoogahi H., 2012, FACE PHOTO RETRIEVAL, P1
   Klare B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1513, DOI 10.1109/ICPR.2010.374
   Klare B., 2010, SPIE, P1
   Klare B. F., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P139, DOI 10.1109/ICB.2012.6199771
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Klum S., 2013, BIOM ICB 2013 INT C, P1, DOI [DOI 10.1109/ICB.2013.6612993, 10.1109/ICB.2013.6612993]
   Klum SJ, 2014, IEEE T INF FOREN SEC, V9, P2248, DOI 10.1109/TIFS.2014.2360825
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusuma G.P., 2011, IVC, P306
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860
   Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Li B, 2009, LECT NOTES ARTIF INT, V5828, P220
   Li Stan Z., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204149
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liao SC, 2009, LECT NOTES COMPUT SC, V5558, P209, DOI 10.1007/978-3-642-01793-3_22
   Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Liu W, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2141
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo P, 2013, IEEE I CONF COMP VIS, P2864, DOI 10.1109/ICCV.2013.356
   Ma HM, 2008, I C WIREL COMM NETW, P10017
   Marchand É, 2001, IMAGE VISION COMPUT, V19, P941, DOI 10.1016/S0262-8856(01)00054-3
   Martinez A.M., 1998, AR FACE DATABASE CVC
   MAURO R, 1992, MEM COGNITION, V20, P433, DOI 10.3758/BF03210927
   McQuiston-Surrett D, 2006, PSYCHOL CRIME LAW, V12, P505, DOI 10.1080/10683160500254904
   Messer K., 1999, Proceedings of the Second International Conference on Audio and Video-based Biometric Person Authentication (AVBPA'99), P1
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Mittal P, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Mittal P, 2015, INT CONF BIOMETR, P251, DOI 10.1109/ICB.2015.7139092
   Mittal P, 2013, IEEE IMAGE PROC, P2797, DOI 10.1109/ICIP.2013.6738576
   Moeini A., 2015, IVC
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Moutafis P, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Nejati H., 2011, IEEE Winter Conference Applications of Computer Vision Workshop (WACVW), P240
   Nizami H., 2009, BIOMETRICS THEORY AP, P1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ouyang S., 2016, CVPR, P1
   Ouyang S., 2014, ACCV IN PRESS
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patel V., 2015, IEEE SIGNAL PROC MAG
   Peng CL, 2016, IEEE T NEUR NET LEAR, V27, P2201, DOI 10.1109/TNNLS.2015.2464681
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Pramanik S., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P409, DOI 10.1109/ICPRIME.2012.6208381
   Rama A., 2006, ACOUSTICS SPEECH SIG, P361
   Ren CX, 2012, IEEE T IMAGE PROCESS, V21, P3770, DOI 10.1109/TIP.2012.2192285
   RHODES G, 1987, COGNITIVE PSYCHOL, V19, P473, DOI 10.1016/0010-0285(87)90016-8
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Shekhar S., 2011, P INT JOINT C BIOMET P 2011 INT JOINT C B, P1
   Sifei Liu, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P79, DOI 10.1109/ICB.2012.6199762
   Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tang X, 2002, IEEE IMAGE PROC, P257
   Tang X., 2004, CVPR, P1
   Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414
   Taylor K., 2001, FORENSIC ART ILLUSTR
   Toderici G, 2010, PROC CVPR IEEE, P2721, DOI 10.1109/CVPR.2010.5539995
   Toderici G., 2013, Proc. 6th Pacific-Rim Symposium on Image and Video Technology, P73
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Uhl RG, 1996, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.1996.517132
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang R, 2009, LECT NOTES COMPUT SC, V5558, P319, DOI 10.1007/978-3-642-01793-3_33
   Wang XG, 2004, PROC CVPR IEEE, P564
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wang YJ, 2006, IMAGE VISION COMPUT, V24, P176, DOI 10.1016/j.imavis.2005.09.025
   Wang YJ, 2005, IMAGE VISION COMPUT, V23, P1018, DOI 10.1016/j.imavis.2005.07.005
   Wang Z., 2013, MESOZOIC CENOZOIC PO, P1
   Wells GL, 2007, CURR DIR PSYCHOL SCI, V16, P6, DOI 10.1111/j.1467-8721.2007.00465.x
   Wright P., 2007, IDENTI KIT
   Wu XX, 2006, IEEE INT SOC CONF, P91
   Wu Y, 2018, REAL ESTATE ECON, V46, P783, DOI 10.1111/1540-6229.12178
   Xiao B, 2009, SIGNAL PROCESS, V89, P1576, DOI 10.1016/j.sigpro.2009.02.008
   Xie XD, 2006, PATTERN RECOGN LETT, V27, P609, DOI 10.1016/j.patrec.2005.09.026
   Xiong Pengfei, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P1, DOI 10.1109/ICB.2012.6199750
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yi D, 2007, LECT NOTES COMPUT SC, V4642, P523
   Yu Q, 2016, P IEEECVF C COMPUTER, P1
   Yuen PC, 2007, IEEE T SYST MAN CY A, V37, P493, DOI 10.1109/TSMCA.2007.897588
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang S., 2015, IEEE T CIRCUITS SYST
   Zhang S., 2015, TIP
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhang Y, 2010, IEEE T SYST MAN CY A, V40, P475, DOI 10.1109/TSMCA.2010.2041654
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhen Lei, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P7, DOI 10.1109/ICB.2012.6199751
   Zhong JJ, 2007, INT CONF ACOUST SPEE, P485
   Zhu J.Y., 2014, TIFS, P501
   Zhu J, 2013, FIXED POINT THEORY A, P1, DOI 10.1186/1687-1812-2013-79
   Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21
   Zou W. W. W., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1152, DOI 10.1109/ICPR.2010.288
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
   Zou X, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P113
NR 161
TC 66
Z9 71
U1 0
U2 72
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2016
VL 56
BP 28
EP 48
DI 10.1016/j.imavis.2016.09.001
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA EF1FW
UT WOS:000390071700003
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Stevenage, SV
   Guest, RM
AF Stevenage, Sarah V.
   Guest, Richard M.
TI Combining forces: Data fusion across man and machine for biometric
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Biometrics Conference
CY OCT, 2015
CL London, ENGLAND
DE Biometric identification; Fusion; Multidisciplinary approach
AB Through the HUMMINGBIRD framework outlined here, we seek to encourage a novel multidisciplinary approach to biometric analysis with the goal of enhancing both understanding and accuracy of identification. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Stevenage, Sarah V.] Univ Southampton, Dept Psychol, Shackleton Bldg, Southampton SO17 1BJ, Hants, England.
   [Guest, Richard M.] Univ Kent, Sch Engn & Digital Arts, Jennison Bldg, Canterbury CT2 7NT, Kent, England.
C3 University of Southampton; University of Kent
RP Stevenage, SV (corresponding author), Univ Southampton, Dept Psychol, Shackleton Bldg, Southampton SO17 1BJ, Hants, England.
EM sys1@soton.ac.uk; RM.Guest@kent.ac.uk
FU EPSRC [EP/J004995/1] Funding Source: UKRI
CR [Anonymous], 2015, Biometrics
   [Anonymous], 2006, Handbook of Multibiometrics
   Blanz V, 1999, PERCEPTION, V28, P575, DOI 10.1068/p2897
   Dror I.E., 2010, Law, Prob, Risk, V9, P47, DOI DOI 10.1093/LPR/MGP031
   Dror I. E., 2015, COGNITIVE HUMAN FACT
   GO Science, 2015, FOR SCI AUTH PROV AS
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   KAPLAN IT, 1965, PERCEPT MOTOR SKILL, V21, P239, DOI 10.2466/pms.1965.21.1.239
   Kiltter J., 2008, 2 IEEE INT C BIOM TH
   Menneer T., 2012, APPL COGNITIVE PSYCH, V21, P915
   Nickerson R. S., 1998, REV GEN PSYCHOL, V2, P175, DOI DOI 10.1037/1089-2680.2.2.175
   Phillips PJ, 2009, LECT NOTES COMPUT SC, V5558, P705, DOI 10.1007/978-3-642-01793-3_72
   POLLACK I, 1954, J ACOUST SOC AM, V26, P403, DOI 10.1121/1.1907349
   ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9
   Stammers S., 2015, 512 POST
   Stevenage S. V., 2015, BIOMETRICS
   Stevenage SV, 2012, J COGN PSYCHOL, V24, P647, DOI 10.1080/20445911.2012.675321
   VALENTINE T, 1991, Q J EXP PSYCHOL-A, V43, P161, DOI 10.1080/14640749108400966
   VANLANCKER D, 1985, J PHONETICS, V13, P19, DOI 10.1016/S0095-4470(19)30723-5
   White D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103510
NR 20
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
BP 18
EP 21
DI 10.1016/j.imavis.2016.03.012
PN 1
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA ED8BO
UT WOS:000389097100006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Tang, J
   Jin, HQ
   Tan, SB
   Liang, D
AF Tang, Jun
   Jin, Haiqun
   Tan, Shoubiao
   Liang, Dong
TI Cross-domain action recognition via collective matrix factorization with
   graph Laplacian regularization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Collective matrix factorization; Graph Laplacian
   regularization; Latent semantic representation
ID K-SVD; DICTIONARY
AB This paper investigates the problem of cross-domain action recognition. Specifically, we present a cross-domain action recognition framework by utilizing some labeled data from other data sets as the auxiliary source domain. It is a challenging task as data from different domains may have different feature distribution. To map data from different domains into the same abstract space and boost the action recognition performance, we propose a method named collective matrix factorization with graph Laplacian regularization (CMFGLR). Our approach is built upon the technique of collective matrix factorization, which simultaneously learns a common latent space, linear projection matrices for obtaining semantic representations, and an optimal linear classifier. Moreover, we explore the label consistency across different domain and the local geometric consistency in each domain and obtain a graph Laplacian regularization term to enhance the discrimination of learned features. Experimental results verify that CMFGLR significantly outperforms several state-of-the-art methods. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Tang, Jun; Jin, Haiqun; Tan, Shoubiao] Anhui Univ, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Huangshan Rd, Hefei 230039, Peoples R China.
   [Tang, Jun; Jin, Haiqun; Tan, Shoubiao; Liang, Dong] Anhui Univ, Sch Elect & Informat Engn, Hefei 230039, Peoples R China.
C3 Anhui University; Anhui University
RP Tan, SB (corresponding author), Anhui Univ, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Huangshan Rd, Hefei 230039, Peoples R China.; Tan, SB (corresponding author), Anhui Univ, Sch Elect & Informat Engn, Hefei 230039, Peoples R China.
EM tangjunahu@163.com; 979361249@qq.com; tsb@ustc.edu; dliang@ahu.edu.cn
RI Dong, Liang/JZD-4605-2024
FU Natural Science Foundation of China [61172127, 61501003]; Anhui
   Provincial Natural Science Foundation [1508085MF120]; key projects of
   outstanding youth talent support program of Anhui Provincial
   universities [gxyqZD2016012]
FX This work was supported by the Natural Science Foundation of China under
   grants 61172127 and 61501003, and by the Anhui Provincial Natural
   Science Foundation under grant 1508085MF120, and by the key projects of
   outstanding youth talent support program of Anhui Provincial
   universities under Grant gxyqZD2016012.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2013, IEEE COMP SEM INT CI
   [Anonymous], 2015, IEEE MTT S INT MICR
   Bouchard G., 2013, P 16 INT C ARTIFICIA, P144
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lee SG, 2011, LINEAR ALGEBRA APPL, V435, P2097, DOI 10.1016/j.laa.2010.09.034
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Lu XQ, 2012, PROC CVPR IEEE, P1648, DOI 10.1109/CVPR.2012.6247858
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shao L., 2015, INT J COMPUT VIS
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shao L, 2014, IEEE T CIRC SYST VID, V24, P504, DOI 10.1109/TCSVT.2013.2276700
   Singh A. P., 2008, P 14 ACM SIGKDD INT, P650
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Zhang H, 2014, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2014.265
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zheng JJ, 2013, IEEE I CONF COMP VIS, P3176, DOI 10.1109/ICCV.2013.394
   Zheng JJ, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.125
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhu F, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.52
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
NR 32
TC 13
Z9 13
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 119
EP 126
DI 10.1016/j.imavis.2016.02.003
PN 2
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300010
DA 2024-07-18
ER

PT J
AU Perdigoto, L
   Araujo, H
AF Perdigoto, Luis
   Araujo, Helder
TI Estimation of mirror shape and extrinsic parameters in axial non-central
   catadioptric systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Non-central catadioptric vision systems; Calibration; Mirror shape
   estimation
ID CAMERA CALIBRATION
AB We propose a method to estimate the mirror shape and position, and the extrinsic parameters in axial non central catadioptric systems (i.e. systems with an axial symmetrical mirror and a pinhole camera with its optical center located at the mirror axis). Our method requires one or more images of a planar calibration pattern consisting of points and lines with known position (e.g. a checkerboard), and that the camera be internally calibrated. We also present an alternative algorithm for the particular case of catadioptric systems with spherical mirror, were the estimation is achieved by fitting quartic curves to the images of lines of the calibration pattern. An analytical solution is presented for every method. Each analytical solution is then refined by a non-linear optimization procedure. We present experimental results, on simulated and real images, that demonstrate the validity of our work. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Perdigoto, Luis; Araujo, Helder] Univ Coimbra, Dept Elect & Comp Engn, Inst Syst & Robot, P-3030 Coimbra, Portugal.
   [Perdigoto, Luis] Polytech Inst Leiria, ESTG, P-2411901 Leiria, Portugal.
C3 Universidade de Coimbra
RP Perdigoto, L (corresponding author), Univ Coimbra, Dept Elect & Comp Engn, Inst Syst & Robot, P-3030 Coimbra, Portugal.; Perdigoto, L (corresponding author), Polytech Inst Leiria, ESTG, P-2411901 Leiria, Portugal.
EM luis.perdigoto@ipleiria.pt; helder@isr.uc.pt
RI Araujo, Helder/B-3554-2008
OI Araujo, Helder/0000-0002-9544-424X; Perdigoto, Luis/0000-0002-2626-3154
FU project "Surgery and Diagnosis Assisted by Computer Using Images" - QREN
   Programme "Mais Centro"; European Fund for Regional Development (FEDER)
   [SCT-2011-02-027-4824]; Portuguese Science Foundation through PIDDAC;
   FEDER through COMPETE Operational Programme Competitive Factors
   [FCT/PTDC/EIAEIA/122454/2010]
FX This work was supported in part by the project "Surgery and Diagnosis
   Assisted by Computer Using Images", funded by the QREN Programme "Mais
   Centro" with financing from the European Fund for Regional Development
   (FEDER), under Grant SCT-2011-02-027-4824, and in part by the Portuguese
   Science Foundation through PIDDAC and FEDER through COMPETE Operational
   Programme Competitive Factors under Project FCT/PTDC/EIAEIA/122454/2010.
CR Agrawal A, 2013, IEEE I CONF COMP VIS, P2368, DOI 10.1109/ICCV.2013.294
   Agrawal A, 2010, LECT NOTES COMPUT SC, V6313, P129
   [Anonymous], 2000, P EUR C COMP VIS
   [Anonymous], 2006, PROC IEEE 4 INT C CO, DOI DOI 10.1109/ICVS.2006.3
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2000, TEMPLATES SOLUTION A
   Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364
   Barreto J., 2001, COMP VIS PATT REC 20, V2, pII
   Barreto JP, 2005, IEEE T PATTERN ANAL, V27, P1327, DOI 10.1109/TPAMI.2005.163
   Barreto JP, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1359
   Bermudez-Cameo J, 2014, INT C PATT RECOG, P2083, DOI 10.1109/ICPR.2014.363
   Caglioti V., CVPR IEEE P
   Caglioti V., 2007, IEEE 11 INT C COMP V, P1
   Fabrizio J, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P45, DOI 10.1109/OMNVIS.2002.1044490
   Goncalves N., 2007, IEEE 11 INT C COMP V, P1
   Gonçalves N, 2007, OPT ENG, V46, DOI 10.1117/1.2752493
   Grossberg MD, 2005, INT J COMPUT VISION, V61, P119, DOI 10.1023/B:VISI.0000043754.56350.10
   Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820
   Kukelova Z, 2012, IEEE T PATTERN ANAL, V34, P1381, DOI 10.1109/TPAMI.2011.230
   Liu MM, 2015, IEEE T PATTERN ANAL, V37, P760, DOI 10.1109/TPAMI.2014.2353622
   Liu MM, 2011, IEEE I CONF COMP VIS, P579, DOI 10.1109/ICCV.2011.6126291
   Mashita T., 2005, P 6 WORKSH OMN VIS O
   Mei C., 2012, Omnidirectional calibration toolbox
   Mei C, 2007, IEEE INT CONF ROBOT, P3945, DOI 10.1109/ROBOT.2007.364084
   Micusík B, 2004, PROC CVPR IEEE, P58
   Morel O, 2007, IEEE INT CONF ROBOT, P3939, DOI 10.1109/ROBOT.2007.364083
   Perdigoto L, 2013, COMPUT VIS IMAGE UND, V117, P909, DOI 10.1016/j.cviu.2013.04.001
   Puig L, 2012, COMPUT VIS IMAGE UND, V116, P120, DOI 10.1016/j.cviu.2011.08.003
   Puig L, 2011, INT J COMPUT VISION, V93, P101, DOI 10.1007/s11263-010-0411-1
   Ramalingam S, 2006, LECT NOTES COMPUT SC, V3851, P704
   Savarese S, 2005, INT J COMPUT VISION, V64, P31, DOI 10.1007/s11263-005-1086-x
   Scaramuzza D., 2012, Ocamcalib: Omnidirectional camera calibration toolbox for matlab
   Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372
   Sturm P, 2007, LECT NOTES COMPUT SC, V4844, P784
   Sturm P, 2010, FOUND TRENDS COMPUT, V6, P1, DOI 10.1561/0600000023
   Swaminathan R., 2001, INT J COMPUTER VISIO
   Taguchi Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866194
   Tardif JP, 2009, IEEE T PATTERN ANAL, V31, P1552, DOI 10.1109/TPAMI.2008.202
   Tarini M, 2005, GRAPH MODELS, V67, P233, DOI 10.1016/j.gmod.2004.11.002
   Thirthala S, 2005, IEEE I CONF COMP VIS, P1539
   Wu YH, 2005, IEEE I CONF COMP VIS, P1547
   Wu YH, 2014, COMPUT VIS IMAGE UND, V126, P11, DOI 10.1016/j.cviu.2014.05.001
   Ying XH, 2004, IEEE T PATTERN ANAL, V26, P1260, DOI 10.1109/TPAMI.2004.79
NR 43
TC 2
Z9 3
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2016
VL 54
BP 45
EP 59
DI 10.1016/j.imavis.2016.06.009
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EB6UG
UT WOS:000387520500005
DA 2024-07-18
ER

PT J
AU Pujadas, ER
   Kjer, HM
   Piella, G
   Ballester, MAG
AF Ruiz Pujadas, Esmeralda
   Kjer, Hans Martin
   Piella, Gemma
   Gonzalez Ballester, Miguel Angel
TI Iterated random walks with shape prior
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Random walks; Segmentation; Shape prior; Iterative segmentation;
   Distance map prior
ID NORMALIZED CUTS; SEGMENTATION
AB We propose a new framework for image segmentation using random walks where a distance shape prior is combined with a region term. The shape prior is weighted by a confidence map to reduce the influence of the prior in high gradient areas and the region term is computed with k-means to estimate the parametric probability density function. Then, random walks is performed iteratively aligning the prior with the current segmentation in every iteration. We tested the proposed approach with natural and medical images and compared it with the latest techniques with random walks and shape priors. The experiments suggest that this method gives promising results for medical and natural images. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Ruiz Pujadas, Esmeralda; Piella, Gemma; Gonzalez Ballester, Miguel Angel] Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona 08018, Spain.
   [Kjer, Hans Martin] Tech Univ Denmark, Dept Appl Math & Comp Sci, Lyngby, Denmark.
   [Gonzalez Ballester, Miguel Angel] ICREA, Barcelona 08018, Spain.
C3 Pompeu Fabra University; Technical University of Denmark; ICREA
RP Pujadas, ER (corresponding author), Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona 08018, Spain.
EM esmeralda.ruiz@upf.edu; hmkj@dtu.dk; gemma.piella@upf.edu;
   ma.gonzalez@upf.edu
RI Ballester, Miguel Angel Gonzalez/D-1349-2013; Kjer, Hans
   Martin/ADK-9995-2022; Piella, Gemma/D-7979-2014
OI Ballester, Miguel Angel Gonzalez/0000-0002-9227-6826; Kjer, Hans
   Martin/0000-0001-7900-5733; Piella, Gemma/0000-0001-5236-5819; Ruiz
   Pujadas, Esmeralda/0000-0001-6150-557X
FU European Union Seventh Frame Programme (FP7) [304857]; ICREA Funding
   Source: Custom
FX The research leading to these results received funding from the European
   Union Seventh Frame Programme (FP7/2007-2013) under grant agreement
   304857, HEAR-EU Project.
CR Baudin PY, 2012, LECT NOTES COMPUT SC, V7510, P569, DOI 10.1007/978-3-642-33415-3_70
   Baudin P.-Y., 2013, SEGMENTATION MOYEN G
   Baudin PY, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.52
   Boykov Y, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P79, DOI 10.1007/0-387-28831-7_5
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chen XJ, 2012, IEEE T IMAGE PROCESS, V21, P2035, DOI 10.1109/TIP.2012.2186306
   Eslami A, 2013, MED IMAGE ANAL, V17, P236, DOI 10.1016/j.media.2012.10.005
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Grady L, 2005, PROC CVPR IEEE, P763
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Kohli P, 2008, INT J COMPUT VISION, V79, P285, DOI 10.1007/s11263-007-0120-6
   Lee YM, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/210604
   Li A., 2013, 2013 INT C DIG IM CO, P1
   Li K.-C., 2012, ADV IMAGE VIDEO TECH, P215
   Min CH, 2004, J COMPUT PHYS, V200, P368, DOI 10.1016/j.jcp.2004.04.019
   Nakagomi K, 2013, MED IMAGE ANAL, V17, P62, DOI 10.1016/j.media.2012.08.002
   Papoutsakis KE, 2010, LECT NOTES COMPUT SC, V6453, P405
   Pujadas ER, 2014, IEEE T IMAGE PROCESS, V23, P163, DOI 10.1109/TIP.2013.2287604
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Ting Yu, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1761, DOI 10.1109/ICCVW.2011.6130462
NR 20
TC 2
Z9 2
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2016
VL 54
BP 12
EP 21
DI 10.1016/j.imavis.2016.07.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EB6UG
UT WOS:000387520500002
DA 2024-07-18
ER

PT J
AU Deng, JK
   Liu, QS
   Yang, J
   Tao, DC
AF Deng, Jiankang
   Liu, Qingshan
   Yang, Jing
   Tao, Dacheng
TI <i>M</i><SUP>3</SUP> CSR: Multi-view, multi-scale and multi-component
   cascade shape regression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face alignment; Cascade shape regression; Multi-view; Multi-scale;
   Multi-component
ID FACE ALIGNMENT; MODELS
AB Automatic face alignment is a fundamental step in facial image analysis. However, this problem continues to be challenging due to the large variability of expression, illumination, occlusion, pose, and detection drift in the real world face images. In this paper, we present a multi-view, multi-scale and multi-component cascade shape regression ((MCSR)-C-3) model for robust face alignment. Firstly, face view is estimated according to the deformable facial parts for learning view specified CSR, which can decrease the shape variance, alleviate the drift of face detection and accelerate shape convergence. Secondly, multi-scale HoG features are used as the shape-index features to incorporate local structure information implicitly, and a multi-scale optimization strategy is adopted to avoid trapping in local optimum. Finally, a component-based shape refinement process is developed to further improve the performance of face alignment. Extensive experiments on the IBUG dataset and the 300-W challenge dataset demonstrate the superiority of the proposed method over the state-of-the-art methods. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Deng, Jiankang; Liu, Qingshan; Yang, Jing] Nanjing Univ Informat & Technol, Sch Informat & Control, B DAT Lab, Nanjing 210044, Jiangsu, Peoples R China.
   [Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, QCIS Lab, 81 Broadway St, Ultimo, NSW 2007, Australia.
C3 Nanjing University of Information Science & Technology; University of
   Technology Sydney
RP Liu, QS (corresponding author), Nanjing Univ Informat & Technol, Sch Informat & Control, B DAT Lab, Nanjing 210044, Jiangsu, Peoples R China.
EM jiankangdeng@gmail.com; qsliu@nuist.edu.cn; yang.xiaojing00@gmail.com;
   Dacheng.Tao@uts.edu.au
RI Liu, Qingqing/HMV-4816-2023; Chen, Rainie/ISS-6016-2023; liu,
   qingqing/HHD-0360-2022; Liu, Qing/GWC-9222-2022; Tao,
   Dacheng/A-5449-2012
OI Tao, Dacheng/0000-0001-7225-5449
FU National Natural Science Foundation of China [61532009, 61272223];
   Graduate Education Innovation Project of Jiangsu [KYLX15_0881]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61532009 and Grant 61272223, in part by
   the Graduate Education Innovation Project of Jiangsu under Grant
   KYLX15_0881.
CR Alabort-i-Medina J, 2014, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2014.439
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], ICCVW
   [Anonymous], 2013, 300 faces in-the-wild challenge: The first facial landmark localization challenge
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2013, ICCV WORKSH, DOI DOI 10.1109/ICCVW.2013.58
   Asthana A, 2015, IEEE T PATTERN ANAL, V37, P1312, DOI 10.1109/TPAMI.2014.2362142
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Çeliktutan O, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-13
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Cristinacce D., 2007, British Mach. Vision Conf, P880
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Koestinger M., 2011, IEEE INT C COMP VIS, P2144, DOI DOI 10.1109/ICCVW.2011.6130513
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Liang L., 2006, CVPR, P1313, DOI [DOI 10.1109/CVPR.2006.45, 10.1109/CVPR.2006.45]
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Pedro F., 2010, IEEE T PATTERN ANAL
   Qian JJ, 2013, IEEE T IMAGE PROCESS, V22, P3591, DOI 10.1109/TIP.2013.2264676
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Saragih J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2881, DOI 10.1109/CVPR.2011.5995618
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Xiong X., 2015, COMPUTER VISION PATT, P2664
   Xiong X., 2014, ARXIV14050601
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320
   Yang H, 2013, IEEE I CONF COMP VIS, P1936, DOI 10.1109/ICCV.2013.243
   Yao AB, 2013, IEEE T IMAGE PROCESS, V22, P3247, DOI 10.1109/TIP.2013.2246523
   Yu X, 2014, LECT NOTES COMPUT SC, V8692, P105, DOI 10.1007/978-3-319-10593-2_8
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang Z., 2014, ARXIV14083967
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhou F, 2013, IEEE I CONF COMP VIS, P1025, DOI 10.1109/ICCV.2013.131
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 51
TC 43
Z9 46
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2016
VL 47
BP 19
EP 26
DI 10.1016/j.imavis.2015.11.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO5LL
UT WOS:000377824500003
DA 2024-07-18
ER

PT J
AU Shah, M
   Deng, JD
   Woodford, BJ
AF Shah, Munir
   Deng, Jeremiah D.
   Woodford, Brendon J.
TI A Self-adaptive CodeBook (SACB) model for real-time background
   subtraction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Background subtraction; Video processing; Parameter learning; Background
   modeling; Code Book model
ID SEGMENTATION
AB Effective and efficient background subtraction is important to a number of computer vision tasks. In this paper, we introduce a new background model that integrates several new techniques to address key challenges for background modeling for moving object detection in videos. The novel features of our proposed Self-adaptive CodeBook (SACB) background model are: a more effective color model using YCbCr color space, a statistical parameter estimation method, and a new algorithm for adding new background codewords into the permanent model and deleting noisy codewords from the models. Also, a new block-based approach is introduced to exploit the local spatial information. The proposed model is rigorously tested and has shown significant performance improvements over several previous models. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Shah, Munir; Deng, Jeremiah D.; Woodford, Brendon J.] Univ Otago, Dept Informat Sci, Hamilton, New Zealand.
C3 University of Otago
RP Shah, M (corresponding author), Univ Otago, Dept Informat Sci, Hamilton, New Zealand.
EM munirsha@gmail.com; jeremiah.deng@otago.ac.nz;
   brendon.woodford@otago.ac.nz
RI Shah, Munir/KHD-5812-2024; Deng, Jeremiah/A-1287-2008
OI Shah, Munir/0000-0001-6084-7404; Deng, Jeremiah/0000-0003-3727-4403
CR [Anonymous], 2010, Handbook of pattern recognition and computer vision
   [Anonymous], 1999, P IEEE C COMPUTER VI
   [Anonymous], IEEE INT C VID SIGN
   Azeem M., 2010, J AM ARAB ACAD SCI T, V1, P112
   Baloch T., 2010, THESIS INDIAN I TECH
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Devi K.S., 2012, INT J COMP APPL, V43, P1
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Evangelio R. H., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P71, DOI 10.1109/AVSS.2011.6027297
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Gallego J, 2012, PATTERN RECOGN LETT, V33, P1558, DOI 10.1016/j.patrec.2012.05.004
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guo JM, 2011, IEEE T CIRC SYST VID, V21, P804, DOI 10.1109/TCSVT.2011.2133270
   Herrero S, 2009, LECT NOTES COMPUT SC, V5807, P33
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Ivanov Y, 1998, 1998 IEEE WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P49
   KaewTraKulPong P., 2001, Proc. European Workshop Advanced Video Based Surveillance Systems, V1, P1
   Kim H, 2008, ELECTRON LETT, V44, P189, DOI 10.1049/el:20083126
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Minglun Gong, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2105, DOI 10.1109/CVPR.2011.5995394
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Schick A., 2012, Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on, P27, DOI DOI 10.1109/CVPRW.2012.6238923
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Sheikh Y, 2009, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2009.5459334
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   White B., 2005, P IEEE INT C MULT EX, P1826
   Zhao C, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/972961
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 31
TC 23
Z9 26
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2015
VL 38
BP 52
EP 64
DI 10.1016/j.imavis.2015.02.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CK4LX
UT WOS:000356196400005
DA 2024-07-18
ER

PT J
AU Huang, ZH
   Li, WJ
   Shang, J
   Wang, J
   Zhang, T
AF Huang, Zheng-Hai
   Li, Wen-Juan
   Shang, Jin
   Wang, Jun
   Zhang, Ting
TI Non-uniform patch based face recognition via 2D-DWT
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Two-dimensional discrete wavelet transform; Integral
   projection; Non-uniform patch
ID IMAGE
AB In this paper, we propose a method for face recognition by using the two-dimensional discrete wavelet transform (2D-DWT) and a new patch strategy. Based on the average image of all training samples, by using integral projection technique for two top-level's high-frequency sub-bands of 2D-DWT, we propose a non-uniform patch strategy for the top-level's low-frequency sub-band. This patch strategy is more suitable to reflect the structure feature of face image; and it is better for retaining the integrity of local information. By applying the obtained patch strategy to all samples, we obtain patches of training samples and testing samples; and then, give the final decision by using the nearest neighbor classifier and the majority voting. Experiments are run on the AR, FERET, Extended Yale B and LFW face databases. The obtained numerical results show that the new face recognition method outperforms the traditional 2D-DWT method and some state-of-the-art patch based methods. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Huang, Zheng-Hai; Li, Wen-Juan; Shang, Jin; Zhang, Ting] Tianjin Univ, Ctr Appl Math, Tianjin 300072, Peoples R China.
   [Shang, Jin; Wang, Jun] Nankai Univ, Ctr Combinator, LPMC TJKLC, Tianjin 300071, Peoples R China.
   [Huang, Zheng-Hai; Zhang, Ting] Tianjin Univ, Sch Sci, Dept Math, Tianjin 300072, Peoples R China.
C3 Tianjin University; Nankai University; Tianjin University
RP Li, WJ (corresponding author), Tianjin Univ, Ctr Appl Math, Tianjin 300072, Peoples R China.
EM liwenjuan@tju.edu.cn
RI Huang, Zheng-Hai/F-8646-2012; Li, yu/HHZ-5236-2022
FU National Natural Science Foundations of China [11171252, 11431002]
FX This work was partially supported by the National Natural Science
   Foundations of China (Grants 11171252 and 11431002).
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 1973, Technical report
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2007, 0749 U MASS
   Atta R, 2012, IEEE T CONSUM ELECTR, V58, P1285, DOI 10.1109/TCE.2012.6414997
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Cavalcanti GDC, 2013, EXPERT SYST APPL, V40, P4971, DOI 10.1016/j.eswa.2013.03.003
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Chen Y, 2010, IEEE IMAGE PROC, P1657, DOI 10.1109/ICIP.2010.5652203
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   Chun-ling Fan, 2012, 2012 8th International Conference on Natural Computation, P575, DOI 10.1109/ICNC.2012.6234703
   DAUBECHIES I, 1992, CBMS NSF SERIES APPL
   Duda R.O., 2001, Pattern Classification, V2nd, P174
   Garcia C, 2000, IMAGE VISION COMPUT, V18, P289, DOI 10.1016/S0262-8856(99)00056-6
   Gonzalez R. C., 2012, DIGITAL IMAGE PROCES, P508
   Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005
   Gumus E, 2010, EXPERT SYST APPL, V37, P6404, DOI 10.1016/j.eswa.2010.02.079
   Huang ZH, 2015, INFORM FUSION, V22, P95, DOI 10.1016/j.inffus.2014.06.001
   Kumar R, 2011, IEEE I CONF COMP VIS, P2375, DOI 10.1109/ICCV.2011.6126520
   Kumar R, 2009, PROC CVPR IEEE, P150, DOI 10.1109/CVPRW.2009.5206837
   Kwak KC, 2004, IEEE T SYST MAN CY B, V34, P1666, DOI 10.1109/TSMCB.2004.827609
   Li B, 2002, KNOWL-BASED SYST, V15, P343, DOI 10.1016/S0950-7051(01)00172-1
   Li DQ, 2005, IEEE T BIO-MED ENG, V52, P1132, DOI 10.1109/TBME.2005.848377
   Lin D., 2006, COMPUTER VISION PATT, V2, P1355
   Nicholl P, 2008, DELTA 2008: FOURTH IEEE INTERNATIONAL SYMPOSIUM ON ELECTRONIC DESIGN, TEST AND APPLICATIONS, PROCEEDINGS, P390, DOI 10.1109/DELTA.2008.39
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Pereira Jose Francisco, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P2481, DOI 10.1109/IJCNN.2009.5178861
   Tan XY, 2005, IEEE T NEURAL NETWOR, V16, P875, DOI 10.1109/TNN.2005.849817
   Tjahyadi R, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2891
   Wang BA, 2012, INT CONF ACOUST SPEE, P1533, DOI 10.1109/ICASSP.2012.6288183
   Wei XJ, 2013, IEEE COMPUT SOC CONF, P70, DOI 10.1109/CVPRW.2013.18
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yu L, 2010, IMAGE VISION COMPUT, V28, P177, DOI 10.1016/j.imavis.2009.05.012
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
NR 34
TC 32
Z9 33
U1 0
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2015
VL 37
BP 12
EP 19
DI 10.1016/j.imavis.2014.12.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CI8NK
UT WOS:000355028800002
DA 2024-07-18
ER

PT J
AU Chen, S
   Liu, CJ
AF Chen, Shuo
   Liu, Chengjun
TI Eye detection using discriminatory Haar features and a new efficient SVM
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Discriminatory feature extraction (DFE); Discriminatory Haar features
   (DHFs); Efficient support vector machine (eSVM); Eye detection; Fisher
   linear discriminant (FLD); Principal component analysis (PCA); Face
   Recognition Grand Challenge (FRGC); BiolD database
ID FACE; COLOR; CLASSIFICATION; LOCALIZATION
AB This paper presents an accurate and efficient eye detection method using the discriminatory Haar features (DHFs) and a new efficient support vector machine (eSVM). The DHFs are extracted by applying a discriminating feature extraction (DFE) method to the 2D Haar wavelet transform. The DFE method is capable of extracting multiple discriminatory features for two-class problems based on two novel measure vectors and a new criterion in the whitened principal component analysis (PCA) space. The eSVM significantly improves the computational efficiency upon the conventional SVM for eye detection without sacrificing the generalization performance. Experiments on the Face Recognition Grand Challenge (FRGC) database and the BioID face database show that (i) the DHFs exhibit promising classification capability for eye detection problem; (ii) the eSVM runs much faster than the conventional SVM; and (iii) the proposed eye detection method achieves near real-time eye detection speed and better eye detection performance than some state-of-the-art eye detection methods. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Chen, Shuo; Liu, Chengjun] New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
C3 New Jersey Institute of Technology
RP Chen, S (corresponding author), New Jersey Inst Technol, Dept Comp Sci, 323 ML King Blvd,Univ Hts, Newark, NJ 07102 USA.
EM sc77@njit.edu
CR Adankon MM, 2009, PATTERN RECOGN, V42, P3264, DOI 10.1016/j.patcog.2008.10.023
   Asteriadis S., 2006, 2 INT S CONTR COMM S
   Bai L, 2006, INT C PATT RECOG, P511
   BEYLKIN G, 1991, COMMUN PUR APPL MATH, V44, P141, DOI 10.1002/cpa.3160440202
   Burrus C. S., 2015, Introduction to wavelets and wavelet transforms. A primer
   Campadelli P, 2009, INT J PATTERN RECOGN, V23, P359, DOI 10.1142/S0218001409007259
   Campadelli P., 2006, BRIT MACHINE VISION, P187
   Chen JH, 2004, IEEE T SYST MAN CY B, V34, P1173, DOI 10.1109/TSMCB.2003.821867
   Cristinacce D., 2004, BMVC, P231
   Davenport MA, 2010, IEEE T PATTERN ANAL, V32, P1888, DOI 10.1109/TPAMI.2010.29
   Eckhardt M, 2009, INT J PATTERN RECOGN, V23, P379, DOI 10.1142/S0218001409007247
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Hamouz M, 2005, IEEE T PATTERN ANAL, V27, P1490, DOI 10.1109/TPAMI.2005.179
   Hamouz M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P67, DOI 10.1109/AFGR.2004.1301510
   JESORSKY O, 2001, 3 INT C AVBPA 2001 H, V2091, P90
   Khan NM, 2012, PATTERN RECOGN, V45, P66, DOI 10.1016/j.patcog.2011.05.004
   Kroon B, 2009, COMPUT VIS IMAGE UND, V113, P921, DOI 10.1016/j.cviu.2009.03.013
   Liu CJ, 2008, IEEE T INF FOREN SEC, V3, P213, DOI 10.1109/TIFS.2008.923824
   Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90
   Liu CJ, 2004, IEEE T SYST MAN CY B, V34, P1117, DOI 10.1109/TSMCB.2003.821449
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604
   Liu YG, 2006, PATTERN RECOGN, V39, P2258, DOI 10.1016/j.patcog.2006.05.034
   Liu ZM, 2008, IEEE T IMAGE PROCESS, V17, P1975, DOI 10.1109/TIP.2008.2002837
   Liu ZM, 2008, COMPUT VIS IMAGE UND, V111, P249, DOI 10.1016/j.cviu.2007.12.002
   Liu ZM, 2010, PATTERN RECOGN, V43, P2882, DOI 10.1016/j.patcog.2010.03.003
   Mita T., 2005, 10 IEEE INT C COMP V
   Mulvaney R, 2006, IEEE T NEURAL NETWOR, V17, P81, DOI 10.1109/TNN.2005.860830
   NGUYEN MH, 2008, 8 IEEE INT C AUT FAC
   Niu ZH, 2006, INT C PATT RECOG, P1216
   Osuna E., 1998, INT C PATTERN RECOGN
   Parris J., 2011, 2011 INT JOINT C BIO
   Porwik P., 2004, Machine Graphics & Vision, V13, P79
   Rätsch G, 2002, IEEE T PATTERN ANAL, V24, P1184, DOI 10.1109/TPAMI.2002.1033211
   Shih PC, 2006, PATTERN RECOGN, V39, P260, DOI 10.1016/j.patcog.2005.07.003
   Su Y, 2011, IEEE T NEURAL NETWOR, V22, P2050, DOI 10.1109/TNN.2011.2170220
   Tian B, 1999, IEEE T NEURAL NETWOR, V10, P138, DOI 10.1109/72.737500
   Valenti R., 2008, 2008 IEEE COMP SOC C
   Vapnik VN, 2000, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-3264-1
   Viola P., 2001, 2001 IEEE COMP SOC C
   Wang P., 2005, 2005 IEEE COMP SOC C
   Wang P, 2007, COMPUT VIS IMAGE UND, V105, P99, DOI 10.1016/j.cviu.2006.08.008
   Yang J, 2007, IEEE T INF FOREN SEC, V2, P781, DOI 10.1109/TIFS.2007.910239
   Zhao XW, 2012, IMAGE VISION COMPUT, V30, P136, DOI 10.1016/j.imavis.2011.12.004
NR 44
TC 50
Z9 56
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2015
VL 33
BP 68
EP 77
DI 10.1016/j.imavis.2014.10.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AZ5KY
UT WOS:000348261100006
DA 2024-07-18
ER

PT J
AU Huang, D
   Ding, HX
   Wang, C
   Wang, YH
   Zhang, GP
   Chen, LM
AF Huang, Di
   Ding, Huaxiong
   Wang, Chen
   Wang, Yunhong
   Zhang, Guangpeng
   Chen, Liming
TI Local circular patterns for multi-modal facial gender and ethnicity
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Soft biometrics; Multi-modal facial gender and ethnicity classification;
   Local descriptor; Decision level fusion
ID FACE RECOGNITION
AB Gender and ethnicity are both key demographic attributes of human beings and they play a very fundamental and important role in automatic machine based face analysis, therefore, there has been increasing attention for face based gender and ethnicity classification in recent years. In this paper, we present an effective and efficient approach on this issue by combining both boosted local texture and shape features extracted from 3D face models, in contrast to the existing ones that only depend on either 2D texture or 3D shape of faces. In order to comprehensively represent the difference between different genders or ethnicities, we propose a novel local descriptor, namely local circular patterns (LCP). LCP improves the widely utilized local binary patterns (LBP) and its variants by replacing the binary quantization with a clustering based one, resulting in higher discriminative power as well as better robustness to noise. Meanwhile the following Adaboost based feature selection finds the most discriminative gender- and race-related features and assigns them with different weights to highlight their importance in classification, which not only further raises the performance but reduces the time and memory cost as well. Experimental results achieved on the FRGC v2.0 and BU-3DFE datasets clearly demonstrate the advantages of the proposed method. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Huang, Di; Wang, Yunhong; Zhang, Guangpeng] Beihang Univ, State Key Lab Software Dev Environm, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Ding, Huaxiong; Wang, Chen; Chen, Liming] CNRS, Ecole Cent Lyon, Dept Math & Comp Sci, F-69134 Lyon, France.
C3 Beihang University; Centre National de la Recherche Scientifique (CNRS);
   Ecole Centrale de Lyon
RP Huang, D (corresponding author), Beihang Univ, State Key Lab Software Dev Environm, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM dhuang@buaa.edu.cn
RI Huang, Di/JBJ-3541-2023
OI Huang, Di/0000-0001-7877-7301
FU National Natural Science Foundation of China (NSFC) [61202237];
   Specialized Research Fund for the Doctoral Program of Higher Education
   [20121102120016]; State Key Laboratory of Software Development
   Environment [SKLSDE-2013ZX-31]; LIA 2MCSI lab; Fundamental Research
   Funds for the Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant 61202237; the Specialized
   Research Fund for the Doctoral Program of Higher Education (No.
   20121102120016); the research program of State Key Laboratory of
   Software Development Environment (SKLSDE-2013ZX-31); the joint project
   by the LIA 2MCSI lab between the group of Ecoles Centrales and Beihang
   University; and the Fundamental Research Funds for the Central
   Universities.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], PERCEPTION
   [Anonymous], BRIT MACH VIS C
   [Anonymous], COMPUTATIONAL LEARNI
   [Anonymous], 2006, BMVC
   Brunelli R., 1992, P DARPA IMAGE UNDERS, P311
   Chan J. K. C., 2007, INT C BIOM
   Golomb BA., 1991, Advances in Neural Information Processing Systems, V3, P572, DOI DOI 10.1007/978-1-4757-2379-3_3
   Guo G., 2010, CVPR Workshop, P79
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Guoying Zhao, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563174
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Han X, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P114, DOI 10.1109/CW.2009.41
   Hosoi S, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P195, DOI 10.1109/AFGR.2004.1301530
   Hu Y, 2010, INT CONF COMPUT AUTO, P369, DOI 10.1109/ICCAE.2010.5451407
   Huang D., IEEE T INF FORENSICS, V7
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huang Di., 2011, CVPR 2011 WORKSHOPS, P1
   Huynh T., 2012, ACCV WORKSH COMP VIS
   Kashima H, 2008, INT C PATT RECOG, P140
   Kim TH, 2012, LECT NOTES COMPUT SC, V7202, P122, DOI 10.1007/978-3-642-31919-8_16
   Lao SH, 2004, LECT NOTES COMPUT SC, V3338, P339
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Lian H., 2005, INT C NAT COMP
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145
   Lu H., 2007, IEEE INT C NAT COMP
   Lu XG, 2006, LECT NOTES COMPUT SC, V3832, P554
   Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847
   Meila M., 2006, Proceedings of the 23rd International Conference on Machine Learning, ACM, Pittsburgh, P625, DOI DOI 10.1145/1143844.1143923
   Moghaddam B., 2000, IEEE INT C AUT FAC G
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Samal A, 2007, J VIS COMMUN IMAGE R, V18, P453, DOI 10.1016/j.jvcir.2007.04.010
   Shakhnarovich G., 2002, IEEE INT C AUT FAC G
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Toderici G., INT J COMPUT VIS, V89
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wu J., 2007, INT C IM AN REC
   Wu J, 2009, IEEE IMAGE PROC, P2449, DOI 10.1109/ICIP.2009.5414129
   Yan X. T. S., 2007, IEEE INTERNATIONAL C
   Yang H, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P645, DOI 10.1109/ICIG.2007.144
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zhu J, 2009, STAT INTERFACE, V2, P349
NR 49
TC 23
Z9 24
U1 0
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1181
EP 1193
DI 10.1016/j.imavis.2014.06.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600019
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, JL
   Rodriguez, JJ
AF Huang, James L.
   Rodriguez, Jeffrey J.
TI Non-rigid registration using gradient of self-similarity response
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Non-rigid registration; Locally affine transformation; Hierarchical
   elastic registration
ID ELASTIC REGISTRATION; DEFORMATIONS; FRAMEWORK
AB Locally affine transformation with globally elastic interpolation is a common strategy for non-rigid registration. Current techniques improve the registration accuracy by only processing the sub-images that contain well-defined structures quantified by Moran's spatial correlation. As an indicator, Moran's metric successfully excludes noisy structures that result in misleading global optimum in terms of similarity. However, some well-defined structures with intensity only varying in one direction may also cause mis-registration. In this paper, we propose a new metric based on the response of a similarity function to quantify the ability of being correctly registered for each sub-image. Using receiver operating characteristic analysis, we show that the proposed metric more accurately reflects such ability than Moran's metric. Incorporating the proposed metric into a hierarchical non-rigid registration scheme, we show that registration accuracy is improved relative to Moran's metric. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Huang, James L.; Rodriguez, Jeffrey J.] Univ Arizona, Dept Elect & Comp Engn, Tucson, AZ 85721 USA.
C3 University of Arizona
RP Huang, JL (corresponding author), Univ Arizona, Dept Elect & Comp Engn, 1230 E Speedway Blvd, Tucson, AZ 85721 USA.
EM liangchh@email.arizona.edu; jrod@ece.arizona.edu
CR Andronache A, 2005, LECT NOTES COMPUT SC, V3750, P976, DOI 10.1007/11566489_120
   Arsigny V, 2006, LECT NOTES COMPUT SC, V4057, P120
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Lee S., 2009, IEEE T VIS COMPUT GR, V36, P5467
   Likar B, 2001, IMAGE VISION COMPUT, V19, P33, DOI 10.1016/S0262-8856(00)00053-6
   Little JA, 1997, COMPUT VIS IMAGE UND, V66, P223, DOI 10.1006/cviu.1997.0608
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Periaswamy S, 2003, IEEE T MED IMAGING, V22, P865, DOI 10.1109/TMI.2003.815069
   Pitiot A, 2006, MED IMAGE ANAL, V10, P465, DOI 10.1016/j.media.2005.03.008
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Woo J, 2009, MED PHYS, V36, P5467, DOI 10.1118/1.3253301
   Zhuang XH, 2010, IEEE T MED IMAGING, V29, P1612, DOI 10.1109/TMI.2010.2047112
   Zhuang XH, 2008, LECT NOTES COMPUT SC, V5242, P425, DOI 10.1007/978-3-540-85990-1_51
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 14
TC 0
Z9 0
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 825
EP 834
DI 10.1016/j.imavis.2014.06.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900001
DA 2024-07-18
ER

PT J
AU Yan, JY
   Wang, FX
   Cao, XB
   Zhang, J
AF Yan, Jingyu
   Wang, Fuxiang
   Cao, Xianbin
   Zhang, Jun
TI Robust object tracking using least absolute deviation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object tracking; Sparse representation; Least absolute deviation
ID VISUAL TRACKING; RECOGNITION; SHRINKAGE
AB Recently, sparse representation has been applied to object tracking, where each candidate target is approximately represented as a sparse linear combination of target templates. In this paper, we present a new tracking algorithm, which is faster and more robust than other tracking algorithms, based on sparse representation. First, with an analysis of many typical tracking examples with various degrees of corruption, we model the corruption as a Laplacian distribution. Then, a LAD-Lasso optimisation model is proposed based on Bayesian Maximum A Posteriori (MAP) estimation theory. Compared with L1 Tracker and APG-L1 Tracker, the number of optimisation variables is reduced greatly; it is equal to the number of target templates, regardless of the dimensions of the feature. Finally, we use the Alternating Direction Method of Multipliers (ADMM) to solve the proposed optimisation problem. Experiments on some challenging sequences demonstrate that our proposed method performs better than the state-of-the-art methods in terms of accuracy and robustness. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Yan, Jingyu; Wang, Fuxiang; Cao, Xianbin; Zhang, Jun] Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Wang, FX (corresponding author), Beijing Univ Aeronaut & Astronaut, Sch Elect & Informat Engn, Xueyuan Rd 37, Beijing 100083, Peoples R China.
EM yan_jy@163.com; wangfx@buaa.edu.cn; xbcao@buaa.edu.cn;
   buaazhangjun@vip.sina.com
CR [Anonymous], 2008, SIAM J OPTIM
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Boyd Stephen, 2004, LIEVEN VANDENBERGHE
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Figueiredo M. A., 2001, PROC 14 INT C NEURAL, P697
   Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Loza A, 2009, MACH VISION APPL, V20, P71, DOI 10.1007/s00138-007-0107-x
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang HS, 2007, J BUS ECON STAT, V25, P347, DOI 10.1198/073500106000000251
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang AY, 2010, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP.2010.5651522
   Yang JF, 2011, SIAM J SCI COMPUT, V33, P250, DOI 10.1137/090777761
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
   [No title captured]
NR 33
TC 7
Z9 7
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 930
EP 939
DI 10.1016/j.imavis.2014.08.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900010
OA Bronze
DA 2024-07-18
ER

PT J
AU Bonarrigo, F
   Signoroni, A
AF Bonarrigo, Francesco
   Signoroni, Alberto
TI Global registration of large collections of range images with an
   improved Optimization-on-a-Manifold approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Global registration; 3D scanning; Range images; Correspondence
   selection; Newton-type optimization; Differential geometry
ID MULTIVIEW REGISTRATION; 3D
AB Concurrently obtaining an accurate, robust and fast global registration of multiple 3D scans is still an open issue for modern 3D modeling pipelines, especially when high metric precision as well as easy usage of high-end devices (structured-light or laser scanners) are required. Various solutions have been proposed (either heuristic, iterative and/or closed form solutions) which present some compromise concerning the fulfillment of the above contrasting requirements. Our purpose here, compared to existing reference solutions, is to go a step further in this perspective by presenting a new technique able to provide improved alignment performance, even on large datasets (both in terms of number of views and/or point density) of range images. Relying on the 'Optimization-on-a-Manifold' (OOM) approach, originally proposed by Krishnan et al., we propose a set of methodological and computational upgrades that produce an operative impact on both accuracy, robustness and computational performance compared to the original solution. In particular, always basing on an unconstrained error minimization over the manifold of rotations, instead of relying on a static set of point correspondences, our algorithm updates the optimization iterations with a dynamically modified set of correspondences in a computationally effective way, leading to substantial improvements in terms of registration accuracy and convergence trend. Other proposed improvements are directed to a substantial reduction of the computational load without sacrificing the alignment performance. Stress tests with increasing view misalignment allowed us to appreciate the convergence robustness of the proposed solution. Eventually, we demonstrate that for very large datasets a further computational speedup can be reached by the adoption of a hybrid (local heuristic followed by global optimization) registration approach. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Bonarrigo, Francesco; Signoroni, Alberto] Univ Brescia, DII, Dept Informat Engn, I-25123 Brescia, Italy.
C3 University of Brescia
RP Signoroni, A (corresponding author), Univ Brescia, DII, Dept Informat Engn, Via Branze 38, I-25123 Brescia, Italy.
EM alberto.signoroni@ing.unibs.it
RI Signoroni, Alberto/U-6789-2019; Signoroni, Alberto/I-4313-2012
CR Benjemaa R., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P34, DOI 10.1007/BFb0054732
   Benjemaa R, 1999, IMAGE VISION COMPUT, V17, P113, DOI 10.1016/S0262-8856(98)00115-2
   Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   Bernardini F, 2002, COMPUT GRAPH FORUM, V21, P149, DOI 10.1111/1467-8659.00574
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574
   Bonarrigo F., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P350, DOI 10.1109/3DIMPVT.2011.51
   Bonarrigo F, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-148
   Borrmann D, 2008, ROBOT AUTON SYST, V56, P130, DOI 10.1016/j.robot.2007.07.002
   Breitenreicher D, 2011, INT J COMPUT VISION, V92, P32, DOI 10.1007/s11263-010-0401-3
   Breitenreicher D, 2009, LECT NOTES COMPUT SC, V5681, P274, DOI 10.1007/978-3-642-03641-5_21
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Cunnington S. J., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P234
   Eggert DW, 1998, COMPUT VIS IMAGE UND, V69, P253, DOI 10.1006/cviu.1998.0667
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X
   Ikemoto L, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P434, DOI 10.1109/IM.2003.1240279
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kriegman D. J, 1994, MINIMIZATION LIE GRO
   Krishnan Shankar, 2007, International Journal of Intelligent Systems Technologies and Applications, V3, P319, DOI 10.1504/IJISTA.2007.014267
   Krishnan S., 2005, 3 EUR S GEOM PROC
   Lee P., 2005, THESIS AUSTR NATL U
   Liu YH, 2010, IEEE T PATTERN ANAL, V32, P12, DOI 10.1109/TPAMI.2008.280
   MASUDA T, 1995, COMPUT VIS IMAGE UND, V61, P295, DOI 10.1006/cviu.1995.1024
   Mitra N.J., 2004, Symposium on Geometry Processing, P23
   Neugebauer P. J., 1997, International Journal of Shape Modeling, V3, P71, DOI 10.1142/S0218654397000070
   Park SY, 2003, PATTERN RECOGN LETT, V24, P2967, DOI 10.1016/S0167-8655(03)00157-0
   Pennec X., 1996, 16 LEEDS ANN STAT WO, P178
   Pezzotti N, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P89, DOI 10.1109/3DIMPVT.2012.32
   Pottmann H, 2004, COMPUT VIS IMAGE UND, V95, P54, DOI 10.1016/j.cviu.2004.04.002
   Pottmann H., 2001, SIMULTANEOUS REGISTR
   Pottmann H, 2006, INT J COMPUT VISION, V67, P277, DOI 10.1007/s11263-006-5167-2
   Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346
   Raja V, 2008, SPRINGER SER ADV MAN, P1, DOI 10.1007/978-1-84628-856-2_1
   Rueckert D, 2011, BIOL MED PHYS BIOMED, P131, DOI 10.1007/978-3-642-15816-2_5
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sharp GC, 2004, IEEE T PATTERN ANAL, V26, P1037, DOI 10.1109/TPAMI.2004.49
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   Silva L, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P268, DOI 10.1109/IM.2003.1240259
   Stoddart A. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P40, DOI 10.1109/ICPR.1996.546720
   Stoddart AJ, 1998, IMAGE VISION COMPUT, V16, P111, DOI 10.1016/S0262-8856(97)00059-0
   Torsello A., 2011, COMP VIS PATT REC CV, P2441
   Vrubel A, 2009, PROC CVPR IEEE, P2679
   Wand Michael, 2007, P 5 EUR S GEOM PROC, P49
   Williams J, 2001, COMPUT VIS IMAGE UND, V81, P117, DOI 10.1006/cviu.2000.0884
NR 45
TC 3
Z9 4
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2014
VL 32
IS 6-7
BP 437
EP 451
DI 10.1016/j.imavis.2014.02.012
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AJ4QM
UT WOS:000337660900006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gunes, H
   Schuller, B
AF Gunes, Hatice
   Schuller, Bjoern
TI Categorical and dimensional affect analysis in continuous input: Current
   trends and future directions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic affect analysis; Continuous input; Multiple modalities;
   Categorical affect description; Dimensional affect description; Survey
ID PLEASURE-AROUSAL-DOMINANCE; EMOTION RECOGNITION; FACIAL EXPRESSION;
   POSTURES; FRAMEWORK; NETWORKS; BEHAVIOR; VALENCE; MOTION; MEMORY
AB In the context of affective human behavior analysis, we use the term continuous input to refer to naturalistic settings where explicit or implicit input from the subject is continuously available, where in a human-human or human-computer interaction setting, the subject plays the role of a producer of the communicative behavior or the role of a recipient of the communicative behavior. As a result, the analysis and the response provided by the automatic system are also envisioned to be continuous over the course of time, within the boundaries of digital machine output. The term continuous affect analysis is used as analysis that is continuous in time as well as analysis that uses affect phenomenon represented in dimensional space. The former refers to acquiring and processing long unsegmented recordings for detection of an affective state or event (e.g., nod, laughter, pain), and the latter refers to prediction of an affect dimension (e.g., valence, arousal, power). In line with the Special Issue on Affect Analysis in Continuous Input, this survey paper aims to put the continuity aspect of affect under the spotlight by investigating the current trends and provide guidance towards possible future directions. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Gunes, Hatice] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England.
   [Schuller, Bjoern] Tech Univ Munich, Inst Human Machine Commun, D-80290 Munich, Germany.
C3 University of London; Queen Mary University London; Technical University
   of Munich
RP Gunes, H (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England.
EM hatice@eecs.qmul.ac.uk
RI Schuller, Björn Wolfgang/D-3241-2011
OI Schuller, Björn Wolfgang/0000-0002-6478-8699
CR Alvarado N, 1997, MOTIV EMOTION, V21, P323, DOI 10.1023/A:1024484306654
   [Anonymous], 2011, AFFECTIVE COMPUTING
   [Anonymous], 2006, P SPEECH PROSODY 3 I
   [Anonymous], P LREC WORKSH MULT C
   [Anonymous], P ACL UPPS SWED
   [Anonymous], J SYNTH EMOTIONS
   [Anonymous], 2009, PROC 1 BIOSENS TECHN
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], PHONETICS LAUGHING
   [Anonymous], 1953, KATHIMERINI
   [Anonymous], 2012, INT J SYNTHETIC EMOT, DOI [10.4018/jse.2012010101, DOI 10.4018/jse.2012010101]
   [Anonymous], P IEEE INT C ENG MED
   [Anonymous], P MEAS BEH EINDH NET
   [Anonymous], 1985, COGNITIVE PSYCHOPHYS
   [Anonymous], P IEEE INT S CONS EL
   [Anonymous], P COGN TECHN
   [Anonymous], 2007, LNAI
   [Anonymous], P AFF BRAIN COMP INT
   [Anonymous], 2009, An introduction to seismology, earthquakes and Earth structure
   [Anonymous], 2007, ICWSM
   [Anonymous], ADV EMOTION RECOGNIT
   [Anonymous], LAB REAL WORLD AFFEC
   [Anonymous], 2011, P ANN C INT SPEECH C
   [Anonymous], P INT C BOD AR NETW
   [Anonymous], 2006, Proceedings of Fechner Day
   [Anonymous], 2011, IEEE T AFFECTIVE COM
   [Anonymous], 2006, P 8 INT C MULT INT, DOI [10.1145/1180995.1181029, DOI 10.1145/1180995.1181029]
   [Anonymous], P 16 EUR SIGN PROC C
   [Anonymous], P ACII 2011 AFF BRAI
   [Anonymous], 2000, SpeechEmotion-2000
   [Anonymous], THESIS U SAARLAND GE
   [Anonymous], BLUEPRINT AFFECTIVE
   [Anonymous], P INT WORKSH OP MIN
   [Anonymous], P AFF COMP INT INT W
   [Anonymous], BODILY EXPRESSION AU
   [Anonymous], BIMODAL EMOTION RECO
   [Anonymous], AUDITORY CORRELATES
   [Anonymous], P IEEE CVPR WORKSH G
   [Anonymous], 2010, PROC LREC INT WORKSH
   Arifin S, 2008, IEEE T MULTIMEDIA, V10, P1325, DOI 10.1109/TMM.2008.2004911
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Balahur A, 2011, LECT NOTES COMPUT SC, V6677, P611, DOI 10.1007/978-3-642-21111-9_69
   Baron-Cohen S, 1998, NATURE, V392, P459, DOI 10.1038/33076
   Baron-Cohen S., 2003, Mind Reading: The interactive guide to emotion
   Batliner A, 2011, COMPUT SPEECH LANG, V25, P4, DOI 10.1016/j.csl.2009.12.003
   Beck A, 2010, 2010 IEEE RO-MAN, P464, DOI 10.1109/ROMAN.2010.5598649
   Bermejo S, 2001, NEURAL NETWORKS, V14, P1447, DOI 10.1016/S0893-6080(01)00106-X
   Berntson GG, 1997, PSYCHOPHYSIOLOGY, V34, P623, DOI 10.1111/j.1469-8986.1997.tb02140.x
   Brugman H., 2004, 4 INT C LANG RES EV
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Cambria E, 2010, LECT NOTES ARTIF INT, V6279, P385, DOI 10.1007/978-3-642-15384-6_41
   Caridakis G, 2008, NEUROCOMPUTING, V71, P2553, DOI 10.1016/j.neucom.2007.11.043
   Carver CS, 2003, COGNITION EMOTION, V17, P241, DOI 10.1080/02699930302294
   Chanel G, 2007, IEEE SYS MAN CYBERN, P375
   Chanel G, 2009, INT J HUM-COMPUT ST, V67, P607, DOI 10.1016/j.ijhcs.2009.03.005
   Chen M, 1999, PERS SOC PSYCHOL B, V25, P215, DOI 10.1177/0146167299025002007
   Cohn JF, 2010, IEEE SIGNAL PROC MAG, V27, P128, DOI 10.1109/MSP.2010.938102
   Cohn JF, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P129, DOI 10.1109/AFGR.2004.1301520
   Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Cowie R., 2010, Proc. of LREC Int. Workshop on Emotion, P42
   Cowie R., 2000, PROC ISCA WORKSHOP S, P19
   Dael N, 2012, J NONVERBAL BEHAV, V36, P97, DOI 10.1007/s10919-012-0130-0
   DAVIDSON RJ, 1982, SCIENCE, V218, P1235, DOI 10.1126/science.7146906
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Ekman P., 2003, UNMASKING FACE GUIDE
   Epps J, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-15
   Espinosa H. P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P786, DOI 10.1109/FG.2011.5771349
   Eyben F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P322, DOI 10.1109/FG.2011.5771417
   Eyben F, 2010, ADV HUM-COMPUT INTER, V2010, DOI 10.1155/2010/263593
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Faghihi U, 2009, IA 2009: IEEE SYMPOSIUM ON INTELLIGENT AGENTS, P23
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Forbes-Riley K, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P201
   Forster J, 1996, J PERS SOC PSYCHOL, V71, P421, DOI 10.1037/0022-3514.71.3.421
   Frantzidis CA, 2010, IEEE T INF TECHNOL B, V14, P309, DOI 10.1109/TITB.2009.2038481
   Frijda N., 1986, EMOTIONS
   Gilroy S.W., 2009, P 3 INT C AFFECTIVE, P1
   Glowinski D., 2008, PROC COMPUTER VISION, P1
   Glowinski D, 2011, IEEE T AFFECT COMPUT, V2, P106, DOI 10.1109/T-AFFC.2011.7
   Grandjean D, 2008, CONSCIOUS COGN, V17, P484, DOI 10.1016/j.concog.2008.03.019
   Gratch J, 2010, IEEE T AFFECT COMPUT, V1, P1, DOI 10.1109/T-AFFC.2010.11
   Grimm M, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P381
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Grundlehner B, 2009, SIXTH INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P156, DOI [10.1109/BSN.2009.21, 10.1109/P3644.20]
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Gunes Hatice, 2010, International Journal of Strategic Synthetic Emotions, V1, P68, DOI 10.4018/jse.2010101605
   Gunes H, 2010, LECT NOTES ARTIF INT, V6356, P371, DOI 10.1007/978-3-642-15892-6_39
   Gunes H, 2009, IEEE T SYST MAN CY B, V39, P64, DOI 10.1109/TSMCB.2008.927269
   Haag A, 2004, LECT NOTES COMPUT SC, V3068, P36
   Healey J, 2011, LECT NOTES COMPUT SC, V6974, P107, DOI 10.1007/978-3-642-24600-5_14
   Heger D, 2011, LECT NOTES COMPUT SC, V6975, P436, DOI 10.1007/978-3-642-24571-8_56
   Hillman CH, 2004, BIOL PSYCHOL, V66, P51, DOI 10.1016/j.biopsycho.2003.07.005
   Hoque M., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P354, DOI 10.1109/FG.2011.5771425
   Huang TS, 2009, IEEE SIGNAL PROC MAG, V26, P67, DOI 10.1109/MSP.2009.932562
   HUTTAR GL, 1968, J SPEECH HEAR RES, V11, P481, DOI 10.1044/jshr.1103.481
   Inderbitzin Martin, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P809, DOI 10.1109/FG.2011.5771353
   Ioannou SV, 2005, NEURAL NETWORKS, V18, P423, DOI 10.1016/j.neunet.2005.03.004
   Janssen D, 2008, J NONVERBAL BEHAV, V32, P79, DOI 10.1007/s10919-007-0045-3
   Jia J, 2011, IEEE T AUDIO SPEECH, V19, P570, DOI 10.1109/TASL.2010.2052246
   Kaernbach Christian, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P792, DOI 10.1109/FG.2011.5771350
   Karg M, 2010, 2010 IEEE RO-MAN, P258, DOI 10.1109/ROMAN.2010.5598640
   Karg M, 2010, IEEE T SYST MAN CY B, V40, P1050, DOI 10.1109/TSMCB.2010.2044040
   Kessens J., 2009, P 3 INT C AFFECTIVE, P1
   Khan MM, 2006, 2006 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1 AND 2, P1
   Khosrowabadi Reza, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4242, DOI 10.1109/ICPR.2010.1031
   Kierkels JJM, 2009, IEEE INT CON MULTI, P1436, DOI 10.1109/ICME.2009.5202772
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Kipp M., 2009, 2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, P1, DOI DOI 10.1109/ACII.2009.5349544
   Kipp M., 2001, Proceedings of the European Conference on Speech Communication and Technology, P1367
   Kleinsmith A, 2005, LECT NOTES ARTIF INT, V3538, P50
   Kleinsmith A, 2007, LECT NOTES COMPUT SC, V4738, P48, DOI 10.1007/978-3-540-74889-2_5
   Kleinsmith A, 2011, IEEE T SYST MAN CY B, V41, P1027, DOI 10.1109/TSMCB.2010.2103557
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kulic D, 2007, IEEE T ROBOT, V23, P991, DOI 10.1109/TRO.2007.904899
   Labov W., 1984, Field methods on the Project of Linguistic Change and Variation, P28
   Laurans Gael., 2009, Affective Computing and Intelligent Interaction and Workshops, P1
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Littlewort Gwen C., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P30, DOI 10.1109/FG.2011.5771418
   Liu C, 2005, IEEE INT CONF ROBOT, P3262, DOI 10.1109/ROBOT.2005.1570613
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525
   Matsumoto K, 2011, COMPUT HUM BEHAV, V27, P1553, DOI 10.1016/j.chb.2010.10.028
   McDuff D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), P17, DOI [DOI 10.1109/CVPRW.2010.5543833, 10.1109/CVPRW.2010.5543833]
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   Meeren HKM, 2005, P NATL ACAD SCI USA, V102, P16518, DOI 10.1073/pnas.0507650102
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Merla A, 2007, P ANN INT IEEE EMBS, P247, DOI 10.1109/IEMBS.2007.4352270
   Metallinou A, 2011, INT CONF ACOUST SPEE, P2288
   Metze F, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P478
   Mihelj M, 2009, 2009 VIRTUAL REHABILITATION INTERNATIONAL CONFERENCE, P160, DOI 10.1109/ICVR.2009.5174225
   Mortillaro M., 2012, International Journal of Synthetic Emotions, V3, P18, DOI DOI 10.4018/JSE.2012010102
   Nakasone Arturo., 2005, Proc. of the 5th International Workshop on Biosignal Interpretation, P219
   Nhan BR, 2010, IEEE T BIO-MED ENG, V57, P979, DOI 10.1109/TBME.2009.2035926
   Nicolaou Mihalis A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P16, DOI 10.1109/FG.2011.5771396
   Nicolaou Mihalis A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3695, DOI 10.1109/ICPR.2010.900
   Nicolaou M.A., 2011, Proceedings of the 19th ACM international conference on Multimedia, P933
   Pantic Maja, 2008, International Journal of Automomous and Adaptive Communications Systems, V1, P168, DOI 10.1504/IJAACS.2008.019799
   Pantic M., 2007, FACE RECOGNITION, P377
   Espinosa HP, 2010, INT CONF ACOUST SPEE, P5138, DOI 10.1109/ICASSP.2010.5495031
   Pfister T, 2011, IEEE T AFFECT COMPUT, V2, P66, DOI 10.1109/T-AFFC.2011.8
   Picard RW, 2009, PHILOS T R SOC B, V364, P3575, DOI 10.1098/rstb.2009.0143
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Pun T, 2006, IEEE T NEUR SYS REH, V14, P210, DOI 10.1109/TNSRE.2006.875544
   Rehm M, 2005, LECT NOTES COMPUT SC, V3711, P180
   Roseman I.J., 2001, Appraisal processes in emotion: Theory, method, research, P3
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Salah AA, 2011, IEEE T AFFECT COMPUT, V2, P64, DOI 10.1109/T-AFFC.2011.16
   Sander D, 2005, NEURAL NETWORKS, V18, P317, DOI 10.1016/j.neunet.2005.03.001
   Sanghvi J, 2011, ACMIEEE INT CONF HUM, P305, DOI 10.1145/1957656.1957781
   Scherer K.R., 1977, Motivation and Emotion, V1, P331, DOI DOI 10.1007/BF00992539
   Schroder M., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), DOI 10.1109/FG.2011.5771472
   Schroder M., 2012, IEEE Trans. Affec- tive Comput., P1
   Schroder M., 2009, INT C AFFECTIVE COMP, P263
   Schröder M, 2010, ADV HUM-COMPUT INTER, V2010, DOI 10.1155/2010/319406
   Schuller B, 2012, IEEE T AFFECT COMPUT, V3, P3, DOI 10.1109/T-AFFC.2012.10
   Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2798
   Schuller B, 2012, INT CONF ACOUST SPEE, P341, DOI 10.1109/ICASSP.2012.6287886
   Schuller B, 2011, LECT NOTES COMPUT SC, V6975, P415, DOI 10.1007/978-3-642-24571-8_53
   Schuller B, 2011, IEEE T AFFECT COMPUT, V2, P192, DOI 10.1109/T-AFFC.2011.17
   Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P801
   Schuller B, 2011, LECT NOTES COMPUT SC, V6456, P448, DOI 10.1007/978-3-642-18184-9_39
   Schuller B, 2010, INT CONF ACOUST SPEE, P5150, DOI 10.1109/ICASSP.2010.5495017
   Schuller B, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P552, DOI 10.1109/ASRU.2009.5372886
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336
   Schuller B, 2009, IMAGE VISION COMPUT, V27, P1760, DOI 10.1016/j.imavis.2009.02.013
   Schuller B, 2011, SPEECH COMMUN, V53, P1059, DOI 10.1016/j.specom.2011.07.003
   Schuller B, 2011, SPEECH COMMUN, V53, P1062, DOI 10.1016/j.specom.2011.01.011
   Sezgin M. C., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P780, DOI 10.1109/FG.2011.5771348
   Sneddon I, 2012, IEEE T AFFECT COMPUT, V3, P32, DOI 10.1109/T-AFFC.2011.26
   Snel J., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P835, DOI 10.1109/FG.2011.5771358
   Soleymani M., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P803, DOI 10.1109/FG.2011.5771352
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Strapparava C, 2010, STUD COMPUT INTELL, V301, P21
   Subrahmanian VS, 2008, IEEE INTELL SYST, V23, P43, DOI 10.1109/MIS.2008.57
   Sun K, 2009, IEEE INT CON MULTI, P566, DOI 10.1109/ICME.2009.5202559
   Sun XF, 2011, LECT NOTES COMPUT SC, V6975, P289, DOI 10.1007/978-3-642-24571-8_32
   Sun XF, 2011, LECT NOTES COMPUT SC, V6974, P367, DOI 10.1007/978-3-642-24600-5_40
   Taleb T, 2010, IEEE T INF TECHNOL B, V14, P335, DOI 10.1109/TITB.2010.2042608
   Tarasov A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P841, DOI 10.1109/FG.2011.5771359
   Tsai TC, 2009, MDM: 2009 10TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P430, DOI 10.1109/MDM.2009.78
   Tsiamyrtzis P, 2007, INT J COMPUT VISION, V71, P197, DOI 10.1007/s11263-006-6106-y
   Van den Stock J, 2007, EMOTION, V7, P487, DOI 10.1037/1528-3542.7.3.487
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Wang P., 2006, Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, V2, P1566
   Wassermann KC, 2003, IEEE MULTIMEDIA, V10, P82, DOI 10.1109/MMUL.2003.1237553
   Whitehill J., 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P20, DOI 10.1109/CVPRW.2011.5981778
   Wöllmer M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2362
   Wöllmer M, 2010, IEEE J-STSP, V4, P867, DOI 10.1109/JSTSP.2010.2057200
   Wöllmer M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P597
   Xunbing Shen, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P1989, DOI 10.1109/ICNC.2010.5584720
   Yang YH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P208
   Yoshitomi Y, 2000, IEEE RO-MAN 2000: 9TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P178, DOI 10.1109/ROMAN.2000.892491
   Yu Chen., 2004, In Proc. 8th International Conference on Spoken Language Processing (ICSLP 2004), P1329
   Zander TO, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025005
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zixing Zhang, 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P523, DOI 10.1109/ASRU.2011.6163986
NR 202
TC 229
Z9 246
U1 1
U2 50
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2013
VL 31
IS 2
BP 120
EP 136
DI 10.1016/j.imavis.2012.06.016
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 102KN
UT WOS:000315843600003
DA 2024-07-18
ER

PT J
AU Li, XL
   Da, FP
AF Li, Xiaoli
   Da, Feipeng
TI Efficient 3D face recognition handling facial expression and hair
   occlusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face recognition; Facial curves; Rejection classifier; Adaptive
   region selection scheme
AB This paper presents an efficient 3D face recognition method to handle facial expression and hair occlusion. The proposed method uses facial curves to form a rejection classifier and produce a facial deformation mapping and then adaptively selects regions for matching. When a new 3D face with an arbitrary pose and expression is queried, the pose is normalized based on the automatically detected nose tip and the principal component analysis (PCA) follows. Then, the facial curve in the nose region is extracted and used to form the rejection classifier which quickly eliminates dissimilar faces in the gallery for efficient recognition. Next, six facial regions which cover the face are segmented and curves in these regions are used to map facial deformation. Regions used for matching are automatically selected based on the deformation mapping. In the end, results of all the matching engines are fused by weighted sum rule. The approach is applied on the FRGC v2.0 dataset and a verification rate of 96.0% for ROC III is achieved as a false acceptance rate (FAR) of 0.1%. In the identification scenario, a rank-one accuracy of 97.8% is achieved. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Da, Feipeng] Southeast Univ, Res Inst Automat, Minist Educ, Key Lab Measurement & Control Complex Syst, Nanjing 210096, Jiangsu, Peoples R China.
   [Li, Xiaoli] Shanghai Municipal Elect Power Co, Training Ctr, Shanghai 200438, Peoples R China.
C3 Southeast University - China
RP Da, FP (corresponding author), Southeast Univ, Res Inst Automat, Minist Educ, Key Lab Measurement & Control Complex Syst, Nanjing 210096, Jiangsu, Peoples R China.
EM lixiaoli@seu.edu.cn; dafp@seu.edu.cn
RI Li, Xiaoli/GYQ-7384-2022
FU National Natural Science Foundation of China [51175081]; Jiangsu Natural
   Science Foundation [BK2010058]; Mass Innovation Foundation of Shanghai
   Municipal Electrical Power Company, China [52097012000A-2]
FX The authors would like to thank the FRGC organizers and Zhejiang
   University for providing the face datas. This research is sponsored by
   the National Natural Science Foundation of China (Grant No. 51175081),
   Jiangsu Natural Science Foundation (Grant No. BK2010058), and the Mass
   Innovation Foundation of Shanghai Municipal Electrical Power Company,
   China (Grant No. 52097012000A-2).
CR Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0
   Alyuz N., 2008, 2 IEEE INT C BIOM TH, P1, DOI DOI 10.1109/BTAS.2008.4699389
   [Anonymous], ICASSP 06
   Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Bronstein AM, 2007, IEEE T IMAGE PROCESS, V16, P188, DOI 10.1109/TIP.2006.884940
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Cook J, 2007, LECT NOTES COMPUT SC, V4642, P271
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Green M. A., 2003, P INT SUP EL C, P1
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Li C.-J., 2006, INT THERMAL SPRAY C, P1, DOI [DOI 10.1109/ICARCV.2006.345357, 10.1109/ICARCV.2006.345357]
   Lin T.H., 2007, IMAGE VISION COMPUT, V28, P1
   Lu XG, 2008, IEEE T PATTERN ANAL, V30, P1346, DOI 10.1109/TPAMI.2007.70784
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Ocegueda O, 2011, PROC CVPR IEEE, P641, DOI 10.1109/CVPR.2011.5995613
   Pan G, 2005, P WORKSH APPL COMP V, P1
   Phillips P.J., 2006, P C COMP VIS PATT RE, P947
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   ter Haar FB, 2009, GRAPH MODELS, V71, P77, DOI 10.1016/j.gmod.2008.12.003
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang YM, 2006, LECT NOTES COMPUT SC, V3851, P581
   Wang YS, 2007, ASIA PACIF MICROWAVE, P1, DOI 10.1109/IITA.2007.19
   Xiangfang Li., 2009, INT C E BUSINESS INF, P1, DOI DOI 10.1007/S00213-008-1432-0
   Zhang L, 2006, VISUAL COMPUT, V22, P43, DOI 10.1007/s00371-005-0352-9
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 31
TC 30
Z9 35
U1 0
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2012
VL 30
IS 9
BP 668
EP 679
DI 10.1016/j.imavis.2012.07.011
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 024EV
UT WOS:000310092600007
DA 2024-07-18
ER

PT J
AU Schwarz, LA
   Mkhitaryan, A
   Mateus, D
   Navab, N
AF Schwarz, Loren Arthur
   Mkhitaryan, Artashes
   Mateus, Diana
   Navab, Nassir
TI Human skeleton tracking from depth data using geodesic distances and
   optical flow
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Human pose estimation; Depth imaging; Geodesic distances
AB In this paper, we present a method for human full-body pose estimation from depth data that can be obtained using Time of Flight (ToF) cameras or the Kinect device. Our approach consists of robustly detecting anatomical landmarks in the 3D data and fitting a skeleton body model using constrained inverse kinematics. Instead of relying on appearance-based features for interest point detection that can vary strongly with illumination and pose changes, we build upon a graph-based representation of the depth data that allows us to measure geodesic distances between body parts. As these distances do not change with body movement, we are able to localize anatomical landmarks independent of pose. For differentiation of body parts that occlude each other, we employ motion information, obtained from the optical flow between subsequent intensity images. We provide a qualitative and quantitative evaluation of our pose tracking method on ToF and Kinect sequences containing movements of varying complexity. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Schwarz, Loren Arthur; Mkhitaryan, Artashes; Mateus, Diana; Navab, Nassir] Tech Univ Munich, Dept Informat, D-85748 Garching, Germany.
C3 Technical University of Munich
RP Schwarz, LA (corresponding author), Tech Univ Munich, Dept Informat, Boltzmannstr 3, D-85748 Garching, Germany.
EM schwarz@in.tum.de
RI Mateus, Diana/ADQ-6247-2022
OI Mateus, Diana/0000-0002-2252-8717
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2010, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], 2011, IEEE C COMP VIS PATT
   Bandouch J., 2008, ARTICULATED MOTION D
   Bleiweiss A., 2009, ACM SIGGRAPH ASIA SK
   Denman S, 2007, PATTERN RECOGN LETT, V28, P1232, DOI 10.1016/j.patrec.2007.02.008
   Fossati A., 2009, IEEE C COMP VIS PATT
   Holte M.B., 2008, COMP VIS PATT REC WO
   Hu R., 2011, COMP VIS PATT REC WO
   Jaeggli T, 2009, INT J COMPUT VISION, V83, P121, DOI 10.1007/s11263-008-0158-0
   Jensen RR, 2009, LECT NOTES COMPUT SC, V5575, P21, DOI 10.1007/978-3-642-02230-2_3
   John V, 2010, IMAGE VISION COMPUT, V28, P1530, DOI 10.1016/j.imavis.2010.03.008
   Johnson R., 2011, ACM C COMP HUM INT C
   Kehl R, 2006, COMPUT VIS IMAGE UND, V104, P190, DOI 10.1016/j.cviu.2006.07.010
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Malassiotis S, 2008, IMAGE VISION COMPUT, V26, P1027, DOI 10.1016/j.imavis.2007.11.007
   Mortara M, 2006, COMPUT GRAPH-UK, V30, P185, DOI 10.1016/j.cag.2006.01.024
   Ning HZ, 2004, IMAGE VISION COMPUT, V22, P429, DOI 10.1016/j.imavis.2004.01.001
   O'Brien JF, 2000, PROC GRAPH INTERF, P53
   Okada R., 2000, IEEE INT C AUT FAC G
   PrimeSense Inc., NITE MIDDL
   Schwarz LA, 2011, IEEE C AUT FAC GEST, P700
   Soutschek Stefan, 2008, COMP VIS PATT REC WO
   Srebrny P, 2010, INT CON DISTR COMP S, DOI 10.1109/ICDCS.2010.29
   Zhu Y., 2008, COMP VIS PATT REC WO
   Zhu YD, 2010, SENSORS-BASEL, V10, P5280, DOI 10.3390/s100505280
NR 29
TC 128
Z9 147
U1 2
U2 44
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 217
EP 226
DI 10.1016/j.imavis.2011.12.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000010
OA Green Published
DA 2024-07-18
ER

PT J
AU Bao, SY
   Sun, M
   Savarese, S
AF Bao, Sid Yingze
   Sun, Min
   Savarese, Silvio
TI Toward coherent object detection and scene layout understanding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Scene layout; Focal length estimation; Supporting
   surface estimation
AB Detecting objects in complex scenes while recovering the scene layout is a critical functionality in many vision-based applications. In this work, we advocate the importance of geometric contextual reasoning for object recognition. We start from the intuition that objects' location and pose in the 3D space are not arbitrarily distributed but rather constrained by the fact that objects must lie on one or multiple supporting surfaces. We model such supporting surfaces by means of hidden parameters (i.e. not explicitly observed) and formulate the problem of joint scene reconstruction and object recognition as the one of finding the set of parameters that maximizes the joint probability of having a number of detected objects on K supporting planes given the observations. As a key ingredient for solving this optimization problem, we have demonstrated a novel relationship between object location and pose in the image, and the scene layout parameters (i.e. normal of one or more supporting planes in 3D and camera pose, location and focal length). Using a novel probabilistic formulation and the above relationship our method has the unique ability to jointly: i) reduce false alarm and false negative object detection rate; ii) recover object location and supporting planes within the 3D camera reference system; iii) infer camera parameters (view point and the focal length) from just one single uncalibrated image. Quantitative and qualitative experimental evaluation on two datasets (desk-top dataset [1] and LabelMe [2]) demonstrates our theoretical claims. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Bao, Sid Yingze; Sun, Min; Savarese, Silvio] Univ Michigan, Ann Arbor, MI 48105 USA.
C3 University of Michigan System; University of Michigan
RP Bao, SY (corresponding author), Univ Michigan, Ann Arbor, MI 48105 USA.
EM yingze@umich.edu; sunmin@umich.edu; silvio@eecs.umich.edu
RI Bao, Yingze/G-1686-2014
FU NSF [CNS 0931474]; Gigascale Systems Research Center; Focus Center
   Research Program (FCRP)
FX We acknowledge the support of NSF (Grant CNS 0931474) and the Gigascale
   Systems Research Center, one of six research centers funded under the
   Focus Center Research Program (FCRP), a Semiconductor Research
   Corporation entity.
CR [Anonymous], 2010, ECCV
   [Anonymous], 1978, COMPUTER VISION SYST
   [Anonymous], 2000, CVPR
   [Anonymous], 2009, ICCV
   [Anonymous], 2008, ECCV
   [Anonymous], 2010, ECCV
   [Anonymous], 2006, CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2007, CVPR SHORT COURSE
   [Anonymous], 2009, ICCV
   [Anonymous], 2003, CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], 2009, ICCV
   [Anonymous], 2005, ICCV
   Arie-Nachimson M., 2009, ICCV
   Bao S. Y.-Z., 2010, CVPR
   BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X
   BIEDERMAN I, 1981, PERCEPTUAL ORG, pCH8
   BROOKS RA, 1981, IJCIA
   Cornelis N, 2008, INT J COMPUT VISION, V78, P121, DOI 10.1007/s11263-007-0081-9
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   FORSYTH DA, 1994, CVPR
   Hanson A.R., 1978, COMPUTER VISION SYST
   HEDAU V, 2009, ECCV
   Hoiem D., 2008, CVPR
   LEIBE B, 2004, DAGM ANN PATT REC S
   Ohta Y., 1985, KNOWLEDGE BASED INTE
   Ozuysal M., 2009, CVPR
   Palmer S., 1999, VISION SCI PHOTONS P
   Payet Nadia., 2011, CVPR
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Savarese Silvio., 2007, ICCV
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Su H., 2009, ICCV
   Sudderth ErikB., 2006, CVPR
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]
NR 37
TC 16
Z9 22
U1 0
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2011
VL 29
IS 9
BP 569
EP 579
DI 10.1016/j.imavis.2011.08.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 836PI
UT WOS:000296123200001
DA 2024-07-18
ER

PT J
AU Lefebvre, S
   Ambellouis, S
   Cabestaing, F
AF Lefebvre, Sebastien
   Ambellouis, Sebastien
   Cabestaing, Francois
TI A 1D approach to correlation-based stereo matching
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Stereovision; Matching Process; Correlation; 1D Window; Fuzzy Logic;
   Confidence Map
ID ALGORITHM
AB In stereovision, indices allowing pixels of the left and right images to be matched are basically one-dimensional features of the epipolar lines. In some situations, these features are not significant or cannot be extracted from the single epipolar line. Therefore, many techniques use 2D neighbourhoods to increase the available information. In this paper, we discuss the systematic use of 2D neighbourhoods for stereo matching. We propose an alternative approach to stereo matching using multiple 1D correlation windows, which yields a semi-dense disparity map and an associated confidence map. A particular technique derived from this approach - using fuzzy filtering and a basic decision rule - is compared to about 80 other methods on the Middlebury image datasets [1]. Results are first presented in the framework of the Middlebury website, then on the Receiver Operating Characteristics (ROC) evaluation [2] and, finally, on stereo image pairs of slanted surfaces. We show that a 1D correlation window is sufficient to provide correct matchings in most cases. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Lefebvre, Sebastien; Ambellouis, Sebastien] LEOST, IFSTTAR, F-59666 Villeneuve Dascq, France.
   [Cabestaing, Francois] CNRS, LAGIS, UMR 8146, F-59666 Villeneuve Dascq, France.
   [Lefebvre, Sebastien; Ambellouis, Sebastien; Cabestaing, Francois] Univ Lille Nord France, F-59000 Lille, France.
C3 Universite Gustave-Eiffel; Universite de Lille; Centrale Lille; Centre
   National de la Recherche Scientifique (CNRS); Universite de Lille
RP Lefebvre, S (corresponding author), LEOST, IFSTTAR, F-59666 Villeneuve Dascq, France.
EM sebastien.lefebvre@ifsttar.fr; sebastien.ambellouis@ifsttar.fr;
   francois.cabestaing@univ-lille1.fr
RI Ambellouis, Sebastien/IAR-5073-2023
OI Ambellouis, Sebastien/0000-0002-3719-1934
CR [Anonymous], RR1369 INRIA
   [Anonymous], P 3 CAN C COMP ROB V
   [Anonymous], 1997, P BRIT MACHINE VISIO
   [Anonymous], EUR C COMP VIS SPRIN
   [Anonymous], INT C IM SIGN PROC T
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], THESIS U SCI TECHNOL
   [Anonymous], 9 AS C COMP VIS XIAN
   [Anonymous], IEEE WORKSH STER MUL
   [Anonymous], IEEE INT C COMP VIS
   Brockers R., 2005, Image and Vision Computing New Zealand (IVCNZ)
   Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040
   Egnal G, 2004, IMAGE VISION COMPUT, V22, P943, DOI 10.1016/j.imavis.2004.03.018
   Forstmann S., 2004, IEEE CVPR WORKSHOP R, P29
   Fusiello A, 2000, INT J PATTERN RECOGN, V14, P1053, DOI 10.1142/S0218001400000696
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Jawahar CV, 2002, PATTERN RECOGN, V35, P1303, DOI 10.1016/S0031-3203(01)00111-X
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Kim JC, 2005, PROC CVPR IEEE, P1075
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Kostkova J., 2003, BMVC Proc, P339
   Liang CK, 2009, PROC CVPR IEEE, P80, DOI 10.1109/CVPRW.2009.5206819
   Mayoral R, 2006, IMAGE VISION COMPUT, V24, P1288, DOI 10.1016/j.imavis.2006.04.006
   Mühlmann K, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P30, DOI 10.1109/SMBV.2001.988760
   Ogale AS, 2004, PROC CVPR IEEE, P568
   Okutomi M, 2002, INT J COMPUT VISION, V47, P261, DOI 10.1023/A:1014510328154
   Patricio MNP, 2004, IEEE IMAGE PROC, P1341, DOI 10.1109/ICIP.2004.1419747
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   Tombari F., 2008, Computer Vision and Pattern Recognition, P1
   Tombari F, 2007, LECT NOTES COMPUT SC, V4872, P427
   Veksler O, 2003, PROC CVPR IEEE, P556
   Wang L, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P798
   Yang Q., 2006, P 17 BRIT MACHINE VI, P989
   Yang Qingxiong., 2007, IEEE INT C COMPUTER
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Yu T., 2007, P 11 IEEE INT C COMP, P1
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 41
TC 5
Z9 5
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2011
VL 29
IS 9
BP 580
EP 593
DI 10.1016/j.imavis.2011.05.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 836PI
UT WOS:000296123200002
DA 2024-07-18
ER

PT J
AU Menezes, P
   Lerasle, F
   Dias, J
AF Menezes, Paulo
   Lerasle, Frederic
   Dias, Jorge
TI Towards human motion capture from a camera mounted on a mobile robot
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Data fusion; Particle filtering; Human motion capture;
   Assistant robot
ID TRACKING; FUSION
AB This article describes a multiple feature data fusion applied to a particle filter for marker-less human motion capture (HMC) by using a single camera devoted to an assistant mobile robot. Particle filters have proved to be well suited to this robotic context. Like numerous approaches, the principle relies on the projection of the model's silhouette of the tracked human limbs and appearance features located on the model surface, to validate the particles (associated configurations) which correspond to the best model-to-image fits. Our particle filter based HMC system is improved and extended in two ways. First, our estimation process is based on the so-called AUXILIARY scheme which has been surprisingly seldom exploited for tracking purpose. This scheme is shown to outperform conventional particle filters as it limits drastically the well-known burst in term of particles when considering high dimensional state-space. The second line of investigation concerns data fusion. Data fusion is considered both in the importance and measurement functions with some degree of adaptability depending on the current human posture and the environmental context encountered by the robot. Implementation and experiments on indoor sequences acquired by an assistant mobile robot highlight the relevance and versatility of our HMC system. Extensions are finally discussed. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Lerasle, Frederic] CNRS, LAAS, F-31077 Toulouse 4, France.
   [Menezes, Paulo; Dias, Jorge] Univ Coimbra, ISR, P-3030290 Coimbra, Portugal.
   [Lerasle, Frederic] Univ Toulouse, UPS, INSA, ISAE,UTI,UTM,LAAS, F-31077 Toulouse 4, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universidade de
   Coimbra; Universite de Toulouse; Institut Superieur de l'Aeronautique et
   de l'Espace (ISAE-SUPAERO); Universite Federale Toulouse Midi-Pyrenees
   (ComUE); Institut National des Sciences Appliquees de Toulouse;
   Universite Toulouse III - Paul Sabatier; Universite de Toulouse - Jean
   Jaures
RP Lerasle, F (corresponding author), CNRS, LAAS, 7 Ave Colonel Roche, F-31077 Toulouse 4, France.
EM lerasle@laas.fr
RI Dias, Jorge Miranda/A-1842-2011; Menezes, Paulo/A-3121-2011
OI Dias, Jorge Miranda/0000-0002-2725-8867; Menezes,
   Paulo/0000-0002-4903-3554
CR [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], J AM STAT ASS
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Azad P, 2007, IEEE INT CONF ROBOT, P3951, DOI 10.1109/ROBOT.2007.364085
   Delamarre Q, 2001, COMPUT VIS IMAGE UND, V81, P328, DOI 10.1006/cviu.2000.0892
   Deutscher J, 2001, PROC CVPR IEEE, P669
   Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758
   Deutscher J., 1999, INT C COMP VIS ICCV
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Gall J, 2008, COMPUT IMAGING VIS, V36, P319
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Geronimo D., 2010, T PATTERN ANAL MACHI, V28, P976
   Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396
   Hasler N., 2009, INT C COMP VIS PATT
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Isard M., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P893, DOI 10.1007/BFb0055711
   Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549
   JONES M, 1998, COLOR DETECTION, P11
   Knoop S, 2006, IEEE INT CONF ROBOT, P1686
   LEE MW, 2002, WORKSH MOT VID COMP
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   McKenna SJ, 2007, IMAGE VISION COMPUT, V25, P852, DOI 10.1016/j.imavis.2006.06.003
   Menezes P, 2005, IEEE-RAS INT C HUMAN, P430
   Menezes P., 2004, IFAC S INT AUT VEH L
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   MUTALI TM, 1998, THESIS BROWN U
   Nierverget J., 1982, COMMUN ACM, V25, P739
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Ramanan D., 2004, INT C COMP VIS PATT
   Rui Y, 2001, PROC CVPR IEEE, P786
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   SIGAL L, 2004, INT C COMP VIS PATT
   Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003
   Stenger B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1063
   Stenger B., 2001, British Machine Vision Conference, P63
   Sutherland I. E., 1974, Computing Surveys, V6, P1, DOI 10.1145/356625.356626
   TORMA P, 2003, AI STAT, P198
   Urtasun R., 2004, EUR C COMP VIS ECCV
   Xu X., 2007, INT C COMP VIS ICCV
   ZIEGLER J, 2006, INT C COMP VIS PATT
NR 42
TC 5
Z9 7
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2011
VL 29
IS 6
BP 382
EP 393
DI 10.1016/j.imavis.2011.01.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 761TD
UT WOS:000290423000002
DA 2024-07-18
ER

PT J
AU Lin, ZC
   Jiang, JS
   Wang, ZY
AF Lin, Zhengchun
   Jiang, Jinshan
   Wang, Zhiyan
TI Edge detection in the feature space
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Edge detection; Image processing; Image feature representation; Kernel
   principal component analysis; Subspace classification; Feature space
ID HYSTERESIS THRESHOLDS
AB To build a consistent image representation model which can process the non-Gaussian distribution data, a novel edge detection method (KPCA-SCF) based on the kernel method is proposed. KPCA-SCF combines kernel principal component analysis and kernel subspace classification proposed in this paper to extract edge features. KPCA-SCF was tested and compared with linear PCA, nonlinear PCA and conventional methods such as Sobel, LOG, Canny, etc. Experiments on synthetic and real-world images show that KPCA-SCF is more robust under noisy conditions. KPCA-SCF's score of F-measure (0.44) ranks 11th in the Berkeley segmentation dataset and benchmark, it (0.54) ranks 10th tested on a noised image. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Lin, Zhengchun] Foshan Inst Stand Technol, Dept Res & Dev, Foshan 528000, Guangdong, Peoples R China.
   [Jiang, Jinshan] S China Univ Technol, Sch Sci, Guangzhou 510640, Guangdong, Peoples R China.
   [Wang, Zhiyan] S China Univ Technol, Sch Comp & Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Lin, ZC (corresponding author), Foshan Inst Stand Technol, Dept Res & Dev, Foshan 528000, Guangdong, Peoples R China.
EM linzhengchun@gmail.com
RI cai, bo/G-1491-2010
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   [Anonymous], 1983, SUBSPACE METHODS PAT
   Berlemont S, 2010, IEEE T IMAGE PROCESS, V19, P74, DOI 10.1109/TIP.2009.2030968
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chin TJ, 2007, IEEE T IMAGE PROCESS, V16, P1662, DOI 10.1109/TIP.2007.896668
   Dikbas S, 2007, IEEE IMAGE PROC, P825
   DONY RD, 1995, IEEE T IMAGE PROCESS, V4, P1358, DOI 10.1109/83.465101
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Jiang W, 2009, IEEE T SYST MAN CY B, V39, P1036, DOI 10.1109/TSMCB.2008.2011646
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kwok JTY, 2004, IEEE T NEURAL NETWOR, V15, P1517, DOI 10.1109/TNN.2004.837781
   LIN Z, 2009, J S CHINA U TECHNOLO, P59
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   Márquez DA, 2007, INT CONF ACOUST SPEE, P581
   MARTIN D, 2002, NEUR INF PROC SYST C, P1255
   MARTIN D, 2001, IEEE COMPUTER SOC DA
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Medina-Carnicer R, 2010, IEEE T IMAGE PROCESS, V19, P165, DOI 10.1109/TIP.2009.2032942
   Medina-Carnicer R, 2009, PATTERN RECOGN, V42, P1284, DOI 10.1016/j.patcog.2008.10.027
   MINH NVD, 2007, 2007 IEEE INT S SIGN, P35
   Mu T, 2007, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P396
   Oja E, 1997, NEUROCOMPUTING, V17, P25, DOI 10.1016/S0925-2312(97)00045-3
   QIUMING C, 2007, 2007 IEEE INT GEOSC, P290
   Rosipal R, 2001, NEURAL COMPUT, V13, P505, DOI 10.1162/089976601300014439
   Saleem M, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P175
   Santhanam A, 2007, ICCTA 2007: INTERNATIONAL CONFERENCE ON COMPUTING: THEORY AND APPLICATIONS, PROCEEDINGS, P665
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shirazi SKG, 2009, COMPUT VIS IMAGE UND, V113, P556, DOI 10.1016/j.cviu.2009.01.001
   VONRIJSBERGEN CJ, 1979, INFORM RETRIEVAL
   XIANGYAN ZW, 2002, PATT REC 2002 P 16 I, V222, P228
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yao HB, 2003, IEEE T GEOSCI REMOTE, V41, P1469, DOI 10.1109/TGRS.2003.811691
   Yi S, 2009, IEEE T IMAGE PROCESS, V18, P929, DOI 10.1109/TIP.2009.2013082
   Zheng WM, 2005, NEURAL PROCESS LETT, V22, P49, DOI 10.1007/s11063-004-0036-x
NR 34
TC 8
Z9 9
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2011
VL 29
IS 2-3
BP 142
EP 154
DI 10.1016/j.imavis.2010.08.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 707NV
UT WOS:000286294200005
DA 2024-07-18
ER

PT J
AU Faille, F
   Petrou, M
AF Faille, Flore
   Petrou, Maria
TI Invariant image reconstruction from irregular samples and hexagonal grid
   splines
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image compression; Hexagonal grids; Image reconstruction; Hexagonal
   splines; Nonuniform sampling; Bio-inspired approaches
ID SCATTERED DATA INTERPOLATION; ALGORITHM
AB We present an algorithm for the reconstruction of images from irregularly placed samples, using linear splines with control points on a hexagonal grid. Several spline approximations are computed for different transformations of the control point grid (e.g. translations and rotations). These approximations are then merged together after compensation of the transformations, yielding a high-quality invariant image reconstruction. Evaluations show that the use of hexagonal grids of the "invariance by integration" principle improves reconstruction quality. An application to image coding is also presented. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Faille, Flore; Petrou, Maria] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
C3 Imperial College London
RP Petrou, M (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
EM maria.petrou@imperial.ac.uk
RI cai, bo/G-1491-2010
CR Altamirano LC, 2003, PATTERN RECOGN LETT, V24, P521, DOI 10.1016/S0167-8655(02)00274-X
   Amidror I, 2002, J ELECTRON IMAGING, V11, P157, DOI 10.1117/1.1455013
   Andersson K, 2007, SIGNAL PROCESS, V87, P353, DOI 10.1016/j.sigpro.2006.04.011
   [Anonymous], 1988, Eye, brain, and vision
   Arigovindan M, 2005, IEEE T IMAGE PROCESS, V14, P450, DOI 10.1109/TIP.2004.841203
   ASAHI T, 2003, P ICIP 03
   BHARATH A, 2001, NEXT GENERATION ARTI
   BOSCH JG, 2005, P 2005 IEEE ULTR S
   Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193
   FAILLE F, 2008, P BMVC
   Galic I, 2005, LECT NOTES COMPUT SC, V3752, P37
   Galíc I, 2008, J MATH IMAGING VIS, V31, P255, DOI 10.1007/s10851-008-0087-0
   Hardie R, 2007, IEEE T IMAGE PROCESS, V16, P2953, DOI 10.1109/TIP.2007.909416
   He X., 2005, P 1 INT C INFORM COM, V2005, P52, DOI DOI 10.1109/ICICT.2005.1598543
   Hong HS, 2008, IEEE T IMAGE PROCESS, V17, P897, DOI 10.1109/TIP.2008.921996
   KADYROV A, 2004, P ICPR 04
   Katartzis A, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P1, DOI 10.1016/B978-0-12-372529-5.00007-X
   Knutsson H., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P515, DOI 10.1109/CVPR.1993.341081
   Lee S, 1997, IEEE T VIS COMPUT GR, V3, P228, DOI 10.1109/2945.620490
   Liao IY, 2008, COMPUT VIS IMAGE UND, V109, P227, DOI 10.1016/j.cviu.2007.10.002
   Martinez-Conde S, 2004, NAT REV NEUROSCI, V5, P229, DOI 10.1038/nrn1348
   MEGLIO F, 2007, P IGARSS 2007
   Middleton L., 2005, Hexagonal Image Processing: A Practical Approach
   MIRAVET C, 2003, P ICANN ICONIP 2003, P401
   NGUYEN N, 2000, P ICIP 00
   Ohtake Y, 2005, GRAPH MODELS, V67, P150, DOI 10.1016/j.gmod.2004.06.003
   OLIVEIRA P, 2006, P ICASSP 2006
   OVERINGTON I, 1992, COMPUTER VISION UNIF
   Pan P, 2008, IEEE T IMAGE PROCESS, V17, P94, DOI 10.1109/TIP.2007.912579
   PANAGIOTOPOULOU A, 2007, P IWSSIP 2007 EC SIP
   Pham TQ, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/83268
   Piroddi R, 2004, ADV IMAG ELECT PHYS, V132, P109, DOI 10.1016/S1076-5670(04)32003-3
   Ramponi G, 2001, IMAGE VISION COMPUT, V19, P451, DOI 10.1016/S0262-8856(00)00090-1
   Sha LW, 2003, J MAGN RESON, V162, P250, DOI 10.1016/S1090-7807(03)00107-1
   Shah NR, 1999, IEEE T IMAGE PROCESS, V8, P879, DOI 10.1109/83.766865
   Snyder WE, 1999, PROC SPIE, V3661, P716, DOI 10.1117/12.348629
   Strohmer T, 1997, IEEE T IMAGE PROCESS, V6, P540, DOI 10.1109/83.563319
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   Van De Ville D, 2004, IEEE T IMAGE PROCESS, V13, P758, DOI 10.1109/TIP.2004.827231
   Van De Ville D, 2002, SIGNAL PROCESS-IMAGE, V17, P393, DOI 10.1016/S0923-5965(02)00009-7
   Vázquez C, 2005, IEEE T IMAGE PROCESS, V14, P713, DOI 10.1109/TIP.2005.847297
   VAZQUEZ C, 2000, P ICIP 00
   VUCINI E, 2008, VISUAL COMPUT, V24, P7
   Young SS, 2006, APPL OPTICS, V45, P5073, DOI 10.1364/AO.45.005073
   ZHANG C, 2004, P ICIP 04
NR 45
TC 8
Z9 9
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1173
EP 1183
DI 10.1016/j.imavis.2009.12.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400001
DA 2024-07-18
ER

PT J
AU Yang, DD
   Sluzek, A
AF Yang Duanduan
   Sluzek, Andrzej
TI A low-dimensional local descriptor incorporating TPS warping for image
   matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image descriptor; Image matching; Interest points; TPS warping
ID PERFORMANCE EVALUATION; RECOGNITION
AB This paper proposes a low-dimensional image descriptor combining shape characteristics and location information. The shape characteristics are obtained from simple rectangular patterns approximating the interest regions. Although the shape component of the descriptor does not perform as well as high-dimensional descriptors (e.g. SIFT) it can be built very quickly. Moreover, it usually provides enough correspondences to align locations of interest regions. The alignment is based on the thin plate spline (TPS) warping algorithm with control points automatically identified by our method. Subsequently, the aligned coordinates contribute additional dimensions to the descriptor. The process may be iterated several times until no further improvement is achieved. Experiments show that incorporation of location data into the descriptor improves performance. The proposed descriptor is compared to SIFT (a standard benchmark which is considered one of the best local descriptors [1]) for real images with various geometric and photometric transformations and for diversified types of scenes. Results show the proposed low-dimensional descriptor generally performs better than SIFT descriptor while the computational complexity of our descriptor is far superior. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Yang Duanduan; Sluzek, Andrzej] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Yang, DD (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Blk N4,Nanyang Ave, Singapore 639798, Singapore.
EM ddyang@ntu.edu.sg; assluzek@ntu.edu.sg
RI Sluzek, Andrzej S/A-3672-2011; cai, bo/G-1491-2010; SLUZEK,
   ANDRZEJ/Q-5398-2019
OI Sluzek, Andrzej S/0000-0003-4148-2600; SLUZEK,
   ANDRZEJ/0000-0003-4148-2600
FU A*STAR Science and Engineering Research Council [072 134 0052]; SERC
FX The results presented in the paper are done under A*STAR Science and
   Engineering Research Council Grant 072 134 0052. The financial support
   of SERC is gratefully acknowledged.
CR [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   Bookstein F.L., 1989, IEEE T PAMI, V16, P460
   Fergus R, 2003, PROC CVPR IEEE, P264
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Ke Y, 2004, PROC CVPR IEEE, P506
   Ke Y., 2004, ACM MULTIMEDIA 04, P869
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   Lazebnik S, 2003, PROC CVPR IEEE, P319
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011
   Moravec HP., 1981, P 7 INT JOINT C ARTI, P785
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   PERONNIN F, 2006, LNCS, V3954, P464
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Sluzek A, 2005, IMAGE VISION COMPUT, V23, P287, DOI 10.1016/j.imavis.2004.03.003
   Tarr MJ, 1997, PSYCHOL SCI, V8, P282, DOI 10.1111/j.1467-9280.1997.tb00439.x
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
NR 22
TC 15
Z9 18
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1184
EP 1195
DI 10.1016/j.imavis.2009.12.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400002
DA 2024-07-18
ER

PT J
AU Burgos-Artizzu, XP
   Ribeiro, A
   Tellaeche, A
   Pajares, G
   Fernández-Quintanilla, C
AF Burgos-Artizzu, Xavier P.
   Ribeiro, Angela
   Tellaeche, Alberto
   Pajares, Gonzalo
   Fernandez-Quintanilla, Cesar
TI Analysis of natural images processing for the extraction of agricultural
   elements
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Precision agriculture; Weed detection; Parameter
   setting; Genetic algorithms
ID WEED DETECTION; CROP PLANTS; COLOR; DISCRIMINATION; IDENTIFICATION;
   SEGMENTATION; SYSTEM; ROBOT
AB This work presents several developed computer-vision-based methods for the estimation of percentages of weed, crop and soil present in an image showing a region of interest of the crop field. The visual detection of weed, crop and soil is an arduous task due to physical similarities between weeds and crop and to the natural and therefore complex environments (with non-controlled illumination) encountered. The image processing was divided in three different stages at which each different agricultural element is extracted: (1) segmentation of vegetation against non-vegetation (soil), (2) crop row elimination (crop) and (3) weed extraction (weed). For each stage, different and interchangeable methods are proposed, each one using a series of input parameters which value can be changed for further refining the processing, A genetic algorithm was then used to find the best value of parameters and method combination for different sets of images. The whole system was tested on several images from different years and fields, resulting in an average correlation coefficient with real data (bio-mass) of 84%, with up to 96% correlation using the best methods on winter cereal images and of up to 84% on maize images. Moreover, the method's low computational complexity leads to the possibility, as future work, of adapting them to real-time processing. (C) 2009 Elsevier B.V, All rights reserved.
C1 [Burgos-Artizzu, Xavier P.; Ribeiro, Angela] CSIC, GPA, IAI, Madrid 28500, Spain.
   [Tellaeche, Alberto] Univ Nacl Educ Distancia, Dpto Informat & Automat, ETS Informat, Madrid, Spain.
   [Pajares, Gonzalo] UCM, Dpto Ingn Software & Inteligencia Artificial, Fac Informat, Madrid, Spain.
   [Fernandez-Quintanilla, Cesar] CSIC, CCMA, Madrid 28500, Spain.
C3 Consejo Superior de Investigaciones Cientificas (CSIC); Universidad
   Nacional de Educacion a Distancia (UNED); Complutense University of
   Madrid; Consejo Superior de Investigaciones Cientificas (CSIC); CSIC -
   Centro de Ciencias Medioambientales (CCMA)
RP Burgos-Artizzu, XP (corresponding author), CSIC, GPA, IAI, Carretera Campo Real,Km 0-200, Madrid 28500, Spain.
EM xpburgos@iai.csic.es
RI Ribeiro, Angela/L-3519-2014; Pajares, Gonzalo/C-1404-2017;
   Burgos-Artizzu, Xavier Paolo/C-1043-2016; Fernandez-Quintanilla,
   Cesar/L-3944-2017
OI Pajares, Gonzalo/0000-0003-0915-6282; Tellaeche,
   Alberto/0000-0001-9236-1951; Ribeiro, Angela/0000-0001-5807-8132;
   Burgos-Artizzu, Xavier Paolo/0000-0001-9681-5404; Fernandez-Quintanilla,
   Cesar/0000-0002-2886-9176
FU Spanish Ministry of Education and Science [AGL2005-06180-C03-03,
   CICYT-DPI-2006-14497, PRICIT-CAM-P-DPI-000176-0505 (ROBOCIT-Y2030)];
   Spanish Council for Scientific Research (CSIC)
FX The Spanish Ministry of Education and Science provides full and
   continuing support for this research work through Projects
   AGL2005-06180-C03-03, CICYT-DPI-2006-14497 and
   PRICIT-CAM-P-DPI-000176-0505 (ROBOCIT-Y2030). The first author currently
   holds a scholarship given by the Spanish Council for Scientific Research
   (CSIC). The authors wish also to thank Pedro Hernaiz and his team.
CR Aitkenhead MJ, 2003, COMPUT ELECTRON AGR, V39, P157, DOI 10.1016/S0168-1699(03)00076-0
   Andreasen C, 1997, WEED RES, V37, P5, DOI 10.1111/j.1365-3180.1997.tb01817.x
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Åstrand B, 2002, AUTON ROBOT, V13, P21, DOI 10.1023/A:1015674004201
   Billingsley J, 1997, COMPUT ELECTRON AGR, V16, P147, DOI 10.1016/S0168-1699(96)00034-8
   Blasco J, 2002, BIOSYST ENG, V83, P149, DOI 10.1006/bioe.2002.0109
   Bosch A, 2007, IMAGE VISION COMPUT, V25, P727, DOI 10.1016/j.imavis.2006.05.015
   Burgos-Artizzu XP, 2007, REV IBEROAM AUTOM IN, V4, P64, DOI 10.1016/S1697-7912(07)70210-8
   BURGOSARTIZZU XP, 2006, 5 C IB SIST CIB INF, V1, P140
   Burks TF, 2005, BIOSYST ENG, V91, P293, DOI 10.1016/j.biosystemseng.2004.12.012
   Cressie N., 1993, STAT SPATIAL DATA
   Davis L., 1987, Genetic algorithms and simulated annealing, V1
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Earl R., 1996, Landwards, V51, P18
   Gée C, 2008, COMPUT ELECTRON AGR, V60, P49, DOI 10.1016/j.compag.2007.06.003
   Gerhards R, 2006, WEED RES, V46, P185, DOI 10.1111/j.1365-3180.2006.00504.x
   Gerhards R, 2003, WEED RES, V43, P385, DOI 10.1046/j.1365-3180.2003.00349.x
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   GOTTSCHALK R, 2008, P 15 INT C MECH MACH
   Granitto PM, 2005, COMPUT ELECTRON AGR, V47, P15, DOI 10.1016/j.compag.2004.10.003
   Hague T, 2001, MECHATRONICS, V11, P1, DOI 10.1016/S0957-4158(00)00003-9
   Hemming J, 2001, J AGR ENG RES, V78, P233, DOI 10.1006/jaer.2000.0639
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Lee W. S., 1999, Precision Agriculture, V1, P95, DOI 10.1023/A:1009977903204
   Lee WS., 1996, Proceedings of the Korean Society for Agricultural Machinery Conference, P802
   López-Granados F, 2002, PLANT SOIL, V246, P97, DOI 10.1023/A:1021568415380
   Martí J, 2001, IMAGE VISION COMPUT, V19, P1041, DOI 10.1016/S0262-8856(01)00065-8
   Marti R., 2003, Revista Iberoamericana de Inteligencia Artificial, V19, P123
   MENGES RM, 1985, WEED SCI, V33, P569, DOI 10.1017/S0043174500082862
   Meyer GE, 2008, COMPUT ELECTRON AGR, V63, P282, DOI 10.1016/j.compag.2008.03.009
   OLSEN HJ, 1995, COMPUT ELECTRON AGR, V12, P147, DOI 10.1016/0168-1699(94)00044-Q
   Onyango CM, 2003, COMPUT ELECTRON AGR, V39, P141, DOI 10.1016/S0168-1699(03)00023-1
   Pérez AJ, 2000, COMPUT ELECTRON AGR, V25, P197, DOI 10.1016/S0168-1699(99)00068-X
   Piron A, 2008, COMPUT ELECTRON AGR, V62, P141, DOI 10.1016/j.compag.2007.12.007
   Ribeiro A, 2005, PRECISION AGRICULTURE 05, P169
   RICHARDSON AJ, 1985, PHOTOGRAMM ENG REM S, V51, P1785
   Sogaard HT, 2003, COMPUT ELECTRON AGR, V38, P141, DOI 10.1016/S0168-1699(02)00140-0
   Stafford JV, 2000, J AGR ENG RES, V76, P267, DOI 10.1006/jaer.2000.0577
   Tellaeche A, 2008, COMPUT ELECTRON AGR, V60, P144, DOI 10.1016/j.compag.2007.07.008
   Thorp K. R., 2004, Precision Agriculture, V5, P477, DOI 10.1007/s11119-004-5321-1
   Tian L, 1999, T ASAE, V42, P893, DOI 10.13031/2013.13269
   Van Evert FK, 2006, WEED TECHNOL, V20, P853, DOI 10.1614/WT-05-132.1
   WOEBBECKE DM, 1995, T ASAE, V38, P271, DOI 10.13031/2013.27839
   YANG C, 2002, CANADIAN BIOSYSTEMS, V44
   Yang Chun-Chieh, 2003, Precision Agriculture, V4, P5, DOI 10.1023/A:1021847103560
NR 46
TC 49
Z9 57
U1 0
U2 45
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 138
EP 149
DI 10.1016/j.imavis.2009.05.009
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000014
DA 2024-07-18
ER

PT J
AU Camarena, JG
   Gregori, V
   Morillas, S
   Sapena, A
AF Camarena, Joan-Gerard
   Gregori, Valentin
   Morillas, Samuel
   Sapena, Almanzor
TI Some improvements for image filtering using peer group techniques
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Adaptive filter; Color image denoising; Peer group filter; Switching
   filter; Vector filter
ID IMPULSE NOISE-REDUCTION; MEDIAN FILTER; VECTOR FILTER; COLOR IMAGES;
   FUZZY FILTER; REMOVAL; SUPPRESSION; DETECTOR; OPTIMIZATION; ALGORITHM
AB An image pixel peer group is defined as the set of its neighbor pixels which are similar to it according to an appropriate distance or similarity measure. This concept has been successfully used to devise algorithms for detection and suppression of impulsive noise in gray-scale and color images. In this paper, we present a novel peer group-based approach intended to improve the trade-off between computational efficiency and filtering quality of previous peer group-based methods. We improve the computational efficiency by using a modification of a recent approach that can only be applied when the distance or similarity measure used fulfills the so-called triangular inequality property. The improvement of the filtering quality is achieved by the inclusion of a refinement stage in the noise detection. The proposed method performs according to the following steps: First, we partition the image into disjoint blocks and we perform a fast classification of the pixels into three types: non-corrupted, non-diagnosed and corrupted; second, we refine the initial findings by analyzing the non-diagnosed pixels and finally every pixel is classified either as corrupted or non-corrupted. Then, only corrupted pixels are replaced so that uncorrupted image data is preserved. Experimental results suggest that the proposed method is able to outperform state-of-the-art methods both in filtering quality and computational efficiency. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Morillas, Samuel] Univ Politecn Valencia, Ctr Invest Tecnol Graf, Valencia 46022, Spain.
   [Camarena, Joan-Gerard; Gregori, Valentin; Sapena, Almanzor] Univ Politecn Valencia, Inst Univ Matemat Pura & Aplicada, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia; Universitat Politecnica de Valencia
RP Morillas, S (corresponding author), Univ Politecn Valencia, Ctr Invest Tecnol Graf, Camino Vera S-N, Valencia 46022, Spain.
EM smorillas@mat.upv.es
RI Camarena, Juan/H-6130-2015; Morillas, Samuel/H-2610-2015; Gregori,
   Valentin/B-8233-2014; Sapena, Almanzor/H-5102-2015
OI Morillas, Samuel/0000-0001-9262-6139; Gregori,
   Valentin/0000-0002-5983-6182; Sapena, Almanzor/0000-0001-8473-6063
FU Generalitat Valenciana [GVPRE/2008/257]; Universidad Politecnica de
   Valencia [2008/3202]
FX The authors acknowledge the support of Generalitat Valenciana under
   Grant GVPRE/2008/257 and Universidad Politecnica de Valencia under grant
   Primeros Proyetos de Investigacion 2008/3202.
CR ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Barner KE, 2006, IEEE T SIGNAL PROCES, V54, P636, DOI 10.1109/TSP.2005.861750
   Camacho J, 2006, J IMAGING SCI TECHN, V50, P427, DOI [10.2352/J.ImagingSci.Technol.(2006)50:5(427), 10.2352/J.lmagingSci.Technol.(2006)50:5(427)]
   Camarena JG, 2008, J VIS COMMUN IMAGE R, V19, P20, DOI 10.1016/j.jvcir.2007.04.003
   Celebi ME, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2772639
   Civicioglu P, 2007, IEEE T IMAGE PROCESS, V16, P759, DOI 10.1109/TIP.2007.891067
   Deng Y., 1999, P IEEE INT S CIRC SY, V4, P21, DOI DOI 10.1109/ISCAS.1999.779933
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Gallegos-Funes FJ, 2004, REAL-TIME IMAGING, V10, P69, DOI 10.1016/j.rti.2004.02.002
   Ho JYF, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P713
   Hore ES, 2003, OPT ENG, V42, P1656, DOI 10.1117/1.1572156
   Jin LH, 2007, IEEE SIGNAL PROC LET, V14, P397, DOI 10.1109/LSP.2006.887840
   Jin LH, 2007, SIGNAL PROCESS, V87, P1345, DOI 10.1016/j.sigpro.2006.11.008
   Jin LH, 2007, OPT ENG, V46, DOI 10.1117/1.2713400
   Kenney C, 2001, IEEE T IMAGE PROCESS, V10, P326, DOI 10.1109/83.902298
   Lin TC, 2004, FUZZY SET SYST, V147, P75, DOI 10.1016/S0165-0114(03)00209-4
   Lucat L, 2002, SIGNAL PROCESS-IMAGE, V17, P509, DOI 10.1016/S0923-5965(02)00023-1
   Lukac R, 2005, INT J IMAG SYST TECH, V15, P236, DOI 10.1002/ima.20058
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   Lukac R, 2005, J INTELL ROBOT SYST, V42, P361, DOI 10.1007/s10846-005-1730-2
   Lukac R, 2005, FUZZY SET SYST, V152, P17, DOI 10.1016/j.fss.2004.10.012
   Lukac R, 2004, EURASIP J APPL SIG P, V2004, P1870, DOI 10.1155/S1110865704312126
   Lukac R, 2004, IEEE T NANOBIOSCI, V3, P272, DOI 10.1109/TNB.2004.837907
   Lukac R, 2004, COMPUT VIS IMAGE UND, V94, P140, DOI 10.1016/j.cviu.2003.10.013
   Lukac R, 2004, MULTIDIM SYST SIGN P, V15, P169, DOI 10.1023/B:MULT.0000017024.66297.a0
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   Lukac R, 2006, J VIS COMMUN IMAGE R, V17, P1, DOI 10.1016/j.jvcir.2005.08.007
   Lukac R, 2006, ADV IMAG ELECT PHYS, V140, P187, DOI 10.1016/S1076-5670(05)40004-X
   Ma ZH, 2005, IEEE T IMAGE PROCESS, V14, P1990, DOI 10.1109/TIP.2005.857269
   Ma ZH, 2005, REAL-TIME IMAGING, V11, P403, DOI 10.1016/j.rti.2005.07.002
   Ma ZH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P205
   Ma ZH, 2007, COMPUT VIS IMAGE UND, V107, P26, DOI 10.1016/j.cviu.2006.11.017
   Ma ZH, 2006, IEEE T IMAGE PROCESS, V15, P2324, DOI 10.1109/TIP.2006.877066
   Morillas S, 2005, REAL-TIME IMAGING, V11, P417, DOI 10.1016/j.rti.2005.06.007
   Morillas S, 2008, COMPUT VIS IMAGE UND, V110, P102, DOI 10.1016/j.cviu.2007.05.001
   Morillas S, 2008, SIGNAL PROCESS, V88, P390, DOI 10.1016/j.sigpro.2007.05.019
   Morillas S, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2767335
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Nie Y, 2006, IEEE T IMAGE PROCESS, V15, P910, DOI 10.1109/TIP.2005.863111
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Ponomaryov VI, 2005, J IMAGING SCI TECHN, V49, P205
   Qin H, 2007, FUZZY SET SYST, V158, P1036, DOI 10.1016/j.fss.2006.10.028
   Schulte S, 2007, FUZZY SET SYST, V158, P270, DOI 10.1016/j.fss.2006.10.010
   Schulte S, 2007, IEEE T IMAGE PROCESS, V16, P2565, DOI 10.1109/TIP.2007.904960
   Schulte S, 2007, IMAGE VISION COMPUT, V25, P1377, DOI 10.1016/j.imavis.2006.10.002
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P3567, DOI 10.1109/TIP.2006.877494
   Shen YZ, 2006, IEEE T SIGNAL PROCES, V54, P2497, DOI 10.1109/TSP.2006.874028
   Shen YZ, 2004, IEEE T VIS COMPUT GR, V10, P252, DOI 10.1109/TVCG.2004.1272725
   Smolka B, 2005, REAL-TIME IMAGING, V11, P389, DOI 10.1016/j.rti.2005.07.003
   Smolka B, 2003, REAL-TIME IMAGING, V9, P261, DOI 10.1016/j.rti.2003.09.015
   Smolka B, 2002, PATTERN RECOGN, V35, P1771, DOI 10.1016/S0031-3203(01)00169-8
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Yuan SQ, 2006, PATTERN RECOGN, V39, P2252, DOI 10.1016/j.patcog.2006.05.010
   Yuan SQ, 2006, SIGNAL PROCESS, V86, P2123, DOI 10.1016/j.sigpro.2006.01.009
   Yüksel ME, 2006, IEEE T IMAGE PROCESS, V15, P928, DOI 10.1109/TIP.2005.863941
   KODAK TEST IMAGES DA
NR 56
TC 30
Z9 30
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 188
EP 201
DI 10.1016/j.imavis.2009.07.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000018
DA 2024-07-18
ER

PT J
AU Zhang, H
   Shu, HZ
   Haigron, P
   Li, BS
   Luo, LM
AF Zhang, H.
   Shu, H. Z.
   Haigron, P.
   Li, B. S.
   Luo, L. M.
TI Construction of a complete set of orthogonal Fourier-Mellin moment
   invariants for pattern recognition applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Orthogonal Fourier-Mellin moments; Completeness; Similarity invariants;
   Moment invariants; Pattern recognition
ID SCALE INVARIANTS; CHARACTER-RECOGNITION; IMAGE-RECONSTRUCTION; ZERNIKE;
   TRANSLATION
AB The completeness property of a set of invariant descriptors is of fundamental importance from the theoretical as well as the practical points of view. In this paper, we propose a general approach to construct a complete set of orthogonal Fourier-Mellin moment (OFMM) invariants. By establishing a relationship between the OFMMs of the original image and those of the image having the same shape but distinct orientation and scale, a complete set of scale and rotation invariants is derived. The efficiency and the robustness to noise of the method for recognition tasks are shown by comparing it with some existing methods on several data sets. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Zhang, H.; Shu, H. Z.; Luo, L. M.] Southeast Univ, Lab Image Sci & Technol, Sch Engn & Comp Sci, Nanjing 210096, Peoples R China.
   [Haigron, P.] INSERM, U642, F-35042 Rennes, France.
   [Haigron, P.] Univ Rennes 1, Lab Traitement Signal & Image, F-35042 Rennes, France.
   [Li, B. S.] Shandong Canc Hosp, Dept Radiat Oncol, Jinan 250117, Peoples R China.
C3 Southeast University - China; Universite de Rennes; Institut National de
   la Sante et de la Recherche Medicale (Inserm); Universite de Rennes;
   Shandong First Medical University & Shandong Academy of Medical Sciences
RP Shu, HZ (corresponding author), Southeast Univ, Lab Image Sci & Technol, Sch Engn & Comp Sci, Nanjing 210096, Peoples R China.
EM shu.list@seu.edu.cn
RI Haigron, Pascal/AAR-6890-2020
FU Program for Changjiang Scholars and Innovative Research Team in
   University; National Natural Science Foundation of China [30670617]
FX This work was supported by Program for Changjiang Scholars and
   Innovative Research Team in University and by the National Natural
   Science Foundation of China under Grant 30670617.
CR ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594
   Bailey RR, 1996, IEEE T PATTERN ANAL, V18, P389, DOI 10.1109/34.491620
   Bin TJ, 2008, IMAGE VISION COMPUT, V26, P563, DOI 10.1016/j.imavis.2007.07.003
   Broumandnia A, 2007, IMAGE VISION COMPUT, V25, P717, DOI 10.1016/j.imavis.2006.05.014
   Chim YC, 1999, IMAGE VISION COMPUT, V17, P299, DOI 10.1016/S0262-8856(98)00110-3
   Chong CW, 2003, PATTERN ANAL APPL, V6, P176, DOI 10.1007/s10044-002-0183-5
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   CRIMMINS TR, 1982, IEEE T SYST MAN CYB, V12, P848, DOI 10.1109/TSMC.1982.4308918
   Derrode S, 2001, COMPUT VIS IMAGE UND, V83, P57, DOI 10.1006/cviu.2001.0922
   Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Flusser J, 2002, PATTERN RECOGN, V35, P3015, DOI 10.1016/S0031-3203(02)00093-6
   FU B, 2005, P SPIE INT SOC OPT 2, V5985
   Ghorbel F, 2006, PATTERN RECOGN LETT, V27, P1361, DOI 10.1016/j.patrec.2006.01.001
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jin L, 2004, PATTERN RECOGN, V37, P1745, DOI 10.1016/j.patcog.2004.02.006
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   KONTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489
   LI YJ, 1992, PATTERN RECOGN, V25, P723, DOI 10.1016/0031-3203(92)90135-6
   Miao ZJ, 2000, PATTERN RECOGN LETT, V21, P169, DOI 10.1016/S0167-8655(99)00144-0
   Papakostas GA, 2007, IET COMPUT VIS, V1, P11, DOI 10.1049/iet-cvi:20060130
   REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087
   Rodtook S, 2005, IMAGE VISION COMPUT, V23, P577, DOI 10.1016/j.imavis.2005.02.001
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Xia T, 2007, J OPT SOC AM A, V24, P50, DOI 10.1364/JOSAA.24.000050
   Xu D, 2008, PATTERN RECOGN, V41, P240, DOI 10.1016/j.patcog.2007.05.001
   YE B, 2005, P SPIE INT SOC OPT 2, V5985
   Zeilberger Doron, 1996, A B AK PETERS
   Zhu HQ, 2007, PATTERN RECOGN, V40, P2530, DOI 10.1016/j.patcog.2006.12.003
NR 32
TC 39
Z9 48
U1 3
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 38
EP 44
DI 10.1016/j.imavis.2009.04.004
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shevchenko, M
   Windridge, D
   Kittler, J
AF Shevchenko, Mikhail
   Windridge, David
   Kittler, Josef
TI A linear-complexity reparameterisation strategy for the hierarchical
   bootstrapping of capabilities within perception-action architectures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Perception-action architectures; Cognitive vision; Subsumption
   architecture; Machine learning (unsupervised); Optimisation
ID KNOWLEDGE
AB Perception-action (PA) architectures are capable of solving a number of problems associated with artificial cognition, in particular, difficulties concerned with framing and symbol grounding. Existing PA algorithms tend to be 'horizontal' in the sense that learners maintain their prior percept-motor competences unchanged throughout learning. We here present a methodology for simultaneous 'horizontal' and 'vertical' perception-action learning in which there additionally exists the capability for incremental accumulation of novel percept-motor competences in a hierarchical fashion.
   The proposed learning mechanism commences with a set of primitive 'innate' capabilities and progressively modifies itself via recursive generalising of parametric spaces within the linked perceptual and motor domains so as to represent environmental affordances in maximally-compact manner. Efficient reparameterising of the percept domain is here accomplished by the exploratory elimination of dimensional redundancy and environmental context.
   Experimental results demonstrate that this approach exhibits an approximately linear increase in computational requirements when learning in a typical unconstrained environment, as compared with at least polynomially-increasing requirements for a classical perception-action system. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Shevchenko, Mikhail; Windridge, David; Kittler, Josef] Univ Surrey, Fac Engn & Phys Sci, Surrey GU2 7XH, England.
C3 University of Surrey
RP Windridge, D (corresponding author), Univ Surrey, Fac Engn & Phys Sci, Surrey GU2 7XH, England.
EM d.windridge@surrey.ac.uk
OI Windridge, David/0000-0001-5507-8516
FU European Union [IST-2003-004176]; European Community [FP7/2007-2013]
FX The work presented here was supported by the European Union, Grant
   COSPAL (IST-2003-004176), and also from the European Community's Seventh
   Framework Programme (FP7/2007-2013) under grant agreement No. 215078.
   However, this paper does not necessarily represent the opinion of the
   European Community, and the European Community is not responsible for
   any use which may be made of its contents.
CR [Anonymous], J ROBOTICS SOC JAPAN
   [Anonymous], 2003, Categorical perception
   [Anonymous], 2003, INTRO STOCHASTIC SEA, DOI DOI 10.1002/0471722138
   [Anonymous], 2002, INTEGRATION SYMBOLIC, DOI DOI 10.1016/S1389-0417(01)00055-9
   Barto AG, 2003, DISCRETE EVENT DYN S, V13, P343
   Borghi AM, 2005, COGN SYST RES, V6, P99, DOI 10.1016/j.cogsys.2004.06.003
   BROOKS RA, 1991, SCIENCE, V253, P1227, DOI 10.1126/science.253.5025.1227
   Chen CH, 1999, IEEE T NEURAL NETWOR, V10, P94, DOI 10.1109/72.737497
   Coradeschi S, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P129
   Elfwing S, 2007, IEEE T EVOLUT COMPUT, V11, P249, DOI 10.1109/TEVC.2006.890270
   FIECHTER C, 1994, COLT94, P88
   FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5
   Gibson J., 1979, The ecological approach to visual perception
   GILES L, 1993, CONNECT SCI, V5, P307
   Granlund G., 2003, P WORKSH COGN VIS SC
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Hirose A, 1999, IEE CONF PUBL, P726, DOI 10.1049/cp:19991197
   Jonker C.M., 2003, COGN SYST RES, V4, P191, DOI DOI 10.1016/S1389-0417(03)00004-4
   Kaelbling L. P., 1993, Proceedings of the tenth international conference on machine learning, P167
   KRAETZSCHMAR GK, 2000, HYBRID NEURAL SYSTEM
   KUIPERS B, 2006, CONNECTION SCI, V18
   MARKMAN A, 1991, TRENDS COGN SCI, V4, P470
   NEWELL A, 1982, ARTIF INTELL, V18, P87, DOI 10.1016/0004-3702(82)90012-1
   PFEIFER R, 1995, ROBOT AUTON SYST, V15, P47, DOI 10.1016/0921-8890(95)00014-7
   Pozarlik R, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P1444, DOI 10.1109/IJCNN.1998.685988
   Sahin E, 2007, ADAPT BEHAV, V15, P447, DOI 10.1177/1059712307084689
   Schalkoff R.J., 1990, Artificial intelligence: an engineering approach
   Scherl RB, 2003, ARTIF INTELL, V144, P1, DOI 10.1016/S0004-3702(02)00365-X
   Sharkey N.E., 2001, Cognitive Systems Research, V2, P251, DOI [10.1016/S1389-0417(01)00036-5, DOI 10.1016/S1389-0417(01)00036-5]
   STEEDMAN M, 2004, 24 ANN M COGN SCI SO, P834
   Steels L, 1997, INT JOINT CONF ARTIF, P1632
   STEELS L, 1995, ROBOT AUTON SYST, V15, P3, DOI 10.1016/0921-8890(95)00011-4
   Stoytchev A., 2005, P AAAI S DEVELOPMENT, P17
   Sun R, 2000, PHILOS PSYCHOL, V13, P149, DOI 10.1080/09515080050075663
   Sun R, 2001, COGNITIVE SCI, V25, P203, DOI 10.1207/s15516709cog2502_2
   Tano S, 2000, NINTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2000), VOLS 1 AND 2, P1056, DOI 10.1109/FUZZY.2000.839198
   UENO A, 1999, 1999 IEEE INT C SYST, V2, P746
   Wermter S, 2000, APPL INTELL, V12, P27, DOI 10.1023/A:1008320219610
   Windridge D, 2008, STUD COMPUT INTELL, V122, P395
   ZIEMKE T, 1996, 6 INT C ART NEUR NET, P611
NR 40
TC 10
Z9 11
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 2
PY 2009
VL 27
IS 11
SI SI
BP 1702
EP 1714
DI 10.1016/j.imavis.2008.12.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 498HJ
UT WOS:000270127800007
DA 2024-07-18
ER

PT J
AU Taylor, JG
   Hartley, M
   Taylor, N
   Panchev, C
   Kasderidis, S
AF Taylor, J. G.
   Hartley, M.
   Taylor, N.
   Panchev, C.
   Kasderidis, S.
TI A hierarchical attention-based neural network architecture, based on
   human brain guidance, for perception, conceptualisation, action and
   reasoning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dorsal and ventral vision; Object representations; Dopamine as reward;
   TD learning
ID VISUAL-ATTENTION; AFFORDANCES; REWARD; V4
AB We present a neural network software architecture, guided by that of the human and more generally primate brain, for the construction of an autonomous cognitive system (which we have named GNOSYS). GNOSYS is created so as to be able to attend to stimuli, to conceptualise them, to learn their predicted reward value and reason about them so as to attain those stimuli in the environment with greatest predicted value. We apply this software system to an embodied version in a robot, and describe the activities in the various component modules of GNOSYS, as well as the overall results. We briefly compare our system with some others proposed to have cognitive powers, and finish by discussion of future developments we propose for our system, as well as expanding on the arguments for and against our approach to creating such a software system. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Taylor, J. G.; Hartley, M.; Taylor, N.] Kings Coll London, Dept Math, London WC2R 2LS, England.
   [Panchev, C.] Univ Sunderland, Dept Comp Sci, Sunderland, England.
   [Kasderidis, S.] Inst Comp Sci, Fdn Res & Technol Hellas, Iraklion, Greece.
C3 University of London; King's College London; University of Sunderland;
   Foundation for Research & Technology - Hellas (FORTH)
RP Taylor, JG (corresponding author), Kings Coll London, Dept Math, London WC2R 2LS, England.
EM john.g.taylor@kcl.ac.uk
OI Panchev, Christo/0000-0002-0243-6006
FU EU
FX We would like to thank the EU for financial support during the work of
   the EU GNOSYS project UGT, CP, NT, SK) and of the EU MATHESIS project
   (MH, JGT), whilst OGT & NT) would also like to thank the UK EPSRC
   project for earlier support for work covering attention.
CR [Anonymous], SCHOLARPEDIA
   [Anonymous], 2004, Semantic Cognition: A Parallel Distributed Processing Approach
   Bendiksby MS, 2006, NEUROPSYCHOLOGIA, V44, P2411, DOI 10.1016/j.neuropsychologia.2006.04.011
   Burghart C, 2005, IEEE-RAS INT C HUMAN, P357
   Christensen WD, 2000, PHILOS PSYCHOL, V13, P5, DOI 10.1080/09515080050002717
   Corbetta M, 2005, NEUROPSYCHOLOGIA, V43, P2041, DOI 10.1016/j.neuropsychologia.2005.03.020
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Deco G, 2005, PROG NEUROBIOL, V76, P236, DOI 10.1016/j.pneurobio.2005.08.004
   EIMER M, 2007, 15 P EUR SOC COGN PS, P40
   Feldman J., 2006, From Molecule to Metaphor: a Neural Theory of Language
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   Hamker FH, 2006, NEURAL NETWORKS, V19, P1371, DOI 10.1016/j.neunet.2006.08.006
   HEFT H, 1989, J THEOR SOC BEHAV, V19, P1, DOI 10.1111/j.1468-5914.1989.tb00133.x
   Hofstadter D. R., 1995, FLUID CONCEPTS CREAT
   Kandel E., 2000, PRINCIPLES NEUROSCIE, V4
   Kanwisher N, 2000, NAT REV NEUROSCI, V1, P91, DOI 10.1038/35039043
   Kasderidis S, 2008, LECT NOTES COMPUT SC, V5164, P959, DOI 10.1007/978-3-540-87559-8_99
   Kasderidis S, 2007, LECT NOTES COMPUT SC, V4669, P922
   Kasderidis S, 2006, LECT NOTES COMPUT SC, V4131, P612
   Krichmar JL, 2005, ARTIF LIFE, V11, P63, DOI 10.1162/1064546053278946
   Mehta AD, 2000, CEREB CORTEX, V10, P359, DOI 10.1093/cercor/10.4.359
   Milner AD., 1995, The visual brain in action
   Mohan V, 2007, INT J NEURAL SYST, V17, P329, DOI 10.1142/S0129065707001172
   MORASSO P, 1981, EXP BRAIN RES, V42, P223
   Morasso P., 2005, Cognitive Processing, DOI DOI 10.1007/S10339-004-0039-6
   Mozer M.C., 1998, Attention, V9, P341
   MURRAY G, 2004, BIG BOOK CONCEPTS
   Natsoulas T, 2004, J MIND BEHAV, V25, P323
   Pasupathy A, 2001, J NEUROPHYSIOL, V86, P2505, DOI 10.1152/jn.2001.86.5.2505
   Raos V, 2004, NEUROIMAGE, V23, P193, DOI 10.1016/j.neuroimage.2004.04.024
   Reynolds JH, 1999, J NEUROSCI, V19, P1736
   Santello M, 2002, J NEUROSCI, V22, P1426, DOI 10.1523/JNEUROSCI.22-04-01426.2002
   Schultz W, 2004, CURR OPIN NEUROBIOL, V14, P139, DOI 10.1016/j.conb.2004.03.017
   Shanahan M, 2006, CONSCIOUS COGN, V15, P433, DOI 10.1016/j.concog.2005.11.005
   SMOLENSKY P, 2006, HARMONIC MIND COGNIT, V1
   Taylor JG, 2007, NEURAL NETWORKS, V20, P929, DOI 10.1016/j.neunet.2007.09.010
   Taylor JG, 2000, BIOL CYBERN, V82, P415, DOI 10.1007/s004220050595
   Taylor JG, 2000, SOC NEUR ABSTR, V26, P2231
   TAYLOR JGU, 2003, P 2003 INT JOINT C N, V1, P298
   Taylor JG, 2008, NEUROCOMPUTING, V71, P2411, DOI 10.1016/j.neucom.2007.12.040
   Taylor JG, 2005, PHYS LIFE REV, V2, P1, DOI 10.1016/j.plrev.2004.12.001
   Taylor NR, 2007, LECT NOTES COMPUT SC, V4669, P973
   Taylor NR, 2007, INTEGR COMPUT-AID E, V14, P283
   Taylor NR, 2006, LECT NOTES COMPUT SC, V4131, P592
   Weng J., 2004, International Journal of Humanoid Robotics, V1, P199
   Young G, 2006, BRAIN COGNITION, V62, P134, DOI 10.1016/j.bandc.2006.04.002
NR 46
TC 11
Z9 11
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 2
PY 2009
VL 27
IS 11
SI SI
BP 1641
EP 1657
DI 10.1016/j.imavis.2009.03.006
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 498HJ
UT WOS:000270127800002
DA 2024-07-18
ER

PT J
AU Shaaban, KM
   Omar, NM
AF Shaaban, Khaled M.
   Omar, Nagwa M.
TI Region-based Deformable Net for automatic color image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deformable contours
ID ALGORITHM; SNAKES
AB This paper introduces a new color image segmentation framework that unifies contour deformation and region-based segmentation. Instead of deforming a single or multiple contours, typically used with classical deformable contour methods, the proposed framework deforms a single planar net that represents the contours of all the objects in the image. The net consists of a group of vertices connected by edges without crossing each other. The connected edges form polygons that represent the segmented regions boundaries. During the deformation process, the algorithm changes the location and the number of vertices as well as the number of polygons to enhance the segmentation fit. The deformation forces for each polygon are generated based upon the average color of the region and the color of the pixels surrounding it. The algorithm is completely autonomous and does not require any user interference, training or pre-knowledge about the image contents. The experimental results demonstrate the capability of the algorithm to segment color images from arbitrary sources within reasonable time. Furthermore, the compact mathematical representation of the resulting boundaries could be of value for further image analysis. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Shaaban, Khaled M.; Omar, Nagwa M.] Assiut Univ, Dept Elect Engn, Assiut, Egypt.
C3 Egyptian Knowledge Bank (EKB); Assiut University
RP Shaaban, KM (corresponding author), Assiut Univ, Dept Elect Engn, Assiut, Egypt.
EM kshaaban@IEEE.org; nagwa_omar@hotmail.com
OI Omar, Nagwa/0000-0002-7089-2740
CR [Anonymous], 2005, P MULT INF RETR WORK
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cardoso JS, 2005, IEEE T IMAGE PROCESS, V14, P1773, DOI 10.1109/TIP.2005.854491
   Celenk M, 1998, P SOC PHOTO-OPT INS, V3304, P250, DOI 10.1117/12.304605
   Chan TF, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P161, DOI 10.1109/VLSM.2001.938895
   Chang CC, 2006, IEEE T IMAGE PROCESS, V15, P2743, DOI 10.1109/TIP.2006.877344
   Dong G, 2005, IEEE T NEURAL NETWOR, V16, P925, DOI 10.1109/TNN.2005.849822
   Foresti GL, 2004, IEEE T SYST MAN CY C, V34, P325, DOI 10.1109/TSMCC.2003.819701
   Han X, 2003, IEEE T PATTERN ANAL, V25, P755, DOI 10.1109/TPAMI.2003.1201824
   HE L, 2003, COMP DEFORMABLE CONT
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555
   Jung YM, 2007, SIAM J APPL MATH, V67, P1213, DOI 10.1137/060662708
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Konstantinos N.Plataniotis e., 2000, Color Image Processing and Applications
   LIU L, 2001, REGION SEGMENTATION
   LOBREGT S, 1995, IEEE T MED IMAGING, V14, P12, DOI 10.1109/42.370398
   Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207
   Luo QM, 2006, IEEE T IMAGE PROCESS, V15, P2755, DOI 10.1109/TIP.2006.877342
   Makrogiannis S, 2005, IEEE T SYST MAN CY B, V35, P44, DOI 10.1109/TSMCB.2004.837756
   Makrogiannis S, 2005, IEEE T SYST MAN CY A, V35, P224, DOI 10.1109/TSMCA.2004.832820
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Papandreou G, 2007, IEEE T IMAGE PROCESS, V16, P229, DOI 10.1109/TIP.2006.884952
   SAARINEN K, 1994, IEEE IMAGE PROC, P1021, DOI 10.1109/ICIP.1994.413690
   Sakalli M, 2006, IEEE T IMAGE PROCESS, V15, P1182, DOI 10.1109/TIP.2006.871401
   Salgado L, 2000, IEEE T CIRC SYST VID, V10, P1029, DOI 10.1109/76.875507
   Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594
   Sclaroff S, 2001, IEEE T PATTERN ANAL, V23, P475, DOI 10.1109/34.922706
   SHAABAN K, 2004, J ENG SCI, V32, P471
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   Tang YJ, 2000, IEEE INTERNATIONAL SYMPOSIUM ON BIO-INFORMATICS AND BIOMEDICAL ENGINEERING, PROCEEDINGS, P347, DOI 10.1109/BIBE.2000.889627
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   Tsai R., 2003, COMMUN MATH SCI, V1, P623
   van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121
   VERGES J, 2005, COLOR CONSTANCY IMAG
   Xia Y, 2006, IEEE T IMAGE PROCESS, V15, P3559, DOI 10.1109/TIP.2006.877513
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
NR 38
TC 8
Z9 8
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1504
EP 1514
DI 10.1016/j.imavis.2009.02.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800009
DA 2024-07-18
ER

PT J
AU Chen, GY
   Dudek, G
AF Chen, G. Y.
   Dudek, G.
TI Auto-correlation wavelet support vector machine
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Wavelets; Support vector machine; Machine learning; Pattern recognition;
   Function regression; Auto-correlation
ID NETWORKS
AB A support vector machine (SVM) with the auto-correlation of a compactly supported wavelet as a kernel is proposed in this paper. The authors prove that this kernel is an admissible support vector kernel. The main advantage of the auto-correlation of a compactly supported wavelet is that it satisfies the translation invariance property, which is very important for its use in signal processing. Also, we can choose a better wavelet by selecting from different wavelet families for our auto-correlation wavelet kernel. This is because for different applications we should choose wavelet filters selectively for the autocorrelation kernel. We should not always select the same wavelet fllters independent of the application, as we demonstrate. Experiments on signal regression and pattern recognition show that this kernel is a feasible kernel for practical applications. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Chen, G. Y.; Dudek, G.] McGill Univ, Ctr Intelligence Machines, Montreal, PQ H3A 2A7, Canada.
C3 McGill University
RP Dudek, G (corresponding author), McGill Univ, Ctr Intelligence Machines, 3480 Univ St, Montreal, PQ H3A 2A7, Canada.
EM gchen@cim.mcgill.ca; dudek@cim.mcgill.ca
RI Dudek, Gregory L/H-3567-2012
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   Canadian Space Agency
FX The authors thank the anonymous reviewers whose constructive ideas and
   suggestions have improved the quality of the paper. This work was
   supported by the postdoctoral fellowship from the Natural Sciences and
   Engineering Research Council of Canada (NSERC) and the Canadian Space
   Agency Postdoctoral Fellowship Supplement. The modified version of
   LIBSVM (a library for support vector machines) tool has been used in
   this paper for classification available at
   http://www.csie.ntu.edu.tw/similar to cjlin/libsvm.
CR [Anonymous], P EUSIPCO 98 RHOD SE
   [Anonymous], 1998, STAT LEARNING THEORY
   Castleman K.R., 1979, DIGITAL IMAGE PROCES
   CHEN G, 2005, P 2 CAN C COMP ROB V
   Chen GY, 2003, PATTERN RECOGN, V36, P1597, DOI 10.1016/S0031-3203(02)00252-2
   CHEN GY, 2005, P IM VIS COMP DUN NZ
   Chui C. K., 1992, An Introduction to Wavelets, DOI 10.2307/2153134
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   Daubechies I., 1992, 10 LECT WAVELETS
   Gunn S. R., 1998, SUPPORT VECTOR MACHI
   JOACHIMS T, 2000, P 17 INT C MACH LEAR
   Kearns M., 1997, Proceedings of the Tenth Annual Conference on Computational Learning Theory, P152, DOI 10.1145/267460.267491
   KINGSBURY NG, 2000, P IEEE ICIP VANC SEP
   KINGSBURY NG, 1999, P IEEE ICASSP 99 PHO
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   SAITO N, 1993, IEEE T SIGNAL PROCES, V41, P3584, DOI 10.1109/78.258102
   Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X
   STRANG G, 1989, SIAM REV, V31, P614, DOI 10.1137/1031128
   Vapnik V., 1999, NATURE STAT LEARNING
   Zhang L, 2004, IEEE T SYST MAN CY B, V34, P34, DOI 10.1109/TSMCB.2003.811113
NR 21
TC 8
Z9 10
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1040
EP 1046
DI 10.1016/j.imavis.2008.09.006
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000006
DA 2024-07-18
ER

PT J
AU Polak, M
   Zhang, H
   Pi, MH
AF Polak, Mark
   Zhang, Hong
   Pi, Minghong
TI An evaluation metric for image segmentation of multiple objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Evaluation; Error measure
AB It is important to be able to evaluate the performance of image segmentation algorithms objectively. In this paper, we define a new error measure which quantifies the performance of an image segmentation algorithm for identifying multiple objects in an image. This error measure is based on object-by-object comparisons of a segmented image and a ground-truth (reference) image. it takes into account the size, shape, and position of each object. Compared to existing error measures, our proposed error measure works at the object level, and is sensitive to both over-segmentation and under-segmentation. Hence, it can serve as a useful tool for comparing image segmentation algorithms and for tuning the parameters of a segmentation algorithm. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Zhang, Hong] Univ Alberta, Dept Comp Sci, Ctr Intelligent Min Syst, Edmonton, AB T6G 2E8, Canada.
C3 University of Alberta
RP Zhang, H (corresponding author), Univ Alberta, Dept Comp Sci, Ctr Intelligent Min Syst, 221 Athabasca Hall, Edmonton, AB T6G 2E8, Canada.
EM mpolak@cs.ualberta.ca; zhang@cs.ualberta.ca; minghong@cs.ualberta.ca
RI cai, bo/G-1491-2010
CR Cardoso JS, 2005, IEEE T IMAGE PROCESS, V14, P1773, DOI 10.1109/TIP.2005.854491
   CHARLES JJ, 2006, P INT C IM AN REC PO
   Franklin J., 1996, Measurement of Blast Fragmentation
   Lee G, 2005, GECCO 2005: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOLS 1 AND 2, P2029
   LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X
   LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   STRASTERS KC, 1991, PATTERN RECOGN LETT, V12, P307, DOI 10.1016/0167-8655(91)90414-H
   WESZKA JS, 1978, IEEE T SYST MAN CYB, V8, P622, DOI 10.1109/TSMC.1978.4310038
   YASNOFF WA, 1977, PATTERN RECOGN, V9, P217, DOI 10.1016/0031-3203(77)90006-1
   ZHANG YJ, 1995, PATTERN RECOGN LETT, V16, P201, DOI 10.1016/0167-8655(94)00083-F
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
NR 13
TC 113
Z9 136
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1223
EP 1227
DI 10.1016/j.imavis.2008.09.008
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000021
DA 2024-07-18
ER

PT J
AU Rothaus, K
   Jiang, XY
   Rhiem, P
AF Rothaus, Kai
   Jiang, Xiaoyi
   Rhiem, Paul
TI Separation of the retinal vascular graph in arteries and veins based
   upon structural knowledge
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Retinal vascular graph; Artery; Vein; Constraint satisfaction problem;
   Constraint propagation
ID VESSEL SEGMENTATION; IMAGES
AB The vascular structure of the retina consists of two kinds of vessels: arteries and veins. Together these vessels form the vascular graph. In this paper, we present an approach to separate arteries and veins based on a pre-segmentation and a few hand-labelled vessel segments. We use a rule-based method to propagate the vessel labels through the vascular graph. The anatomical characteristics of the vessels on the retina are modelled as a dual constraint graph. We embed this task as double-layered constrained search problem steered by a heuristical AC-3 algorithm to overcome the NP-hard computational complexity. Results are presented on vascular graphs generated from manual as well as on automatical segmentation. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Rothaus, Kai; Jiang, Xiaoyi; Rhiem, Paul] Univ Munster, Dept Math & Comp Sci, D-48149 Munster, Germany.
C3 University of Munster
RP Rothaus, K (corresponding author), Univ Munster, Dept Math & Comp Sci, Einsteinstr 62, D-48149 Munster, Germany.
EM rothaus@uni-muenster.de
RI Jiang, Xiaoyi/AAA-3532-2022
OI Jiang, Xiaoyi/0000-0001-7678-9528
CR Aguilar W, 2007, LECT NOTES COMPUT SC, V4538, P25
   AKITA K, 1982, PATTERN RECOGN, V15, P431, DOI 10.1016/0031-3203(82)90022-X
   [Anonymous], 2003, Artificial intelligence: A modern approach
   BRANDON L, 2003, MICCAI, V1, P618
   Chrastek R, 2002, P IAPR WORKSH MACH V, P240
   Grisan E, 2003, P ANN INT IEEE EMBS, V25, P890, DOI 10.1109/IEMBS.2003.1279908
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   HSU W, 2001, CVPR, V2, P246
   Huang K, 2005, LECT NOTES COMPUT SC, V3765, P103
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Larsen M, 2005, INVEST OPHTH VIS SCI, V46, P709, DOI 10.1167/iovs.04-0604
   Martinez-Perez ME, 2002, IEEE T BIO-MED ENG, V49, P912, DOI 10.1109/TBME.2002.800789
   PAL I, 2000, BILDVERARBEITUNG MED, P319
   Patton N, 2006, PROG RETIN EYE RES, V25, P99, DOI 10.1016/j.preteyeres.2005.07.001
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   ROTHAUS K, 2005, P 3 EMBEC
   Simó A, 2001, PATTERN RECOGN, V34, P795, DOI 10.1016/S0031-3203(00)00032-7
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Thönnes E, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P937
   Wang JJ, 2006, HEART, V92, P1583, DOI 10.1136/hrt.2006.090522
NR 21
TC 86
Z9 94
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 864
EP 875
DI 10.1016/j.imavis.2008.02.013
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300005
DA 2024-07-18
ER

PT J
AU Rami-Shojaei, S
   Vachier, C
   Schmitt, C
AF Rami-Shojaei, Sabrina
   Vachier, Corinne
   Schmitt, Christophe
TI Automatic analysis of 2D foam sequences: Application to the
   characterization of aqueous proteins foams stability
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Foams stability; Macroscopic imaging; Mathematical morphology;
   Granulometric analysis; Tracking
ID KINETICS; BUBBLES; TIME
AB Aqueous foams occur in several industrial applications including food production. One of the challenging issues in foams study is to evaluate the air bubbles stability. This problem is addressed in the present work using sequences of 2D macroscopic images of aqueous foams carried out in a glass column.
   Despite commercial softwares that are currently used in microscopy, the automatic analysis of foam sequences is still an unsolved problem. It can be related to two fundamental problems in the field of image analysis: the granulometric analysis and the automatic tracking of objects in image sequences. Rather than an adaptation of existing granulometric or tracking methods, the proposed foam analyzer consists in a new algorithm based on a double tracking of the foam bubbles: a scale-space tracking, where the scale parameter is the size, and a temporal tracking. It ensures a complete description of any bubble through the time and the detection of any bubbles interaction so that the foam's structure is finally entirely and very precisely described.
   The proposed foam analyzer has been validated by comparing the characteristics computed by the automatic method to those that can be predicted via the foams physical propel-ties. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Vachier, Corinne] PRES UnivSud, Ctr Math & Leurs Applicat, ENS Cachan, CNRS, F-94235 Cachan, France.
   [Rami-Shojaei, Sabrina; Schmitt, Christophe] Nestle Res Ctr, CH-1000 Lausanne, Switzerland.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Paris
   Saclay; Nestle SA
RP Vachier, C (corresponding author), PRES UnivSud, Ctr Math & Leurs Applicat, ENS Cachan, CNRS, 61 Av Pt Wilson, F-94235 Cachan, France.
EM Corinne.Vachier@cmla.ens-cachan.fr
RI Vachier, corinne/AGZ-6030-2022
CR [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 1990, THESIS ECOLE MINES P
   [Anonymous], 1967, Elements pour une theorie des milieux poreux
   Axelos MAV, 2003, LANGMUIR, V19, P6598, DOI 10.1021/la020965r
   Bals A, 2003, INT DAIRY J, V13, P903, DOI 10.1016/S0958-6946(03)00111-0
   BASCLE B, 1994, RR2439 ROBOTVIS
   Beucher S., 1979, Use of watersheds in contour detection
   BOISSONNET G, 2001, STRUCTURE DECONTAMIN, V29, P201
   COHEN L, 2002, ACTES JOURNEES ETUDE
   COHEN L, P 2 EUR C COMP VIS, P458
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Dickinson E, 2002, J COLLOID INTERF SCI, V252, P202, DOI 10.1006/jcis.2002.8405
   DURIAN DJ, 1991, PHYS REV A, V44, pR7902, DOI 10.1103/PhysRevA.44.R7902
   FIGUEROA PJ, 1998, SIGNAL PROCESS, V9, P941
   GRIMAUD M, 1992, IMAGE ALGEBRA MORPHO, V3
   GUICHARD F, 1995, PARTIAL DIFFERENTIAL
   GUILLERME C, 1993, J TEXTURE STUD, V24, P287, DOI 10.1111/j.1745-4603.1993.tb01285.x
   Horaud R, 1993, VISION ORDINATEUR OU
   HORN B, 1980, 572 MIT, V13, P1245
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Kloek W, 2001, J COLLOID INTERF SCI, V237, P158, DOI 10.1006/jcis.2001.7454
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   Matheron G., 1975, Random sets and integral geometry
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   Meyer F, 1999, LECT NOTES COMPUT SC, V1682, P187
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   MEYER F, P 2 EUR C COMP VIS, P476
   MEYER F, 1997, ANN TELECOMMUNICATIO
   Monnereau C, 1998, PHYS REV LETT, V80, P5228, DOI 10.1103/PhysRevLett.80.5228
   Montminy MD, 2004, J COLLOID INTERF SCI, V280, P202, DOI 10.1016/j.jcis.2004.07.032
   MOREL JM, 2002, P INT S MATH MORPH C
   Murray BS, 2007, ROY SOC CH, P369, DOI 10.1039/9781847557698-00369
   Murray BS, 2005, LANGMUIR, V21, P4622, DOI 10.1021/la047333k
   NAJMAN L, 1994, SIGNAL PROCESS, V38, P99, DOI 10.1016/0165-1684(94)90059-0
   Rouimi S, 2005, FOOD HYDROCOLLOID, V19, P467, DOI 10.1016/j.foodhyd.2004.10.032
   Saint-Jalmes A, 2002, J PHYS-CONDENS MAT, V14, P9397, DOI 10.1088/0953-8984/14/40/325
   Sarker DK, 1998, J TEXTURE STUD, V29, P15, DOI 10.1111/j.1745-4603.1998.tb00151.x
   Schmitt C, 2005, LANGMUIR, V21, P7786, DOI 10.1021/la0510984
   Schmitt C, 2007, LANGMUIR, V23, P4155, DOI 10.1021/la0632575
   SERRA J, 1993, P SPIE IM ALG MATH M
   Serra J., 1983, IMAGE ANAL MATH MORP
   Serra J., 1988, IMAGE ANAL MATH MORP
   Solé A, 2004, IEEE T IMAGE PROCESS, V13, P1245, DOI 10.1109/TIP.2004.832864
   Unterhaslberger G, 2007, ROY SOC CH, P177, DOI 10.1039/9781847557698-00177
   Vachier C, 2005, J MATH IMAGING VIS, V22, P251, DOI 10.1007/s10851-005-4893-3
   VACHIER C, 1998, RFIA 98 RECONNAISSAN, V1, P307
   VACHIER C, 2001, P GRETSI TOUL 1 SEPT
   VACHIER C, 1995, P 1995 IEEE WORKSH N, V1, P254
   VACHIER C, 1995, P SPIE
   Vincent L, 1994, COMP IMAG VIS, V2, P265
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Weaire D., 2000, PHYS FOAMS
   WILDE P, 2000, CURRENT OPINION COLL, V5
   Wilde P.T., 1996, METHODS TESTING PROT
   YU MA, 1991, J AGR FOOD CHEM, V39, P1555, DOI 10.1021/jf00009a004
NR 55
TC 15
Z9 17
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 609
EP 622
DI 10.1016/j.imavis.2008.10.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000001
DA 2024-07-18
ER

PT J
AU Paley, MNJ
   Chow, LS
   Whitby, EH
   Cook, GG
AF Paley, Martyn N. J.
   Chow, Li Sze
   Whitby, Elspeth H.
   Cook, Greg G.
TI Modelling of axonal fields in the optic nerve for direct MR detection
   studies
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optic nerve; Axonal waveform; Direct MR detection; Neuronal firing;
   Axonal firing; Hodgkin-Huxley equations; Direct neuronal detection; MRI
ID MAGNETIC-RESONANCE; NEURONAL-ACTIVITY; CURRENTS; BRAIN
AB A number of studies have now shown that direct detection of neuronal firing by MRI may be possible. The optic nerve carries all visual information from the eye to the brain and is a particularly promising target for these measurements. However, it has been assumed that the effects of axonal firing may not be detectable, as a single firing event produces a bipolar waveform of around 1 ms duration whose effects should cancel oil MR. A simulation of the magnetic modulation which could feasibly be produced by the optic nerve over an extended period and with different firing rates has been developed. The Hodgkin-Huxley equations were calculated for ail array of model ganglion cell axons which were assumed to act as voltage to pulse frequency converters. Dependence of the modulating waveform on relative action potential firing start time was investigated. Although the simulated waveforms were bipolar at the beginning, during the period of MR acquisition the different frequencies combine to produce a largely positive waveform. The simulation included only contrast luminance changes and not color, spatial correlations or other more sophisticated processing in the retina. A gradient echo sequence was used at 3 T to create images for analysis by the ghost reconstructed alternating current estimation (GRACE) method from phantoms subject to current modulation by the actual modelled axonal waveforms. The optic nerve was also imaged using the same method during visual stimulus by a strobe light in adult human volunteers at 3 T. Analysis of digitized video recordings of eye locations during strobe stimulation outside the magnet showed no correlation with the applied strobe frequency over the short duration of the scans. images of the optic nerves at ail echo time of TE = 39 ms had weak but significant first harmonic ghosts in locations consistent with the applied stimulus as calculated from GRACE theory in just two out of thirteen studies on 10 volunteers and a detection rate of only 15% providing no clear evidence for direct detection in these experiments. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Paley, Martyn N. J.; Chow, Li Sze; Whitby, Elspeth H.] Univ Sheffield, Royal Hallamshire Hosp, Sheffield S10 2JF, Yorks, England.
C3 University of Sheffield
RP Paley, MNJ (corresponding author), Univ Sheffield, Royal Hallamshire Hosp, Glossop Rd, Sheffield S10 2JF, Yorks, England.
EM m.n.paley@sheffield.ac.uk
RI Whitby, Elspeth/G-5517-2010; Chow, Li Sze/J-4587-2015
OI Chow, Li Sze/0000-0003-3877-4434; Whitby, Elspeth/0000-0002-8912-8013
CR Bandettini PA, 2005, APPL MAGN RESON, V29, P65, DOI 10.1007/BF03166956
   Bodurka J, 1999, J MAGN RESON, V137, P265, DOI 10.1006/jmre.1998.1680
   Bodurka J, 2002, MAGNET RESON MED, V47, P1052, DOI 10.1002/mrm.10159
   Chow LS, 2006, NEUROIMAGE, V30, P835, DOI 10.1016/j.neuroimage.2005.10.024
   Chu RN, 2004, NEUROIMAGE, V23, P1059, DOI 10.1016/j.neuroimage.2004.07.003
   Felblinger J, 1996, MAGNET RESON MED, V36, P410, DOI 10.1002/mrm.1910360312
   Galambos R, 2003, INT J PSYCHOPHYSIOL, V48, P133, DOI 10.1016/S0167-8760(03)00050-3
   Hines ML, 2001, NEUROSCIENTIST, V7, P123, DOI 10.1177/107385840100700207
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Jessell TM., 2000, PRINCIPLES NEURAL SC
   Kamei H, 1999, IEEE T MAGN, V35, P4109, DOI 10.1109/20.800771
   Kenyon GT, 2004, IEEE T NEURAL NETWOR, V15, P1083, DOI 10.1109/TNN.2004.832722
   KOLB H, 2002, ORG RETINA VISUAL SY
   Konn D, 2004, MAGN RESON IMAGING, V22, P1413, DOI 10.1016/j.mri.2004.10.012
   Konn D, 2003, MAGN RESON MED, V50, P40, DOI 10.1002/mrm.10494
   MIKELBERG FS, 1989, OPHTHALMOLOGY, V96, P1325
   Riva CE, 2005, PROG RETIN EYE RES, V24, P183, DOI 10.1016/j.preteyeres.2004.07.002
   Song AW, 2001, MAGN RESON IMAGING, V19, P763, DOI 10.1016/S0730-725X(01)00406-4
   Stanisz GJ, 2005, MAGNET RESON MED, V54, P507, DOI 10.1002/mrm.20605
   STERLING P, 2003, SYNAPTIC ORG BRAIN
   WIKSWO JP, 1980, SCIENCE, V208, P53, DOI 10.1126/science.7361105
   Xiong JH, 2003, HUM BRAIN MAPP, V20, P41, DOI 10.1002/hbm.10124
   Yang H, 2003, MAGN RESON MED, V50, P633, DOI 10.1002/mrm.10573
NR 23
TC 9
Z9 11
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 331
EP 341
DI 10.1016/j.imavis.2008.05.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600003
DA 2024-07-18
ER

PT J
AU Van Aerschot, W
   Jansen, M
   Bultheel, A
AF Van Aerschot, W.
   Jansen, M.
   Bultheel, A.
TI Normal mesh based geometrical image compression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Normal multiresolution mesh; Image compression; Piecewise smooth;
   Wavelets
ID APPROXIMATION
AB Recently the performance of nonlinear transforms have been given a lot of attention to overcome the suboptimal n-terms approximation power of tensor product wavelet methods on higher dimensions. The suboptimal performance prevails when the latter are used for a sparse representation of functions consisting of smoothly varying areas separated by smooth contours. This paper introduces a method creating normal meshes with nonsubdivision connectivity to approximate the nonsmoothness of such images efficiently. From a domain decomposition viewpoint, the method is a triangulation refinement method preserving contours. The transform is nonlinear as it depends on the actual image. This paper proposes an normal offset based compression algorithm for digital images. The discretisation causes the transform to become redundant. We further propose a model to encode the obtained coefficients. We show promising rate distortion curves and compare the results with the JPEG2000 encoder. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Van Aerschot, W.; Jansen, M.; Bultheel, A.] Katholieke Univ Leuven, Dept Comp Sci, B-3000 Louvain, Belgium.
   [Jansen, M.] Katholieke Univ Leuven, Dept Math, B-3000 Louvain, Belgium.
C3 KU Leuven; KU Leuven
RP Van Aerschot, W (corresponding author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3000 Louvain, Belgium.
EM ward.vanaerschot@cs.kuleuven.be; maarten.jansen@wis.kuleuven.be;
   adhemar.bultheel@cs.kuleuven.be
RI Bultheel, Adhemar/A-2785-2016; Bultheel, Adhemar/N-5358-2019
OI Bultheel, Adhemar/0000-0001-9562-5297; Bultheel,
   Adhemar/0000-0001-9562-5297
FU Fund for Scientific Research (FWO) [G.0431.05]; Belgian Programme on
   Interuniversity Poles of Attraction; Belgian Federal Science Policy
   Office; Center Of Excellence on Optimisation in Engineering
FX The work is supported by the Fund for Scientific Research (FWO) project
   SMID: Stability of Multiscale Transforms on Irregular Data, grant
   #G.0431.05 and the Belgian Programme on Interuniversity Poles of
   Attraction, initiated by the Belgian Federal Science Policy Office and
   by the Center Of Excellence on Optimisation in Engineering of the
   K.U.Leuven.
CR Agarwal DK, 2002, ENVIRON ECOL STAT, V9, P341, DOI 10.1023/A:1020910605990
   [Anonymous], 2000, CURVES SURFACES
   Breiman L, 1998, BIOMETRICS, DOI [10.1201/9781315139470, DOI 10.2307/2530946]
   CHOI H, 2003, SGP 03, P52
   Daubechies I, 2004, CONSTR APPROX, V20, P399, DOI 10.1007/s00365-003-0543-4
   Dekel S, 2005, SIAM J NUMER ANAL, V43, P707, DOI 10.1137/040604649
   Demaret L, 2006, SIGNAL PROCESS, V86, P1604, DOI 10.1016/j.sigpro.2005.09.003
   DeVore R. A., 1998, Acta Numerica, V7, P51, DOI 10.1017/S0962492900002816
   DO MN, 2003, WAVELETS, P83
   Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261
   Friedel I, 2004, ACM T GRAPHIC, V23, P1061, DOI 10.1145/1027411.1027418
   GUSKOV I, 2000, SIGGRAPH 2000 C P
   JANSEN M, 2005, APPL COMPUTATIONAL H
   Khodakovsky A, 2004, MATH VISUAL, P189
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   Le Pennec E, 2005, MULTISCALE MODEL SIM, V4, P992, DOI 10.1137/040619454
   Payan F, 2005, COMPUT AIDED GEOM D, V22, P466, DOI 10.1016/j.cagd.2005.04.001
   SIMONCELLI E, 1999, SPIE P, V3813, P206
   SULLIVAN GJ, P SPIE, V5960
   VANAERSCHOT W, 2006, 475 TW KU LEUV DEP C
   VANAERSCHOT W, 2006, CURVES SURFACES AVIG
NR 21
TC 1
Z9 1
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 459
EP 468
DI 10.1016/j.imavis.2008.06.017
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600016
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Tistarelli, M
   Bicego, M
   Grosso, E
AF Tistarelli, Massimo
   Bicego, Manuele
   Grosso, Enrico
TI Dynamic face recognition: From human to machine vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Face recognition; Computer vision; Human perception
ID HIDDEN; DISCRIMINATION; AMYGDALA; INFANTS; MONKEY; AREA
AB As confirmed by recent neurophysiological studies, the use of dynamic information is extremely important for humans in visual perception of biological forms and motion. Apart from the mere computation of the visual motion of the viewed objects, the motion itself conveys far more information, which helps understanding the scene. This paper provides an overview and some new insights on the use of dynamic visual information for face recognition. In this context, not only physical features emerge in the face representation, but also behavioral features should be accounted. While physical features are obtained from the subject's face appearance, behavioral features are obtained from the individual motion and articulation of the face. In order to capture both the face appearance and the face dynamics, a dynamical face model based on a combination of Hidden Markov Models is presented. The number of states (or facial expressions) are automatically determined from the data by unsupervised clustering of expressions of faces in the video. The underlying architecture closely recalls the neural patterns activated in the perception of moving faces. Experimental results obtained from real video image data show the feasibility of the proposed approach. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Tistarelli, Massimo] Univ Sassari, DAP, Comp Vis Lab, I-07041 Alghero, SS, Italy.
   [Bicego, Manuele; Grosso, Enrico] Univ Sassari, DEIR, Comp Vis Lab, I-07100 Sassari, Italy.
C3 University of Sassari; University of Sassari
RP Tistarelli, M (corresponding author), Univ Sassari, DAP, Comp Vis Lab, Piazza Duomo 6, I-07041 Alghero, SS, Italy.
EM tista@uniss.it
RI Tistarelli, Massimo/AAH-9437-2021
OI Tistarelli, Massimo/0000-0002-3406-3048
CR AGGLETON JP, 1980, BRAIN RES, V190, P347, DOI 10.1016/0006-8993(80)90279-6
   [Anonymous], 2005, EXPRESS EMOT MAN, DOI DOI 10.1037/10001-000
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], THESIS CAMBRIDGE U
   [Anonymous], P EUR C COMP VIS
   [Anonymous], EYE MOVEMENTS VISION
   Bicego M, 2006, LECT NOTES COMPUT SC, V3832, P113
   Bicego M, 2005, LECT NOTES COMPUT SC, V3546, P329
   Bicego M, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P52, DOI 10.1109/ICIAP.2003.1234024
   BICEGO M, 2005, P SPIE INT WORKSH BI
   BIUK Z, 2001, P INT S IM SIGN PROC
   BRAATHEN B, 2001, ACM WORKSH PERC US I
   DAMASIO AR, 1982, NEUROLOGY, V32, P331, DOI 10.1212/WNL.32.4.331
   deHaan M, 1997, CHILD DEV, V68, P187, DOI 10.2307/1131845
   FAGAN JF, 1972, J EXP CHILD PSYCHOL, V14, P453, DOI 10.1016/0022-0965(72)90065-3
   Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079
   Gauthier I, 1999, NAT NEUROSCI, V2, P568, DOI 10.1038/9224
   GOREN CC, 1975, PEDIATRICS, V56, P544
   Hadid A., 2005, Electronic Letters on Computer Vision and Image Analysis, V5, P1, DOI [DOI 10.5565/REV/ELCVIA.80, 10.5565/rev/elcvia.80]
   HAITH MM, 1977, SCIENCE, V198, P853, DOI 10.1126/science.918670
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   KLIN A, 2001, NICHD COLLABORATIVE
   Knight B, 1997, VIS COGN, V4, P265, DOI 10.1080/713756764
   KOHIR VV, 1998, P WORKSH ADV FAC IM
   LEE KC, 2003, P INT C COMP VIS PAT
   LEONARD CM, 1985, BEHAV BRAIN RES, V15, P159, DOI 10.1016/0166-4328(85)90062-2
   LI C, 2000, THESIS VANDERBILT U
   Li Y., 2001, THESIS U LONDON QUEE
   LIU X, 2003, P INT C COMP VIS PAT
   McCarthy G, 1997, J COGNITIVE NEUROSCI, V9, P605, DOI 10.1162/jocn.1997.9.5.605
   Nahm FKD, 1997, J COGNITIVE NEUROSCI, V9, P611, DOI 10.1162/jocn.1997.9.5.611
   Nefian AV, 1998, INT CONF ACOUST SPEE, P2721, DOI 10.1109/ICASSP.1998.678085
   Nelson CA, 2001, INFANT CHILD DEV, V10, P3, DOI 10.1002/icd.239
   O'Toole AJ, 2002, TRENDS COGN SCI, V6, P261, DOI 10.1016/S1364-6613(02)01908-3
   OTOOLE A, 2006, COMMUNICATION
   Panuccio A., 2002, Structural, Syntactic, and Statistical Pattern Recognition. Joint IAPR International Workshops SSPR 2002 and SPR 2002 (Lecture Notes in Computer Science Vol. 2396), P734
   PICARD RW, 2000, IBM SYSTEM, V3
   PICARD RW, 2001, TR532 MIT SPIE
   PIKE A, 2006, COMMUNICATION
   RABINER L, 1989, P INT C AC SPEECH SI, P405
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Schultz RT, 2000, ARCH GEN PSYCHIAT, V57, P331, DOI 10.1001/archpsyc.57.4.331
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shepherd J., 1981, Perceiving and Remembering Faces, P55
   Smyth P, 1997, ADV NEUR IN, V9, P648
   Tistarelli M, 2000, IMAGE VISION COMPUT, V18, P299, DOI 10.1016/S0262-8856(99)00059-1
   Vaina LM, 2001, P NATL ACAD SCI USA, V98, P11656, DOI 10.1073/pnas.191374198
   WALTON GE, 1993, PSYCHOL SCI, V4, P203, DOI 10.1111/j.1467-9280.1993.tb00488.x
   WECHSLER H, 1998, NATO ASI SERIES F, V163
   WISKOTT L, 1995, P INT WORKSH AUT FAC, P92
   YAMAGUCHI O, 1998, P INT C AUT FAC GEST
   Zhou SH, 2003, COMPUT VIS IMAGE UND, V91, P214, DOI 10.1016/S1077-3142(03)00080-8
NR 54
TC 22
Z9 29
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 2
PY 2009
VL 27
IS 3
SI SI
BP 222
EP 232
DI 10.1016/j.imavis.2007.05.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 393QA
UT WOS:000262386600002
DA 2024-07-18
ER

PT J
AU Kovács, T
AF Kovacs, Tamas
TI A fast classification based method for fractal image encoding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fractal image compression; classification
ID COMPRESSION; SEARCH
AB In the present paper a fast and efficient fractal image encoding method based on classification of image blocks is presented. Two parameters are used to sort image blocks into disjoint classes: the direction of the approximate first derivative and a normalized root mean square error of the fitting plane in the given block. With the help of these parameters the number of domain blocks examined for a range block is reduced dramatically, and thus, the classification results in a considerable acceleration of the encoding process, without loss of the reconstruction fidelity. The proposed method is compared to recently developed fast classification algorithms and a 'No search algorithm', and its rate-distortion performance under the same encoding time limit is proved to be better than that of the others. (C) 2008 Published by Elsevier B.V.
C1 Kecskemet Coll, Fac Mech Engn & Automat, Inst Informat, H-6000 Kecskemet, Hungary.
RP Kovács, T (corresponding author), Kecskemet Coll, Fac Mech Engn & Automat, Inst Informat, Izsaki 10, H-6000 Kecskemet, Hungary.
EM kovacs.tamas@gamf.kefo.hu
CR [Anonymous], FRACTAL IMAGE COMPRE
   BANIEQBAL B, 1995, P SOC PHOTO-OPT INS, V2418, P67, DOI 10.1117/12.204140
   BARNSLEY MF, 1988, BYTE             JAN, P215
   Barnsley MF., 1993, Fractals Everywhere
   Belloulata K, 2005, J VIS COMMUN IMAGE R, V16, P55, DOI 10.1016/j.jvcir.2004.02.001
   Chung KL, 2006, CHAOS SOLITON FRACT, V29, P215, DOI 10.1016/j.chaos.2005.08.023
   Davis GM, 1998, IEEE T IMAGE PROCESS, V7, P141, DOI 10.1109/83.660992
   Distasi R, 1998, ELECTRON LETT, V34, P751, DOI 10.1049/el:19980597
   DUDBRIDGE F, 1994, FRACTAL IMAGE COMPRE, P231
   Duh DJ, 2005, IMAGE VISION COMPUT, V23, P1115, DOI 10.1016/j.imavis.2005.05.013
   ENDO D, 1998, P INT C IMAGE P ICIP, V981, P788
   Fisher Y., 1995, Fractal Image Compression: Theory and Application
   FISHER Y, 1992, SIGGRAPH 92 COURSE N, V12
   Hartenstein H, 2000, SIGNAL PROCESS-IMAGE, V16, P383, DOI 10.1016/S0923-5965(00)00003-5
   Hufnagl C, 2000, REAL-TIME IMAGING, V6, P267, DOI 10.1006/rtim.1998.0164
   Hurtgen B., 1993, SPIE VISUAL COMMUN P, P397
   Iano Y, 2006, IEEE T IMAGE PROCESS, V15, P98, DOI 10.1109/TIP.2005.860317
   JACQUIN AE, 1993, P IEEE, V81, P1451, DOI 10.1109/5.241507
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Monro D.M., 1992, P INT C AC SPEECH SI, V3, P4585
   SAUPE D, 1998, C P NATO ASI FRACTAL
   Shen FR, 2004, SIGNAL PROCESS-IMAGE, V19, P393, DOI 10.1016/j.image.2004.02.002
   Tong CS, 2002, IEEE T IMAGE PROCESS, V11, P605, DOI 10.1109/TIP.2002.1014992
   Tong CS, 2001, IEEE T IMAGE PROCESS, V10, P1269, DOI 10.1109/83.941851
   Truong TK, 2004, CHAOS SOLITON FRACT, V22, P1071, DOI 10.1016/j.chaos.2004.03.015
   Van de Walle A., 1997, Fractals, V5, P3, DOI 10.1142/S0218348X97000590
   Vidya D, 2000, J SYST ARCHITECT, V46, P1275, DOI 10.1016/S1383-7621(00)00018-7
   Wang Z, 2000, SIGNAL PROCESS-IMAGE, V15, P767, DOI 10.1016/S0923-5965(99)00018-1
   Wu XW, 2005, COMPUT ELECTR ENG, V31, P402, DOI 10.1016/j.compeleceng.2005.02.003
NR 29
TC 31
Z9 31
U1 0
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1129
EP 1136
DI 10.1016/j.imavis.2007.12.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300006
DA 2024-07-18
ER

PT J
AU Ozawa, K
AF Ozawa, Kazumasa
TI Dual fractals
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE dual fractals; dual-similarity; Hutchinson operator; image coding;
   template matching; secret sharing; feature extraction
AB This paper presents some definitions and propositions concerning to dual fractals. Among them, dual-similarity plays a key-role not only in generating dual fractals but also in handling inter-pattern relations. Dual-similarity is basically defined as a pair of the similarity relations between two patterns, from which two mirror operators have been derived. This paper shows that each mirror operator is nothing but a contraction mapping associated with a unique attractor. Next, the mirror operator has been extended to ring mapping defined as a cyclic sequence of contraction mappings for a sequence of patterns. Basic experiments have been carried out, correlating with some application schemes, to verify the obtained theoretical outcomes in the sense of approximation to the truth. (C) 2007 Elsevier B.V. All rights reserved.
C1 Osaka Electrocommun Univ, Dept Informat Engn, Osaka 5728530, Japan.
C3 Osaka Electro-Communication University
RP Ozawa, K (corresponding author), Osaka Electrocommun Univ, Dept Informat Engn, Neyagawa Shi, Osaka 5728530, Japan.
EM ozawa@ozlab.osakac.acjp
CR ARAKAWA K, 1996, MODELS IMAGE PROCESS, V5, P413
   Barnsley MF., 1993, Fractals Everywhere
   Cochran WO, 1996, IEEE T VIS COMPUT GR, V2, P313, DOI 10.1109/2945.556500
   DATCU M, 1996, P EUR C SYNTH AP RAD, P375
   Fisher Y., 1995, Fractal Image Compression: Theory and Application
   HUERIGEN B, 1994, SPIE P, V2308, P1683
   HUTCHINSON JE, 1981, INDIANA U MATH J, V30, P713, DOI 10.1512/iumj.1981.30.30055
   Luenberger D. G., 1997, Optimization by Vector Space Methods
   Mandelbrot B.B., 1977, FRACTALS FORM CHANCE
   Masaki T., 2000, Journal of the Institute of Image Electronics Engineers of Japan, V29, P147
   NAGAMOTO K, 2002, PRMU200289 IEICE, P55
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   Ozawa K., 2001, Proceedings of 12th Scandinavian Conference on Image Analysis, P759
   PEITGEN HO, 1991, FRACTALS CLASSROOM 1
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   Véhel JL, 1994, FRACTALS, V2, P379, DOI 10.1142/S0218348X94000478
NR 16
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 622
EP 631
DI 10.1016/j.imavis.2007.07.012
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900002
DA 2024-07-18
ER

PT J
AU Fu, J
   Caulfield, HJ
AF Fu, Jian
   Caulfield, H. John
TI Making a smarter color camera
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE artificial color; hyperspectral imaging; smart camera; divide and
   conquer
ID ARTIFICIAL COLOR; RECOGNITION
AB One meaning of "smart camera" is that it images objects in the class(es) of interest while not imaging objects in other class(es). Such a camera would be most useful if it were software controlled and operated at TV frame rates. In this paper, Artificial Color is applied in the design of such a camera. We show here how to segregate objects by color even when there are nearly identical neighboring colors. The process uses a multiple stage ("divide and conquer") approach. The method used employs only linear discriminants, so it is simple to implement in software, firmware, or hardware. An example of undoing one of nature's best camouflage efforts is shown. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Fu, Jian] Alabama A&M Univ, Dept Comp Sci, Normal, AL 35762 USA.
   [Caulfield, H. John] Alabama A&M Univ, Res Inst, Normal, AL 35762 USA.
C3 Alabama A&M University; Alabama A&M University
RP Fu, J (corresponding author), Alabama A&M Univ, Dept Comp Sci, Normal, AL 35762 USA.
EM jian.fu@email.aamu.edu; John.Caulfield@cim.aamu.edu
CR Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Caulfield HJ, 2006, APPL PHYS B-LASERS O, V84, P275, DOI 10.1007/s00340-006-2332-9
   Caulfield HJ, 2005, PATTERN RECOGN, V38, P1225, DOI 10.1016/j.patcog.2005.01.009
   Caulfield HJ, 2004, INFORM SCIENCES, V167, P1, DOI 10.1016/j.ins.2003.09.027
   Caulfield HJ, 2003, NEUROCOMPUTING, V51, P463, DOI 10.1016/S0925-2312(02)00698-7
   CAULFIELD HJ, 1984, OPT ENG, V23, P16, DOI 10.1117/12.7973245
   Chai SM, 2000, APPL OPTICS, V39, P835, DOI 10.1364/AO.39.000835
   DAVIS LS, 1999, 3 INT WORKSH COOP DI
   FRANKEL D, 1985, OPT ENG, V24, P996, DOI 10.1117/12.7973616
   Fu J, 2005, J IMAGING SCI TECHN, V49, P498
   Fu J, 2005, PATTERN RECOGN LETT, V26, P2244, DOI 10.1016/j.patrec.2005.03.032
   Fu J, 2005, IMAGE VISION COMPUT, V23, P761, DOI 10.1016/j.imavis.2005.05.009
   Fu J, 2004, J ELECTRON IMAGING, V13, P553, DOI 10.1117/1.1760081
   FU J, 2005, THESIS U ALABAMA HUN
   Fu J, 2007, PATTERN RECOGN, V40, P2251, DOI 10.1016/j.patcog.2006.12.023
   Fu J, 2007, J IMAGING SCI TECHN, V51, P148, DOI 10.2352/J.ImagingSci.Technol.(2007)51:2(148)
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025
   Wolf W, 2002, COMPUTER, V35, P48, DOI 10.1109/MC.2002.1033027
NR 19
TC 1
Z9 1
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 253
EP 258
DI 10.1016/j.imavis.2007.06.004
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500009
DA 2024-07-18
ER

PT J
AU Zhao, Z
   Teoh, EK
AF Zhao, ZheEn
   Teoh, Eam Khwang
TI A new scheme for automated 3D PDM construction using deformable models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Point Distribution Model Construction; automatic landmarking; Active
   Shape Model
ID ACTIVE SHAPE MODELS; APPEARANCE MODELS; SEGMENTATION; REGISTRATION;
   SEQUENCES
AB This paper describes a novel scheme to build a 3D Point Distribution Model (PDM) from a set of segmented training volumetric images. This approach is based on a deformable model algorithm to find correspondences across a set of surfaces/samples. It selects one sample as the template, and then deforms the template to approximate all other samples. These approximations carry the correspondences from the template to all other samples. The challenge is that a single template cannot guarantee accurate approximations to all other samples. The proposed solution is first to select the template sample, which brings the most accurate approximations to others among all samples. For each sample, which is not approximated accurately by the template, a "bridge" sample is chosen so that the bridge approximates accurately the current sample and the template approximates accurately to the bridge. The correspondences are then carried over from the template to the current sample via the "bridge". A PDM is then constructed from the set of template's approximations to all samples. This method is applied to construct four PDMs from 3D human brain Magnetic Resonance Images (MRIs). The four 3D PDMs constructed show considerable improvement on the approximation accuracy as compared to that constructed by adapting arbitrary templates. This improvement is important, as the approximation accuracy is the major concern of the deformable model-based approaches for the construction of PDMs. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Zhao, ZheEn] Duke Univ, Dept Psychiat, Durham, NC 27705 USA.
   [Zhao, ZheEn; Teoh, Eam Khwang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Duke University; Nanyang Technological University
RP Zhao, Z (corresponding author), Duke Univ, Dept Psychiat, Durham, NC 27705 USA.
EM kurtzhao@pmail.ntu.edu.sg
CR BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bosch JG, 2002, IEEE T MED IMAGING, V21, P1374, DOI 10.1109/TMI.2002.806427
   BRETT A, 2000, P MED IMAGE UNDERSTA, P175
   Brett AD, 1999, IMAGE VISION COMPUT, V17, P635, DOI 10.1016/S0262-8856(98)00184-X
   Brett AD, 2000, IMAGE VISION COMPUT, V18, P739, DOI 10.1016/S0262-8856(99)00077-3
   COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4
   Cootes TF, 2004, LECT NOTES COMPUT SC, V2034, P316
   DAVIES RH, 2002, P EUR C COMP VIS 3, P3
   de Bruijne M, 2003, LECT NOTES COMPUT SC, V2732, P136
   Frangi AF, 2002, IEEE T MED IMAGING, V21, P1151, DOI 10.1109/TMI.2002.804426
   HILL A, 1994, BMVC94 - PROCEEDINGS OF THE 5TH BRITISH MACHINE VISION CONFERENCE, VOLS 1 AND 2, P429
   Hill A, 2000, IEEE T PATTERN ANAL, V22, P241, DOI 10.1109/34.841756
   Hill A., 1993, fth British Machine Vision Conference, P1, DOI DOI 10.5244/C.7.34
   Hutton T., 2003, British Machine Vision Conference, P439
   IBANEZ L, INS SOFTW CONS
   *ISBR, INT BRAIN SEGM REP
   Kaus MR, 2004, MED IMAGE ANAL, V8, P245, DOI 10.1016/j.media.2004.06.015
   Kaus MR, 2003, IEEE T MED IMAGING, V22, P1005, DOI 10.1109/TMI.2003.815864
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Mitchell SC, 2002, IEEE T MED IMAGING, V21, P1167, DOI 10.1109/TMI.2002.804425
   Paglieroni DW, 2004, PATTERN RECOGN, V37, P1607, DOI 10.1016/j.patcog.2004.01.017
   Paulsen R., 2002, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2002. 5th International Conference. Proceedings, Part II (Lecture Notes in Computer Science Vol.2489), P373
   Paulsen RR, 2003, LECT NOTES COMPUT SC, V2732, P1
   Rueckert D, 2003, IEEE T MED IMAGING, V22, P1014, DOI 10.1109/TMI.2003.815865
   Schroeder W., 1998, The visualization toolkit an object-oriented approach to 3D graphics
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   Shahidi R, 2001, Comput Aided Surg, V6, P176, DOI 10.3109/10929080109146004
   Shen DG, 2001, IEEE T MED IMAGING, V20, P257, DOI 10.1109/42.921475
   Stefanescu R, 2004, MED IMAGE ANAL, V8, P325, DOI 10.1016/j.media.2004.06.010
   Styner M, 2003, MED IMAGE ANAL, V7, P207, DOI 10.1016/S1361-8415(02)00110-X
   Taylor R.H., 1995, COMPUTER INTEGRATED
   Walker KN, 2002, IMAGE VISION COMPUT, V20, P435, DOI 10.1016/S0262-8856(02)00014-8
   Xue Z, 2001, PATTERN RECOGN, V34, P1171, DOI 10.1016/S0031-3203(00)00067-4
   ZHAO Z, 2006, THESIS NANYANG TECHN
NR 34
TC 7
Z9 10
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 275
EP 288
DI 10.1016/j.imavis.2007.06.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500011
DA 2024-07-18
ER

PT J
AU Rothenstein, AL
   Tsotsos, JK
AF Rothenstein, Albert L.
   Tsotsos, John K.
TI Attention links sensing to recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE cognitive vision; attention; recognition; selective tuning
ID SELECTIVE VISUAL-ATTENTION; LATERAL GENICULATE-NUCLEUS; SACCADE TARGET
   SELECTION; FRONTAL EYE FIELD; EXTRASTRIATE CORTEX; SUPERIOR COLLICULUS;
   SPATIAL ATTENTION; SEARCH TASK; OBJECT RECOGNITION; COMPLEXITY LEVEL
AB This paper presents arguments that explicit strategies for visual attentional selection are important for cognitive vision systems, and shows that a number of proposals currently exist for exactly how parts of this goal may be accomplished. A comprehensive survey of approaches to computational attention is given. A key characteristic of virtually all the models surveyed here is that they receive significant inspiration from the neurobiology and psychophysics of human and primate vision. This, although not necessarily a key component of mainstream computer vision, seems very appropriate for cognitive vision systems given a definition of the topic that always includes the goal of human-like visual performance. A particular model, the Selective Tuning model, is overviewed in some detail. The growing neurobiological and psychophysical evidence for its biological plausibility is cited highlighting the fact that it has more biological support than other models; it is further claimed that it may form an appropriate starting point for the difficult task of integrating attention into cognitive vision systems. (c) 2006 Elsevier B.V. All rights reserved.
C1 York Univ, Ctr Vis Res, Dept Comp Sci, N York, ON M3J 1P3, Canada.
C3 York University - Canada
RP Rothenstein, AL (corresponding author), York Univ, Ctr Vis Res, Dept Comp Sci, 4700 Keele St, N York, ON M3J 1P3, Canada.
EM albertlr@cs.yorku.ca; tsotsos@cs.yorku.ca
RI Tsotsos, John K/G-3436-2011; Tsotsos, John/N-1131-2019; Tsotsos,
   John/HTO-0616-2023
OI Tsotsos, John/0000-0002-8621-9147; 
CR ALOIMONOS J, 1993, ACTIVE PERCEPTION CO, P292
   ANDERSON CH, 1987, P NATL ACAD SCI USA, V84, P6297, DOI 10.1073/pnas.84.17.6297
   [Anonymous], 7 INT C ART NEUR NET
   [Anonymous], 1998, ATTENTION
   BACKER G, 2003, INT WORKSH ATT PERF
   Bahcall DO, 1999, VISION RES, V39, P71, DOI 10.1016/S0042-6989(98)00090-X
   Baluja S, 1997, ARTIF INTELL, V97, P381, DOI 10.1016/S0004-3702(97)00065-9
   Barlow H B, 1972, Perception, V1, P371, DOI 10.1068/p010371
   BENAV MB, 1992, PERCEPT PSYCHOPHYS, V52, P277, DOI 10.3758/BF03209145
   BIEDERMA.I, 1972, SCIENCE, V177, P77, DOI 10.1126/science.177.4043.77
   BRAUN J, 1990, PERCEPT PSYCHOPHYS, V48, P45, DOI 10.3758/BF03205010
   Britten KH, 1996, NATURE, V382, P497, DOI 10.1038/382497a0
   Caputo G, 1998, VISION RES, V38, P669, DOI 10.1016/S0042-6989(97)00189-2
   Chun MM, 1998, COGNITIVE PSYCHOL, V36, P28, DOI 10.1006/cogp.1998.0681
   CULHANE S, 1992, 2 EUR C COMP VIS
   Cutzu F, 2003, VISION RES, V43, P205, DOI 10.1016/S0042-6989(02)00491-1
   Deco G, 2001, J COMPUT NEUROSCI, V10, P231, DOI 10.1023/A:1011233530729
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   DICKMANNS ED, 1992, J APPL INTELLIGENCE, V2, P251
   DRAPER BA, 2003, INT WORKSH ATT PERF
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1
   FUKUSHIMA K, 1991, INT JOINT C NEUR NET
   Ghose GM, 1999, NEURON, V24, P79, DOI 10.1016/S0896-6273(00)80823-5
   Gottlieb JP, 1998, NATURE, V391, P481, DOI 10.1038/35135
   HELMHOLTZ HV, 1924, SOUTHALLHELMHOLTZS T, P3
   Horowitz TS, 1998, NATURE, V394, P575, DOI 10.1038/29068
   Horwitz GD, 1999, SCIENCE, V284, P1158, DOI 10.1126/science.284.5417.1158
   Ignashchenkova A, 2004, NAT NEUROSCI, V7, P56, DOI 10.1038/nn1169
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   ITTI L, 1999, SPIE HUMAN VISION EL
   Joseph JS, 1997, NATURE, V387, P805, DOI 10.1038/42940
   Kastner S, 1998, SCIENCE, V282, P108, DOI 10.1126/science.282.5386.108
   Klein RM, 2000, TRENDS COGN SCI, V4, P138, DOI 10.1016/S1364-6613(00)01452-2
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   KOCH C, 1984, THEORETICAL ANAL EL
   Kristjánsson A, 2002, VISION RES, V42, P2039, DOI 10.1016/S0042-6989(02)00129-3
   Kustov AA, 1996, NATURE, V384, P74, DOI 10.1038/384074a0
   LEE KW, 2003, INT WORKSH ATT PERF
   Lee TS, 2002, NAT NEUROSCI, V5, P589, DOI 10.1038/nn860
   Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9
   MALJKOVIC V, 1994, MEM COGNITION, V22, P657, DOI 10.3758/BF03209251
   McPeek RM, 2002, J NEUROPHYSIOL, V88, P2019, DOI 10.1152/jn.2002.88.4.2019
   Mehta SD, 2000, CEREB CORTEX, V10, P343, DOI 10.1093/cercor/10.4.343
   MORAN J, 1985, SCIENCE, V229, P782, DOI 10.1126/science.4023713
   Mounts JRW, 1999, PERCEPT PSYCHOPHYS, V61, P322, DOI 10.3758/BF03206891
   Mounts JRW, 2000, PERCEPT PSYCHOPHYS, V62, P969, DOI 10.3758/BF03212082
   MOZER MC, 1983, J EXP PSYCHOL HUMAN, V9, P531, DOI 10.1037/0096-1523.9.4.531
   MOZER MC, 1991, NEURAL NETWORK MODEL, P217
   Müller NG, 2005, VISION RES, V45, P1129, DOI 10.1016/j.visres.2004.11.003
   Müller NG, 2004, NEUROREPORT, V15, P977, DOI 10.1097/01.wnr.000012504766941.17
   O'Connor DH, 2002, NAT NEUROSCI, V5, P1203, DOI 10.1038/nn957
   Oliva A, 2003, IEEE INT C IM PROC B
   OLSHAUSEN BA, 1993, J NEUROSCI, V13, P4700
   PETERSEN SE, 1987, NEUROPSYCHOLOGIA, V25, P97, DOI 10.1016/0028-3932(87)90046-7
   POSNER MI, 1990, ANNU REV NEUROSCI, V13, P25, DOI 10.1146/annurev.ne.13.030190.000325
   Postma EO, 1997, NEURAL NETWORKS, V10, P993, DOI 10.1016/S0893-6080(97)00034-8
   Pouget A., 1995, HDB BRAIN THEORY NEU, P335
   RENSINK RA, 2000, PSYCHE, P6
   Reynolds JH, 1999, J NEUROSCI, V19, P1736
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   ROBINSON DL, 1992, TRENDS NEUROSCI, V15, P127, DOI 10.1016/0166-2236(92)90354-B
   ROLLS ET, 2002, COMPUTATIONAL NEUROS, pR18
   Roskies AL, 1999, NEURON, V24, P7, DOI 10.1016/S0896-6273(00)80817-X
   Rybak IA, 1998, VISION RES, V38, P2387, DOI 10.1016/S0042-6989(98)00020-0
   SANDINI G, 1993, ACTIVE PERCEPTION
   Schall JD, 2004, VISION RES, V44, P1453, DOI 10.1016/j.visres.2003.10.025
   SCHALL JD, 1995, REV NEUROSCIENCE, V6, P63
   SHERMAN SM, 1986, EXP BRAIN RES, V63, P1
   Slotnick SD, 2003, NEUROIMAGE, V19, P1602, DOI 10.1016/S1053-8119(03)00187-3
   Slotnick SD, 2002, NEUROREPORT, V13, P773, DOI 10.1097/00001756-200205070-00008
   STEINMAN BA, 1995, VISION RES, V35, P1859, DOI 10.1016/0042-6989(94)00276-R
   THOMPSON KG, 1977, J NEUROPHYSIOL, V77, P1046
   TIPPER SP, 1988, MEM COGNITION, V16, P64, DOI 10.3758/BF03197746
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
   TREISMAN A, 1982, COGNITIVE PSYCHOL, V14, P107, DOI 10.1016/0010-0285(82)90006-8
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9
   TSOTSOS JK, 1991, BEHAV BRAIN SCI, V14, P768
   Tsotsos JK, 2005, COMPUT VIS IMAGE UND, V100, P3, DOI 10.1016/j.cviu.2004.10.011
   TSOTSOS JK, 1990, BEHAV BRAIN SCI, V13, P423, DOI 10.1017/S0140525X00079577
   TSOTSOS JK, 1995, ARTIF INTELL, V75, P135, DOI 10.1016/0004-3702(94)00019-W
   TSOTSOS JK, 1992, INT J COMPUT VISION, V7, P127, DOI 10.1007/BF00128132
   TSOTSOS JK, 1989, INT JOINT C ART INT
   Tsotsos JK, 1987, INT C COMP VIS HUM M
   TSOTSOS JK, 1999, PSYCHE INTERDISCIPLI
   TSOTSOS JK, 2002, C BIOL MOT COMP VIS
   vandeLaar P, 1997, NEURAL NETWORKS, V10, P981, DOI 10.1016/S0893-6080(97)00031-2
   Vanduffel W, 2000, CEREB CORTEX, V10, P109, DOI 10.1093/cercor/10.2.109
   VERNON D, 2003, DAGST SEM
   von der Malsburg C, 1999, NEURON, V24, P95, DOI 10.1016/S0896-6273(00)80825-9
   WAI W, 1994, IAPR C PATT REC JER
   Walther D, 2002, LECT NOTES COMPUT SC, V2525, P472
   WIXSON L, 1994, GAZE SELECTION VISUA, pR14
   Wolfe JM, 2003, TRENDS COGN SCI, V7, P70, DOI 10.1016/S1364-6613(02)00024-4
   Wolfe JM, 2000, J EXP PSYCHOL HUMAN, V26, P693, DOI 10.1037/0096-1523.26.2.693
   Yantis S, 2002, NAT NEUROSCI, V5, P995, DOI 10.1038/nn921
NR 96
TC 36
Z9 46
U1 0
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 114
EP 126
DI 10.1016/j.imavis.2005.08.011
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100010
DA 2024-07-18
ER

PT J
AU Smith, P
   Lobo, ND
   Shah, M
AF Smith, Paul
   Lobo, Niels da Vitoria
   Shah, Mubarak
TI Resolving hand over face occlusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE human-computer interaction; HCI; occlusion
AB The ability to segment or track the hand is an important problem in computer vision. While various solutions have been proposed, many methods do not work against complex or cluttered backgrounds. Solving these cases is essential to solving many problems in the domain of computer vision such as, human-computer interaction (HCI), surveillance, and virtual reality (i.e., augmented desks). This paper presents a method to segment the hand over complex backgrounds, such as the face. The similar colors and texture of the hand and face make the problem particularly challenging. The method is not restricted to only segmenting hands across faces and uses no knowledge of hands. Our method is based on the underlying concept of an image force field. In this representation change is measured through how particles move through the field. Each individual image location consists of a vector value which is a nonlinear combination of the remaining pixels in the image. We introduce and develop a novel physics-based feature that is able to measure regional structure in the image thus avoiding the problem of local pixel-based analysis, which breaks down under our conditions. The regional image structure changes in the occluded region during occlusion, while elsewhere the regional structure remains relatively constant. We model the regional image structure at all image locations over time using a mixture of Gaussians (MoG) to detect the occluded region in the image. We have tested the method on a number of sequences demonstrating the versatility of the proposed approach. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Cent Florida, Sch Comp Sci, Comp Vis Lab, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Smith, P (corresponding author), Univ Cent Florida, Sch Comp Sci, Comp Vis Lab, Orlando, FL 32816 USA.
EM rsmith@cs.ucf.edu; niels@cs.ucf.edu; shah@cs.ucf.edu
RI Sahoo, Sarat Kumar/J-8765-2014
OI Sahoo, Sarat Kumar/0000-0001-5734-6844; Shah,
   Mubarak/0000-0001-6172-5572
CR AHMAD T, 1997, IMAGE VISION COMPUTI
   [Anonymous], PAMI
   ARGYROS AA, 2004, CVPR
   Athitsos V., 2003, CVPR
   BRETZNER L, 2002, AUTOMATIC FACE GESTU
   BRTHES L, 2004, INT C ROB AUT
   Comaniciu D., 2000, CVPR
   CUI Y, 1995, AUTOMATIC FACE GESTU
   CUI Y, 1996, AUTOMATIC FACE GESTU
   DAVIS J, 1994, ECCV
   FEI H, 2004, ECCV
   HAMADA Y, 2004, AUTOMATIC FACE GESTU
   HURLEY DJ, 2002, IVC
   JEONG MH, 2001, 11 INT C IM AN PROC
   KOLSCH M, 2004, AUTOMATIC FACE GESTU
   MOLLOY D, 1999, 7 INT C IM PROC ITS
   SATOH Y, 2002, ICPR
   SHAN C, 2004, AUTOMATIC FACE GESTU
   SHERRAH J, 2000, BMVC
   STEFANOV N, 2005, CVPR
   STENGER B, 2004, INT WORKSH HUM COMP
   TOMANICIU D, 2002, TPAMI
   TRIESCH J, 2002, IMAGE VISION COMPUTI
   TRIESCH J, 2001, TPAMI
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]
   Wang Huiyu, 2021, CVPR
   ZHOU H, 2003, ICCV
   ZHU X, 2000, AUTOMATIC FACE GESTU
NR 28
TC 10
Z9 11
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1432
EP 1448
DI 10.1016/j.imavis.2006.12.012
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000006
DA 2024-07-18
ER

PT J
AU Czyz, J
   Ristic, B
   Macq, B
AF Czyz, Jacek
   Ristic, Branko
   Macq, Benoit
TI A particle filter for joint detection and tracking of color objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE visual tracking; particle filter; hybrid sequential estimation;
   multiple-target tracking
AB Color is a powerful feature for tracking deformable objects in image sequences with complex backgrounds. The color particle filter has proven to be an efficient, simple and robust tracking algorithm. In this paper, we present a hybrid valued sequential state estimation algorithm, and its particle filter-based implementation, that extends the standard color particle filter in two ways. First, target detection and deletion are embedded in the particle filter without relying on an external track initialization and cancellation algorithm. Second, the algorithm is able to track multiple objects sharing the same color description while keeping the attractive properties of the original color particle filter. The performance of the proposed filter are evaluated qualitatively on various real-world video sequences with appearing and disappearing targets. (c) 2006 Elsevier B.V. All rights reserved.
C1 Catholic Univ Louvain, Commun Lab, B-1348 Louvain, Belgium.
   DSTO, ISRD, Edinburgh, SA 5111, Australia.
C3 Universite Catholique Louvain; Defence Science & Technology
RP Czyz, J (corresponding author), Catholic Univ Louvain, Commun Lab, Pl Levant 2, B-1348 Louvain, Belgium.
EM czyz@tele.ucl.ac.be
RI Ristic, Branko/J-9948-2017
OI Ristic, Branko/0000-0001-8561-4412
CR [Anonymous], 2000, P IEEE C COMP VIS PA
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Black MJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P16, DOI 10.1109/AFGR.1998.670919
   COX IJ, 1993, INT J COMPUT VISION, V10, P53, DOI 10.1007/BF01440847
   DAUM FE, 2003, P IEEE AER C BIG SKY
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   DOUCET A, 2001, SEQUENTIAL M CARLO M
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Haritaoglu I., 1998, EUR C COMPUTER VISIO, P877
   Hue C, 2002, IEEE T AERO ELEC SYS, V38, P791, DOI 10.1109/TAES.2002.1039400
   Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Isard M., 1996, Proceedings of the European Conference on Computer Vision (ECCV), P343
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   PEREZ P, 2002, INCS, V2350, P661
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   Ristic B., 2003, Beyond the Kalman Filter: Particle Filters for Tracking Applications
   Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110
   WELCH G, 95041 TR
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yilmaz A, 2003, IMAGE VISION COMPUT, V21, P623, DOI 10.1016/S0262-8856(03)00059-3
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 24
TC 82
Z9 107
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1271
EP 1281
DI 10.1016/j.imavis.2006.07.027
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000008
DA 2024-07-18
ER

PT J
AU Hayet, JB
   Lerasle, F
   Devy, M
AF Hayet, J. B.
   Lerasle, F.
   Devy, M.
TI A visual landmark framework for mobile robot navigation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE visual landmarks; visual navigation; object recognition
AB This article describes visual functions dedicated to the extraction and recognition of visual landmarks, here planar quadrangles detected by a single camera. Landmarks are extracted among edge segments through a relaxation scheme, used to apply geometrical, topological and appearance constraints on sets of segments. Once extracted, such a landmark is characterized by invariant attributes so that recognition is made possible from a large range of viewpoints.
   Landmarks are represented by an icon which is built using the homography between the current viewpoint and a reference shape (a square). When detected again, the landmark is recognized by using a distance between icons. We propose a comparison of several of these metrics and an evaluation on actual and synthetic images that shows the validity of our approach. Results issued from experiments of a mobile robot navigating in an indoor environment are finally presented. (c) 2006 Elsevier B.V. All rights reserved.
C1 CNRS, LAAS, F-31077 Toulouse, France.
C3 Centre National de la Recherche Scientifique (CNRS)
RP Hayet, JB (corresponding author), CNRS, LAAS, 7 Ave Colonel Roche, F-31077 Toulouse, France.
EM Jean-Bernard.Hayet@ensta.org
RI Hayet, Jean-Bernard/AAQ-8527-2020
OI Hayet, Jean-Bernard/0000-0002-6662-2553
CR BRANCA A, 2000, P INT S ROB AUT ISRA, P569
   CHOSET H, 1997, GRAPH
   Colios CI, 2000, INT C PATT RECOG, P128, DOI 10.1109/ICPR.2000.902880
   ELINAS P, 2006, P IEEE INT C ROB AUT
   FOX D, 1999, J ARTIFICIAL INTELLI, V11, P1265
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   HAYET JB, 2003, P INT C ROB AUT ICRA
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V19
   Jang GJ, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1037, DOI 10.1109/ROBOT.2002.1013492
   Launay F, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P3918, DOI 10.1109/ROBOT.2002.1014338
   MATA M, 2001, P INT C ROB AUT ICRA
   Mikolajczyk K., 2003, P INT C COMP VIS PAT
   MORISSET B, 2002, P INT C INT AUT SYST
   SANTOSVICTOR J, 1999, P INT C COMP VIS SYS, P1799
   Se S, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P226, DOI 10.1109/IRDS.2002.1041393
   Sim R, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1972, DOI 10.1109/ROBOT.1999.770397
   Thrun S., 2002, Robotic mapping: A survey
NR 17
TC 23
Z9 30
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1341
EP 1351
DI 10.1016/j.imavis.2006.08.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dou, WB
   Ruan, S
   Chen, YP
   Bloyet, D
   Constans, JM
AF Dou, Weibei
   Ruan, Su
   Chen, Yanping
   Bloyet, Daniel
   Constans, Jean-Marc
TI A framework of fuzzy information fusion for the segmentation of brain
   tumor tissues on MR images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE fuzzy; information fusion; segmentation; brain tumor; MRI
ID OBJECT DEFINITION; CONNECTEDNESS; ALGORITHMS
AB A framework of fuzzy information fusion is proposed in this paper to automatically segment tumor areas of human brain from multispectral magnetic resonance imaging (MRI) such as T1-weighted, T2-weighted and proton density (PD) images. A priori knowledge about tumors described by radiology experts for different types of MR1 are very helpful to guide a automatic and a precise segmentation. However, the terminology used by radiology experts are variable in term of image signal. In order to benefit of these descriptions, we propose to modellize them by fuzzy models. One fuzzy model is built for one type of MR1 sequence. The segmentation is finally based on a fusion of different fuzzy information obtained from different types of MRI images. Our algorithm consists of four stages: the registration of multispectral MR images, the creation of fuzzy models describing the characteristics of tumor, the fusion based on fuzzy fusion operators and the adjustment by fuzzy region growing based on fuzzy connecting. The comparison between the obtained results and the hand-tracings of a radiology expert shows that the proposed algorithm is efficient. An average probability of correct detection 96% and an average probability of false detection 5% are obtained through studies of four patients. (c) 2006 Elsevier B.V. All rights reserved.
C1 CNRS, GREYC, UMR 6072, F-14050 Caen, France.
   Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   CCReSTIC, F-10026 Troyes, France.
   Nanfang Hosp, Imaging Dianost Ctr, Guangzhou, Peoples R China.
   CHRU, EA3916, Unite IRM, F-14033 Caen, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de Caen
   Normandie; Tsinghua University; Southern Medical University - China; CHU
   de Caen NORMANDIE; Universite de Caen Normandie
RP Dou, WB (corresponding author), CNRS, GREYC, UMR 6072, 6 Blvd Marechal Juin, F-14050 Caen, France.
EM douwb@tsinghua.edu.cn
RI ; Dou, Weibei/K-6044-2012
OI Ruan, Su/0000-0001-8785-6917; Dou, Weibei/0000-0001-8555-2776
CR Aguilar M., 2002, ISIF, P1206
   ALEXANDER E, 1996, NEUROSURGERY CLIN AP, P260
   [Anonymous], P 8 NAT DAT FUS C DA
   Barra V, 2001, IEEE T MED IMAGING, V20, P549, DOI 10.1109/42.932740
   Behloul F, 1998, P ANN INT IEEE EMBS, V20, P492, DOI 10.1109/IEMBS.1998.745954
   CABRAL JE, 1993, MED IMAGING IMAGE PR, V1898, P171
   Clark MC, 1998, IEEE T MED IMAGING, V17, P187, DOI 10.1109/42.700731
   Fan Y, 2002, IEEE T MED IMAGING, V21, P904, DOI 10.1109/TMI.2002.803126
   Gibbs P, 1996, PHYS MED BIOL, V41, P2437, DOI 10.1088/0031-9155/41/11/014
   Hamacher H., 1978, Fuzzy Sets and Systems, V1, P269, DOI 10.1016/0165-0114(78)90018-0
   Ho S, 2002, INT C PATT RECOG, P532, DOI 10.1109/ICPR.2002.1044788
   Kaus MR, 2001, RADIOLOGY, V218, P586, DOI 10.1148/radiology.218.2.r01fe44586
   KLIR G, 2000, OPERATIONS FUZZY SET
   LEFEVRE E, 2000, CGIP 2000 1 INT C CO
   MANCAS M, P IEEE VIS C 2003
   PEDRYCZ, 1998, INTRO FUZZY SETS ANA
   Pitiot A, 2002, IEEE T MED IMAGING, V21, P910, DOI 10.1109/TMI.2002.803124
   Ruan S, 2002, COMPUT VIS IMAGE UND, V85, P54, DOI 10.1006/cviu.2002.0957
   Saha PK, 2001, COMPUT VIS IMAGE UND, V83, P275, DOI 10.1006/cviu.2001.0927
   Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174
   Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021
   Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750
   Udupa JK, 2002, IEEE T PATTERN ANAL, V24, P1485, DOI 10.1109/TPAMI.2002.1046162
   Van Leemput K, 2003, IEEE T MED IMAGING, V22, P105, DOI 10.1109/TMI.2002.806587
   Warfield SK, 2000, MED IMAGE ANAL, V4, P43, DOI 10.1016/S1361-8415(00)00003-7
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 26
TC 105
Z9 114
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 164
EP 171
DI 10.1016/j.imavis.2006.01.025
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700005
DA 2024-07-18
ER

PT J
AU De, I
   Chanda, B
   Chattopadhyay, B
AF De, Ishita
   Chanda, Bhabatosh
   Chattopadhyay, Buddhajyoti
TI Enhancing effective depth-of-field by image fusion using mathematical
   morphology
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE depth-of-field; multifocus images; registration; correlation; image
   fusion; morphological filters; multiscale top-hat transformation; image
   gradient
ID MOTION ESTIMATION; SEARCH ALGORITHM; REGISTRATION
AB Reduced depth-of-field (DOF) poses a problem in the light optical imaging system, since the objects present outside this zone appear blurry in the recorded image. The effective DOF of the sensor may be enhanced considerably without compromising the quality of the image by fusing images captured with different focused regions. This paper presents an image fusion technique suitable for combining multifocus images of a scene. The method employs morphological filters to select sharply focused regions from various images and then combines them together to reconstruct the image in which all the regions are properly focused. A performance measure based on image gradients is used to compare the results obtained by the proposed method with those obtained by other image fusion techniques. (c) 2006 Elsevier B.V. All rights reserved.
C1 Indian Stat Inst, Elect & Commun Sci Unit, Kolkata 700108, India.
   Barrackpore Rastraguru Surendranath Coll, Dept Comp Sci, Kolkata 700120, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Chanda, B (corresponding author), Indian Stat Inst, Elect & Commun Sci Unit, Kolkata 700108, India.
EM chanda@isical.ac.in
CR [Anonymous], P 4 INT C COMP VIS B
   [Anonymous], P 3 INT C INF FUS
   Bloch I, 1996, IEEE T SYST MAN CY A, V26, P52, DOI 10.1109/3468.477860
   Bradburn S, 1998, APPL EXTENDED DEPTH
   Brown L.G., 1992, ACM COMPUT SURV, V24, P325, DOI DOI 10.1145/146370.146374
   Chanda B., 2000, DIGITAL IMAGE PROCES
   CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464
   Eltoukhy H. A., 2003, P SPIE EL IM JUN
   GHANBARI M, 1990, IEEE T COMMUN, V38, P950, DOI 10.1109/26.57512
   Li BY, 2003, CHROMATOGRAPHIA, V57, P235, DOI 10.1007/BF02491722
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   MATSOPOULOS GK, 1994, IEE P-VIS IMAGE SIGN, V141, P137, DOI 10.1049/ip-vis:19941184
   Mukhopadhyay S, 2001, PATTERN RECOGN, V34, P1939, DOI 10.1016/S0031-3203(00)00123-0
   Perlman P., 1971, BASIC MICROSCOPE TEC
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Roberts L. G., 1965, OPTICAL ELECT OPTICA
   Robinson D, 2004, IEEE T IMAGE PROCESS, V13, P1185, DOI 10.1109/TIP.2004.832923
   Seales WB, 1996, P SOC PHOTO-OPT INS, V2905, P227, DOI 10.1117/12.256333
   ZHANG Z, 1998, 32 AS C SIGN SYST CO, V1, P603
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 21
TC 97
Z9 117
U1 1
U2 26
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2006
VL 24
IS 12
BP 1278
EP 1287
DI 10.1016/j.imavis.2006.04.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 107AH
UT WOS:000242142600002
DA 2024-07-18
ER

PT J
AU Meng, Q
   Li, B
   Holstein, H
AF Meng, Q.
   Li, B.
   Holstein, H.
TI Recognition of human periodic movements from unstructured information
   using a motion-based frequency domain approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE human periodic motion classification; motion-based recognition; gait
   analysis; visual perception; moving light displays (MLDs); motion power
   spectral analysis
ID GAIT RECOGNITION; PERCEPTION; TRACKING
AB Feature-based motion cues play an important role in biological visual perception. We present a motion-based frequency-domain scheme for human periodic motion recognition. As a baseline study of feature based recognition we use unstructured feature-point kinematic data obtained directly from a marker-based optical motion capture (MoCap) system, rather than accommodate bootstrapping from the low-level image processing of feature detection. Motion power spectral analysis is applied to a set of unidentified trajectories of feature points representing whole body kinematics. Feature power vectors are extracted from motion power spectra and mapped to a low dimensionality of feature space as motion templates that offer frequency domain signatures to characterise different periodic motions. Recognition of a new instance of periodic motion against pre-stored motion templates is carried out by seeking best motion power spectral similarity. We test this method through nine examples of human periodic motion using MoCap data. The recognition results demonstrate that feature-based spectral analysis allows classification of periodic motions from low-level, un-structured interpretation without recovering underlying kinematics. Contrasting with common structure-based spatio-temporal approaches, this motion-based frequency-domain method avoids a time-consuming recovery of underlying kinematic structures in visual analysis and largely reduces the parameter domain in the presence of human motion irregularities. (c) 2006 Elsevier B.V. All rights reserved.
C1 Manchester Metropolitan Univ, Dept Comp & Math, Manchester M1 5GD, Lancs, England.
   Univ Wales, Dept Comp Sci, Aberystwyth, Dyfed, Wales.
C3 Manchester Metropolitan University; Aberystwyth University
RP Li, B (corresponding author), Manchester Metropolitan Univ, Dept Comp & Math, Manchester M1 5GD, Lancs, England.
EM b.li@mmu.ac.uk
CR ABDELKADER C, 2002, IEEE INT C AUT FAC G
   Angeloni C., 1994, IEEE Transactions on Rehabilitation Engineering, V2, P40, DOI 10.1109/86.296343
   BARCLAY CD, 1978, PERCEPT PSYCHOPHYS, V23, P145, DOI 10.3758/BF03208295
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   BOYD J, 1997, P IEEE COMP VIS PATT
   CAMPBELL L, 1996, P IEEE INT C COMP VI, P624
   CEDRAS C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P214, DOI 10.1109/CVPR.1994.323832
   Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]
   CUTLER R, 2000, P IEEE COMP VIS PATT, P326
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   DEUTSCHER ADJ, 2001, P IEEE COMP VIS PATT
   Dorfmüller K, 1999, COMPUT GRAPH-UK, V23, P795, DOI 10.1016/S0097-8493(99)00105-3
   FERRIGNO G, 1988, MED BIOL ENG COMPUT, V26, P321, DOI 10.1007/BF02447089
   FUJIYOSHI H, 1998, P IEEE WORKSH APPL C
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056
   Gleicher M, 1999, COMPUT GRAPHICS-US, V33, P51, DOI 10.1145/345370.345409
   GODDARD NH, 1992, THESIS U ROCHESTER
   Hill H, 2000, PSYCHOL SCI, V11, P223, DOI 10.1111/1467-9280.00245
   Hilton A, 2000, VISUAL COMPUT, V16, P411, DOI 10.1007/PL00013395
   Huang PS, 1999, ARTIF INTELL ENG, V13, P359, DOI 10.1016/S0954-1810(99)00008-4
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   Kakadiaris IA, 1998, INT J COMPUT VISION, V30, P191, DOI 10.1023/A:1008071332753
   KOHLE M, 1996, P 7 AUSTR C NEUR NET
   Li Y, 2002, IMAGE VISION COMPUT, V20, P841, DOI 10.1016/S0262-8856(02)00094-X
   MA Y, 2004, BRAIN INSPIRED COGNI
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   NING H, 2002, P IEEE INT C MULT IN
   Pentland AP, 1996, SCI AM, V274, P68, DOI 10.1038/scientificamerican0496-68
   Polana R, 1997, INT J COMPUT VISION, V23, P261, DOI 10.1023/A:1007975200487
   Polana R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P2, DOI 10.1109/CVPR.1993.341009
   Ren XF, 2005, IEEE I CONF COMP VIS, P824
   Richards JG, 1999, HUM MOVEMENT SCI, V18, P589, DOI 10.1016/S0167-9457(99)00023-8
   SHAH M., 1997, MOTION BASED RECOGNI
   SHAH SP, 1995, ADV CEM BASED MATER, V2, P1, DOI 10.1016/1065-7355(95)90032-2
   SODERKVIST I, 1993, J BIOMECH, V26, P1473, DOI 10.1016/0021-9290(93)90098-Y
   STODDART AJ, 1999, IEE ELECT COMMUNICAT, V103
   TSAI PS, 1994, PATTERN RECOGN, V27, P1591, DOI 10.1016/0031-3203(94)90079-5
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Whittle M.W., 2014, GAIT ANAL INTRO
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
NR 43
TC 19
Z9 26
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 795
EP 809
DI 10.1016/j.imavis.2006.01.033
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100001
OA Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Figueroa, PJ
   Leite, NJ
   Barros, RML
AF Figueroa, Pascual J.
   Leite, Neucimar J.
   Barros, Ricardo M. L.
TI Background recovering in outdoor image sequences: An example of soccer
   players segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE background recovering; sport video images; mathematical morphology;
   image segmentation
AB In this work, we consider the problem of background pixels information recovering which can be used, for example, in applications concerning segmentation and tracking of components in video images. Shortly, to recover the background of image sequences representing outdoor scenes, we consider a non-parametric morphological leveling operation, which takes into account the specific problem of lighting changes and the fact that we can have both slow and fast motion in the scene. We illustrate the segmentation of players based on the difference between image sequences and the corresponding recovered background representation. We also discuss the reduction of shadows in digital video of soccer games and show the good results of the whole background recovering and segmentation process. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Estadual Campinas, Inst Computacao, BR-13084971 Campinas, SP, Brazil.
   Univ Estadual Campinas, Fac Educ Fis, Lab Instrumentacao Biomecan, BR-13083851 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas; Universidade Estadual de Campinas
RP Leite, NJ (corresponding author), Univ Estadual Campinas, Inst Computacao, Avenida Albert Einstein,1251,Caixa Postal 6176, BR-13084971 Campinas, SP, Brazil.
EM neucimar@ic.unicamp.br
RI Leite, Neucimar J/H-7299-2012; de Barros, Ricardo Machado
   Leite/AAF-4555-2020
OI de Barros, Ricardo Machado Leite/0000-0002-9554-1381
CR [Anonymous], IMAGE ANAL MATH MORP
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   Cavallaro A, 2001, PROC SPIE, V4310, P465
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   François ARJ, 1999, INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY, PROCEEDINGS, P227
   GRIMAUD M, 1992, P IM ALG MORPH IM PR, V3, P294
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Lu Y, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, PROCEEDINGS, P807
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Mech R, 1997, INT CONF ACOUST SPEE, P2657, DOI 10.1109/ICASSP.1997.595335
   Meier T, 1999, IEEE T CIRC SYST VID, V9, P1190, DOI 10.1109/76.809155
   Moscheni F, 1998, IEEE T PATTERN ANAL, V20, P897, DOI 10.1109/34.713358
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   RIDDER C, 1995, ADAPTIVE BACKGROUND
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
NR 17
TC 46
Z9 52
U1 3
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2006
VL 24
IS 4
BP 363
EP 374
DI 10.1016/j.imavis.2005.12.012
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 049US
UT WOS:000238043500005
DA 2024-07-18
ER

PT J
AU Kang, SH
   Shen, JH
AF Kang, SH
   Shen, JH
TI Video dejittering by bake and shake
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE line jitters; dejittering; Perona-Malik; bake; edge preservation; total
   variation; PDE based method; Newton-Raphson; shake; texture
ID EDGE-DETECTION; IMAGE; TV
AB Video jittering occurs when the horizontal lines of video image frames are randomly displaced due 10 the corruption of synchronization signals or electromagnetic interference during video transmission. Inspired by the recent Bayesian/variational dejittering model of Shen (SIAM J. Appl. Math., vol. 64, pp. 1691-1708, 2004), in the current paper we propose a novel dejittering approach nicknamed 'bake-and-shake.' The bake step is to apply Perona-Malik type nonlinear diffusions to 'melt away' or heat Up the jittered video frames, based upon which the shake step is able to optimally estimate. the individual line jitters and renormalize the jittered images. Numerical implementation of the bake-and-shake algorithm as well as several computational results are presented. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Kentucky, Dept Math, Lexington, KY 40506 USA.
   Univ Minnesota, Sch Math, Minneapolis, MN 55455 USA.
C3 University of Kentucky; University of Minnesota System; University of
   Minnesota Twin Cities
RP Univ Kentucky, Dept Math, 715 Patterson Off Tower, Lexington, KY 40506 USA.
EM skang@ms.uky.edu; jhshen@math.umn.edu
OI Shen, Jackie/0000-0003-0653-3951; Kang, Sung Ha/0000-0002-0312-6595
CR [Anonymous], 1992, Introduction to numerical analysis
   Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan TF, 2003, SIAM J APPL MATH, V63, P564
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P231, DOI 10.1109/83.902288
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Kimmel R, 2002, J VIS COMMUN IMAGE R, V13, P238, DOI 10.1006/jvci.2001.0501
   Kokaram A, 1997, INT CONF ACOUST SPEE, P2553, DOI 10.1109/ICASSP.1997.595309
   Kokaram A., 1998, Motion Picture Restoration
   KOKARAM AC, 1992, SIGNAL PROCESS, V6, P1283
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shen JH, 2004, SIAM J APPL MATH, V64, P1691, DOI 10.1137/S0036139902418699
   Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563
   Trahanias PE, 1996, IEEE T IMAGE PROCESS, V5, P868, DOI 10.1109/83.503905
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Witkin A.P., 1984, Image Understanding, P79
NR 20
TC 7
Z9 7
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 143
EP 152
DI 10.1016/j.imavis.2005.09.022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900004
DA 2024-07-18
ER

PT J
AU Wang, YJ
   Chua, CS
AF Wang, YJ
   Chua, CS
TI Robust face recognition from 2D and 3D images using structural Hausdorff
   distance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; range data; Gabor filter response; point signature;
   structural Hausdorff distance
AB This paper presents a recognition system that is invariant to both viewing directions and facial expressions. This system is based on both 3D range data as well as 2D grey-level facial images. An irregular 2D mesh labeled by 12 landmarks and a 3D region labeled by four landmarks are defined in each face for feature extraction. Nodes of the 2D mesh are described by Gabor filter responses and 3D points are represented by Point signatures. A subset of mesh nodes (feature nodes), from which discriminating and expression-invariant 2D features can be extracted. is automatically selected for each subject. In the face library, each subject is represented, using both 2D and 3D features, by a frontal face with a neutral facial expression. To classify test faces under varying views or varying facial expressions, a robust Structural Hausdorff Distance is proposed to handle the possible case of matching incomplete data under structural constraints. The best matched model is determined based on the linear integration of matching results ill 2D and 31) domains. Good experimental results have been obtained based oil our database (involving 80 persons with different facial expressions and viewpoints). (c) 2005 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Elect & Elect Engn, Nanyang Ave, Singapore 639798, Singapore.
EM ecschua@nlu.edu.sg
CR Alkoot FM, 1999, PATTERN RECOGN LETT, V20, P1361, DOI 10.1016/S0167-8655(99)00107-5
   [Anonymous], P 5 IEEE INT C AUT F
   Ayinde O, 2002, PATTERN RECOGN, V35, P1275, DOI 10.1016/S0031-3203(01)00120-0
   Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9
   BEYMER D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P500, DOI 10.1109/ICCV.1995.466898
   BEYMER DJ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P756, DOI 10.1109/CVPR.1994.323893
   Bowyer KW, 2004, INT C PATT RECOG, P358, DOI 10.1109/ICPR.2004.1334126
   Carcassoni M, 2000, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2000.906013
   CHANG KI, 2003, WORKSH MULT US AUTH, P25
   Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   Feng GC, 2000, IEEE T SYST MAN CY A, V30, P871, DOI 10.1109/3468.895926
   Gao Y, 2001, IEE P-VIS IMAGE SIGN, V148, P248, DOI 10.1049/ip-vis:20010377
   Halici U, 1999, INT SER COMPUTAT INT, P1
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Petrakos M, 2001, IEEE T GEOSCI REMOTE, V39, P2539, DOI 10.1109/36.964992
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3
   Takacs B, 1998, PATTERN RECOGN, V31, P1873, DOI 10.1016/S0031-3203(98)00076-4
   Tanaka HT, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P372, DOI 10.1109/AFGR.1998.670977
   TURK DC, 1991, APS B, V1, P1
   Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
NR 25
TC 16
Z9 18
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 176
EP 185
DI 10.1016/j.imavis.2005.09.025
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900007
DA 2024-07-18
ER

PT J
AU Bensaali, F
   Amira, A
AF Bensaali, F
   Amira, A
TI Accelerating colour space conversion on reconfigurable hardware
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE colour space conversion; field programmable gate array; distributed
   arithmetic
AB Colour space conversion is very important in many types of image processing applications including video compression. This operation consumes up to 40% of the entire processing power of a highly optimised decoder. Therefore, techniques which efficiently implement this conversion are desired. This paper presents two novel architectures for efficient implementation of a Colour Space Converter (CSC) suitable for Field Programmable Gate Array (FPGAs) and VLSI. The proposed architectures are based on Distributed Arithmetic (DA) ROM accumulator principles. The architectures have been implemented and verified using the Celoxica RC1000 FPGA development board. In addition, they are platform independent and have a low latency (eight cycles). The first architecture has a throughput of height, while the second one is fully pipelined and has a throughput of one and capable of sustained data rate of over 234 mega-conversions/s. (c) 2005 Elsevier B.V. All rights reserved.
C1 Queens Univ Belfast, Sch Comp Sci, Belfast BT7 1NN, Antrim, North Ireland.
C3 Queens University Belfast
RP Queens Univ Belfast, Sch Comp Sci, Belfast BT7 1NN, Antrim, North Ireland.
EM f.bensaali@qub.ac.uk; a.amira@qub.ac.uk
OI Bensaali, Faycal/0000-0002-9273-4735
CR Albiol A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P681, DOI 10.1109/ICIP.2001.958585
   *ALMA TECHN, 2002, HIGH PERF COL SPAC C
   AMIRA A, 2001, THESIS QUEENS U BELF
   AMIRA A, 2003, P INT C IM PROC ICIP
   *AMPH SEM LTD, 2002, COL SPAC CONV
   BARTKOWIAK M, 2001, EURASIP ECMCS 2001 B
   BENSAALI F, 2003, INT C COMP COMM CONT
   BENSAALI F, 2004, LECT NOTES COMPUTER
   BENSAALI F, 2003, 10 IEEE INT C EL CIR
   BRACAMONTE J, 2000, IEEE NORD SIGN PROC
   *CEL LTD, 2001, RC1000 CEL LTD
   *CEL LTED, 2003, MAN HAND C LANG REF
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   GUSTAFSSON O, 2000, P IEEE NORD SIGN PRO, P295
   Mitchell J.L., 1996, MPEG VIDEO COMPRESSI
   OHLSSON H, 2000, P IEEE NORD SIGN PRO, P295
   PAYETTE B, 2002, XAPP637
   Poynton CharlesA., 1996, TECHNICAL INTRO DIGI
   Sima M, 2003, IEEE INT CONF ASAP, P250, DOI 10.1109/ASAP.2003.1212848
NR 19
TC 15
Z9 18
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2005
VL 23
IS 11
BP 935
EP 942
DI 10.1016/j.imavis.2005.03.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 973KF
UT WOS:000232520600001
DA 2024-07-18
ER

PT J
AU Navon, E
   Miller, O
   Averbuch, A
AF Navon, E
   Miller, O
   Averbuch, A
TI Color image segmentation based on adaptive local thresholds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE local thresholds; image segmentation; homogeneity; splitting; merging
ID COMPRESSION; WATERSHEDS
AB The goal of still color image segmentation is to divide the image into homogeneous regions. Object extraction, object recognition and object-based compression are typical applications that use still segmentation as a low-level image processing. In this paper, we present a new method for color image segmentation. The proposed algorithm divides the image into homogeneous regions by local thresholds. The number of thresholds and their values are adaptively derived by an automatic process, where local information is taken into consideration. First, the watershed algorithm is applied. Its results are used as an initialization for the next step, which is iterative merging process. During the iterative process, regions are merged and local thresholds are derived. The thresholds are determined one-by-one at different times during the merging process. Every threshold is calculated by local information on any region and its surroundings. Any statistical information on the input images is not given. The algorithm is found to be reliable and robust to different kind of images. (C) 2004 Elsevier B.V. All rights reserved.
C1 Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel.
C3 Tel Aviv University
RP Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel.
EM ofer@miller-home.net
RI cai, bo/G-1491-2010
CR ADAMS R, 1994, IEEE T PATT AN MACH, V6
   [Anonymous], 1974, P 2 INT JOINT C PATT
   [Anonymous], 1987, INT J PATTERN RECOGN, DOI [DOI 10.1142/S0218001487000242, 10.1142/s0218001487000242]
   Belloulata K, 2002, IEEE T IMAGE PROCESS, V11, P351, DOI 10.1109/TIP.2002.999669
   BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081
   BEVERIDGE JR, 1989, INT J COMPUT VISION, V2, P311, DOI 10.1007/BF00158168
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHANG YL, 1994, IEEE T IMAGE PROCESS, V3, P868, DOI 10.1109/83.336259
   CHEN SY, 1991, CVGIP-GRAPH MODEL IM, V53, P457, DOI 10.1016/1049-9652(91)90030-N
   CHENG HD, 2000, IEEE T IMAGING PROCE, V9
   Cox I. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P557, DOI 10.1109/ICPR.1996.546886
   De Smet P, 1998, CISST'98: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, P266
   DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   DUFAUX F, 1995, IEEE P INT C IM P 95
   GAO H, 2001, IEEE T CIRCUITS SYST, V11
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jain KA, 1989, FUNDAMENTAL DIGITAL
   KUNT M, 1987, IEEE T CIRCUITS SYST, V34, P1306, DOI 10.1109/TCS.1987.1086071
   Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   MURRIETACID R, 1998, IEEE RSJ INT C INT R, P738
   Ozyildiz E, 2002, PATTERN RECOGN, V35, P2013, DOI 10.1016/S0031-3203(01)00181-9
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050
   PERONA P, 1998, P EUR C COMP VIS, P655
   RADHA H, 1996, IEEE T IMAGING PROCE, V5
   SARABI A, 1981, PATTERN RECOGN, V13, P417, DOI 10.1016/0031-3203(81)90004-2
   SCHACTER B, 1975, SCEN SEGMENTATION CL
   Sharon E, 2000, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2000.855801
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SUETENS P, 1992, COMPUT SURV, V24, P5, DOI 10.1145/128762.128763
   TENENBAUM JM, 1974, 87 STANDF RES I ART
   Thomas H., 1990, INTRO ALGORITHMS
   Underwood S., 1977, Computer Graphics and Image Processing, V6, P1
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wang XD, 1998, BIO-MED MATER ENG, V8, P1
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   WU ZY, 1993, CVGIP-GRAPH MODEL IM, V55, P370, DOI 10.1006/cgip.1993.1028
   YANG DS, 1998, P INT C PATT REC BRI, P738
NR 42
TC 99
Z9 126
U1 3
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2005
VL 23
IS 1
BP 69
EP 85
DI 10.1016/j.imavis.2004.05.011
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 882BO
UT WOS:000225913700007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Campadelli, P
   Lanzarotti, R
AF Campadelli, P
   Lanzarotti, R
TI Fiducial point localization in color images of face foregrounds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE facial feature extraction; fiducial point estimation; face analysis
ID RECOGNITION
AB We describe a method for the automatic identification of facial features (eyes, nose, mouth and chin) and the precise localization of their fiducial points (e.g. nose tip, mouth and eye corners) in color images of face foregrounds.
   The algorithm requires as input 2D color images, representing face foregrounds with homogeneous background; it is scale-independent, it deals with either frontal, rotated (up to 30degrees) or slightly tilted (up to 10degrees) faces, and it is robust to different facial expressions, requiring the mouth closed and the eyes opened, and no wearing glasses.
   The method proceeds with subsequent refinements: first, it identifies the sub images containing each feature, afterwards, it processes the single features separately by a blend of techniques which use both color and shape information.
   The system has been tested on three databases: the XM2VTS database, the University of Stirling database, and ours, for a total of 1650 images. The obtained results are described quantitatively and discussed. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Milan, Dipartimento Sci Informaz, I-20135 Milan, Italy.
C3 University of Milan
RP Univ Milan, Dipartimento Sci Informaz, Via Comelico 39-41, I-20135 Milan, Italy.
EM campadelli@dsi.unimi.it; lanzarotti@dsi.unimi.it
OI Lanzarotti, Raffaella/0000-0002-8534-4413
CR AHLBERG J, 1999, LITHISYR2172
   AIZAWA K, 1996, VIDEO CODING 2 GENER
   [Anonymous], PSYCHOL IMAGE COLLEC
   BRAATHEN B, 2002, INT C AUT FAC GEST R
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Campadelli P, 2002, LECT NOTES COMPUT SC, V2486, P124
   CAMPADELLI P, 2003, COLOR BASED METHOD F
   CAMPADELLI P, P IEEE INT C IM AN P, P68
   Dubuisson M, 1994, P 12 INT C PATT REC
   Eisert P, 2000, IEEE T CIRC SYST VID, V10, P344, DOI 10.1109/76.836279
   Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693
   Herpers R., 1998, FACE RECOGNITION THE, P457
   Hsu RL, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P693, DOI 10.1109/ICIP.2001.958588
   Kawaguchi T, 2000, IEEE IMAGE PROC, P49, DOI 10.1109/ICIP.2000.900889
   Lo H.-C., 2002, Proceedings of the IASTED International Conference Signal Processing, Pattern Recognition, and Application, P235
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Odone F, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P290, DOI 10.1109/ICIAP.2001.957024
   OSUNA E, 1997, P INT C COMP VIS PAT
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pardàs M, 2001, IEEE IMAGE PROC, P1058, DOI 10.1109/ICIP.2001.959231
   Petrov M, 1998, IEEE COMPUT GRAPH, V18, P28, DOI 10.1109/38.674969
   PIGHIN F, 1998, P SIGGRAPH 98, P75
   PROESMAN M, 1998, P ICCV98, P215
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   TURKER M, 1991, J COGNITIVE NEUROSCI, V3
   UCHIYAMA T, 1994, IEEE T PATTERN ANAL, V16, P1197, DOI 10.1109/34.387488
   Wiskott L, 1999, INT SER COMPUTAT INT, P355
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zamperoni P., 1996, INT J SHAPE MODEL, V2, P189
   ZAMPERONI P, 1996, PROGR FEATURE PROCES
NR 31
TC 15
Z9 17
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2004
VL 22
IS 11
BP 863
EP 872
DI 10.1016/j.imavis.2003.07.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 847MJ
UT WOS:000223396600001
DA 2024-07-18
ER

PT J
AU Kittler, J
   Ghaderi, R
   Windeatt, T
   Matas, J
AF Kittler, J
   Ghaderi, R
   Windeatt, T
   Matas, J
TI Face verification via error correcting output codes
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE error correcting output coding; sub-sets; Minkowski
AB We propose a novel approach to face verification based on the Error Correcting Output Coding (ECOC) classifier design concept. In the training phase, the client set is repeatedly divided into two ECOC specified sub-sets (super-classes) to train a set of binary classifiers. The output of the classifiers defines the ECOC feature space, in which it is easier to separate transformed patterns representing clients and impostors. As a matching score in this space, we propose the average first order Minkowski distance between the probe and gallery images. The proposed method exhibits superior verification performance on the well known XM2VTS data set as compared with previously reported results. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
C3 University of Surrey
RP Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
EM j.kittler@eiin.suffey.ac.uk; t.windeatt@eim.surrey.ac.uk
RI , Matas/AAW-3282-2020
OI Matas, Jiri/0000-0003-0863-4844; ghaderi, reza/0000-0002-1499-6465
CR ALLWEIN EL, 2000, MACH LEARN, P1
   [Anonymous], INT C ART INT SOFT C
   Belhumeur P.N., 1996, P EUROPEAN C COMPUTE, V1, P45
   BENYACOUB S, 1999, COMPUTER VISION PATT, P580
   Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281
   Devijver P. A., 1982, PATTERN RECOGNITION, V265
   DIETTERICH TG, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P572
   Dietterich TG, 1994, J ARTIF INTELL RES, V2, P263
   Ghaderi R, 2000, INT C PATT RECOG, P203, DOI 10.1109/ICPR.2000.906048
   JAMES G, 1998, THESIS U STANFORD
   Kittler J., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P42
   KITTLER J, 2000, STAT DIRECTIONS SHAP, P63
   Kittler J., 2000, MULTIPLE CLASSIFIER
   LI YP, 2000, THESIS U SURREY SURR
   Luettin J., 1998, EVALUATION PROTOCOL
   Matas J, 1999, IMAGE VISION COMPUT, V17, P575, DOI 10.1016/S0262-8856(98)00176-0
   Matas J, 2000, INT C PATT RECOG, P858
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Peterson W. W., 1972, ERROR CORRECTING COD
   Samaria F. S., 1994, P 2 IEEE WORKSH APPL
   Sejnowski T. J., 1987, Complex Systems, V1, P145
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   WINDEATT T, 2000, 14 ANN INT C SOC PHO, P23
NR 23
TC 29
Z9 30
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1163
EP 1169
DI 10.1016/j.imavis.2003.09.013
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100011
DA 2024-07-18
ER

PT J
AU Davis, JW
   Gao, H
AF Davis, JW
   Gao, H
TI An expressive three-mode principal components model of human action
   style
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE action recognition; style; three-mode principal components; motion
   analysis; gesture recognition
ID VISUAL-PERCEPTION; BIOLOGICAL MOTION; HUMAN MOVEMENT; RECOGNITION;
   GENDER
AB We present a three-mode expressive-feature model for representing and recognizing performance styles of human actions. A set of style variations for an action are initially arranged into a three-mode data representation (body pose, time, style) and factored into its three-mode principal components to reduce the data dimensionality. We next embed tunable weights on trajectories within the sub-space model to enable different context-based style estimations. We outline physical and perceptual parameterization methods for choosing style labels for the training data, from which we automatically learn the necessary expressive weights using a gradient descent procedure. Experiments are presented examining several motion-capture walking variations corresponding to carrying load, gender, and pace. Results demonstrate a greater flexibility of the expressive three-mode model, over standard squared-error style estimation, to adapt to different style matching criteria. (C) 2003 Elsevier B.V. All rights reserved.
C1 Ohio State Univ, Dept Comp & Informat Sci, Comp Vis Lab, Dreese Lab 491, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Ohio State Univ, Dept Comp & Informat Sci, Comp Vis Lab, Dreese Lab 491, 2015 Neil Ave, Columbus, OH 43210 USA.
EM jwdavis@cis.ohio-state.edu
RI Davis, James/D-4314-2012
CR AGARWAL J, 1997, NONR ART MOT WKSHP I, P90
   Ali A, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P28, DOI 10.1109/EVENT.2001.938863
   [Anonymous], 1984, Muscles, reflexes, and locomotion
   [Anonymous], 1983, Three-mode Principal Component Analysis. Theory and Applications
   BARCLAY CD, 1978, PERCEPT PSYCHOPHYS, V23, P145, DOI 10.3758/BF03208295
   Ben-Arie J, 2002, IEEE T PATTERN ANAL, V24, P1091, DOI 10.1109/TPAMI.2002.1023805
   Black MJ, 1997, PROC CVPR IEEE, P561, DOI 10.1109/CVPR.1997.609381
   Bobick A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P307, DOI 10.1109/ICPR.1996.546039
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581
   Burden R. L., 2011, NUMERICAL ANAL
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   CUI YT, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P631, DOI 10.1109/ICCV.1995.466879
   CUTTING JE, 1978, J EXP PSYCHOL HUMAN, V4, P357, DOI 10.1037/0096-1523.4.3.357
   DAVIS J, 2002, WKSHP MOT VID COMP I, P139
   Davis J. W., 2002, SIGGRAPH C ABSTR APP, P182
   Davis JW, 2001, LECT NOTES COMPUT SC, V2091, P295
   Davis JW, 2002, INT C PATT RECOG, P315, DOI 10.1109/ICPR.2002.1044702
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Dockstader SL, 2002, INT C PATT RECOG, P5, DOI 10.1109/ICPR.2002.1044575
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   GIESE M, 2000, INT J COMPUT VIS, V38
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   KOZLOWSKI LT, 1978, PERCEPT PSYCHOPHYS, V23, P459, DOI 10.3758/BF03204150
   KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740
   KROONENBERG PM, 1980, PSYCHOMETRIKA, V45, P69, DOI 10.1007/BF02293599
   Li N., 1997, MOTION BASED RECOGNI, P345
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   NEAL RJ, 1991, HUM MOVEMENT SCI, V10, P653, DOI 10.1016/0167-9457(91)90021-O
   Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203
   Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0
   Rao C, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P55, DOI 10.1109/EVENT.2001.938867
   Rosales R, 2000, PROC CVPR IEEE, P721, DOI 10.1109/CVPR.2000.854946
   RUNESON S, 1981, J EXP PSYCHOL HUMAN, V7, P733, DOI 10.1037/0096-1523.7.4.733
   Tenenbaum JB, 1997, ADV NEUR IN, V9, P662
   Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   UNUMA M, 1991, P COMP AN, P77
   Unuma M., 1995, P 22 ANN C COMPUTER, P91, DOI DOI 10.1145/218380.218419
   VASILESCU M, 2001, SIGGRAPH C ABSTR APP, P200
   Vasilescu M.A. O., 2002, Proc. ECCV, P447
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   Yamamoto M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P604, DOI 10.1109/AFGR.1998.671014
NR 45
TC 13
Z9 18
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2003
VL 21
IS 11
BP 1001
EP 1016
DI 10.1016/S0262-8856(03)00138-0
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 731CP
UT WOS:000185867200005
DA 2024-07-18
ER

PT J
AU Zhao, T
   Nevatia, R
AF Zhao, T
   Nevatia, R
TI Car detection in low resolution aerial images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE car detection; object detection multi-cue integration; Bayesian network;
   aerial image analysis
AB We present a system to detect passenger cars in aerial images along the road directions where cars appear as small objects. We pose this as a 3D object recognition problem to account for the variation in viewpoint and the shadow. We started from psychological tests to find important features for human detection of cars. Based on these observations, we selected the boundary of the car body, the boundary of the front windshield. and the shadow as the features. Some of these features are affected by the intensity of the car and whether or not there is a shadow along it. This information is represented in the structure of the Bayesian network that we use to integrate all features. Experiments show very promising results even on some very challenging images. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Univ So Calif, Inst Robot & Intelligent Syst, PHE 232,MC-0273, Los Angeles, CA 90089 USA.
EM taozhao@iris.usc.edu; nevatia@iris.usc.edu
CR Burlina P., 1997, DARPA Image Understanding Workshop, P577
   Kim ZW, 1999, COMPUT VIS IMAGE UND, V76, P278, DOI 10.1006/cviu.1999.0803
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   LIU G, VEHICLE DETECTION AE
   Moon H, 2002, IMAGE VISION COMPUT, V20, P1, DOI 10.1016/S0262-8856(01)00059-2
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Pearl J., 1988, PROBABILISTIC REASON
   Price K, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P148, DOI 10.1109/WACV.2000.895416
   Rajagopalan A. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1204, DOI 10.1109/ICCV.1999.790417
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
NR 11
TC 84
Z9 93
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2003
VL 21
IS 8
BP 693
EP 703
DI 10.1016/S0262-8856(03)00064-7
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 706VM
UT WOS:000184475800002
DA 2024-07-18
ER

PT J
AU Stevens, MR
   Snorrason, M
AF Stevens, MR
   Snorrason, M
TI Automatic target segmentation using PMMW imagery
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT IEEE Workshop in Computer Vision Beyond the Visible Spectrum
CY DEC   14, 2001
CL KAUAI, HAWAII
SP IEEE
DE automatic target segmentation; target detection; passive
   millimeter-wave; laser radar
AB Automatic target segmentation is complicated by the highly variable appearance of tat-gets in imagery taken under realistic operating conditions. In many situations, high-resolution, high-fidelity imagery only complicates the isolation of targets from non-target background. In this paper we present an analysis of the signatures of military vehicles in low-resolution, low-fidelity passive millimeter-wave (PMMW) imagery. A simple model based on Gaussian curvature is developed that characterizes a wide range of target types. This model is used to segment imagery into binary target/non-target regions. The performance of this algorithm is compared to a set of algorithms operating on co-registered laser radar (LADAR) imagery. The comparison shows the PMMW segmentation algorithm producing much fewer false alarm regions. but missing more targets than the LADAR algorithms. We also demonstrate that PMMW sensors show great promise for target detection and for cueing subsequent target identification algorithms. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Charles River Analyt, Cambridge, MA 02138 USA.
C3 Charles River Analytics Inc
RP Stevens, MR (corresponding author), Charles River Analyt, Cambridge, MA 02138 USA.
CR [Anonymous], 1989, FUNDAMENTALS DIGITAL
   BHATTACHARJEE S, 2000, INT C IM PROC IEEE
   BLUME BT, 1997, AEROSENSE SPIE, V3079
   BLUME BT, 1998, AEROSENSE SPIE, V3378
   FORNACA S, 1998, AEROSENSE SPIE
   Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791
   Klein L. A., 1997, MILLIMETER WAVE INFR
   LIN C, 1999, AEROSENSE SPIE
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   *NICH RES CORP, 1999, IRMA 4 1 MAN
   STEVENS M, 2001, SPIE AEROSENSE
   STEVENS MR, 2001, COMPUTER VISION VISI
   TANG YL, 1993, NASA C PUBLICATION, P313
   TARLETON N, 1998, AEROSENSE SPIE
   WATSON JS, 1998, AEROSENSE SPIE, V3375
NR 15
TC 3
Z9 3
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2003
VL 21
IS 7
BP 609
EP 622
DI 10.1016/S0262-8856(03)00058-1
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 706FR
UT WOS:000184443400005
DA 2024-07-18
ER

EF